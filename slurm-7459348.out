NODELIST=lrdn0028
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
0
213


DEVICE SET
DEVICE SET
DEVICE SET
DEVICE SET
09/09/2024 16:56:14 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 0
09/09/2024 16:56:14 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 1
09/09/2024 16:56:14 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 2
09/09/2024 16:56:14 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 3
09/09/2024 16:56:14 - INFO - torch.distributed.distributed_c10d -   Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
09/09/2024 16:56:14 - INFO - torch.distributed.distributed_c10d -   Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
09/09/2024 16:56:14 - INFO - torch.distributed.distributed_c10d -   Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
09/09/2024 16:56:14 - INFO - torch.distributed.distributed_c10d -   Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
09/09/2024 16:56:14 - INFO - __main__ -   ==================model_configs==================

09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_model_type : vast
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_itm_ratio : 0.1
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_frozen_vision : False
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_frozen_audio : False
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_checkpointing : True
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_max_caption_len : 40
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_max_omni_caption_len : 70
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_max_subtitle_len : 70
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_contra_dim : 512
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_inherit_keys : ['vision_encoder_type', 'audio_encoder_type', 'audio_melbins', 'audio_target_length']
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_frame_embedding_type : adaptive
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_vision_resolution : 224
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_vision_encoder_type : evaclip01_giant
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_audio_encoder_type : beats
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_audio_melbins : 64
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_audio_target_length : 1024
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_beam_size : 3
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_captioner_mode : False
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_generate_nums : 1
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_ret_bidirection_evaluation : False
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_itm_rerank_num : 50
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_evaluation_type : evaluation_mm
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_default : ./config/vast/default_model_cfg.json
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_max_vision_sample_num : 2
09/09/2024 16:56:14 - INFO - __main__ -   model_cfg_max_audio_sample_num : 1
09/09/2024 16:56:14 - INFO - __main__ -   ==================run_configs==================

09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_checkpoint : 
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_output_dir : ./output/vast/pretrain_vast/downstream/finetuneVolume256batchlossonlyvolume
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_gradient_accumulation_steps : 1
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_clip_lr : 5e-07
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_optim : adamw
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_learning_rate : 2e-05
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_betas : [0.9, 0.98]
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_weight_decay : 0.01
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_grad_norm : 2.0
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_warmup_ratio : 0.1
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_resume : False
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_seed : 50
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_fp16 : True
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_bf16 : False
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_zero_shot : False
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_scheduler : warmup_linear
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_new_lr : 0
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_new_params_name : []
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_valid_freq : 10
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_dataset_mix_type : random
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_remove_before_ckpt : True
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_first_eval : True
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_pretrain_dir : ./output/vast/pretrain_vast
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_num_train_steps : 0
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_save_best : True
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_pin_mem : True
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_vision_resolution : 224
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_use_ddp : False
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_mode : training
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_log_steps : 100
09/09/2024 16:56:14 - INFO - __main__ -   run_cfg_default : ./config/vast/default_run_cfg.json
09/09/2024 16:56:14 - INFO - __main__ -   ==================data_configs==================

09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_finetune_area_train_type : annoindexed
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_finetune_area_train_training : True
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_finetune_area_train_name : finetune_area
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_finetune_area_train_txt : ../vast27m/annotations100k.json
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_finetune_area_train_vision : ../vast27m/videos/
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_finetune_area_train_audio : ../vast27m/audios
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_finetune_area_train_vision_transforms : crop_flip
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_finetune_area_train_vision_format : video_rawvideo
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_finetune_area_train_vision_sample_num : 2
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_finetune_area_train_audio_sample_num : 1
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_finetune_area_train_task : ret%tv%ta
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_finetune_area_train_epoch : 5
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_finetune_area_train_n_workers : 8
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_finetune_area_train_batch_size : 256
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_msrvtt_ret_val_type : annoindexed
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_msrvtt_ret_val_training : False
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_msrvtt_ret_val_name : msrvtt_ret
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_msrvtt_ret_val_txt : datasets/annotations/msrvtt/descs_ret_test.json
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_msrvtt_ret_val_vision : ../MSRVTT/video_test
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_msrvtt_ret_val_vision_transforms : crop_flip
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_msrvtt_ret_val_vision_format : video_rawvideo
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_msrvtt_ret_val_audio : ../MSRVTT/audio_test
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_msrvtt_ret_val_vision_sample_num : 8
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_msrvtt_ret_val_audio_sample_num : 1
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_msrvtt_ret_val_task : ret%tv
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_msrvtt_ret_val_n_workers : 8
09/09/2024 16:56:14 - INFO - __main__ -   data_cfg_msrvtt_ret_val_batch_size : 64
wandb: Tracking run with wandb version 0.17.8
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
09/09/2024 16:56:19 - INFO - __main__ -   finetune_area Using clip mean and std.
09/09/2024 16:56:19 - INFO - __main__ -   finetune_area transforms crop_flip
ci sono 99621 labelsci sono 99621 labels
ci sono 99621 labels
ci sono 99621 labels

09/09/2024 16:57:01 - INFO - __main__ -   Create Dataset finetune_area Success
09/09/2024 16:57:01 - INFO - __main__ -    loader ret%tv%ta--finetune_area , ratio 1945 , bs_pergpu 64, n_workers 8
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556a771702c0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
09/09/2024 16:57:04 - INFO - __main__ -   msrvtt_ret Using clip mean and std.
09/09/2024 16:57:04 - INFO - __main__ -   msrvtt_ret transforms crop_flip
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
ci sono 884 labels
ci sono 884 labels
ci sono 884 labels
ci sono 884 labels
09/09/2024 16:57:04 - INFO - __main__ -   Create Dataset msrvtt_ret Success
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Please 'pip install xformers'
Please 'pip install xformers'
Please 'pip install xformers'
Please 'pip install xformers'
Please 'pip install xformers'
Please 'pip install xformers'
Please 'pip install xformers'
Please 'pip install xformers'
Please 'pip install xformers'
09/09/2024 16:57:07 - INFO - root -   Loaded EVA01-CLIP-g-14 model config.
09/09/2024 16:57:07 - INFO - root -   Loaded EVA01-CLIP-g-14 model config.
09/09/2024 16:57:07 - INFO - root -   Loaded EVA01-CLIP-g-14 model config.
Please 'pip install xformers'
Please 'pip install xformers'
Please 'pip install xformers'
09/09/2024 16:57:08 - INFO - root -   Loaded EVA01-CLIP-g-14 model config.
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x562362599b40] mmco: unref short failure
[h264 @ 0x559b354a8e40] mmco: unref short failure
[h264 @ 0x559b354a8e40] mmco: unref short failure
[h264 @ 0x559f7d7684c0] mmco: unref short failure
[h264 @ 0x559f7d7684c0] mmco: unref short failure
[h264 @ 0x559f8026df00] mmco: unref short failure
[h264 @ 0x559f7d8b00c0] mmco: unref short failure
[h264 @ 0x559f7d8b00c0] mmco: unref short failure
[h264 @ 0x562362ba1a80] mmco: unref short failure
[h264 @ 0x559f7f09d540] mmco: unref short failure
[h264 @ 0x559f7f09d540] mmco: unref short failure
[h264 @ 0x559b34b61180] mmco: unref short failure
[h264 @ 0x559f824bb140] mmco: unref short failure
09/09/2024 16:58:20 - INFO - root -   Loading pretrained EVA01-CLIP-g-14 weights (./pretrained_weights/clip/EVA01_CLIP_g_14_psz14_s11B.pt).
09/09/2024 16:58:20 - INFO - root -   Loading pretrained EVA01-CLIP-g-14 weights (./pretrained_weights/clip/EVA01_CLIP_g_14_psz14_s11B.pt).
09/09/2024 16:58:23 - INFO - root -   Loading pretrained EVA01-CLIP-g-14 weights (./pretrained_weights/clip/EVA01_CLIP_g_14_psz14_s11B.pt).
[h264 @ 0x559f801dbc80] mmco: unref short failure
[h264 @ 0x559f801dbc80] mmco: unref short failure
09/09/2024 16:58:31 - INFO - root -   Loading pretrained EVA01-CLIP-g-14 weights (./pretrained_weights/clip/EVA01_CLIP_g_14_psz14_s11B.pt).
09/09/2024 16:58:34 - INFO - root -   incompatible_keys.missing_keys: []
09/09/2024 16:58:34 - INFO - root -   incompatible_keys.missing_keys: []
09/09/2024 16:58:34 - INFO - root -   incompatible_keys.missing_keys: []
09/09/2024 16:58:36 - INFO - model.audio_encoders.beats.beats -   BEATs Config: {'input_patch_size': 16, 'embed_dim': 512, 'conv_bias': False, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_wise_gradient_decay_ratio': 1.0, 'layer_norm_first': False, 'deep_norm': True, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True, 'finetuned_model': False, 'predictor_dropout': 0.1, 'predictor_class': 527}
09/09/2024 16:58:36 - INFO - model.audio_encoders.beats.beats -   BEATs Config: {'input_patch_size': 16, 'embed_dim': 512, 'conv_bias': False, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_wise_gradient_decay_ratio': 1.0, 'layer_norm_first': False, 'deep_norm': True, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True, 'finetuned_model': False, 'predictor_dropout': 0.1, 'predictor_class': 527}
09/09/2024 16:58:36 - INFO - model.audio_encoders.beats.beats -   BEATs Config: {'input_patch_size': 16, 'embed_dim': 512, 'conv_bias': False, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_wise_gradient_decay_ratio': 1.0, 'layer_norm_first': False, 'deep_norm': True, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True, 'finetuned_model': False, 'predictor_dropout': 0.1, 'predictor_class': 527}
[h264 @ 0x559b39de4d40] mmco: unref short failure
[h264 @ 0x559b39de4d40] mmco: unref short failure
[h264 @ 0x559b3b4daa40] mmco: unref short failure
[h264 @ 0x559b3b4daa40] mmco: unref short failure
[h264 @ 0x556a791ca200] mmco: unref short failure
09/09/2024 16:58:43 - INFO - root -   incompatible_keys.missing_keys: []
09/09/2024 16:58:45 - INFO - model.audio_encoders.beats.beats -   BEATs Config: {'input_patch_size': 16, 'embed_dim': 512, 'conv_bias': False, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_wise_gradient_decay_ratio': 1.0, 'layer_norm_first': False, 'deep_norm': True, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True, 'finetuned_model': False, 'predictor_dropout': 0.1, 'predictor_class': 527}
09/09/2024 16:58:50 - WARNING - model.text_encoders.bert.bert -   If you want to use `BertForMaskedLM` make sure `config.is_decoder=False` for bi-directional self-attention.
09/09/2024 16:58:50 - WARNING - model.text_encoders.bert.bert -   If you want to use `BertForMaskedLM` make sure `config.is_decoder=False` for bi-directional self-attention.
09/09/2024 16:58:50 - WARNING - model.text_encoders.bert.bert -   If you want to use `BertForMaskedLM` make sure `config.is_decoder=False` for bi-directional self-attention.
[h264 @ 0x556a7a8d6740] mmco: unref short failure
[h264 @ 0x556a79969c00] mmco: unref short failure
09/09/2024 16:58:58 - WARNING - model.text_encoders.bert.bert -   If you want to use `BertForMaskedLM` make sure `config.is_decoder=False` for bi-directional self-attention.
Some weights of BertForMaskedLM were not initialized from the model checkpoint at ./pretrained_weights/bert/bert-base-uncased and are newly initialized: ['encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.key.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.query.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.key.bias', 'cls.predictions.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.query.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.query.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertForMaskedLM were not initialized from the model checkpoint at ./pretrained_weights/bert/bert-base-uncased and are newly initialized: ['encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.key.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'cls.predictions.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.11.crossattention.output.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.10.crossattention.self.value.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertForMaskedLM were not initialized from the model checkpoint at ./pretrained_weights/bert/bert-base-uncased and are newly initialized: ['encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.output.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.output.dense.weight', 'cls.predictions.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.key.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[h264 @ 0x562369f32a40] mmco: unref short failure
[h264 @ 0x562369f32a40] mmco: unref short failure
Some weights of BertForMaskedLM were not initialized from the model checkpoint at ./pretrained_weights/bert/bert-base-uncased and are newly initialized: ['encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.7.crossattention.self.value.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.11.crossattention.self.value.bias', 'cls.predictions.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.8.crossattention.self.key.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.value.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[h264 @ 0x556a78d69ac0] mmco: unref short failure
[h264 @ 0x556a78d69ac0] mmco: unref short failure
09/09/2024 16:59:23 - INFO - __main__ -   load_from_pretrained: ./output/vast/pretrain_vast/ckpt/model_step_204994.pt
09/09/2024 16:59:23 - INFO - __main__ -   Load from pretrained dir ./output/vast/pretrain_vast
[h264 @ 0x56236cff3680] mmco: unref short failure
[h264 @ 0x56236cff3680] mmco: unref short failure
[h264 @ 0x559b409a7840] mmco: unref short failure
09/09/2024 16:59:29 - INFO - __main__ -   Unexpected keys ['vision_encoder.text.logit_scale']
09/09/2024 16:59:29 - INFO - __main__ -   missing_keys  ['vision_encoder.logit_scale']
[h264 @ 0x56236483d800] mmco: unref short failure
09/09/2024 16:59:36 - INFO - __main__ -   ==================learning_rate_settings==================

09/09/2024 16:59:36 - INFO - __main__ -     basic_lr : 2e-05
09/09/2024 16:59:36 - INFO - __main__ -     clip_lr_visual : 5e-07
09/09/2024 16:59:36 - INFO - __main__ -     clip_lr_visual_len : 245
09/09/2024 16:59:36 - INFO - __main__ -     new_lr : 0
09/09/2024 16:59:36 - INFO - __main__ -     new_params_name: []
09/09/2024 16:59:36 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 16:59:36 - INFO - __main__ -   start running ret%tv validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559b34ee4dc0] mmco: unref short failure
[h264 @ 0x559f84286280] mmco: unref short failure
[h264 @ 0x56236320c240] mmco: unref short failure
[h264 @ 0x56236320c240] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559f7e0e33c0] mmco: unref short failure
[h264 @ 0x559f7e0e33c0] mmco: unref short failure
[h264 @ 0x56236848f600] mmco: unref short failure
[h264 @ 0x56236848f600] mmco: unref short failure
[h264 @ 0x56236245e880] mmco: unref short failure
[h264 @ 0x56236245e880] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
[h264 @ 0x559f8059ef00] mmco: unref short failure
[h264 @ 0x556a792ac440] mmco: unref short failure
[h264 @ 0x556a792ac440] mmco: unref short failure
[h264 @ 0x556a7ce84d00] mmco: unref short failure
[h264 @ 0x559b371d87c0] mmco: unref short failure
[h264 @ 0x559b371d87c0] mmco: unref short failure
[h264 @ 0x556a83d042c0] mmco: unref short failure
[h264 @ 0x556a81c0af80] mmco: unref short failure
[h264 @ 0x556a81c0af80] mmco: unref short failure
[h264 @ 0x559b35534ec0] mmco: unref short failure
[h264 @ 0x559b35534ec0] mmco: unref short failure
[h264 @ 0x559f88bef000] mmco: unref short failure
[h264 @ 0x56236d072ec0] mmco: unref short failure
[h264 @ 0x562362d08b80] mmco: unref short failure
[h264 @ 0x562362d08b80] mmco: unref short failure
[h264 @ 0x562362d08b80] mmco: unref short failure
[h264 @ 0x562362d08b80] mmco: unref short failure
[h264 @ 0x559b33dc7000] mmco: unref short failure
[h264 @ 0x559f7d6f9680] mmco: unref short failure
[h264 @ 0x559f7d6f9680] mmco: unref short failure
[h264 @ 0x559b4230b980] mmco: unref short failure
[h264 @ 0x559b4230b980] mmco: unref short failure
[h264 @ 0x562370709bc0] mmco: unref short failure
[h264 @ 0x562370709bc0] mmco: unref short failure
  0%|          | 0/221 [00:00<?, ?it/s]  1%|          | 2/221 [00:00<00:20, 10.86it/s]  2%|▏         | 4/221 [00:00<00:21, 10.28it/s]  3%|▎         | 7/221 [00:00<00:17, 12.25it/s]  4%|▍         | 9/221 [00:00<00:15, 13.72it/s]  5%|▌         | 12/221 [00:02<01:14,  2.79it/s]  7%|▋         | 15/221 [00:03<00:50,  4.11it/s]  8%|▊         | 17/221 [00:03<00:43,  4.74it/s]  9%|▊         | 19/221 [00:03<00:35,  5.63it/s] 10%|▉         | 21/221 [00:03<00:28,  7.01it/s] 10%|█         | 23/221 [00:07<02:17,  1.44it/s] 12%|█▏        | 26/221 [00:07<01:28,  2.20it/s] 13%|█▎        | 28/221 [00:08<01:06,  2.88it/s] 14%|█▍        | 31/221 [00:08<00:45,  4.15it/s] 15%|█▍        | 33/221 [00:08<00:36,  5.20it/s] 16%|█▋        | 36/221 [00:08<00:25,  7.24it/s] 17%|█▋        | 38/221 [00:08<00:22,  8.11it/s] 18%|█▊        | 40/221 [00:08<00:19,  9.45it/s] 19%|█▉        | 43/221 [00:08<00:14, 12.25it/s] 20%|██        | 45/221 [00:09<00:20,  8.51it/s] 21%|██▏       | 47/221 [00:13<01:57,  1.48it/s] 23%|██▎       | 50/221 [00:13<01:15,  2.26it/s] 24%|██▍       | 54/221 [00:17<01:45,  1.58it/s] 25%|██▌       | 56/221 [00:18<01:46,  1.56it/s] 27%|██▋       | 60/221 [00:18<01:06,  2.43it/s] 29%|██▉       | 64/221 [00:19<00:43,  3.64it/s] 30%|██▉       | 66/221 [00:23<01:44,  1.49it/s] 31%|███       | 68/221 [00:23<01:23,  1.83it/s] 32%|███▏      | 70/221 [00:23<01:05,  2.31it/s] 33%|███▎      | 72/221 [00:24<00:50,  2.93it/s] 34%|███▍      | 75/221 [00:24<00:35,  4.16it/s] 35%|███▍      | 77/221 [00:24<00:27,  5.19it/s] 36%|███▌      | 79/221 [00:24<00:25,  5.56it/s] 37%|███▋      | 82/221 [00:24<00:19,  7.00it/s] 39%|███▉      | 86/221 [00:25<00:13, 10.15it/s] 40%|███▉      | 88/221 [00:25<00:12, 10.50it/s] 41%|████      | 90/221 [00:25<00:13,  9.82it/s] 42%|████▏     | 93/221 [00:25<00:14,  8.94it/s] 43%|████▎     | 96/221 [00:26<00:13,  9.54it/s] 45%|████▍     | 99/221 [00:26<00:10, 11.35it/s] 46%|████▌     | 102/221 [00:26<00:08, 13.62it/s] 48%|████▊     | 105/221 [00:26<00:07, 15.76it/s] 48%|████▊     | 107/221 [00:26<00:11,  9.84it/s] 50%|████▉     | 110/221 [00:27<00:08, 12.56it/s] 51%|█████     | 112/221 [00:27<00:10, 10.23it/s] 52%|█████▏    | 115/221 [00:27<00:08, 12.95it/s] 53%|█████▎    | 117/221 [00:32<01:07,  1.55it/s] 54%|█████▍    | 119/221 [00:32<00:50,  2.02it/s] 55%|█████▌    | 122/221 [00:32<00:33,  3.00it/s] 56%|█████▌    | 124/221 [00:32<00:25,  3.77it/s] 57%|█████▋    | 126/221 [00:33<00:26,  3.53it/s] 58%|█████▊    | 128/221 [00:33<00:26,  3.54it/s] 59%|█████▉    | 131/221 [00:34<00:17,  5.23it/s] 60%|██████    | 133/221 [00:34<00:15,  5.58it/s] 61%|██████    | 135/221 [00:35<00:28,  3.05it/s] 62%|██████▏   | 136/221 [00:36<00:28,  2.97it/s] 62%|██████▏   | 137/221 [00:38<00:56,  1.48it/s] 62%|██████▏   | 138/221 [00:38<00:48,  1.71it/s] 63%|██████▎   | 139/221 [00:38<00:44,  1.86it/s] 63%|██████▎   | 140/221 [00:39<00:37,  2.19it/s] 64%|██████▍   | 141/221 [00:39<00:31,  2.56it/s] 64%|██████▍   | 142/221 [00:39<00:24,  3.19it/s] 66%|██████▌   | 145/221 [00:39<00:12,  5.98it/s] 67%|██████▋   | 148/221 [00:39<00:09,  7.69it/s] 68%|██████▊   | 150/221 [00:40<00:09,  7.25it/s] 68%|██████▊   | 151/221 [00:40<00:10,  6.47it/s] 70%|██████▉   | 154/221 [00:40<00:07,  9.22it/s] 71%|███████   | 156/221 [00:45<00:47,  1.37it/s] 71%|███████   | 157/221 [00:45<00:40,  1.60it/s] 72%|███████▏  | 160/221 [00:45<00:23,  2.64it/s] 73%|███████▎  | 162/221 [00:45<00:17,  3.30it/s] 74%|███████▍  | 164/221 [00:45<00:13,  4.10it/s] 75%|███████▌  | 166/221 [00:50<00:46,  1.18it/s] 76%|███████▌  | 167/221 [00:52<00:58,  1.08s/it] 76%|███████▋  | 169/221 [00:52<00:40,  1.28it/s] 77%|███████▋  | 170/221 [00:53<00:33,  1.51it/s] 78%|███████▊  | 173/221 [00:53<00:18,  2.62it/s] 79%|███████▉  | 175/221 [00:53<00:13,  3.49it/s] 80%|████████  | 177/221 [00:53<00:09,  4.49it/s] 81%|████████  | 179/221 [00:54<00:12,  3.29it/s] 82%|████████▏ | 182/221 [00:54<00:08,  4.84it/s] 84%|████████▎ | 185/221 [00:54<00:05,  6.77it/s] 85%|████████▍ | 187/221 [00:54<00:04,  8.12it/s] 86%|████████▌ | 189/221 [00:54<00:03,  8.37it/s] 87%|████████▋ | 193/221 [00:55<00:02, 12.36it/s] 89%|████████▊ | 196/221 [00:55<00:01, 14.96it/s] 90%|█████████ | 199/221 [00:55<00:01, 16.04it/s] 91%|█████████▏| 202/221 [00:55<00:01, 16.28it/s] 93%|█████████▎| 205/221 [00:55<00:01, 15.28it/s] 94%|█████████▍| 208/221 [00:55<00:00, 16.86it/s] 95%|█████████▌| 210/221 [00:56<00:00, 17.29it/s] 96%|█████████▌| 212/221 [00:56<00:00, 15.96it/s] 97%|█████████▋| 214/221 [00:56<00:00, 10.08it/s] 98%|█████████▊| 216/221 [00:58<00:01,  3.24it/s] 99%|█████████▊| 218/221 [00:58<00:00,  4.21it/s]100%|█████████▉| 220/221 [01:03<00:00,  1.22it/s]100%|█████████▉| 220/221 [01:03<00:00,  3.49it/s]
  0%|          | 0/221 [00:00<?, ?it/s]  0%|          | 1/221 [00:00<00:57,  3.79it/s]  1%|          | 2/221 [00:00<00:57,  3.79it/s]  1%|▏         | 3/221 [00:00<00:57,  3.79it/s]  2%|▏         | 4/221 [00:01<00:57,  3.79it/s]  2%|▏         | 5/221 [00:01<00:56,  3.79it/s]  3%|▎         | 6/221 [00:01<00:56,  3.79it/s]  3%|▎         | 7/221 [00:01<00:56,  3.79it/s]  4%|▎         | 8/221 [00:02<00:56,  3.79it/s]  4%|▍         | 9/221 [00:02<00:55,  3.79it/s]  5%|▍         | 10/221 [00:02<00:55,  3.79it/s]  5%|▍         | 11/221 [00:02<00:55,  3.79it/s]  5%|▌         | 12/221 [00:03<00:55,  3.79it/s]  6%|▌         | 13/221 [00:03<00:54,  3.79it/s]  6%|▋         | 14/221 [00:03<00:54,  3.79it/s]  7%|▋         | 15/221 [00:03<00:54,  3.79it/s]  7%|▋         | 16/221 [00:04<00:54,  3.79it/s]  8%|▊         | 17/221 [00:04<00:53,  3.79it/s]  8%|▊         | 18/221 [00:04<00:53,  3.79it/s]  9%|▊         | 19/221 [00:05<00:53,  3.79it/s]  9%|▉         | 20/221 [00:05<00:53,  3.79it/s] 10%|▉         | 21/221 [00:05<00:52,  3.79it/s] 10%|▉         | 22/221 [00:05<00:52,  3.79it/s] 10%|█         | 23/221 [00:06<00:52,  3.79it/s] 11%|█         | 24/221 [00:06<00:51,  3.79it/s] 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s] 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s] 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s] 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s] 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s] 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s] 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s] 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s] 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s] 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s] 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s] 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s] 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s] 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s] 18%|█▊        | 39/221 [00:10<00:47,  3.79it/s] 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s] 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s] 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s] 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s] 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s] 20%|██        | 45/221 [00:11<00:46,  3.79it/s] 21%|██        | 46/221 [00:12<00:46,  3.79it/s] 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s] 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s] 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s] 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s] 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s] 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s] 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s] 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s] 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s] 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s] 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s] 26%|██▌       | 58/221 [00:15<00:42,  3.79it/s] 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s] 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s] 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s] 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s] 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s] 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s] 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s] 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s] 30%|███       | 67/221 [00:17<00:40,  3.79it/s] 31%|███       | 68/221 [00:17<00:40,  3.79it/s] 31%|███       | 69/221 [00:18<00:40,  3.79it/s] 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s] 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s] 33%|███▎      | 72/221 [00:18<00:39,  3.79it/s] 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s] 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s] 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s] 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s] 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s] 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s] 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s] 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s] 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s] 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s] 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s] 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s] 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s] 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s] 39%|███▉      | 87/221 [00:22<00:35,  3.79it/s] 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s] 40%|████      | 89/221 [00:23<00:34,  3.80it/s] 41%|████      | 90/221 [00:23<00:34,  3.79it/s] 41%|████      | 91/221 [00:23<00:34,  3.79it/s] 42%|████▏     | 92/221 [00:24<00:33,  3.79it/s] 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s] 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s] 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s] 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s] 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s] 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s] 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s] 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s] 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s] 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s] 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s] 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s] 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s] 48%|████▊     | 106/221 [00:27<00:30,  3.79it/s] 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s] 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s] 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s] 50%|████▉     | 110/221 [00:28<00:29,  3.79it/s] 50%|█████     | 111/221 [00:29<00:28,  3.79it/s] 51%|█████     | 112/221 [00:29<00:28,  3.79it/s] 51%|█████     | 113/221 [00:29<00:28,  3.79it/s] 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s] 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s] 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s] 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s] 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s] 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s] 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s] 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s] 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s] 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s] 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s] 57%|█████▋    | 125/221 [00:32<00:25,  3.79it/s] 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s] 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s] 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s] 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s] 59%|█████▉    | 130/221 [00:34<00:23,  3.79it/s] 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s] 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s] 60%|██████    | 133/221 [00:35<00:23,  3.79it/s] 61%|██████    | 134/221 [00:35<00:22,  3.79it/s] 61%|██████    | 135/221 [00:35<00:22,  3.79it/s] 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s] 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s] 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s] 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s] 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s] 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s] 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s] 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s] 65%|██████▌   | 144/221 [00:37<00:20,  3.79it/s] 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s] 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s] 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s] 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s] 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s] 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s] 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s] 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s] 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s] 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s] 70%|███████   | 155/221 [00:40<00:17,  3.79it/s] 71%|███████   | 156/221 [00:41<00:17,  3.79it/s] 71%|███████   | 157/221 [00:41<00:16,  3.79it/s] 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s] 72%|███████▏  | 159/221 [00:41<00:16,  3.79it/s] 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s] 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s] 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s] 74%|███████▍  | 163/221 [00:42<00:15,  3.79it/s] 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s] 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s] 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s] 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s] 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s] 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s] 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s] 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s] 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s] 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s] 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s] 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s] 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s] 80%|████████  | 177/221 [00:46<00:11,  3.79it/s] 81%|████████  | 178/221 [00:46<00:11,  3.79it/s] 81%|████████  | 179/221 [00:47<00:11,  3.79it/s] 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s] 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s] 82%|████████▏ | 182/221 [00:47<00:10,  3.79it/s] 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s] 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s] 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s] 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s] 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s] 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s] 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s] 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s] 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s] 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s] 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s] 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s] 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s] 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s] 89%|████████▉ | 197/221 [00:51<00:06,  3.79it/s] 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s] 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s] 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s] 91%|█████████ | 201/221 [00:52<00:05,  3.79it/s] 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s] 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s] 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s] 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s] 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s] 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s] 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s] 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s] 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s] 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s] 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s] 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s] 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s] 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s] 98%|█████████▊| 216/221 [00:56<00:01,  3.79it/s] 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s] 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s] 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s]100%|█████████▉| 220/221 [00:57<00:00,  3.79it/s]100%|██████████| 221/221 [00:58<00:00,  3.79it/s]100%|██████████| 221/221 [00:58<00:00,  3.79it/s]
  0%|          | 0/221 [00:00<?, ?it/s]  1%|          | 2/221 [00:00<00:37,  5.77it/s]  1%|▏         | 3/221 [00:00<00:45,  4.79it/s]  2%|▏         | 4/221 [00:00<00:37,  5.82it/s]  2%|▏         | 5/221 [00:00<00:36,  5.99it/s]  3%|▎         | 7/221 [00:01<00:37,  5.73it/s]  4%|▎         | 8/221 [00:01<00:45,  4.66it/s]  4%|▍         | 9/221 [00:01<00:40,  5.19it/s]  5%|▍         | 10/221 [00:02<00:54,  3.90it/s]  5%|▍         | 11/221 [00:02<00:55,  3.76it/s]  5%|▌         | 12/221 [00:02<00:52,  4.01it/s]  6%|▌         | 13/221 [00:03<01:08,  3.04it/s]  6%|▋         | 14/221 [00:03<01:03,  3.27it/s]  7%|▋         | 15/221 [00:03<00:59,  3.47it/s]  7%|▋         | 16/221 [00:03<01:03,  3.22it/s]  8%|▊         | 17/221 [00:04<01:13,  2.78it/s]  8%|▊         | 18/221 [00:04<01:04,  3.12it/s]  9%|▊         | 19/221 [00:04<01:02,  3.21it/s]  9%|▉         | 20/221 [00:05<00:53,  3.73it/s] 10%|▉         | 21/221 [00:05<00:53,  3.75it/s] 10%|▉         | 22/221 [00:05<00:54,  3.68it/s] 11%|█         | 24/221 [00:06<00:45,  4.34it/s] 11%|█▏        | 25/221 [00:06<00:49,  3.97it/s] 12%|█▏        | 26/221 [00:06<00:51,  3.78it/s] 12%|█▏        | 27/221 [00:06<00:47,  4.11it/s] 13%|█▎        | 28/221 [00:07<01:00,  3.21it/s] 13%|█▎        | 29/221 [00:07<00:58,  3.29it/s] 14%|█▎        | 30/221 [00:07<00:59,  3.22it/s] 14%|█▍        | 31/221 [00:08<00:53,  3.57it/s] 14%|█▍        | 32/221 [00:08<00:45,  4.11it/s] 15%|█▍        | 33/221 [00:08<00:43,  4.30it/s] 15%|█▌        | 34/221 [00:08<00:43,  4.34it/s] 16%|█▌        | 35/221 [00:09<00:49,  3.78it/s] 16%|█▋        | 36/221 [00:09<00:50,  3.67it/s] 17%|█▋        | 37/221 [00:09<00:46,  3.94it/s] 17%|█▋        | 38/221 [00:09<00:45,  4.04it/s] 18%|█▊        | 39/221 [00:10<00:43,  4.15it/s] 18%|█▊        | 40/221 [00:10<00:51,  3.54it/s] 19%|█▊        | 41/221 [00:10<00:53,  3.35it/s] 19%|█▉        | 42/221 [00:10<00:44,  4.07it/s] 19%|█▉        | 43/221 [00:11<00:41,  4.32it/s] 20%|█▉        | 44/221 [00:11<00:39,  4.49it/s] 20%|██        | 45/221 [00:11<00:42,  4.15it/s] 21%|██        | 46/221 [00:11<00:43,  4.04it/s] 21%|██▏       | 47/221 [00:12<00:40,  4.35it/s] 22%|██▏       | 48/221 [00:12<00:34,  4.96it/s] 22%|██▏       | 49/221 [00:12<00:35,  4.90it/s] 23%|██▎       | 50/221 [00:12<00:51,  3.30it/s] 23%|██▎       | 51/221 [00:13<00:45,  3.73it/s] 24%|██▎       | 52/221 [00:13<00:46,  3.64it/s] 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s] 24%|██▍       | 54/221 [00:13<00:46,  3.58it/s] 25%|██▍       | 55/221 [00:14<00:43,  3.78it/s] 25%|██▌       | 56/221 [00:14<00:42,  3.90it/s] 26%|██▌       | 57/221 [00:14<00:40,  4.07it/s] 26%|██▌       | 58/221 [00:14<00:43,  3.76it/s] 27%|██▋       | 59/221 [00:15<00:38,  4.19it/s] 27%|██▋       | 60/221 [00:15<00:35,  4.58it/s] 28%|██▊       | 61/221 [00:15<00:35,  4.48it/s] 28%|██▊       | 62/221 [00:15<00:36,  4.39it/s] 29%|██▊       | 63/221 [00:16<00:35,  4.40it/s] 29%|██▉       | 64/221 [00:16<00:39,  3.98it/s] 29%|██▉       | 65/221 [00:16<00:39,  4.00it/s] 30%|██▉       | 66/221 [00:17<00:49,  3.11it/s] 30%|███       | 67/221 [00:17<00:48,  3.15it/s] 31%|███       | 68/221 [00:17<00:43,  3.55it/s] 31%|███       | 69/221 [00:18<01:00,  2.51it/s] 32%|███▏      | 70/221 [00:18<00:55,  2.73it/s] 32%|███▏      | 71/221 [00:18<00:46,  3.19it/s] 33%|███▎      | 72/221 [00:19<00:48,  3.05it/s] 33%|███▎      | 73/221 [00:19<00:42,  3.49it/s] 33%|███▎      | 74/221 [00:19<00:34,  4.24it/s] 34%|███▍      | 75/221 [00:19<00:35,  4.12it/s] 34%|███▍      | 76/221 [00:19<00:32,  4.47it/s] 35%|███▍      | 77/221 [00:20<00:40,  3.54it/s] 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s] 36%|███▌      | 79/221 [00:21<00:51,  2.74it/s] 36%|███▌      | 80/221 [00:21<00:50,  2.78it/s] 37%|███▋      | 81/221 [00:21<00:40,  3.44it/s] 37%|███▋      | 82/221 [00:21<00:42,  3.30it/s] 38%|███▊      | 83/221 [00:22<00:41,  3.32it/s] 38%|███▊      | 84/221 [00:22<00:38,  3.55it/s] 38%|███▊      | 85/221 [00:22<00:33,  4.02it/s] 39%|███▉      | 86/221 [00:22<00:30,  4.46it/s] 39%|███▉      | 87/221 [00:22<00:28,  4.70it/s] 40%|███▉      | 88/221 [00:23<00:39,  3.33it/s] 40%|████      | 89/221 [00:23<00:42,  3.12it/s] 41%|████      | 90/221 [00:24<00:37,  3.45it/s] 41%|████      | 91/221 [00:24<00:33,  3.86it/s] 42%|████▏     | 92/221 [00:24<00:38,  3.35it/s] 42%|████▏     | 93/221 [00:25<00:45,  2.81it/s] 43%|████▎     | 94/221 [00:25<00:43,  2.94it/s] 43%|████▎     | 95/221 [00:25<00:41,  3.07it/s] 43%|████▎     | 96/221 [00:25<00:36,  3.45it/s] 44%|████▍     | 97/221 [00:26<00:36,  3.44it/s] 44%|████▍     | 98/221 [00:26<00:41,  2.99it/s] 45%|████▍     | 99/221 [00:26<00:41,  2.97it/s] 45%|████▌     | 100/221 [00:27<00:40,  3.02it/s] 46%|████▌     | 101/221 [00:27<00:38,  3.12it/s] 46%|████▌     | 102/221 [00:27<00:42,  2.83it/s] 47%|████▋     | 103/221 [00:28<00:36,  3.26it/s] 47%|████▋     | 104/221 [00:28<00:35,  3.33it/s] 48%|████▊     | 105/221 [00:28<00:40,  2.88it/s] 48%|████▊     | 106/221 [00:29<00:35,  3.22it/s] 48%|████▊     | 107/221 [00:29<00:36,  3.14it/s] 49%|████▉     | 108/221 [00:29<00:35,  3.20it/s] 49%|████▉     | 109/221 [00:29<00:30,  3.68it/s] 50%|████▉     | 110/221 [00:30<00:31,  3.47it/s] 50%|█████     | 111/221 [00:30<00:34,  3.23it/s] 51%|█████     | 112/221 [00:30<00:34,  3.18it/s] 51%|█████     | 113/221 [00:31<00:30,  3.51it/s] 52%|█████▏    | 114/221 [00:31<00:25,  4.24it/s] 52%|█████▏    | 115/221 [00:31<00:28,  3.76it/s] 52%|█████▏    | 116/221 [00:31<00:29,  3.62it/s] 53%|█████▎    | 117/221 [00:32<00:28,  3.69it/s] 53%|█████▎    | 118/221 [00:32<00:27,  3.79it/s] 54%|█████▍    | 119/221 [00:32<00:28,  3.64it/s] 54%|█████▍    | 120/221 [00:33<00:26,  3.76it/s] 55%|█████▍    | 121/221 [00:33<00:23,  4.33it/s] 55%|█████▌    | 122/221 [00:33<00:22,  4.40it/s] 56%|█████▌    | 123/221 [00:33<00:23,  4.13it/s] 56%|█████▌    | 124/221 [00:33<00:24,  4.02it/s] 57%|█████▋    | 125/221 [00:34<00:28,  3.38it/s] 57%|█████▋    | 126/221 [00:34<00:25,  3.71it/s] 57%|█████▋    | 127/221 [00:34<00:30,  3.10it/s] 58%|█████▊    | 128/221 [00:35<00:28,  3.24it/s] 58%|█████▊    | 129/221 [00:35<00:23,  3.96it/s] 59%|█████▉    | 130/221 [00:35<00:23,  3.95it/s] 60%|█████▉    | 132/221 [00:36<00:20,  4.41it/s] 60%|██████    | 133/221 [00:36<00:23,  3.80it/s] 61%|██████    | 134/221 [00:36<00:24,  3.60it/s] 61%|██████    | 135/221 [00:36<00:22,  3.89it/s] 62%|██████▏   | 136/221 [00:37<00:22,  3.71it/s] 62%|██████▏   | 137/221 [00:37<00:23,  3.63it/s] 62%|██████▏   | 138/221 [00:37<00:24,  3.35it/s] 63%|██████▎   | 139/221 [00:38<00:25,  3.21it/s] 63%|██████▎   | 140/221 [00:38<00:24,  3.27it/s] 64%|██████▍   | 141/221 [00:38<00:23,  3.34it/s] 64%|██████▍   | 142/221 [00:38<00:21,  3.70it/s] 65%|██████▍   | 143/221 [00:39<00:21,  3.58it/s] 65%|██████▌   | 144/221 [00:39<00:22,  3.38it/s] 66%|██████▌   | 145/221 [00:39<00:20,  3.75it/s] 66%|██████▌   | 146/221 [00:39<00:17,  4.32it/s] 67%|██████▋   | 147/221 [00:40<00:19,  3.75it/s] 67%|██████▋   | 148/221 [00:40<00:21,  3.33it/s] 67%|██████▋   | 149/221 [00:41<00:21,  3.30it/s] 68%|██████▊   | 150/221 [00:41<00:21,  3.34it/s] 68%|██████▊   | 151/221 [00:41<00:24,  2.91it/s] 69%|██████▉   | 152/221 [00:42<00:26,  2.58it/s] 69%|██████▉   | 153/221 [00:42<00:22,  3.02it/s] 70%|██████▉   | 154/221 [00:42<00:19,  3.47it/s] 70%|███████   | 155/221 [00:42<00:19,  3.43it/s] 71%|███████   | 156/221 [00:43<00:19,  3.27it/s] 71%|███████   | 157/221 [00:43<00:21,  3.04it/s] 71%|███████▏  | 158/221 [00:43<00:19,  3.17it/s] 72%|███████▏  | 159/221 [00:44<00:16,  3.85it/s] 72%|███████▏  | 160/221 [00:44<00:14,  4.27it/s] 73%|███████▎  | 161/221 [00:44<00:13,  4.42it/s] 73%|███████▎  | 162/221 [00:44<00:11,  5.17it/s] 74%|███████▍  | 163/221 [00:44<00:12,  4.46it/s] 74%|███████▍  | 164/221 [00:45<00:12,  4.55it/s] 75%|███████▍  | 165/221 [00:45<00:15,  3.73it/s] 75%|███████▌  | 166/221 [00:45<00:14,  3.88it/s] 76%|███████▌  | 167/221 [00:45<00:12,  4.41it/s] 76%|███████▌  | 168/221 [00:46<00:11,  4.45it/s] 76%|███████▋  | 169/221 [00:46<00:10,  4.91it/s] 77%|███████▋  | 170/221 [00:46<00:16,  3.10it/s] 77%|███████▋  | 171/221 [00:47<00:14,  3.50it/s] 78%|███████▊  | 172/221 [00:47<00:13,  3.69it/s] 78%|███████▊  | 173/221 [00:47<00:14,  3.40it/s] 79%|███████▊  | 174/221 [00:47<00:14,  3.16it/s] 79%|███████▉  | 175/221 [00:48<00:14,  3.19it/s] 80%|███████▉  | 176/221 [00:48<00:13,  3.45it/s] 80%|████████  | 177/221 [00:48<00:11,  3.79it/s] 81%|████████  | 178/221 [00:49<00:13,  3.22it/s] 81%|████████  | 179/221 [00:49<00:12,  3.28it/s] 81%|████████▏ | 180/221 [00:49<00:11,  3.71it/s] 82%|████████▏ | 181/221 [00:49<00:09,  4.19it/s] 82%|████████▏ | 182/221 [00:50<00:11,  3.25it/s] 83%|████████▎ | 183/221 [00:50<00:11,  3.25it/s] 83%|████████▎ | 184/221 [00:50<00:09,  3.71it/s] 84%|████████▎ | 185/221 [00:50<00:09,  3.98it/s] 84%|████████▍ | 186/221 [00:51<00:10,  3.44it/s] 85%|████████▍ | 187/221 [00:51<00:10,  3.24it/s] 85%|████████▌ | 188/221 [00:51<00:10,  3.29it/s] 86%|████████▌ | 189/221 [00:52<00:08,  3.63it/s] 86%|████████▌ | 190/221 [00:52<00:09,  3.41it/s] 86%|████████▋ | 191/221 [00:52<00:07,  3.92it/s] 87%|████████▋ | 192/221 [00:52<00:07,  3.88it/s] 87%|████████▋ | 193/221 [00:53<00:06,  4.41it/s] 88%|████████▊ | 194/221 [00:53<00:05,  4.51it/s] 88%|████████▊ | 195/221 [00:53<00:06,  4.20it/s] 89%|████████▊ | 196/221 [00:53<00:06,  3.89it/s] 89%|████████▉ | 197/221 [00:54<00:05,  4.07it/s] 90%|████████▉ | 198/221 [00:54<00:06,  3.57it/s] 90%|█████████ | 199/221 [00:54<00:06,  3.52it/s] 90%|█████████ | 200/221 [00:55<00:06,  3.06it/s] 91%|█████████ | 201/221 [00:55<00:06,  3.19it/s] 91%|█████████▏| 202/221 [00:55<00:06,  2.89it/s] 92%|█████████▏| 203/221 [00:56<00:05,  3.30it/s] 92%|█████████▏| 204/221 [00:56<00:04,  3.55it/s] 93%|█████████▎| 205/221 [00:56<00:03,  4.11it/s] 93%|█████████▎| 206/221 [00:56<00:04,  3.52it/s] 94%|█████████▎| 207/221 [00:57<00:03,  3.64it/s] 94%|█████████▍| 208/221 [00:57<00:03,  3.28it/s] 95%|█████████▍| 209/221 [00:57<00:03,  3.30it/s] 95%|█████████▌| 210/221 [00:57<00:02,  3.68it/s] 95%|█████████▌| 211/221 [00:58<00:03,  3.28it/s] 96%|█████████▌| 212/221 [00:58<00:02,  3.45it/s] 96%|█████████▋| 213/221 [00:58<00:02,  3.98it/s] 97%|█████████▋| 214/221 [00:59<00:02,  3.42it/s] 97%|█████████▋| 215/221 [00:59<00:01,  3.70it/s] 98%|█████████▊| 216/221 [00:59<00:01,  3.51it/s] 98%|█████████▊| 217/221 [01:00<00:01,  3.25it/s] 99%|█████████▊| 218/221 [01:00<00:00,  3.25it/s] 99%|█████████▉| 219/221 [01:00<00:00,  3.08it/s]100%|█████████▉| 220/221 [01:01<00:00,  3.10it/s]100%|██████████| 221/221 [01:01<00:00,  2.98it/s]100%|██████████| 221/221 [01:01<00:00,  3.60it/s]
09/09/2024 17:05:22 - INFO - __main__ -   ==== evaluation--ret%tv--msrvtt_ret_ret_area_forward========

09/09/2024 17:05:22 - INFO - __main__ -   {'area_r1': 24.1, 'area_recall': '24.1/43.1/50.6', 'area_ravg': 39.3}
09/09/2024 17:05:22 - INFO - __main__ -   ==== evaluation--ret%tv--msrvtt_ret_ret_area_backard========

09/09/2024 17:05:22 - INFO - __main__ -   {'forward_r1': 33.3, 'forward_recall': '33.3/64.7/75.1', 'forward_ravg': 57.7}
09/09/2024 17:05:22 - INFO - __main__ -   ==== evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video========

09/09/2024 17:05:22 - INFO - __main__ -   {'area_video_r1': 33.3, 'area_video_recall': '33.3/64.4/75.9', 'area_video_ravg': 57.8}
09/09/2024 17:05:22 - INFO - __main__ -   ==== evaluation--ret%tv--msrvtt_ret_ret_itm_area========

09/09/2024 17:05:22 - INFO - __main__ -   {'area_video_r1': 47.4, 'area_video_recall': '47.4/66.6/72.1', 'area_video_ravg': 62.0, 'area_video_back_r1': 42.8, 'area_video_back_recall': '42.8/67.6/77.0', 'area_video_back_ravg': 62.5}
09/09/2024 17:05:22 - INFO - __main__ -   ==== evaluation--ret%tv--msrvtt_ret_ret_itc_tv========

09/09/2024 17:05:22 - INFO - __main__ -   {'video_r1': 44.9, 'video_recall': '44.9/72.4/82.5', 'video_ravg': 66.6}
09/09/2024 17:05:22 - INFO - __main__ -   ==== evaluation--ret%tv--msrvtt_ret_ret_itm_tv========

09/09/2024 17:05:22 - INFO - __main__ -   {'video_r1': 50.3, 'video_recall': '50.3/72.4/80.4', 'video_ravg': 67.7}
  0%|          | 0/1945 [00:00<?, ?it/s][h264 @ 0x559b40a4d9c0] mmco: unref short failure
[h264 @ 0x559f87227900] mmco: unref short failure
[h264 @ 0x559f87227900] mmco: unref short failure
[h264 @ 0x559f87227900] mmco: unref short failure
[h264 @ 0x559f87227900] mmco: unref short failure
/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_optimizer.py:171: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1485.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_optimizer.py:171: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1485.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_optimizer.py:171: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1485.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_optimizer.py:171: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1485.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
  0%|          | 1/1945 [00:10<5:28:23, 10.14s/it]  0%|          | 2/1945 [00:14<3:40:46,  6.82s/it][h264 @ 0x559b3af97840] mmco: unref short failure
[h264 @ 0x56237112e300] mmco: unref short failure
[h264 @ 0x56237112e300] mmco: unref short failure
[h264 @ 0x56237112e300] mmco: unref short failure
[h264 @ 0x56237112e300] mmco: unref short failure
[h264 @ 0x56237112e300] mmco: unref short failure
[h264 @ 0x56237112e300] mmco: unref short failure
[h264 @ 0x556a7dd675c0] mmco: unref short failure
  0%|          | 3/1945 [00:19<3:08:07,  5.81s/it][h264 @ 0x562362b9d480] mmco: unref short failure
[h264 @ 0x562362b9d480] mmco: unref short failure
[h264 @ 0x559f849161c0] mmco: unref short failure
[h264 @ 0x559f849161c0] mmco: unref short failure
[h264 @ 0x559f849161c0] mmco: unref short failure
  0%|          | 4/1945 [00:24<3:05:51,  5.75s/it][h264 @ 0x559f7de9d680] mmco: unref short failure
[h264 @ 0x559f7de9d680] mmco: unref short failure
  0%|          | 5/1945 [00:31<3:12:22,  5.95s/it][h264 @ 0x562369145a00] mmco: unref short failure
[h264 @ 0x562369145a00] mmco: unref short failure
[h264 @ 0x556a7d48b600] mmco: unref short failure
[h264 @ 0x556a7d48b600] mmco: unref short failure
  0%|          | 6/1945 [00:38<3:22:49,  6.28s/it][h264 @ 0x56236d4e9d40] mmco: unref short failure
[h264 @ 0x559f7dc2a7c0] mmco: unref short failure
[h264 @ 0x559f7dc2a7c0] mmco: unref short failure
not have audios 8-qwaveiHMM.3
  0%|          | 7/1945 [00:46<3:47:19,  7.04s/it]  0%|          | 8/1945 [00:53<3:47:17,  7.04s/it]  0%|          | 9/1945 [01:01<3:50:33,  7.15s/it][h264 @ 0x559f81d46000] mmco: unref short failure
[h264 @ 0x559f81d46000] mmco: unref short failure
  1%|          | 10/1945 [01:08<3:53:31,  7.24s/it][h264 @ 0x56236770f380] mmco: unref short failure
[h264 @ 0x56236770f380] mmco: unref short failure
  1%|          | 11/1945 [01:16<3:56:19,  7.33s/it]  1%|          | 12/1945 [01:23<3:52:11,  7.21s/it][h264 @ 0x556a79b34100] mmco: unref short failure
[h264 @ 0x556a79b34100] mmco: unref short failure
[h264 @ 0x556a7b745780] mmco: unref short failure
[h264 @ 0x556a7b745780] mmco: unref short failure
[h264 @ 0x559b3c36c2c0] mmco: unref short failure
  1%|          | 13/1945 [01:31<4:00:02,  7.45s/it]  1%|          | 14/1945 [01:37<3:51:24,  7.19s/it][h264 @ 0x559f83eb9f00] mmco: unref short failure
[h264 @ 0x559f83eb9f00] mmco: unref short failure
[h264 @ 0x56236cff4e80] mmco: unref short failure
[h264 @ 0x56236cff4e80] mmco: unref short failure
[h264 @ 0x56236cff4e80] mmco: unref short failure
  1%|          | 15/1945 [01:45<3:58:20,  7.41s/it][h264 @ 0x559b45705200] mmco: unref short failure
[h264 @ 0x559b45705200] mmco: unref short failure
[h264 @ 0x559b45705200] mmco: unref short failure
[h264 @ 0x559b45705200] mmco: unref short failure
  1%|          | 16/1945 [01:52<3:53:50,  7.27s/it][h264 @ 0x562362e445c0] mmco: unref short failure
[h264 @ 0x562362e445c0] mmco: unref short failure
[h264 @ 0x562362e445c0] mmco: unref short failure
[h264 @ 0x562362e445c0] mmco: unref short failure
[h264 @ 0x562362e445c0] mmco: unref short failure
[h264 @ 0x562362e445c0] mmco: unref short failure
[h264 @ 0x562362e445c0] mmco: unref short failure
[h264 @ 0x562362e445c0] mmco: unref short failure
[h264 @ 0x56237387ec00] mmco: unref short failure
[h264 @ 0x559b3d848080] mmco: unref short failure
[h264 @ 0x559b3d848080] mmco: unref short failure
[h264 @ 0x559b3d848080] mmco: unref short failure
[h264 @ 0x559b3d848080] mmco: unref short failure
  1%|          | 17/1945 [02:02<4:21:03,  8.12s/it][h264 @ 0x556a81865540] mmco: unref short failure
[h264 @ 0x562368211140] mmco: unref short failure
[h264 @ 0x559b3cb089c0] mmco: unref short failure
[h264 @ 0x559b3cb089c0] mmco: unref short failure
[h264 @ 0x559b45593000] mmco: unref short failure
[h264 @ 0x559b45593000] mmco: unref short failure
[h264 @ 0x559b3647b5c0] mmco: unref short failure
[h264 @ 0x559b3647b5c0] mmco: unref short failure
[h264 @ 0x5623666065c0] mmco: unref short failure
[h264 @ 0x559f7cfa6200] mmco: unref short failure
[h264 @ 0x559f7cfa6200] mmco: unref short failure
[h264 @ 0x556a7c734dc0] mmco: unref short failure
[h264 @ 0x556a7c734dc0] mmco: unref short failure
  1%|          | 18/1945 [02:14<4:54:31,  9.17s/it]  1%|          | 19/1945 [02:21<4:33:51,  8.53s/it][h264 @ 0x556a7dde3bc0] mmco: unref short failure
[h264 @ 0x556a77732a40] mmco: unref short failure
[h264 @ 0x559f80802fc0] mmco: unref short failure
[h264 @ 0x559f80802fc0] mmco: unref short failure
[h264 @ 0x559b3647ba80] mmco: unref short failure
  1%|          | 20/1945 [02:32<4:55:57,  9.22s/it][h264 @ 0x556a7a5fad40] mmco: unref short failure
[h264 @ 0x556a7a5fad40] mmco: unref short failure
[h264 @ 0x556a7a5fad40] mmco: unref short failure
[h264 @ 0x556a7a5fad40] mmco: unref short failure
  1%|          | 21/1945 [02:39<4:40:05,  8.73s/it]  1%|          | 22/1945 [02:46<4:20:02,  8.11s/it][h264 @ 0x562362e82500] mmco: unref short failure
[h264 @ 0x562362e82500] mmco: unref short failure
[h264 @ 0x559f7ea30180] mmco: unref short failure
[h264 @ 0x56236db9b000] mmco: unref short failure
[h264 @ 0x56236db9b000] mmco: unref short failure
[h264 @ 0x56236db9b000] mmco: unref short failure
[h264 @ 0x56236db9b000] mmco: unref short failure
  1%|          | 23/1945 [02:53<4:10:55,  7.83s/it][h264 @ 0x562364914fc0] mmco: unref short failure
[h264 @ 0x562364914fc0] mmco: unref short failure
[h264 @ 0x562364914fc0] mmco: unref short failure
[h264 @ 0x562364914fc0] mmco: unref short failure
[h264 @ 0x556a7efc18c0] mmco: unref short failure
[h264 @ 0x559b36913080] mmco: unref short failure
[h264 @ 0x559b36913080] mmco: unref short failure
[h264 @ 0x559f81d466c0] mmco: unref short failure
[h264 @ 0x559b38d07680] mmco: unref short failure
[h264 @ 0x559b38d07680] mmco: unref short failure
[h264 @ 0x556a8406bd80] mmco: unref short failure
[h264 @ 0x556a8406bd80] mmco: unref short failure
[h264 @ 0x559f8e103b00] mmco: unref short failure
[h264 @ 0x559f8e103b00] mmco: unref short failure
[h264 @ 0x559f8e103440] mmco: unref short failure
[h264 @ 0x559f8e103440] mmco: unref short failure
[h264 @ 0x5623699c6640] mmco: unref short failure
[h264 @ 0x5623699c6640] mmco: unref short failure
  1%|          | 24/1945 [03:35<9:39:29, 18.10s/it]  1%|▏         | 25/1945 [03:42<7:52:13, 14.76s/it][h264 @ 0x559f7e7541c0] mmco: unref short failure
[h264 @ 0x559b3bb89200] mmco: unref short failure
[h264 @ 0x559b41217900] mmco: unref short failure
[h264 @ 0x559b3d50d3c0] mmco: unref short failure
[h264 @ 0x56236834e2c0] mmco: unref short failure
[h264 @ 0x559f8b7667c0] mmco: unref short failure
[h264 @ 0x559f8b7667c0] mmco: unref short failure
[h264 @ 0x559b42653240] mmco: unref short failure
[h264 @ 0x559b42653240] mmco: unref short failure
[h264 @ 0x556a77dca340] mmco: unref short failure
[h264 @ 0x556a77dca340] mmco: unref short failure
[h264 @ 0x559b363cf1c0] mmco: unref short failure
[h264 @ 0x559b363cf1c0] mmco: unref short failure
[h264 @ 0x56236ab12500] mmco: unref short failure
[h264 @ 0x56236ab12500] mmco: unref short failure
[h264 @ 0x56236ab12500] mmco: unref short failure
[h264 @ 0x56236ab12500] mmco: unref short failure
  1%|▏         | 26/1945 [04:17<11:09:32, 20.93s/it][h264 @ 0x5623625220c0] mmco: unref short failure
  1%|▏         | 27/1945 [04:24<8:55:06, 16.74s/it]   1%|▏         | 28/1945 [04:32<7:25:17, 13.94s/it][h264 @ 0x559b3783ac40] mmco: unref short failure
  1%|▏         | 29/1945 [04:42<6:48:01, 12.78s/it][h264 @ 0x559f80d07340] mmco: unref short failure
[h264 @ 0x556a802f93c0] mmco: unref short failure
[h264 @ 0x562373828a00] mmco: unref short failure
[h264 @ 0x562373828a00] mmco: unref short failure
  2%|▏         | 30/1945 [04:54<6:42:11, 12.60s/it][h264 @ 0x559b4104b980] mmco: unref short failure
[h264 @ 0x559b40260340] mmco: unref short failure
  2%|▏         | 31/1945 [05:03<6:06:03, 11.48s/it][h264 @ 0x556a86e45c40] mmco: unref short failure
[h264 @ 0x559f89876b00] mmco: unref short failure
[h264 @ 0x559f89876b00] mmco: unref short failure
[h264 @ 0x559f81d7a180] mmco: unref short failure
[h264 @ 0x559f81d7a180] mmco: unref short failure
[h264 @ 0x559b35e30340] mmco: unref short failure
[h264 @ 0x56237872b680] mmco: unref short failure
[h264 @ 0x56237872b680] mmco: unref short failure
[h264 @ 0x556a784baa40] mmco: unref short failure
[h264 @ 0x556a784baa40] mmco: unref short failure
[h264 @ 0x556a784baa40] mmco: unref short failure
[h264 @ 0x556a784baa40] mmco: unref short failure
[h264 @ 0x559f82afc940] mmco: unref short failure
  2%|▏         | 32/1945 [05:40<10:06:32, 19.02s/it][h264 @ 0x556a798c6500] mmco: unref short failure
[h264 @ 0x556a798c6500] mmco: unref short failure
  2%|▏         | 33/1945 [05:47<8:14:20, 15.51s/it] [h264 @ 0x559b3b53c6c0] mmco: unref short failure
[h264 @ 0x559b36f58400] mmco: unref short failure
[h264 @ 0x559b36f58400] mmco: unref short failure
[h264 @ 0x559b471ac680] mmco: unref short failure
[h264 @ 0x559b40695900] mmco: unref short failure
[h264 @ 0x556a8c967800] mmco: unref short failure
[h264 @ 0x556a8c967800] mmco: unref short failure
[h264 @ 0x559b471b2b00] mmco: unref short failure
[h264 @ 0x556a8c675a00] mmco: unref short failure
[h264 @ 0x556a8c675a00] mmco: unref short failure
  2%|▏         | 34/1945 [06:24<11:39:29, 21.96s/it][h264 @ 0x559f7fbe61c0] mmco: unref short failure
[h264 @ 0x559f7fbe61c0] mmco: unref short failure
[h264 @ 0x559f7c360800] mmco: unref short failure
  2%|▏         | 35/1945 [06:32<9:25:15, 17.76s/it] [h264 @ 0x562372057400] mmco: unref short failure
  2%|▏         | 36/1945 [06:39<7:47:36, 14.70s/it][h264 @ 0x559b46fd9c40] mmco: unref short failure
[h264 @ 0x562372fd2440] mmco: unref short failure
[h264 @ 0x562372fd2440] mmco: unref short failure
[h264 @ 0x559b3e2d3640] mmco: unref short failure
[h264 @ 0x559b3e2d3640] mmco: unref short failure
  2%|▏         | 37/1945 [06:49<7:03:49, 13.33s/it][h264 @ 0x559b3e8e7b40] mmco: unref short failure
[h264 @ 0x559b3e8e7b40] mmco: unref short failure
[h264 @ 0x559b373f5dc0] mmco: unref short failure
[h264 @ 0x559b373f5dc0] mmco: unref short failure
  2%|▏         | 38/1945 [06:56<6:00:37, 11.35s/it][h264 @ 0x556a7da4d400] mmco: unref short failure
[h264 @ 0x556a7da4d400] mmco: unref short failure
[h264 @ 0x559b3be53140] mmco: unref short failure
  2%|▏         | 39/1945 [07:03<5:17:47, 10.00s/it][h264 @ 0x556a826d0340] mmco: unref short failure
[h264 @ 0x559f7e144cc0] mmco: unref short failure
[h264 @ 0x559f7e144cc0] mmco: unref short failure
[h264 @ 0x5623637e54c0] mmco: unref short failure
[h264 @ 0x562365ecce40] mmco: unref short failure
[h264 @ 0x562365ecce40] mmco: unref short failure
[h264 @ 0x562363f5ae40] mmco: unref short failure
[h264 @ 0x556a80da2a00] mmco: unref short failure
[h264 @ 0x556a80da2a00] mmco: unref short failure
[h264 @ 0x559b491cb1c0] mmco: unref short failure
[h264 @ 0x559f8e8353c0] mmco: unref short failure
[h264 @ 0x559f8e8353c0] mmco: unref short failure
  2%|▏         | 40/1945 [07:42<9:54:48, 18.73s/it][h264 @ 0x56236dbdcf80] mmco: unref short failure
[h264 @ 0x56236dbdcf80] mmco: unref short failure
[h264 @ 0x559f86fbff00] mmco: unref short failure
[h264 @ 0x559f86fbff00] mmco: unref short failure
[h264 @ 0x562362dac000] mmco: unref short failure
[h264 @ 0x562362dac000] mmco: unref short failure
  2%|▏         | 41/1945 [07:49<8:00:39, 15.15s/it][h264 @ 0x5623683153c0] mmco: unref short failure
[h264 @ 0x559b36130700] mmco: unref short failure
[h264 @ 0x559b37cd88c0] mmco: unref short failure
[h264 @ 0x559b37cd88c0] mmco: unref short failure
[h264 @ 0x556a7a5f6a80] mmco: unref short failure
[h264 @ 0x556a7a5f6a80] mmco: unref short failure
[h264 @ 0x556a7a5f6a80] mmco: unref short failure
[h264 @ 0x556a7a5f6a80] mmco: unref short failure
[h264 @ 0x559b491eca00] mmco: unref short failure
[h264 @ 0x559b43638f80] mmco: unref short failure
[h264 @ 0x56236d292680] mmco: unref short failure
[h264 @ 0x559b3728afc0] mmco: unref short failure
  2%|▏         | 42/1945 [08:23<10:55:50, 20.68s/it][h264 @ 0x559f909c7100] mmco: unref short failure
[h264 @ 0x556a79fb3f40] mmco: unref short failure
  2%|▏         | 43/1945 [08:31<8:58:43, 16.99s/it] [h264 @ 0x562369ee5b40] mmco: unref short failure
[h264 @ 0x562369ee5b40] mmco: unref short failure
[h264 @ 0x562369ee5b40] mmco: unref short failure
[h264 @ 0x562369ee5b40] mmco: unref short failure
  2%|▏         | 44/1945 [08:38<7:28:16, 14.15s/it][h264 @ 0x5623631b3b00] mmco: unref short failure
[h264 @ 0x5623631b3b00] mmco: unref short failure
[h264 @ 0x562364b4b3c0] mmco: unref short failure
[h264 @ 0x559b3b1e80c0] mmco: unref short failure
[h264 @ 0x559f7d0d6140] mmco: unref short failure
  2%|▏         | 45/1945 [08:46<6:22:39, 12.08s/it]  2%|▏         | 46/1945 [08:53<5:40:21, 10.75s/it][h264 @ 0x556a871f62c0] mmco: unref short failure
[h264 @ 0x556a8b73ee00] mmco: unref short failure
[h264 @ 0x556a8b73ee00] mmco: unref short failure
  2%|▏         | 47/1945 [09:01<5:07:10,  9.71s/it][h264 @ 0x559b3e948100] mmco: unref short failure
[h264 @ 0x559f84e09f00] mmco: unref short failure
[h264 @ 0x562363c0b380] mmco: unref short failure
[h264 @ 0x562363c0b380] mmco: unref short failure
[h264 @ 0x562363f29d80] mmco: unref short failure
[h264 @ 0x562363f29d80] mmco: unref short failure
[h264 @ 0x562363f29d80] mmco: unref short failure
[h264 @ 0x559f8aacb640] mmco: unref short failure
[h264 @ 0x559f8aacb640] mmco: unref short failure
[h264 @ 0x556a8880fd00] mmco: unref short failure
  2%|▏         | 48/1945 [09:36<9:05:55, 17.27s/it]  3%|▎         | 49/1945 [09:43<7:37:18, 14.47s/it]09/09/2024 17:15:06 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 17:15:06 - INFO - __main__ -   start running ret%tv validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x56236e42cac0] mmco: unref short failure
[h264 @ 0x56236e42cac0] mmco: unref short failure
[h264 @ 0x562371116dc0] mmco: unref short failure
[h264 @ 0x562371116dc0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556a785c3880] mmco: unref short failure
[h264 @ 0x556a785c3880] mmco: unref short failure
[h264 @ 0x559b3d386740] mmco: unref short failure
[h264 @ 0x559b3d386740] mmco: unref short failure
[h264 @ 0x5623764f1400] mmco: unref short failure
[h264 @ 0x556a7bf81540] mmco: unref short failure
[h264 @ 0x556a7bf81540] mmco: unref short failure
[h264 @ 0x556a81e3af40] mmco: unref short failure
[h264 @ 0x556a85cb2f00] mmco: unref short failure
[h264 @ 0x56236f997640] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559b461e0c00] mmco: unref short failure
[h264 @ 0x556a7a6366c0] mmco: unref short failure
[h264 @ 0x556a8dbdd380] mmco: unref short failure
[h264 @ 0x559f9294fac0] mmco: unref short failure
[h264 @ 0x559b4f352dc0] mmco: unref short failure
[h264 @ 0x559b4f352dc0] mmco: unref short failure
[h264 @ 0x56237499ff40] mmco: unref short failure
[h264 @ 0x56237499ff40] mmco: unref short failure
[h264 @ 0x559f921d4d80] mmco: unref short failure
[h264 @ 0x559f921d4d80] mmco: unref short failure
[h264 @ 0x559f89cfcc00] mmco: unref short failure
[h264 @ 0x559f89cfcc00] mmco: unref short failure
[h264 @ 0x562379779500] mmco: unref short failure
[h264 @ 0x562379779500] mmco: unref short failure
[h264 @ 0x562379779500] mmco: unref short failure
[h264 @ 0x562379779500] mmco: unref short failure
[h264 @ 0x559f8e755840] mmco: unref short failure
[h264 @ 0x559b447ef6c0] mmco: unref short failure
[h264 @ 0x559b447ef6c0] mmco: unref short failure
[h264 @ 0x559f8981da00] mmco: unref short failure
[h264 @ 0x559f8981da00] mmco: unref short failure
[h264 @ 0x56236ea11940] mmco: unref short failure
[h264 @ 0x56236ea11940] mmco: unref short failure
[h264 @ 0x556a8b53c840] mmco: unref short failure
[h264 @ 0x556a8b53c840] mmco: unref short failure
[h264 @ 0x559f90e252c0] mmco: unref short failure
[h264 @ 0x559f90e252c0] mmco: unref short failure
[h264 @ 0x562374369940] mmco: unref short failure
[h264 @ 0x562374369940] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:35,  6.21it/s][A
  1%|          | 2/221 [00:00<01:08,  3.19it/s][A
  1%|▏         | 3/221 [00:00<01:09,  3.13it/s][A
  2%|▏         | 5/221 [00:01<00:40,  5.33it/s][A
  3%|▎         | 7/221 [00:01<00:35,  6.00it/s][A
  4%|▎         | 8/221 [00:01<00:32,  6.53it/s][A
  4%|▍         | 9/221 [00:01<00:32,  6.56it/s][A
  5%|▍         | 10/221 [00:01<00:38,  5.52it/s][A
  5%|▍         | 11/221 [00:02<00:37,  5.62it/s][A
  5%|▌         | 12/221 [00:02<01:11,  2.94it/s][A
  6%|▌         | 13/221 [00:02<00:58,  3.56it/s][A
  6%|▋         | 14/221 [00:03<00:56,  3.69it/s][A
  7%|▋         | 15/221 [00:03<00:47,  4.30it/s][A
  7%|▋         | 16/221 [00:03<00:48,  4.23it/s][A
  8%|▊         | 17/221 [00:03<00:57,  3.53it/s][A
  8%|▊         | 18/221 [00:04<00:50,  4.03it/s][A
  9%|▊         | 19/221 [00:04<00:45,  4.48it/s][A
 10%|▉         | 21/221 [00:04<00:43,  4.61it/s][A
 10%|▉         | 22/221 [00:06<01:56,  1.70it/s][A
 10%|█         | 23/221 [00:06<01:36,  2.05it/s][A
 11%|█         | 24/221 [00:06<01:15,  2.61it/s][A
 11%|█▏        | 25/221 [00:06<00:59,  3.28it/s][A
 12%|█▏        | 26/221 [00:07<00:53,  3.63it/s][A
 12%|█▏        | 27/221 [00:07<00:54,  3.56it/s][A
 13%|█▎        | 28/221 [00:07<00:56,  3.40it/s][A
 13%|█▎        | 29/221 [00:07<00:46,  4.13it/s][A
 14%|█▍        | 31/221 [00:08<00:36,  5.24it/s][A
 14%|█▍        | 32/221 [00:08<00:34,  5.51it/s][A
 15%|█▍        | 33/221 [00:08<00:35,  5.23it/s][A
 15%|█▌        | 34/221 [00:08<00:36,  5.16it/s][A
 16%|█▌        | 35/221 [00:08<00:32,  5.76it/s][A
 16%|█▋        | 36/221 [00:08<00:28,  6.41it/s][A
 17%|█▋        | 37/221 [00:09<00:32,  5.73it/s][A
 17%|█▋        | 38/221 [00:09<00:40,  4.52it/s][A
 18%|█▊        | 39/221 [00:09<00:33,  5.36it/s][A
 18%|█▊        | 40/221 [00:09<00:31,  5.83it/s][A[h264 @ 0x56237828e080] mmco: unref short failure

 19%|█▊        | 41/221 [00:09<00:35,  5.04it/s][A
 19%|█▉        | 42/221 [00:10<00:34,  5.26it/s][A
 19%|█▉        | 43/221 [00:10<00:30,  5.82it/s][A
 20%|█▉        | 44/221 [00:10<00:28,  6.15it/s][A
 20%|██        | 45/221 [00:10<00:42,  4.18it/s][A
 21%|██        | 46/221 [00:11<00:43,  4.02it/s][A[h264 @ 0x556a8d833780] mmco: unref short failure
[h264 @ 0x556a842f0200] mmco: unref short failure
[h264 @ 0x556a842f0200] mmco: unref short failure
[h264 @ 0x559b3af8ad80] mmco: unref short failure
[h264 @ 0x559b3af8ad80] mmco: unref short failure

 21%|██▏       | 47/221 [00:15<04:25,  1.53s/it][A
 22%|██▏       | 49/221 [00:15<02:30,  1.15it/s][A
 23%|██▎       | 50/221 [00:15<01:59,  1.43it/s][A
 23%|██▎       | 51/221 [00:16<01:37,  1.75it/s][A
 24%|██▎       | 52/221 [00:16<01:16,  2.21it/s][A
 24%|██▍       | 53/221 [00:16<01:01,  2.72it/s][A[h264 @ 0x559f94aaae40] mmco: unref short failure
[h264 @ 0x562364c37dc0] mmco: unref short failure
[h264 @ 0x562364c37dc0] mmco: unref short failure

 24%|██▍       | 54/221 [00:19<03:21,  1.20s/it][A
 25%|██▍       | 55/221 [00:20<02:46,  1.01s/it][A
 25%|██▌       | 56/221 [00:20<02:03,  1.34it/s][A
 26%|██▌       | 57/221 [00:20<01:32,  1.77it/s][A
 27%|██▋       | 59/221 [00:20<00:57,  2.82it/s][A
 27%|██▋       | 60/221 [00:21<00:55,  2.90it/s][A
 28%|██▊       | 61/221 [00:21<00:46,  3.43it/s][A
 28%|██▊       | 62/221 [00:21<00:39,  4.05it/s][A
 29%|██▊       | 63/221 [00:21<00:32,  4.83it/s][A
 29%|██▉       | 65/221 [00:21<00:25,  6.17it/s][A
 30%|██▉       | 66/221 [00:24<01:55,  1.34it/s][A
 30%|███       | 67/221 [00:24<01:39,  1.54it/s][A
 31%|███       | 68/221 [00:24<01:18,  1.95it/s][A[h264 @ 0x562375ff58c0] mmco: unref short failure

 31%|███       | 69/221 [00:25<01:09,  2.17it/s][A
 32%|███▏      | 70/221 [00:25<00:54,  2.75it/s][A
 32%|███▏      | 71/221 [00:25<00:45,  3.33it/s][A
 33%|███▎      | 72/221 [00:25<00:41,  3.59it/s][A
 33%|███▎      | 73/221 [00:25<00:42,  3.47it/s][A
 33%|███▎      | 74/221 [00:25<00:35,  4.14it/s][A
 34%|███▍      | 75/221 [00:26<00:34,  4.21it/s][A
 34%|███▍      | 76/221 [00:26<00:30,  4.82it/s][A
 35%|███▍      | 77/221 [00:26<00:25,  5.59it/s][A[h264 @ 0x556a847b42c0] mmco: unref short failure

 36%|███▌      | 79/221 [00:26<00:29,  4.81it/s][A
 36%|███▌      | 80/221 [00:27<00:29,  4.73it/s][A
 37%|███▋      | 81/221 [00:27<00:27,  5.13it/s][A
 37%|███▋      | 82/221 [00:27<00:28,  4.86it/s][A
 38%|███▊      | 83/221 [00:27<00:24,  5.59it/s][A
 38%|███▊      | 85/221 [00:27<00:20,  6.80it/s][A
 39%|███▉      | 86/221 [00:28<00:23,  5.63it/s][A
 39%|███▉      | 87/221 [00:28<00:24,  5.41it/s][A
 40%|███▉      | 88/221 [00:28<00:26,  4.95it/s][A
 40%|████      | 89/221 [00:28<00:26,  5.01it/s][A
 41%|████      | 90/221 [00:28<00:24,  5.32it/s][A
 42%|████▏     | 92/221 [00:29<00:22,  5.79it/s][A
 42%|████▏     | 93/221 [00:29<00:35,  3.57it/s][A
 43%|████▎     | 94/221 [00:30<00:31,  4.00it/s][A
 43%|████▎     | 95/221 [00:30<00:29,  4.28it/s][A
 43%|████▎     | 96/221 [00:30<00:31,  4.01it/s][A
 44%|████▍     | 97/221 [00:30<00:25,  4.82it/s][A[h264 @ 0x556a86f14240] mmco: unref short failure

 44%|████▍     | 98/221 [00:31<00:37,  3.26it/s][A
 45%|████▍     | 99/221 [00:31<00:32,  3.74it/s][A
 45%|████▌     | 100/221 [00:31<00:26,  4.51it/s][A
 46%|████▌     | 101/221 [00:31<00:27,  4.38it/s][A
 46%|████▌     | 102/221 [00:31<00:27,  4.28it/s][A
 47%|████▋     | 103/221 [00:32<00:25,  4.54it/s][A
 47%|████▋     | 104/221 [00:32<00:21,  5.39it/s][A
 48%|████▊     | 105/221 [00:32<00:19,  5.93it/s][A
 48%|████▊     | 106/221 [00:32<00:25,  4.53it/s][A[h264 @ 0x559b43f48700] mmco: unref short failure
[h264 @ 0x559b43f48700] mmco: unref short failure

 48%|████▊     | 107/221 [00:32<00:25,  4.53it/s][A
 49%|████▉     | 108/221 [00:33<00:21,  5.18it/s][A
 50%|████▉     | 110/221 [00:33<00:18,  5.85it/s][A
 50%|█████     | 111/221 [00:33<00:24,  4.45it/s][A
 51%|█████     | 112/221 [00:33<00:25,  4.20it/s][A
 51%|█████     | 113/221 [00:34<00:25,  4.31it/s][A
 52%|█████▏    | 115/221 [00:34<00:18,  5.76it/s][A[h264 @ 0x559b3a3baf80] mmco: unref short failure
[h264 @ 0x556a92ac4000] mmco: unref short failure

 52%|█████▏    | 116/221 [00:38<02:07,  1.21s/it][A
 53%|█████▎    | 117/221 [00:39<01:41,  1.03it/s][A
 53%|█████▎    | 118/221 [00:39<01:17,  1.32it/s][A
 54%|█████▍    | 119/221 [00:39<01:00,  1.70it/s][A
 54%|█████▍    | 120/221 [00:39<00:50,  2.01it/s][A
 55%|█████▍    | 121/221 [00:40<00:45,  2.22it/s][A
 55%|█████▌    | 122/221 [00:40<00:37,  2.61it/s][A
 56%|█████▌    | 123/221 [00:40<00:32,  3.06it/s][A
 56%|█████▌    | 124/221 [00:40<00:28,  3.45it/s][A
 57%|█████▋    | 125/221 [00:41<00:34,  2.78it/s][A
 57%|█████▋    | 126/221 [00:41<00:31,  2.99it/s][A
 57%|█████▋    | 127/221 [00:42<00:45,  2.09it/s][A
 58%|█████▊    | 128/221 [00:43<00:57,  1.63it/s][A
 58%|█████▊    | 129/221 [00:43<00:42,  2.15it/s][A
 59%|█████▉    | 130/221 [00:43<00:33,  2.74it/s][A
 60%|█████▉    | 132/221 [00:43<00:26,  3.32it/s][A
 60%|██████    | 133/221 [00:44<00:24,  3.54it/s][A
 61%|██████    | 134/221 [00:44<00:28,  3.04it/s][A
 61%|██████    | 135/221 [00:45<00:31,  2.69it/s][A[h264 @ 0x559b3730c100] mmco: unref short failure
[h264 @ 0x559b3730c100] mmco: unref short failure

 62%|██████▏   | 136/221 [00:46<00:55,  1.54it/s][A
 62%|██████▏   | 137/221 [00:50<02:19,  1.66s/it][A
 62%|██████▏   | 138/221 [00:51<01:51,  1.35s/it][A[h264 @ 0x559b4f2cff00] mmco: unref short failure
[h264 @ 0x559b4f2cff00] mmco: unref short failure

 63%|██████▎   | 139/221 [00:52<01:38,  1.21s/it][A
 63%|██████▎   | 140/221 [00:52<01:14,  1.08it/s][A[h264 @ 0x559f81f70c00] mmco: unref short failure
[h264 @ 0x559f81f70c00] mmco: unref short failure

 64%|██████▍   | 141/221 [00:52<01:05,  1.23it/s][A
 64%|██████▍   | 142/221 [00:53<00:52,  1.49it/s][A
 65%|██████▍   | 143/221 [00:53<00:41,  1.87it/s][A
 66%|██████▌   | 145/221 [00:53<00:24,  3.05it/s][A
 67%|██████▋   | 147/221 [00:53<00:18,  4.02it/s][A
 67%|██████▋   | 148/221 [00:54<00:20,  3.57it/s][A
 67%|██████▋   | 149/221 [00:54<00:19,  3.76it/s][A
 68%|██████▊   | 150/221 [00:54<00:16,  4.40it/s][A
 68%|██████▊   | 151/221 [00:54<00:15,  4.59it/s][A
 69%|██████▉   | 152/221 [00:55<00:18,  3.76it/s][A
 69%|██████▉   | 153/221 [00:55<00:16,  4.01it/s][A
 70%|███████   | 155/221 [00:55<00:11,  5.60it/s][A[h264 @ 0x556a81b75c00] mmco: unref short failure

 71%|███████   | 157/221 [01:00<01:05,  1.02s/it][A
 71%|███████▏  | 158/221 [01:00<00:53,  1.18it/s][A
 72%|███████▏  | 160/221 [01:00<00:33,  1.81it/s][A
 73%|███████▎  | 162/221 [01:00<00:22,  2.61it/s][A
 74%|███████▍  | 163/221 [01:01<00:20,  2.85it/s][A
 74%|███████▍  | 164/221 [01:01<00:17,  3.27it/s][A
 75%|███████▍  | 165/221 [01:01<00:15,  3.69it/s][A
 75%|███████▌  | 166/221 [01:05<01:15,  1.37s/it][A[h264 @ 0x559f84ce9c00] mmco: unref short failure

 76%|███████▌  | 168/221 [01:09<01:22,  1.55s/it][A
 76%|███████▋  | 169/221 [01:09<01:03,  1.22s/it][A
 77%|███████▋  | 170/221 [01:09<00:50,  1.00it/s][A
 77%|███████▋  | 171/221 [01:10<00:42,  1.19it/s][A
 78%|███████▊  | 173/221 [01:10<00:25,  1.87it/s][A
 79%|███████▊  | 174/221 [01:10<00:21,  2.20it/s][A
 79%|███████▉  | 175/221 [01:10<00:17,  2.65it/s][A
 80%|████████  | 177/221 [01:11<00:11,  3.68it/s][A
 81%|████████  | 178/221 [01:11<00:11,  3.71it/s][A[h264 @ 0x56236caac340] mmco: unref short failure
[h264 @ 0x56236caac340] mmco: unref short failure
[h264 @ 0x56236caac340] mmco: unref short failure
[h264 @ 0x56236caac340] mmco: unref short failure

 81%|████████  | 179/221 [01:15<00:47,  1.13s/it][A[h264 @ 0x559b378f8300] mmco: unref short failure
[h264 @ 0x559b378f8300] mmco: unref short failure
[h264 @ 0x559b378f8300] mmco: unref short failure
[h264 @ 0x559b378f8300] mmco: unref short failure

 82%|████████▏ | 182/221 [01:15<00:22,  1.74it/s][A
 83%|████████▎ | 183/221 [01:15<00:18,  2.03it/s][A
 83%|████████▎ | 184/221 [01:15<00:15,  2.44it/s][A
 84%|████████▍ | 186/221 [01:15<00:09,  3.59it/s][A
 85%|████████▌ | 188/221 [01:15<00:06,  4.77it/s][A
 86%|████████▌ | 190/221 [01:16<00:05,  5.31it/s][A
 87%|████████▋ | 193/221 [01:16<00:03,  7.78it/s][A
 88%|████████▊ | 195/221 [01:16<00:04,  6.24it/s][A
 89%|████████▉ | 197/221 [01:16<00:03,  7.57it/s][A
 90%|█████████ | 199/221 [01:17<00:02,  8.52it/s][A
 91%|█████████ | 201/221 [01:17<00:02,  9.31it/s][A
 92%|█████████▏| 203/221 [01:17<00:01,  9.35it/s][A
 93%|█████████▎| 205/221 [01:17<00:01,  9.92it/s][A
 94%|█████████▎| 207/221 [01:17<00:01,  9.11it/s][A
 95%|█████████▍| 209/221 [01:18<00:01,  9.78it/s][A
 95%|█████████▌| 211/221 [01:18<00:01,  8.19it/s][A
 96%|█████████▌| 212/221 [01:18<00:01,  8.22it/s][A
 97%|█████████▋| 214/221 [01:18<00:00,  7.28it/s][A
 98%|█████████▊| 216/221 [01:19<00:00,  8.74it/s][A
 99%|█████████▊| 218/221 [01:23<00:02,  1.27it/s][A
100%|█████████▉| 220/221 [01:28<00:01,  1.25s/it][A100%|██████████| 221/221 [01:28<00:00,  2.51it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:57,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:52,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:22<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:37<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:51<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  1%|          | 2/221 [00:00<00:48,  4.49it/s][A
  1%|▏         | 3/221 [00:00<00:54,  4.03it/s][A
  2%|▏         | 4/221 [00:00<00:45,  4.74it/s][A
  2%|▏         | 5/221 [00:01<00:45,  4.77it/s][A
  3%|▎         | 7/221 [00:01<00:42,  5.05it/s][A
  4%|▎         | 8/221 [00:01<00:47,  4.47it/s][A
  4%|▍         | 9/221 [00:01<00:44,  4.78it/s][A
  5%|▍         | 10/221 [00:02<01:03,  3.31it/s][A
  5%|▍         | 11/221 [00:02<01:00,  3.49it/s][A
  5%|▌         | 12/221 [00:02<00:53,  3.87it/s][A
  6%|▌         | 13/221 [00:03<01:03,  3.26it/s][A
  6%|▋         | 14/221 [00:03<00:58,  3.51it/s][A
  7%|▋         | 15/221 [00:03<00:55,  3.74it/s][A
  7%|▋         | 16/221 [00:04<01:01,  3.32it/s][A
  8%|▊         | 17/221 [00:04<01:17,  2.62it/s][A
  8%|▊         | 18/221 [00:04<01:06,  3.04it/s][A
  9%|▊         | 19/221 [00:05<01:01,  3.27it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.77it/s][A
 10%|▉         | 21/221 [00:05<00:51,  3.91it/s][A
 10%|▉         | 22/221 [00:05<00:51,  3.89it/s][A
 11%|█         | 24/221 [00:06<00:40,  4.87it/s][A
 11%|█▏        | 25/221 [00:06<00:40,  4.85it/s][A
 12%|█▏        | 26/221 [00:06<00:45,  4.29it/s][A
 12%|█▏        | 27/221 [00:06<00:39,  4.93it/s][A
 13%|█▎        | 28/221 [00:07<00:53,  3.64it/s][A
 13%|█▎        | 29/221 [00:07<00:49,  3.90it/s][A
 14%|█▎        | 30/221 [00:07<00:57,  3.34it/s][A
 14%|█▍        | 31/221 [00:08<00:54,  3.52it/s][A
 14%|█▍        | 32/221 [00:08<00:44,  4.23it/s][A
 15%|█▍        | 33/221 [00:08<00:42,  4.39it/s][A
 15%|█▌        | 34/221 [00:08<00:37,  5.03it/s][A
 16%|█▌        | 35/221 [00:08<00:44,  4.19it/s][A
 16%|█▋        | 36/221 [00:09<00:49,  3.77it/s][A
 17%|█▋        | 37/221 [00:09<00:43,  4.22it/s][A
 17%|█▋        | 38/221 [00:09<00:43,  4.25it/s][A
 18%|█▊        | 39/221 [00:09<00:40,  4.54it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.82it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.75it/s][A
 19%|█▉        | 42/221 [00:10<00:41,  4.29it/s][A
 19%|█▉        | 43/221 [00:10<00:39,  4.55it/s][A
 20%|█▉        | 44/221 [00:10<00:36,  4.81it/s][A
 20%|██        | 45/221 [00:11<00:44,  3.97it/s][A
 21%|██        | 46/221 [00:11<00:44,  3.95it/s][A
 21%|██▏       | 47/221 [00:11<00:43,  4.02it/s][A
 22%|██▏       | 48/221 [00:11<00:36,  4.77it/s][A
 22%|██▏       | 49/221 [00:12<00:35,  4.82it/s][A
 23%|██▎       | 50/221 [00:12<00:49,  3.44it/s][A
 23%|██▎       | 51/221 [00:12<00:40,  4.16it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.81it/s][A
 24%|██▍       | 53/221 [00:13<00:41,  4.09it/s][A
 24%|██▍       | 54/221 [00:13<00:44,  3.76it/s][A
 25%|██▍       | 55/221 [00:13<00:45,  3.66it/s][A
 25%|██▌       | 56/221 [00:14<00:39,  4.19it/s][A
 26%|██▌       | 57/221 [00:14<00:37,  4.32it/s][A
 26%|██▌       | 58/221 [00:14<00:46,  3.49it/s][A
 27%|██▋       | 59/221 [00:14<00:41,  3.93it/s][A
 27%|██▋       | 60/221 [00:15<00:36,  4.45it/s][A
 28%|██▊       | 61/221 [00:15<00:35,  4.51it/s][A
 28%|██▊       | 62/221 [00:15<00:39,  4.06it/s][A
 29%|██▊       | 63/221 [00:15<00:38,  4.10it/s][A
 29%|██▉       | 64/221 [00:16<00:43,  3.59it/s][A
 29%|██▉       | 65/221 [00:16<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:16<00:49,  3.14it/s][A
 30%|███       | 67/221 [00:17<00:46,  3.31it/s][A
 31%|███       | 68/221 [00:17<00:41,  3.67it/s][A
 31%|███       | 69/221 [00:17<00:57,  2.63it/s][A
 32%|███▏      | 70/221 [00:18<00:53,  2.85it/s][A
 32%|███▏      | 71/221 [00:18<00:44,  3.38it/s][A
 33%|███▎      | 72/221 [00:18<00:51,  2.91it/s][A
 33%|███▎      | 73/221 [00:19<00:48,  3.07it/s][A
 34%|███▍      | 75/221 [00:19<00:37,  3.89it/s][A
 34%|███▍      | 76/221 [00:19<00:35,  4.07it/s][A
 35%|███▍      | 77/221 [00:20<00:42,  3.38it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.80it/s][A
 36%|███▌      | 79/221 [00:20<00:47,  2.99it/s][A
 36%|███▌      | 80/221 [00:21<00:45,  3.07it/s][A
 37%|███▋      | 81/221 [00:21<00:39,  3.51it/s][A
 37%|███▋      | 82/221 [00:21<00:42,  3.31it/s][A
 38%|███▊      | 83/221 [00:21<00:41,  3.31it/s][A
 38%|███▊      | 84/221 [00:22<00:40,  3.36it/s][A
 38%|███▊      | 85/221 [00:22<00:33,  4.06it/s][A
 39%|███▉      | 86/221 [00:22<00:30,  4.38it/s][A
 39%|███▉      | 87/221 [00:22<00:35,  3.81it/s][A
 40%|███▉      | 88/221 [00:23<00:43,  3.03it/s][A
 40%|████      | 89/221 [00:23<00:42,  3.09it/s][A
 41%|████      | 90/221 [00:23<00:38,  3.38it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.80it/s][A
 42%|████▏     | 92/221 [00:24<00:37,  3.44it/s][A
 42%|████▏     | 93/221 [00:24<00:43,  2.97it/s][A
 43%|████▎     | 94/221 [00:25<00:44,  2.83it/s][A
 43%|████▎     | 95/221 [00:25<00:42,  2.94it/s][A
 43%|████▎     | 96/221 [00:25<00:42,  2.93it/s][A
 44%|████▍     | 97/221 [00:26<00:39,  3.15it/s][A
 44%|████▍     | 98/221 [00:26<00:50,  2.45it/s][A
 45%|████▍     | 99/221 [00:27<00:43,  2.82it/s][A
 45%|████▌     | 100/221 [00:27<00:41,  2.88it/s][A
 46%|████▌     | 101/221 [00:27<00:38,  3.14it/s][A
 46%|████▌     | 102/221 [00:28<00:44,  2.69it/s][A
 47%|████▋     | 103/221 [00:28<00:36,  3.24it/s][A
 47%|████▋     | 104/221 [00:28<00:32,  3.56it/s][A
 48%|████▊     | 105/221 [00:28<00:36,  3.18it/s][A
 48%|████▊     | 106/221 [00:29<00:34,  3.30it/s][A
 48%|████▊     | 107/221 [00:29<00:32,  3.55it/s][A
 49%|████▉     | 108/221 [00:29<00:31,  3.62it/s][A
 49%|████▉     | 109/221 [00:29<00:26,  4.16it/s][A
 50%|████▉     | 110/221 [00:30<00:28,  3.94it/s][A
 50%|█████     | 111/221 [00:30<00:31,  3.52it/s][A
 51%|█████     | 112/221 [00:30<00:30,  3.52it/s][A
 51%|█████     | 113/221 [00:30<00:27,  3.93it/s][A
 52%|█████▏    | 114/221 [00:31<00:22,  4.74it/s][A
 52%|█████▏    | 115/221 [00:31<00:23,  4.56it/s][A
 52%|█████▏    | 116/221 [00:31<00:24,  4.32it/s][A
 53%|█████▎    | 117/221 [00:31<00:25,  4.15it/s][A
 53%|█████▎    | 118/221 [00:32<00:24,  4.22it/s][A
 54%|█████▍    | 119/221 [00:32<00:28,  3.59it/s][A
 54%|█████▍    | 120/221 [00:32<00:25,  3.91it/s][A
 55%|█████▍    | 121/221 [00:32<00:21,  4.72it/s][A
 55%|█████▌    | 122/221 [00:32<00:23,  4.28it/s][A
 56%|█████▌    | 123/221 [00:33<00:23,  4.21it/s][A
 56%|█████▌    | 124/221 [00:33<00:25,  3.76it/s][A
 57%|█████▋    | 125/221 [00:33<00:28,  3.39it/s][A
 57%|█████▋    | 126/221 [00:34<00:25,  3.76it/s][A
 57%|█████▋    | 127/221 [00:34<00:28,  3.29it/s][A
 58%|█████▊    | 128/221 [00:34<00:27,  3.33it/s][A
 58%|█████▊    | 129/221 [00:34<00:22,  4.07it/s][A
 59%|█████▉    | 130/221 [00:35<00:22,  4.07it/s][A
 59%|█████▉    | 131/221 [00:35<00:18,  4.82it/s][A
 60%|█████▉    | 132/221 [00:35<00:28,  3.17it/s][A
 60%|██████    | 133/221 [00:36<00:27,  3.19it/s][A
 61%|██████    | 134/221 [00:36<00:31,  2.80it/s][A
 61%|██████    | 135/221 [00:36<00:30,  2.78it/s][A
 62%|██████▏   | 136/221 [00:37<00:28,  2.97it/s][A
 62%|██████▏   | 137/221 [00:37<00:26,  3.23it/s][A
 62%|██████▏   | 138/221 [00:37<00:26,  3.08it/s][A
 63%|██████▎   | 139/221 [00:38<00:26,  3.07it/s][A
 63%|██████▎   | 140/221 [00:38<00:27,  2.96it/s][A
 64%|██████▍   | 141/221 [00:38<00:26,  3.01it/s][A
 64%|██████▍   | 142/221 [00:39<00:23,  3.37it/s][A
 65%|██████▍   | 143/221 [00:39<00:23,  3.25it/s][A
 65%|██████▌   | 144/221 [00:39<00:24,  3.14it/s][A
 66%|██████▌   | 145/221 [00:39<00:21,  3.59it/s][A
 66%|██████▌   | 146/221 [00:40<00:16,  4.42it/s][A
 67%|██████▋   | 147/221 [00:40<00:19,  3.80it/s][A
 67%|██████▋   | 148/221 [00:40<00:24,  3.04it/s][A
 67%|██████▋   | 149/221 [00:41<00:26,  2.69it/s][A
 68%|██████▊   | 150/221 [00:41<00:24,  2.87it/s][A
 68%|██████▊   | 151/221 [00:42<00:24,  2.81it/s][A
 69%|██████▉   | 152/221 [00:42<00:24,  2.80it/s][A
 69%|██████▉   | 153/221 [00:42<00:20,  3.36it/s][A
 70%|██████▉   | 154/221 [00:42<00:17,  3.84it/s][A
 70%|███████   | 155/221 [00:42<00:17,  3.88it/s][A
 71%|███████   | 156/221 [00:43<00:18,  3.59it/s][A
 71%|███████   | 157/221 [00:43<00:19,  3.31it/s][A
 71%|███████▏  | 158/221 [00:43<00:18,  3.40it/s][A
 72%|███████▏  | 159/221 [00:44<00:15,  4.12it/s][A
 72%|███████▏  | 160/221 [00:44<00:13,  4.47it/s][A
 73%|███████▎  | 161/221 [00:44<00:13,  4.57it/s][A
 74%|███████▍  | 163/221 [00:44<00:11,  4.89it/s][A
 74%|███████▍  | 164/221 [00:45<00:12,  4.63it/s][A
 75%|███████▍  | 165/221 [00:45<00:14,  3.83it/s][A
 75%|███████▌  | 166/221 [00:45<00:14,  3.89it/s][A
 76%|███████▌  | 167/221 [00:45<00:11,  4.54it/s][A
 76%|███████▌  | 168/221 [00:46<00:11,  4.57it/s][A
 76%|███████▋  | 169/221 [00:46<00:09,  5.24it/s][A
 77%|███████▋  | 170/221 [00:46<00:12,  4.18it/s][A
 77%|███████▋  | 171/221 [00:46<00:12,  3.88it/s][A
 78%|███████▊  | 172/221 [00:47<00:13,  3.59it/s][A
 78%|███████▊  | 173/221 [00:47<00:15,  3.09it/s][A
 79%|███████▊  | 174/221 [00:47<00:15,  3.07it/s][A
 79%|███████▉  | 175/221 [00:48<00:14,  3.27it/s][A
 80%|███████▉  | 176/221 [00:48<00:11,  3.92it/s][A
 80%|████████  | 177/221 [00:48<00:10,  4.00it/s][A
 81%|████████  | 178/221 [00:49<00:13,  3.21it/s][A
 81%|████████  | 179/221 [00:49<00:13,  3.20it/s][A
 81%|████████▏ | 180/221 [00:49<00:11,  3.63it/s][A
 82%|████████▏ | 181/221 [00:49<00:09,  4.02it/s][A
 82%|████████▏ | 182/221 [00:50<00:11,  3.44it/s][A
 83%|████████▎ | 183/221 [00:50<00:11,  3.26it/s][A
 83%|████████▎ | 184/221 [00:50<00:10,  3.50it/s][A
 84%|████████▎ | 185/221 [00:50<00:09,  3.93it/s][A
 84%|████████▍ | 186/221 [00:51<00:12,  2.74it/s][A
 85%|████████▍ | 187/221 [00:51<00:11,  2.87it/s][A
 85%|████████▌ | 188/221 [00:52<00:10,  3.02it/s][A
 86%|████████▌ | 189/221 [00:52<00:09,  3.21it/s][A
 86%|████████▌ | 190/221 [00:52<00:09,  3.32it/s][A
 86%|████████▋ | 191/221 [00:52<00:07,  3.92it/s][A
 87%|████████▋ | 192/221 [00:53<00:07,  3.92it/s][A
 87%|████████▋ | 193/221 [00:53<00:06,  4.57it/s][A
 88%|████████▊ | 194/221 [00:53<00:06,  4.33it/s][A
 88%|████████▊ | 195/221 [00:53<00:06,  4.05it/s][A
 89%|████████▊ | 196/221 [00:54<00:06,  3.65it/s][A
 89%|████████▉ | 197/221 [00:54<00:06,  3.96it/s][A
 90%|████████▉ | 198/221 [00:54<00:06,  3.44it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.39it/s][A
 90%|█████████ | 200/221 [00:55<00:06,  3.46it/s][A
 91%|█████████ | 201/221 [00:55<00:05,  3.81it/s][A
 91%|█████████▏| 202/221 [00:55<00:05,  3.32it/s][A
 92%|█████████▏| 203/221 [00:56<00:04,  3.63it/s][A
 92%|█████████▏| 204/221 [00:56<00:04,  3.86it/s][A
 93%|█████████▎| 205/221 [00:56<00:03,  4.43it/s][A
 93%|█████████▎| 206/221 [00:56<00:03,  3.76it/s][A
 94%|█████████▎| 207/221 [00:56<00:03,  3.77it/s][A
 94%|█████████▍| 208/221 [00:57<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [00:57<00:03,  3.43it/s][A
 95%|█████████▌| 210/221 [00:57<00:02,  4.11it/s][A
 95%|█████████▌| 211/221 [00:58<00:02,  3.40it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  3.53it/s][A
 96%|█████████▋| 213/221 [00:58<00:01,  4.00it/s][A
 97%|█████████▋| 214/221 [00:59<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [00:59<00:01,  3.89it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.46it/s][A
 98%|█████████▊| 217/221 [00:59<00:01,  2.98it/s][A
 99%|█████████▊| 218/221 [01:00<00:01,  2.97it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.07it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.34it/s][A
100%|██████████| 221/221 [01:01<00:00,  3.29it/s][A100%|██████████| 221/221 [01:01<00:00,  3.61it/s]
09/09/2024 17:21:01 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 49--===========

09/09/2024 17:21:01 - INFO - __main__ -   {'area_r1': 36.7, 'area_recall': '36.7/58.3/65.7', 'area_ravg': 53.5}
09/09/2024 17:21:01 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 49--===========

09/09/2024 17:21:01 - INFO - __main__ -   {'forward_r1': 38.0, 'forward_recall': '38.0/66.9/77.8', 'forward_ravg': 60.9}
09/09/2024 17:21:01 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 49--===========

09/09/2024 17:21:01 - INFO - __main__ -   {'area_video_r1': 37.1, 'area_video_recall': '37.1/68.2/77.8', 'area_video_ravg': 61.0}
09/09/2024 17:21:01 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 49=======

09/09/2024 17:21:01 - INFO - __main__ -   {'area_video_r1': 37.1, 'area_video_recall': '37.1/68.2/77.8', 'area_video_ravg': 61.0}
09/09/2024 17:21:01 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 49--===========

09/09/2024 17:21:01 - INFO - __main__ -   {'area_video_r1': 49.4, 'area_video_recall': '49.4/72.4/78.6', 'area_video_ravg': 66.8, 'area_video_back_r1': 46.0, 'area_video_back_recall': '46.0/70.5/79.0', 'area_video_back_ravg': 65.2}
09/09/2024 17:21:01 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 49=======

09/09/2024 17:21:01 - INFO - __main__ -   {'area_video_r1': 49.4, 'area_video_recall': '49.4/72.4/78.6', 'area_video_ravg': 66.8, 'area_video_back_r1': 46.0, 'area_video_back_recall': '46.0/70.5/79.0', 'area_video_back_ravg': 65.2}
09/09/2024 17:21:01 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 49--===========

09/09/2024 17:21:01 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 17:21:01 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 17:21:01 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 17:21:01 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 49--===========

09/09/2024 17:21:01 - INFO - __main__ -   {'video_r1': 50.1, 'video_recall': '50.1/73.6/81.1', 'video_ravg': 68.3}
09/09/2024 17:21:01 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 49=======

09/09/2024 17:21:01 - INFO - __main__ -   {'video_r1': 50.1, 'video_recall': '50.1/73.6/81.1', 'video_ravg': 68.3}
09/09/2024 17:21:39 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.009376425296068192, 'loss_ret%tv%ta--finetune_area/loss_area': 3.8461408615112305, 'loss_ret%tv%ta--finetune_area/total_loss': 3.8555173873901367}
  3%|▎         | 50/1945 [16:20<67:55:59, 129.05s/it][h264 @ 0x559b466ece40] mmco: unref short failure
[h264 @ 0x559b466ece40] mmco: unref short failure
  3%|▎         | 51/1945 [16:24<48:15:02, 91.71s/it] [h264 @ 0x556a85e638c0] mmco: unref short failure
[h264 @ 0x556a85e638c0] mmco: unref short failure
  3%|▎         | 52/1945 [16:29<34:31:37, 65.66s/it]  3%|▎         | 53/1945 [16:35<25:01:20, 47.61s/it][h264 @ 0x559f92204700] mmco: unref short failure
[h264 @ 0x559f92204700] mmco: unref short failure
  3%|▎         | 54/1945 [16:40<18:22:45, 34.99s/it][h264 @ 0x556a84839c40] mmco: unref short failure
[h264 @ 0x556a84839c40] mmco: unref short failure
  3%|▎         | 55/1945 [16:47<13:52:59, 26.44s/it]  3%|▎         | 56/1945 [16:53<10:40:40, 20.35s/it][h264 @ 0x56236ae8e6c0] mmco: unref short failure
[h264 @ 0x56236ae8e6c0] mmco: unref short failure
[h264 @ 0x559f7eae43c0] mmco: unref short failure
  3%|▎         | 57/1945 [17:00<8:34:09, 16.34s/it]   3%|▎         | 58/1945 [17:08<7:15:03, 13.83s/it][h264 @ 0x556a85ddd5c0] mmco: unref short failure
[h264 @ 0x556a85ddd5c0] mmco: unref short failure
  3%|▎         | 59/1945 [17:16<6:21:21, 12.13s/it]  3%|▎         | 60/1945 [17:24<5:44:15, 10.96s/it][h264 @ 0x559f803154c0] mmco: unref short failure
  3%|▎         | 61/1945 [17:33<5:19:39, 10.18s/it][h264 @ 0x556a7a4e9b00] mmco: unref short failure
[h264 @ 0x556a8d5c8b00] mmco: unref short failure
[h264 @ 0x556a8d5c8b00] mmco: unref short failure
  3%|▎         | 62/1945 [17:41<4:56:46,  9.46s/it]  3%|▎         | 63/1945 [17:49<4:52:12,  9.32s/it][h264 @ 0x556a86da2fc0] mmco: unref short failure
[h264 @ 0x559f930314c0] mmco: unref short failure
  3%|▎         | 64/1945 [17:57<4:33:11,  8.71s/it][h264 @ 0x56236d4845c0] mmco: unref short failure
[h264 @ 0x56236d4845c0] mmco: unref short failure
[h264 @ 0x56236b68eb80] mmco: unref short failure
[h264 @ 0x556a86dfb080] mmco: unref short failure
[h264 @ 0x556a86dfb080] mmco: unref short failure
  3%|▎         | 65/1945 [18:04<4:15:01,  8.14s/it]  3%|▎         | 66/1945 [18:10<3:58:06,  7.60s/it][h264 @ 0x562363a2c940] mmco: unref short failure
  3%|▎         | 67/1945 [18:17<3:53:36,  7.46s/it][h264 @ 0x56236f7dc4c0] mmco: unref short failure
[h264 @ 0x56236f7dc4c0] mmco: unref short failure
[h264 @ 0x559f86efaa00] mmco: unref short failure
  3%|▎         | 68/1945 [18:24<3:48:52,  7.32s/it][h264 @ 0x556a78af1e00] mmco: unref short failure
  4%|▎         | 69/1945 [18:32<3:51:19,  7.40s/it][h264 @ 0x556a78f2b440] mmco: unref short failure
[h264 @ 0x556a78f2b440] mmco: unref short failure
[h264 @ 0x556a78f2b440] mmco: unref short failure
[h264 @ 0x556a78f2b440] mmco: unref short failure
[h264 @ 0x556a86d2c280] mmco: unref short failure
[h264 @ 0x559b4b7c7d00] mmco: unref short failure
[h264 @ 0x559b4b7c7d00] mmco: unref short failure
[h264 @ 0x56236a60f7c0] mmco: unref short failure
[h264 @ 0x56236a60f7c0] mmco: unref short failure
[h264 @ 0x56236a60f7c0] mmco: unref short failure
[h264 @ 0x56236a60f7c0] mmco: unref short failure
  4%|▎         | 70/1945 [18:46<4:57:41,  9.53s/it][h264 @ 0x559b39a402c0] mmco: unref short failure
[h264 @ 0x559b39a402c0] mmco: unref short failure
[h264 @ 0x559b3a394380] mmco: unref short failure
[h264 @ 0x556a7935cb00] mmco: unref short failure
[h264 @ 0x556a7935cb00] mmco: unref short failure
  4%|▎         | 71/1945 [18:53<4:34:26,  8.79s/it][h264 @ 0x562372c82880] mmco: unref short failure
[h264 @ 0x562372c82880] mmco: unref short failure
[h264 @ 0x562372c82880] mmco: unref short failure
[h264 @ 0x562372c82880] mmco: unref short failure
[h264 @ 0x559f9011cdc0] mmco: unref short failure
[h264 @ 0x559b3e7f5b40] mmco: unref short failure
[h264 @ 0x559b3e7f5b40] mmco: unref short failure
  4%|▎         | 72/1945 [19:00<4:16:22,  8.21s/it]  4%|▍         | 73/1945 [19:07<4:04:40,  7.84s/it][h264 @ 0x556a793675c0] mmco: unref short failure
[h264 @ 0x556a87989600] mmco: unref short failure
[h264 @ 0x556a87989600] mmco: unref short failure
[h264 @ 0x556a793675c0] mmco: unref short failure
[h264 @ 0x559f91a30540] mmco: unref short failure
[h264 @ 0x562362e155c0] mmco: unref short failure
[h264 @ 0x562362e155c0] mmco: unref short failure
[h264 @ 0x559b4089d6c0] mmco: unref short failure
[h264 @ 0x559b4089d6c0] mmco: unref short failure
[h264 @ 0x556a86e97240] mmco: unref short failure
[h264 @ 0x556a86e97240] mmco: unref short failure
[h264 @ 0x556a879f4f80] mmco: unref short failure
[h264 @ 0x559b447ef480] mmco: unref short failure
[h264 @ 0x559f96992680] mmco: unref short failure
[h264 @ 0x56236d9d05c0] mmco: unref short failure
[h264 @ 0x56236d9d05c0] mmco: unref short failure
[h264 @ 0x5623718a8180] mmco: unref short failure
[h264 @ 0x559b4950a1c0] mmco: unref short failure
[h264 @ 0x559b4950a1c0] mmco: unref short failure
[h264 @ 0x562371f36880] mmco: unref short failure
[h264 @ 0x562371f36880] mmco: unref short failure
[h264 @ 0x562371f36880] mmco: unref short failure
[h264 @ 0x562377608180] mmco: unref short failure
[h264 @ 0x562377608180] mmco: unref short failure
[h264 @ 0x562377608180] mmco: unref short failure
[h264 @ 0x562377608180] mmco: unref short failure
[h264 @ 0x559b44987f00] mmco: unref short failure
[h264 @ 0x559f8923b740] mmco: unref short failure
[h264 @ 0x559f8923b740] mmco: unref short failure
[h264 @ 0x56236c1edc00] mmco: unref short failure
[h264 @ 0x56236c1edc00] mmco: unref short failure
[h264 @ 0x562362ee6740] mmco: unref short failure
[h264 @ 0x562362ee6740] mmco: unref short failure
[h264 @ 0x556a7ac7bb80] mmco: unref short failure
[h264 @ 0x56237453a8c0] mmco: unref short failure
[h264 @ 0x559b40e38540] mmco: unref short failure
[h264 @ 0x559f90e29540] mmco: unref short failure
[h264 @ 0x559f90e29540] mmco: unref short failure
[h264 @ 0x559f90e29540] mmco: unref short failure
[h264 @ 0x559f90e29540] mmco: unref short failure
  4%|▍         | 74/1945 [20:00<11:07:22, 21.40s/it][h264 @ 0x562366b99180] mmco: unref short failure
  4%|▍         | 75/1945 [20:08<8:58:39, 17.28s/it] [h264 @ 0x556a7ac7b900] mmco: unref short failure
[h264 @ 0x556a79033240] mmco: unref short failure
[h264 @ 0x556a79033240] mmco: unref short failure
[h264 @ 0x556a79033240] mmco: unref short failure
[h264 @ 0x556a79033240] mmco: unref short failure
[h264 @ 0x559b4703a8c0] mmco: unref short failure
  4%|▍         | 76/1945 [20:23<8:35:31, 16.55s/it][h264 @ 0x556a8d6903c0] mmco: unref short failure
[h264 @ 0x559f92f9b980] mmco: unref short failure
[h264 @ 0x559f92f9b980] mmco: unref short failure
[h264 @ 0x559f7d8fa8c0] mmco: unref short failure
[h264 @ 0x559f7d8fa8c0] mmco: unref short failure
[h264 @ 0x556a83b5d700] mmco: unref short failure
[h264 @ 0x556a83b5d700] mmco: unref short failure
[h264 @ 0x556a866e6140] mmco: unref short failure
[h264 @ 0x556a8bb0bc40] mmco: unref short failure
[h264 @ 0x556a8bb0bc40] mmco: unref short failure
  4%|▍         | 77/1945 [20:40<8:43:57, 16.83s/it][h264 @ 0x56236b751780] mmco: unref short failure
[h264 @ 0x559f7fca2980] mmco: unref short failure
[h264 @ 0x559f7fca2980] mmco: unref short failure
[h264 @ 0x559b4c268540] mmco: unref short failure
[h264 @ 0x559b4c268540] mmco: unref short failure
  4%|▍         | 78/1945 [20:54<8:14:09, 15.88s/it][h264 @ 0x559b47770e80] mmco: unref short failure
[h264 @ 0x559b47770e80] mmco: unref short failure
[h264 @ 0x559b47770e80] mmco: unref short failure
[h264 @ 0x559b47770e80] mmco: unref short failure
[h264 @ 0x559b47770e80] mmco: unref short failure
[h264 @ 0x559b47770e80] mmco: unref short failure
[h264 @ 0x559b47770e80] mmco: unref short failure
[h264 @ 0x559b47770e80] mmco: unref short failure
[h264 @ 0x559b47770e80] mmco: unref short failure
[h264 @ 0x559b47770e80] mmco: unref short failure
  4%|▍         | 79/1945 [21:01<6:54:02, 13.31s/it][h264 @ 0x559b468b7380] mmco: unref short failure
[h264 @ 0x559b468b7380] mmco: unref short failure
  4%|▍         | 80/1945 [21:09<6:01:03, 11.62s/it]  4%|▍         | 81/1945 [21:16<5:16:44, 10.20s/it][h264 @ 0x556a794cef40] mmco: unref short failure
[h264 @ 0x559b4a634600] mmco: unref short failure
[h264 @ 0x559b4a634600] mmco: unref short failure
[h264 @ 0x562366ca9340] mmco: unref short failure
[h264 @ 0x562366ca9340] mmco: unref short failure
[h264 @ 0x559f96b239c0] mmco: unref short failure
[h264 @ 0x559f96b239c0] mmco: unref short failure
[h264 @ 0x562365ecd040] mmco: unref short failure
[h264 @ 0x562365ecd040] mmco: unref short failure
[h264 @ 0x556a94448180] mmco: unref short failure
[h264 @ 0x556a94448180] mmco: unref short failure
[h264 @ 0x559b4a280a80] mmco: unref short failure
[h264 @ 0x559b4a280a80] mmco: unref short failure
[h264 @ 0x559b4a280a80] mmco: unref short failure
not have audios 7wavFXW3AFw.7
[h264 @ 0x559b39e59680] mmco: unref short failure
[h264 @ 0x559b39e59680] mmco: unref short failure
[h264 @ 0x56237a646f80] mmco: unref short failure
[h264 @ 0x56237a646f80] mmco: unref short failure
[h264 @ 0x559f971b9600] mmco: unref short failure
[h264 @ 0x559f971b9600] mmco: unref short failure
[h264 @ 0x559f971b9600] mmco: unref short failure
[h264 @ 0x559f971b9600] mmco: unref short failure
[h264 @ 0x556a850f2380] mmco: unref short failure
[h264 @ 0x556a84f0a0c0] mmco: unref short failure
[h264 @ 0x556a84f0a0c0] mmco: unref short failure
  4%|▍         | 82/1945 [22:04<11:14:11, 21.71s/it]  4%|▍         | 83/1945 [22:12<9:02:19, 17.48s/it] [h264 @ 0x56237d69db40] mmco: unref short failure
[h264 @ 0x56237d69db40] mmco: unref short failure
[h264 @ 0x559f916f2bc0] mmco: unref short failure
[h264 @ 0x559f916f2bc0] mmco: unref short failure
[h264 @ 0x556a90673240] mmco: unref short failure
  4%|▍         | 84/1945 [22:27<8:41:04, 16.80s/it][h264 @ 0x556a8d717ac0] mmco: unref short failure
[h264 @ 0x556a827f9400] mmco: unref short failure
[h264 @ 0x559f8aeaa380] mmco: unref short failure
[h264 @ 0x559f8aeaa380] mmco: unref short failure
  4%|▍         | 85/1945 [22:37<7:34:56, 14.68s/it][h264 @ 0x556a7e5ee4c0] mmco: unref short failure
  4%|▍         | 86/1945 [22:55<8:05:35, 15.67s/it][h264 @ 0x559b371e8b00] mmco: unref short failure
  4%|▍         | 87/1945 [23:03<6:54:57, 13.40s/it][h264 @ 0x56237dad8e80] mmco: unref short failure
[h264 @ 0x56237dad8e80] mmco: unref short failure
[h264 @ 0x556a86e2a4c0] mmco: unref short failure
[h264 @ 0x556a86e2a4c0] mmco: unref short failure
[h264 @ 0x559f82faa9c0] mmco: unref short failure
[h264 @ 0x559f82faa9c0] mmco: unref short failure
[h264 @ 0x562364ec8400] mmco: unref short failure
[h264 @ 0x562364ec8400] mmco: unref short failure
  5%|▍         | 88/1945 [23:10<5:59:03, 11.60s/it][h264 @ 0x5623742ebd00] mmco: unref short failure
[h264 @ 0x5623742ebd00] mmco: unref short failure
[h264 @ 0x5623754954c0] mmco: unref short failure
[h264 @ 0x556a7fe32800] mmco: unref short failure
  5%|▍         | 89/1945 [23:18<5:25:09, 10.51s/it][h264 @ 0x562376ff8cc0] mmco: unref short failure
[h264 @ 0x562376ff8cc0] mmco: unref short failure
[h264 @ 0x559b468a5ac0] mmco: unref short failure
[h264 @ 0x559b468a5ac0] mmco: unref short failure
[h264 @ 0x559b468a5ac0] mmco: unref short failure
[h264 @ 0x559b468a5ac0] mmco: unref short failure
[h264 @ 0x559b4d9910c0] mmco: unref short failure
[h264 @ 0x56237dad87c0] mmco: unref short failure
[h264 @ 0x56237dad87c0] mmco: unref short failure
[h264 @ 0x559f7fe65cc0] mmco: unref short failure
[h264 @ 0x559f7fe65cc0] mmco: unref short failure
[h264 @ 0x556a87a575c0] mmco: unref short failure
[h264 @ 0x556a87a575c0] mmco: unref short failure
[h264 @ 0x559f7d6a95c0] mmco: unref short failure
[h264 @ 0x559f7d6a95c0] mmco: unref short failure
[h264 @ 0x559f7d63ed80] mmco: unref short failure
[h264 @ 0x559f7d63ed80] mmco: unref short failure
[h264 @ 0x562370822b40] mmco: unref short failure
[h264 @ 0x559b46cf5a40] mmco: unref short failure
[h264 @ 0x559b46cf5a40] mmco: unref short failure
[h264 @ 0x559f8b69d080] mmco: unref short failure
[h264 @ 0x559f8b69d080] mmco: unref short failure
[h264 @ 0x556a84dc5280] mmco: unref short failure
[h264 @ 0x56237d9252c0] mmco: unref short failure
[h264 @ 0x56237d9252c0] mmco: unref short failure
[h264 @ 0x56237d9252c0] mmco: unref short failure
[h264 @ 0x56237d9252c0] mmco: unref short failure
[h264 @ 0x56237d9252c0] mmco: unref short failure
[h264 @ 0x56237d9252c0] mmco: unref short failure
[h264 @ 0x559f868bce80] mmco: unref short failure
[h264 @ 0x562378c6bbc0] mmco: unref short failure
  5%|▍         | 90/1945 [24:14<12:26:13, 24.14s/it][h264 @ 0x56236b348fc0] mmco: unref short failure
[h264 @ 0x556a7d0f4880] mmco: unref short failure
[h264 @ 0x562368ccc100] mmco: unref short failure
  5%|▍         | 91/1945 [24:21<9:47:37, 19.02s/it] [h264 @ 0x559b36b5c380] mmco: unref short failure
[h264 @ 0x559b36b5c380] mmco: unref short failure
  5%|▍         | 92/1945 [24:28<7:57:50, 15.47s/it]  5%|▍         | 93/1945 [24:44<8:00:25, 15.56s/it][h264 @ 0x556a91809e40] mmco: unref short failure
[h264 @ 0x5623679e4240] mmco: unref short failure
[h264 @ 0x5623679e4240] mmco: unref short failure
[h264 @ 0x56237e77a8c0] mmco: unref short failure
[h264 @ 0x56237e77a8c0] mmco: unref short failure
[h264 @ 0x5623733fd840] mmco: unref short failure
[h264 @ 0x559f92401040] mmco: unref short failure
  5%|▍         | 94/1945 [25:04<8:36:33, 16.74s/it][h264 @ 0x559b3fbdb9c0] mmco: unref short failure
[h264 @ 0x559b3fbdb9c0] mmco: unref short failure
[h264 @ 0x559b42aa8780] mmco: unref short failure
[h264 @ 0x56237f4eac40] mmco: unref short failure
[h264 @ 0x56237f4eac40] mmco: unref short failure
[h264 @ 0x556a90331ac0] mmco: unref short failure
  5%|▍         | 95/1945 [25:11<7:11:44, 14.00s/it]  5%|▍         | 96/1945 [25:19<6:10:55, 12.04s/it][h264 @ 0x559f923e4080] mmco: unref short failure
[h264 @ 0x559f923e4080] mmco: unref short failure
[h264 @ 0x56237884e8c0] mmco: unref short failure
  5%|▍         | 97/1945 [25:26<5:29:45, 10.71s/it][h264 @ 0x559b3b809580] mmco: unref short failure
[h264 @ 0x559f92eb73c0] mmco: unref short failure
[h264 @ 0x559f92eb73c0] mmco: unref short failure
[h264 @ 0x559f95124140] mmco: unref short failure
[h264 @ 0x559f95124140] mmco: unref short failure
[h264 @ 0x559b4f6de5c0] mmco: unref short failure
[h264 @ 0x559f8feede80] mmco: unref short failure
[h264 @ 0x556a92e5d640] mmco: unref short failure
[h264 @ 0x559f8bd1cc80] mmco: unref short failure
[h264 @ 0x559f8bd1cc80] mmco: unref short failure
[h264 @ 0x556a7ada5200] mmco: unref short failure
[h264 @ 0x556a7ada5200] mmco: unref short failure
[h264 @ 0x556a91f72540] mmco: unref short failure
  5%|▌         | 98/1945 [26:25<12:50:23, 25.03s/it][h264 @ 0x556a8a0dc6c0] mmco: unref short failure
[h264 @ 0x556a8a0dc6c0] mmco: unref short failure
[h264 @ 0x559b4e3cba80] mmco: unref short failure
  5%|▌         | 99/1945 [26:31<9:59:47, 19.49s/it] 09/09/2024 17:31:54 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 17:31:54 - INFO - __main__ -   start running ret%tv validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559b4c8ffc00] mmco: unref short failure
[h264 @ 0x559b4c8ffc00] mmco: unref short failure
[h264 @ 0x559f822a56c0] mmco: unref short failure
[h264 @ 0x559f822a56c0] mmco: unref short failure
[h264 @ 0x559f822a56c0] mmco: unref short failure
[h264 @ 0x559f822a56c0] mmco: unref short failure
[h264 @ 0x559f822a56c0] mmco: unref short failure
[h264 @ 0x559b47601300] mmco: unref short failure
[h264 @ 0x559b3e6fb3c0] mmco: unref short failure
[h264 @ 0x559b3e6fb3c0] mmco: unref short failure
[h264 @ 0x562375148480] mmco: unref short failure
[h264 @ 0x562375148480] mmco: unref short failure
[h264 @ 0x56237814cb80] mmco: unref short failure
[h264 @ 0x56237814cb80] mmco: unref short failure
[h264 @ 0x56237814cb80] mmco: unref short failure
[h264 @ 0x56237814cb80] mmco: unref short failure
[h264 @ 0x556a82eee280] mmco: unref short failure
[h264 @ 0x556a82eee280] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559b4f6c9240] mmco: unref short failure
[h264 @ 0x559b4f6c9240] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559f8debd4c0] mmco: unref short failure
[h264 @ 0x559f8debd4c0] mmco: unref short failure
[h264 @ 0x559f8debd4c0] mmco: unref short failure
[h264 @ 0x559f8debd4c0] mmco: unref short failure
[h264 @ 0x559f8debd4c0] mmco: unref short failure
[h264 @ 0x559f8debd4c0] mmco: unref short failure
[h264 @ 0x559f8debd4c0] mmco: unref short failure
[h264 @ 0x559f8debd4c0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559f7eb16500] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556a7862e580] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559b4b781940] mmco: unref short failure
[h264 @ 0x559b4b781940] mmco: unref short failure
[h264 @ 0x556a95ec3540] mmco: unref short failure
[h264 @ 0x556a95ec3540] mmco: unref short failure
[h264 @ 0x5623639d2740] mmco: unref short failure
[h264 @ 0x5623639d2740] mmco: unref short failure
[h264 @ 0x556a95ec3540] mmco: unref short failure
[h264 @ 0x556a95ec3540] mmco: unref short failure
[h264 @ 0x556a95ec3540] mmco: unref short failure
[h264 @ 0x556a95ec3540] mmco: unref short failure
[h264 @ 0x559b46d829c0] mmco: unref short failure
[h264 @ 0x556a7adb6400] mmco: unref short failure
[h264 @ 0x559f982870c0] mmco: unref short failure
[h264 @ 0x559b4e532440] mmco: unref short failure
[h264 @ 0x559b4e532440] mmco: unref short failure
[h264 @ 0x56237d53e9c0] mmco: unref short failure
[h264 @ 0x56237922e600] mmco: unref short failure
[h264 @ 0x5623723c9580] mmco: unref short failure
[h264 @ 0x556a91f74e00] mmco: unref short failure
[h264 @ 0x556a91f74e00] mmco: unref short failure
[h264 @ 0x559b4f6de5c0] mmco: unref short failure
[h264 @ 0x559b4f6de5c0] mmco: unref short failure
[h264 @ 0x559b4f6de5c0] mmco: unref short failure
[h264 @ 0x559b4f6de5c0] mmco: unref short failure
[h264 @ 0x559f8d290bc0] mmco: unref short failure
[h264 @ 0x559f8d290bc0] mmco: unref short failure
[h264 @ 0x556a7ecbb1c0] mmco: unref short failure
[h264 @ 0x556a7ecbb1c0] mmco: unref short failure
[h264 @ 0x559f8d290bc0] mmco: unref short failure
[h264 @ 0x559f8d290bc0] mmco: unref short failure
[h264 @ 0x556a7ecbb1c0] mmco: unref short failure
[h264 @ 0x559f8d290bc0] mmco: unref short failure
[h264 @ 0x559f8d290bc0] mmco: unref short failure
[h264 @ 0x559b36887a00] mmco: unref short failure
[h264 @ 0x556a8ec13380] mmco: unref short failure
[h264 @ 0x556a8ec13380] mmco: unref short failure
[h264 @ 0x562376ff8a40] mmco: unref short failure
[h264 @ 0x562376ff8a40] mmco: unref short failure
[h264 @ 0x556a918d34c0] mmco: unref short failure
[h264 @ 0x559b35c30b00] mmco: unref short failure
[h264 @ 0x559b4f71b940] mmco: unref short failure
[h264 @ 0x559b4f71b940] mmco: unref short failure
[h264 @ 0x5623770a5b80] mmco: unref short failure
[h264 @ 0x56237306e140] mmco: unref short failure
[h264 @ 0x559b47548a00] mmco: unref short failure
[h264 @ 0x559b47548a00] mmco: unref short failure
[h264 @ 0x559b3b1d7f00] mmco: unref short failure
[h264 @ 0x559b3b1d7f00] mmco: unref short failure
[h264 @ 0x559b3b1d7f00] mmco: unref short failure
[h264 @ 0x559b3b1d7f00] mmco: unref short failure
[h264 @ 0x559b42e296c0] mmco: unref short failure
[h264 @ 0x5623746fa1c0] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:11,  3.07it/s][A
  1%|          | 2/221 [00:00<01:21,  2.68it/s][A
  1%|▏         | 3/221 [00:01<01:29,  2.44it/s][A
  2%|▏         | 4/221 [00:01<01:14,  2.91it/s][A
  2%|▏         | 5/221 [00:01<01:12,  2.97it/s][A
  3%|▎         | 6/221 [00:02<01:05,  3.28it/s][A
  3%|▎         | 7/221 [00:02<01:01,  3.47it/s][A
  4%|▎         | 8/221 [00:02<00:53,  3.95it/s][A[h264 @ 0x559b4b679280] mmco: unref short failure
[h264 @ 0x559b4b679280] mmco: unref short failure

  4%|▍         | 9/221 [00:02<00:50,  4.16it/s][A[h264 @ 0x559b4f0d9f80] mmco: unref short failure
[h264 @ 0x559b4f0d9f80] mmco: unref short failure

  5%|▍         | 10/221 [00:02<00:56,  3.72it/s][A
  5%|▍         | 11/221 [00:03<00:52,  3.99it/s][A
  5%|▌         | 12/221 [00:03<00:56,  3.70it/s][A
  6%|▌         | 13/221 [00:03<00:49,  4.22it/s][A
  6%|▋         | 14/221 [00:03<00:46,  4.43it/s][A
  7%|▋         | 15/221 [00:04<00:50,  4.04it/s][A
  7%|▋         | 16/221 [00:04<01:01,  3.31it/s][A
  8%|▊         | 17/221 [00:05<01:20,  2.53it/s][A
  8%|▊         | 18/221 [00:05<01:14,  2.73it/s][A
  9%|▊         | 19/221 [00:05<01:06,  3.05it/s][A
  9%|▉         | 20/221 [00:05<01:01,  3.28it/s][A
 10%|▉         | 21/221 [00:06<00:57,  3.48it/s][A
 10%|▉         | 22/221 [00:06<01:09,  2.87it/s][A
 10%|█         | 23/221 [00:06<01:02,  3.17it/s][A
 11%|█         | 24/221 [00:07<00:58,  3.39it/s][A
 11%|█▏        | 25/221 [00:07<01:09,  2.81it/s][A
 12%|█▏        | 26/221 [00:08<01:16,  2.56it/s][A
 12%|█▏        | 27/221 [00:08<01:02,  3.10it/s][A
 13%|█▎        | 28/221 [00:08<01:10,  2.75it/s][A
 13%|█▎        | 29/221 [00:09<01:03,  3.03it/s][A
 14%|█▎        | 30/221 [00:09<01:08,  2.77it/s][A
 14%|█▍        | 31/221 [00:09<01:07,  2.82it/s][A
 14%|█▍        | 32/221 [00:10<00:57,  3.30it/s][A
 15%|█▍        | 33/221 [00:10<00:57,  3.28it/s][A
 15%|█▌        | 34/221 [00:10<00:46,  4.01it/s][A
 16%|█▌        | 35/221 [00:10<00:43,  4.31it/s][A
 16%|█▋        | 36/221 [00:11<00:51,  3.60it/s][A
 17%|█▋        | 37/221 [00:11<00:57,  3.21it/s][A
 17%|█▋        | 38/221 [00:11<01:02,  2.95it/s][A
 18%|█▊        | 39/221 [00:11<00:48,  3.73it/s][A
 18%|█▊        | 40/221 [00:12<00:54,  3.32it/s][A
 19%|█▊        | 41/221 [00:12<00:47,  3.82it/s][A
 19%|█▉        | 42/221 [00:13<01:04,  2.78it/s][A
 19%|█▉        | 43/221 [00:13<00:54,  3.25it/s][A
 20%|█▉        | 44/221 [00:13<00:45,  3.91it/s][A
 20%|██        | 45/221 [00:13<00:58,  2.98it/s][A
 21%|██        | 46/221 [00:14<00:51,  3.41it/s][A
 21%|██▏       | 47/221 [00:15<01:35,  1.83it/s][A
 22%|██▏       | 48/221 [00:15<01:12,  2.37it/s][A
 22%|██▏       | 49/221 [00:15<01:02,  2.73it/s][A
 23%|██▎       | 50/221 [00:15<00:59,  2.88it/s][A
 23%|██▎       | 51/221 [00:16<00:50,  3.34it/s][A
 24%|██▎       | 52/221 [00:16<00:52,  3.24it/s][A
 24%|██▍       | 53/221 [00:16<00:42,  3.93it/s][A
 24%|██▍       | 54/221 [00:17<01:31,  1.82it/s][A
 25%|██▍       | 55/221 [00:18<01:25,  1.95it/s][A
 25%|██▌       | 56/221 [00:18<01:06,  2.49it/s][A
 26%|██▌       | 57/221 [00:18<00:57,  2.88it/s][A
 26%|██▌       | 58/221 [00:18<00:49,  3.29it/s][A
 27%|██▋       | 59/221 [00:19<00:47,  3.41it/s][A[h264 @ 0x556a94e33b40] mmco: unref short failure
[h264 @ 0x556a94e33b40] mmco: unref short failure

 27%|██▋       | 60/221 [00:19<01:09,  2.30it/s][A
 28%|██▊       | 61/221 [00:19<00:56,  2.82it/s][A
 28%|██▊       | 62/221 [00:20<01:00,  2.65it/s][A
 29%|██▊       | 63/221 [00:20<00:53,  2.96it/s][A
 29%|██▉       | 64/221 [00:21<01:01,  2.55it/s][A
 29%|██▉       | 65/221 [00:21<00:53,  2.90it/s][A
 30%|██▉       | 66/221 [00:21<00:58,  2.66it/s][A
 30%|███       | 67/221 [00:22<00:48,  3.17it/s][A
 31%|███       | 68/221 [00:22<00:40,  3.77it/s][A
 31%|███       | 69/221 [00:22<01:03,  2.38it/s][A
 32%|███▏      | 70/221 [00:23<01:02,  2.42it/s][A
 32%|███▏      | 71/221 [00:23<00:50,  2.94it/s][A
 33%|███▎      | 72/221 [00:23<00:54,  2.75it/s][A
 33%|███▎      | 73/221 [00:24<00:59,  2.50it/s][A
 33%|███▎      | 74/221 [00:24<00:52,  2.81it/s][A
 34%|███▍      | 75/221 [00:25<00:53,  2.75it/s][A
 34%|███▍      | 76/221 [00:25<00:46,  3.14it/s][A
 35%|███▍      | 77/221 [00:25<00:47,  3.04it/s][A
 35%|███▌      | 78/221 [00:25<00:37,  3.84it/s][A
 36%|███▌      | 79/221 [00:26<00:41,  3.38it/s][A
 36%|███▌      | 80/221 [00:26<00:40,  3.50it/s][A
 37%|███▋      | 81/221 [00:26<00:44,  3.14it/s][A
 37%|███▋      | 82/221 [00:27<00:48,  2.87it/s][A
 38%|███▊      | 83/221 [00:27<00:52,  2.64it/s][A[h264 @ 0x56237498c680] mmco: unref short failure
[h264 @ 0x56237498c680] mmco: unref short failure

 38%|███▊      | 84/221 [00:27<00:45,  3.00it/s][A
 39%|███▉      | 86/221 [00:28<00:31,  4.25it/s][A
 39%|███▉      | 87/221 [00:29<00:59,  2.27it/s][A
 40%|███▉      | 88/221 [00:29<01:03,  2.09it/s][A
 40%|████      | 89/221 [00:30<00:58,  2.26it/s][A
 41%|████      | 90/221 [00:30<00:51,  2.54it/s][A
 41%|████      | 91/221 [00:30<00:43,  3.01it/s][A
 42%|████▏     | 92/221 [00:30<00:38,  3.32it/s][A
 42%|████▏     | 93/221 [00:31<00:39,  3.23it/s][A
 43%|████▎     | 94/221 [00:31<00:43,  2.92it/s][A
 43%|████▎     | 95/221 [00:31<00:42,  2.94it/s][A[h264 @ 0x562379dd9f00] mmco: unref short failure
[h264 @ 0x562379dd9f00] mmco: unref short failure

 43%|████▎     | 96/221 [00:32<00:52,  2.39it/s][A
 44%|████▍     | 97/221 [00:32<00:46,  2.67it/s][A
 44%|████▍     | 98/221 [00:33<00:59,  2.07it/s][A
 45%|████▍     | 99/221 [00:33<00:49,  2.48it/s][A
 45%|████▌     | 100/221 [00:34<00:46,  2.58it/s][A
 46%|████▌     | 101/221 [00:34<00:40,  2.93it/s][A
 46%|████▌     | 102/221 [00:34<00:43,  2.71it/s][A
 47%|████▋     | 104/221 [00:34<00:29,  4.00it/s][A[h264 @ 0x559f815822c0] mmco: unref short failure
[h264 @ 0x556a90672fc0] mmco: unref short failure

 48%|████▊     | 105/221 [00:35<00:29,  3.88it/s][A
 48%|████▊     | 106/221 [00:35<00:45,  2.54it/s][A
 48%|████▊     | 107/221 [00:36<00:38,  2.93it/s][A
 49%|████▉     | 108/221 [00:36<00:37,  3.05it/s][A
 49%|████▉     | 109/221 [00:36<00:36,  3.09it/s][A
 50%|████▉     | 110/221 [00:36<00:31,  3.48it/s][A
 50%|█████     | 111/221 [00:37<00:34,  3.21it/s][A
 51%|█████     | 112/221 [00:37<00:30,  3.58it/s][A
 51%|█████     | 113/221 [00:37<00:27,  3.88it/s][A
 52%|█████▏    | 115/221 [00:37<00:20,  5.22it/s][A
 52%|█████▏    | 116/221 [00:38<00:32,  3.26it/s][A
 53%|█████▎    | 117/221 [00:39<00:33,  3.09it/s][A
 53%|█████▎    | 118/221 [00:39<00:28,  3.57it/s][A
 54%|█████▍    | 119/221 [00:39<00:31,  3.28it/s][A
 54%|█████▍    | 120/221 [00:39<00:25,  3.98it/s][A
 55%|█████▍    | 121/221 [00:39<00:20,  4.78it/s][A
 55%|█████▌    | 122/221 [00:40<00:23,  4.17it/s][A
 56%|█████▌    | 123/221 [00:40<00:24,  4.00it/s][A
 56%|█████▌    | 124/221 [00:40<00:26,  3.67it/s][A
 57%|█████▋    | 125/221 [00:41<00:32,  2.98it/s][A
 57%|█████▋    | 126/221 [00:41<00:31,  3.04it/s][A
 57%|█████▋    | 127/221 [00:42<00:53,  1.75it/s][A
 58%|█████▊    | 128/221 [00:43<00:48,  1.91it/s][A
 58%|█████▊    | 129/221 [00:43<00:38,  2.37it/s][A
 59%|█████▉    | 130/221 [00:43<00:32,  2.82it/s][A
 59%|█████▉    | 131/221 [00:43<00:26,  3.45it/s][A[h264 @ 0x559f905f1d00] mmco: unref short failure

 60%|█████▉    | 132/221 [00:44<00:48,  1.84it/s][A
 60%|██████    | 133/221 [00:45<00:41,  2.11it/s][A
 61%|██████    | 134/221 [00:45<00:48,  1.79it/s][A
 61%|██████    | 135/221 [00:46<00:50,  1.70it/s][A
 62%|██████▏   | 136/221 [00:46<00:44,  1.93it/s][A
 62%|██████▏   | 137/221 [00:47<00:38,  2.20it/s][A
 62%|██████▏   | 138/221 [00:47<00:38,  2.18it/s][A
 63%|██████▎   | 139/221 [00:48<00:44,  1.83it/s][A[h264 @ 0x556a7daaf8c0] mmco: unref short failure

 63%|██████▎   | 140/221 [00:48<00:38,  2.10it/s][A
 64%|██████▍   | 141/221 [00:48<00:35,  2.24it/s][A
 64%|██████▍   | 142/221 [00:49<00:31,  2.48it/s][A
 65%|██████▍   | 143/221 [00:49<00:29,  2.61it/s][A[h264 @ 0x556a9044c600] mmco: unref short failure

 65%|██████▌   | 144/221 [00:49<00:25,  2.97it/s][A
 66%|██████▌   | 145/221 [00:49<00:20,  3.68it/s][A
 67%|██████▋   | 147/221 [00:50<00:16,  4.39it/s][A[h264 @ 0x559b4b6f8040] mmco: unref short failure
[h264 @ 0x559b4b6f8040] mmco: unref short failure
[h264 @ 0x559b4b6f8040] mmco: unref short failure
[h264 @ 0x559b4b6f8040] mmco: unref short failure

 67%|██████▋   | 148/221 [00:50<00:20,  3.61it/s][A
 67%|██████▋   | 149/221 [00:51<00:23,  3.11it/s][A
 68%|██████▊   | 150/221 [00:51<00:20,  3.49it/s][A
 68%|██████▊   | 151/221 [00:51<00:21,  3.30it/s][A[h264 @ 0x559b3d92f3c0] mmco: unref short failure

 69%|██████▉   | 152/221 [00:52<00:30,  2.23it/s][A
 69%|██████▉   | 153/221 [00:52<00:23,  2.85it/s][A
 70%|██████▉   | 154/221 [00:52<00:20,  3.26it/s][A
 70%|███████   | 155/221 [00:53<00:18,  3.55it/s][A
 71%|███████   | 156/221 [00:53<00:19,  3.42it/s][A
 71%|███████   | 157/221 [00:53<00:23,  2.69it/s][A
 71%|███████▏  | 158/221 [00:54<00:22,  2.81it/s][A[h264 @ 0x559b4e737a00] mmco: unref short failure
[h264 @ 0x559b4e737a00] mmco: unref short failure

 72%|███████▏  | 159/221 [00:54<00:18,  3.43it/s][A
 72%|███████▏  | 160/221 [00:54<00:14,  4.11it/s][A
 73%|███████▎  | 161/221 [00:54<00:12,  4.79it/s][A
 73%|███████▎  | 162/221 [00:54<00:10,  5.57it/s][A
 74%|███████▍  | 163/221 [00:55<00:12,  4.71it/s][A
 74%|███████▍  | 164/221 [00:55<00:11,  4.76it/s][A
 75%|███████▍  | 165/221 [00:55<00:11,  5.03it/s][A
 75%|███████▌  | 166/221 [00:56<00:22,  2.50it/s][A[h264 @ 0x56236e485140] mmco: unref short failure

 76%|███████▌  | 168/221 [00:57<00:22,  2.35it/s][A
 77%|███████▋  | 170/221 [00:57<00:16,  3.16it/s][A
 77%|███████▋  | 171/221 [00:57<00:17,  2.92it/s][A
 78%|███████▊  | 172/221 [00:58<00:15,  3.21it/s][A
 78%|███████▊  | 173/221 [00:58<00:16,  2.96it/s][A
 79%|███████▊  | 174/221 [00:58<00:13,  3.56it/s][A
 79%|███████▉  | 175/221 [00:58<00:12,  3.68it/s][A
 80%|███████▉  | 176/221 [00:59<00:10,  4.44it/s][A
 80%|████████  | 177/221 [00:59<00:09,  4.82it/s][A[h264 @ 0x556a84d86940] mmco: unref short failure

 81%|████████  | 178/221 [01:00<00:17,  2.48it/s][A
 81%|████████  | 179/221 [01:00<00:16,  2.53it/s][A
 81%|████████▏ | 180/221 [01:00<00:12,  3.21it/s][A
 82%|████████▏ | 182/221 [01:00<00:09,  4.26it/s][A
 83%|████████▎ | 183/221 [01:01<00:09,  3.95it/s][A
 83%|████████▎ | 184/221 [01:01<00:10,  3.65it/s][A
 84%|████████▍ | 186/221 [01:02<00:10,  3.46it/s][A
 85%|████████▍ | 187/221 [01:02<00:09,  3.69it/s][A
 85%|████████▌ | 188/221 [01:02<00:08,  3.92it/s][A
 86%|████████▌ | 189/221 [01:02<00:08,  3.76it/s][A
 86%|████████▌ | 190/221 [01:03<00:08,  3.50it/s][A
 86%|████████▋ | 191/221 [01:03<00:07,  4.18it/s][A
 87%|████████▋ | 192/221 [01:03<00:06,  4.50it/s][A
 88%|████████▊ | 194/221 [01:05<00:14,  1.92it/s][A
 88%|████████▊ | 195/221 [01:05<00:11,  2.29it/s][A
 89%|████████▊ | 196/221 [01:05<00:09,  2.75it/s][A
 89%|████████▉ | 197/221 [01:05<00:08,  3.00it/s][A
 90%|████████▉ | 198/221 [01:06<00:06,  3.37it/s][A
 90%|█████████ | 199/221 [01:06<00:06,  3.50it/s][A
 90%|█████████ | 200/221 [01:06<00:05,  4.06it/s][A
 91%|█████████ | 201/221 [01:06<00:04,  4.55it/s][A
 91%|█████████▏| 202/221 [01:06<00:04,  4.32it/s][A
 92%|█████████▏| 203/221 [01:07<00:04,  4.31it/s][A
 92%|█████████▏| 204/221 [01:07<00:03,  4.78it/s][A
 93%|█████████▎| 205/221 [01:07<00:03,  5.18it/s][A
 93%|█████████▎| 206/221 [01:07<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [01:08<00:03,  4.27it/s][A
 95%|█████████▍| 209/221 [01:08<00:02,  4.41it/s][A
 95%|█████████▌| 211/221 [01:08<00:02,  4.67it/s][A
 96%|█████████▌| 212/221 [01:09<00:01,  4.59it/s][A
 96%|█████████▋| 213/221 [01:09<00:01,  4.94it/s][A
 97%|█████████▋| 214/221 [01:09<00:01,  3.60it/s][A
 97%|█████████▋| 215/221 [01:09<00:01,  4.31it/s][A
 98%|█████████▊| 216/221 [01:10<00:01,  4.06it/s][A
 98%|█████████▊| 217/221 [01:10<00:01,  3.43it/s][A
 99%|█████████▊| 218/221 [01:10<00:00,  3.78it/s][A
 99%|█████████▉| 219/221 [01:11<00:00,  3.53it/s][A
100%|█████████▉| 220/221 [01:11<00:00,  2.49it/s][A100%|██████████| 221/221 [01:11<00:00,  3.08it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:57,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:51,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:22<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:37<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:51<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:22,  9.83it/s][A
  1%|          | 2/221 [00:00<01:01,  3.56it/s][A
  1%|▏         | 3/221 [00:00<01:03,  3.41it/s][A
  2%|▏         | 4/221 [00:00<00:51,  4.19it/s][A
  2%|▏         | 5/221 [00:01<00:46,  4.66it/s][A
  3%|▎         | 7/221 [00:01<00:40,  5.33it/s][A
  4%|▎         | 8/221 [00:01<00:36,  5.80it/s][A
  4%|▍         | 9/221 [00:01<00:36,  5.78it/s][A
  5%|▍         | 10/221 [00:02<00:53,  3.91it/s][A
  5%|▍         | 11/221 [00:02<00:47,  4.40it/s][A
  5%|▌         | 12/221 [00:02<00:43,  4.85it/s][A
  6%|▌         | 13/221 [00:02<00:48,  4.32it/s][A
  6%|▋         | 14/221 [00:02<00:43,  4.79it/s][A
  7%|▋         | 15/221 [00:03<00:44,  4.67it/s][A
  7%|▋         | 16/221 [00:03<00:51,  3.98it/s][A
  8%|▊         | 17/221 [00:04<01:18,  2.61it/s][A
  8%|▊         | 18/221 [00:04<01:03,  3.19it/s][A
  9%|▊         | 19/221 [00:04<00:53,  3.75it/s][A
  9%|▉         | 20/221 [00:04<00:46,  4.32it/s][A
 10%|▉         | 21/221 [00:04<00:39,  5.07it/s][A
 10%|▉         | 22/221 [00:05<00:42,  4.71it/s][A
 11%|█         | 24/221 [00:05<00:35,  5.56it/s][A
 11%|█▏        | 25/221 [00:05<00:34,  5.76it/s][A
 12%|█▏        | 26/221 [00:05<00:37,  5.15it/s][A
 13%|█▎        | 28/221 [00:06<00:39,  4.83it/s][A
 13%|█▎        | 29/221 [00:06<00:35,  5.37it/s][A
 14%|█▎        | 30/221 [00:06<00:49,  3.86it/s][A
 14%|█▍        | 31/221 [00:07<00:45,  4.15it/s][A
 15%|█▍        | 33/221 [00:07<00:36,  5.15it/s][A
 16%|█▌        | 35/221 [00:07<00:32,  5.74it/s][A
 16%|█▋        | 36/221 [00:07<00:42,  4.37it/s][A
 17%|█▋        | 37/221 [00:08<00:39,  4.69it/s][A
 17%|█▋        | 38/221 [00:08<00:43,  4.22it/s][A
 18%|█▊        | 40/221 [00:08<00:39,  4.59it/s][A
 19%|█▊        | 41/221 [00:08<00:36,  4.90it/s][A
 19%|█▉        | 42/221 [00:09<00:38,  4.70it/s][A
 19%|█▉        | 43/221 [00:09<00:38,  4.66it/s][A
 20%|█▉        | 44/221 [00:09<00:37,  4.73it/s][A
 20%|██        | 45/221 [00:10<00:45,  3.87it/s][A
 21%|██        | 46/221 [00:10<00:38,  4.51it/s][A
 21%|██▏       | 47/221 [00:10<00:36,  4.73it/s][A
 22%|██▏       | 49/221 [00:10<00:31,  5.44it/s][A
 23%|██▎       | 50/221 [00:10<00:35,  4.80it/s][A
 23%|██▎       | 51/221 [00:11<00:33,  5.06it/s][A
 24%|██▎       | 52/221 [00:11<00:32,  5.12it/s][A
 24%|██▍       | 53/221 [00:11<00:31,  5.34it/s][A
 24%|██▍       | 54/221 [00:12<00:49,  3.36it/s][A
 25%|██▍       | 55/221 [00:12<00:49,  3.35it/s][A
 26%|██▌       | 57/221 [00:12<00:36,  4.47it/s][A
 26%|██▌       | 58/221 [00:12<00:38,  4.28it/s][A
 27%|██▋       | 59/221 [00:13<00:34,  4.65it/s][A
 27%|██▋       | 60/221 [00:13<00:44,  3.64it/s][A
 28%|██▊       | 61/221 [00:13<00:38,  4.13it/s][A
 28%|██▊       | 62/221 [00:13<00:42,  3.75it/s][A
 29%|██▊       | 63/221 [00:14<00:48,  3.23it/s][A
 29%|██▉       | 64/221 [00:15<01:03,  2.45it/s][A
 29%|██▉       | 65/221 [00:15<00:55,  2.81it/s][A
 30%|██▉       | 66/221 [00:15<00:56,  2.76it/s][A
 30%|███       | 67/221 [00:15<00:47,  3.25it/s][A
 31%|███       | 68/221 [00:15<00:38,  3.98it/s][A
 31%|███       | 69/221 [00:16<01:01,  2.48it/s][A
 32%|███▏      | 70/221 [00:16<00:52,  2.87it/s][A
 32%|███▏      | 71/221 [00:17<00:45,  3.29it/s][A
 33%|███▎      | 72/221 [00:17<00:55,  2.67it/s][A
 33%|███▎      | 73/221 [00:18<00:58,  2.53it/s][A
 34%|███▍      | 75/221 [00:18<00:42,  3.47it/s][A
 34%|███▍      | 76/221 [00:18<00:38,  3.81it/s][A
 35%|███▍      | 77/221 [00:19<00:45,  3.14it/s][A
 36%|███▌      | 79/221 [00:19<00:39,  3.59it/s][A
 36%|███▌      | 80/221 [00:19<00:37,  3.81it/s][A
 37%|███▋      | 81/221 [00:20<00:37,  3.72it/s][A
 37%|███▋      | 82/221 [00:20<00:39,  3.52it/s][A
 38%|███▊      | 83/221 [00:20<00:49,  2.78it/s][A
 38%|███▊      | 84/221 [00:21<00:44,  3.10it/s][A
 39%|███▉      | 86/221 [00:21<00:28,  4.67it/s][A
 39%|███▉      | 87/221 [00:22<00:52,  2.57it/s][A
 40%|███▉      | 88/221 [00:22<00:52,  2.53it/s][A
 40%|████      | 89/221 [00:22<00:46,  2.85it/s][A
 41%|████      | 90/221 [00:23<00:41,  3.16it/s][A
 41%|████      | 91/221 [00:23<00:36,  3.57it/s][A
 42%|████▏     | 92/221 [00:23<00:31,  4.04it/s][A
 42%|████▏     | 93/221 [00:23<00:33,  3.77it/s][A
 43%|████▎     | 94/221 [00:24<00:34,  3.63it/s][A
 43%|████▎     | 95/221 [00:24<00:36,  3.48it/s][A
 43%|████▎     | 96/221 [00:25<00:52,  2.40it/s][A
 44%|████▍     | 97/221 [00:25<00:44,  2.76it/s][A
 44%|████▍     | 98/221 [00:26<01:01,  2.01it/s][A
 45%|████▍     | 99/221 [00:26<00:49,  2.45it/s][A
 45%|████▌     | 100/221 [00:26<00:43,  2.81it/s][A
 46%|████▌     | 101/221 [00:26<00:37,  3.18it/s][A
 46%|████▌     | 102/221 [00:27<00:52,  2.25it/s][A
 47%|████▋     | 104/221 [00:27<00:33,  3.46it/s][A
 48%|████▊     | 105/221 [00:28<00:32,  3.57it/s][A
 48%|████▊     | 106/221 [00:28<00:39,  2.94it/s][A
 48%|████▊     | 107/221 [00:28<00:33,  3.42it/s][A
 49%|████▉     | 108/221 [00:28<00:32,  3.44it/s][A
 49%|████▉     | 109/221 [00:29<00:28,  3.88it/s][A
 50%|████▉     | 110/221 [00:29<00:28,  3.93it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.73it/s][A
 51%|█████     | 112/221 [00:29<00:29,  3.75it/s][A
 51%|█████     | 113/221 [00:30<00:27,  3.91it/s][A
 52%|█████▏    | 115/221 [00:30<00:20,  5.21it/s][A
 52%|█████▏    | 116/221 [00:30<00:21,  4.97it/s][A
 53%|█████▎    | 117/221 [00:31<00:25,  4.12it/s][A
 53%|█████▎    | 118/221 [00:31<00:24,  4.20it/s][A
 54%|█████▍    | 119/221 [00:31<00:28,  3.55it/s][A
 54%|█████▍    | 120/221 [00:31<00:24,  4.20it/s][A
 55%|█████▍    | 121/221 [00:31<00:19,  5.03it/s][A
 55%|█████▌    | 122/221 [00:32<00:22,  4.36it/s][A
 56%|█████▌    | 123/221 [00:32<00:20,  4.69it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.81it/s][A
 57%|█████▋    | 125/221 [00:33<00:27,  3.50it/s][A
 57%|█████▋    | 127/221 [00:33<00:26,  3.49it/s][A
 58%|█████▊    | 128/221 [00:33<00:26,  3.52it/s][A
 59%|█████▉    | 130/221 [00:34<00:19,  4.57it/s][A
 59%|█████▉    | 131/221 [00:34<00:17,  5.20it/s][A
 60%|█████▉    | 132/221 [00:36<00:50,  1.75it/s][A
 60%|██████    | 133/221 [00:36<00:43,  2.04it/s][A
 61%|██████    | 134/221 [00:36<00:48,  1.79it/s][A
 61%|██████    | 135/221 [00:37<00:57,  1.50it/s][A
 62%|██████▏   | 136/221 [00:38<00:47,  1.80it/s][A
 62%|██████▏   | 137/221 [00:38<00:40,  2.09it/s][A
 62%|██████▏   | 138/221 [00:38<00:36,  2.25it/s][A
 63%|██████▎   | 139/221 [00:39<00:37,  2.20it/s][A
 63%|██████▎   | 140/221 [00:39<00:34,  2.34it/s][A
 64%|██████▍   | 141/221 [00:40<00:31,  2.54it/s][A
 64%|██████▍   | 142/221 [00:40<00:28,  2.82it/s][A
 65%|██████▍   | 143/221 [00:40<00:29,  2.67it/s][A
 65%|██████▌   | 144/221 [00:41<00:29,  2.64it/s][A
 66%|██████▌   | 146/221 [00:41<00:17,  4.19it/s][A
 67%|██████▋   | 147/221 [00:41<00:19,  3.80it/s][A
 67%|██████▋   | 148/221 [00:41<00:20,  3.64it/s][A
 67%|██████▋   | 149/221 [00:42<00:25,  2.84it/s][A
 68%|██████▊   | 150/221 [00:42<00:22,  3.12it/s][A
 68%|██████▊   | 151/221 [00:43<00:23,  2.96it/s][A
 69%|██████▉   | 152/221 [00:43<00:24,  2.78it/s][A
 69%|██████▉   | 153/221 [00:43<00:19,  3.48it/s][A
 70%|██████▉   | 154/221 [00:43<00:16,  3.98it/s][A
 70%|███████   | 155/221 [00:44<00:18,  3.61it/s][A
 71%|███████   | 156/221 [00:44<00:17,  3.70it/s][A
 71%|███████   | 157/221 [00:44<00:18,  3.52it/s][A
 71%|███████▏  | 158/221 [00:44<00:18,  3.45it/s][A
 72%|███████▏  | 159/221 [00:45<00:14,  4.19it/s][A
 72%|███████▏  | 160/221 [00:45<00:12,  4.73it/s][A
 73%|███████▎  | 161/221 [00:45<00:12,  4.63it/s][A
 74%|███████▍  | 163/221 [00:45<00:11,  5.09it/s][A
 74%|███████▍  | 164/221 [00:45<00:10,  5.35it/s][A
 75%|███████▍  | 165/221 [00:46<00:12,  4.64it/s][A
 75%|███████▌  | 166/221 [00:46<00:12,  4.58it/s][A
 76%|███████▌  | 167/221 [00:46<00:10,  5.26it/s][A
 76%|███████▌  | 168/221 [00:46<00:09,  5.45it/s][A
 76%|███████▋  | 169/221 [00:46<00:08,  6.17it/s][A
 77%|███████▋  | 170/221 [00:47<00:08,  5.88it/s][A
 77%|███████▋  | 171/221 [00:47<00:12,  3.99it/s][A
 78%|███████▊  | 172/221 [00:47<00:11,  4.19it/s][A
 78%|███████▊  | 173/221 [00:48<00:14,  3.27it/s][A
 79%|███████▊  | 174/221 [00:48<00:14,  3.17it/s][A
 79%|███████▉  | 175/221 [00:48<00:13,  3.33it/s][A
 80%|███████▉  | 176/221 [00:48<00:10,  4.13it/s][A
 80%|████████  | 177/221 [00:49<00:09,  4.53it/s][A
 81%|████████  | 178/221 [00:49<00:14,  2.97it/s][A
 81%|████████  | 179/221 [00:50<00:14,  2.97it/s][A
 81%|████████▏ | 180/221 [00:50<00:11,  3.46it/s][A
 82%|████████▏ | 181/221 [00:50<00:09,  4.24it/s][A
 82%|████████▏ | 182/221 [00:50<00:09,  3.99it/s][A
 83%|████████▎ | 183/221 [00:50<00:10,  3.47it/s][A
 83%|████████▎ | 184/221 [00:51<00:10,  3.40it/s][A
 84%|████████▎ | 185/221 [00:51<00:08,  4.21it/s][A
 84%|████████▍ | 186/221 [00:52<00:13,  2.67it/s][A
 85%|████████▍ | 187/221 [00:52<00:11,  2.96it/s][A
 85%|████████▌ | 188/221 [00:52<00:10,  3.09it/s][A
 86%|████████▌ | 189/221 [00:52<00:10,  3.18it/s][A
 86%|████████▌ | 190/221 [00:53<00:09,  3.26it/s][A
 86%|████████▋ | 191/221 [00:53<00:07,  3.97it/s][A
 87%|████████▋ | 192/221 [00:53<00:07,  4.13it/s][A
 88%|████████▊ | 194/221 [00:54<00:07,  3.69it/s][A
 88%|████████▊ | 195/221 [00:54<00:06,  3.76it/s][A
 89%|████████▊ | 196/221 [00:54<00:06,  3.76it/s][A
 89%|████████▉ | 197/221 [00:55<00:07,  3.38it/s][A
 90%|████████▉ | 198/221 [00:55<00:07,  3.25it/s][A
 90%|█████████ | 199/221 [00:55<00:06,  3.34it/s][A
 90%|█████████ | 200/221 [00:55<00:05,  3.80it/s][A
 91%|█████████ | 201/221 [00:55<00:04,  4.43it/s][A
 91%|█████████▏| 202/221 [00:56<00:04,  3.82it/s][A
 92%|█████████▏| 203/221 [00:56<00:04,  3.96it/s][A
 92%|█████████▏| 204/221 [00:56<00:04,  3.96it/s][A
 93%|█████████▎| 206/221 [00:57<00:03,  4.08it/s][A
 94%|█████████▍| 208/221 [00:57<00:02,  4.47it/s][A
 95%|█████████▍| 209/221 [00:57<00:02,  4.21it/s][A
 95%|█████████▌| 211/221 [00:58<00:02,  4.48it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  4.33it/s][A
 96%|█████████▋| 213/221 [00:58<00:01,  4.64it/s][A
 97%|█████████▋| 214/221 [00:59<00:02,  3.16it/s][A
 97%|█████████▋| 215/221 [00:59<00:01,  3.77it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.43it/s][A
 98%|█████████▊| 217/221 [01:00<00:01,  3.05it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.15it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.37it/s][A
100%|█████████▉| 220/221 [01:01<00:00,  3.89it/s][A
100%|██████████| 221/221 [01:01<00:00,  4.55it/s][A100%|██████████| 221/221 [01:01<00:00,  3.62it/s]
09/09/2024 17:37:32 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 99--===========

09/09/2024 17:37:32 - INFO - __main__ -   {'area_r1': 42.1, 'area_recall': '42.1/69.9/80.2', 'area_ravg': 64.1}
09/09/2024 17:37:32 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 99--===========

09/09/2024 17:37:32 - INFO - __main__ -   {'forward_r1': 37.0, 'forward_recall': '37.0/64.4/75.8', 'forward_ravg': 59.0}
09/09/2024 17:37:32 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 99--===========

09/09/2024 17:37:32 - INFO - __main__ -   {'area_video_r1': 36.8, 'area_video_recall': '36.8/65.2/76.0', 'area_video_ravg': 59.3}
09/09/2024 17:37:32 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 49=======

09/09/2024 17:37:32 - INFO - __main__ -   {'area_video_r1': 37.1, 'area_video_recall': '37.1/68.2/77.8', 'area_video_ravg': 61.0}
09/09/2024 17:37:32 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 99--===========

09/09/2024 17:37:32 - INFO - __main__ -   {'area_video_r1': 50.6, 'area_video_recall': '50.6/75.9/82.5', 'area_video_ravg': 69.6, 'area_video_back_r1': 50.2, 'area_video_back_recall': '50.2/73.0/80.9', 'area_video_back_ravg': 68.0}
09/09/2024 17:37:32 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 99=======

09/09/2024 17:37:32 - INFO - __main__ -   {'area_video_r1': 50.6, 'area_video_recall': '50.6/75.9/82.5', 'area_video_ravg': 69.6, 'area_video_back_r1': 50.2, 'area_video_back_recall': '50.2/73.0/80.9', 'area_video_back_ravg': 68.0}
09/09/2024 17:37:32 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 99--===========

09/09/2024 17:37:32 - INFO - __main__ -   {'video_r1': 41.4, 'video_recall': '41.4/70.8/80.9', 'video_ravg': 64.4}
09/09/2024 17:37:32 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 17:37:32 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 17:37:32 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 99--===========

09/09/2024 17:37:32 - INFO - __main__ -   {'video_r1': 50.1, 'video_recall': '50.1/75.5/82.0', 'video_ravg': 69.2}
09/09/2024 17:37:32 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 99=======

09/09/2024 17:37:32 - INFO - __main__ -   {'video_r1': 50.1, 'video_recall': '50.1/75.5/82.0', 'video_ravg': 69.2}
09/09/2024 17:38:04 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.01347567792981863, 'loss_ret%tv%ta--finetune_area/loss_area': 2.545590877532959, 'loss_ret%tv%ta--finetune_area/total_loss': 2.5590665340423584}
[h264 @ 0x559f96901600] mmco: unref short failure
[h264 @ 0x559f96901600] mmco: unref short failure
  5%|▌         | 100/1945 [32:44<64:20:34, 125.55s/it][h264 @ 0x562367169240] mmco: unref short failure
[h264 @ 0x562367169240] mmco: unref short failure
[h264 @ 0x559b378771c0] mmco: unref short failure
  5%|▌         | 101/1945 [32:49<45:41:26, 89.20s/it]   5%|▌         | 102/1945 [32:53<32:39:28, 63.79s/it][h264 @ 0x559f89db3140] mmco: unref short failure
[h264 @ 0x559b38d75a00] mmco: unref short failure
[h264 @ 0x559b38d75a00] mmco: unref short failure
[h264 @ 0x562376a2bcc0] mmco: unref short failure
[h264 @ 0x562376a2bcc0] mmco: unref short failure
[h264 @ 0x562376a2bcc0] mmco: unref short failure
[h264 @ 0x562376a2bcc0] mmco: unref short failure
[h264 @ 0x562376a2bcc0] mmco: unref short failure
[h264 @ 0x562376a2bcc0] mmco: unref short failure
[h264 @ 0x562376a2bcc0] mmco: unref short failure
[h264 @ 0x562376a2bcc0] mmco: unref short failure
  5%|▌         | 103/1945 [32:58<23:38:24, 46.20s/it][h264 @ 0x559b4b583980] mmco: unref short failure
[h264 @ 0x559b4b583980] mmco: unref short failure
[h264 @ 0x559b4b583980] mmco: unref short failure
[h264 @ 0x559b4b583980] mmco: unref short failure
[h264 @ 0x559b3da5ac40] mmco: unref short failure
[h264 @ 0x559b3da5ac40] mmco: unref short failure
[h264 @ 0x559b3da5ac40] mmco: unref short failure
  5%|▌         | 104/1945 [33:04<17:27:22, 34.13s/it][h264 @ 0x562380ec6a40] mmco: unref short failure
  5%|▌         | 105/1945 [33:10<13:01:48, 25.49s/it][h264 @ 0x559f932a0280] mmco: unref short failure
[h264 @ 0x559f8d9aafc0] mmco: unref short failure
[h264 @ 0x559f8d9aafc0] mmco: unref short failure
[h264 @ 0x559b3da5ac40] mmco: unref short failure
[h264 @ 0x559b3da5ac40] mmco: unref short failure
  5%|▌         | 106/1945 [33:16<10:05:02, 19.74s/it][h264 @ 0x56237b4f6640] mmco: unref short failure
[h264 @ 0x56237b4f6640] mmco: unref short failure
[h264 @ 0x556a88b81cc0] mmco: unref short failure
[h264 @ 0x556a88b81cc0] mmco: unref short failure
  6%|▌         | 107/1945 [33:24<8:11:44, 16.05s/it]   6%|▌         | 108/1945 [33:31<6:50:39, 13.41s/it][h264 @ 0x559b35068440] mmco: unref short failure
  6%|▌         | 109/1945 [33:39<6:02:48, 11.86s/it][h264 @ 0x56237c7f5e00] mmco: unref short failure
[h264 @ 0x56237c7f5e00] mmco: unref short failure
[h264 @ 0x56237c7f5e00] mmco: unref short failure
[h264 @ 0x56237c7f5e00] mmco: unref short failure
  6%|▌         | 110/1945 [33:46<5:18:47, 10.42s/it][h264 @ 0x559b39ff0580] mmco: unref short failure
[h264 @ 0x559b39ff0580] mmco: unref short failure
  6%|▌         | 111/1945 [33:53<4:46:18,  9.37s/it]  6%|▌         | 112/1945 [34:00<4:21:54,  8.57s/it]  6%|▌         | 113/1945 [34:09<4:26:35,  8.73s/it][h264 @ 0x559f9ab0f1c0] mmco: unref short failure
[h264 @ 0x559f9ab0f1c0] mmco: unref short failure
  6%|▌         | 114/1945 [34:16<4:09:03,  8.16s/it][h264 @ 0x556a83528180] mmco: unref short failure
[h264 @ 0x556a83528180] mmco: unref short failure
[h264 @ 0x562379f48a00] mmco: unref short failure
[h264 @ 0x562379f48a00] mmco: unref short failure
[h264 @ 0x562379f48a00] mmco: unref short failure
  6%|▌         | 115/1945 [34:23<4:00:31,  7.89s/it][h264 @ 0x56237c78ea00] mmco: unref short failure
[h264 @ 0x56236cc1ca00] mmco: unref short failure
[h264 @ 0x56236cc1ca00] mmco: unref short failure
[h264 @ 0x559f9922e540] mmco: unref short failure
[h264 @ 0x562378591000] mmco: unref short failure
[h264 @ 0x559b5387e3c0] mmco: unref short failure
[h264 @ 0x559b5387e3c0] mmco: unref short failure
  6%|▌         | 116/1945 [34:30<3:52:20,  7.62s/it][h264 @ 0x559f90409200] mmco: unref short failure
[h264 @ 0x559f90409200] mmco: unref short failure
[h264 @ 0x559b4cc38780] mmco: unref short failure
[h264 @ 0x559b4cc38780] mmco: unref short failure
[h264 @ 0x559f8e5d8080] mmco: unref short failure
[h264 @ 0x559b3e3fb5c0] mmco: unref short failure
[h264 @ 0x559b3e3fb5c0] mmco: unref short failure
  6%|▌         | 117/1945 [34:37<3:52:15,  7.62s/it][h264 @ 0x559b3976f2c0] mmco: unref short failure
[h264 @ 0x559b3976f2c0] mmco: unref short failure
[h264 @ 0x559b4f1beec0] mmco: unref short failure
[h264 @ 0x559b4f1beec0] mmco: unref short failure
[h264 @ 0x559b4f1beec0] mmco: unref short failure
[h264 @ 0x559f96563ec0] mmco: unref short failure
[h264 @ 0x559f96563ec0] mmco: unref short failure
[h264 @ 0x556a99e6b880] mmco: unref short failure
[h264 @ 0x556a99e6b880] mmco: unref short failure
  6%|▌         | 118/1945 [34:53<5:05:04, 10.02s/it][h264 @ 0x56236c8ff580] mmco: unref short failure
  6%|▌         | 119/1945 [35:01<4:43:00,  9.30s/it][h264 @ 0x559f95ae0e40] mmco: unref short failure
[h264 @ 0x559b3dd16500] mmco: unref short failure
  6%|▌         | 120/1945 [35:09<4:32:32,  8.96s/it][h264 @ 0x559b4f3ab3c0] mmco: unref short failure
[h264 @ 0x559b4f3ab3c0] mmco: unref short failure
  6%|▌         | 121/1945 [35:19<4:38:22,  9.16s/it][h264 @ 0x556a8b490c00] mmco: unref short failure
[h264 @ 0x559b3dae9f40] mmco: unref short failure
[h264 @ 0x556a83727a40] mmco: unref short failure
[h264 @ 0x556a8217f340] mmco: unref short failure
[h264 @ 0x556a8217f340] mmco: unref short failure
[h264 @ 0x559f874e0880] mmco: unref short failure
[h264 @ 0x559f874e0880] mmco: unref short failure
  6%|▋         | 122/1945 [35:28<4:43:36,  9.33s/it][h264 @ 0x556a987f8780] mmco: unref short failure
[h264 @ 0x556a987f8780] mmco: unref short failure
[h264 @ 0x559b34bab400] mmco: unref short failure
  6%|▋         | 123/1945 [35:35<4:24:19,  8.70s/it][h264 @ 0x559f9656a380] mmco: unref short failure
[h264 @ 0x559f985a64c0] mmco: unref short failure
[h264 @ 0x559f95276000] mmco: unref short failure
[h264 @ 0x559f95276000] mmco: unref short failure
[h264 @ 0x556a85b013c0] mmco: unref short failure
[h264 @ 0x556a8db6dcc0] mmco: unref short failure
[h264 @ 0x556a8db6dcc0] mmco: unref short failure
[h264 @ 0x559f7c89f4c0] mmco: unref short failure
[h264 @ 0x559f7c89f4c0] mmco: unref short failure
[h264 @ 0x556a89ce7940] mmco: unref short failure
[h264 @ 0x559f83feaac0] mmco: unref short failure
[h264 @ 0x559f83feaac0] mmco: unref short failure
[h264 @ 0x562381108d40] mmco: unref short failure
[h264 @ 0x562381108d40] mmco: unref short failure
[h264 @ 0x556a8283a200] mmco: unref short failure
  6%|▋         | 124/1945 [36:14<8:57:37, 17.71s/it][h264 @ 0x56237232d100] mmco: unref short failure
[h264 @ 0x56237232d100] mmco: unref short failure
[h264 @ 0x556a94704680] mmco: unref short failure
[h264 @ 0x556a94704680] mmco: unref short failure
[h264 @ 0x559b3dad76c0] mmco: unref short failure
[h264 @ 0x559b3dad76c0] mmco: unref short failure
[h264 @ 0x556a8ba557c0] mmco: unref short failure
[h264 @ 0x556a8ba557c0] mmco: unref short failure
  6%|▋         | 125/1945 [36:31<8:52:06, 17.54s/it][h264 @ 0x559f84062880] mmco: unref short failure
[h264 @ 0x559f84062880] mmco: unref short failure
[h264 @ 0x559b3dfc9440] mmco: unref short failure
[h264 @ 0x556a90f89740] mmco: unref short failure
[h264 @ 0x559f89165500] mmco: unref short failure
  6%|▋         | 126/1945 [36:57<10:02:32, 19.88s/it][h264 @ 0x562373eec240] mmco: unref short failure
  7%|▋         | 127/1945 [37:04<8:06:00, 16.04s/it] [h264 @ 0x56237973c800] mmco: unref short failure
[h264 @ 0x56237973c800] mmco: unref short failure
[h264 @ 0x56237973c800] mmco: unref short failure
[h264 @ 0x56237973c800] mmco: unref short failure
[h264 @ 0x559b49d73680] mmco: unref short failure
[h264 @ 0x559b3ee50280] mmco: unref short failure
[h264 @ 0x562373ba5980] mmco: unref short failure
  7%|▋         | 128/1945 [37:20<8:03:55, 15.98s/it]  7%|▋         | 129/1945 [37:26<6:40:18, 13.23s/it][h264 @ 0x559f93940e80] mmco: unref short failure
[h264 @ 0x559b53bf6540] mmco: unref short failure
[h264 @ 0x559b53bf6540] mmco: unref short failure
  7%|▋         | 130/1945 [37:33<5:38:32, 11.19s/it]  7%|▋         | 131/1945 [37:40<5:01:22,  9.97s/it][h264 @ 0x559b373bea40] mmco: unref short failure
[h264 @ 0x559b373bea40] mmco: unref short failure
[h264 @ 0x559b49242540] mmco: unref short failure
[h264 @ 0x559b49242540] mmco: unref short failure
[h264 @ 0x559b4f4e1800] mmco: unref short failure
[h264 @ 0x562381841000] mmco: unref short failure
[h264 @ 0x562381841000] mmco: unref short failure
[h264 @ 0x556a80417c40] mmco: unref short failure
[h264 @ 0x556a80417c40] mmco: unref short failure
[h264 @ 0x556a80417c40] mmco: unref short failure
[h264 @ 0x559b474a5c80] mmco: unref short failure
[h264 @ 0x559b35c82840] mmco: unref short failure
[h264 @ 0x559b35c82840] mmco: unref short failure
[h264 @ 0x559b35c82840] mmco: unref short failure
[h264 @ 0x559b35c82840] mmco: unref short failure
  7%|▋         | 132/1945 [38:27<10:36:02, 21.05s/it][h264 @ 0x559f850ae640] mmco: unref short failure
[h264 @ 0x559f7ddf5000] mmco: unref short failure
[h264 @ 0x559f9741fc00] mmco: unref short failure
[h264 @ 0x559b3af8b6c0] mmco: unref short failure
[h264 @ 0x559b3af8b6c0] mmco: unref short failure
  7%|▋         | 133/1945 [38:37<8:59:16, 17.86s/it] [h264 @ 0x562369699c00] mmco: unref short failure
[h264 @ 0x562369699c00] mmco: unref short failure
[h264 @ 0x56237c7f6280] mmco: unref short failure
[h264 @ 0x56237c7f6280] mmco: unref short failure
[h264 @ 0x556a862e1140] mmco: unref short failure
[h264 @ 0x556a862e1140] mmco: unref short failure
  7%|▋         | 134/1945 [38:59<9:36:47, 19.11s/it][h264 @ 0x56237f501600] mmco: unref short failure
[h264 @ 0x56237f501600] mmco: unref short failure
[h264 @ 0x559b3d3c3000] mmco: unref short failure
  7%|▋         | 135/1945 [39:07<7:50:39, 15.60s/it][h264 @ 0x556a94283400] mmco: unref short failure
[h264 @ 0x556a94283400] mmco: unref short failure
[h264 @ 0x556a96605780] mmco: unref short failure
[h264 @ 0x556a96605780] mmco: unref short failure
[h264 @ 0x56237d925540] mmco: unref short failure
[h264 @ 0x559f98232f00] mmco: unref short failure
[h264 @ 0x559f98232f00] mmco: unref short failure
[h264 @ 0x559f98232f00] mmco: unref short failure
  7%|▋         | 136/1945 [39:29<8:53:53, 17.71s/it]  7%|▋         | 137/1945 [39:37<7:19:00, 14.57s/it][h264 @ 0x56237be86140] mmco: unref short failure
[h264 @ 0x56237be86140] mmco: unref short failure
[h264 @ 0x56237be86140] mmco: unref short failure
[h264 @ 0x56237be86140] mmco: unref short failure
[h264 @ 0x556a8e2bf040] mmco: unref short failure
[h264 @ 0x556a8e2bf040] mmco: unref short failure
  7%|▋         | 138/1945 [39:44<6:12:48, 12.38s/it][h264 @ 0x559b3d7c53c0] mmco: unref short failure
[h264 @ 0x559b3ac7afc0] mmco: unref short failure
  7%|▋         | 139/1945 [39:51<5:29:01, 10.93s/it][h264 @ 0x559f84b1da00] mmco: unref short failure
[h264 @ 0x559f84b1da00] mmco: unref short failure
[h264 @ 0x556a7933c200] mmco: unref short failure
[h264 @ 0x5623631fc300] mmco: unref short failure
[h264 @ 0x559b51097c40] mmco: unref short failure
[h264 @ 0x556a8e2bf040] mmco: unref short failure
  7%|▋         | 140/1945 [40:25<8:55:54, 17.81s/it][h264 @ 0x559f850981c0] mmco: unref short failure
  7%|▋         | 141/1945 [40:37<7:59:57, 15.96s/it][h264 @ 0x559f8d832080] mmco: unref short failure
[h264 @ 0x559f8d832080] mmco: unref short failure
[h264 @ 0x559f8d832080] mmco: unref short failure
[h264 @ 0x559f8d832080] mmco: unref short failure
[h264 @ 0x56237db26780] mmco: unref short failure
[h264 @ 0x56237db26780] mmco: unref short failure
[h264 @ 0x562363158400] mmco: unref short failure
[h264 @ 0x559b4d473900] mmco: unref short failure
[h264 @ 0x559b4d473900] mmco: unref short failure
[h264 @ 0x556a9a9e2fc0] mmco: unref short failure
  7%|▋         | 142/1945 [41:02<9:17:31, 18.55s/it][h264 @ 0x559f98f31700] mmco: unref short failure
[h264 @ 0x56236ac30dc0] mmco: unref short failure
[h264 @ 0x559f81dab780] mmco: unref short failure
[h264 @ 0x559f81dab780] mmco: unref short failure
[h264 @ 0x559f81dab780] mmco: unref short failure
[h264 @ 0x559f81dab780] mmco: unref short failure
[h264 @ 0x559b34bd7380] mmco: unref short failure
[h264 @ 0x56237ffe3d40] mmco: unref short failure
  7%|▋         | 143/1945 [41:22<9:31:10, 19.02s/it]  7%|▋         | 144/1945 [41:29<7:43:55, 15.46s/it][h264 @ 0x556a8a1bdd80] mmco: unref short failure
[h264 @ 0x556a8a1bdd80] mmco: unref short failure
  7%|▋         | 145/1945 [41:35<6:20:02, 12.67s/it][h264 @ 0x562368640b00] mmco: unref short failure
[h264 @ 0x559b3ad49680] mmco: unref short failure
[h264 @ 0x559b3ad49680] mmco: unref short failure
[h264 @ 0x559b3ad49680] mmco: unref short failure
[h264 @ 0x559b3ad49680] mmco: unref short failure
  8%|▊         | 146/1945 [41:42<5:29:01, 10.97s/it][h264 @ 0x56237584d380] mmco: unref short failure
  8%|▊         | 147/1945 [41:50<5:03:01, 10.11s/it][h264 @ 0x559b43ed2040] mmco: unref short failure
[h264 @ 0x559b3a6ca880] mmco: unref short failure
[h264 @ 0x5623710818c0] mmco: unref short failure
[h264 @ 0x5623710818c0] mmco: unref short failure
[h264 @ 0x556a881ee700] mmco: unref short failure
[h264 @ 0x559b45ddee00] mmco: unref short failure
[h264 @ 0x559b45ddee00] mmco: unref short failure
[h264 @ 0x559b45ddee00] mmco: unref short failure
[h264 @ 0x556a8504a2c0] mmco: unref short failure
[h264 @ 0x559b45dde940] mmco: unref short failure
[h264 @ 0x559b45dde940] mmco: unref short failure
[h264 @ 0x556a79ec2380] mmco: unref short failure
[h264 @ 0x556a79ec2380] mmco: unref short failure
[h264 @ 0x562381e4be00] mmco: unref short failure
[h264 @ 0x562381e4be00] mmco: unref short failure
[h264 @ 0x559b42218a80] mmco: unref short failure
[h264 @ 0x559b42218a80] mmco: unref short failure
[h264 @ 0x559b42218a80] mmco: unref short failure
[h264 @ 0x559b42218a80] mmco: unref short failure
[h264 @ 0x556a9595f540] mmco: unref short failure
  8%|▊         | 148/1945 [42:35<10:14:17, 20.51s/it][h264 @ 0x559b4f6f5540] mmco: unref short failure
  8%|▊         | 149/1945 [42:42<8:13:27, 16.49s/it] 09/09/2024 17:48:04 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 17:48:04 - INFO - __main__ -   start running ret%tv validation...
[h264 @ 0x562371f4d500] mmco: unref short failure
[h264 @ 0x562371f4d500] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559b49f27bc0] mmco: unref short failure
[h264 @ 0x559b49f27bc0] mmco: unref short failure
[h264 @ 0x56237e6b3540] mmco: unref short failure
[h264 @ 0x56237e6b3540] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559b3ad4f280] mmco: unref short failure
[h264 @ 0x559b3ad4f280] mmco: unref short failure
[h264 @ 0x559f99e4e500] mmco: unref short failure
[h264 @ 0x56236f649bc0] mmco: unref short failure
[h264 @ 0x559f7d570740] mmco: unref short failure
[h264 @ 0x559f7d570740] mmco: unref short failure
[h264 @ 0x559f7dab52c0] mmco: unref short failure
[h264 @ 0x56236f679b00] mmco: unref short failure
[h264 @ 0x56236f679b00] mmco: unref short failure
[h264 @ 0x56237e5f5700] mmco: unref short failure
[h264 @ 0x56237e5f5700] mmco: unref short failure
[h264 @ 0x559f9b358f00] mmco: unref short failure
[h264 @ 0x559f9b358f00] mmco: unref short failure
[h264 @ 0x56236f679b00] mmco: unref short failure
[h264 @ 0x56236f679b00] mmco: unref short failure
[h264 @ 0x5623637a5100] mmco: unref short failure
[h264 @ 0x5623637a5100] mmco: unref short failure
[h264 @ 0x559f9c71c0c0] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:21,  2.71it/s][A
  1%|          | 2/221 [00:00<01:20,  2.71it/s][A
  1%|▏         | 3/221 [00:01<01:26,  2.53it/s][A
  2%|▏         | 4/221 [00:01<01:18,  2.75it/s][A
  2%|▏         | 5/221 [00:01<01:10,  3.06it/s][A
  3%|▎         | 6/221 [00:01<00:54,  3.94it/s][A
  3%|▎         | 7/221 [00:02<00:51,  4.19it/s][A
  4%|▎         | 8/221 [00:02<00:44,  4.78it/s][A
  4%|▍         | 9/221 [00:02<00:47,  4.49it/s][A
  5%|▍         | 10/221 [00:03<01:12,  2.91it/s][A
  5%|▍         | 11/221 [00:03<01:07,  3.09it/s][A
  5%|▌         | 12/221 [00:03<01:08,  3.03it/s][A
  6%|▌         | 13/221 [00:03<01:01,  3.37it/s][A
  6%|▋         | 14/221 [00:04<00:57,  3.62it/s][A
  7%|▋         | 15/221 [00:04<00:51,  3.97it/s][A
  7%|▋         | 16/221 [00:04<00:59,  3.44it/s][A
  8%|▊         | 17/221 [00:05<01:24,  2.41it/s][A
  8%|▊         | 18/221 [00:05<01:20,  2.51it/s][A
  9%|▊         | 19/221 [00:05<01:08,  2.94it/s][A
  9%|▉         | 20/221 [00:06<00:57,  3.51it/s][A
 10%|▉         | 21/221 [00:06<00:50,  3.96it/s][A
 10%|▉         | 22/221 [00:06<01:00,  3.31it/s][A
 10%|█         | 23/221 [00:06<00:47,  4.14it/s][A
 11%|█         | 24/221 [00:07<00:49,  4.02it/s][A
 11%|█▏        | 25/221 [00:07<00:47,  4.10it/s][A
 12%|█▏        | 26/221 [00:07<00:55,  3.51it/s][A
 12%|█▏        | 27/221 [00:07<00:49,  3.89it/s][A
 13%|█▎        | 28/221 [00:08<01:24,  2.28it/s][A
 13%|█▎        | 29/221 [00:09<01:11,  2.67it/s][A
 14%|█▎        | 30/221 [00:09<01:08,  2.81it/s][A[h264 @ 0x562363b2e5c0] mmco: unref short failure
[h264 @ 0x562363b2e5c0] mmco: unref short failure

 14%|█▍        | 31/221 [00:09<01:03,  2.97it/s][A
 15%|█▍        | 33/221 [00:09<00:45,  4.16it/s][A
 16%|█▌        | 35/221 [00:10<00:38,  4.85it/s][A
 16%|█▋        | 36/221 [00:10<00:52,  3.51it/s][A
 17%|█▋        | 37/221 [00:11<00:56,  3.26it/s][A
 17%|█▋        | 38/221 [00:11<01:02,  2.94it/s][A
 18%|█▊        | 39/221 [00:11<00:51,  3.55it/s][A
 18%|█▊        | 40/221 [00:11<00:52,  3.43it/s][A
 19%|█▊        | 41/221 [00:12<00:46,  3.87it/s][A
 19%|█▉        | 42/221 [00:12<00:52,  3.41it/s][A
 19%|█▉        | 43/221 [00:12<00:47,  3.78it/s][A
 20%|█▉        | 44/221 [00:12<00:44,  3.94it/s][A
 20%|██        | 45/221 [00:13<01:02,  2.81it/s][A
 21%|██        | 46/221 [00:13<00:55,  3.13it/s][A
 21%|██▏       | 47/221 [00:14<01:07,  2.59it/s][A
 22%|██▏       | 48/221 [00:14<00:52,  3.27it/s][A
 22%|██▏       | 49/221 [00:14<00:53,  3.20it/s][A
 23%|██▎       | 50/221 [00:15<00:49,  3.44it/s][A
 23%|██▎       | 51/221 [00:15<00:42,  4.03it/s][A
 24%|██▎       | 52/221 [00:15<00:41,  4.08it/s][A
 24%|██▍       | 53/221 [00:15<00:39,  4.30it/s][A
 24%|██▍       | 54/221 [00:17<01:58,  1.41it/s][A
 25%|██▍       | 55/221 [00:17<01:45,  1.57it/s][A
 25%|██▌       | 56/221 [00:18<01:20,  2.05it/s][A[h264 @ 0x559f7da56e40] mmco: unref short failure
[h264 @ 0x559f7da56e40] mmco: unref short failure

 26%|██▌       | 57/221 [00:18<01:07,  2.44it/s][A[h264 @ 0x559b4b3b2b80] mmco: unref short failure
[h264 @ 0x559b4b3b2b80] mmco: unref short failure

 26%|██▌       | 58/221 [00:18<00:55,  2.96it/s][A
 27%|██▋       | 59/221 [00:18<00:51,  3.13it/s][A[h264 @ 0x559f8b00d140] mmco: unref short failure

 27%|██▋       | 60/221 [00:19<01:21,  1.97it/s][A
 28%|██▊       | 61/221 [00:19<01:05,  2.46it/s][A
 28%|██▊       | 62/221 [00:20<00:57,  2.76it/s][A
 29%|██▊       | 63/221 [00:20<00:47,  3.32it/s][A
 29%|██▉       | 64/221 [00:20<00:53,  2.92it/s][A
 29%|██▉       | 65/221 [00:20<00:44,  3.47it/s][A
 30%|██▉       | 66/221 [00:21<00:49,  3.14it/s][A
 30%|███       | 67/221 [00:21<00:46,  3.34it/s][A
 31%|███       | 68/221 [00:21<00:39,  3.84it/s][A
 31%|███       | 69/221 [00:22<01:12,  2.10it/s][A
 32%|███▏      | 70/221 [00:22<01:00,  2.50it/s][A
 32%|███▏      | 71/221 [00:23<00:51,  2.89it/s][A
 33%|███▎      | 72/221 [00:23<00:51,  2.91it/s][A
 33%|███▎      | 73/221 [00:23<00:54,  2.72it/s][A[h264 @ 0x559b35311940] mmco: unref short failure

 33%|███▎      | 74/221 [00:23<00:42,  3.44it/s][A[h264 @ 0x559b35311940] mmco: unref short failure

 34%|███▍      | 75/221 [00:24<00:50,  2.91it/s][A
 34%|███▍      | 76/221 [00:24<00:43,  3.36it/s][A
 35%|███▍      | 77/221 [00:25<00:48,  2.98it/s][A
 36%|███▌      | 79/221 [00:25<00:42,  3.34it/s][A
 36%|███▌      | 80/221 [00:25<00:43,  3.21it/s][A
 37%|███▋      | 81/221 [00:26<00:45,  3.09it/s][A
 37%|███▋      | 82/221 [00:26<00:46,  3.01it/s][A
 38%|███▊      | 83/221 [00:27<00:49,  2.80it/s][A
 38%|███▊      | 84/221 [00:27<00:46,  2.92it/s][A
 38%|███▊      | 85/221 [00:27<00:43,  3.14it/s][A
 39%|███▉      | 86/221 [00:27<00:40,  3.29it/s][A
 39%|███▉      | 87/221 [00:28<01:12,  1.85it/s][A
 40%|███▉      | 88/221 [00:29<01:17,  1.71it/s][A
 40%|████      | 89/221 [00:30<01:07,  1.96it/s][A
 41%|████      | 90/221 [00:30<00:56,  2.32it/s][A
 41%|████      | 91/221 [00:30<00:44,  2.90it/s][A[h264 @ 0x556a8a4e3bc0] mmco: unref short failure
[h264 @ 0x556a8a4e3bc0] mmco: unref short failure

 42%|████▏     | 92/221 [00:30<00:44,  2.87it/s][A[h264 @ 0x559b3d8c0c00] mmco: unref short failure
[h264 @ 0x559b3d8c0c00] mmco: unref short failure

 42%|████▏     | 93/221 [00:31<00:48,  2.66it/s][A
 43%|████▎     | 94/221 [00:31<00:42,  2.98it/s][A
 43%|████▎     | 95/221 [00:31<00:41,  3.01it/s][A
 43%|████▎     | 96/221 [00:32<00:50,  2.46it/s][A
 44%|████▍     | 97/221 [00:32<00:48,  2.56it/s][A
 44%|████▍     | 98/221 [00:33<00:56,  2.17it/s][A
 45%|████▍     | 99/221 [00:33<00:50,  2.42it/s][A
 45%|████▌     | 100/221 [00:33<00:43,  2.75it/s][A
 46%|████▌     | 101/221 [00:34<00:38,  3.13it/s][A
 46%|████▌     | 102/221 [00:34<00:45,  2.61it/s][A
 47%|████▋     | 103/221 [00:34<00:36,  3.26it/s][A
 47%|████▋     | 104/221 [00:35<00:35,  3.31it/s][A
 48%|████▊     | 105/221 [00:35<00:35,  3.28it/s][A
 48%|████▊     | 106/221 [00:35<00:47,  2.43it/s][A
 48%|████▊     | 107/221 [00:36<00:39,  2.90it/s][A
 49%|████▉     | 108/221 [00:36<00:38,  2.91it/s][A[h264 @ 0x56237c41c080] mmco: unref short failure
[h264 @ 0x56237c41c080] mmco: unref short failure

 49%|████▉     | 109/221 [00:36<00:38,  2.90it/s][A
 50%|████▉     | 110/221 [00:37<00:32,  3.40it/s][A
 50%|█████     | 111/221 [00:37<00:34,  3.16it/s][A
 51%|█████     | 112/221 [00:37<00:34,  3.19it/s][A
 51%|█████     | 113/221 [00:38<00:33,  3.24it/s][A
 52%|█████▏    | 114/221 [00:38<00:26,  4.01it/s][A
 52%|█████▏    | 115/221 [00:38<00:22,  4.76it/s][A
 52%|█████▏    | 116/221 [00:38<00:37,  2.77it/s][A
 53%|█████▎    | 117/221 [00:39<00:36,  2.83it/s][A
 53%|█████▎    | 118/221 [00:39<00:38,  2.69it/s][A
 54%|█████▍    | 119/221 [00:40<00:37,  2.71it/s][A
 54%|█████▍    | 120/221 [00:40<00:30,  3.31it/s][A
 55%|█████▍    | 121/221 [00:40<00:24,  4.00it/s][A
 55%|█████▌    | 122/221 [00:40<00:26,  3.78it/s][A
 56%|█████▌    | 123/221 [00:40<00:23,  4.24it/s][A
 56%|█████▌    | 124/221 [00:41<00:27,  3.58it/s][A
 57%|█████▋    | 125/221 [00:41<00:34,  2.81it/s][A
 57%|█████▋    | 126/221 [00:42<00:35,  2.70it/s][A
 57%|█████▋    | 127/221 [00:43<01:06,  1.41it/s][A[h264 @ 0x562362d92680] mmco: unref short failure

 58%|█████▊    | 128/221 [00:44<00:56,  1.65it/s][A
 58%|█████▊    | 129/221 [00:44<00:43,  2.12it/s][A
 59%|█████▉    | 130/221 [00:44<00:35,  2.59it/s][A
 59%|█████▉    | 131/221 [00:44<00:29,  3.02it/s][A
 60%|█████▉    | 132/221 [00:45<00:53,  1.65it/s][A
 60%|██████    | 133/221 [00:46<00:48,  1.82it/s][A
 61%|██████    | 134/221 [00:46<00:53,  1.62it/s][A
 61%|██████    | 135/221 [00:47<00:51,  1.69it/s][A
 62%|██████▏   | 136/221 [00:47<00:44,  1.89it/s][A
 62%|██████▏   | 137/221 [00:48<00:38,  2.19it/s][A
 62%|██████▏   | 138/221 [00:48<00:35,  2.31it/s][A
 63%|██████▎   | 139/221 [00:49<00:43,  1.88it/s][A
 63%|██████▎   | 140/221 [00:49<00:37,  2.18it/s][A[h264 @ 0x56236862dec0] mmco: unref short failure

 64%|██████▍   | 141/221 [00:49<00:31,  2.53it/s][A
 64%|██████▍   | 142/221 [00:50<00:28,  2.77it/s][A[h264 @ 0x559f7dab52c0] mmco: unref short failure

 65%|██████▍   | 143/221 [00:50<00:28,  2.74it/s][A
 65%|██████▌   | 144/221 [00:50<00:26,  2.93it/s][A
 66%|██████▌   | 145/221 [00:50<00:22,  3.44it/s][A
 66%|██████▌   | 146/221 [00:51<00:18,  4.15it/s][A
 67%|██████▋   | 147/221 [00:51<00:19,  3.81it/s][A
 67%|██████▋   | 148/221 [00:51<00:22,  3.23it/s][A
 67%|██████▋   | 149/221 [00:52<00:23,  3.03it/s][A
 68%|██████▊   | 150/221 [00:52<00:22,  3.20it/s][A
 68%|██████▊   | 151/221 [00:53<00:28,  2.49it/s][A
 69%|██████▉   | 152/221 [00:54<00:52,  1.31it/s][A
 69%|██████▉   | 153/221 [00:54<00:40,  1.68it/s][A
 70%|██████▉   | 154/221 [00:55<00:32,  2.05it/s][A
 70%|███████   | 155/221 [00:55<00:27,  2.43it/s][A
 71%|███████   | 156/221 [00:55<00:27,  2.38it/s][A[h264 @ 0x559f95f4d880] mmco: unref short failure

 71%|███████   | 157/221 [00:56<00:26,  2.37it/s][A
 71%|███████▏  | 158/221 [00:56<00:32,  1.96it/s][A
 72%|███████▏  | 159/221 [00:57<00:24,  2.50it/s][A
 72%|███████▏  | 160/221 [00:57<00:20,  2.93it/s][A
 73%|███████▎  | 161/221 [00:57<00:17,  3.50it/s][A
 73%|███████▎  | 162/221 [00:57<00:14,  3.95it/s][A
 74%|███████▍  | 163/221 [00:57<00:15,  3.73it/s][A[h264 @ 0x56236cfe5480] mmco: unref short failure
[h264 @ 0x56236cfe5480] mmco: unref short failure

 74%|███████▍  | 164/221 [00:58<00:14,  3.90it/s][A
 75%|███████▍  | 165/221 [00:58<00:12,  4.36it/s][A
 75%|███████▌  | 166/221 [00:58<00:14,  3.73it/s][A
 76%|███████▌  | 167/221 [00:58<00:12,  4.28it/s][A
 76%|███████▌  | 168/221 [00:59<00:21,  2.52it/s][A[h264 @ 0x556a9958bd00] mmco: unref short failure

 76%|███████▋  | 169/221 [00:59<00:16,  3.16it/s][A
 77%|███████▋  | 170/221 [01:00<00:15,  3.27it/s][A
 77%|███████▋  | 171/221 [01:00<00:16,  3.03it/s][A
 78%|███████▊  | 172/221 [01:00<00:14,  3.48it/s][A
 78%|███████▊  | 173/221 [01:01<00:16,  2.98it/s][A
 79%|███████▊  | 174/221 [01:01<00:14,  3.35it/s][A
 79%|███████▉  | 175/221 [01:01<00:13,  3.46it/s][A
 80%|███████▉  | 176/221 [01:01<00:11,  3.78it/s][A
 80%|████████  | 177/221 [01:01<00:10,  4.33it/s][A[h264 @ 0x562363199740] mmco: unref short failure
[h264 @ 0x562363199740] mmco: unref short failure

[h264 @ 0x562363199740] mmco: unref short failure
[h264 @ 0x562363199740] mmco: unref short failure
 81%|████████  | 178/221 [01:02<00:15,  2.75it/s][A
 81%|████████  | 179/221 [01:02<00:15,  2.74it/s][A
 81%|████████▏ | 180/221 [01:03<00:11,  3.47it/s][A
 82%|████████▏ | 182/221 [01:03<00:08,  4.66it/s][A
 83%|████████▎ | 183/221 [01:03<00:08,  4.22it/s][A
 83%|████████▎ | 184/221 [01:03<00:09,  3.72it/s][A
 84%|████████▍ | 186/221 [01:04<00:09,  3.80it/s][A
 85%|████████▍ | 187/221 [01:04<00:08,  3.88it/s][A
 85%|████████▌ | 188/221 [01:04<00:08,  3.98it/s][A
 86%|████████▌ | 189/221 [01:05<00:08,  3.84it/s][A
 86%|████████▌ | 190/221 [01:05<00:08,  3.55it/s][A
 86%|████████▋ | 191/221 [01:05<00:06,  4.32it/s][A
 87%|████████▋ | 192/221 [01:05<00:06,  4.64it/s][A
 88%|████████▊ | 194/221 [01:07<00:10,  2.66it/s][A
 88%|████████▊ | 195/221 [01:07<00:08,  3.08it/s][A
 89%|████████▊ | 196/221 [01:07<00:07,  3.35it/s][A
 89%|████████▉ | 197/221 [01:07<00:06,  3.58it/s][A
 90%|████████▉ | 198/221 [01:07<00:05,  3.96it/s][A
 90%|█████████ | 199/221 [01:08<00:05,  3.88it/s][A[h264 @ 0x56236d478d80] mmco: unref short failure

 90%|█████████ | 200/221 [01:08<00:04,  4.37it/s][A
 91%|█████████ | 201/221 [01:08<00:04,  4.76it/s][A
 91%|█████████▏| 202/221 [01:08<00:04,  4.42it/s][A
 92%|█████████▏| 203/221 [01:08<00:03,  4.57it/s][A
 92%|█████████▏| 204/221 [01:09<00:03,  4.70it/s][A
 93%|█████████▎| 205/221 [01:09<00:03,  5.33it/s][A
 93%|█████████▎| 206/221 [01:09<00:04,  3.35it/s][A
 94%|█████████▍| 208/221 [01:10<00:03,  4.03it/s][A
 95%|█████████▍| 209/221 [01:10<00:02,  4.27it/s][A
 95%|█████████▌| 211/221 [01:10<00:02,  4.57it/s][A
 96%|█████████▌| 212/221 [01:10<00:02,  4.43it/s][A
 96%|█████████▋| 213/221 [01:11<00:01,  4.70it/s][A
 97%|█████████▋| 214/221 [01:11<00:02,  3.18it/s][A
 97%|█████████▋| 215/221 [01:11<00:01,  3.62it/s][A
 98%|█████████▊| 216/221 [01:12<00:01,  3.66it/s][A
 98%|█████████▊| 217/221 [01:12<00:01,  3.28it/s][A
 99%|█████████▊| 218/221 [01:12<00:00,  3.32it/s][A
 99%|█████████▉| 219/221 [01:13<00:00,  3.44it/s][A
100%|█████████▉| 220/221 [01:13<00:00,  2.30it/s][A100%|██████████| 221/221 [01:13<00:00,  2.99it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.78it/s][A
  1%|          | 2/221 [00:00<00:58,  3.77it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.77it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.77it/s][A
  2%|▏         | 5/221 [00:01<00:57,  3.77it/s][A
  3%|▎         | 6/221 [00:01<00:57,  3.76it/s][A
  3%|▎         | 7/221 [00:01<00:57,  3.74it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.75it/s][A
  4%|▍         | 9/221 [00:02<00:56,  3.75it/s][A
  5%|▍         | 10/221 [00:02<00:56,  3.75it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.76it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.76it/s][A
  6%|▌         | 13/221 [00:03<00:55,  3.76it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.77it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.77it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.77it/s][A
  8%|▊         | 17/221 [00:04<00:54,  3.77it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.77it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.77it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.77it/s][A
 10%|▉         | 21/221 [00:05<00:53,  3.77it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.77it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.77it/s][A
 11%|█         | 24/221 [00:06<00:52,  3.76it/s][A
 11%|█▏        | 25/221 [00:06<00:52,  3.76it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.77it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.77it/s][A
 13%|█▎        | 28/221 [00:07<00:51,  3.77it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.78it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.78it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.78it/s][A
 14%|█▍        | 32/221 [00:08<00:50,  3.78it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.78it/s][A
 15%|█▌        | 34/221 [00:09<00:49,  3.78it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.78it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.78it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:14<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:23<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:28<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:42<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:47<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:52<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:57<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:25,  8.47it/s][A
  1%|          | 2/221 [00:00<00:53,  4.06it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.78it/s][A
  2%|▏         | 4/221 [00:00<00:49,  4.39it/s][A
  2%|▏         | 5/221 [00:01<00:43,  5.02it/s][A
  3%|▎         | 7/221 [00:01<00:37,  5.76it/s][A
  4%|▎         | 8/221 [00:01<00:33,  6.44it/s][A
  4%|▍         | 9/221 [00:01<00:36,  5.77it/s][A
  5%|▍         | 10/221 [00:02<01:02,  3.36it/s][A
  5%|▍         | 11/221 [00:02<00:54,  3.83it/s][A
  5%|▌         | 12/221 [00:02<00:46,  4.46it/s][A
  6%|▌         | 13/221 [00:02<00:55,  3.77it/s][A
  6%|▋         | 14/221 [00:03<00:46,  4.41it/s][A
  7%|▋         | 15/221 [00:03<00:47,  4.34it/s][A
  7%|▋         | 16/221 [00:03<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<01:22,  2.46it/s][A
  8%|▊         | 18/221 [00:04<01:08,  2.95it/s][A
  9%|▊         | 19/221 [00:04<00:58,  3.46it/s][A
  9%|▉         | 20/221 [00:04<00:46,  4.30it/s][A
 10%|▉         | 21/221 [00:05<00:40,  4.98it/s][A
 10%|▉         | 22/221 [00:05<00:47,  4.19it/s][A
 11%|█         | 24/221 [00:05<00:36,  5.33it/s][A
 11%|█▏        | 25/221 [00:05<00:36,  5.42it/s][A
 12%|█▏        | 26/221 [00:05<00:38,  5.07it/s][A
 13%|█▎        | 28/221 [00:06<00:44,  4.31it/s][A
 13%|█▎        | 29/221 [00:06<00:39,  4.87it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.80it/s][A
 14%|█▍        | 31/221 [00:07<00:45,  4.20it/s][A
 15%|█▍        | 33/221 [00:07<00:35,  5.36it/s][A
 16%|█▌        | 35/221 [00:07<00:31,  5.83it/s][A
 16%|█▋        | 36/221 [00:08<00:43,  4.29it/s][A
 17%|█▋        | 37/221 [00:08<00:40,  4.53it/s][A
 17%|█▋        | 38/221 [00:08<00:47,  3.85it/s][A
 18%|█▊        | 40/221 [00:09<00:41,  4.33it/s][A
 19%|█▊        | 41/221 [00:09<00:38,  4.72it/s][A
 19%|█▉        | 42/221 [00:09<00:39,  4.58it/s][A
 19%|█▉        | 43/221 [00:09<00:42,  4.23it/s][A
 20%|█▉        | 44/221 [00:10<00:44,  3.98it/s][A
 20%|██        | 45/221 [00:10<00:47,  3.72it/s][A
 21%|██        | 46/221 [00:10<00:40,  4.36it/s][A
 21%|██▏       | 47/221 [00:10<00:37,  4.59it/s][A
 22%|██▏       | 48/221 [00:10<00:32,  5.37it/s][A
 22%|██▏       | 49/221 [00:11<00:33,  5.20it/s][A
 23%|██▎       | 50/221 [00:11<00:34,  5.02it/s][A
 23%|██▎       | 51/221 [00:11<00:28,  5.88it/s][A
 24%|██▎       | 52/221 [00:11<00:29,  5.72it/s][A
 24%|██▍       | 53/221 [00:11<00:28,  5.85it/s][A
 24%|██▍       | 54/221 [00:12<00:52,  3.18it/s][A
 25%|██▍       | 55/221 [00:12<00:51,  3.21it/s][A
 25%|██▌       | 56/221 [00:12<00:41,  3.99it/s][A
 26%|██▌       | 57/221 [00:13<00:38,  4.30it/s][A
 26%|██▌       | 58/221 [00:13<00:37,  4.40it/s][A
 27%|██▋       | 59/221 [00:13<00:33,  4.81it/s][A
 27%|██▋       | 60/221 [00:13<00:47,  3.37it/s][A
 28%|██▊       | 61/221 [00:14<00:41,  3.90it/s][A
 28%|██▊       | 62/221 [00:14<00:40,  3.89it/s][A
 29%|██▊       | 63/221 [00:14<00:48,  3.27it/s][A
 29%|██▉       | 64/221 [00:15<00:55,  2.82it/s][A
 29%|██▉       | 65/221 [00:15<00:45,  3.41it/s][A
 30%|██▉       | 66/221 [00:15<00:50,  3.04it/s][A
 30%|███       | 67/221 [00:16<00:46,  3.33it/s][A
 31%|███       | 68/221 [00:16<00:37,  4.07it/s][A
 31%|███       | 69/221 [00:17<01:12,  2.09it/s][A
 32%|███▏      | 70/221 [00:17<00:59,  2.52it/s][A
 32%|███▏      | 71/221 [00:17<00:51,  2.92it/s][A
 33%|███▎      | 72/221 [00:18<00:56,  2.65it/s][A
 33%|███▎      | 73/221 [00:18<00:57,  2.55it/s][A
 34%|███▍      | 75/221 [00:18<00:43,  3.39it/s][A
 34%|███▍      | 76/221 [00:19<00:39,  3.66it/s][A
 35%|███▍      | 77/221 [00:19<00:47,  3.03it/s][A
 36%|███▌      | 79/221 [00:19<00:40,  3.49it/s][A
 36%|███▌      | 80/221 [00:20<00:38,  3.71it/s][A
 37%|███▋      | 81/221 [00:20<00:37,  3.76it/s][A
 37%|███▋      | 82/221 [00:20<00:37,  3.67it/s][A
 38%|███▊      | 83/221 [00:21<00:49,  2.77it/s][A
 38%|███▊      | 84/221 [00:21<00:43,  3.17it/s][A
 39%|███▉      | 86/221 [00:21<00:28,  4.76it/s][A
 39%|███▉      | 87/221 [00:22<00:46,  2.85it/s][A
 40%|███▉      | 88/221 [00:22<00:48,  2.72it/s][A
 40%|████      | 89/221 [00:23<00:43,  3.01it/s][A
 41%|████      | 90/221 [00:23<00:40,  3.21it/s][A
 41%|████      | 91/221 [00:23<00:34,  3.75it/s][A
 42%|████▏     | 92/221 [00:23<00:31,  4.05it/s][A
 42%|████▏     | 93/221 [00:24<00:40,  3.18it/s][A
 43%|████▎     | 94/221 [00:24<00:39,  3.24it/s][A
 43%|████▎     | 95/221 [00:24<00:39,  3.21it/s][A
 43%|████▎     | 96/221 [00:25<00:47,  2.61it/s][A
 44%|████▍     | 97/221 [00:25<00:40,  3.05it/s][A
 44%|████▍     | 98/221 [00:26<00:51,  2.40it/s][A
 45%|████▍     | 99/221 [00:26<00:43,  2.78it/s][A
 45%|████▌     | 100/221 [00:26<00:38,  3.13it/s][A
 46%|████▌     | 101/221 [00:26<00:34,  3.49it/s][A
 46%|████▌     | 102/221 [00:27<01:01,  1.92it/s][A
 47%|████▋     | 104/221 [00:28<00:39,  2.96it/s][A
 48%|████▊     | 105/221 [00:28<00:35,  3.22it/s][A
 48%|████▊     | 106/221 [00:28<00:40,  2.85it/s][A
 48%|████▊     | 107/221 [00:29<00:34,  3.30it/s][A
 49%|████▉     | 108/221 [00:29<00:33,  3.32it/s][A
 49%|████▉     | 109/221 [00:29<00:27,  4.00it/s][A
 50%|████▉     | 110/221 [00:29<00:26,  4.19it/s][A
 50%|█████     | 111/221 [00:29<00:26,  4.13it/s][A
 51%|█████     | 112/221 [00:30<00:26,  4.07it/s][A
 51%|█████     | 113/221 [00:30<00:28,  3.82it/s][A
 52%|█████▏    | 115/221 [00:30<00:20,  5.27it/s][A
 52%|█████▏    | 116/221 [00:30<00:21,  4.96it/s][A
 53%|█████▎    | 117/221 [00:31<00:24,  4.22it/s][A
 53%|█████▎    | 118/221 [00:31<00:23,  4.37it/s][A
 54%|█████▍    | 119/221 [00:31<00:27,  3.66it/s][A
 54%|█████▍    | 120/221 [00:32<00:24,  4.21it/s][A
 55%|█████▍    | 121/221 [00:32<00:20,  4.89it/s][A
 55%|█████▌    | 122/221 [00:32<00:23,  4.30it/s][A
 56%|█████▌    | 123/221 [00:32<00:19,  4.91it/s][A
 56%|█████▌    | 124/221 [00:33<00:26,  3.72it/s][A
 57%|█████▋    | 125/221 [00:33<00:28,  3.39it/s][A
 57%|█████▋    | 126/221 [00:33<00:23,  4.09it/s][A
 57%|█████▋    | 127/221 [00:33<00:28,  3.25it/s][A
 58%|█████▊    | 128/221 [00:34<00:27,  3.40it/s][A
 59%|█████▉    | 130/221 [00:34<00:20,  4.54it/s][A
 60%|█████▉    | 132/221 [00:36<00:44,  2.00it/s][A
 60%|██████    | 133/221 [00:36<00:39,  2.24it/s][A
 61%|██████    | 134/221 [00:37<00:45,  1.93it/s][A
 61%|██████    | 135/221 [00:38<00:53,  1.62it/s][A
 62%|██████▏   | 136/221 [00:38<00:44,  1.90it/s][A
 62%|██████▏   | 137/221 [00:38<00:37,  2.25it/s][A
 62%|██████▏   | 138/221 [00:39<00:34,  2.39it/s][A
 63%|██████▎   | 139/221 [00:39<00:38,  2.13it/s][A
 63%|██████▎   | 140/221 [00:40<00:34,  2.33it/s][A
 64%|██████▍   | 141/221 [00:40<00:29,  2.76it/s][A
 64%|██████▍   | 142/221 [00:40<00:26,  3.03it/s][A
 65%|██████▍   | 143/221 [00:40<00:29,  2.64it/s][A
 65%|██████▌   | 144/221 [00:41<00:31,  2.48it/s][A
 66%|██████▌   | 146/221 [00:41<00:18,  3.96it/s][A
 67%|██████▋   | 147/221 [00:41<00:20,  3.67it/s][A
 67%|██████▋   | 148/221 [00:42<00:22,  3.29it/s][A
 67%|██████▋   | 149/221 [00:42<00:25,  2.86it/s][A
 68%|██████▊   | 150/221 [00:43<00:22,  3.17it/s][A
 68%|██████▊   | 151/221 [00:43<00:24,  2.89it/s][A
 69%|██████▉   | 152/221 [00:44<00:29,  2.31it/s][A
 69%|██████▉   | 153/221 [00:44<00:23,  2.90it/s][A
 70%|██████▉   | 154/221 [00:44<00:20,  3.30it/s][A
 70%|███████   | 155/221 [00:44<00:19,  3.30it/s][A
 71%|███████   | 156/221 [00:44<00:19,  3.39it/s][A
 71%|███████   | 157/221 [00:45<00:18,  3.38it/s][A
 71%|███████▏  | 158/221 [00:45<00:18,  3.45it/s][A
 72%|███████▏  | 159/221 [00:45<00:14,  4.23it/s][A
 72%|███████▏  | 160/221 [00:45<00:13,  4.61it/s][A
 73%|███████▎  | 161/221 [00:46<00:13,  4.43it/s][A
 74%|███████▍  | 163/221 [00:46<00:11,  5.06it/s][A
 74%|███████▍  | 164/221 [00:46<00:10,  5.33it/s][A
 75%|███████▍  | 165/221 [00:46<00:12,  4.63it/s][A
 75%|███████▌  | 166/221 [00:47<00:12,  4.57it/s][A
 76%|███████▌  | 167/221 [00:47<00:10,  5.35it/s][A
 76%|███████▌  | 168/221 [00:47<00:10,  5.22it/s][A
 76%|███████▋  | 169/221 [00:47<00:09,  5.76it/s][A
 77%|███████▋  | 170/221 [00:47<00:09,  5.23it/s][A
 77%|███████▋  | 171/221 [00:48<00:11,  4.23it/s][A
 78%|███████▊  | 172/221 [00:48<00:10,  4.52it/s][A
 78%|███████▊  | 173/221 [00:48<00:14,  3.33it/s][A
 79%|███████▊  | 174/221 [00:49<00:15,  2.99it/s][A
 79%|███████▉  | 175/221 [00:49<00:14,  3.13it/s][A
 80%|████████  | 177/221 [00:49<00:10,  4.30it/s][A
 81%|████████  | 178/221 [00:50<00:13,  3.18it/s][A
 81%|████████  | 179/221 [00:50<00:13,  3.13it/s][A
 81%|████████▏ | 180/221 [00:50<00:11,  3.57it/s][A
 82%|████████▏ | 181/221 [00:50<00:09,  4.24it/s][A
 82%|████████▏ | 182/221 [00:51<00:09,  4.04it/s][A
 83%|████████▎ | 183/221 [00:51<00:10,  3.74it/s][A
 83%|████████▎ | 184/221 [00:51<00:10,  3.63it/s][A
 84%|████████▍ | 186/221 [00:52<00:10,  3.29it/s][A
 85%|████████▍ | 187/221 [00:52<00:10,  3.36it/s][A
 85%|████████▌ | 188/221 [00:53<00:09,  3.38it/s][A
 86%|████████▌ | 189/221 [00:53<00:09,  3.38it/s][A
 86%|████████▌ | 190/221 [00:53<00:09,  3.44it/s][A
 86%|████████▋ | 191/221 [00:53<00:07,  4.12it/s][A
 87%|████████▋ | 192/221 [00:53<00:06,  4.33it/s][A
 88%|████████▊ | 194/221 [00:54<00:06,  3.86it/s][A
 88%|████████▊ | 195/221 [00:54<00:06,  3.98it/s][A
 89%|████████▊ | 196/221 [00:55<00:06,  3.68it/s][A
 89%|████████▉ | 197/221 [00:55<00:06,  3.53it/s][A
 90%|████████▉ | 198/221 [00:55<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:56<00:06,  3.47it/s][A
 90%|█████████ | 200/221 [00:56<00:05,  3.73it/s][A
 91%|█████████ | 201/221 [00:56<00:04,  4.21it/s][A
 91%|█████████▏| 202/221 [00:56<00:04,  3.83it/s][A
 92%|█████████▏| 203/221 [00:56<00:04,  3.97it/s][A
 92%|█████████▏| 204/221 [00:57<00:04,  3.68it/s][A
 93%|█████████▎| 206/221 [00:57<00:03,  3.80it/s][A
 94%|█████████▍| 208/221 [00:58<00:02,  4.44it/s][A
 95%|█████████▍| 209/221 [00:58<00:02,  4.46it/s][A
 95%|█████████▌| 211/221 [00:58<00:02,  4.67it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  4.47it/s][A
 96%|█████████▋| 213/221 [00:59<00:01,  4.59it/s][A
 97%|█████████▋| 214/221 [01:00<00:02,  2.61it/s][A
 97%|█████████▋| 215/221 [01:00<00:01,  3.05it/s][A
 98%|█████████▊| 216/221 [01:00<00:01,  2.98it/s][A
 98%|█████████▊| 217/221 [01:00<00:01,  2.85it/s][A
 99%|█████████▊| 218/221 [01:01<00:00,  3.03it/s][A
 99%|█████████▉| 219/221 [01:01<00:00,  3.15it/s][A
100%|█████████▉| 220/221 [01:01<00:00,  3.64it/s][A
100%|██████████| 221/221 [01:01<00:00,  4.29it/s][A100%|██████████| 221/221 [01:01<00:00,  3.57it/s]
09/09/2024 17:53:43 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 149--===========

09/09/2024 17:53:43 - INFO - __main__ -   {'area_r1': 42.4, 'area_recall': '42.4/70.2/79.9', 'area_ravg': 64.2}
09/09/2024 17:53:43 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 149--===========

09/09/2024 17:53:43 - INFO - __main__ -   {'forward_r1': 38.7, 'forward_recall': '38.7/66.4/77.1', 'forward_ravg': 60.7}
09/09/2024 17:53:43 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 149--===========

09/09/2024 17:53:43 - INFO - __main__ -   {'area_video_r1': 39.0, 'area_video_recall': '39.0/66.5/78.1', 'area_video_ravg': 61.2}
09/09/2024 17:53:43 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 149=======

09/09/2024 17:53:43 - INFO - __main__ -   {'area_video_r1': 39.0, 'area_video_recall': '39.0/66.5/78.1', 'area_video_ravg': 61.2}
09/09/2024 17:53:43 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 149--===========

09/09/2024 17:53:43 - INFO - __main__ -   {'area_video_r1': 52.0, 'area_video_recall': '52.0/75.2/82.6', 'area_video_ravg': 69.9, 'area_video_back_r1': 49.5, 'area_video_back_recall': '49.5/73.4/80.8', 'area_video_back_ravg': 67.9}
09/09/2024 17:53:43 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 149=======

09/09/2024 17:53:43 - INFO - __main__ -   {'area_video_r1': 52.0, 'area_video_recall': '52.0/75.2/82.6', 'area_video_ravg': 69.9, 'area_video_back_r1': 49.5, 'area_video_back_recall': '49.5/73.4/80.8', 'area_video_back_ravg': 67.9}
09/09/2024 17:53:43 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 149--===========

09/09/2024 17:53:43 - INFO - __main__ -   {'video_r1': 41.1, 'video_recall': '41.1/71.4/81.8', 'video_ravg': 64.7}
09/09/2024 17:53:43 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 17:53:43 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 17:53:43 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 149--===========

09/09/2024 17:53:43 - INFO - __main__ -   {'video_r1': 51.8, 'video_recall': '51.8/75.1/82.4', 'video_ravg': 69.8}
09/09/2024 17:53:43 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 149=======

09/09/2024 17:53:43 - INFO - __main__ -   {'video_r1': 51.8, 'video_recall': '51.8/75.1/82.4', 'video_ravg': 69.8}
09/09/2024 17:54:18 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.013347366824746132, 'loss_ret%tv%ta--finetune_area/loss_area': 2.643437623977661, 'loss_ret%tv%ta--finetune_area/total_loss': 2.656785011291504}
  8%|▊         | 150/1945 [48:58<62:04:15, 124.49s/it]  8%|▊         | 151/1945 [49:03<44:02:52, 88.39s/it] [h264 @ 0x559b4c223b00] mmco: unref short failure
[h264 @ 0x559b4c223b00] mmco: unref short failure
  8%|▊         | 152/1945 [49:07<31:29:56, 63.24s/it]  8%|▊         | 153/1945 [49:12<22:45:39, 45.73s/it][h264 @ 0x56236245e800] mmco: unref short failure
  8%|▊         | 154/1945 [49:19<16:54:02, 33.97s/it][h264 @ 0x559f7fe3fb40] mmco: unref short failure
  8%|▊         | 155/1945 [49:24<12:42:00, 25.54s/it][h264 @ 0x559b4c45ef00] mmco: unref short failure
[h264 @ 0x559b4c45ef00] mmco: unref short failure
  8%|▊         | 156/1945 [49:31<9:52:23, 19.87s/it] [h264 @ 0x559b350e8300] mmco: unref short failure
[h264 @ 0x559b49af0280] mmco: unref short failure
  8%|▊         | 157/1945 [49:38<7:57:58, 16.04s/it][h264 @ 0x559f9ae0a640] mmco: unref short failure
[h264 @ 0x556a91d920c0] mmco: unref short failure
[h264 @ 0x562362e70580] mmco: unref short failure
  8%|▊         | 158/1945 [49:46<6:41:18, 13.47s/it][h264 @ 0x556a8b370bc0] mmco: unref short failure
  8%|▊         | 159/1945 [49:53<5:43:33, 11.54s/it][h264 @ 0x559f8449f740] mmco: unref short failure
  8%|▊         | 160/1945 [50:00<5:08:23, 10.37s/it][h264 @ 0x559f9355f7c0] mmco: unref short failure
[h264 @ 0x559f9355f7c0] mmco: unref short failure
[h264 @ 0x559f95046d00] mmco: unref short failure
[h264 @ 0x559f95046d00] mmco: unref short failure
[h264 @ 0x559f995f41c0] mmco: unref short failure
[h264 @ 0x559f995f41c0] mmco: unref short failure
  8%|▊         | 161/1945 [50:08<4:48:33,  9.71s/it][h264 @ 0x559b4c223b00] mmco: unref short failure
[h264 @ 0x5623676cce00] mmco: unref short failure
[h264 @ 0x5623676cce00] mmco: unref short failure
  8%|▊         | 162/1945 [50:16<4:26:55,  8.98s/it]  8%|▊         | 163/1945 [50:25<4:26:39,  8.98s/it][h264 @ 0x5623718c7a00] mmco: unref short failure
[h264 @ 0x5623718c7a00] mmco: unref short failure
  8%|▊         | 164/1945 [50:32<4:14:12,  8.56s/it][h264 @ 0x559b41e11480] mmco: unref short failure
[h264 @ 0x559b41e11480] mmco: unref short failure
[h264 @ 0x559f8e763280] mmco: unref short failure
[h264 @ 0x559f8e763280] mmco: unref short failure
[h264 @ 0x556a78746f00] mmco: unref short failure
  8%|▊         | 165/1945 [50:39<3:58:25,  8.04s/it][h264 @ 0x56237b45f640] mmco: unref short failure
[h264 @ 0x559f8fc58980] mmco: unref short failure
  9%|▊         | 166/1945 [50:46<3:50:31,  7.77s/it]  9%|▊         | 167/1945 [50:53<3:42:58,  7.52s/it][h264 @ 0x559f7fdae840] mmco: unref short failure
[h264 @ 0x559f7fdae840] mmco: unref short failure
  9%|▊         | 168/1945 [51:01<3:44:50,  7.59s/it][h264 @ 0x556a94c0bb80] mmco: unref short failure
[h264 @ 0x5623767c2000] mmco: unref short failure
[h264 @ 0x5623767c2000] mmco: unref short failure
  9%|▊         | 169/1945 [51:10<4:01:34,  8.16s/it][h264 @ 0x559b49778b00] mmco: unref short failure
[h264 @ 0x56237d99e980] mmco: unref short failure
[h264 @ 0x559f97ce4000] mmco: unref short failure
  9%|▊         | 170/1945 [51:23<4:37:43,  9.39s/it][h264 @ 0x556a8ee13dc0] mmco: unref short failure
[h264 @ 0x556a8ee13dc0] mmco: unref short failure
[h264 @ 0x559f9964dbc0] mmco: unref short failure
[h264 @ 0x559f9964dbc0] mmco: unref short failure
  9%|▉         | 171/1945 [51:36<5:13:47, 10.61s/it][h264 @ 0x56237bf6ef40] mmco: unref short failure
[h264 @ 0x56237bf6ef40] mmco: unref short failure
[h264 @ 0x56237b613040] mmco: unref short failure
  9%|▉         | 172/1945 [51:44<4:52:03,  9.88s/it]  9%|▉         | 173/1945 [51:52<4:34:22,  9.29s/it][h264 @ 0x559b42e61240] mmco: unref short failure
[h264 @ 0x556a80e24e80] mmco: unref short failure
[h264 @ 0x562373c2c440] mmco: unref short failure
[h264 @ 0x562373c2c440] mmco: unref short failure
[h264 @ 0x556a924f0fc0] mmco: unref short failure
[h264 @ 0x559f9d4eff40] mmco: unref short failure
[h264 @ 0x559f9d4eff40] mmco: unref short failure
[h264 @ 0x559f7d681240] mmco: unref short failure
[h264 @ 0x559b555f54c0] mmco: unref short failure
[h264 @ 0x559b555f54c0] mmco: unref short failure
[h264 @ 0x559b5503a840] mmco: unref short failure
[h264 @ 0x559b5503a840] mmco: unref short failure
[h264 @ 0x556a9457e6c0] mmco: unref short failure
[h264 @ 0x56237ed30600] mmco: unref short failure
[h264 @ 0x556a8d6a7180] mmco: unref short failure
[h264 @ 0x559b4d63d500] mmco: unref short failure
[h264 @ 0x559b4d63d500] mmco: unref short failure
[h264 @ 0x559b4d63d500] mmco: unref short failure
[h264 @ 0x559b4d63d500] mmco: unref short failure
[h264 @ 0x556a78cb0e40] mmco: unref short failure
[h264 @ 0x556a78cb0e40] mmco: unref short failure
  9%|▉         | 174/1945 [52:48<11:21:40, 23.09s/it][h264 @ 0x559b4f1cbf80] mmco: unref short failure
[h264 @ 0x559f870c5780] mmco: unref short failure
[h264 @ 0x559f7d0d6600] mmco: unref short failure
  9%|▉         | 175/1945 [52:55<9:02:07, 18.38s/it] [h264 @ 0x5623801891c0] mmco: unref short failure
[h264 @ 0x5623801891c0] mmco: unref short failure
[h264 @ 0x559b4270e340] mmco: unref short failure
[h264 @ 0x559b4270e340] mmco: unref short failure
[h264 @ 0x559b4270e340] mmco: unref short failure
[h264 @ 0x559b4270e340] mmco: unref short failure
[h264 @ 0x559b34b82880] mmco: unref short failure
[h264 @ 0x559b34b82880] mmco: unref short failure
  9%|▉         | 176/1945 [53:02<7:25:47, 15.12s/it][h264 @ 0x559f7d65f1c0] mmco: unref short failure
[h264 @ 0x559f7d65f1c0] mmco: unref short failure
[h264 @ 0x556a7a975a00] mmco: unref short failure
[h264 @ 0x556a7a975a00] mmco: unref short failure
  9%|▉         | 177/1945 [53:18<7:27:34, 15.19s/it]  9%|▉         | 178/1945 [53:27<6:31:21, 13.29s/it][h264 @ 0x559f99c91cc0] mmco: unref short failure
[h264 @ 0x5623637a5100] mmco: unref short failure
[h264 @ 0x5623637a5100] mmco: unref short failure
[h264 @ 0x556a7e32ba40] mmco: unref short failure
[h264 @ 0x556a7e32ba40] mmco: unref short failure
  9%|▉         | 179/1945 [53:39<6:25:48, 13.11s/it][h264 @ 0x556a7ddfb840] mmco: unref short failure
[h264 @ 0x556a7ddfb840] mmco: unref short failure
[h264 @ 0x556a7ddfb840] mmco: unref short failure
[h264 @ 0x556a7ddfb840] mmco: unref short failure
  9%|▉         | 180/1945 [53:50<6:00:08, 12.24s/it]  9%|▉         | 181/1945 [53:57<5:19:35, 10.87s/it][h264 @ 0x559b36d43780] mmco: unref short failure
[h264 @ 0x559b36d43780] mmco: unref short failure
[h264 @ 0x56236b119a40] mmco: unref short failure
[h264 @ 0x56236b119a40] mmco: unref short failure
[h264 @ 0x556a7857ca40] mmco: unref short failure
[h264 @ 0x556a7857ca40] mmco: unref short failure
[h264 @ 0x559b399ed3c0] mmco: unref short failure
[h264 @ 0x559b399ed3c0] mmco: unref short failure
[h264 @ 0x556a8c8efa80] mmco: unref short failure
[h264 @ 0x556a8c8efa80] mmco: unref short failure
[h264 @ 0x556a8c8efa80] mmco: unref short failure
[h264 @ 0x556a8c8efa80] mmco: unref short failure
[h264 @ 0x556a8c8efa80] mmco: unref short failure
[h264 @ 0x556a8c8efa80] mmco: unref short failure
[h264 @ 0x562369638780] mmco: unref short failure
[h264 @ 0x559b34ca1740] mmco: unref short failure
[h264 @ 0x559b3837bd80] mmco: unref short failure
[h264 @ 0x559b3837bd80] mmco: unref short failure
[h264 @ 0x559b444cb280] mmco: unref short failure
[h264 @ 0x559b444cb280] mmco: unref short failure
[h264 @ 0x556a8558fdc0] mmco: unref short failure
[h264 @ 0x559b39085540] mmco: unref short failure
[h264 @ 0x559b39085540] mmco: unref short failure
[h264 @ 0x5623635df880] mmco: unref short failure
[h264 @ 0x5623635df880] mmco: unref short failure
[h264 @ 0x556a786416c0] mmco: unref short failure
[h264 @ 0x556a786416c0] mmco: unref short failure
[h264 @ 0x556a7e614f00] mmco: unref short failure
[h264 @ 0x556a7e614f00] mmco: unref short failure
[h264 @ 0x556a8d6a7800] mmco: unref short failure
  9%|▉         | 182/1945 [54:45<10:47:10, 22.02s/it][h264 @ 0x5623636c6600] mmco: unref short failure
[h264 @ 0x5623636c6600] mmco: unref short failure
  9%|▉         | 183/1945 [54:55<9:01:00, 18.42s/it] [h264 @ 0x556a79ec2a00] mmco: unref short failure
[h264 @ 0x5623636de680] mmco: unref short failure
  9%|▉         | 184/1945 [55:03<7:29:55, 15.33s/it][h264 @ 0x559b47a65a40] mmco: unref short failure
[h264 @ 0x559b47a65a40] mmco: unref short failure
[h264 @ 0x559b47a65a40] mmco: unref short failure
[h264 @ 0x559b47a65a40] mmco: unref short failure
[h264 @ 0x559f8ff82300] mmco: unref short failure
[h264 @ 0x559f8ff82300] mmco: unref short failure
[h264 @ 0x559f8ff82300] mmco: unref short failure
[h264 @ 0x559f8ff82300] mmco: unref short failure
[h264 @ 0x559f8ff82300] mmco: unref short failure
[h264 @ 0x559f8ff82300] mmco: unref short failure
[h264 @ 0x559f8ff82300] mmco: unref short failure
[h264 @ 0x559b41e11880] mmco: unref short failure
[h264 @ 0x559f8cc0b780] mmco: unref short failure
[h264 @ 0x559f995f3f40] mmco: unref short failure
[h264 @ 0x559f995f3f40] mmco: unref short failure
 10%|▉         | 185/1945 [55:26<8:36:28, 17.61s/it] 10%|▉         | 186/1945 [55:34<7:10:13, 14.68s/it][h264 @ 0x559b3f51c440] mmco: unref short failure
 10%|▉         | 187/1945 [55:42<6:05:38, 12.48s/it][h264 @ 0x559b353b3a00] mmco: unref short failure
[h264 @ 0x559b50885340] mmco: unref short failure
[h264 @ 0x562363740640] mmco: unref short failure
[h264 @ 0x562363740640] mmco: unref short failure
[h264 @ 0x562363740640] mmco: unref short failure
[h264 @ 0x562363740640] mmco: unref short failure
[h264 @ 0x562363740640] mmco: unref short failure
 10%|▉         | 188/1945 [55:50<5:33:51, 11.40s/it][h264 @ 0x559b49778680] mmco: unref short failure
[h264 @ 0x559b49778680] mmco: unref short failure
[h264 @ 0x559b466b1940] mmco: unref short failure
[h264 @ 0x559f97eabec0] mmco: unref short failure
[h264 @ 0x559b3d7c4b00] mmco: unref short failure
[h264 @ 0x559f80ed7100] mmco: unref short failure
 10%|▉         | 189/1945 [55:58<5:02:26, 10.33s/it][h264 @ 0x556a7862e380] mmco: unref short failure
[h264 @ 0x556a7862e380] mmco: unref short failure
[h264 @ 0x562362aa8300] mmco: unref short failure
[h264 @ 0x562362aa8300] mmco: unref short failure
[h264 @ 0x556a7d6068c0] mmco: unref short failure
[h264 @ 0x559b3d7c4b00] mmco: unref short failure
[h264 @ 0x559b3d7c4b00] mmco: unref short failure
[h264 @ 0x556a83211880] mmco: unref short failure
[h264 @ 0x559b4e245ac0] mmco: unref short failure
[h264 @ 0x559b4e245ac0] mmco: unref short failure
[h264 @ 0x559b4e245ac0] mmco: unref short failure
[h264 @ 0x5623661a4600] mmco: unref short failure
[h264 @ 0x5623661a4600] mmco: unref short failure
[h264 @ 0x559f9bc7e0c0] mmco: unref short failure
[h264 @ 0x559f9bc7e0c0] mmco: unref short failure
[h264 @ 0x559b353b40c0] mmco: unref short failure
[h264 @ 0x559b353b40c0] mmco: unref short failure
 10%|▉         | 190/1945 [56:45<10:24:15, 21.34s/it] 10%|▉         | 191/1945 [56:56<8:47:24, 18.04s/it] [h264 @ 0x56236d9837c0] mmco: unref short failure
[h264 @ 0x556a891efc80] mmco: unref short failure
[h264 @ 0x556a891efc80] mmco: unref short failure
 10%|▉         | 192/1945 [57:04<7:19:02, 15.03s/it][h264 @ 0x559b49af0040] mmco: unref short failure
[h264 @ 0x559b49af0040] mmco: unref short failure
[h264 @ 0x559b3648f680] mmco: unref short failure
[h264 @ 0x559f7e716880] mmco: unref short failure
[h264 @ 0x559f7e716880] mmco: unref short failure
[h264 @ 0x559f92362e80] mmco: unref short failure
[h264 @ 0x559f92362e80] mmco: unref short failure
 10%|▉         | 193/1945 [57:37<9:57:16, 20.45s/it][h264 @ 0x559f93434580] mmco: unref short failure
[h264 @ 0x559f93434580] mmco: unref short failure
 10%|▉         | 194/1945 [57:44<8:00:55, 16.48s/it][h264 @ 0x556a7d6066c0] mmco: unref short failure
 10%|█         | 195/1945 [57:52<6:43:40, 13.84s/it][h264 @ 0x562366412dc0] mmco: unref short failure
[h264 @ 0x562366412dc0] mmco: unref short failure
 10%|█         | 196/1945 [57:59<5:43:28, 11.78s/it][h264 @ 0x5623732a8600] mmco: unref short failure
 10%|█         | 197/1945 [58:05<4:57:19, 10.21s/it][h264 @ 0x556a87526a80] mmco: unref short failure
[h264 @ 0x556a87526a80] mmco: unref short failure
[h264 @ 0x559f7eadfc40] mmco: unref short failure
[h264 @ 0x559f87255ac0] mmco: unref short failure
[h264 @ 0x559f87255ac0] mmco: unref short failure
[h264 @ 0x556a796ed940] mmco: unref short failure
[h264 @ 0x556a796ed940] mmco: unref short failure
[h264 @ 0x559b37431c40] mmco: unref short failure
[h264 @ 0x559b37431c40] mmco: unref short failure
[h264 @ 0x556a80864f00] mmco: unref short failure
[h264 @ 0x559b45ed7480] mmco: unref short failure
[h264 @ 0x559b45ed7480] mmco: unref short failure
[h264 @ 0x559b3980cb40] mmco: unref short failure
 10%|█         | 198/1945 [58:51<10:09:22, 20.93s/it] 10%|█         | 199/1945 [58:59<8:13:22, 16.95s/it] 09/09/2024 18:04:21 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 18:04:21 - INFO - __main__ -   start running ret%tv validation...
[h264 @ 0x556a79f94100] mmco: unref short failure
[h264 @ 0x556a79f94100] mmco: unref short failure
[h264 @ 0x556a79f94100] mmco: unref short failure
[h264 @ 0x556a79f94100] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556a817c5200] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556a7fe49cc0] mmco: unref short failure
[h264 @ 0x556a7fe49cc0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556a7f4f5480] mmco: unref short failure
[h264 @ 0x56236eeabf80] mmco: unref short failure
[h264 @ 0x56236eeabf80] mmco: unref short failure
[h264 @ 0x562363b2e780] mmco: unref short failure
[h264 @ 0x556a83211f40] mmco: unref short failure
[h264 @ 0x556a78b99080] mmco: unref short failure
[h264 @ 0x559f8f597c80] mmco: unref short failure
[h264 @ 0x556a790c8b80] mmco: unref short failure
[h264 @ 0x556a7b37f500] mmco: unref short failure
[h264 @ 0x556a7b37f500] mmco: unref short failure
[h264 @ 0x559b3ac7afc0] mmco: unref short failure
[h264 @ 0x559f7d605d40] mmco: unref short failure
[h264 @ 0x559f7d605d40] mmco: unref short failure
[h264 @ 0x559f7d605d40] mmco: unref short failure
[h264 @ 0x559f7d605d40] mmco: unref short failure
[h264 @ 0x56236455e280] mmco: unref short failure
[h264 @ 0x559b577d6240] mmco: unref short failure
[h264 @ 0x56236ad50ec0] mmco: unref short failure
[h264 @ 0x559b36f9b040] mmco: unref short failure
[h264 @ 0x559b36f9b040] mmco: unref short failure
[h264 @ 0x559b36f9b040] mmco: unref short failure
[h264 @ 0x559b36f9b040] mmco: unref short failure
[h264 @ 0x559b36f9b040] mmco: unref short failure
[h264 @ 0x559b36f9b040] mmco: unref short failure
[h264 @ 0x56237fb4e1c0] mmco: unref short failure
[h264 @ 0x556a7b37f500] mmco: unref short failure
[h264 @ 0x556a7b37f500] mmco: unref short failure
[h264 @ 0x559f9cdbfac0] mmco: unref short failure
[h264 @ 0x559f9cdbfac0] mmco: unref short failure
[h264 @ 0x562376f2c100] mmco: unref short failure
[h264 @ 0x562376f2c100] mmco: unref short failure
[h264 @ 0x559b35048880] mmco: unref short failure
[h264 @ 0x559b35048880] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:29,  2.46it/s][A
  1%|          | 2/221 [00:00<01:39,  2.19it/s][A
  1%|▏         | 3/221 [00:01<01:37,  2.23it/s][A
  2%|▏         | 4/221 [00:01<01:19,  2.73it/s][A
  2%|▏         | 5/221 [00:01<01:12,  3.00it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.82it/s][A
  3%|▎         | 7/221 [00:02<00:50,  4.24it/s][A
  4%|▎         | 8/221 [00:02<00:43,  4.86it/s][A
  4%|▍         | 9/221 [00:02<00:47,  4.43it/s][A[h264 @ 0x556a80a6ba80] mmco: unref short failure

  5%|▍         | 10/221 [00:03<01:08,  3.09it/s][A
  5%|▍         | 11/221 [00:03<01:00,  3.48it/s][A
  5%|▌         | 12/221 [00:03<01:07,  3.08it/s][A
  6%|▌         | 13/221 [00:03<01:02,  3.34it/s][A
  6%|▋         | 14/221 [00:04<01:03,  3.24it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.36it/s][A
  7%|▋         | 16/221 [00:04<01:05,  3.15it/s][A
  8%|▊         | 17/221 [00:05<01:38,  2.07it/s][A[h264 @ 0x56237eb1ae00] mmco: unref short failure

  8%|▊         | 18/221 [00:06<01:25,  2.37it/s][A
  9%|▊         | 19/221 [00:06<01:11,  2.83it/s][A
  9%|▉         | 20/221 [00:06<01:02,  3.20it/s][A
 10%|▉         | 21/221 [00:06<01:00,  3.33it/s][A
 10%|▉         | 22/221 [00:07<01:03,  3.12it/s][A
 10%|█         | 23/221 [00:07<00:50,  3.91it/s][A
 11%|█         | 24/221 [00:07<00:43,  4.51it/s][A
 11%|█▏        | 25/221 [00:07<00:48,  4.07it/s][A
 12%|█▏        | 26/221 [00:08<00:59,  3.27it/s][A
 12%|█▏        | 27/221 [00:08<00:48,  4.01it/s][A
 13%|█▎        | 28/221 [00:08<01:13,  2.61it/s][A
 13%|█▎        | 29/221 [00:09<01:01,  3.10it/s][A
 14%|█▎        | 30/221 [00:09<00:51,  3.73it/s][A
 14%|█▍        | 31/221 [00:09<00:50,  3.73it/s][A
 14%|█▍        | 32/221 [00:09<00:44,  4.21it/s][A
 15%|█▍        | 33/221 [00:09<00:39,  4.76it/s][A
 15%|█▌        | 34/221 [00:09<00:34,  5.46it/s][A
 16%|█▌        | 35/221 [00:10<00:41,  4.44it/s][A
 16%|█▋        | 36/221 [00:10<00:47,  3.88it/s][A
 17%|█▋        | 37/221 [00:10<00:51,  3.56it/s][A
 17%|█▋        | 38/221 [00:11<01:02,  2.91it/s][A
 18%|█▊        | 39/221 [00:11<00:50,  3.61it/s][A
 18%|█▊        | 40/221 [00:11<00:49,  3.62it/s][A
 19%|█▊        | 41/221 [00:12<00:45,  3.93it/s][A
 19%|█▉        | 42/221 [00:12<01:09,  2.58it/s][A
 19%|█▉        | 43/221 [00:12<00:59,  2.97it/s][A
 20%|█▉        | 44/221 [00:13<00:48,  3.66it/s][A
 20%|██        | 45/221 [00:14<01:31,  1.92it/s][A
 21%|██        | 46/221 [00:14<01:34,  1.85it/s][A
 21%|██▏       | 47/221 [00:15<01:51,  1.56it/s][A
 22%|██▏       | 48/221 [00:15<01:27,  1.98it/s][A
 22%|██▏       | 49/221 [00:16<01:21,  2.11it/s][A
 23%|██▎       | 50/221 [00:16<01:07,  2.52it/s][A
 23%|██▎       | 51/221 [00:16<00:59,  2.85it/s][A
 24%|██▎       | 52/221 [00:16<00:54,  3.13it/s][A
 24%|██▍       | 53/221 [00:17<00:51,  3.29it/s][A
 24%|██▍       | 54/221 [00:19<02:20,  1.19it/s][A
 25%|██▍       | 55/221 [00:19<02:07,  1.30it/s][A
 25%|██▌       | 56/221 [00:20<01:44,  1.58it/s][A
 26%|██▌       | 57/221 [00:20<01:26,  1.90it/s][A
 26%|██▌       | 58/221 [00:20<01:07,  2.43it/s][A
 27%|██▋       | 59/221 [00:20<00:54,  2.97it/s][A
 27%|██▋       | 60/221 [00:21<01:12,  2.22it/s][A
 28%|██▊       | 61/221 [00:21<01:00,  2.65it/s][A
 28%|██▊       | 62/221 [00:21<00:54,  2.91it/s][A
 29%|██▊       | 63/221 [00:22<00:48,  3.23it/s][A
 29%|██▉       | 64/221 [00:22<00:47,  3.34it/s][A
 29%|██▉       | 65/221 [00:22<00:41,  3.80it/s][A
 30%|██▉       | 66/221 [00:23<01:00,  2.58it/s][A
 30%|███       | 67/221 [00:23<00:57,  2.69it/s][A[h264 @ 0x556a8b634f00] mmco: unref short failure
[h264 @ 0x556a8b634f00] mmco: unref short failure

 31%|███       | 68/221 [00:23<00:46,  3.27it/s][A
 31%|███       | 69/221 [00:24<01:15,  2.02it/s][A
 32%|███▏      | 70/221 [00:24<01:01,  2.46it/s][A
 32%|███▏      | 71/221 [00:25<00:54,  2.74it/s][A
 33%|███▎      | 72/221 [00:25<00:54,  2.75it/s][A
 33%|███▎      | 73/221 [00:26<00:57,  2.55it/s][A
 33%|███▎      | 74/221 [00:26<00:45,  3.24it/s][A
 34%|███▍      | 75/221 [00:26<00:48,  3.02it/s][A
 34%|███▍      | 76/221 [00:26<00:44,  3.24it/s][A
 35%|███▍      | 77/221 [00:27<00:49,  2.90it/s][A
 35%|███▌      | 78/221 [00:27<00:39,  3.61it/s][A
 36%|███▌      | 79/221 [00:27<00:43,  3.25it/s][A
 36%|███▌      | 80/221 [00:27<00:35,  3.92it/s][A
 37%|███▋      | 81/221 [00:28<00:37,  3.73it/s][A
 37%|███▋      | 82/221 [00:28<00:54,  2.53it/s][A[h264 @ 0x556a989117c0] mmco: unref short failure

 38%|███▊      | 83/221 [00:29<00:49,  2.77it/s][A
 38%|███▊      | 84/221 [00:29<00:44,  3.09it/s][A
 38%|███▊      | 85/221 [00:29<00:37,  3.64it/s][A
 39%|███▉      | 86/221 [00:29<00:38,  3.50it/s][A
 39%|███▉      | 87/221 [00:31<01:36,  1.39it/s][A
 40%|███▉      | 88/221 [00:32<01:37,  1.37it/s][A
 40%|████      | 89/221 [00:32<01:17,  1.70it/s][A
 41%|████      | 90/221 [00:32<01:03,  2.06it/s][A
 41%|████      | 91/221 [00:33<00:50,  2.60it/s][A
 42%|████▏     | 92/221 [00:33<00:46,  2.77it/s][A
 42%|████▏     | 93/221 [00:33<00:46,  2.74it/s][A
 43%|████▎     | 94/221 [00:33<00:39,  3.18it/s][A
 43%|████▎     | 95/221 [00:34<00:36,  3.44it/s][A[h264 @ 0x559f812cf780] mmco: unref short failure
[h264 @ 0x559f812cf780] mmco: unref short failure

 43%|████▎     | 96/221 [00:34<00:58,  2.14it/s][A
 44%|████▍     | 97/221 [00:35<00:48,  2.57it/s][A
 44%|████▍     | 98/221 [00:35<00:48,  2.51it/s][A
 45%|████▍     | 99/221 [00:35<00:41,  2.96it/s][A
 45%|████▌     | 100/221 [00:36<00:37,  3.21it/s][A
 46%|████▌     | 101/221 [00:36<00:31,  3.78it/s][A
 46%|████▌     | 102/221 [00:36<00:39,  3.01it/s][A
 47%|████▋     | 103/221 [00:36<00:31,  3.76it/s][A
 47%|████▋     | 104/221 [00:37<00:28,  4.05it/s][A
 48%|████▊     | 105/221 [00:37<00:31,  3.72it/s][A
 48%|████▊     | 106/221 [00:38<00:44,  2.56it/s][A
 48%|████▊     | 107/221 [00:38<00:37,  3.05it/s][A
 49%|████▉     | 108/221 [00:38<00:35,  3.23it/s][A
 49%|████▉     | 109/221 [00:38<00:30,  3.68it/s][A
 50%|████▉     | 110/221 [00:38<00:26,  4.26it/s][A
 50%|█████     | 111/221 [00:39<00:34,  3.18it/s][A
 51%|█████     | 112/221 [00:39<00:31,  3.50it/s][A
 51%|█████     | 113/221 [00:39<00:31,  3.40it/s][A
 52%|█████▏    | 115/221 [00:39<00:20,  5.17it/s][A[h264 @ 0x559f8f5975c0] mmco: unref short failure
[h264 @ 0x559f8f5975c0] mmco: unref short failure
[h264 @ 0x559f8f5975c0] mmco: unref short failure
[h264 @ 0x559f8f5975c0] mmco: unref short failure
[h264 @ 0x559f8f5975c0] mmco: unref short failure
[h264 @ 0x559f8f5975c0] mmco: unref short failure

 52%|█████▏    | 116/221 [00:40<00:41,  2.54it/s][A
 53%|█████▎    | 117/221 [00:41<00:38,  2.69it/s][A
 53%|█████▎    | 118/221 [00:41<00:32,  3.16it/s][A[h264 @ 0x559b41e88a00] mmco: unref short failure
[h264 @ 0x559b41e88a00] mmco: unref short failure

 54%|█████▍    | 119/221 [00:41<00:33,  3.03it/s][A
 54%|█████▍    | 120/221 [00:41<00:28,  3.51it/s][A
 55%|█████▍    | 121/221 [00:42<00:26,  3.78it/s][A
 55%|█████▌    | 122/221 [00:42<00:27,  3.55it/s][A
 56%|█████▌    | 123/221 [00:42<00:24,  4.01it/s][A[h264 @ 0x559b36cd4d80] mmco: unref short failure
[h264 @ 0x559b36cd4d80] mmco: unref short failure

 56%|█████▌    | 124/221 [00:43<00:27,  3.57it/s][A
 57%|█████▋    | 125/221 [00:43<00:31,  3.01it/s][A
 57%|█████▋    | 126/221 [00:43<00:32,  2.95it/s][A[h264 @ 0x56236267f580] mmco: unref short failure

 57%|█████▋    | 127/221 [00:45<01:00,  1.54it/s][A
 58%|█████▊    | 128/221 [00:45<00:52,  1.76it/s][A
 58%|█████▊    | 129/221 [00:45<00:40,  2.29it/s][A
 59%|█████▉    | 130/221 [00:45<00:33,  2.75it/s][A
 59%|█████▉    | 131/221 [00:46<00:26,  3.40it/s][A
 60%|█████▉    | 132/221 [00:47<00:46,  1.91it/s][A
 60%|██████    | 133/221 [00:47<00:39,  2.23it/s][A
 61%|██████    | 134/221 [00:48<00:46,  1.88it/s][A
 61%|██████    | 135/221 [00:48<00:36,  2.34it/s][A
 62%|██████▏   | 136/221 [00:48<00:35,  2.40it/s][A
 62%|██████▏   | 137/221 [00:48<00:30,  2.77it/s][A
 62%|██████▏   | 138/221 [00:49<00:31,  2.66it/s][A
 63%|██████▎   | 139/221 [00:50<00:39,  2.06it/s][A
 63%|██████▎   | 140/221 [00:50<00:35,  2.29it/s][A
 64%|██████▍   | 141/221 [00:50<00:33,  2.41it/s][A
 64%|██████▍   | 142/221 [00:51<00:29,  2.72it/s][A
 65%|██████▍   | 143/221 [00:51<00:28,  2.78it/s][A
 65%|██████▌   | 144/221 [00:51<00:25,  3.04it/s][A
 66%|██████▌   | 146/221 [00:51<00:15,  4.88it/s][A
 67%|██████▋   | 147/221 [00:52<00:16,  4.57it/s][A
 67%|██████▋   | 148/221 [00:52<00:14,  4.96it/s][A
 67%|██████▋   | 149/221 [00:52<00:14,  5.10it/s][A
 68%|██████▊   | 150/221 [00:52<00:13,  5.37it/s][A
 68%|██████▊   | 151/221 [00:53<00:22,  3.17it/s][A[h264 @ 0x559f8a9c9ec0] mmco: unref short failure

 69%|██████▉   | 152/221 [00:54<00:46,  1.49it/s][A
 69%|██████▉   | 153/221 [00:54<00:36,  1.88it/s][A
 70%|██████▉   | 154/221 [00:55<00:29,  2.25it/s][A
 70%|███████   | 155/221 [00:55<00:25,  2.57it/s][A
 71%|███████   | 156/221 [00:55<00:28,  2.29it/s][A
 71%|███████   | 157/221 [00:56<00:31,  2.03it/s][A
 71%|███████▏  | 158/221 [00:56<00:25,  2.47it/s][A
 72%|███████▏  | 160/221 [00:57<00:18,  3.31it/s][A
 73%|███████▎  | 162/221 [00:57<00:13,  4.52it/s][A[h264 @ 0x559b36380300] mmco: unref short failure

 74%|███████▍  | 163/221 [00:57<00:12,  4.68it/s][A
 74%|███████▍  | 164/221 [00:57<00:11,  4.76it/s][A
 75%|███████▍  | 165/221 [00:57<00:10,  5.23it/s][A
 75%|███████▌  | 166/221 [00:58<00:12,  4.29it/s][A
 76%|███████▌  | 167/221 [00:58<00:10,  4.92it/s][A
 76%|███████▌  | 168/221 [00:59<00:25,  2.11it/s][A
 76%|███████▋  | 169/221 [00:59<00:19,  2.71it/s][A[h264 @ 0x559f7d83e080] mmco: unref short failure

 77%|███████▋  | 170/221 [00:59<00:16,  3.06it/s][A
 77%|███████▋  | 171/221 [01:00<00:16,  2.96it/s][A
 78%|███████▊  | 172/221 [01:00<00:14,  3.50it/s][A
 78%|███████▊  | 173/221 [01:00<00:14,  3.36it/s][A
 79%|███████▊  | 174/221 [01:00<00:12,  3.65it/s][A
 79%|███████▉  | 175/221 [01:01<00:12,  3.81it/s][A
 80%|███████▉  | 176/221 [01:01<00:09,  4.54it/s][A
 80%|████████  | 177/221 [01:01<00:08,  5.10it/s][A
 81%|████████  | 178/221 [01:01<00:13,  3.28it/s][A
 81%|████████  | 179/221 [01:02<00:14,  2.86it/s][A
 81%|████████▏ | 180/221 [01:02<00:11,  3.54it/s][A
 82%|████████▏ | 181/221 [01:02<00:09,  4.29it/s][A
 82%|████████▏ | 182/221 [01:03<00:11,  3.31it/s][A
 83%|████████▎ | 183/221 [01:03<00:10,  3.54it/s][A
 83%|████████▎ | 184/221 [01:03<00:10,  3.68it/s][A
 84%|████████▍ | 186/221 [01:03<00:07,  4.50it/s][A
 85%|████████▍ | 187/221 [01:04<00:07,  4.36it/s][A
 85%|████████▌ | 188/221 [01:04<00:07,  4.60it/s][A
 86%|████████▌ | 189/221 [01:04<00:07,  4.54it/s][A
 86%|████████▌ | 190/221 [01:04<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [01:05<00:06,  4.56it/s][A
 87%|████████▋ | 192/221 [01:05<00:06,  4.74it/s][A
 88%|████████▊ | 194/221 [01:06<00:09,  2.75it/s][A
 88%|████████▊ | 195/221 [01:06<00:07,  3.27it/s][A
 89%|████████▊ | 196/221 [01:06<00:06,  3.59it/s][A
 89%|████████▉ | 197/221 [01:06<00:06,  3.87it/s][A
 90%|████████▉ | 198/221 [01:07<00:05,  4.00it/s][A
 90%|█████████ | 199/221 [01:07<00:05,  4.40it/s][A
 90%|█████████ | 200/221 [01:07<00:04,  5.04it/s][A
 91%|█████████ | 201/221 [01:07<00:03,  5.24it/s][A
 91%|█████████▏| 202/221 [01:07<00:03,  5.32it/s][A
 92%|█████████▏| 203/221 [01:07<00:03,  4.80it/s][A
 92%|█████████▏| 204/221 [01:08<00:03,  5.18it/s][A
 93%|█████████▎| 206/221 [01:08<00:03,  3.92it/s][A
 94%|█████████▍| 208/221 [01:09<00:02,  4.94it/s][A
 95%|█████████▍| 209/221 [01:09<00:02,  5.15it/s][A
 95%|█████████▌| 211/221 [01:09<00:01,  5.19it/s][A
 96%|█████████▌| 212/221 [01:09<00:01,  5.08it/s][A
 96%|█████████▋| 213/221 [01:10<00:01,  5.09it/s][A
 97%|█████████▋| 214/221 [01:10<00:02,  3.09it/s][A
 97%|█████████▋| 215/221 [01:10<00:01,  3.43it/s][A
 98%|█████████▊| 216/221 [01:11<00:01,  3.39it/s][A
 98%|█████████▊| 217/221 [01:11<00:01,  3.00it/s][A
 99%|█████████▊| 218/221 [01:11<00:00,  3.12it/s][A
 99%|█████████▉| 219/221 [01:12<00:00,  3.30it/s][A
100%|█████████▉| 220/221 [01:13<00:00,  1.96it/s][A
100%|██████████| 221/221 [01:13<00:00,  2.54it/s][A100%|██████████| 221/221 [01:13<00:00,  3.01it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.78it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.78it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.78it/s][A
  2%|▏         | 5/221 [00:01<00:57,  3.78it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.78it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.78it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.78it/s][A
  4%|▍         | 9/221 [00:02<00:56,  3.78it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.78it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:51,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:22<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:37<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:51<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:29,  7.40it/s][A
  1%|          | 2/221 [00:00<01:01,  3.56it/s][A
  1%|▏         | 3/221 [00:00<01:02,  3.48it/s][A
  2%|▏         | 4/221 [00:01<00:55,  3.93it/s][A
  2%|▏         | 5/221 [00:01<00:47,  4.56it/s][A
  3%|▎         | 7/221 [00:01<00:38,  5.55it/s][A
  4%|▎         | 8/221 [00:01<00:36,  5.77it/s][A
  4%|▍         | 9/221 [00:01<00:39,  5.32it/s][A
  5%|▍         | 10/221 [00:02<01:04,  3.28it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.77it/s][A
  5%|▌         | 12/221 [00:02<00:46,  4.45it/s][A
  6%|▌         | 13/221 [00:03<01:10,  2.94it/s][A
  7%|▋         | 15/221 [00:03<00:52,  3.89it/s][A
  7%|▋         | 16/221 [00:04<01:00,  3.39it/s][A
  8%|▊         | 17/221 [00:04<01:20,  2.55it/s][A
  8%|▊         | 18/221 [00:04<01:09,  2.94it/s][A
  9%|▊         | 19/221 [00:05<00:59,  3.40it/s][A
  9%|▉         | 20/221 [00:05<00:49,  4.10it/s][A
 10%|▉         | 21/221 [00:05<00:42,  4.74it/s][A
 10%|▉         | 22/221 [00:05<00:48,  4.14it/s][A
 10%|█         | 23/221 [00:05<00:39,  4.99it/s][A
 11%|█         | 24/221 [00:05<00:37,  5.21it/s][A
 11%|█▏        | 25/221 [00:06<00:37,  5.16it/s][A
 12%|█▏        | 26/221 [00:06<00:40,  4.83it/s][A
 13%|█▎        | 28/221 [00:06<00:41,  4.66it/s][A
 13%|█▎        | 29/221 [00:07<00:39,  4.90it/s][A
 14%|█▎        | 30/221 [00:07<00:42,  4.45it/s][A
 14%|█▍        | 31/221 [00:07<00:39,  4.81it/s][A
 15%|█▍        | 33/221 [00:07<00:30,  6.22it/s][A
 16%|█▌        | 35/221 [00:08<00:31,  5.99it/s][A
 16%|█▋        | 36/221 [00:08<00:43,  4.25it/s][A
 17%|█▋        | 37/221 [00:08<00:40,  4.50it/s][A
 17%|█▋        | 38/221 [00:09<00:47,  3.84it/s][A
 18%|█▊        | 40/221 [00:09<00:43,  4.11it/s][A
 19%|█▊        | 41/221 [00:09<00:40,  4.48it/s][A
 19%|█▉        | 42/221 [00:09<00:42,  4.16it/s][A
 19%|█▉        | 43/221 [00:10<00:51,  3.43it/s][A
 20%|█▉        | 44/221 [00:10<00:55,  3.20it/s][A
 20%|██        | 45/221 [00:11<00:53,  3.28it/s][A
 21%|██        | 46/221 [00:11<00:46,  3.77it/s][A
 21%|██▏       | 47/221 [00:11<00:44,  3.88it/s][A
 22%|██▏       | 48/221 [00:11<00:37,  4.61it/s][A
 22%|██▏       | 49/221 [00:11<00:35,  4.79it/s][A
 23%|██▎       | 50/221 [00:11<00:36,  4.63it/s][A
 23%|██▎       | 51/221 [00:12<00:32,  5.29it/s][A
 24%|██▎       | 52/221 [00:12<00:31,  5.44it/s][A
 24%|██▍       | 53/221 [00:12<00:29,  5.77it/s][A
 24%|██▍       | 54/221 [00:13<00:53,  3.13it/s][A
 25%|██▍       | 55/221 [00:13<00:49,  3.38it/s][A
 25%|██▌       | 56/221 [00:13<00:39,  4.17it/s][A
 26%|██▌       | 57/221 [00:13<00:38,  4.30it/s][A
 26%|██▌       | 58/221 [00:13<00:37,  4.40it/s][A
 27%|██▋       | 59/221 [00:14<00:34,  4.65it/s][A
 27%|██▋       | 60/221 [00:14<00:48,  3.31it/s][A
 28%|██▊       | 61/221 [00:14<00:41,  3.83it/s][A
 28%|██▊       | 62/221 [00:14<00:41,  3.82it/s][A
 29%|██▊       | 63/221 [00:15<00:42,  3.69it/s][A
 29%|██▉       | 64/221 [00:15<00:49,  3.19it/s][A
 29%|██▉       | 65/221 [00:15<00:42,  3.71it/s][A
 30%|██▉       | 66/221 [00:16<00:52,  2.97it/s][A
 30%|███       | 67/221 [00:16<00:50,  3.03it/s][A
 31%|███       | 69/221 [00:17<01:02,  2.44it/s][A
 32%|███▏      | 70/221 [00:17<00:53,  2.84it/s][A
 32%|███▏      | 71/221 [00:18<00:46,  3.20it/s][A
 33%|███▎      | 72/221 [00:18<00:51,  2.90it/s][A
 33%|███▎      | 73/221 [00:18<00:54,  2.71it/s][A
 34%|███▍      | 75/221 [00:19<00:41,  3.50it/s][A
 34%|███▍      | 76/221 [00:19<00:38,  3.75it/s][A
 35%|███▍      | 77/221 [00:19<00:46,  3.09it/s][A
 35%|███▌      | 78/221 [00:20<00:38,  3.69it/s][A
 36%|███▌      | 79/221 [00:20<00:41,  3.39it/s][A
 36%|███▌      | 80/221 [00:20<00:37,  3.73it/s][A
 37%|███▋      | 81/221 [00:20<00:36,  3.82it/s][A
 37%|███▋      | 82/221 [00:21<00:39,  3.52it/s][A
 38%|███▊      | 83/221 [00:21<00:47,  2.89it/s][A
 38%|███▊      | 84/221 [00:21<00:41,  3.33it/s][A
 39%|███▉      | 86/221 [00:22<00:28,  4.75it/s][A
 39%|███▉      | 87/221 [00:22<00:46,  2.85it/s][A
 40%|███▉      | 88/221 [00:23<00:49,  2.68it/s][A
 40%|████      | 89/221 [00:23<00:43,  3.03it/s][A
 41%|████      | 90/221 [00:23<00:42,  3.11it/s][A
 41%|████      | 91/221 [00:24<00:35,  3.62it/s][A
 42%|████▏     | 92/221 [00:24<00:31,  4.05it/s][A
 42%|████▏     | 93/221 [00:24<00:42,  3.00it/s][A
 43%|████▎     | 94/221 [00:25<00:42,  2.99it/s][A
 43%|████▎     | 95/221 [00:25<00:41,  3.06it/s][A
 43%|████▎     | 96/221 [00:25<00:47,  2.63it/s][A
 44%|████▍     | 97/221 [00:26<00:40,  3.06it/s][A
 44%|████▍     | 98/221 [00:26<00:50,  2.42it/s][A
 45%|████▍     | 99/221 [00:26<00:42,  2.89it/s][A
 45%|████▌     | 100/221 [00:27<00:37,  3.20it/s][A
 46%|████▌     | 101/221 [00:27<00:32,  3.64it/s][A
 46%|████▌     | 102/221 [00:28<00:59,  1.99it/s][A
 47%|████▋     | 104/221 [00:28<00:38,  3.05it/s][A
 48%|████▊     | 105/221 [00:28<00:36,  3.22it/s][A
 48%|████▊     | 106/221 [00:29<00:40,  2.83it/s][A
 48%|████▊     | 107/221 [00:29<00:36,  3.16it/s][A
 49%|████▉     | 108/221 [00:29<00:34,  3.32it/s][A
 49%|████▉     | 109/221 [00:29<00:27,  4.02it/s][A
 50%|████▉     | 110/221 [00:30<00:29,  3.73it/s][A
 50%|█████     | 111/221 [00:30<00:29,  3.77it/s][A
 51%|█████     | 112/221 [00:30<00:28,  3.83it/s][A
 51%|█████     | 113/221 [00:31<00:28,  3.84it/s][A
 52%|█████▏    | 115/221 [00:31<00:21,  4.99it/s][A
 52%|█████▏    | 116/221 [00:31<00:22,  4.72it/s][A
 53%|█████▎    | 117/221 [00:31<00:24,  4.28it/s][A
 53%|█████▎    | 118/221 [00:32<00:22,  4.53it/s][A
 54%|█████▍    | 119/221 [00:32<00:28,  3.64it/s][A
 54%|█████▍    | 120/221 [00:32<00:23,  4.25it/s][A
 55%|█████▍    | 121/221 [00:32<00:20,  4.91it/s][A
 55%|█████▌    | 122/221 [00:32<00:22,  4.41it/s][A
 56%|█████▌    | 123/221 [00:33<00:19,  4.91it/s][A
 56%|█████▌    | 124/221 [00:33<00:23,  4.14it/s][A
 57%|█████▋    | 125/221 [00:33<00:27,  3.55it/s][A
 57%|█████▋    | 126/221 [00:33<00:22,  4.23it/s][A
 57%|█████▋    | 127/221 [00:34<00:27,  3.43it/s][A
 58%|█████▊    | 128/221 [00:34<00:26,  3.53it/s][A
 59%|█████▉    | 130/221 [00:34<00:19,  4.74it/s][A
 59%|█████▉    | 131/221 [00:34<00:16,  5.42it/s][A
 60%|█████▉    | 132/221 [00:36<00:47,  1.86it/s][A
 60%|██████    | 133/221 [00:36<00:42,  2.09it/s][A
 61%|██████    | 134/221 [00:37<00:46,  1.87it/s][A
 61%|██████    | 135/221 [00:38<00:46,  1.83it/s][A
 62%|██████▏   | 136/221 [00:38<00:39,  2.15it/s][A
 62%|██████▏   | 137/221 [00:38<00:33,  2.51it/s][A
 62%|██████▏   | 138/221 [00:38<00:32,  2.58it/s][A
 63%|██████▎   | 139/221 [00:39<00:37,  2.20it/s][A
 63%|██████▎   | 140/221 [00:39<00:33,  2.41it/s][A
 64%|██████▍   | 141/221 [00:40<00:27,  2.95it/s][A
 64%|██████▍   | 142/221 [00:40<00:24,  3.26it/s][A
 65%|██████▍   | 143/221 [00:40<00:31,  2.50it/s][A
 65%|██████▌   | 144/221 [00:41<00:32,  2.35it/s][A
 66%|██████▌   | 146/221 [00:41<00:19,  3.78it/s][A
 67%|██████▋   | 147/221 [00:41<00:20,  3.57it/s][A
 67%|██████▋   | 148/221 [00:42<00:23,  3.09it/s][A
 67%|██████▋   | 149/221 [00:42<00:25,  2.82it/s][A
 68%|██████▊   | 150/221 [00:43<00:23,  3.05it/s][A
 68%|██████▊   | 151/221 [00:43<00:29,  2.37it/s][A
 69%|██████▉   | 152/221 [00:44<00:37,  1.83it/s][A
 69%|██████▉   | 153/221 [00:44<00:28,  2.39it/s][A
 70%|██████▉   | 154/221 [00:44<00:24,  2.76it/s][A
 70%|███████   | 155/221 [00:45<00:23,  2.87it/s][A
 71%|███████   | 156/221 [00:45<00:23,  2.73it/s][A
 71%|███████   | 157/221 [00:45<00:22,  2.81it/s][A
 71%|███████▏  | 158/221 [00:46<00:20,  3.01it/s][A
 72%|███████▏  | 159/221 [00:46<00:16,  3.68it/s][A
 72%|███████▏  | 160/221 [00:46<00:14,  4.09it/s][A
 73%|███████▎  | 161/221 [00:46<00:14,  4.08it/s][A
 74%|███████▍  | 163/221 [00:47<00:11,  4.86it/s][A
 74%|███████▍  | 164/221 [00:47<00:10,  5.53it/s][A
 75%|███████▍  | 165/221 [00:47<00:12,  4.62it/s][A
 75%|███████▌  | 166/221 [00:47<00:11,  4.60it/s][A
 76%|███████▌  | 167/221 [00:47<00:10,  5.24it/s][A
 76%|███████▌  | 168/221 [00:48<00:10,  4.92it/s][A
 76%|███████▋  | 169/221 [00:48<00:09,  5.56it/s][A
 77%|███████▋  | 170/221 [00:48<00:10,  4.71it/s][A
 77%|███████▋  | 171/221 [00:48<00:12,  4.02it/s][A
 78%|███████▊  | 172/221 [00:49<00:11,  4.28it/s][A
 78%|███████▊  | 173/221 [00:49<00:15,  3.18it/s][A
 79%|███████▊  | 174/221 [00:50<00:17,  2.70it/s][A
 79%|███████▉  | 175/221 [00:50<00:15,  2.89it/s][A
 80%|███████▉  | 176/221 [00:50<00:12,  3.67it/s][A
 80%|████████  | 177/221 [00:50<00:10,  4.12it/s][A
 81%|████████  | 178/221 [00:51<00:13,  3.14it/s][A
 81%|████████  | 179/221 [00:51<00:13,  3.08it/s][A
 81%|████████▏ | 180/221 [00:51<00:10,  3.73it/s][A
 82%|████████▏ | 181/221 [00:51<00:09,  4.28it/s][A
 82%|████████▏ | 182/221 [00:52<00:10,  3.87it/s][A
 83%|████████▎ | 183/221 [00:52<00:09,  4.05it/s][A
 83%|████████▎ | 184/221 [00:52<00:09,  4.09it/s][A
 84%|████████▎ | 185/221 [00:52<00:07,  4.85it/s][A
 84%|████████▍ | 186/221 [00:53<00:10,  3.45it/s][A
 85%|████████▍ | 187/221 [00:53<00:09,  3.55it/s][A
 85%|████████▌ | 188/221 [00:53<00:09,  3.53it/s][A
 86%|████████▌ | 189/221 [00:53<00:09,  3.52it/s][A
 86%|████████▌ | 190/221 [00:54<00:09,  3.35it/s][A
 86%|████████▋ | 191/221 [00:54<00:07,  4.09it/s][A
 87%|████████▋ | 192/221 [00:54<00:06,  4.22it/s][A
 88%|████████▊ | 194/221 [00:55<00:06,  3.92it/s][A
 88%|████████▊ | 195/221 [00:55<00:06,  4.03it/s][A
 89%|████████▊ | 196/221 [00:55<00:07,  3.46it/s][A
 89%|████████▉ | 197/221 [00:56<00:07,  3.34it/s][A
 90%|████████▉ | 198/221 [00:56<00:07,  2.90it/s][A
 90%|█████████ | 199/221 [00:56<00:07,  3.14it/s][A
 90%|█████████ | 200/221 [00:57<00:06,  3.08it/s][A
 91%|█████████ | 201/221 [00:57<00:05,  3.61it/s][A
 91%|█████████▏| 202/221 [00:57<00:05,  3.39it/s][A
 92%|█████████▏| 203/221 [00:57<00:05,  3.55it/s][A
 92%|█████████▏| 204/221 [00:58<00:05,  3.36it/s][A
 93%|█████████▎| 206/221 [00:58<00:03,  3.75it/s][A
 94%|█████████▍| 208/221 [00:59<00:02,  4.42it/s][A
 95%|█████████▍| 209/221 [00:59<00:02,  4.45it/s][A
 95%|█████████▌| 211/221 [00:59<00:02,  4.66it/s][A
 96%|█████████▌| 212/221 [00:59<00:02,  4.48it/s][A
 96%|█████████▋| 213/221 [01:00<00:01,  4.66it/s][A
 97%|█████████▋| 214/221 [01:01<00:02,  2.41it/s][A
 97%|█████████▋| 215/221 [01:01<00:02,  2.75it/s][A
 98%|█████████▊| 216/221 [01:01<00:01,  2.74it/s][A
 98%|█████████▊| 217/221 [01:02<00:01,  2.69it/s][A
 99%|█████████▊| 218/221 [01:02<00:01,  2.88it/s][A
 99%|█████████▉| 219/221 [01:02<00:00,  3.14it/s][A
100%|█████████▉| 220/221 [01:02<00:00,  3.62it/s][A
100%|██████████| 221/221 [01:03<00:00,  3.87it/s][A100%|██████████| 221/221 [01:03<00:00,  3.51it/s]
09/09/2024 18:10:08 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 199--===========

09/09/2024 18:10:08 - INFO - __main__ -   {'area_r1': 41.0, 'area_recall': '41.0/69.6/78.5', 'area_ravg': 63.0}
09/09/2024 18:10:08 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 199--===========

09/09/2024 18:10:08 - INFO - __main__ -   {'forward_r1': 39.1, 'forward_recall': '39.1/66.6/75.6', 'forward_ravg': 60.4}
09/09/2024 18:10:08 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 199--===========

09/09/2024 18:10:08 - INFO - __main__ -   {'area_video_r1': 40.0, 'area_video_recall': '40.0/67.2/78.2', 'area_video_ravg': 61.8}
09/09/2024 18:10:08 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 199=======

09/09/2024 18:10:08 - INFO - __main__ -   {'area_video_r1': 40.0, 'area_video_recall': '40.0/67.2/78.2', 'area_video_ravg': 61.8}
09/09/2024 18:10:08 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 199--===========

09/09/2024 18:10:08 - INFO - __main__ -   {'area_video_r1': 51.7, 'area_video_recall': '51.7/75.1/83.1', 'area_video_ravg': 70.0, 'area_video_back_r1': 49.5, 'area_video_back_recall': '49.5/72.9/81.1', 'area_video_back_ravg': 67.8}
09/09/2024 18:10:08 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 149=======

09/09/2024 18:10:08 - INFO - __main__ -   {'area_video_r1': 52.0, 'area_video_recall': '52.0/75.2/82.6', 'area_video_ravg': 69.9, 'area_video_back_r1': 49.5, 'area_video_back_recall': '49.5/73.4/80.8', 'area_video_back_ravg': 67.9}
09/09/2024 18:10:08 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 199--===========

09/09/2024 18:10:08 - INFO - __main__ -   {'video_r1': 40.5, 'video_recall': '40.5/69.2/80.3', 'video_ravg': 63.3}
09/09/2024 18:10:08 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 18:10:08 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 18:10:08 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 199--===========

09/09/2024 18:10:08 - INFO - __main__ -   {'video_r1': 51.2, 'video_recall': '51.2/75.2/82.2', 'video_ravg': 69.6}
09/09/2024 18:10:08 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 149=======

09/09/2024 18:10:08 - INFO - __main__ -   {'video_r1': 51.8, 'video_recall': '51.8/75.1/82.4', 'video_ravg': 69.8}
09/09/2024 18:10:36 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.014747357927262783, 'loss_ret%tv%ta--finetune_area/loss_area': 2.535886287689209, 'loss_ret%tv%ta--finetune_area/total_loss': 2.550633668899536}
 10%|█         | 200/1945 [1:05:16<60:39:18, 125.13s/it] 10%|█         | 201/1945 [1:05:20<43:01:24, 88.81s/it] [h264 @ 0x556a82cbd0c0] mmco: unref short failure
[h264 @ 0x559b4b6cd840] mmco: unref short failure
[h264 @ 0x559b4b6cd840] mmco: unref short failure
 10%|█         | 202/1945 [1:05:25<30:47:08, 63.59s/it] 10%|█         | 203/1945 [1:05:30<22:18:59, 46.12s/it][h264 @ 0x559b3ad4f500] mmco: unref short failure
[h264 @ 0x559b3ad4f500] mmco: unref short failure
 10%|█         | 204/1945 [1:05:37<16:30:35, 34.14s/it][h264 @ 0x556a832121c0] mmco: unref short failure
[h264 @ 0x556a832121c0] mmco: unref short failure
[h264 @ 0x559b503c6ec0] mmco: unref short failure
[h264 @ 0x559b503c6ec0] mmco: unref short failure
[h264 @ 0x559b503c6ec0] mmco: unref short failure
[h264 @ 0x559b503c6ec0] mmco: unref short failure
 11%|█         | 205/1945 [1:05:42<12:20:12, 25.52s/it][h264 @ 0x559f82fc2e80] mmco: unref short failure
 11%|█         | 206/1945 [1:05:49<9:34:20, 19.82s/it] [h264 @ 0x556a88831e40] mmco: unref short failure
[h264 @ 0x556a88831e40] mmco: unref short failure
[h264 @ 0x559b36332100] mmco: unref short failure
[h264 @ 0x559b3980c940] mmco: unref short failure
[h264 @ 0x559b3980c940] mmco: unref short failure
[h264 @ 0x559b3ad4f080] mmco: unref short failure
 11%|█         | 207/1945 [1:05:56<7:45:08, 16.06s/it][h264 @ 0x56237b8fba40] mmco: unref short failure
[h264 @ 0x559f9b443ac0] mmco: unref short failure
[h264 @ 0x559f9b443ac0] mmco: unref short failure
 11%|█         | 208/1945 [1:06:04<6:37:14, 13.72s/it][h264 @ 0x562380157b80] mmco: unref short failure
[h264 @ 0x562380157b80] mmco: unref short failure
 11%|█         | 209/1945 [1:06:11<5:34:42, 11.57s/it][h264 @ 0x559b48b4f240] mmco: unref short failure
[h264 @ 0x559b48b4f240] mmco: unref short failure
[h264 @ 0x559b48b4f240] mmco: unref short failure
[h264 @ 0x559b48b4f240] mmco: unref short failure
[h264 @ 0x559b3f6a1bc0] mmco: unref short failure
[h264 @ 0x559b3f6a1bc0] mmco: unref short failure
 11%|█         | 210/1945 [1:06:19<5:06:47, 10.61s/it][h264 @ 0x56237eb1b000] mmco: unref short failure
[h264 @ 0x56237eb1b000] mmco: unref short failure
 11%|█         | 211/1945 [1:06:26<4:37:23,  9.60s/it][h264 @ 0x559f7f4e23c0] mmco: unref short failure
[h264 @ 0x559f7f4e23c0] mmco: unref short failure
[h264 @ 0x562364e549c0] mmco: unref short failure
 11%|█         | 212/1945 [1:06:34<4:17:21,  8.91s/it] 11%|█         | 213/1945 [1:06:42<4:08:20,  8.60s/it][h264 @ 0x559b350e7e40] mmco: unref short failure
[h264 @ 0x56236da2c440] mmco: unref short failure
[h264 @ 0x56236da2c440] mmco: unref short failure
[h264 @ 0x5623650536c0] mmco: unref short failure
 11%|█         | 214/1945 [1:06:48<3:51:51,  8.04s/it] 11%|█         | 215/1945 [1:06:56<3:49:46,  7.97s/it][h264 @ 0x559b3a5bdb80] mmco: unref short failure
[h264 @ 0x559b356df3c0] mmco: unref short failure
[h264 @ 0x559f995deac0] mmco: unref short failure
[h264 @ 0x559f995deac0] mmco: unref short failure
[h264 @ 0x559f995deac0] mmco: unref short failure
[h264 @ 0x556a7bd3f980] mmco: unref short failure
[h264 @ 0x559b3f6a1dc0] mmco: unref short failure
[h264 @ 0x559b3f6a1dc0] mmco: unref short failure
[h264 @ 0x556a8f041480] mmco: unref short failure
[h264 @ 0x556a8f041480] mmco: unref short failure
 11%|█         | 216/1945 [1:07:04<3:53:29,  8.10s/it][h264 @ 0x556a83fc6e40] mmco: unref short failure
[h264 @ 0x556a83fc6e40] mmco: unref short failure
[h264 @ 0x5623630cf940] mmco: unref short failure
 11%|█         | 217/1945 [1:07:12<3:46:23,  7.86s/it] 11%|█         | 218/1945 [1:07:20<3:49:11,  7.96s/it][h264 @ 0x559b35def8c0] mmco: unref short failure
[h264 @ 0x559b35def8c0] mmco: unref short failure
[h264 @ 0x559b35def8c0] mmco: unref short failure
[h264 @ 0x559f7f671280] mmco: unref short failure
 11%|█▏        | 219/1945 [1:07:30<4:05:58,  8.55s/it][h264 @ 0x556a83b68f00] mmco: unref short failure
[h264 @ 0x556a83b68f00] mmco: unref short failure
[h264 @ 0x556a78c59500] mmco: unref short failure
[h264 @ 0x556a78c59500] mmco: unref short failure
[h264 @ 0x556a78c59500] mmco: unref short failure
[h264 @ 0x556a78c59500] mmco: unref short failure
 11%|█▏        | 220/1945 [1:07:40<4:19:35,  9.03s/it][h264 @ 0x559f9c238c40] mmco: unref short failure
[h264 @ 0x559b35438400] mmco: unref short failure
[h264 @ 0x559b35438400] mmco: unref short failure
[h264 @ 0x559b526436c0] mmco: unref short failure
[h264 @ 0x559b49a57680] mmco: unref short failure
[h264 @ 0x559b49a57680] mmco: unref short failure
 11%|█▏        | 221/1945 [1:07:53<4:51:07, 10.13s/it][h264 @ 0x56236466c180] mmco: unref short failure
 11%|█▏        | 222/1945 [1:08:00<4:30:31,  9.42s/it][h264 @ 0x56237fa26980] mmco: unref short failure
[h264 @ 0x556a7853db40] mmco: unref short failure
[h264 @ 0x556a7853db40] mmco: unref short failure
[h264 @ 0x559b35d91580] mmco: unref short failure
 11%|█▏        | 223/1945 [1:08:09<4:23:12,  9.17s/it][h264 @ 0x562377753380] mmco: unref short failure
[h264 @ 0x562377753380] mmco: unref short failure
[h264 @ 0x559b533cec80] mmco: unref short failure
[h264 @ 0x559b533cec80] mmco: unref short failure
[h264 @ 0x559b54209740] mmco: unref short failure
[h264 @ 0x556a828da8c0] mmco: unref short failure
[h264 @ 0x559b5669b0c0] mmco: unref short failure
[h264 @ 0x559f937e3380] mmco: unref short failure
[h264 @ 0x559f9bc5d4c0] mmco: unref short failure
[h264 @ 0x556a82cfe640] mmco: unref short failure
[h264 @ 0x556a82cfe640] mmco: unref short failure
[h264 @ 0x556a7998dcc0] mmco: unref short failure
[h264 @ 0x559f7f640dc0] mmco: unref short failure
[h264 @ 0x559f7f640dc0] mmco: unref short failure
 12%|█▏        | 224/1945 [1:08:57<9:58:01, 20.85s/it][h264 @ 0x56236f549400] mmco: unref short failure
[h264 @ 0x56236f549400] mmco: unref short failure
 12%|█▏        | 225/1945 [1:09:11<8:53:06, 18.60s/it][h264 @ 0x559b49e5ca80] mmco: unref short failure
[h264 @ 0x556a96c79380] mmco: unref short failure
[h264 @ 0x556a96c79380] mmco: unref short failure
[h264 @ 0x5623804b1440] mmco: unref short failure
[h264 @ 0x5623804b1440] mmco: unref short failure
[h264 @ 0x5623631ba000] mmco: unref short failure
[h264 @ 0x556a7e6cd840] mmco: unref short failure
[h264 @ 0x556a7e6cd840] mmco: unref short failure
 12%|█▏        | 226/1945 [1:09:27<8:32:41, 17.89s/it][h264 @ 0x559f7d123c00] mmco: unref short failure
[h264 @ 0x559f7d123c00] mmco: unref short failure
[h264 @ 0x556a8500acc0] mmco: unref short failure
[h264 @ 0x562367103dc0] mmco: unref short failure
 12%|█▏        | 227/1945 [1:09:34<6:59:43, 14.66s/it][h264 @ 0x556a8d6a7180] mmco: unref short failure
[h264 @ 0x556a8d6a7180] mmco: unref short failure
 12%|█▏        | 228/1945 [1:09:41<5:55:00, 12.41s/it][h264 @ 0x559b363327c0] mmco: unref short failure
[h264 @ 0x559b363327c0] mmco: unref short failure
 12%|█▏        | 229/1945 [1:09:53<5:54:16, 12.39s/it][h264 @ 0x556a8a4ba780] mmco: unref short failure
[h264 @ 0x559b3bd76cc0] mmco: unref short failure
[h264 @ 0x559b3bd76cc0] mmco: unref short failure
[h264 @ 0x562371fb0bc0] mmco: unref short failure
[h264 @ 0x562371fb0bc0] mmco: unref short failure
[h264 @ 0x56237ce11580] mmco: unref short failure
[h264 @ 0x56237ce11580] mmco: unref short failure
[h264 @ 0x559b39de37c0] mmco: unref short failure
 12%|█▏        | 230/1945 [1:10:08<6:14:36, 13.11s/it][h264 @ 0x556a7a8d22c0] mmco: unref short failure
[h264 @ 0x556a7a8d22c0] mmco: unref short failure
[h264 @ 0x556a7a8d22c0] mmco: unref short failure
[h264 @ 0x556a7a8d22c0] mmco: unref short failure
[h264 @ 0x559f93434580] mmco: unref short failure
[h264 @ 0x559f971b9380] mmco: unref short failure
[h264 @ 0x559f971b9380] mmco: unref short failure
[h264 @ 0x559f971b9380] mmco: unref short failure
[h264 @ 0x559f971b9380] mmco: unref short failure
[h264 @ 0x559f971b9380] mmco: unref short failure
[h264 @ 0x559f971b9380] mmco: unref short failure
[h264 @ 0x562371fb7240] mmco: unref short failure
 12%|█▏        | 231/1945 [1:10:15<5:17:31, 11.11s/it][h264 @ 0x556a86593b40] mmco: unref short failure
[h264 @ 0x559f93379fc0] mmco: unref short failure
[h264 @ 0x559f93379fc0] mmco: unref short failure
[h264 @ 0x559f93379fc0] mmco: unref short failure
[h264 @ 0x562365c510c0] mmco: unref short failure
[h264 @ 0x562365c510c0] mmco: unref short failure
[h264 @ 0x56238569ef00] mmco: unref short failure
[h264 @ 0x56238569ef00] mmco: unref short failure
[h264 @ 0x562366feac00] mmco: unref short failure
[h264 @ 0x562366feac00] mmco: unref short failure
not have audios ua_Kowav7hg.20
[h264 @ 0x559f8d8663c0] mmco: unref short failure
[h264 @ 0x559f8d8663c0] mmco: unref short failure
[h264 @ 0x562363abd040] mmco: unref short failure
[h264 @ 0x559b57ab91c0] mmco: unref short failure
[h264 @ 0x559b57ab91c0] mmco: unref short failure
[h264 @ 0x556a77bdda40] mmco: unref short failure
[h264 @ 0x556a77bdda40] mmco: unref short failure
[h264 @ 0x556a77bdda40] mmco: unref short failure
[h264 @ 0x559f8f59a740] mmco: unref short failure
[h264 @ 0x559b3afacf80] mmco: unref short failure
[h264 @ 0x559b3afacf80] mmco: unref short failure
[h264 @ 0x559b4f2396c0] mmco: unref short failure
[h264 @ 0x559b4f2396c0] mmco: unref short failure
[h264 @ 0x559b4f2396c0] mmco: unref short failure
[h264 @ 0x559b4f2396c0] mmco: unref short failure
[h264 @ 0x559f9ae0aac0] mmco: unref short failure
[h264 @ 0x556a7d263a40] mmco: unref short failure
[h264 @ 0x556a7d263a40] mmco: unref short failure
[h264 @ 0x559f80e929c0] mmco: unref short failure
[h264 @ 0x559f80e929c0] mmco: unref short failure
 12%|█▏        | 232/1945 [1:10:57<9:49:02, 20.63s/it][h264 @ 0x5623828eea80] mmco: unref short failure
[h264 @ 0x556a8b1cf480] mmco: unref short failure
[h264 @ 0x556a83b26bc0] mmco: unref short failure
[h264 @ 0x556a83b26bc0] mmco: unref short failure
[h264 @ 0x56237caff000] mmco: unref short failure
[h264 @ 0x56237caff000] mmco: unref short failure
[h264 @ 0x559f8079ea40] mmco: unref short failure
[h264 @ 0x559f8079ea40] mmco: unref short failure
 12%|█▏        | 233/1945 [1:11:11<8:52:14, 18.65s/it][h264 @ 0x559f98f59640] mmco: unref short failure
[h264 @ 0x559f95ce1c80] mmco: unref short failure
[h264 @ 0x559f95ce1c80] mmco: unref short failure
[h264 @ 0x5623632db880] mmco: unref short failure
[h264 @ 0x5623632db880] mmco: unref short failure
[h264 @ 0x559b406c8040] mmco: unref short failure
 12%|█▏        | 234/1945 [1:11:26<8:14:28, 17.34s/it][h264 @ 0x559b34f28340] mmco: unref short failure
[h264 @ 0x559b34f28340] mmco: unref short failure
[h264 @ 0x559b34f28340] mmco: unref short failure
[h264 @ 0x559b34f28340] mmco: unref short failure
[h264 @ 0x559b34f28340] mmco: unref short failure
[h264 @ 0x559b34f28340] mmco: unref short failure
[h264 @ 0x559b3e5c97c0] mmco: unref short failure
 12%|█▏        | 235/1945 [1:11:37<7:25:04, 15.62s/it][h264 @ 0x556a783dc300] mmco: unref short failure
 12%|█▏        | 236/1945 [1:11:50<6:55:48, 14.60s/it][h264 @ 0x559b459ab980] mmco: unref short failure
 12%|█▏        | 237/1945 [1:11:58<6:02:14, 12.72s/it][h264 @ 0x556a93e9b740] mmco: unref short failure
[h264 @ 0x556a93e9b740] mmco: unref short failure
[h264 @ 0x556a93e9b740] mmco: unref short failure
[h264 @ 0x556a93e9b740] mmco: unref short failure
[h264 @ 0x559f8ba90780] mmco: unref short failure
[h264 @ 0x559f8ba90780] mmco: unref short failure
[h264 @ 0x556a78daa340] mmco: unref short failure
[h264 @ 0x556a78daa340] mmco: unref short failure
[h264 @ 0x56237fe148c0] mmco: unref short failure
[h264 @ 0x56237fe148c0] mmco: unref short failure
[h264 @ 0x556a86e4e800] mmco: unref short failure
[h264 @ 0x556a86e4e800] mmco: unref short failure
[h264 @ 0x56237ed30600] mmco: unref short failure
[h264 @ 0x56237ed30600] mmco: unref short failure
 12%|█▏        | 238/1945 [1:12:08<5:35:32, 11.79s/it] 12%|█▏        | 239/1945 [1:12:14<4:52:02, 10.27s/it][h264 @ 0x559b3f5a3fc0] mmco: unref short failure
[h264 @ 0x559b3f5a3fc0] mmco: unref short failure
[h264 @ 0x559b3afacb80] mmco: unref short failure
[h264 @ 0x559f7f255a40] mmco: unref short failure
[h264 @ 0x559b3d3b1680] mmco: unref short failure
[h264 @ 0x559b3d3b1680] mmco: unref short failure
[h264 @ 0x559b3d3b1680] mmco: unref short failure
[h264 @ 0x559b3d3b1680] mmco: unref short failure
[h264 @ 0x559b36a7ce40] mmco: unref short failure
[h264 @ 0x559b36f8e4c0] mmco: unref short failure
[h264 @ 0x559b36f8e4c0] mmco: unref short failure
[h264 @ 0x562368306440] mmco: unref short failure
[h264 @ 0x562368306440] mmco: unref short failure
[h264 @ 0x562368306440] mmco: unref short failure
[h264 @ 0x562368306440] mmco: unref short failure
[h264 @ 0x559f7fa38400] mmco: unref short failure
[h264 @ 0x559f7fa38400] mmco: unref short failure
 12%|█▏        | 240/1945 [1:12:56<9:18:56, 19.67s/it][h264 @ 0x556a802573c0] mmco: unref short failure
[h264 @ 0x56237a6509c0] mmco: unref short failure
 12%|█▏        | 241/1945 [1:13:10<8:30:28, 17.97s/it][h264 @ 0x559f97def380] mmco: unref short failure
[h264 @ 0x559f97def380] mmco: unref short failure
[h264 @ 0x559f97def380] mmco: unref short failure
[h264 @ 0x559f97def380] mmco: unref short failure
[h264 @ 0x559f86e17d00] mmco: unref short failure
 12%|█▏        | 242/1945 [1:13:32<9:03:01, 19.13s/it] 12%|█▏        | 243/1945 [1:13:38<7:15:18, 15.35s/it][h264 @ 0x556a792ba9c0] mmco: unref short failure
[h264 @ 0x556a792ba9c0] mmco: unref short failure
 13%|█▎        | 244/1945 [1:13:50<6:43:13, 14.22s/it][h264 @ 0x56236317ee80] mmco: unref short failure
[h264 @ 0x559b491e28c0] mmco: unref short failure
[h264 @ 0x559b491e28c0] mmco: unref short failure
 13%|█▎        | 245/1945 [1:14:07<7:09:26, 15.16s/it] 13%|█▎        | 246/1945 [1:14:14<5:57:11, 12.61s/it][h264 @ 0x559f91d7c8c0] mmco: unref short failure
[h264 @ 0x559f8f92b4c0] mmco: unref short failure
[h264 @ 0x559f8f92b4c0] mmco: unref short failure
[h264 @ 0x559b3dda3f40] mmco: unref short failure
 13%|█▎        | 247/1945 [1:14:21<5:14:07, 11.10s/it][h264 @ 0x559b35df45c0] mmco: unref short failure
[h264 @ 0x559b35df45c0] mmco: unref short failure
[h264 @ 0x556a88b5c540] mmco: unref short failure
[h264 @ 0x556a88b5c540] mmco: unref short failure
[h264 @ 0x559f97eb83c0] mmco: unref short failure
[h264 @ 0x559f97eb83c0] mmco: unref short failure
[h264 @ 0x559b3a650400] mmco: unref short failure
[h264 @ 0x559b3a650400] mmco: unref short failure
[h264 @ 0x556a79125700] mmco: unref short failure
[h264 @ 0x559f8a9ca340] mmco: unref short failure
[h264 @ 0x556a7ca4f0c0] mmco: unref short failure
[h264 @ 0x559b3d3b1a80] mmco: unref short failure
[h264 @ 0x559b3d3b1a80] mmco: unref short failure
[h264 @ 0x559f8f56ed40] mmco: unref short failure
[h264 @ 0x559f8f56ed40] mmco: unref short failure
[h264 @ 0x559f8f59a2c0] mmco: unref short failure
[h264 @ 0x559f8f59a2c0] mmco: unref short failure
[h264 @ 0x562364e10700] mmco: unref short failure
[h264 @ 0x562364e10700] mmco: unref short failure
[h264 @ 0x556a8ac690c0] mmco: unref short failure
[h264 @ 0x556a8eed0b80] mmco: unref short failure
 13%|█▎        | 248/1945 [1:14:59<8:56:46, 18.98s/it][h264 @ 0x559b4498ed80] mmco: unref short failure
[h264 @ 0x559b44f44540] mmco: unref short failure
[h264 @ 0x559b44f44540] mmco: unref short failure
[h264 @ 0x5623676cd840] mmco: unref short failure
[h264 @ 0x5623676cd840] mmco: unref short failure
[h264 @ 0x559b4cc47540] mmco: unref short failure
[h264 @ 0x559b4cc47540] mmco: unref short failure
[h264 @ 0x556a93539900] mmco: unref short failure
[h264 @ 0x559f7e935580] mmco: unref short failure
[h264 @ 0x559f7e935580] mmco: unref short failure
[h264 @ 0x559f7e935580] mmco: unref short failure
[h264 @ 0x559f7e935580] mmco: unref short failure
[h264 @ 0x559f7d0fec40] mmco: unref short failure
 13%|█▎        | 249/1945 [1:15:23<9:38:11, 20.46s/it]09/09/2024 18:20:45 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 18:20:45 - INFO - __main__ -   start running ret%tv validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556a78c79180] mmco: unref short failure
[h264 @ 0x556a78c79180] mmco: unref short failure
[h264 @ 0x556a78c79180] mmco: unref short failure
[h264 @ 0x556a78c79180] mmco: unref short failure
[h264 @ 0x559b51545e80] mmco: unref short failure
[h264 @ 0x559b51545e80] mmco: unref short failure
[h264 @ 0x559f9103f840] mmco: unref short failure
[h264 @ 0x562380067100] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556a9895e080] mmco: unref short failure
[h264 @ 0x556a9895e080] mmco: unref short failure
[h264 @ 0x556a9895e080] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556a95ef1380] mmco: unref short failure
[h264 @ 0x556a95ef1380] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556a7d44b9c0] mmco: unref short failure
[h264 @ 0x556a7d44b9c0] mmco: unref short failure
[h264 @ 0x56237856e300] mmco: unref short failure
[h264 @ 0x56237856e300] mmco: unref short failure
[h264 @ 0x559f7d9102c0] mmco: unref short failure
[h264 @ 0x559b55dd9380] mmco: unref short failure
[h264 @ 0x559f7fba4540] mmco: unref short failure
[h264 @ 0x559b4e187440] mmco: unref short failure
[h264 @ 0x556a7b985c80] mmco: unref short failure
[h264 @ 0x559b36efff80] mmco: unref short failure
[h264 @ 0x559b36efff80] mmco: unref short failure
[h264 @ 0x559b3553acc0] mmco: unref short failure
[h264 @ 0x556a98855780] mmco: unref short failure
[h264 @ 0x556a98855780] mmco: unref short failure
[h264 @ 0x556a78fc5c80] mmco: unref short failure
[h264 @ 0x556a78fc5c80] mmco: unref short failure
[h264 @ 0x56236bb221c0] mmco: unref short failure
[h264 @ 0x56236bb221c0] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:37,  1.39it/s][A
  1%|          | 2/221 [00:01<02:44,  1.33it/s][A
  1%|▏         | 3/221 [00:01<02:07,  1.71it/s][A
  2%|▏         | 4/221 [00:02<01:34,  2.30it/s][A
  2%|▏         | 5/221 [00:02<01:16,  2.83it/s][A
  3%|▎         | 6/221 [00:02<01:07,  3.18it/s][A
  3%|▎         | 7/221 [00:02<01:02,  3.43it/s][A
  4%|▎         | 8/221 [00:03<01:02,  3.42it/s][A
  4%|▍         | 9/221 [00:03<01:00,  3.51it/s][A
  5%|▍         | 10/221 [00:03<01:15,  2.80it/s][A
  5%|▍         | 11/221 [00:04<01:02,  3.37it/s][A[h264 @ 0x56237c4c5280] mmco: unref short failure
[h264 @ 0x56237c4c5280] mmco: unref short failure

  5%|▌         | 12/221 [00:04<01:15,  2.77it/s][A
  6%|▌         | 13/221 [00:04<01:08,  3.06it/s][A
  6%|▋         | 14/221 [00:05<01:12,  2.84it/s][A
  7%|▋         | 15/221 [00:05<01:05,  3.16it/s][A
  7%|▋         | 16/221 [00:06<01:23,  2.45it/s][A
  8%|▊         | 17/221 [00:06<01:32,  2.20it/s][A
  8%|▊         | 18/221 [00:06<01:22,  2.46it/s][A
  9%|▊         | 19/221 [00:07<01:11,  2.84it/s][A
  9%|▉         | 20/221 [00:07<01:04,  3.13it/s][A
 10%|▉         | 21/221 [00:07<00:58,  3.43it/s][A
 10%|▉         | 22/221 [00:07<00:54,  3.68it/s][A
 10%|█         | 23/221 [00:07<00:44,  4.43it/s][A
 11%|█         | 24/221 [00:08<00:39,  5.03it/s][A
 11%|█▏        | 25/221 [00:08<00:52,  3.73it/s][A
 12%|█▏        | 26/221 [00:08<01:04,  3.02it/s][A
 12%|█▏        | 27/221 [00:09<00:51,  3.74it/s][A
 13%|█▎        | 28/221 [00:10<01:30,  2.14it/s][A
 13%|█▎        | 29/221 [00:10<01:14,  2.57it/s][A
 14%|█▎        | 30/221 [00:10<01:06,  2.87it/s][A
 14%|█▍        | 31/221 [00:10<01:03,  2.99it/s][A[h264 @ 0x559b4b6ccf00] mmco: unref short failure

 14%|█▍        | 32/221 [00:11<01:01,  3.06it/s][A
 15%|█▍        | 33/221 [00:11<00:56,  3.32it/s][A
 15%|█▌        | 34/221 [00:11<00:45,  4.07it/s][A
 16%|█▌        | 35/221 [00:11<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:12<00:53,  3.45it/s][A[h264 @ 0x556a85929340] mmco: unref short failure

 17%|█▋        | 37/221 [00:12<01:05,  2.82it/s][A
 17%|█▋        | 38/221 [00:13<01:11,  2.57it/s][A
 18%|█▊        | 39/221 [00:13<00:57,  3.19it/s][A
 18%|█▊        | 40/221 [00:13<00:53,  3.36it/s][A[h264 @ 0x556a7e54b300] mmco: unref short failure
[h264 @ 0x556a7e54b300] mmco: unref short failure

 19%|█▊        | 41/221 [00:13<00:45,  3.96it/s][A[h264 @ 0x556a7e54b300] mmco: unref short failure

 19%|█▉        | 42/221 [00:14<01:13,  2.43it/s][A
 19%|█▉        | 43/221 [00:14<00:58,  3.06it/s][A
 20%|█▉        | 44/221 [00:14<00:46,  3.77it/s][A[h264 @ 0x559b508eae80] mmco: unref short failure
[h264 @ 0x559b508eae80] mmco: unref short failure
[h264 @ 0x559b508eae80] mmco: unref short failure
[h264 @ 0x559b508eae80] mmco: unref short failure

 20%|██        | 45/221 [00:15<01:14,  2.36it/s][A
 21%|██        | 46/221 [00:15<01:17,  2.26it/s][A
 21%|██▏       | 47/221 [00:16<01:21,  2.14it/s][A
 22%|██▏       | 48/221 [00:16<01:03,  2.73it/s][A
 22%|██▏       | 49/221 [00:17<01:07,  2.54it/s][A
 23%|██▎       | 50/221 [00:17<00:57,  3.00it/s][A[h264 @ 0x559f9a4d6780] mmco: unref short failure
[h264 @ 0x559f9a4d6780] mmco: unref short failure

 23%|██▎       | 51/221 [00:17<00:46,  3.64it/s][A
 24%|██▎       | 52/221 [00:17<00:41,  4.05it/s][A
 24%|██▍       | 53/221 [00:17<00:40,  4.15it/s][A
 24%|██▍       | 54/221 [00:18<01:28,  1.90it/s][A
 25%|██▍       | 55/221 [00:19<01:34,  1.76it/s][A
 25%|██▌       | 56/221 [00:19<01:17,  2.14it/s][A
 26%|██▌       | 57/221 [00:20<01:08,  2.38it/s][A
 26%|██▌       | 58/221 [00:20<00:57,  2.82it/s][A
 27%|██▋       | 59/221 [00:20<00:49,  3.27it/s][A
 27%|██▋       | 60/221 [00:21<01:17,  2.08it/s][A
 28%|██▊       | 61/221 [00:21<01:06,  2.41it/s][A
 28%|██▊       | 62/221 [00:22<01:00,  2.62it/s][A
 29%|██▊       | 63/221 [00:22<01:01,  2.57it/s][A
 29%|██▉       | 64/221 [00:22<00:55,  2.81it/s][A
 29%|██▉       | 65/221 [00:22<00:48,  3.23it/s][A
 30%|██▉       | 66/221 [00:23<00:49,  3.12it/s][A
 30%|███       | 67/221 [00:23<01:07,  2.28it/s][A
 31%|███       | 68/221 [00:24<00:52,  2.90it/s][A[h264 @ 0x559f7da6e100] mmco: unref short failure
[h264 @ 0x559f7da6e100] mmco: unref short failure

 31%|███       | 69/221 [00:24<01:03,  2.40it/s][A
 32%|███▏      | 70/221 [00:24<00:52,  2.90it/s][A
 32%|███▏      | 71/221 [00:25<00:50,  2.96it/s][A[h264 @ 0x559b46c82d80] mmco: unref short failure

 33%|███▎      | 72/221 [00:25<01:05,  2.27it/s][A
 33%|███▎      | 73/221 [00:26<01:03,  2.33it/s][A
 33%|███▎      | 74/221 [00:26<00:50,  2.88it/s][A
 34%|███▍      | 75/221 [00:26<00:48,  2.99it/s][A
 34%|███▍      | 76/221 [00:26<00:44,  3.25it/s][A
[h264 @ 0x559b39de1700] mmco: unref short failure
[h264 @ 0x559b39de1700] mmco: unref short failure
 35%|███▍      | 77/221 [00:27<00:41,  3.50it/s][A
 35%|███▌      | 78/221 [00:27<00:36,  3.94it/s][A
 36%|███▌      | 79/221 [00:28<00:53,  2.66it/s][A
 36%|███▌      | 80/221 [00:28<00:45,  3.07it/s][A
 37%|███▋      | 81/221 [00:28<00:48,  2.91it/s][A
 37%|███▋      | 82/221 [00:29<00:58,  2.36it/s][A
 38%|███▊      | 83/221 [00:29<00:52,  2.61it/s][A
 38%|███▊      | 84/221 [00:29<00:51,  2.65it/s][A
 38%|███▊      | 85/221 [00:30<00:42,  3.23it/s][A
 39%|███▉      | 86/221 [00:30<00:36,  3.70it/s][A[h264 @ 0x559b51a74440] mmco: unref short failure

 39%|███▉      | 87/221 [00:31<01:05,  2.05it/s][A
 40%|███▉      | 88/221 [00:32<01:21,  1.63it/s][A
 40%|████      | 89/221 [00:32<01:09,  1.91it/s][A[h264 @ 0x556a7b216fc0] mmco: unref short failure
[h264 @ 0x556a7b216fc0] mmco: unref short failure

 41%|████      | 90/221 [00:32<01:01,  2.13it/s][A
 41%|████      | 91/221 [00:32<00:47,  2.73it/s][A
 42%|████▏     | 92/221 [00:33<00:48,  2.66it/s][A
 42%|████▏     | 93/221 [00:33<00:45,  2.83it/s][A
 43%|████▎     | 94/221 [00:33<00:38,  3.26it/s][A
 43%|████▎     | 95/221 [00:34<00:41,  3.05it/s][A
 43%|████▎     | 96/221 [00:34<00:37,  3.35it/s][A
 44%|████▍     | 97/221 [00:34<00:33,  3.75it/s][A
 44%|████▍     | 98/221 [00:34<00:31,  3.90it/s][A
 45%|████▍     | 99/221 [00:34<00:26,  4.59it/s][A
 45%|████▌     | 100/221 [00:35<00:27,  4.41it/s][A
 46%|████▌     | 101/221 [00:35<00:26,  4.45it/s][A
 46%|████▌     | 102/221 [00:35<00:29,  4.07it/s][A
 47%|████▋     | 103/221 [00:35<00:24,  4.84it/s][A
 47%|████▋     | 104/221 [00:35<00:20,  5.64it/s][A
 48%|████▊     | 105/221 [00:36<00:20,  5.54it/s][A[h264 @ 0x56237fc85e40] mmco: unref short failure
[h264 @ 0x56237fc85e40] mmco: unref short failure
[h264 @ 0x56237fc85e40] mmco: unref short failure
[h264 @ 0x56237fc85e40] mmco: unref short failure
[h264 @ 0x56237fc85e40] mmco: unref short failure

 48%|████▊     | 106/221 [00:37<00:48,  2.40it/s][A
 48%|████▊     | 107/221 [00:37<00:39,  2.91it/s][A
 49%|████▉     | 108/221 [00:37<00:35,  3.16it/s][A
 49%|████▉     | 109/221 [00:37<00:32,  3.43it/s][A
 50%|████▉     | 110/221 [00:38<00:35,  3.08it/s][A
 50%|█████     | 111/221 [00:38<00:45,  2.42it/s][A
 51%|█████     | 112/221 [00:39<00:37,  2.87it/s][A[h264 @ 0x56237c37d200] mmco: unref short failure
[h264 @ 0x56237c37d200] mmco: unref short failure

 51%|█████     | 113/221 [00:39<00:38,  2.81it/s][A
 52%|█████▏    | 114/221 [00:39<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:39<00:25,  4.21it/s][A
 52%|█████▏    | 116/221 [00:40<00:45,  2.32it/s][A
 53%|█████▎    | 117/221 [00:40<00:41,  2.52it/s][A
 53%|█████▎    | 118/221 [00:41<00:36,  2.79it/s][A
 54%|█████▍    | 119/221 [00:41<00:39,  2.61it/s][A
 54%|█████▍    | 120/221 [00:41<00:33,  2.99it/s][A
 55%|█████▍    | 121/221 [00:41<00:27,  3.68it/s][A
 55%|█████▌    | 122/221 [00:42<00:26,  3.81it/s][A
 56%|█████▌    | 123/221 [00:42<00:23,  4.18it/s][A
 56%|█████▌    | 124/221 [00:42<00:24,  3.98it/s][A
 57%|█████▋    | 125/221 [00:43<00:28,  3.35it/s][A
 57%|█████▋    | 126/221 [00:43<00:27,  3.50it/s][A
 57%|█████▋    | 127/221 [00:43<00:34,  2.74it/s][A
 58%|█████▊    | 128/221 [00:44<00:33,  2.78it/s][A
 58%|█████▊    | 129/221 [00:44<00:26,  3.52it/s][A
 59%|█████▉    | 130/221 [00:44<00:26,  3.43it/s][A
 59%|█████▉    | 131/221 [00:44<00:24,  3.65it/s][A
 60%|█████▉    | 132/221 [00:45<00:23,  3.74it/s][A
 60%|██████    | 133/221 [00:45<00:27,  3.25it/s][A
 61%|██████    | 134/221 [00:45<00:29,  2.95it/s][A
 61%|██████    | 135/221 [00:46<00:27,  3.12it/s][A
 62%|██████▏   | 136/221 [00:46<00:26,  3.17it/s][A
 62%|██████▏   | 137/221 [00:46<00:22,  3.67it/s][A
 62%|██████▏   | 138/221 [00:47<00:25,  3.24it/s][A
 63%|██████▎   | 139/221 [00:47<00:29,  2.74it/s][A
 63%|██████▎   | 140/221 [00:47<00:28,  2.86it/s][A
 64%|██████▍   | 141/221 [00:48<00:27,  2.90it/s][A[h264 @ 0x556a8d75b300] mmco: unref short failure
[h264 @ 0x556a8d75b300] mmco: unref short failure

 64%|██████▍   | 142/221 [00:48<00:26,  3.02it/s][A
 65%|██████▍   | 143/221 [00:48<00:25,  3.12it/s][A
 65%|██████▌   | 144/221 [00:49<00:24,  3.16it/s][A
 66%|██████▌   | 145/221 [00:49<00:20,  3.69it/s][A
 66%|██████▌   | 146/221 [00:49<00:18,  4.10it/s][A
 67%|██████▋   | 147/221 [00:49<00:19,  3.87it/s][A
 67%|██████▋   | 148/221 [00:50<00:20,  3.58it/s][A
 67%|██████▋   | 149/221 [00:50<00:18,  3.81it/s][A[h264 @ 0x562377ec0d40] mmco: unref short failure
[h264 @ 0x562377ec0d40] mmco: unref short failure

 68%|██████▊   | 150/221 [00:50<00:17,  4.04it/s][A
 68%|██████▊   | 151/221 [00:51<00:24,  2.83it/s][A
 69%|██████▉   | 152/221 [00:52<00:42,  1.61it/s][A
 69%|██████▉   | 153/221 [00:52<00:36,  1.88it/s][A
 70%|██████▉   | 154/221 [00:52<00:28,  2.33it/s][A
 70%|███████   | 155/221 [00:53<00:23,  2.79it/s][A
 71%|███████   | 156/221 [00:53<00:27,  2.37it/s][A
 71%|███████   | 157/221 [00:54<00:28,  2.28it/s][A
 71%|███████▏  | 158/221 [00:54<00:23,  2.67it/s][A
 72%|███████▏  | 159/221 [00:54<00:18,  3.38it/s][A
 72%|███████▏  | 160/221 [00:54<00:18,  3.27it/s][A
 73%|███████▎  | 162/221 [00:55<00:15,  3.81it/s][A
 74%|███████▍  | 163/221 [00:55<00:15,  3.80it/s][A
 74%|███████▍  | 164/221 [00:55<00:14,  3.84it/s][A
 75%|███████▍  | 165/221 [00:55<00:13,  4.23it/s][A
 75%|███████▌  | 166/221 [00:56<00:17,  3.18it/s][A
 76%|███████▌  | 167/221 [00:56<00:14,  3.78it/s][A
 76%|███████▌  | 168/221 [00:57<00:21,  2.51it/s][A
 76%|███████▋  | 169/221 [00:57<00:16,  3.13it/s][A
 77%|███████▋  | 170/221 [00:57<00:15,  3.29it/s][A
 77%|███████▋  | 171/221 [00:58<00:17,  2.92it/s][A
 78%|███████▊  | 172/221 [00:58<00:13,  3.68it/s][A
 78%|███████▊  | 173/221 [00:58<00:13,  3.60it/s][A
 79%|███████▊  | 174/221 [00:58<00:11,  3.98it/s][A
 79%|███████▉  | 175/221 [00:58<00:12,  3.83it/s][A
 80%|███████▉  | 176/221 [00:59<00:10,  4.22it/s][A
 80%|████████  | 177/221 [00:59<00:09,  4.74it/s][A
 81%|████████  | 178/221 [00:59<00:10,  4.19it/s][A
 81%|████████  | 179/221 [00:59<00:11,  3.76it/s][A
 82%|████████▏ | 181/221 [01:00<00:08,  4.79it/s][A
 82%|████████▏ | 182/221 [01:00<00:08,  4.79it/s][A
 83%|████████▎ | 183/221 [01:00<00:07,  4.93it/s][A
 83%|████████▎ | 184/221 [01:00<00:07,  4.69it/s][A[h264 @ 0x559f98f59640] mmco: unref short failure
[h264 @ 0x559f98f59640] mmco: unref short failure

 84%|████████▍ | 186/221 [01:01<00:06,  5.06it/s][A
 85%|████████▍ | 187/221 [01:01<00:07,  4.37it/s][A
 85%|████████▌ | 188/221 [01:01<00:07,  4.40it/s][A
 86%|████████▌ | 189/221 [01:02<00:07,  4.12it/s][A
 86%|████████▌ | 190/221 [01:02<00:08,  3.59it/s][A
 86%|████████▋ | 191/221 [01:02<00:07,  4.25it/s][A
 87%|████████▋ | 192/221 [01:02<00:06,  4.20it/s][A
 88%|████████▊ | 194/221 [01:03<00:11,  2.45it/s][A
 88%|████████▊ | 195/221 [01:04<00:09,  2.82it/s][A
 89%|████████▊ | 196/221 [01:04<00:08,  3.01it/s][A
 89%|████████▉ | 197/221 [01:04<00:07,  3.41it/s][A
 90%|████████▉ | 198/221 [01:04<00:05,  3.83it/s][A
 90%|█████████ | 200/221 [01:05<00:04,  4.52it/s][A
 91%|█████████ | 201/221 [01:05<00:04,  4.80it/s][A
 91%|█████████▏| 202/221 [01:05<00:04,  4.57it/s][A
 92%|█████████▏| 203/221 [01:06<00:05,  3.58it/s][A
 92%|█████████▏| 204/221 [01:06<00:04,  3.84it/s][A[h264 @ 0x559f7fba4540] mmco: unref short failure

 93%|█████████▎| 206/221 [01:07<00:05,  2.84it/s][A
 94%|█████████▍| 208/221 [01:07<00:03,  3.94it/s][A
 95%|█████████▍| 209/221 [01:07<00:02,  4.08it/s][A
 95%|█████████▌| 210/221 [01:07<00:02,  4.62it/s][A
 95%|█████████▌| 211/221 [01:08<00:02,  3.95it/s][A
 96%|█████████▌| 212/221 [01:08<00:02,  4.23it/s][A
 96%|█████████▋| 213/221 [01:08<00:01,  4.24it/s][A
 97%|█████████▋| 214/221 [01:08<00:01,  4.26it/s][A
 97%|█████████▋| 215/221 [01:08<00:01,  4.11it/s][A
 98%|█████████▊| 216/221 [01:09<00:01,  3.57it/s][A
 98%|█████████▊| 217/221 [01:09<00:01,  3.24it/s][A[h264 @ 0x559f94d7bb80] mmco: unref short failure

 99%|█████████▊| 218/221 [01:09<00:00,  3.38it/s][A
 99%|█████████▉| 219/221 [01:10<00:00,  3.55it/s][A
100%|█████████▉| 220/221 [01:11<00:00,  1.86it/s][A
100%|██████████| 221/221 [01:11<00:00,  2.28it/s][A100%|██████████| 221/221 [01:11<00:00,  3.09it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.78it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.78it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.78it/s][A
  2%|▏         | 5/221 [00:01<00:57,  3.78it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.78it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.78it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.78it/s][A
  4%|▍         | 9/221 [00:02<00:56,  3.78it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:51,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:22<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:37<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:51<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:36,  5.99it/s][A
  1%|          | 2/221 [00:00<01:08,  3.21it/s][A
  1%|▏         | 3/221 [00:00<01:06,  3.27it/s][A
  2%|▏         | 4/221 [00:01<00:58,  3.70it/s][A
  2%|▏         | 5/221 [00:01<00:50,  4.26it/s][A
  3%|▎         | 6/221 [00:01<00:40,  5.28it/s][A
  3%|▎         | 7/221 [00:01<00:46,  4.58it/s][A
  4%|▎         | 8/221 [00:01<00:48,  4.35it/s][A
  4%|▍         | 9/221 [00:02<00:48,  4.41it/s][A
  5%|▍         | 10/221 [00:02<01:06,  3.18it/s][A
  5%|▍         | 11/221 [00:02<00:57,  3.66it/s][A
  5%|▌         | 12/221 [00:02<00:49,  4.25it/s][A
  6%|▌         | 13/221 [00:03<01:12,  2.85it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<01:05,  3.11it/s][A
  8%|▊         | 17/221 [00:05<01:25,  2.39it/s][A
  8%|▊         | 18/221 [00:05<01:13,  2.75it/s][A
  9%|▊         | 19/221 [00:05<01:11,  2.83it/s][A
  9%|▉         | 20/221 [00:05<00:58,  3.43it/s][A
 10%|▉         | 21/221 [00:05<00:51,  3.86it/s][A
 10%|▉         | 22/221 [00:06<00:49,  4.01it/s][A
 10%|█         | 23/221 [00:06<00:41,  4.80it/s][A
 11%|█         | 24/221 [00:06<00:39,  5.00it/s][A
 11%|█▏        | 25/221 [00:06<00:41,  4.76it/s][A
 12%|█▏        | 26/221 [00:06<00:43,  4.48it/s][A
 12%|█▏        | 27/221 [00:07<00:37,  5.22it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.83it/s][A
 13%|█▎        | 29/221 [00:07<00:41,  4.58it/s][A
 14%|█▎        | 30/221 [00:07<00:44,  4.31it/s][A
 14%|█▍        | 31/221 [00:08<00:43,  4.38it/s][A
 15%|█▍        | 33/221 [00:08<00:33,  5.69it/s][A
 16%|█▌        | 35/221 [00:08<00:32,  5.76it/s][A
 16%|█▋        | 36/221 [00:09<00:43,  4.22it/s][A
 17%|█▋        | 37/221 [00:09<00:42,  4.37it/s][A
 17%|█▋        | 38/221 [00:09<00:48,  3.80it/s][A
 18%|█▊        | 40/221 [00:10<00:41,  4.33it/s][A
 19%|█▊        | 41/221 [00:10<00:39,  4.60it/s][A
 19%|█▉        | 42/221 [00:10<00:43,  4.07it/s][A
 19%|█▉        | 43/221 [00:10<00:51,  3.43it/s][A
 20%|█▉        | 44/221 [00:11<00:51,  3.45it/s][A
 20%|██        | 45/221 [00:11<00:49,  3.57it/s][A
 21%|██        | 46/221 [00:11<00:41,  4.19it/s][A
 21%|██▏       | 47/221 [00:11<00:42,  4.13it/s][A
 22%|██▏       | 48/221 [00:12<00:36,  4.74it/s][A
 22%|██▏       | 49/221 [00:12<00:37,  4.62it/s][A
 23%|██▎       | 50/221 [00:12<00:42,  4.06it/s][A
 23%|██▎       | 51/221 [00:12<00:35,  4.75it/s][A
 24%|██▎       | 52/221 [00:12<00:33,  5.00it/s][A
 24%|██▍       | 53/221 [00:13<00:29,  5.65it/s][A
 24%|██▍       | 54/221 [00:13<00:56,  2.95it/s][A
 25%|██▍       | 55/221 [00:13<00:50,  3.28it/s][A
 25%|██▌       | 56/221 [00:14<00:41,  3.98it/s][A
 26%|██▌       | 57/221 [00:14<00:38,  4.22it/s][A
 26%|██▌       | 58/221 [00:14<00:36,  4.44it/s][A
 27%|██▋       | 59/221 [00:14<00:36,  4.50it/s][A
 27%|██▋       | 60/221 [00:15<00:41,  3.89it/s][A
 28%|██▊       | 61/221 [00:15<00:36,  4.37it/s][A
 28%|██▊       | 62/221 [00:15<00:37,  4.24it/s][A
 29%|██▊       | 63/221 [00:15<00:36,  4.38it/s][A
 29%|██▉       | 64/221 [00:16<00:47,  3.30it/s][A
 29%|██▉       | 65/221 [00:16<00:40,  3.84it/s][A
 30%|██▉       | 66/221 [00:16<00:48,  3.19it/s][A
 30%|███       | 67/221 [00:17<00:52,  2.93it/s][A
 31%|███       | 68/221 [00:17<00:42,  3.63it/s][A
 31%|███       | 69/221 [00:17<00:56,  2.69it/s][A
 32%|███▏      | 70/221 [00:18<00:46,  3.27it/s][A
 32%|███▏      | 71/221 [00:18<00:41,  3.62it/s][A
 33%|███▎      | 72/221 [00:18<00:46,  3.23it/s][A
 33%|███▎      | 73/221 [00:19<00:50,  2.93it/s][A
 33%|███▎      | 74/221 [00:19<00:39,  3.70it/s][A
 34%|███▍      | 75/221 [00:19<00:40,  3.64it/s][A
 34%|███▍      | 76/221 [00:19<00:35,  4.03it/s][A
 35%|███▍      | 77/221 [00:19<00:33,  4.27it/s][A
 35%|███▌      | 78/221 [00:19<00:28,  4.96it/s][A
 36%|███▌      | 79/221 [00:20<00:41,  3.45it/s][A
 36%|███▌      | 80/221 [00:20<00:37,  3.77it/s][A
 37%|███▋      | 81/221 [00:20<00:35,  3.92it/s][A
 37%|███▋      | 82/221 [00:21<00:37,  3.71it/s][A
 38%|███▊      | 83/221 [00:21<00:43,  3.18it/s][A
 38%|███▊      | 84/221 [00:21<00:36,  3.72it/s][A
 38%|███▊      | 85/221 [00:21<00:29,  4.55it/s][A
 39%|███▉      | 86/221 [00:22<00:26,  5.04it/s][A
 39%|███▉      | 87/221 [00:22<00:55,  2.43it/s][A
 40%|███▉      | 88/221 [00:23<00:58,  2.27it/s][A
 40%|████      | 89/221 [00:23<00:50,  2.60it/s][A
 41%|████      | 90/221 [00:23<00:46,  2.79it/s][A
 41%|████      | 91/221 [00:24<00:38,  3.39it/s][A
 42%|████▏     | 92/221 [00:24<00:35,  3.61it/s][A
 42%|████▏     | 93/221 [00:24<00:46,  2.77it/s][A
 43%|████▎     | 94/221 [00:25<00:43,  2.95it/s][A
 43%|████▎     | 95/221 [00:25<00:41,  3.02it/s][A
 43%|████▎     | 96/221 [00:25<00:37,  3.32it/s][A
 44%|████▍     | 97/221 [00:25<00:34,  3.63it/s][A
 44%|████▍     | 98/221 [00:26<00:34,  3.57it/s][A
 45%|████▍     | 99/221 [00:26<00:30,  4.04it/s][A
 45%|████▌     | 100/221 [00:26<00:29,  4.11it/s][A
 46%|████▌     | 101/221 [00:26<00:29,  4.13it/s][A
 46%|████▌     | 102/221 [00:27<00:49,  2.41it/s][A
 47%|████▋     | 103/221 [00:27<00:38,  3.09it/s][A
 47%|████▋     | 104/221 [00:28<00:33,  3.54it/s][A
 48%|████▊     | 105/221 [00:28<00:29,  3.93it/s][A
 48%|████▊     | 106/221 [00:28<00:37,  3.07it/s][A
 48%|████▊     | 107/221 [00:28<00:34,  3.29it/s][A
 49%|████▉     | 108/221 [00:29<00:33,  3.36it/s][A
 49%|████▉     | 109/221 [00:29<00:27,  4.08it/s][A
 50%|████▉     | 110/221 [00:29<00:28,  3.89it/s][A
 50%|█████     | 111/221 [00:29<00:31,  3.52it/s][A
 51%|█████     | 112/221 [00:30<00:29,  3.64it/s][A
 51%|█████     | 113/221 [00:30<00:27,  3.90it/s][A
 52%|█████▏    | 115/221 [00:30<00:21,  4.93it/s][A
 52%|█████▏    | 116/221 [00:30<00:22,  4.61it/s][A
 53%|█████▎    | 117/221 [00:31<00:25,  4.13it/s][A
 53%|█████▎    | 118/221 [00:31<00:24,  4.20it/s][A
 54%|█████▍    | 119/221 [00:31<00:30,  3.38it/s][A
 54%|█████▍    | 120/221 [00:32<00:27,  3.73it/s][A
 55%|█████▌    | 122/221 [00:32<00:22,  4.38it/s][A
 56%|█████▌    | 123/221 [00:32<00:22,  4.37it/s][A
 56%|█████▌    | 124/221 [00:33<00:25,  3.85it/s][A
 57%|█████▋    | 125/221 [00:33<00:27,  3.46it/s][A
 57%|█████▋    | 126/221 [00:33<00:24,  3.84it/s][A
 57%|█████▋    | 127/221 [00:34<00:28,  3.32it/s][A
 58%|█████▊    | 128/221 [00:34<00:26,  3.46it/s][A
 59%|█████▉    | 130/221 [00:34<00:20,  4.42it/s][A
 59%|█████▉    | 131/221 [00:34<00:18,  4.90it/s][A
 60%|█████▉    | 132/221 [00:35<00:30,  2.87it/s][A
 60%|██████    | 133/221 [00:35<00:27,  3.15it/s][A
 61%|██████    | 134/221 [00:36<00:31,  2.77it/s][A
 61%|██████    | 135/221 [00:36<00:33,  2.54it/s][A
 62%|██████▏   | 136/221 [00:36<00:29,  2.84it/s][A
 62%|██████▏   | 137/221 [00:37<00:26,  3.20it/s][A
 62%|██████▏   | 138/221 [00:37<00:26,  3.11it/s][A
 63%|██████▎   | 139/221 [00:38<00:31,  2.60it/s][A
 63%|██████▎   | 140/221 [00:38<00:28,  2.82it/s][A
 64%|██████▍   | 141/221 [00:38<00:24,  3.30it/s][A
 64%|██████▍   | 142/221 [00:38<00:21,  3.65it/s][A
 65%|██████▍   | 143/221 [00:39<00:31,  2.45it/s][A
 65%|██████▌   | 144/221 [00:39<00:33,  2.32it/s][A
 66%|██████▌   | 146/221 [00:40<00:20,  3.70it/s][A
 67%|██████▋   | 147/221 [00:40<00:20,  3.59it/s][A
 67%|██████▋   | 148/221 [00:40<00:24,  2.99it/s][A
 67%|██████▋   | 149/221 [00:41<00:23,  3.01it/s][A
 68%|██████▊   | 150/221 [00:41<00:22,  3.22it/s][A
 68%|██████▊   | 151/221 [00:41<00:23,  3.03it/s][A
 69%|██████▉   | 152/221 [00:43<00:39,  1.75it/s][A
 69%|██████▉   | 153/221 [00:43<00:30,  2.24it/s][A
 70%|██████▉   | 154/221 [00:43<00:24,  2.73it/s][A
 70%|███████   | 155/221 [00:43<00:23,  2.82it/s][A
 71%|███████   | 156/221 [00:44<00:27,  2.33it/s][A
 71%|███████   | 157/221 [00:44<00:24,  2.56it/s][A
 71%|███████▏  | 158/221 [00:44<00:22,  2.75it/s][A
 72%|███████▏  | 159/221 [00:44<00:17,  3.48it/s][A
 72%|███████▏  | 160/221 [00:45<00:16,  3.66it/s][A
 73%|███████▎  | 161/221 [00:45<00:14,  4.05it/s][A
 73%|███████▎  | 162/221 [00:45<00:12,  4.54it/s][A
 74%|███████▍  | 163/221 [00:45<00:13,  4.43it/s][A
 74%|███████▍  | 164/221 [00:45<00:11,  5.11it/s][A
 75%|███████▍  | 165/221 [00:46<00:11,  4.85it/s][A
 75%|███████▌  | 166/221 [00:46<00:12,  4.48it/s][A
 76%|███████▌  | 168/221 [00:46<00:09,  5.34it/s][A
 76%|███████▋  | 169/221 [00:46<00:09,  5.56it/s][A
 77%|███████▋  | 170/221 [00:47<00:11,  4.39it/s][A
 77%|███████▋  | 171/221 [00:47<00:12,  4.15it/s][A
 78%|███████▊  | 172/221 [00:47<00:10,  4.73it/s][A
 78%|███████▊  | 173/221 [00:48<00:13,  3.48it/s][A
 79%|███████▊  | 174/221 [00:48<00:16,  2.89it/s][A
 79%|███████▉  | 175/221 [00:48<00:15,  3.00it/s][A
 80%|███████▉  | 176/221 [00:49<00:12,  3.66it/s][A
 80%|████████  | 177/221 [00:49<00:11,  3.85it/s][A
 81%|████████  | 178/221 [00:49<00:11,  3.84it/s][A
 81%|████████  | 179/221 [00:49<00:11,  3.60it/s][A
 81%|████████▏ | 180/221 [00:50<00:09,  4.11it/s][A
 82%|████████▏ | 181/221 [00:50<00:08,  4.86it/s][A
 82%|████████▏ | 182/221 [00:50<00:10,  3.69it/s][A
 83%|████████▎ | 183/221 [00:50<00:09,  3.86it/s][A
 83%|████████▎ | 184/221 [00:51<00:09,  4.01it/s][A
 84%|████████▍ | 186/221 [00:51<00:09,  3.86it/s][A
 85%|████████▍ | 187/221 [00:51<00:09,  3.58it/s][A
 85%|████████▌ | 188/221 [00:52<00:09,  3.56it/s][A
 86%|████████▌ | 189/221 [00:52<00:09,  3.54it/s][A
 86%|████████▌ | 190/221 [00:52<00:09,  3.23it/s][A
 86%|████████▋ | 191/221 [00:52<00:07,  3.85it/s][A
 87%|████████▋ | 192/221 [00:53<00:07,  3.96it/s][A
 88%|████████▊ | 194/221 [00:53<00:07,  3.57it/s][A
 88%|████████▊ | 195/221 [00:54<00:07,  3.71it/s][A
 89%|████████▊ | 196/221 [00:54<00:07,  3.22it/s][A
 89%|████████▉ | 197/221 [00:54<00:07,  3.20it/s][A
 90%|████████▉ | 198/221 [00:55<00:08,  2.86it/s][A
 90%|█████████ | 199/221 [00:55<00:06,  3.34it/s][A
 90%|█████████ | 200/221 [00:55<00:07,  2.95it/s][A
 91%|█████████ | 201/221 [00:56<00:05,  3.35it/s][A
 91%|█████████▏| 202/221 [00:56<00:05,  3.23it/s][A
 92%|█████████▏| 203/221 [00:56<00:05,  3.58it/s][A
 92%|█████████▏| 204/221 [00:57<00:05,  3.16it/s][A
 93%|█████████▎| 206/221 [00:57<00:04,  3.30it/s][A
 94%|█████████▍| 208/221 [00:57<00:03,  3.86it/s][A
 95%|█████████▍| 209/221 [00:58<00:02,  4.03it/s][A
 95%|█████████▌| 211/221 [00:58<00:02,  4.33it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  4.15it/s][A
 96%|█████████▋| 213/221 [00:59<00:01,  4.39it/s][A
 97%|█████████▋| 214/221 [00:59<00:02,  3.23it/s][A
 97%|█████████▋| 215/221 [00:59<00:01,  3.41it/s][A
 98%|█████████▊| 216/221 [01:00<00:01,  3.15it/s][A
 98%|█████████▊| 217/221 [01:00<00:01,  3.03it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.29it/s][A
 99%|█████████▉| 219/221 [01:01<00:00,  3.28it/s][A
100%|█████████▉| 220/221 [01:01<00:00,  3.73it/s][A
100%|██████████| 221/221 [01:01<00:00,  3.91it/s][A100%|██████████| 221/221 [01:01<00:00,  3.59it/s]
09/09/2024 18:26:28 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 249--===========

09/09/2024 18:26:28 - INFO - __main__ -   {'area_r1': 41.5, 'area_recall': '41.5/68.2/75.9', 'area_ravg': 61.9}
09/09/2024 18:26:28 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 249--===========

09/09/2024 18:26:28 - INFO - __main__ -   {'forward_r1': 37.7, 'forward_recall': '37.7/63.2/72.6', 'forward_ravg': 57.8}
09/09/2024 18:26:28 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 249--===========

09/09/2024 18:26:28 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 18:26:28 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/09/2024 18:26:28 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 18:26:28 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 249--===========

09/09/2024 18:26:28 - INFO - __main__ -   {'area_video_r1': 51.8, 'area_video_recall': '51.8/74.8/81.4', 'area_video_ravg': 69.3, 'area_video_back_r1': 50.9, 'area_video_back_recall': '50.9/72.9/81.2', 'area_video_back_ravg': 68.3}
09/09/2024 18:26:28 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 149=======

09/09/2024 18:26:28 - INFO - __main__ -   {'area_video_r1': 52.0, 'area_video_recall': '52.0/75.2/82.6', 'area_video_ravg': 69.9, 'area_video_back_r1': 49.5, 'area_video_back_recall': '49.5/73.4/80.8', 'area_video_back_ravg': 67.9}
09/09/2024 18:26:28 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 249--===========

09/09/2024 18:26:28 - INFO - __main__ -   {'video_r1': 42.2, 'video_recall': '42.2/70.2/80.5', 'video_ravg': 64.3}
09/09/2024 18:26:28 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 18:26:28 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 18:26:28 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 249--===========

09/09/2024 18:26:28 - INFO - __main__ -   {'video_r1': 52.0, 'video_recall': '52.0/75.1/82.8', 'video_ravg': 70.0}
09/09/2024 18:26:28 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 249=======

09/09/2024 18:26:28 - INFO - __main__ -   {'video_r1': 52.0, 'video_recall': '52.0/75.1/82.8', 'video_ravg': 70.0}
09/09/2024 18:26:59 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.011407217010855675, 'loss_ret%tv%ta--finetune_area/loss_area': 1.695375680923462, 'loss_ret%tv%ta--finetune_area/total_loss': 1.7067829370498657}
[h264 @ 0x5623804b1440] mmco: unref short failure
 13%|█▎        | 250/1945 [1:21:39<59:56:55, 127.32s/it][h264 @ 0x559b4b6cd5c0] mmco: unref short failure
[h264 @ 0x559b4b6cd5c0] mmco: unref short failure
[h264 @ 0x556a8eaaf340] mmco: unref short failure
 13%|█▎        | 251/1945 [1:21:44<42:32:11, 90.40s/it] [h264 @ 0x556a796b2b80] mmco: unref short failure
[h264 @ 0x556a796b2b80] mmco: unref short failure
[h264 @ 0x562366f6e200] mmco: unref short failure
[h264 @ 0x562366f6e200] mmco: unref short failure
[h264 @ 0x562364e2b200] mmco: unref short failure
[h264 @ 0x562364e2b200] mmco: unref short failure
 13%|█▎        | 252/1945 [1:21:48<30:23:46, 64.63s/it][h264 @ 0x56237c4c5080] mmco: unref short failure
[h264 @ 0x56237c4c5080] mmco: unref short failure
[h264 @ 0x556a84e9d580] mmco: unref short failure
[h264 @ 0x556a84e9d580] mmco: unref short failure
 13%|█▎        | 253/1945 [1:21:53<22:00:31, 46.83s/it][h264 @ 0x56237b4e69c0] mmco: unref short failure
[h264 @ 0x56237b4e69c0] mmco: unref short failure
[h264 @ 0x559f9cf57580] mmco: unref short failure
 13%|█▎        | 254/1945 [1:22:00<16:21:16, 34.82s/it][h264 @ 0x559b442db8c0] mmco: unref short failure
[h264 @ 0x559b442db8c0] mmco: unref short failure
 13%|█▎        | 255/1945 [1:22:06<12:16:06, 26.13s/it][h264 @ 0x556a79db7740] mmco: unref short failure
[h264 @ 0x556a79db7740] mmco: unref short failure
[h264 @ 0x556a79db7740] mmco: unref short failure
[h264 @ 0x556a79db7740] mmco: unref short failure
[h264 @ 0x559b44489100] mmco: unref short failure
[h264 @ 0x559b44489100] mmco: unref short failure
 13%|█▎        | 256/1945 [1:22:13<9:30:11, 20.26s/it] [h264 @ 0x56236298c340] mmco: unref short failure
[h264 @ 0x56236298c340] mmco: unref short failure
 13%|█▎        | 257/1945 [1:22:21<7:50:30, 16.72s/it] 13%|█▎        | 258/1945 [1:22:28<6:30:36, 13.89s/it] 13%|█▎        | 259/1945 [1:22:36<5:34:14, 11.90s/it][h264 @ 0x559b4d9afd80] mmco: unref short failure
 13%|█▎        | 260/1945 [1:22:43<4:52:12, 10.40s/it][h264 @ 0x559b4d3a9b80] mmco: unref short failure
 13%|█▎        | 261/1945 [1:22:49<4:22:33,  9.35s/it][h264 @ 0x56237607dbc0] mmco: unref short failure
[h264 @ 0x56237607dbc0] mmco: unref short failure
[h264 @ 0x559f9bc5d840] mmco: unref short failure
[h264 @ 0x559f9bc5d840] mmco: unref short failure
 13%|█▎        | 262/1945 [1:22:57<4:08:01,  8.84s/it][h264 @ 0x556a796b2980] mmco: unref short failure
[h264 @ 0x556a796b2980] mmco: unref short failure
[h264 @ 0x556a796b2980] mmco: unref short failure
 14%|█▎        | 263/1945 [1:23:05<3:57:06,  8.46s/it][h264 @ 0x559f831ea740] mmco: unref short failure
[h264 @ 0x556a7841a940] mmco: unref short failure
[h264 @ 0x556a7841a940] mmco: unref short failure
 14%|█▎        | 264/1945 [1:23:12<3:45:47,  8.06s/it][h264 @ 0x559b372799c0] mmco: unref short failure
[h264 @ 0x559b4159c340] mmco: unref short failure
[h264 @ 0x559b4159c340] mmco: unref short failure
[h264 @ 0x559b4159c340] mmco: unref short failure
[h264 @ 0x559b4159c340] mmco: unref short failure
 14%|█▎        | 265/1945 [1:23:20<3:45:46,  8.06s/it][h264 @ 0x559f831ea740] mmco: unref short failure
[h264 @ 0x559f831ea740] mmco: unref short failure
[h264 @ 0x556a82cbcec0] mmco: unref short failure
[h264 @ 0x556a82cbcec0] mmco: unref short failure
[h264 @ 0x56237d1a70c0] mmco: unref short failure
 14%|█▎        | 266/1945 [1:23:27<3:35:12,  7.69s/it][h264 @ 0x559b35aa5280] mmco: unref short failure
 14%|█▎        | 267/1945 [1:23:33<3:25:58,  7.36s/it][h264 @ 0x56236c3e1180] mmco: unref short failure
[h264 @ 0x56236c3e1180] mmco: unref short failure
[h264 @ 0x56236c3e1180] mmco: unref short failure
[h264 @ 0x56236c3e1180] mmco: unref short failure
[h264 @ 0x556a78aefd40] mmco: unref short failure
[h264 @ 0x556a78aefd40] mmco: unref short failure
[h264 @ 0x559f96556480] mmco: unref short failure
[h264 @ 0x559f7dc93c80] mmco: unref short failure
[h264 @ 0x559f7dc93c80] mmco: unref short failure
[h264 @ 0x556a85314e40] mmco: unref short failure
[h264 @ 0x556a85314e40] mmco: unref short failure
[h264 @ 0x559b4d82fc80] mmco: unref short failure
[h264 @ 0x559b4d82fc80] mmco: unref short failure
 14%|█▍        | 268/1945 [1:23:40<3:24:03,  7.30s/it][h264 @ 0x556a98252880] mmco: unref short failure
[h264 @ 0x56237bf6ef40] mmco: unref short failure
[h264 @ 0x56237bf6ef40] mmco: unref short failure
[h264 @ 0x5623632f1f00] mmco: unref short failure
[h264 @ 0x5623632f1f00] mmco: unref short failure
[h264 @ 0x556a8d2cd200] mmco: unref short failure
[h264 @ 0x559f9ae0aac0] mmco: unref short failure
 14%|█▍        | 269/1945 [1:23:53<4:10:46,  8.98s/it] 14%|█▍        | 270/1945 [1:24:00<3:52:14,  8.32s/it][h264 @ 0x556a80fdc300] mmco: unref short failure
[h264 @ 0x556a80fdc300] mmco: unref short failure
 14%|█▍        | 271/1945 [1:24:09<3:56:04,  8.46s/it][h264 @ 0x562362b3ee80] mmco: unref short failure
[h264 @ 0x562362b3ee80] mmco: unref short failure
 14%|█▍        | 272/1945 [1:24:18<4:03:43,  8.74s/it][h264 @ 0x559f81150380] mmco: unref short failure
[h264 @ 0x559f81150380] mmco: unref short failure
[h264 @ 0x562363ebf200] mmco: unref short failure
[h264 @ 0x559f83c0fd80] mmco: unref short failure
[h264 @ 0x559f8dbd3540] mmco: unref short failure
[h264 @ 0x559b3a772440] mmco: unref short failure
[h264 @ 0x559b3a772440] mmco: unref short failure
 14%|█▍        | 273/1945 [1:24:39<5:44:05, 12.35s/it][h264 @ 0x556a784fab40] mmco: unref short failure
[h264 @ 0x556a784fab40] mmco: unref short failure
[h264 @ 0x556a8b808b00] mmco: unref short failure
[h264 @ 0x556a8b808b00] mmco: unref short failure
[h264 @ 0x559f7d517e00] mmco: unref short failure
[h264 @ 0x556a7f705a80] mmco: unref short failure
[h264 @ 0x556a7f705a80] mmco: unref short failure
[h264 @ 0x556a78c00580] mmco: unref short failure
[h264 @ 0x556a78c00580] mmco: unref short failure
[h264 @ 0x556a78c00580] mmco: unref short failure
[h264 @ 0x556a78c00580] mmco: unref short failure
[h264 @ 0x556a8defc700] mmco: unref short failure
[h264 @ 0x556a8defc700] mmco: unref short failure
[h264 @ 0x559f9afe4600] mmco: unref short failure
[h264 @ 0x559f9afe4600] mmco: unref short failure
[h264 @ 0x559f9afe4600] mmco: unref short failure
[h264 @ 0x559f9afe4600] mmco: unref short failure
[h264 @ 0x556a93e91a00] mmco: unref short failure
[h264 @ 0x556a93e91a00] mmco: unref short failure
[h264 @ 0x556a78ac27c0] mmco: unref short failure
[h264 @ 0x559f94e83a80] mmco: unref short failure
[h264 @ 0x559f94e83a80] mmco: unref short failure
[h264 @ 0x56236494e500] mmco: unref short failure
[h264 @ 0x56236494e500] mmco: unref short failure
 14%|█▍        | 274/1945 [1:25:09<8:09:59, 17.59s/it][h264 @ 0x559b3b63ce40] mmco: unref short failure
[h264 @ 0x559b3b63ce40] mmco: unref short failure
[h264 @ 0x556a79fadb00] mmco: unref short failure
[h264 @ 0x556a79fadb00] mmco: unref short failure
[h264 @ 0x556a82187b40] mmco: unref short failure
[h264 @ 0x559f8e5180c0] mmco: unref short failure
[h264 @ 0x559f8e5180c0] mmco: unref short failure
[h264 @ 0x556a8836e400] mmco: unref short failure
[h264 @ 0x556a8836e400] mmco: unref short failure
[h264 @ 0x556a8836e400] mmco: unref short failure
[h264 @ 0x556a8836e400] mmco: unref short failure
[h264 @ 0x559f8a72d6c0] mmco: unref short failure
 14%|█▍        | 275/1945 [1:25:30<8:35:24, 18.52s/it][h264 @ 0x556a98825b40] mmco: unref short failure
[h264 @ 0x559b564b8dc0] mmco: unref short failure
[h264 @ 0x556a78c78f00] mmco: unref short failure
[h264 @ 0x556a78c78f00] mmco: unref short failure
[h264 @ 0x556a78c78f00] mmco: unref short failure
[h264 @ 0x556a78c78f00] mmco: unref short failure
[h264 @ 0x556a78c78f00] mmco: unref short failure
[h264 @ 0x556a7ce89d80] mmco: unref short failure
 14%|█▍        | 276/1945 [1:25:55<9:32:42, 20.59s/it] 14%|█▍        | 277/1945 [1:26:02<7:36:12, 16.41s/it] 14%|█▍        | 278/1945 [1:26:09<6:21:23, 13.73s/it] 14%|█▍        | 279/1945 [1:26:16<5:26:33, 11.76s/it][h264 @ 0x562374523600] mmco: unref short failure
[h264 @ 0x562374523600] mmco: unref short failure
[h264 @ 0x559b4497a780] mmco: unref short failure
 14%|█▍        | 280/1945 [1:26:24<4:53:58, 10.59s/it][h264 @ 0x56236b679c00] mmco: unref short failure
[h264 @ 0x559b3fb76800] mmco: unref short failure
[h264 @ 0x559b49eb62c0] mmco: unref short failure
[h264 @ 0x559b49eb62c0] mmco: unref short failure
[h264 @ 0x556a967b0400] mmco: unref short failure
 14%|█▍        | 281/1945 [1:26:44<6:07:42, 13.26s/it][h264 @ 0x559f88ae7680] mmco: unref short failure
[h264 @ 0x556a945fe780] mmco: unref short failure
[h264 @ 0x559b38604780] mmco: unref short failure
[h264 @ 0x559f9956bfc0] mmco: unref short failure
[h264 @ 0x559f9956bfc0] mmco: unref short failure
[h264 @ 0x556a7c71bec0] mmco: unref short failure
 14%|█▍        | 282/1945 [1:27:11<8:07:20, 17.58s/it][h264 @ 0x559f7f0d9900] mmco: unref short failure
[h264 @ 0x559f7f0d9900] mmco: unref short failure
[h264 @ 0x556a784fa940] mmco: unref short failure
[h264 @ 0x556a784fa940] mmco: unref short failure
[h264 @ 0x556a984b3540] mmco: unref short failure
[h264 @ 0x556a984b3540] mmco: unref short failure
[h264 @ 0x559f873f2340] mmco: unref short failure
[h264 @ 0x559f873f2340] mmco: unref short failure
[h264 @ 0x556a88ad7c00] mmco: unref short failure
 15%|█▍        | 283/1945 [1:27:29<8:11:51, 17.76s/it][h264 @ 0x559f8f5975c0] mmco: unref short failure
[h264 @ 0x559f8f5975c0] mmco: unref short failure
[h264 @ 0x56236cd0c6c0] mmco: unref short failure
[h264 @ 0x559f9c991200] mmco: unref short failure
[h264 @ 0x556a9abc8f40] mmco: unref short failure
[h264 @ 0x556a9abc8f40] mmco: unref short failure
[h264 @ 0x556a88ad8080] mmco: unref short failure
[h264 @ 0x559f8b13a6c0] mmco: unref short failure
 15%|█▍        | 284/1945 [1:27:48<8:21:38, 18.12s/it][h264 @ 0x556a8f598a00] mmco: unref short failure
[h264 @ 0x556a8f598a00] mmco: unref short failure
[h264 @ 0x559f8438ad00] mmco: unref short failure
 15%|█▍        | 285/1945 [1:27:56<6:52:06, 14.90s/it] 15%|█▍        | 286/1945 [1:28:03<5:48:49, 12.62s/it][h264 @ 0x559f7e716400] mmco: unref short failure
[h264 @ 0x5623856ab7c0] mmco: unref short failure
[h264 @ 0x5623856ab7c0] mmco: unref short failure
[h264 @ 0x556a88ad7a00] mmco: unref short failure
[h264 @ 0x556a8414e500] mmco: unref short failure
 15%|█▍        | 287/1945 [1:28:20<6:24:38, 13.92s/it][h264 @ 0x559b3e358000] mmco: unref short failure
 15%|█▍        | 288/1945 [1:28:27<5:28:11, 11.88s/it][h264 @ 0x559f9847c7c0] mmco: unref short failure
[h264 @ 0x559b43e836c0] mmco: unref short failure
[h264 @ 0x559b43e836c0] mmco: unref short failure
[h264 @ 0x556a7adbac80] mmco: unref short failure
[h264 @ 0x559f9a18f600] mmco: unref short failure
[h264 @ 0x559f9a18f600] mmco: unref short failure
[h264 @ 0x559f9a18f600] mmco: unref short failure
[h264 @ 0x559f9a18f600] mmco: unref short failure
[h264 @ 0x559f9a18f600] mmco: unref short failure
[h264 @ 0x559f9a18f600] mmco: unref short failure
[h264 @ 0x556a8fc370c0] mmco: unref short failure
 15%|█▍        | 289/1945 [1:28:49<6:47:20, 14.76s/it][h264 @ 0x556a8624fd00] mmco: unref short failure
[h264 @ 0x559f820c05c0] mmco: unref short failure
[h264 @ 0x556a8394df00] mmco: unref short failure
[h264 @ 0x5623733d8040] mmco: unref short failure
 15%|█▍        | 290/1945 [1:29:11<7:52:25, 17.13s/it][h264 @ 0x556a7f2cf680] mmco: unref short failure
[h264 @ 0x562374df5e00] mmco: unref short failure
[h264 @ 0x562374df5e00] mmco: unref short failure
[h264 @ 0x556a82517380] mmco: unref short failure
[h264 @ 0x556a8a6a5fc0] mmco: unref short failure
[h264 @ 0x556a8a6a5fc0] mmco: unref short failure
 15%|█▍        | 291/1945 [1:29:33<8:29:46, 18.49s/it][h264 @ 0x556a85a93e40] mmco: unref short failure
[h264 @ 0x562379b10800] mmco: unref short failure
[h264 @ 0x556a85a94040] mmco: unref short failure
[h264 @ 0x559b3549a400] mmco: unref short failure
[h264 @ 0x559b3549a400] mmco: unref short failure
[h264 @ 0x559b48781140] mmco: unref short failure
[h264 @ 0x559b48781140] mmco: unref short failure
 15%|█▌        | 292/1945 [1:29:50<8:16:54, 18.04s/it][h264 @ 0x559f906a2280] mmco: unref short failure
[h264 @ 0x56236681b240] mmco: unref short failure
[h264 @ 0x56236681b240] mmco: unref short failure
[h264 @ 0x559f86261c00] mmco: unref short failure
[h264 @ 0x559f86261c00] mmco: unref short failure
[h264 @ 0x559f86261c00] mmco: unref short failure
[h264 @ 0x559f86261c00] mmco: unref short failure
[h264 @ 0x56237aca9940] mmco: unref short failure
 15%|█▌        | 293/1945 [1:29:58<6:50:28, 14.91s/it] 15%|█▌        | 294/1945 [1:30:06<5:56:30, 12.96s/it][h264 @ 0x559b362332c0] mmco: unref short failure
[h264 @ 0x559b362332c0] mmco: unref short failure
[h264 @ 0x556a93f6e140] mmco: unref short failure
[h264 @ 0x556a93f6e140] mmco: unref short failure
[h264 @ 0x559f9ae63e00] mmco: unref short failure
[h264 @ 0x559f9ae63e00] mmco: unref short failure
[h264 @ 0x559b3afacb80] mmco: unref short failure
[h264 @ 0x559b3afacb80] mmco: unref short failure
 15%|█▌        | 295/1945 [1:30:23<6:33:27, 14.31s/it][h264 @ 0x556a97a52bc0] mmco: unref short failure
[h264 @ 0x556a97a52bc0] mmco: unref short failure
 15%|█▌        | 296/1945 [1:30:32<5:45:40, 12.58s/it][h264 @ 0x559b3b63cd40] mmco: unref short failure
[h264 @ 0x556a7adbaa80] mmco: unref short failure
[h264 @ 0x556a7adbaa80] mmco: unref short failure
 15%|█▌        | 297/1945 [1:30:49<6:24:02, 13.98s/it][h264 @ 0x559b39760f80] mmco: unref short failure
[h264 @ 0x559b39760f80] mmco: unref short failure
[h264 @ 0x556a8fabcec0] mmco: unref short failure
[h264 @ 0x556a8fabcec0] mmco: unref short failure
[h264 @ 0x556a951b2980] mmco: unref short failure
[h264 @ 0x556a951b2980] mmco: unref short failure
[h264 @ 0x562362ddee00] mmco: unref short failure
[h264 @ 0x562362ddee00] mmco: unref short failure
[h264 @ 0x559f8605e340] mmco: unref short failure
[h264 @ 0x56236ab69a00] mmco: unref short failure
[h264 @ 0x556a934d1e80] mmco: unref short failure
[h264 @ 0x556a934d1e80] mmco: unref short failure
[h264 @ 0x556a888c1040] mmco: unref short failure
[h264 @ 0x556a888c1040] mmco: unref short failure
[h264 @ 0x556a888c1040] mmco: unref short failure
[h264 @ 0x556a888c1040] mmco: unref short failure
 15%|█▌        | 298/1945 [1:31:14<7:49:24, 17.10s/it][h264 @ 0x56237607dc80] mmco: unref short failure
[h264 @ 0x559f9c4ef680] mmco: unref short failure
[h264 @ 0x556a7ce6cf40] mmco: unref short failure
[h264 @ 0x556a7ce6cf40] mmco: unref short failure
[h264 @ 0x562373a00d40] mmco: unref short failure
[h264 @ 0x56237f997f80] mmco: unref short failure
[h264 @ 0x556a79df5080] mmco: unref short failure
[h264 @ 0x559f820b8d80] mmco: unref short failure
[h264 @ 0x556a8fabcc40] mmco: unref short failure
[h264 @ 0x5623682f4d00] mmco: unref short failure
[h264 @ 0x559f8ad2cd40] mmco: unref short failure
[h264 @ 0x559f8ad2cd40] mmco: unref short failure
[h264 @ 0x562379a1d940] mmco: unref short failure
 15%|█▌        | 299/1945 [1:31:39<8:59:39, 19.67s/it]09/09/2024 18:37:02 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 18:37:02 - INFO - __main__ -   start running ret%tv validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556a9a8ee740] mmco: unref short failure
[h264 @ 0x556a9a8ee740] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x56237698a600] mmco: unref short failure
[h264 @ 0x56237698a600] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556a88101500] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x562367437f00] mmco: unref short failure
[h264 @ 0x556a7d4f3100] mmco: unref short failure
[h264 @ 0x556a7d4f3100] mmco: unref short failure
[h264 @ 0x559b3a1157c0] mmco: unref short failure
[h264 @ 0x559b3c58c040] mmco: unref short failure
[h264 @ 0x559f8067e080] mmco: unref short failure
[h264 @ 0x559f8067e080] mmco: unref short failure
[h264 @ 0x562377af0c40] mmco: unref short failure
[h264 @ 0x562377af0c40] mmco: unref short failure
[h264 @ 0x559f8e866700] mmco: unref short failure
[h264 @ 0x559b35527c80] mmco: unref short failure
[h264 @ 0x559b35527c80] mmco: unref short failure
[h264 @ 0x56236e1cc400] mmco: unref short failure
[h264 @ 0x559f88a70040] mmco: unref short failure
[h264 @ 0x559f88a70040] mmco: unref short failure
[h264 @ 0x559f88a70040] mmco: unref short failure
[h264 @ 0x559f88a70040] mmco: unref short failure
[h264 @ 0x556a82517600] mmco: unref short failure
[h264 @ 0x556a82517600] mmco: unref short failure
[h264 @ 0x562368529680] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A[h264 @ 0x556a81d26e80] mmco: unref short failure

  0%|          | 1/221 [00:00<02:31,  1.46it/s][A
  1%|          | 2/221 [00:01<02:26,  1.50it/s][A
  1%|▏         | 3/221 [00:01<01:46,  2.04it/s][A
  2%|▏         | 4/221 [00:01<01:34,  2.30it/s][A
  2%|▏         | 5/221 [00:02<01:14,  2.91it/s][A
  3%|▎         | 6/221 [00:02<01:00,  3.54it/s][A
  3%|▎         | 7/221 [00:02<00:56,  3.80it/s][A
  4%|▎         | 8/221 [00:02<01:03,  3.36it/s][A
  4%|▍         | 9/221 [00:03<01:08,  3.11it/s][A
  5%|▍         | 10/221 [00:03<01:29,  2.35it/s][A
  5%|▍         | 11/221 [00:04<01:13,  2.84it/s][A
  5%|▌         | 12/221 [00:04<01:28,  2.35it/s][A
  6%|▌         | 13/221 [00:04<01:17,  2.68it/s][A
  6%|▋         | 14/221 [00:05<01:30,  2.28it/s][A
  7%|▋         | 15/221 [00:05<01:19,  2.59it/s][A
  7%|▋         | 16/221 [00:06<01:19,  2.58it/s][A
  8%|▊         | 17/221 [00:06<01:41,  2.02it/s][A
  8%|▊         | 18/221 [00:07<01:29,  2.26it/s][A
  9%|▊         | 19/221 [00:07<01:10,  2.85it/s][A
  9%|▉         | 20/221 [00:07<01:01,  3.24it/s][A
 10%|▉         | 21/221 [00:07<00:55,  3.60it/s][A
 10%|▉         | 22/221 [00:08<00:49,  4.00it/s][A
 10%|█         | 23/221 [00:08<00:46,  4.28it/s][A
 11%|█         | 24/221 [00:08<00:43,  4.49it/s][A
 11%|█▏        | 25/221 [00:08<00:44,  4.42it/s][A
 12%|█▏        | 26/221 [00:09<01:01,  3.16it/s][A[h264 @ 0x559b3d7b2440] mmco: unref short failure
[h264 @ 0x559b3d7b2440] mmco: unref short failure
[h264 @ 0x559b3d7b2440] mmco: unref short failure
[h264 @ 0x559b3d7b2440] mmco: unref short failure
[h264 @ 0x559b3d7b2440] mmco: unref short failure
[h264 @ 0x559b3d7b2440] mmco: unref short failure

 12%|█▏        | 27/221 [00:09<00:50,  3.88it/s][A
 13%|█▎        | 28/221 [00:09<01:14,  2.57it/s][A
 13%|█▎        | 29/221 [00:10<01:18,  2.43it/s][A
 14%|█▎        | 30/221 [00:10<01:12,  2.64it/s][A
 14%|█▍        | 31/221 [00:11<01:05,  2.88it/s][A
 14%|█▍        | 32/221 [00:11<00:52,  3.57it/s][A
 15%|█▍        | 33/221 [00:11<00:48,  3.88it/s][A
 15%|█▌        | 34/221 [00:11<00:41,  4.49it/s][A
 16%|█▌        | 35/221 [00:11<00:45,  4.04it/s][A
 16%|█▋        | 36/221 [00:12<00:55,  3.35it/s][A
 17%|█▋        | 37/221 [00:12<01:03,  2.90it/s][A
 17%|█▋        | 38/221 [00:13<01:07,  2.70it/s][A
 18%|█▊        | 39/221 [00:13<01:01,  2.97it/s][A
 18%|█▊        | 40/221 [00:13<01:03,  2.87it/s][A[h264 @ 0x5623778573c0] mmco: unref short failure

 19%|█▊        | 41/221 [00:13<00:52,  3.41it/s][A
 19%|█▉        | 42/221 [00:14<01:09,  2.57it/s][A
 19%|█▉        | 43/221 [00:14<00:56,  3.17it/s][A
 20%|█▉        | 44/221 [00:14<00:51,  3.46it/s][A
 20%|██        | 45/221 [00:15<01:22,  2.13it/s][A
 21%|██        | 46/221 [00:16<01:14,  2.33it/s][A
 21%|██▏       | 47/221 [00:16<01:14,  2.33it/s][A
 22%|██▏       | 48/221 [00:16<00:58,  2.93it/s][A
 22%|██▏       | 49/221 [00:17<01:23,  2.07it/s][A[h264 @ 0x559f9fab9cc0] mmco: unref short failure
[h264 @ 0x559f9fab9cc0] mmco: unref short failure

 23%|██▎       | 50/221 [00:17<01:13,  2.34it/s][A
 23%|██▎       | 51/221 [00:17<00:56,  3.01it/s][A
 24%|██▎       | 52/221 [00:18<00:51,  3.26it/s][A
 24%|██▍       | 53/221 [00:18<00:44,  3.76it/s][A
 24%|██▍       | 54/221 [00:19<01:40,  1.66it/s][A
 25%|██▍       | 55/221 [00:20<01:29,  1.86it/s][A
 25%|██▌       | 56/221 [00:20<01:13,  2.25it/s][A
 26%|██▌       | 57/221 [00:20<00:59,  2.74it/s][A
 26%|██▌       | 58/221 [00:20<00:47,  3.40it/s][A
 27%|██▋       | 59/221 [00:20<00:49,  3.30it/s][A
 27%|██▋       | 60/221 [00:21<01:18,  2.06it/s][A
 28%|██▊       | 61/221 [00:22<01:07,  2.36it/s][A
 28%|██▊       | 62/221 [00:22<01:02,  2.53it/s][A
 29%|██▊       | 63/221 [00:22<00:54,  2.89it/s][A
 29%|██▉       | 64/221 [00:23<00:53,  2.91it/s][A
 29%|██▉       | 65/221 [00:23<00:49,  3.15it/s][A
 30%|██▉       | 66/221 [00:23<00:48,  3.18it/s][A
 30%|███       | 67/221 [00:24<01:07,  2.28it/s][A
 31%|███       | 68/221 [00:24<01:00,  2.55it/s][A
 31%|███       | 69/221 [00:25<01:13,  2.06it/s][A
 32%|███▏      | 70/221 [00:25<01:01,  2.46it/s][A
 32%|███▏      | 71/221 [00:26<01:07,  2.21it/s][A
 33%|███▎      | 72/221 [00:26<01:07,  2.21it/s][A
 33%|███▎      | 73/221 [00:26<01:05,  2.27it/s][A
 33%|███▎      | 74/221 [00:27<00:52,  2.78it/s][A
 34%|███▍      | 75/221 [00:27<00:50,  2.87it/s][A
 34%|███▍      | 76/221 [00:27<00:46,  3.12it/s][A
 35%|███▍      | 77/221 [00:27<00:42,  3.36it/s][A
 35%|███▌      | 78/221 [00:28<00:38,  3.70it/s][A
 36%|███▌      | 79/221 [00:28<00:49,  2.86it/s][A
 36%|███▌      | 80/221 [00:28<00:43,  3.24it/s][A
 37%|███▋      | 81/221 [00:29<00:41,  3.40it/s][A
 37%|███▋      | 82/221 [00:29<00:49,  2.80it/s][A
 38%|███▊      | 83/221 [00:30<01:01,  2.25it/s][A
 38%|███▊      | 84/221 [00:30<00:55,  2.47it/s][A
 38%|███▊      | 85/221 [00:30<00:43,  3.10it/s][A
 39%|███▉      | 86/221 [00:31<00:40,  3.32it/s][A
 39%|███▉      | 87/221 [00:31<01:01,  2.16it/s][A
 40%|███▉      | 88/221 [00:32<01:06,  2.01it/s][A
 40%|████      | 89/221 [00:32<01:03,  2.06it/s][A
 41%|████      | 90/221 [00:33<00:57,  2.27it/s][A
 41%|████      | 91/221 [00:33<00:53,  2.45it/s][A
 42%|████▏     | 92/221 [00:33<00:48,  2.65it/s][A
 42%|████▏     | 93/221 [00:34<00:49,  2.57it/s][A
 43%|████▎     | 94/221 [00:34<00:40,  3.14it/s][A
 43%|████▎     | 95/221 [00:34<00:41,  3.02it/s][A[h264 @ 0x559f9d7df880] mmco: unref short failure
[h264 @ 0x559f9d7df880] mmco: unref short failure

 43%|████▎     | 96/221 [00:35<00:39,  3.18it/s][A
 44%|████▍     | 97/221 [00:35<00:34,  3.59it/s][A
 44%|████▍     | 98/221 [00:35<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:35<00:26,  4.64it/s][A
 45%|████▌     | 100/221 [00:35<00:25,  4.67it/s][A
 46%|████▌     | 101/221 [00:36<00:31,  3.80it/s][A
 46%|████▌     | 102/221 [00:36<00:34,  3.47it/s][A
 47%|████▋     | 103/221 [00:36<00:29,  4.00it/s][A
 47%|████▋     | 104/221 [00:36<00:24,  4.71it/s][A
 48%|████▊     | 105/221 [00:37<00:24,  4.68it/s][A
 48%|████▊     | 106/221 [00:37<00:47,  2.43it/s][A
 48%|████▊     | 107/221 [00:38<00:40,  2.80it/s][A
 49%|████▉     | 108/221 [00:38<00:38,  2.92it/s][A
 49%|████▉     | 109/221 [00:38<00:37,  2.96it/s][A
 50%|████▉     | 110/221 [00:39<00:40,  2.76it/s][A
 50%|█████     | 111/221 [00:39<00:44,  2.49it/s][A
 51%|█████     | 112/221 [00:39<00:36,  2.97it/s][A
 51%|█████     | 113/221 [00:40<00:36,  2.94it/s][A
 52%|█████▏    | 114/221 [00:40<00:31,  3.36it/s][A
 52%|█████▏    | 115/221 [00:40<00:29,  3.64it/s][A[h264 @ 0x559f903fc580] mmco: unref short failure

 52%|█████▏    | 116/221 [00:41<00:59,  1.76it/s][A
 53%|█████▎    | 117/221 [00:42<00:52,  1.98it/s][A
 53%|█████▎    | 118/221 [00:42<00:45,  2.24it/s][A
 54%|█████▍    | 119/221 [00:43<00:46,  2.22it/s][A
 54%|█████▍    | 120/221 [00:43<00:42,  2.40it/s][A
 55%|█████▍    | 121/221 [00:43<00:34,  2.93it/s][A
 55%|█████▌    | 122/221 [00:43<00:29,  3.40it/s][A
 56%|█████▌    | 123/221 [00:43<00:26,  3.76it/s][A
 56%|█████▌    | 124/221 [00:44<00:23,  4.07it/s][A
 57%|█████▋    | 125/221 [00:44<00:26,  3.56it/s][A
 57%|█████▋    | 126/221 [00:44<00:25,  3.78it/s][A
 57%|█████▋    | 127/221 [00:45<00:29,  3.15it/s][A
 58%|█████▊    | 128/221 [00:45<00:30,  3.05it/s][A
 58%|█████▊    | 129/221 [00:45<00:27,  3.30it/s][A
 59%|█████▉    | 130/221 [00:46<00:27,  3.33it/s][A
 59%|█████▉    | 131/221 [00:46<00:24,  3.66it/s][A
 60%|█████▉    | 132/221 [00:46<00:21,  4.08it/s][A
 60%|██████    | 133/221 [00:46<00:27,  3.19it/s][A
 61%|██████    | 134/221 [00:47<00:25,  3.43it/s][A
 61%|██████    | 135/221 [00:47<00:21,  4.05it/s][A
 62%|██████▏   | 136/221 [00:47<00:23,  3.64it/s][A
 62%|██████▏   | 137/221 [00:47<00:20,  4.01it/s][A[h264 @ 0x559b35c93980] mmco: unref short failure

 62%|██████▏   | 138/221 [00:48<00:23,  3.50it/s][A[h264 @ 0x559f7f412c80] mmco: unref short failure
[h264 @ 0x559f7f412c80] mmco: unref short failure
[h264 @ 0x559f7f412c80] mmco: unref short failure
[h264 @ 0x559f7f412c80] mmco: unref short failure

 63%|██████▎   | 139/221 [00:48<00:28,  2.92it/s][A
 63%|██████▎   | 140/221 [00:49<00:27,  2.92it/s][A
 64%|██████▍   | 141/221 [00:49<00:25,  3.11it/s][A
 64%|██████▍   | 142/221 [00:49<00:24,  3.18it/s][A
 65%|██████▍   | 143/221 [00:49<00:25,  3.04it/s][A
 65%|██████▌   | 144/221 [00:50<00:27,  2.83it/s][A
 66%|██████▌   | 145/221 [00:50<00:23,  3.18it/s][A
 66%|██████▌   | 146/221 [00:50<00:21,  3.57it/s][A
 67%|██████▋   | 147/221 [00:51<00:21,  3.49it/s][A
 67%|██████▋   | 148/221 [00:51<00:21,  3.33it/s][A
 67%|██████▋   | 149/221 [00:51<00:17,  4.01it/s][A
 68%|██████▊   | 150/221 [00:51<00:17,  4.12it/s][A
 68%|██████▊   | 151/221 [00:52<00:26,  2.68it/s][A
 69%|██████▉   | 152/221 [00:53<00:49,  1.39it/s][A
 69%|██████▉   | 153/221 [00:54<00:40,  1.66it/s][A
 70%|██████▉   | 154/221 [00:54<00:32,  2.06it/s][A
 70%|███████   | 155/221 [00:54<00:24,  2.68it/s][A
 71%|███████   | 156/221 [00:54<00:22,  2.89it/s][A[h264 @ 0x559b37cf9f00] mmco: unref short failure
[h264 @ 0x559b37cf9f00] mmco: unref short failure

 71%|███████   | 157/221 [00:55<00:24,  2.61it/s][A
 71%|███████▏  | 158/221 [00:55<00:21,  2.88it/s][A
 72%|███████▏  | 159/221 [00:55<00:17,  3.56it/s][A
 72%|███████▏  | 160/221 [00:56<00:18,  3.31it/s][A
 73%|███████▎  | 161/221 [00:56<00:14,  4.05it/s][A
 73%|███████▎  | 162/221 [00:56<00:21,  2.68it/s][A
 74%|███████▍  | 163/221 [00:57<00:20,  2.82it/s][A
 74%|███████▍  | 164/221 [00:57<00:17,  3.19it/s][A
 75%|███████▍  | 165/221 [00:57<00:14,  3.88it/s][A
 75%|███████▌  | 166/221 [00:58<00:18,  2.98it/s][A
 76%|███████▌  | 167/221 [00:58<00:14,  3.69it/s][A
 76%|███████▌  | 168/221 [00:58<00:17,  2.96it/s][A
 76%|███████▋  | 169/221 [00:58<00:14,  3.54it/s][A
 77%|███████▋  | 170/221 [00:59<00:14,  3.48it/s][A
 77%|███████▋  | 171/221 [00:59<00:16,  3.02it/s][A
 78%|███████▊  | 173/221 [00:59<00:11,  4.07it/s][A
 79%|███████▊  | 174/221 [01:00<00:11,  4.25it/s][A
 79%|███████▉  | 175/221 [01:00<00:12,  3.54it/s][A
 80%|███████▉  | 176/221 [01:00<00:11,  3.91it/s][A
 80%|████████  | 177/221 [01:00<00:10,  4.35it/s][A
 81%|████████  | 178/221 [01:01<00:09,  4.58it/s][A
 81%|████████  | 179/221 [01:01<00:10,  3.91it/s][A
 81%|████████▏ | 180/221 [01:01<00:09,  4.51it/s][A
 82%|████████▏ | 181/221 [01:01<00:09,  4.22it/s][A
 82%|████████▏ | 182/221 [01:01<00:08,  4.87it/s][A
 83%|████████▎ | 183/221 [01:02<00:07,  5.30it/s][A
 83%|████████▎ | 184/221 [01:02<00:08,  4.18it/s][A
 84%|████████▎ | 185/221 [01:02<00:07,  4.83it/s][A
 84%|████████▍ | 186/221 [01:02<00:08,  3.95it/s][A
 85%|████████▍ | 187/221 [01:03<00:07,  4.37it/s][A
 85%|████████▌ | 188/221 [01:03<00:07,  4.30it/s][A
 86%|████████▌ | 189/221 [01:03<00:08,  3.96it/s][A
 86%|████████▌ | 190/221 [01:03<00:08,  3.54it/s][A
 86%|████████▋ | 191/221 [01:04<00:07,  4.13it/s][A
 87%|████████▋ | 192/221 [01:04<00:08,  3.35it/s][A
 88%|████████▊ | 194/221 [01:05<00:10,  2.65it/s][A
 88%|████████▊ | 195/221 [01:05<00:09,  2.88it/s][A
 89%|████████▊ | 196/221 [01:06<00:08,  2.81it/s][A
 89%|████████▉ | 197/221 [01:06<00:07,  3.34it/s][A
 90%|████████▉ | 198/221 [01:06<00:06,  3.55it/s][A
 90%|█████████ | 199/221 [01:06<00:05,  4.25it/s][A
 90%|█████████ | 200/221 [01:06<00:05,  3.97it/s][A
 91%|█████████ | 201/221 [01:07<00:04,  4.30it/s][A
 91%|█████████▏| 202/221 [01:07<00:04,  4.36it/s][A
 92%|█████████▏| 203/221 [01:07<00:04,  4.45it/s][A
 92%|█████████▏| 204/221 [01:07<00:04,  4.17it/s][A
 93%|█████████▎| 205/221 [01:07<00:03,  4.86it/s][A
 93%|█████████▎| 206/221 [01:08<00:05,  2.81it/s][A
 94%|█████████▎| 207/221 [01:08<00:03,  3.51it/s][A
 94%|█████████▍| 208/221 [01:08<00:03,  4.13it/s][A
 95%|█████████▍| 209/221 [01:09<00:02,  4.30it/s][A
 95%|█████████▌| 210/221 [01:09<00:02,  5.00it/s][A
 95%|█████████▌| 211/221 [01:09<00:02,  4.03it/s][A
 96%|█████████▌| 212/221 [01:09<00:02,  4.27it/s][A
 96%|█████████▋| 213/221 [01:10<00:01,  4.17it/s][A
 97%|█████████▋| 214/221 [01:10<00:02,  3.41it/s][A
 97%|█████████▋| 215/221 [01:10<00:01,  3.54it/s][A
 98%|█████████▊| 216/221 [01:11<00:01,  3.28it/s][A
 98%|█████████▊| 217/221 [01:11<00:01,  3.11it/s][A
 99%|█████████▊| 218/221 [01:11<00:00,  3.09it/s][A
 99%|█████████▉| 219/221 [01:11<00:00,  3.60it/s][A
100%|█████████▉| 220/221 [01:13<00:00,  1.53it/s][A
100%|██████████| 221/221 [01:13<00:00,  1.89it/s][A100%|██████████| 221/221 [01:13<00:00,  3.00it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.78it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.78it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.78it/s][A
  2%|▏         | 5/221 [00:01<00:57,  3.78it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.78it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.78it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.78it/s][A
  4%|▍         | 9/221 [00:02<00:56,  3.78it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.78it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.78it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.78it/s][A
  6%|▌         | 13/221 [00:03<00:55,  3.78it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.78it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.78it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.78it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.78it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.78it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.78it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.78it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.78it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.78it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:52,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:47,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:22<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:23,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:37<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:51<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:37,  5.83it/s][A
  1%|          | 2/221 [00:00<01:07,  3.23it/s][A
  1%|▏         | 3/221 [00:00<01:07,  3.24it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.77it/s][A
  2%|▏         | 5/221 [00:01<00:51,  4.21it/s][A
  3%|▎         | 7/221 [00:01<00:45,  4.74it/s][A
  4%|▎         | 8/221 [00:01<00:47,  4.45it/s][A
  4%|▍         | 9/221 [00:02<00:48,  4.40it/s][A
  5%|▍         | 10/221 [00:02<01:07,  3.12it/s][A
  5%|▍         | 11/221 [00:02<00:59,  3.50it/s][A
  5%|▌         | 12/221 [00:03<00:51,  4.04it/s][A
  6%|▌         | 13/221 [00:03<01:15,  2.74it/s][A
  7%|▋         | 15/221 [00:04<00:55,  3.73it/s][A
  7%|▋         | 16/221 [00:04<01:02,  3.26it/s][A
  8%|▊         | 17/221 [00:05<01:25,  2.37it/s][A
  8%|▊         | 18/221 [00:05<01:13,  2.74it/s][A
  9%|▊         | 19/221 [00:05<01:06,  3.04it/s][A
  9%|▉         | 20/221 [00:05<00:54,  3.67it/s][A
 10%|▉         | 21/221 [00:05<00:48,  4.11it/s][A
 10%|▉         | 22/221 [00:06<00:47,  4.23it/s][A
 11%|█         | 24/221 [00:06<00:37,  5.30it/s][A
 11%|█▏        | 25/221 [00:06<00:38,  5.09it/s][A
 12%|█▏        | 26/221 [00:06<00:41,  4.75it/s][A
 12%|█▏        | 27/221 [00:06<00:35,  5.39it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.80it/s][A
 13%|█▎        | 29/221 [00:07<00:43,  4.41it/s][A
 14%|█▎        | 30/221 [00:07<00:44,  4.26it/s][A
 14%|█▍        | 31/221 [00:08<00:42,  4.46it/s][A
 15%|█▍        | 33/221 [00:08<00:34,  5.48it/s][A
 15%|█▌        | 34/221 [00:08<00:30,  6.14it/s][A
 16%|█▌        | 35/221 [00:08<00:34,  5.38it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.82it/s][A
 17%|█▋        | 37/221 [00:09<00:46,  3.95it/s][A
 17%|█▋        | 38/221 [00:09<00:51,  3.58it/s][A
 18%|█▊        | 39/221 [00:09<00:42,  4.24it/s][A
 18%|█▊        | 40/221 [00:10<00:42,  4.22it/s][A
 19%|█▊        | 41/221 [00:10<00:37,  4.84it/s][A
 19%|█▉        | 42/221 [00:10<00:46,  3.87it/s][A
 19%|█▉        | 43/221 [00:10<00:52,  3.37it/s][A
 20%|█▉        | 44/221 [00:11<00:49,  3.58it/s][A
 20%|██        | 45/221 [00:11<00:48,  3.66it/s][A
 21%|██        | 46/221 [00:11<00:42,  4.17it/s][A
 21%|██▏       | 47/221 [00:11<00:41,  4.17it/s][A
 22%|██▏       | 48/221 [00:12<00:37,  4.62it/s][A
 22%|██▏       | 49/221 [00:12<00:36,  4.68it/s][A
 23%|██▎       | 50/221 [00:12<00:39,  4.37it/s][A
 23%|██▎       | 51/221 [00:12<00:35,  4.76it/s][A
 24%|██▎       | 52/221 [00:12<00:34,  4.93it/s][A
 24%|██▍       | 53/221 [00:12<00:30,  5.56it/s][A
 24%|██▍       | 54/221 [00:13<00:56,  2.93it/s][A
 25%|██▍       | 55/221 [00:13<00:53,  3.08it/s][A
 25%|██▌       | 56/221 [00:14<00:44,  3.73it/s][A
 26%|██▌       | 57/221 [00:14<00:41,  3.92it/s][A
 26%|██▌       | 58/221 [00:14<00:40,  4.03it/s][A
 27%|██▋       | 59/221 [00:14<00:38,  4.17it/s][A
 27%|██▋       | 60/221 [00:15<00:43,  3.67it/s][A
 28%|██▊       | 61/221 [00:15<00:39,  4.09it/s][A
 28%|██▊       | 62/221 [00:15<00:41,  3.87it/s][A
 29%|██▊       | 63/221 [00:15<00:39,  4.00it/s][A
 29%|██▉       | 64/221 [00:16<00:47,  3.32it/s][A
 29%|██▉       | 65/221 [00:16<00:38,  4.04it/s][A
 30%|██▉       | 66/221 [00:16<00:47,  3.26it/s][A
 30%|███       | 67/221 [00:17<00:54,  2.84it/s][A
 31%|███       | 68/221 [00:17<00:44,  3.42it/s][A
 31%|███       | 69/221 [00:18<00:59,  2.56it/s][A
 32%|███▏      | 70/221 [00:18<00:47,  3.20it/s][A
 32%|███▏      | 71/221 [00:18<00:40,  3.69it/s][A
 33%|███▎      | 72/221 [00:18<00:44,  3.34it/s][A
 33%|███▎      | 73/221 [00:19<00:49,  2.98it/s][A
 33%|███▎      | 74/221 [00:19<00:39,  3.73it/s][A
 34%|███▍      | 75/221 [00:19<00:39,  3.66it/s][A
 34%|███▍      | 76/221 [00:19<00:35,  4.03it/s][A
 35%|███▍      | 77/221 [00:19<00:33,  4.36it/s][A
 35%|███▌      | 78/221 [00:20<00:28,  4.97it/s][A
 36%|███▌      | 79/221 [00:20<00:40,  3.52it/s][A
 36%|███▌      | 80/221 [00:20<00:35,  3.93it/s][A
 37%|███▋      | 81/221 [00:20<00:33,  4.12it/s][A
 37%|███▋      | 82/221 [00:21<00:35,  3.92it/s][A
 38%|███▊      | 83/221 [00:21<00:41,  3.33it/s][A
 38%|███▊      | 84/221 [00:21<00:34,  3.99it/s][A
 38%|███▊      | 85/221 [00:21<00:28,  4.69it/s][A
 39%|███▉      | 86/221 [00:22<00:27,  4.98it/s][A
 39%|███▉      | 87/221 [00:22<00:53,  2.50it/s][A
 40%|███▉      | 88/221 [00:23<00:55,  2.42it/s][A
 40%|████      | 89/221 [00:23<00:47,  2.77it/s][A
 41%|████      | 90/221 [00:23<00:45,  2.91it/s][A
 41%|████      | 91/221 [00:24<00:37,  3.51it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.71it/s][A
 42%|████▏     | 93/221 [00:25<00:52,  2.44it/s][A
 43%|████▎     | 94/221 [00:25<00:47,  2.69it/s][A
 43%|████▎     | 95/221 [00:25<00:43,  2.90it/s][A
 43%|████▎     | 96/221 [00:25<00:36,  3.41it/s][A
 44%|████▍     | 97/221 [00:25<00:33,  3.71it/s][A
 44%|████▍     | 98/221 [00:26<00:32,  3.84it/s][A
 45%|████▍     | 99/221 [00:26<00:28,  4.31it/s][A
 45%|████▌     | 100/221 [00:26<00:28,  4.32it/s][A
 46%|████▌     | 101/221 [00:26<00:29,  4.08it/s][A
 46%|████▌     | 102/221 [00:27<00:44,  2.65it/s][A
 47%|████▋     | 103/221 [00:27<00:35,  3.32it/s][A
 47%|████▋     | 104/221 [00:27<00:31,  3.75it/s][A
 48%|████▊     | 105/221 [00:28<00:29,  3.96it/s][A
 48%|████▊     | 106/221 [00:28<00:37,  3.04it/s][A
 48%|████▊     | 107/221 [00:28<00:34,  3.35it/s][A
 49%|████▉     | 108/221 [00:29<00:32,  3.47it/s][A
 49%|████▉     | 109/221 [00:29<00:26,  4.15it/s][A
 50%|████▉     | 110/221 [00:29<00:27,  4.04it/s][A
 50%|█████     | 111/221 [00:29<00:28,  3.86it/s][A
 51%|█████     | 112/221 [00:30<00:28,  3.78it/s][A
 51%|█████     | 113/221 [00:30<00:25,  4.18it/s][A
 52%|█████▏    | 115/221 [00:30<00:20,  5.05it/s][A
 52%|█████▏    | 116/221 [00:30<00:22,  4.67it/s][A
 53%|█████▎    | 117/221 [00:31<00:26,  3.97it/s][A
 53%|█████▎    | 118/221 [00:31<00:24,  4.15it/s][A
 54%|█████▍    | 119/221 [00:31<00:32,  3.15it/s][A
 54%|█████▍    | 120/221 [00:32<00:28,  3.56it/s][A
 55%|█████▌    | 122/221 [00:32<00:23,  4.24it/s][A
 56%|█████▌    | 123/221 [00:32<00:23,  4.17it/s][A
 56%|█████▌    | 124/221 [00:33<00:25,  3.73it/s][A
 57%|█████▋    | 125/221 [00:33<00:26,  3.56it/s][A
 57%|█████▋    | 126/221 [00:33<00:24,  3.93it/s][A
 57%|█████▋    | 127/221 [00:34<00:30,  3.13it/s][A
 58%|█████▊    | 128/221 [00:34<00:27,  3.33it/s][A
 59%|█████▉    | 130/221 [00:34<00:20,  4.48it/s][A
 59%|█████▉    | 131/221 [00:34<00:18,  4.96it/s][A
 60%|█████▉    | 132/221 [00:35<00:25,  3.43it/s][A
 60%|██████    | 133/221 [00:35<00:25,  3.45it/s][A
 61%|██████    | 134/221 [00:36<00:29,  2.91it/s][A
 61%|██████    | 135/221 [00:36<00:32,  2.62it/s][A
 62%|██████▏   | 136/221 [00:36<00:29,  2.87it/s][A
 62%|██████▏   | 137/221 [00:36<00:25,  3.29it/s][A
 62%|██████▏   | 138/221 [00:37<00:25,  3.20it/s][A
 63%|██████▎   | 139/221 [00:37<00:30,  2.73it/s][A
 63%|██████▎   | 140/221 [00:38<00:27,  2.98it/s][A
 64%|██████▍   | 141/221 [00:38<00:23,  3.43it/s][A
 64%|██████▍   | 142/221 [00:38<00:21,  3.76it/s][A
 65%|██████▍   | 143/221 [00:39<00:29,  2.65it/s][A
 65%|██████▌   | 144/221 [00:39<00:31,  2.48it/s][A
 66%|██████▌   | 146/221 [00:39<00:19,  3.93it/s][A
 67%|██████▋   | 147/221 [00:40<00:19,  3.76it/s][A
 67%|██████▋   | 148/221 [00:40<00:21,  3.40it/s][A
 67%|██████▋   | 149/221 [00:40<00:20,  3.53it/s][A
 68%|██████▊   | 150/221 [00:40<00:19,  3.60it/s][A
 68%|██████▊   | 151/221 [00:41<00:22,  3.13it/s][A
 69%|██████▉   | 152/221 [00:42<00:37,  1.86it/s][A
 69%|██████▉   | 153/221 [00:42<00:29,  2.34it/s][A
 70%|██████▉   | 154/221 [00:42<00:24,  2.71it/s][A
 70%|███████   | 155/221 [00:43<00:24,  2.71it/s][A
 71%|███████   | 156/221 [00:43<00:25,  2.57it/s][A
 71%|███████   | 157/221 [00:43<00:23,  2.77it/s][A
 71%|███████▏  | 158/221 [00:44<00:21,  2.88it/s][A
 72%|███████▏  | 160/221 [00:44<00:16,  3.63it/s][A
 73%|███████▎  | 161/221 [00:44<00:15,  3.94it/s][A
 73%|███████▎  | 162/221 [00:44<00:13,  4.38it/s][A
 74%|███████▍  | 163/221 [00:45<00:14,  4.14it/s][A
 74%|███████▍  | 164/221 [00:45<00:11,  4.88it/s][A
 75%|███████▍  | 165/221 [00:45<00:11,  4.99it/s][A
 75%|███████▌  | 166/221 [00:45<00:12,  4.49it/s][A
 76%|███████▌  | 168/221 [00:46<00:10,  5.20it/s][A
 76%|███████▋  | 169/221 [00:46<00:09,  5.40it/s][A
 77%|███████▋  | 170/221 [00:46<00:12,  4.21it/s][A
 77%|███████▋  | 171/221 [00:46<00:12,  3.95it/s][A
 78%|███████▊  | 172/221 [00:47<00:10,  4.54it/s][A
 78%|███████▊  | 173/221 [00:47<00:13,  3.63it/s][A
 79%|███████▊  | 174/221 [00:47<00:16,  2.91it/s][A
 79%|███████▉  | 175/221 [00:48<00:15,  2.97it/s][A
 80%|███████▉  | 176/221 [00:48<00:12,  3.51it/s][A
 80%|████████  | 177/221 [00:48<00:11,  3.91it/s][A
 81%|████████  | 178/221 [00:48<00:10,  4.26it/s][A
 81%|████████  | 179/221 [00:49<00:10,  3.89it/s][A
 81%|████████▏ | 180/221 [00:49<00:09,  4.30it/s][A
 82%|████████▏ | 181/221 [00:49<00:08,  4.70it/s][A
 82%|████████▏ | 182/221 [00:49<00:09,  4.01it/s][A
 83%|████████▎ | 183/221 [00:50<00:09,  3.88it/s][A
 83%|████████▎ | 184/221 [00:50<00:08,  4.12it/s][A
 84%|████████▎ | 185/221 [00:50<00:07,  4.78it/s][A
 84%|████████▍ | 186/221 [00:50<00:09,  3.64it/s][A
 85%|████████▍ | 187/221 [00:51<00:09,  3.49it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.47it/s][A
 86%|████████▌ | 189/221 [00:51<00:08,  3.60it/s][A
 86%|████████▌ | 190/221 [00:52<00:09,  3.24it/s][A
 86%|████████▋ | 191/221 [00:52<00:08,  3.74it/s][A
 87%|████████▋ | 192/221 [00:52<00:07,  3.89it/s][A
 88%|████████▊ | 194/221 [00:53<00:07,  3.70it/s][A
 88%|████████▊ | 195/221 [00:53<00:06,  3.83it/s][A
 89%|████████▊ | 196/221 [00:53<00:08,  3.10it/s][A
 89%|████████▉ | 197/221 [00:54<00:07,  3.02it/s][A
 90%|████████▉ | 198/221 [00:54<00:08,  2.71it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.20it/s][A
 90%|█████████ | 200/221 [00:55<00:07,  2.92it/s][A
 91%|█████████ | 201/221 [00:55<00:06,  3.22it/s][A
 91%|█████████▏| 202/221 [00:55<00:05,  3.23it/s][A
 92%|█████████▏| 203/221 [00:56<00:05,  3.49it/s][A
 92%|█████████▏| 204/221 [00:56<00:05,  2.94it/s][A
 93%|█████████▎| 205/221 [00:56<00:04,  3.70it/s][A
 93%|█████████▎| 206/221 [00:57<00:04,  3.16it/s][A
 94%|█████████▍| 208/221 [00:57<00:03,  3.89it/s][A
 95%|█████████▍| 209/221 [00:57<00:03,  3.90it/s][A
 95%|█████████▌| 211/221 [00:58<00:02,  4.24it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  4.17it/s][A
 96%|█████████▋| 213/221 [00:58<00:01,  4.33it/s][A
 97%|█████████▋| 214/221 [00:58<00:02,  3.49it/s][A
 97%|█████████▋| 215/221 [00:59<00:01,  3.67it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.44it/s][A
 98%|█████████▊| 217/221 [00:59<00:01,  3.25it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.41it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.28it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.76it/s][A
100%|██████████| 221/221 [01:00<00:00,  4.12it/s][A100%|██████████| 221/221 [01:00<00:00,  3.63it/s]
09/09/2024 18:42:42 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 299--===========

09/09/2024 18:42:42 - INFO - __main__ -   {'area_r1': 40.7, 'area_recall': '40.7/66.7/76.1', 'area_ravg': 61.2}
09/09/2024 18:42:42 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 299--===========

09/09/2024 18:42:42 - INFO - __main__ -   {'forward_r1': 38.1, 'forward_recall': '38.1/64.4/74.8', 'forward_ravg': 59.1}
09/09/2024 18:42:42 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 299--===========

09/09/2024 18:42:42 - INFO - __main__ -   {'area_video_r1': 40.4, 'area_video_recall': '40.4/68.2/77.5', 'area_video_ravg': 62.0}
09/09/2024 18:42:42 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/09/2024 18:42:42 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 18:42:42 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 299--===========

09/09/2024 18:42:42 - INFO - __main__ -   {'area_video_r1': 52.3, 'area_video_recall': '52.3/75.3/82.1', 'area_video_ravg': 69.9, 'area_video_back_r1': 51.0, 'area_video_back_recall': '51.0/74.7/81.9', 'area_video_back_ravg': 69.2}
09/09/2024 18:42:42 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 299=======

09/09/2024 18:42:42 - INFO - __main__ -   {'area_video_r1': 52.3, 'area_video_recall': '52.3/75.3/82.1', 'area_video_ravg': 69.9, 'area_video_back_r1': 51.0, 'area_video_back_recall': '51.0/74.7/81.9', 'area_video_back_ravg': 69.2}
09/09/2024 18:42:42 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 299--===========

09/09/2024 18:42:42 - INFO - __main__ -   {'video_r1': 41.7, 'video_recall': '41.7/70.1/80.4', 'video_ravg': 64.1}
09/09/2024 18:42:42 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 18:42:42 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 18:42:42 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 299--===========

09/09/2024 18:42:42 - INFO - __main__ -   {'video_r1': 52.8, 'video_recall': '52.8/75.2/82.4', 'video_ravg': 70.1}
09/09/2024 18:42:42 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 299=======

09/09/2024 18:42:42 - INFO - __main__ -   {'video_r1': 52.8, 'video_recall': '52.8/75.2/82.4', 'video_ravg': 70.1}
09/09/2024 18:43:15 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.007340382318943739, 'loss_ret%tv%ta--finetune_area/loss_area': 1.3390424251556396, 'loss_ret%tv%ta--finetune_area/total_loss': 1.3463828563690186}
[h264 @ 0x556a8e0ac1c0] mmco: unref short failure
[h264 @ 0x556a8e0ac1c0] mmco: unref short failure
[h264 @ 0x556a8e0ac1c0] mmco: unref short failure
[h264 @ 0x556a8e0ac1c0] mmco: unref short failure
[h264 @ 0x556a8e0ac1c0] mmco: unref short failure
[h264 @ 0x556a8e0ac1c0] mmco: unref short failure
 15%|█▌        | 300/1945 [1:37:55<57:49:15, 126.54s/it] 15%|█▌        | 301/1945 [1:37:59<41:02:04, 89.86s/it] [h264 @ 0x559f866f8400] mmco: unref short failure
 16%|█▌        | 302/1945 [1:38:04<29:22:09, 64.35s/it] 16%|█▌        | 303/1945 [1:38:10<21:19:37, 46.76s/it][h264 @ 0x562368de6f40] mmco: unref short failure
 16%|█▌        | 304/1945 [1:38:16<15:43:01, 34.48s/it][h264 @ 0x56238351c000] mmco: unref short failure
[h264 @ 0x556a894d1d80] mmco: unref short failure
 16%|█▌        | 305/1945 [1:38:23<12:01:34, 26.40s/it][h264 @ 0x562377794d00] mmco: unref short failure
 16%|█▌        | 306/1945 [1:38:31<9:24:58, 20.68s/it] [h264 @ 0x56237df05780] mmco: unref short failure
[h264 @ 0x56237df05780] mmco: unref short failure
[h264 @ 0x56236f497b40] mmco: unref short failure
[h264 @ 0x56236f497b40] mmco: unref short failure
[h264 @ 0x56236f497b40] mmco: unref short failure
 16%|█▌        | 307/1945 [1:38:38<7:37:02, 16.74s/it][h264 @ 0x556a7e1a0440] mmco: unref short failure
[h264 @ 0x559b38d04e40] mmco: unref short failure
[h264 @ 0x556a854340c0] mmco: unref short failure
[h264 @ 0x556a854340c0] mmco: unref short failure
 16%|█▌        | 308/1945 [1:38:46<6:19:08, 13.90s/it][h264 @ 0x562363713a80] mmco: unref short failure
[h264 @ 0x5623630dda80] mmco: unref short failure
 16%|█▌        | 309/1945 [1:38:53<5:23:35, 11.87s/it][h264 @ 0x559b56495140] mmco: unref short failure
[h264 @ 0x559b56495140] mmco: unref short failure
[h264 @ 0x562381cf3700] mmco: unref short failure
 16%|█▌        | 310/1945 [1:39:01<4:56:55, 10.90s/it][h264 @ 0x56236c757d80] mmco: unref short failure
[h264 @ 0x556a8b7e27c0] mmco: unref short failure
[h264 @ 0x556a8b7e27c0] mmco: unref short failure
 16%|█▌        | 311/1945 [1:39:09<4:30:16,  9.92s/it][h264 @ 0x559b47750bc0] mmco: unref short failure
[h264 @ 0x559b47750bc0] mmco: unref short failure
[h264 @ 0x559b47750bc0] mmco: unref short failure
[h264 @ 0x559b47750bc0] mmco: unref short failure
[h264 @ 0x559b47750bc0] mmco: unref short failure
[h264 @ 0x559b47750bc0] mmco: unref short failure
[h264 @ 0x556a8bd25840] mmco: unref short failure
[h264 @ 0x556a8bd25840] mmco: unref short failure
 16%|█▌        | 312/1945 [1:39:17<4:13:58,  9.33s/it][h264 @ 0x562379ab6d00] mmco: unref short failure
[h264 @ 0x559b4f8c1340] mmco: unref short failure
[h264 @ 0x556a863f5900] mmco: unref short failure
 16%|█▌        | 313/1945 [1:39:24<3:58:11,  8.76s/it][h264 @ 0x556a8f2d8dc0] mmco: unref short failure
 16%|█▌        | 314/1945 [1:39:31<3:39:37,  8.08s/it] 16%|█▌        | 315/1945 [1:39:37<3:27:04,  7.62s/it][h264 @ 0x559f9c4da040] mmco: unref short failure
 16%|█▌        | 316/1945 [1:39:44<3:21:50,  7.43s/it] 16%|█▋        | 317/1945 [1:39:51<3:15:33,  7.21s/it][h264 @ 0x559b3af2a5c0] mmco: unref short failure
[h264 @ 0x559b3af2a5c0] mmco: unref short failure
[h264 @ 0x56236ebf3680] mmco: unref short failure
[h264 @ 0x56236ebf3680] mmco: unref short failure
[h264 @ 0x559b36056d00] mmco: unref short failure
[h264 @ 0x559b3e5c6280] mmco: unref short failure
[h264 @ 0x559b3e5c6280] mmco: unref short failure
[h264 @ 0x559b3e5c6280] mmco: unref short failure
[h264 @ 0x559b3e5c6280] mmco: unref short failure
 16%|█▋        | 318/1945 [1:39:59<3:19:05,  7.34s/it] 16%|█▋        | 319/1945 [1:40:06<3:20:44,  7.41s/it][h264 @ 0x5623822a4780] mmco: unref short failure
[h264 @ 0x5623822a4780] mmco: unref short failure
[h264 @ 0x562380372880] mmco: unref short failure
[h264 @ 0x562380372880] mmco: unref short failure
[h264 @ 0x56237def3bc0] mmco: unref short failure
[h264 @ 0x559b41059d40] mmco: unref short failure
[h264 @ 0x556a86c40740] mmco: unref short failure
[h264 @ 0x556a86c40740] mmco: unref short failure
[h264 @ 0x559f7d27c540] mmco: unref short failure
[h264 @ 0x559f7d27c540] mmco: unref short failure
 16%|█▋        | 320/1945 [1:40:22<4:31:29, 10.02s/it][h264 @ 0x559f97b0f2c0] mmco: unref short failure
[h264 @ 0x559f97b0f2c0] mmco: unref short failure
[h264 @ 0x556a92713300] mmco: unref short failure
[h264 @ 0x556a92713300] mmco: unref short failure
 17%|█▋        | 321/1945 [1:40:29<4:06:39,  9.11s/it][h264 @ 0x556a7f826700] mmco: unref short failure
[h264 @ 0x556a7f826700] mmco: unref short failure
[h264 @ 0x559f8410ef40] mmco: unref short failure
[h264 @ 0x559b4848d240] mmco: unref short failure
[h264 @ 0x559b4848d240] mmco: unref short failure
 17%|█▋        | 322/1945 [1:40:39<4:12:41,  9.34s/it] 17%|█▋        | 323/1945 [1:40:47<3:55:38,  8.72s/it][h264 @ 0x559f85419c00] mmco: unref short failure
[h264 @ 0x559f85419c00] mmco: unref short failure
[h264 @ 0x559f8f6d1200] mmco: unref short failure
[h264 @ 0x559f94ae15c0] mmco: unref short failure
[h264 @ 0x559f94ae15c0] mmco: unref short failure
[h264 @ 0x559f9dcb10c0] mmco: unref short failure
[h264 @ 0x556a87719dc0] mmco: unref short failure
[h264 @ 0x556a87719dc0] mmco: unref short failure
[h264 @ 0x559b37b0d240] mmco: unref short failure
[h264 @ 0x559b37b0d240] mmco: unref short failure
[h264 @ 0x559b4aaa8840] mmco: unref short failure
[h264 @ 0x556a912c50c0] mmco: unref short failure
[h264 @ 0x556a912c50c0] mmco: unref short failure
[h264 @ 0x559f904f6a40] mmco: unref short failure
[h264 @ 0x556a92664f00] mmco: unref short failure
[h264 @ 0x556a92664f00] mmco: unref short failure
[h264 @ 0x5623639310c0] mmco: unref short failure
[h264 @ 0x5623639310c0] mmco: unref short failure
[h264 @ 0x5623639310c0] mmco: unref short failure
[h264 @ 0x559b46737ec0] mmco: unref short failure
[h264 @ 0x559b46737ec0] mmco: unref short failure
[h264 @ 0x559f9687a7c0] mmco: unref short failure
[h264 @ 0x559b3a08f800] mmco: unref short failure
[h264 @ 0x559f9b58d480] mmco: unref short failure
[h264 @ 0x559f8ac71f00] mmco: unref short failure
[h264 @ 0x559f8ac71f00] mmco: unref short failure
 17%|█▋        | 324/1945 [1:41:37<9:35:43, 21.31s/it][h264 @ 0x559f8541e600] mmco: unref short failure
[h264 @ 0x559f9aa25840] mmco: unref short failure
[h264 @ 0x559f9aa25840] mmco: unref short failure
[h264 @ 0x556a911fd780] mmco: unref short failure
[h264 @ 0x556a911fd780] mmco: unref short failure
 17%|█▋        | 325/1945 [1:41:53<8:48:53, 19.59s/it] 17%|█▋        | 326/1945 [1:42:01<7:14:25, 16.10s/it][h264 @ 0x559b4e407cc0] mmco: unref short failure
[h264 @ 0x559b4e407cc0] mmco: unref short failure
[h264 @ 0x559f92010240] mmco: unref short failure
[h264 @ 0x559f92010240] mmco: unref short failure
 17%|█▋        | 327/1945 [1:42:12<6:31:46, 14.53s/it][h264 @ 0x559b3d57e080] mmco: unref short failure
[h264 @ 0x559b3d57e080] mmco: unref short failure
[h264 @ 0x562380d46840] mmco: unref short failure
[h264 @ 0x559f8ac72100] mmco: unref short failure
[h264 @ 0x559f8ac72100] mmco: unref short failure
[h264 @ 0x5623738b78c0] mmco: unref short failure
[h264 @ 0x56237636f380] mmco: unref short failure
[h264 @ 0x559b444a5000] mmco: unref short failure
 17%|█▋        | 328/1945 [1:42:27<6:38:41, 14.79s/it][h264 @ 0x556a972f0500] mmco: unref short failure
 17%|█▋        | 329/1945 [1:42:34<5:37:55, 12.55s/it][h264 @ 0x559b3602ae00] mmco: unref short failure
[h264 @ 0x559b3602ae00] mmco: unref short failure
[h264 @ 0x559b3602ae00] mmco: unref short failure
[h264 @ 0x559b3602ae00] mmco: unref short failure
 17%|█▋        | 330/1945 [1:42:45<5:24:08, 12.04s/it][h264 @ 0x559b3657bf40] mmco: unref short failure
 17%|█▋        | 331/1945 [1:42:53<4:46:03, 10.63s/it][h264 @ 0x562374eb9340] mmco: unref short failure
[h264 @ 0x562374eb9340] mmco: unref short failure
[h264 @ 0x556a9b394700] mmco: unref short failure
[h264 @ 0x556a9b394700] mmco: unref short failure
[h264 @ 0x556a9b394900] mmco: unref short failure
[h264 @ 0x562380162080] mmco: unref short failure
[h264 @ 0x562362e134c0] mmco: unref short failure
[h264 @ 0x562362e134c0] mmco: unref short failure
[h264 @ 0x562362e134c0] mmco: unref short failure
[h264 @ 0x562362e134c0] mmco: unref short failure
[h264 @ 0x562362e134c0] mmco: unref short failure
[h264 @ 0x562362e134c0] mmco: unref short failure
[h264 @ 0x562362e134c0] mmco: unref short failure
[h264 @ 0x562362e134c0] mmco: unref short failure
[h264 @ 0x562362e134c0] mmco: unref short failure
[h264 @ 0x559f86997bc0] mmco: unref short failure
[h264 @ 0x559b39515040] mmco: unref short failure
[h264 @ 0x559b39515040] mmco: unref short failure
[h264 @ 0x559b39515040] mmco: unref short failure
[h264 @ 0x5623706e06c0] mmco: unref short failure
[h264 @ 0x5623706e06c0] mmco: unref short failure
[h264 @ 0x556a83c31880] mmco: unref short failure
[h264 @ 0x556a83c31880] mmco: unref short failure
[h264 @ 0x5623635de900] mmco: unref short failure
[h264 @ 0x556a94084000] mmco: unref short failure
[h264 @ 0x556a94084000] mmco: unref short failure
[h264 @ 0x556a7b10b980] mmco: unref short failure
[h264 @ 0x559b50b873c0] mmco: unref short failure
[h264 @ 0x559f7f2f1c00] mmco: unref short failure
[h264 @ 0x559f7f2f1c00] mmco: unref short failure
[h264 @ 0x559f7f2f1c00] mmco: unref short failure
[h264 @ 0x559f7f2f1c00] mmco: unref short failure
[h264 @ 0x556a8e0bed00] mmco: unref short failure
 17%|█▋        | 332/1945 [1:43:45<10:25:46, 23.28s/it][h264 @ 0x559b3ce66ec0] mmco: unref short failure
[h264 @ 0x559b3ce66ec0] mmco: unref short failure
 17%|█▋        | 333/1945 [1:43:53<8:17:17, 18.51s/it]  17%|█▋        | 334/1945 [1:44:05<7:29:35, 16.74s/it] 17%|█▋        | 335/1945 [1:44:13<6:19:16, 14.13s/it][h264 @ 0x556a7a672440] mmco: unref short failure
[h264 @ 0x559f864e3140] mmco: unref short failure
[h264 @ 0x559f864e3140] mmco: unref short failure
[h264 @ 0x559f8d246e80] mmco: unref short failure
[h264 @ 0x56237db260c0] mmco: unref short failure
[h264 @ 0x56237db260c0] mmco: unref short failure
 17%|█▋        | 336/1945 [1:44:39<7:48:21, 17.47s/it][h264 @ 0x559f85bec980] mmco: unref short failure
[h264 @ 0x559f964f0dc0] mmco: unref short failure
[h264 @ 0x559f87337440] mmco: unref short failure
 17%|█▋        | 337/1945 [1:44:47<6:35:45, 14.77s/it][h264 @ 0x559f9b2e8a80] mmco: unref short failure
[h264 @ 0x559f9b2e8a80] mmco: unref short failure
[h264 @ 0x559f8a71c840] mmco: unref short failure
[h264 @ 0x559f86cb0300] mmco: unref short failure
[h264 @ 0x559f86cb0300] mmco: unref short failure
 17%|█▋        | 338/1945 [1:44:55<5:37:57, 12.62s/it] 17%|█▋        | 339/1945 [1:45:04<5:08:12, 11.51s/it][h264 @ 0x559f9700cc00] mmco: unref short failure
[h264 @ 0x559f9700cc00] mmco: unref short failure
[h264 @ 0x56237f080780] mmco: unref short failure
[h264 @ 0x56237f080780] mmco: unref short failure
[h264 @ 0x559b541fa800] mmco: unref short failure
[h264 @ 0x56237f080780] mmco: unref short failure
[h264 @ 0x56237f080780] mmco: unref short failure
[h264 @ 0x56237f080780] mmco: unref short failure
[h264 @ 0x56237f080780] mmco: unref short failure
[h264 @ 0x559f7e6fddc0] mmco: unref short failure
[h264 @ 0x559b3c8df9c0] mmco: unref short failure
[h264 @ 0x559b3c8df9c0] mmco: unref short failure
[h264 @ 0x559b433f1040] mmco: unref short failure
[h264 @ 0x559b433f1040] mmco: unref short failure
[h264 @ 0x559f904d2f80] mmco: unref short failure
[h264 @ 0x559f904d2f80] mmco: unref short failure
[h264 @ 0x559f904d2f80] mmco: unref short failure
[h264 @ 0x559f904d2f80] mmco: unref short failure
[h264 @ 0x556a77cc71c0] mmco: unref short failure
[h264 @ 0x556a7e64bc00] mmco: unref short failure
[h264 @ 0x556a7e64bc00] mmco: unref short failure
[h264 @ 0x5623820811c0] mmco: unref short failure
[h264 @ 0x5623820811c0] mmco: unref short failure
[h264 @ 0x559f827c1a00] mmco: unref short failure
[h264 @ 0x559f9a550380] mmco: unref short failure
[h264 @ 0x559f9a550380] mmco: unref short failure
[h264 @ 0x56236ee67c80] mmco: unref short failure
[h264 @ 0x559b355571c0] mmco: unref short failure
[h264 @ 0x559b355571c0] mmco: unref short failure
[h264 @ 0x556a792b7700] mmco: unref short failure
[h264 @ 0x559f8d246e80] mmco: unref short failure
[h264 @ 0x556a7e4a9840] mmco: unref short failure
[h264 @ 0x556a7e4a9840] mmco: unref short failure
[h264 @ 0x56236434bf00] mmco: unref short failure
[h264 @ 0x56236434bf00] mmco: unref short failure
 17%|█▋        | 340/1945 [1:45:47<9:22:57, 21.05s/it][h264 @ 0x559f810e1180] mmco: unref short failure
 18%|█▊        | 341/1945 [1:45:58<8:03:02, 18.07s/it][h264 @ 0x559b3a5c7280] mmco: unref short failure
[h264 @ 0x559f868a2280] mmco: unref short failure
[h264 @ 0x559f868a2280] mmco: unref short failure
 18%|█▊        | 342/1945 [1:46:12<7:29:55, 16.84s/it][h264 @ 0x56237e7fd900] mmco: unref short failure
[h264 @ 0x559b3657bf40] mmco: unref short failure
[h264 @ 0x559b3657bf40] mmco: unref short failure
 18%|█▊        | 343/1945 [1:46:20<6:15:55, 14.08s/it][h264 @ 0x559b54f0dec0] mmco: unref short failure
[h264 @ 0x559b54f0dec0] mmco: unref short failure
[h264 @ 0x559f846e1d00] mmco: unref short failure
[h264 @ 0x559f846e1d00] mmco: unref short failure
[h264 @ 0x5623673c1fc0] mmco: unref short failure
 18%|█▊        | 344/1945 [1:46:39<7:00:05, 15.74s/it][h264 @ 0x56236354be00] mmco: unref short failure
[h264 @ 0x559f89a38b40] mmco: unref short failure
 18%|█▊        | 345/1945 [1:46:46<5:46:12, 12.98s/it][h264 @ 0x556a84813480] mmco: unref short failure
 18%|█▊        | 346/1945 [1:46:53<5:00:07, 11.26s/it][h264 @ 0x559b52cb2780] mmco: unref short failure
[h264 @ 0x559b52cb2780] mmco: unref short failure
 18%|█▊        | 347/1945 [1:47:01<4:29:26, 10.12s/it][h264 @ 0x559f7da9e7c0] mmco: unref short failure
[h264 @ 0x559f92ea3740] mmco: unref short failure
[h264 @ 0x556a94682080] mmco: unref short failure
[h264 @ 0x559b49be1340] mmco: unref short failure
[h264 @ 0x559f83eed240] mmco: unref short failure
[h264 @ 0x559f83eed240] mmco: unref short failure
[h264 @ 0x562381ce8500] mmco: unref short failure
[h264 @ 0x562381ce8500] mmco: unref short failure
[h264 @ 0x562362ceea00] mmco: unref short failure
[h264 @ 0x562362ceea00] mmco: unref short failure
[h264 @ 0x556a933d2640] mmco: unref short failure
[h264 @ 0x556a933d2640] mmco: unref short failure
[h264 @ 0x562380d46a80] mmco: unref short failure
[h264 @ 0x56236dfd7240] mmco: unref short failure
[h264 @ 0x56236dfd7240] mmco: unref short failure
[h264 @ 0x56238164f5c0] mmco: unref short failure
[h264 @ 0x56238164f5c0] mmco: unref short failure
 18%|█▊        | 348/1945 [1:47:52<10:03:32, 22.68s/it][h264 @ 0x556a7b759cc0] mmco: unref short failure
 18%|█▊        | 349/1945 [1:48:01<8:09:44, 18.41s/it] 09/09/2024 18:53:23 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 18:53:23 - INFO - __main__ -   start running ret%tv validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559b3c354700] mmco: unref short failure
[h264 @ 0x559b3c354700] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x56237c133080] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559b37c015c0] mmco: unref short failure
[h264 @ 0x559f7ffa4040] mmco: unref short failure
[h264 @ 0x559f7ffa4040] mmco: unref short failure
[h264 @ 0x559f7ffa4040] mmco: unref short failure
[h264 @ 0x559f7ffa4040] mmco: unref short failure
[h264 @ 0x559f7c7f1b80] mmco: unref short failure
[h264 @ 0x559f7c7f1b80] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556a7fb57f40] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559b54fb1340] mmco: unref short failure
[h264 @ 0x556a82e4ad00] mmco: unref short failure
[h264 @ 0x556a82e4ad00] mmco: unref short failure
[h264 @ 0x559b3e879840] mmco: unref short failure
[h264 @ 0x559b3e879840] mmco: unref short failure
[h264 @ 0x559b3e879840] mmco: unref short failure
[h264 @ 0x559b3e879840] mmco: unref short failure
[h264 @ 0x56236a595780] mmco: unref short failure
[h264 @ 0x56236a595780] mmco: unref short failure
[h264 @ 0x556a84813480] mmco: unref short failure
[h264 @ 0x556a8f2cd580] mmco: unref short failure
[h264 @ 0x556a8f2cd580] mmco: unref short failure
[h264 @ 0x556a8f2cd580] mmco: unref short failure
[h264 @ 0x556a8f2cd580] mmco: unref short failure
[h264 @ 0x559b3cf7e300] mmco: unref short failure
[h264 @ 0x559b3cf7e300] mmco: unref short failure
[h264 @ 0x559b3cf7e300] mmco: unref short failure
[h264 @ 0x559b3cf7e300] mmco: unref short failure
[h264 @ 0x559b41208fc0] mmco: unref short failure
[h264 @ 0x556a8355c100] mmco: unref short failure
[h264 @ 0x556a8e9af9c0] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:36,  1.41it/s][A
  1%|          | 2/221 [00:01<02:02,  1.78it/s][A
  1%|▏         | 3/221 [00:01<01:32,  2.36it/s][A
  2%|▏         | 4/221 [00:01<01:12,  2.98it/s][A
  2%|▏         | 5/221 [00:01<01:02,  3.46it/s][A
  3%|▎         | 6/221 [00:01<00:52,  4.11it/s][A
  3%|▎         | 7/221 [00:02<00:50,  4.20it/s][A
  4%|▎         | 8/221 [00:02<00:59,  3.55it/s][A
  4%|▍         | 9/221 [00:02<01:03,  3.33it/s][A
  5%|▍         | 10/221 [00:03<01:17,  2.73it/s][A
  5%|▍         | 11/221 [00:03<01:12,  2.91it/s][A
  5%|▌         | 12/221 [00:04<01:29,  2.34it/s][A
  6%|▌         | 13/221 [00:04<01:21,  2.55it/s][A
  6%|▋         | 14/221 [00:05<01:46,  1.95it/s][A
  7%|▋         | 15/221 [00:05<01:31,  2.24it/s][A
  7%|▋         | 16/221 [00:06<01:27,  2.35it/s][A
  8%|▊         | 17/221 [00:06<01:47,  1.89it/s][A
  8%|▊         | 18/221 [00:07<01:35,  2.13it/s][A
  9%|▊         | 19/221 [00:07<01:13,  2.74it/s][A
  9%|▉         | 20/221 [00:07<01:04,  3.12it/s][A
 10%|▉         | 21/221 [00:07<00:57,  3.51it/s][A
 10%|▉         | 22/221 [00:07<00:49,  4.06it/s][A
 11%|█         | 24/221 [00:08<00:36,  5.40it/s][A
 11%|█▏        | 25/221 [00:08<00:36,  5.42it/s][A
 12%|█▏        | 26/221 [00:08<00:51,  3.76it/s][A
 12%|█▏        | 27/221 [00:09<00:46,  4.20it/s][A
 13%|█▎        | 28/221 [00:09<01:04,  3.00it/s][A
 13%|█▎        | 29/221 [00:10<01:24,  2.26it/s][A
 14%|█▎        | 30/221 [00:10<01:15,  2.54it/s][A
 14%|█▍        | 31/221 [00:10<01:07,  2.82it/s][A
 14%|█▍        | 32/221 [00:10<00:53,  3.55it/s][A
 15%|█▍        | 33/221 [00:11<00:50,  3.71it/s][A
 15%|█▌        | 34/221 [00:11<00:46,  3.99it/s][A
 16%|█▌        | 35/221 [00:11<00:45,  4.07it/s][A
 16%|█▋        | 36/221 [00:12<00:55,  3.35it/s][A
 17%|█▋        | 37/221 [00:12<01:06,  2.75it/s][A
 17%|█▋        | 38/221 [00:13<01:20,  2.28it/s][A
 18%|█▊        | 39/221 [00:13<01:10,  2.59it/s][A
 18%|█▊        | 40/221 [00:13<01:04,  2.81it/s][A
 19%|█▊        | 41/221 [00:13<00:51,  3.48it/s][A
 19%|█▉        | 42/221 [00:14<01:02,  2.86it/s][A
 19%|█▉        | 43/221 [00:14<00:51,  3.46it/s][A
 20%|█▉        | 44/221 [00:14<00:41,  4.26it/s][A
 20%|██        | 45/221 [00:15<01:12,  2.44it/s][A
 21%|██        | 46/221 [00:15<01:10,  2.49it/s][A
 21%|██▏       | 47/221 [00:16<01:13,  2.37it/s][A
 22%|██▏       | 48/221 [00:16<00:56,  3.07it/s][A
 22%|██▏       | 49/221 [00:17<01:17,  2.23it/s][A[h264 @ 0x556a933bbf00] mmco: unref short failure
[h264 @ 0x556a933bbf00] mmco: unref short failure

 23%|██▎       | 50/221 [00:17<01:16,  2.24it/s][A[h264 @ 0x559b496f7340] mmco: unref short failure

 24%|██▎       | 52/221 [00:17<00:50,  3.33it/s][A
 24%|██▍       | 53/221 [00:18<00:46,  3.58it/s][A
 24%|██▍       | 54/221 [00:19<01:26,  1.94it/s][A
 25%|██▍       | 55/221 [00:19<01:18,  2.13it/s][A
 25%|██▌       | 56/221 [00:19<01:06,  2.47it/s][A
 26%|██▌       | 57/221 [00:19<00:55,  2.95it/s][A
 26%|██▌       | 58/221 [00:20<00:48,  3.36it/s][A
 27%|██▋       | 59/221 [00:20<00:44,  3.62it/s][A
 27%|██▋       | 60/221 [00:21<01:07,  2.39it/s][A
 28%|██▊       | 61/221 [00:21<00:57,  2.80it/s][A
 28%|██▊       | 62/221 [00:21<00:51,  3.09it/s][A
 29%|██▊       | 63/221 [00:21<00:46,  3.41it/s][A
 29%|██▉       | 64/221 [00:22<00:40,  3.86it/s][A
 29%|██▉       | 65/221 [00:22<00:40,  3.88it/s][A
 30%|██▉       | 66/221 [00:22<00:41,  3.69it/s][A
 30%|███       | 67/221 [00:23<00:54,  2.82it/s][A
 31%|███       | 68/221 [00:23<00:45,  3.39it/s][A
 31%|███       | 69/221 [00:23<00:56,  2.68it/s][A
 32%|███▏      | 70/221 [00:24<00:49,  3.04it/s][A[h264 @ 0x559fa064aec0] mmco: unref short failure
[h264 @ 0x559fa064aec0] mmco: unref short failure

 32%|███▏      | 71/221 [00:24<00:53,  2.80it/s][A
 33%|███▎      | 72/221 [00:24<00:56,  2.66it/s][A
 33%|███▎      | 73/221 [00:25<00:55,  2.65it/s][A
 33%|███▎      | 74/221 [00:25<00:45,  3.21it/s][A
 34%|███▍      | 75/221 [00:25<00:49,  2.93it/s][A
 34%|███▍      | 76/221 [00:25<00:40,  3.58it/s][A
 35%|███▍      | 77/221 [00:26<00:35,  4.06it/s][A
 35%|███▌      | 78/221 [00:26<00:32,  4.34it/s][A
 36%|███▌      | 79/221 [00:26<00:43,  3.25it/s][A
 36%|███▌      | 80/221 [00:27<00:41,  3.42it/s][A
 37%|███▋      | 81/221 [00:27<00:39,  3.52it/s][A
 37%|███▋      | 82/221 [00:28<00:55,  2.50it/s][A
 38%|███▊      | 83/221 [00:28<00:59,  2.33it/s][A
 38%|███▊      | 84/221 [00:28<00:56,  2.44it/s][A
 38%|███▊      | 85/221 [00:29<00:47,  2.85it/s][A
 39%|███▉      | 86/221 [00:29<00:44,  3.05it/s][A
 39%|███▉      | 87/221 [00:29<00:52,  2.58it/s][A
 40%|███▉      | 88/221 [00:30<00:58,  2.28it/s][A
 40%|████      | 89/221 [00:30<00:55,  2.38it/s][A
 41%|████      | 90/221 [00:31<00:48,  2.71it/s][A
 41%|████      | 91/221 [00:31<00:39,  3.30it/s][A
 42%|████▏     | 92/221 [00:31<00:36,  3.54it/s][A
 42%|████▏     | 93/221 [00:31<00:39,  3.28it/s][A
 43%|████▎     | 94/221 [00:31<00:32,  3.89it/s][A
 43%|████▎     | 95/221 [00:32<00:35,  3.51it/s][A
 43%|████▎     | 96/221 [00:32<00:37,  3.37it/s][A
 44%|████▍     | 97/221 [00:32<00:33,  3.70it/s][A
 44%|████▍     | 98/221 [00:33<00:31,  3.85it/s][A
 45%|████▍     | 99/221 [00:33<00:26,  4.60it/s][A
 45%|████▌     | 100/221 [00:33<00:26,  4.63it/s][A
 46%|████▌     | 101/221 [00:33<00:23,  5.04it/s][A
 46%|████▌     | 102/221 [00:33<00:24,  4.80it/s][A
 47%|████▋     | 103/221 [00:33<00:23,  5.01it/s][A
 47%|████▋     | 104/221 [00:34<00:20,  5.74it/s][A
 48%|████▊     | 105/221 [00:34<00:20,  5.68it/s][A
 48%|████▊     | 106/221 [00:35<00:45,  2.53it/s][A
 48%|████▊     | 107/221 [00:35<00:36,  3.11it/s][A
 49%|████▉     | 108/221 [00:35<00:31,  3.59it/s][A
 49%|████▉     | 109/221 [00:35<00:32,  3.43it/s][A[h264 @ 0x559f7efd3a00] mmco: unref short failure

 50%|████▉     | 110/221 [00:36<00:40,  2.73it/s][A
 50%|█████     | 111/221 [00:36<00:42,  2.56it/s][A
 51%|█████     | 112/221 [00:36<00:34,  3.16it/s][A
 51%|█████     | 113/221 [00:37<00:41,  2.62it/s][A
 52%|█████▏    | 114/221 [00:37<00:33,  3.19it/s][A
 52%|█████▏    | 116/221 [00:39<01:04,  1.63it/s][A
 53%|█████▎    | 117/221 [00:39<00:56,  1.84it/s][A
 53%|█████▎    | 118/221 [00:40<00:50,  2.04it/s][A
 54%|█████▍    | 119/221 [00:40<00:44,  2.28it/s][A
 54%|█████▍    | 120/221 [00:40<00:40,  2.47it/s][A[h264 @ 0x5623720fed00] mmco: unref short failure
[h264 @ 0x5623720fed00] mmco: unref short failure

 55%|█████▍    | 121/221 [00:40<00:32,  3.11it/s][A
 55%|█████▌    | 122/221 [00:41<00:28,  3.49it/s][A
 56%|█████▌    | 123/221 [00:41<00:27,  3.62it/s][A[h264 @ 0x559b421b1a00] mmco: unref short failure
[h264 @ 0x559b421b1a00] mmco: unref short failure

 56%|█████▌    | 124/221 [00:41<00:24,  4.00it/s][A
 57%|█████▋    | 125/221 [00:42<00:28,  3.35it/s][A
 57%|█████▋    | 126/221 [00:42<00:26,  3.62it/s][A[h264 @ 0x556a91856280] mmco: unref short failure

 57%|█████▋    | 127/221 [00:42<00:29,  3.21it/s][A[h264 @ 0x562373b79880] mmco: unref short failure

 58%|█████▊    | 128/221 [00:43<00:31,  2.91it/s][A
 58%|█████▊    | 129/221 [00:43<00:26,  3.53it/s][A
 59%|█████▉    | 130/221 [00:43<00:25,  3.53it/s][A
 59%|█████▉    | 131/221 [00:43<00:21,  4.22it/s][A[h264 @ 0x56237f080780] mmco: unref short failure

 60%|█████▉    | 132/221 [00:43<00:18,  4.94it/s][A
 60%|██████    | 133/221 [00:44<00:23,  3.73it/s][A[h264 @ 0x556a9abc92c0] mmco: unref short failure

 61%|██████    | 134/221 [00:44<00:20,  4.29it/s][A
 61%|██████    | 135/221 [00:44<00:18,  4.77it/s][A
 62%|██████▏   | 136/221 [00:44<00:21,  4.01it/s][A
 62%|██████▏   | 137/221 [00:45<00:19,  4.22it/s][A
 62%|██████▏   | 138/221 [00:45<00:23,  3.51it/s][A
 63%|██████▎   | 139/221 [00:45<00:27,  2.98it/s][A
 63%|██████▎   | 140/221 [00:46<00:25,  3.13it/s][A
 64%|██████▍   | 141/221 [00:46<00:22,  3.59it/s][A
 64%|██████▍   | 142/221 [00:46<00:24,  3.20it/s][A
 65%|██████▍   | 143/221 [00:46<00:21,  3.59it/s][A
 65%|██████▌   | 144/221 [00:47<00:21,  3.60it/s][A
 66%|██████▌   | 146/221 [00:47<00:15,  4.82it/s][A
 67%|██████▋   | 147/221 [00:47<00:16,  4.50it/s][A
 67%|██████▋   | 148/221 [00:47<00:16,  4.34it/s][A
 67%|██████▋   | 149/221 [00:48<00:14,  4.82it/s][A
 68%|██████▊   | 150/221 [00:48<00:14,  4.77it/s][A
 68%|██████▊   | 151/221 [00:48<00:20,  3.34it/s][A
 69%|██████▉   | 152/221 [00:50<00:42,  1.61it/s][A
 69%|██████▉   | 153/221 [00:50<00:36,  1.84it/s][A
 70%|██████▉   | 154/221 [00:50<00:30,  2.21it/s][A
 70%|███████   | 155/221 [00:50<00:23,  2.82it/s][A
 71%|███████   | 156/221 [00:51<00:21,  3.09it/s][A[h264 @ 0x56236b2ba940] mmco: unref short failure
[h264 @ 0x56236b2ba940] mmco: unref short failure

 71%|███████   | 157/221 [00:51<00:23,  2.68it/s][A
 71%|███████▏  | 158/221 [00:52<00:21,  2.91it/s][A
 72%|███████▏  | 159/221 [00:52<00:17,  3.59it/s][A
 72%|███████▏  | 160/221 [00:52<00:17,  3.54it/s][A
 73%|███████▎  | 161/221 [00:52<00:13,  4.35it/s][A
 73%|███████▎  | 162/221 [00:53<00:20,  2.83it/s][A
 74%|███████▍  | 163/221 [00:53<00:18,  3.19it/s][A
 74%|███████▍  | 164/221 [00:53<00:17,  3.21it/s][A
 75%|███████▌  | 166/221 [00:54<00:16,  3.36it/s][A
 76%|███████▌  | 167/221 [00:54<00:13,  3.95it/s][A
 76%|███████▌  | 168/221 [00:54<00:17,  3.04it/s][A
 76%|███████▋  | 169/221 [00:55<00:14,  3.54it/s][A
 77%|███████▋  | 170/221 [00:55<00:14,  3.48it/s][A
 77%|███████▋  | 171/221 [00:55<00:15,  3.28it/s][A
 78%|███████▊  | 173/221 [00:55<00:10,  4.38it/s][A
 79%|███████▊  | 174/221 [00:56<00:10,  4.34it/s][A
 79%|███████▉  | 175/221 [00:56<00:12,  3.59it/s][A
 80%|███████▉  | 176/221 [00:56<00:10,  4.10it/s][A
 80%|████████  | 177/221 [00:56<00:09,  4.55it/s][A
 81%|████████  | 178/221 [00:57<00:08,  5.13it/s][A
 81%|████████  | 179/221 [00:57<00:09,  4.23it/s][A
 82%|████████▏ | 181/221 [00:57<00:08,  4.87it/s][A
 82%|████████▏ | 182/221 [00:57<00:07,  5.45it/s][A
 83%|████████▎ | 183/221 [00:58<00:06,  5.67it/s][A
 83%|████████▎ | 184/221 [00:58<00:07,  4.78it/s][A
 84%|████████▍ | 186/221 [00:58<00:07,  4.82it/s][A
 85%|████████▍ | 187/221 [00:58<00:06,  5.02it/s][A
 85%|████████▌ | 188/221 [00:59<00:07,  4.68it/s][A
 86%|████████▌ | 189/221 [00:59<00:07,  4.14it/s][A[h264 @ 0x56238164f5c0] mmco: unref short failure
[h264 @ 0x56238164f5c0] mmco: unref short failure

 86%|████████▌ | 190/221 [00:59<00:08,  3.59it/s][A
 87%|████████▋ | 192/221 [01:00<00:06,  4.54it/s][A
 88%|████████▊ | 194/221 [01:00<00:07,  3.47it/s][A
 88%|████████▊ | 195/221 [01:01<00:06,  3.75it/s][A
 89%|████████▊ | 196/221 [01:01<00:08,  2.99it/s][A
 89%|████████▉ | 197/221 [01:01<00:06,  3.52it/s][A
 90%|████████▉ | 198/221 [01:02<00:06,  3.63it/s][A
 90%|█████████ | 199/221 [01:02<00:05,  4.34it/s][A
 90%|█████████ | 200/221 [01:02<00:05,  4.03it/s][A
 91%|█████████ | 201/221 [01:02<00:04,  4.11it/s][A
 91%|█████████▏| 202/221 [01:02<00:04,  4.17it/s][A
 92%|█████████▏| 203/221 [01:03<00:03,  4.68it/s][A
 92%|█████████▏| 204/221 [01:03<00:04,  4.12it/s][A
 93%|█████████▎| 205/221 [01:03<00:03,  4.96it/s][A
 93%|█████████▎| 206/221 [01:04<00:04,  3.17it/s][A
 94%|█████████▎| 207/221 [01:04<00:03,  3.56it/s][A
 94%|█████████▍| 208/221 [01:04<00:03,  4.10it/s][A
 95%|█████████▍| 209/221 [01:04<00:02,  4.08it/s][A
 95%|█████████▌| 211/221 [01:05<00:02,  4.22it/s][A[h264 @ 0x559f7d1cd1c0] mmco: unref short failure

 96%|█████████▌| 212/221 [01:05<00:01,  4.54it/s][A[h264 @ 0x559f7d1cd1c0] mmco: unref short failure
[h264 @ 0x559f7d1cd1c0] mmco: unref short failure

 96%|█████████▋| 213/221 [01:05<00:01,  4.23it/s][A
 97%|█████████▋| 214/221 [01:05<00:01,  4.31it/s][A
 97%|█████████▋| 215/221 [01:06<00:01,  4.03it/s][A
 98%|█████████▊| 216/221 [01:06<00:01,  3.79it/s][A[h264 @ 0x5623701d0880] mmco: unref short failure
[h264 @ 0x5623701d0880] mmco: unref short failure

 98%|█████████▊| 217/221 [01:06<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:07<00:00,  3.38it/s][A
 99%|█████████▉| 219/221 [01:07<00:00,  3.68it/s][A
100%|█████████▉| 220/221 [01:09<00:00,  1.12it/s][A
100%|██████████| 221/221 [01:09<00:00,  1.45it/s][A100%|██████████| 221/221 [01:09<00:00,  3.16it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<01:01,  3.49it/s][A
  4%|▍         | 9/221 [00:02<00:59,  3.58it/s][A
  5%|▍         | 10/221 [00:02<00:57,  3.64it/s][A
  5%|▍         | 11/221 [00:02<00:56,  3.69it/s][A
  5%|▌         | 12/221 [00:03<00:56,  3.72it/s][A
  6%|▌         | 13/221 [00:03<00:55,  3.74it/s][A
  6%|▋         | 14/221 [00:03<00:55,  3.76it/s][A
  7%|▋         | 15/221 [00:04<00:54,  3.77it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.77it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.78it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.78it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:51,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:09<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:47,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:14<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:18<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:23<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:28<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:23,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:47<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:52<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:57<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:36,  6.00it/s][A
  1%|          | 2/221 [00:00<00:53,  4.08it/s][A
  1%|▏         | 3/221 [00:00<00:59,  3.68it/s][A
  2%|▏         | 4/221 [00:00<00:53,  4.09it/s][A
  2%|▏         | 5/221 [00:01<00:49,  4.33it/s][A
  3%|▎         | 7/221 [00:01<00:44,  4.85it/s][A
  4%|▎         | 8/221 [00:01<00:50,  4.20it/s][A
  4%|▍         | 9/221 [00:02<00:50,  4.20it/s][A
  5%|▍         | 10/221 [00:02<01:09,  3.06it/s][A
  5%|▍         | 11/221 [00:02<01:02,  3.35it/s][A
  5%|▌         | 12/221 [00:03<00:54,  3.87it/s][A
  6%|▌         | 13/221 [00:03<01:21,  2.55it/s][A
  6%|▋         | 14/221 [00:03<01:04,  3.21it/s][A
  7%|▋         | 15/221 [00:04<01:00,  3.43it/s][A
  7%|▋         | 16/221 [00:04<01:10,  2.92it/s][A
  8%|▊         | 17/221 [00:05<01:30,  2.25it/s][A
  8%|▊         | 18/221 [00:05<01:17,  2.62it/s][A
  9%|▊         | 19/221 [00:05<01:08,  2.93it/s][A
  9%|▉         | 20/221 [00:05<00:55,  3.64it/s][A
 10%|▉         | 21/221 [00:06<00:49,  4.02it/s][A
 10%|▉         | 22/221 [00:06<00:48,  4.07it/s][A
 11%|█         | 24/221 [00:06<00:38,  5.18it/s][A
 11%|█▏        | 25/221 [00:06<00:40,  4.84it/s][A
 12%|█▏        | 26/221 [00:07<00:42,  4.54it/s][A
 13%|█▎        | 28/221 [00:07<00:47,  4.06it/s][A
 13%|█▎        | 29/221 [00:07<00:41,  4.58it/s][A
 14%|█▎        | 30/221 [00:08<00:44,  4.25it/s][A
 14%|█▍        | 31/221 [00:08<00:42,  4.43it/s][A
 15%|█▍        | 33/221 [00:08<00:44,  4.24it/s][A
 15%|█▌        | 34/221 [00:08<00:38,  4.88it/s][A
 16%|█▌        | 35/221 [00:09<00:37,  4.92it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.80it/s][A
 17%|█▋        | 37/221 [00:09<00:47,  3.87it/s][A
 17%|█▋        | 38/221 [00:10<00:51,  3.57it/s][A
 18%|█▊        | 39/221 [00:10<00:43,  4.19it/s][A
 18%|█▊        | 40/221 [00:10<00:45,  4.00it/s][A
 19%|█▊        | 41/221 [00:10<00:37,  4.82it/s][A
 19%|█▉        | 42/221 [00:10<00:41,  4.34it/s][A
 19%|█▉        | 43/221 [00:11<00:47,  3.74it/s][A
 20%|█▉        | 44/221 [00:11<00:44,  3.95it/s][A
 20%|██        | 45/221 [00:11<00:43,  4.04it/s][A
 21%|██        | 46/221 [00:11<00:39,  4.45it/s][A
 21%|██▏       | 47/221 [00:12<00:38,  4.56it/s][A
 22%|██▏       | 48/221 [00:12<00:33,  5.22it/s][A
 22%|██▏       | 49/221 [00:12<00:33,  5.10it/s][A
 23%|██▎       | 50/221 [00:12<00:39,  4.30it/s][A
 23%|██▎       | 51/221 [00:12<00:36,  4.61it/s][A
 24%|██▎       | 52/221 [00:13<00:34,  4.86it/s][A
 24%|██▍       | 53/221 [00:13<00:30,  5.46it/s][A
 24%|██▍       | 54/221 [00:13<00:49,  3.37it/s][A
 25%|██▍       | 55/221 [00:13<00:46,  3.58it/s][A
 25%|██▌       | 56/221 [00:14<00:39,  4.14it/s][A
 26%|██▌       | 57/221 [00:14<00:39,  4.15it/s][A
 26%|██▌       | 58/221 [00:14<00:37,  4.32it/s][A
 27%|██▋       | 59/221 [00:14<00:36,  4.44it/s][A
 27%|██▋       | 60/221 [00:15<00:37,  4.25it/s][A
 28%|██▊       | 61/221 [00:15<00:35,  4.52it/s][A
 28%|██▊       | 62/221 [00:15<00:35,  4.44it/s][A
 29%|██▊       | 63/221 [00:15<00:35,  4.44it/s][A
 29%|██▉       | 64/221 [00:16<00:44,  3.53it/s][A
 29%|██▉       | 65/221 [00:16<00:35,  4.35it/s][A
 30%|██▉       | 66/221 [00:16<00:42,  3.61it/s][A
 30%|███       | 67/221 [00:17<00:49,  3.10it/s][A
 31%|███       | 68/221 [00:17<00:42,  3.62it/s][A
 31%|███       | 69/221 [00:17<00:52,  2.87it/s][A
 32%|███▏      | 70/221 [00:17<00:44,  3.42it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.84it/s][A
 33%|███▎      | 72/221 [00:18<00:43,  3.39it/s][A
 33%|███▎      | 73/221 [00:18<00:47,  3.13it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.81it/s][A
 34%|███▍      | 76/221 [00:19<00:36,  4.02it/s][A
 35%|███▍      | 77/221 [00:19<00:32,  4.38it/s][A
 35%|███▌      | 78/221 [00:19<00:29,  4.92it/s][A
 36%|███▌      | 79/221 [00:20<00:41,  3.44it/s][A
 36%|███▌      | 80/221 [00:20<00:37,  3.76it/s][A
 37%|███▋      | 81/221 [00:20<00:35,  3.90it/s][A
 37%|███▋      | 82/221 [00:20<00:33,  4.09it/s][A
 38%|███▊      | 83/221 [00:21<00:39,  3.52it/s][A
 38%|███▊      | 84/221 [00:21<00:34,  3.99it/s][A
 39%|███▉      | 86/221 [00:21<00:29,  4.56it/s][A
 39%|███▉      | 87/221 [00:22<00:42,  3.13it/s][A
 40%|███▉      | 88/221 [00:22<00:47,  2.80it/s][A
 40%|████      | 89/221 [00:23<00:43,  3.03it/s][A
 41%|████      | 90/221 [00:23<00:42,  3.07it/s][A
 41%|████      | 91/221 [00:23<00:34,  3.72it/s][A
 42%|████▏     | 92/221 [00:23<00:34,  3.76it/s][A
 42%|████▏     | 93/221 [00:24<00:53,  2.37it/s][A
 43%|████▎     | 94/221 [00:24<00:47,  2.67it/s][A
 43%|████▎     | 95/221 [00:25<00:43,  2.87it/s][A
 43%|████▎     | 96/221 [00:25<00:37,  3.33it/s][A
 44%|████▍     | 97/221 [00:25<00:34,  3.64it/s][A
 44%|████▍     | 98/221 [00:25<00:31,  3.95it/s][A
 45%|████▍     | 99/221 [00:25<00:27,  4.40it/s][A
 45%|████▌     | 100/221 [00:26<00:28,  4.29it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.77it/s][A
 46%|████▌     | 102/221 [00:27<00:43,  2.71it/s][A
 47%|████▋     | 103/221 [00:27<00:35,  3.28it/s][A
 47%|████▋     | 104/221 [00:27<00:31,  3.70it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.86it/s][A
 48%|████▊     | 106/221 [00:28<00:38,  2.96it/s][A
 48%|████▊     | 107/221 [00:28<00:36,  3.13it/s][A
 49%|████▉     | 108/221 [00:28<00:34,  3.30it/s][A
 49%|████▉     | 109/221 [00:28<00:28,  3.98it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.80it/s][A
 50%|█████     | 111/221 [00:29<00:30,  3.65it/s][A
 51%|█████     | 112/221 [00:29<00:30,  3.53it/s][A
 51%|█████     | 113/221 [00:30<00:28,  3.83it/s][A
 52%|█████▏    | 115/221 [00:30<00:22,  4.73it/s][A
 52%|█████▏    | 116/221 [00:30<00:23,  4.46it/s][A
 53%|█████▎    | 117/221 [00:30<00:26,  3.96it/s][A
 53%|█████▎    | 118/221 [00:31<00:25,  4.08it/s][A
 54%|█████▍    | 119/221 [00:31<00:31,  3.26it/s][A
 54%|█████▍    | 120/221 [00:31<00:28,  3.56it/s][A
 55%|█████▍    | 121/221 [00:31<00:22,  4.35it/s][A
 55%|█████▌    | 122/221 [00:32<00:24,  4.04it/s][A
 56%|█████▌    | 123/221 [00:32<00:24,  3.96it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.74it/s][A
 57%|█████▋    | 125/221 [00:33<00:27,  3.46it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.78it/s][A
 57%|█████▋    | 127/221 [00:33<00:29,  3.18it/s][A
 58%|█████▊    | 128/221 [00:34<00:27,  3.36it/s][A
 59%|█████▉    | 130/221 [00:34<00:21,  4.32it/s][A
 59%|█████▉    | 131/221 [00:34<00:17,  5.02it/s][A
 60%|█████▉    | 132/221 [00:34<00:22,  4.00it/s][A
 60%|██████    | 133/221 [00:35<00:22,  3.86it/s][A
 61%|██████    | 134/221 [00:35<00:24,  3.54it/s][A
 61%|██████    | 135/221 [00:35<00:25,  3.36it/s][A
 62%|██████▏   | 136/221 [00:36<00:24,  3.51it/s][A
 62%|██████▏   | 137/221 [00:36<00:21,  3.83it/s][A
 62%|██████▏   | 138/221 [00:36<00:23,  3.50it/s][A
 63%|██████▎   | 139/221 [00:37<00:28,  2.88it/s][A
 63%|██████▎   | 140/221 [00:37<00:26,  3.06it/s][A
 64%|██████▍   | 141/221 [00:37<00:23,  3.41it/s][A
 64%|██████▍   | 142/221 [00:37<00:21,  3.72it/s][A
 65%|██████▍   | 143/221 [00:38<00:27,  2.82it/s][A
 65%|██████▌   | 144/221 [00:38<00:28,  2.69it/s][A
 66%|██████▌   | 146/221 [00:38<00:17,  4.17it/s][A
 67%|██████▋   | 147/221 [00:39<00:18,  3.93it/s][A
 67%|██████▋   | 148/221 [00:39<00:20,  3.52it/s][A
 67%|██████▋   | 149/221 [00:39<00:20,  3.50it/s][A
 68%|██████▊   | 150/221 [00:40<00:19,  3.62it/s][A
 68%|██████▊   | 151/221 [00:40<00:22,  3.12it/s][A
 69%|██████▉   | 152/221 [00:41<00:35,  1.93it/s][A
 69%|██████▉   | 153/221 [00:41<00:28,  2.42it/s][A
 70%|██████▉   | 154/221 [00:42<00:24,  2.75it/s][A
 70%|███████   | 155/221 [00:42<00:24,  2.71it/s][A
 71%|███████   | 156/221 [00:42<00:24,  2.61it/s][A
 71%|███████   | 157/221 [00:43<00:22,  2.78it/s][A
 71%|███████▏  | 158/221 [00:43<00:22,  2.78it/s][A
 72%|███████▏  | 160/221 [00:43<00:17,  3.56it/s][A
 73%|███████▎  | 161/221 [00:44<00:15,  3.94it/s][A
 73%|███████▎  | 162/221 [00:44<00:13,  4.35it/s][A
 74%|███████▍  | 163/221 [00:44<00:13,  4.18it/s][A
 74%|███████▍  | 164/221 [00:44<00:11,  4.83it/s][A
 75%|███████▍  | 165/221 [00:44<00:11,  4.88it/s][A
 75%|███████▌  | 166/221 [00:45<00:12,  4.43it/s][A
 76%|███████▌  | 167/221 [00:45<00:10,  5.28it/s][A
 76%|███████▌  | 168/221 [00:45<00:10,  4.94it/s][A
 76%|███████▋  | 169/221 [00:45<00:09,  5.21it/s][A
 77%|███████▋  | 170/221 [00:46<00:14,  3.63it/s][A
 77%|███████▋  | 171/221 [00:46<00:13,  3.73it/s][A
 78%|███████▊  | 172/221 [00:46<00:11,  4.25it/s][A
 78%|███████▊  | 173/221 [00:46<00:13,  3.45it/s][A
 79%|███████▊  | 174/221 [00:47<00:17,  2.71it/s][A
 79%|███████▉  | 175/221 [00:47<00:15,  2.91it/s][A
 80%|███████▉  | 176/221 [00:47<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:48<00:11,  3.78it/s][A
 81%|████████  | 178/221 [00:48<00:10,  4.03it/s][A
 81%|████████  | 179/221 [00:48<00:11,  3.78it/s][A
 81%|████████▏ | 180/221 [00:48<00:09,  4.30it/s][A
 82%|████████▏ | 181/221 [00:48<00:08,  4.58it/s][A
 82%|████████▏ | 182/221 [00:49<00:10,  3.62it/s][A
 83%|████████▎ | 183/221 [00:49<00:10,  3.47it/s][A
 83%|████████▎ | 184/221 [00:49<00:10,  3.68it/s][A
 84%|████████▎ | 185/221 [00:49<00:07,  4.53it/s][A
 84%|████████▍ | 186/221 [00:50<00:09,  3.86it/s][A
 85%|████████▍ | 187/221 [00:50<00:09,  3.50it/s][A
 85%|████████▌ | 188/221 [00:50<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:51<00:09,  3.47it/s][A
 86%|████████▌ | 190/221 [00:51<00:09,  3.23it/s][A
 86%|████████▋ | 191/221 [00:51<00:07,  3.80it/s][A
 87%|████████▋ | 192/221 [00:52<00:07,  3.84it/s][A
 88%|████████▊ | 194/221 [00:52<00:06,  3.97it/s][A
 88%|████████▊ | 195/221 [00:52<00:06,  4.04it/s][A
 89%|████████▊ | 196/221 [00:53<00:08,  3.04it/s][A
 89%|████████▉ | 197/221 [00:53<00:07,  3.03it/s][A
 90%|████████▉ | 198/221 [00:54<00:08,  2.78it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.19it/s][A
 90%|█████████ | 200/221 [00:54<00:07,  2.75it/s][A
 91%|█████████ | 201/221 [00:55<00:06,  2.94it/s][A
 91%|█████████▏| 202/221 [00:55<00:06,  2.88it/s][A
 92%|█████████▏| 203/221 [00:55<00:05,  3.30it/s][A
 92%|█████████▏| 204/221 [00:56<00:06,  2.82it/s][A
 93%|█████████▎| 205/221 [00:56<00:04,  3.57it/s][A
 93%|█████████▎| 206/221 [00:56<00:04,  3.11it/s][A
 94%|█████████▎| 207/221 [00:56<00:03,  3.81it/s][A
 94%|█████████▍| 208/221 [00:57<00:03,  3.60it/s][A
 95%|█████████▍| 209/221 [00:57<00:03,  3.76it/s][A
 95%|█████████▌| 211/221 [00:57<00:02,  4.16it/s][A
 96%|█████████▌| 212/221 [00:57<00:02,  4.08it/s][A
 96%|█████████▋| 213/221 [00:58<00:01,  4.24it/s][A
 97%|█████████▋| 214/221 [00:58<00:01,  3.51it/s][A
 97%|█████████▋| 215/221 [00:58<00:01,  3.63it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.58it/s][A
 98%|█████████▊| 217/221 [00:59<00:01,  3.38it/s][A
 99%|█████████▊| 218/221 [00:59<00:00,  3.36it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.02it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.46it/s][A
100%|██████████| 221/221 [01:00<00:00,  3.82it/s][A100%|██████████| 221/221 [01:00<00:00,  3.65it/s]
09/09/2024 18:59:01 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 349--===========

09/09/2024 18:59:01 - INFO - __main__ -   {'area_r1': 39.7, 'area_recall': '39.7/66.2/76.4', 'area_ravg': 60.7}
09/09/2024 18:59:01 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 349--===========

09/09/2024 18:59:01 - INFO - __main__ -   {'forward_r1': 36.1, 'forward_recall': '36.1/62.9/73.9', 'forward_ravg': 57.6}
09/09/2024 18:59:01 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 349--===========

09/09/2024 18:59:01 - INFO - __main__ -   {'area_video_r1': 39.4, 'area_video_recall': '39.4/67.8/77.8', 'area_video_ravg': 61.7}
09/09/2024 18:59:01 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/09/2024 18:59:01 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 18:59:01 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 349--===========

09/09/2024 18:59:01 - INFO - __main__ -   {'area_video_r1': 52.3, 'area_video_recall': '52.3/74.5/82.2', 'area_video_ravg': 69.7, 'area_video_back_r1': 50.2, 'area_video_back_recall': '50.2/74.9/82.1', 'area_video_back_ravg': 69.1}
09/09/2024 18:59:01 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 349=======

09/09/2024 18:59:01 - INFO - __main__ -   {'area_video_r1': 52.3, 'area_video_recall': '52.3/74.5/82.2', 'area_video_ravg': 69.7, 'area_video_back_r1': 50.2, 'area_video_back_recall': '50.2/74.9/82.1', 'area_video_back_ravg': 69.1}
09/09/2024 18:59:01 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 349--===========

09/09/2024 18:59:01 - INFO - __main__ -   {'video_r1': 42.0, 'video_recall': '42.0/70.6/81.2', 'video_ravg': 64.6}
09/09/2024 18:59:01 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 18:59:01 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 18:59:01 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 349--===========

09/09/2024 18:59:01 - INFO - __main__ -   {'video_r1': 52.8, 'video_recall': '52.8/75.8/82.6', 'video_ravg': 70.4}
09/09/2024 18:59:01 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 349=======

09/09/2024 18:59:01 - INFO - __main__ -   {'video_r1': 52.8, 'video_recall': '52.8/75.8/82.6', 'video_ravg': 70.4}
09/09/2024 18:59:32 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.009352768771350384, 'loss_ret%tv%ta--finetune_area/loss_area': 1.3171055316925049, 'loss_ret%tv%ta--finetune_area/total_loss': 1.3264583349227905}
[h264 @ 0x56237411dfc0] mmco: unref short failure
[h264 @ 0x56237411dfc0] mmco: unref short failure
[h264 @ 0x559f9a550380] mmco: unref short failure
 18%|█▊        | 350/1945 [1:54:13<55:07:30, 124.42s/it][h264 @ 0x562376f9ac80] mmco: unref short failure
[h264 @ 0x562376f9ac80] mmco: unref short failure
[h264 @ 0x559b35bf0d80] mmco: unref short failure
[h264 @ 0x559b35bf0d80] mmco: unref short failure
 18%|█▊        | 351/1945 [1:54:17<39:06:11, 88.31s/it] [h264 @ 0x559b42818d40] mmco: unref short failure
[h264 @ 0x559b42818d40] mmco: unref short failure
[h264 @ 0x559f8d237280] mmco: unref short failure
 18%|█▊        | 352/1945 [1:54:22<27:58:54, 63.24s/it][h264 @ 0x556a8a566dc0] mmco: unref short failure
 18%|█▊        | 353/1945 [1:54:26<20:12:38, 45.70s/it][h264 @ 0x556a7c3c73c0] mmco: unref short failure
[h264 @ 0x559f8ab040c0] mmco: unref short failure
[h264 @ 0x559f8ab040c0] mmco: unref short failure
 18%|█▊        | 354/1945 [1:54:32<14:51:08, 33.61s/it][h264 @ 0x556a7c3c73c0] mmco: unref short failure
[h264 @ 0x559b507513c0] mmco: unref short failure
[h264 @ 0x559b507513c0] mmco: unref short failure
 18%|█▊        | 355/1945 [1:54:37<11:08:47, 25.24s/it][h264 @ 0x56236354be00] mmco: unref short failure
 18%|█▊        | 356/1945 [1:54:45<8:45:01, 19.82s/it] [h264 @ 0x559b539f72c0] mmco: unref short failure
[h264 @ 0x559b539f72c0] mmco: unref short failure
 18%|█▊        | 357/1945 [1:54:52<7:03:30, 16.00s/it][h264 @ 0x556a82e4ad00] mmco: unref short failure
[h264 @ 0x556a82e4ad00] mmco: unref short failure
 18%|█▊        | 358/1945 [1:54:59<5:57:08, 13.50s/it] 18%|█▊        | 359/1945 [1:55:07<5:10:06, 11.73s/it][h264 @ 0x559f9b240700] mmco: unref short failure
 19%|█▊        | 360/1945 [1:55:15<4:39:34, 10.58s/it][h264 @ 0x556a98815bc0] mmco: unref short failure
[h264 @ 0x556a98815bc0] mmco: unref short failure
 19%|█▊        | 361/1945 [1:55:23<4:18:13,  9.78s/it][h264 @ 0x559f8a183600] mmco: unref short failure
[h264 @ 0x559f867872c0] mmco: unref short failure
[h264 @ 0x559f867872c0] mmco: unref short failure
[h264 @ 0x559b405fd380] mmco: unref short failure
[h264 @ 0x559b405fd380] mmco: unref short failure
[h264 @ 0x556a7e4a2bc0] mmco: unref short failure
[h264 @ 0x556a7e4a2bc0] mmco: unref short failure
 19%|█▊        | 362/1945 [1:55:31<4:08:02,  9.40s/it][h264 @ 0x556a81e2c9c0] mmco: unref short failure
[h264 @ 0x556a81e2c9c0] mmco: unref short failure
[h264 @ 0x556a98815bc0] mmco: unref short failure
[h264 @ 0x5623813d8300] mmco: unref short failure
[h264 @ 0x5623813d8300] mmco: unref short failure
 19%|█▊        | 363/1945 [1:55:39<3:57:44,  9.02s/it] 19%|█▊        | 364/1945 [1:55:46<3:42:09,  8.43s/it][h264 @ 0x559b4b3b81c0] mmco: unref short failure
[h264 @ 0x559b4b3b81c0] mmco: unref short failure
[h264 @ 0x556a8ba78180] mmco: unref short failure
[h264 @ 0x556a8ba78180] mmco: unref short failure
[h264 @ 0x559b34bc79c0] mmco: unref short failure
[h264 @ 0x559b34bc79c0] mmco: unref short failure
 19%|█▉        | 365/1945 [1:55:54<3:34:20,  8.14s/it][h264 @ 0x559f9a88b3c0] mmco: unref short failure
 19%|█▉        | 366/1945 [1:56:01<3:28:47,  7.93s/it][h264 @ 0x56237c133080] mmco: unref short failure
[h264 @ 0x56237c133080] mmco: unref short failure
 19%|█▉        | 367/1945 [1:56:09<3:24:28,  7.77s/it][h264 @ 0x556a7c8c9e80] mmco: unref short failure
[h264 @ 0x556a7c8c9e80] mmco: unref short failure
[h264 @ 0x559b5340ad00] mmco: unref short failure
 19%|█▉        | 368/1945 [1:56:17<3:25:53,  7.83s/it][h264 @ 0x556a8777cbc0] mmco: unref short failure
[h264 @ 0x56237410e600] mmco: unref short failure
[h264 @ 0x56237410e600] mmco: unref short failure
[h264 @ 0x56237410e600] mmco: unref short failure
[h264 @ 0x56237410e600] mmco: unref short failure
[h264 @ 0x559b360caf40] mmco: unref short failure
[h264 @ 0x559b360caf40] mmco: unref short failure
[h264 @ 0x559f9b3c5540] mmco: unref short failure
[h264 @ 0x559b373b7740] mmco: unref short failure
[h264 @ 0x559f970ed680] mmco: unref short failure
[h264 @ 0x559f970ed680] mmco: unref short failure
[h264 @ 0x559f970ed680] mmco: unref short failure
[h264 @ 0x559f970ed680] mmco: unref short failure
[h264 @ 0x556a78b73e40] mmco: unref short failure
[h264 @ 0x556a78b73e40] mmco: unref short failure
 19%|█▉        | 369/1945 [1:56:33<4:29:51, 10.27s/it][h264 @ 0x5623654eff40] mmco: unref short failure
[h264 @ 0x5623654eff40] mmco: unref short failure
 19%|█▉        | 370/1945 [1:56:41<4:11:28,  9.58s/it][h264 @ 0x56237c4d2000] mmco: unref short failure
[h264 @ 0x56237c4d2000] mmco: unref short failure
[h264 @ 0x559b3fa07800] mmco: unref short failure
 19%|█▉        | 371/1945 [1:56:48<3:54:31,  8.94s/it][h264 @ 0x559f84276300] mmco: unref short failure
[h264 @ 0x559f8c866340] mmco: unref short failure
[h264 @ 0x559f8c866340] mmco: unref short failure
[h264 @ 0x559f93453280] mmco: unref short failure
[h264 @ 0x56236979bc00] mmco: unref short failure
[h264 @ 0x56236979bc00] mmco: unref short failure
[h264 @ 0x56236979bc00] mmco: unref short failure
[h264 @ 0x56236979bc00] mmco: unref short failure
[h264 @ 0x56236e791740] mmco: unref short failure
 19%|█▉        | 372/1945 [1:56:56<3:46:57,  8.66s/it][h264 @ 0x56236aa45d40] mmco: unref short failure
[h264 @ 0x56236aa45d40] mmco: unref short failure
 19%|█▉        | 373/1945 [1:57:06<3:56:27,  9.03s/it][h264 @ 0x559f86c653c0] mmco: unref short failure
[h264 @ 0x559b39c70cc0] mmco: unref short failure
[h264 @ 0x556a7c1a5c00] mmco: unref short failure
[h264 @ 0x556a7c1a5c00] mmco: unref short failure
[h264 @ 0x556a83c60f80] mmco: unref short failure
[h264 @ 0x559f8a6c5040] mmco: unref short failure
[h264 @ 0x559f8a6c5040] mmco: unref short failure
[h264 @ 0x559f949cb480] mmco: unref short failure
[h264 @ 0x559f949cb480] mmco: unref short failure
[h264 @ 0x562371aa9d80] mmco: unref short failure
[h264 @ 0x562371aa9d80] mmco: unref short failure
[h264 @ 0x562371aa9d80] mmco: unref short failure
[h264 @ 0x562371aa9d80] mmco: unref short failure
[h264 @ 0x559b54d01200] mmco: unref short failure
[h264 @ 0x556a82f05f00] mmco: unref short failure
[h264 @ 0x556a82f05f00] mmco: unref short failure
[h264 @ 0x556a82f05f00] mmco: unref short failure
[h264 @ 0x559b5340ab00] mmco: unref short failure
[h264 @ 0x559b5340ab00] mmco: unref short failure
[h264 @ 0x559b5340ab00] mmco: unref short failure
[h264 @ 0x559b5340ab00] mmco: unref short failure
 19%|█▉        | 374/1945 [1:57:48<8:12:57, 18.83s/it][h264 @ 0x56237d4b0ec0] mmco: unref short failure
[h264 @ 0x559f982be040] mmco: unref short failure
[h264 @ 0x562366d68300] mmco: unref short failure
[h264 @ 0x562366d68300] mmco: unref short failure
 19%|█▉        | 375/1945 [1:58:08<8:23:33, 19.24s/it][h264 @ 0x556a8a140280] mmco: unref short failure
[h264 @ 0x556a8a140280] mmco: unref short failure
[h264 @ 0x559f808a6380] mmco: unref short failure
[h264 @ 0x5623697ef040] mmco: unref short failure
[h264 @ 0x5623697ef040] mmco: unref short failure
[h264 @ 0x5623697ef040] mmco: unref short failure
[h264 @ 0x5623697ef040] mmco: unref short failure
[h264 @ 0x56236c54dd80] mmco: unref short failure
[h264 @ 0x56236c54dd80] mmco: unref short failure
[h264 @ 0x559f80e51e00] mmco: unref short failure
[h264 @ 0x559f80e51e00] mmco: unref short failure
[h264 @ 0x562365a7f040] mmco: unref short failure
[h264 @ 0x562365a7f040] mmco: unref short failure
[h264 @ 0x562365a7f040] mmco: unref short failure
[h264 @ 0x562365a7f040] mmco: unref short failure
[h264 @ 0x5623743e8c00] mmco: unref short failure
[h264 @ 0x5623743e8c00] mmco: unref short failure
 19%|█▉        | 376/1945 [1:58:20<7:30:25, 17.22s/it][h264 @ 0x559b521153c0] mmco: unref short failure
[h264 @ 0x559f7dc8a380] mmco: unref short failure
[h264 @ 0x559f7dc8a380] mmco: unref short failure
[h264 @ 0x559f8b4d3740] mmco: unref short failure
[h264 @ 0x559f8b4d3740] mmco: unref short failure
[h264 @ 0x559f8b4d3740] mmco: unref short failure
[h264 @ 0x559f849a8200] mmco: unref short failure
[h264 @ 0x559f849a8200] mmco: unref short failure
[h264 @ 0x556a95613f40] mmco: unref short failure
[h264 @ 0x556a95613f40] mmco: unref short failure
[h264 @ 0x556a95613f40] mmco: unref short failure
[h264 @ 0x556a95613f40] mmco: unref short failure
 19%|█▉        | 377/1945 [1:58:39<7:40:46, 17.63s/it][h264 @ 0x556a87819c80] mmco: unref short failure
[h264 @ 0x556a87819c80] mmco: unref short failure
[h264 @ 0x559f842713c0] mmco: unref short failure
[h264 @ 0x559f842713c0] mmco: unref short failure
[h264 @ 0x559f842713c0] mmco: unref short failure
[h264 @ 0x559f842713c0] mmco: unref short failure
[h264 @ 0x56236d872680] mmco: unref short failure
[h264 @ 0x56236d872680] mmco: unref short failure
[h264 @ 0x56236d872680] mmco: unref short failure
[h264 @ 0x56236d872680] mmco: unref short failure
[h264 @ 0x559f8d5ad580] mmco: unref short failure
[h264 @ 0x559f8d5ad580] mmco: unref short failure
[h264 @ 0x56237655dc00] mmco: unref short failure
[h264 @ 0x56237655dc00] mmco: unref short failure
 19%|█▉        | 378/1945 [1:58:46<6:15:45, 14.39s/it] 19%|█▉        | 379/1945 [1:58:53<5:18:14, 12.19s/it] 20%|█▉        | 380/1945 [1:59:00<4:42:04, 10.81s/it][h264 @ 0x559fa024d180] mmco: unref short failure
[h264 @ 0x559fa024d180] mmco: unref short failure
[h264 @ 0x56236d5a3e40] mmco: unref short failure
 20%|█▉        | 381/1945 [1:59:08<4:16:10,  9.83s/it][h264 @ 0x556a8c8efa80] mmco: unref short failure
[h264 @ 0x556a8c8efa80] mmco: unref short failure
[h264 @ 0x556a8bd09540] mmco: unref short failure
[h264 @ 0x556a8bd09540] mmco: unref short failure
[h264 @ 0x562373815bc0] mmco: unref short failure
[h264 @ 0x559fa024d180] mmco: unref short failure
 20%|█▉        | 382/1945 [1:59:41<7:14:46, 16.69s/it] 20%|█▉        | 383/1945 [1:59:53<6:39:56, 15.36s/it][h264 @ 0x559f7d1d7040] mmco: unref short failure
[h264 @ 0x559f7d1d7040] mmco: unref short failure
[h264 @ 0x559f8e1c7180] mmco: unref short failure
[h264 @ 0x556a8b1b87c0] mmco: unref short failure
[h264 @ 0x556a915b54c0] mmco: unref short failure
[h264 @ 0x556a915b54c0] mmco: unref short failure
[h264 @ 0x556a915b54c0] mmco: unref short failure
 20%|█▉        | 384/1945 [2:00:03<6:01:02, 13.88s/it] 20%|█▉        | 385/1945 [2:00:09<4:59:10, 11.51s/it] 20%|█▉        | 386/1945 [2:00:13<3:58:53,  9.19s/it] 20%|█▉        | 387/1945 [2:00:17<3:16:42,  7.58s/it] 20%|█▉        | 388/1945 [2:00:21<2:47:11,  6.44s/it]/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556b2d637040] mmco: unref short failure
[h264 @ 0x556b2d637040] mmco: unref short failure
[h264 @ 0x556b2d637040] mmco: unref short failure
[h264 @ 0x556b2d637040] mmco: unref short failure
[h264 @ 0x5624172b2540] mmco: unref short failure
[h264 @ 0x5624172b2540] mmco: unref short failure
[h264 @ 0x556b2d5fdd00] mmco: unref short failure
[h264 @ 0x556b2d5fdd00] mmco: unref short failure
[h264 @ 0x556b2d5fdd00] mmco: unref short failure
[h264 @ 0x556b2d5fdd00] mmco: unref short failure
[h264 @ 0x556b2cedb800] mmco: unref short failure
[h264 @ 0x55a032de2180] mmco: unref short failure
[h264 @ 0x55a032de2180] mmco: unref short failure
[h264 @ 0x55a032de2180] mmco: unref short failure
[h264 @ 0x55a032de2180] mmco: unref short failure
[h264 @ 0x559be9174880] mmco: unref short failure
[h264 @ 0x559be9174880] mmco: unref short failure
[h264 @ 0x559be9174880] mmco: unref short failure
[h264 @ 0x559be9174880] mmco: unref short failure
[h264 @ 0x556b2d986940] mmco: unref short failure
[h264 @ 0x562416884380] mmco: unref short failure
[h264 @ 0x5624172c2680] mmco: unref short failure
[h264 @ 0x5624172c2680] mmco: unref short failure
[h264 @ 0x556b2d5bf180] mmco: unref short failure
[h264 @ 0x562416bdd8c0] mmco: unref short failure
[h264 @ 0x562418e85b80] mmco: unref short failure
[h264 @ 0x556b2d9612c0] mmco: unref short failure
[h264 @ 0x556b2d9612c0] mmco: unref short failure
[h264 @ 0x56241baa9e80] mmco: unref short failure
[h264 @ 0x56241baa9e80] mmco: unref short failure
[h264 @ 0x56241baa9e80] mmco: unref short failure
[h264 @ 0x56241baa9e80] mmco: unref short failure
[h264 @ 0x56241baa9e80] mmco: unref short failure
[h264 @ 0x56241baa9e80] mmco: unref short failure
[h264 @ 0x556b30a5f9c0] mmco: unref short failure
[h264 @ 0x556b30a5f9c0] mmco: unref short failure
[h264 @ 0x556b30a5f9c0] mmco: unref short failure
[h264 @ 0x556b2df4f180] mmco: unref short failure
[h264 @ 0x556b2df4f180] mmco: unref short failure
[h264 @ 0x556b2df4f180] mmco: unref short failure
[h264 @ 0x556b2df4f180] mmco: unref short failure
[h264 @ 0x556b2df4f180] mmco: unref short failure
[h264 @ 0x556b2df4f180] mmco: unref short failure
[h264 @ 0x556b343c8ec0] mmco: unref short failure
[h264 @ 0x556b343c8ec0] mmco: unref short failure
[h264 @ 0x559be9803f40] mmco: unref short failure
[h264 @ 0x562416acdbc0] mmco: unref short failure
[h264 @ 0x562416acdbc0] mmco: unref short failure
[h264 @ 0x559bede52800] mmco: unref short failure
[h264 @ 0x55a0349e2080] mmco: unref short failure
[h264 @ 0x55a0349e2080] mmco: unref short failure
[h264 @ 0x55a032ec9080] mmco: unref short failure
[h264 @ 0x55a0330c2c40] mmco: unref short failure
[h264 @ 0x559be9b5d340] mmco: unref short failure
[h264 @ 0x559be9b5d340] mmco: unref short failure
[h264 @ 0x559be9b5d340] mmco: unref short failure
[h264 @ 0x559be9b5d340] mmco: unref short failure
[h264 @ 0x559bf39a9480] mmco: unref short failure
[h264 @ 0x559bf39a9480] mmco: unref short failure
[h264 @ 0x556b2d6d83c0] mmco: unref short failure
[h264 @ 0x556b2d6d83c0] mmco: unref short failure
[h264 @ 0x5624174b8400] mmco: unref short failure
[h264 @ 0x55a034a8c2c0] mmco: unref short failure
[h264 @ 0x55a034a8c2c0] mmco: unref short failure
 20%|██        | 389/1945 [2:02:39<19:53:33, 46.02s/it][h264 @ 0x55a033d90a80] mmco: unref short failure
[h264 @ 0x562421778080] mmco: unref short failure
[h264 @ 0x562421778080] mmco: unref short failure
[h264 @ 0x56241baa2340] mmco: unref short failure
[h264 @ 0x562419827880] mmco: unref short failure
[h264 @ 0x562419827880] mmco: unref short failure
 20%|██        | 390/1945 [2:02:47<14:56:43, 34.60s/it][h264 @ 0x562418166f80] mmco: unref short failure
[h264 @ 0x562418166f80] mmco: unref short failure
[h264 @ 0x562418166f80] mmco: unref short failure
[h264 @ 0x562418166f80] mmco: unref short failure
[h264 @ 0x562418166f80] mmco: unref short failure
 20%|██        | 391/1945 [2:02:55<11:25:36, 26.47s/it][h264 @ 0x55a033ba8180] mmco: unref short failure
[h264 @ 0x55a033ba8180] mmco: unref short failure
 20%|██        | 392/1945 [2:03:01<8:52:53, 20.59s/it]  20%|██        | 393/1945 [2:03:09<7:11:00, 16.66s/it][h264 @ 0x5624192c49c0] mmco: unref short failure
[h264 @ 0x5624192c49c0] mmco: unref short failure
[h264 @ 0x559bef506f40] mmco: unref short failure
[h264 @ 0x559bef506f40] mmco: unref short failure
 20%|██        | 394/1945 [2:03:16<5:57:05, 13.81s/it][h264 @ 0x56241d3bce40] mmco: unref short failure
 20%|██        | 395/1945 [2:03:23<5:05:30, 11.83s/it][h264 @ 0x556b2fc04cc0] mmco: unref short failure
[h264 @ 0x556b2fc04cc0] mmco: unref short failure
[h264 @ 0x56241dde5940] mmco: unref short failure
[h264 @ 0x562416b3b280] mmco: unref short failure
[h264 @ 0x562416b3b280] mmco: unref short failure
 20%|██        | 396/1945 [2:03:30<4:27:20, 10.36s/it][h264 @ 0x556b3351f080] mmco: unref short failure
[h264 @ 0x559befd95fc0] mmco: unref short failure
[h264 @ 0x559befd95fc0] mmco: unref short failure
[h264 @ 0x55a0331cc580] mmco: unref short failure
[h264 @ 0x55a0331cc580] mmco: unref short failure
[h264 @ 0x5624199cde80] mmco: unref short failure
[h264 @ 0x559bf3f30000] mmco: unref short failure
[h264 @ 0x556b3337fd00] mmco: unref short failure
[h264 @ 0x556b3337fd00] mmco: unref short failure
[h264 @ 0x55a037d93580] mmco: unref short failure
[h264 @ 0x55a037d93580] mmco: unref short failure
[h264 @ 0x55a037d93580] mmco: unref short failure
[h264 @ 0x55a037d93580] mmco: unref short failure
[h264 @ 0x55a036f1e300] mmco: unref short failure
[h264 @ 0x55a036f1e300] mmco: unref short failure
[h264 @ 0x562418087cc0] mmco: unref short failure
[h264 @ 0x55a0338e3780] mmco: unref short failure
[h264 @ 0x55a0338e3780] mmco: unref short failure
[h264 @ 0x559bec933800] mmco: unref short failure
[h264 @ 0x562416ace140] mmco: unref short failure
[h264 @ 0x562416ace140] mmco: unref short failure
[h264 @ 0x562416ace140] mmco: unref short failure
[h264 @ 0x562416ace140] mmco: unref short failure
[h264 @ 0x56241ccc1340] mmco: unref short failure
[h264 @ 0x562416ace140] mmco: unref short failure
[h264 @ 0x562416ace140] mmco: unref short failure
[h264 @ 0x56241ccc1340] mmco: unref short failure
[h264 @ 0x562416ace140] mmco: unref short failure
[h264 @ 0x562416ace140] mmco: unref short failure
[h264 @ 0x562416ace140] mmco: unref short failure
[h264 @ 0x562416ace140] mmco: unref short failure
[h264 @ 0x559bf100bc40] mmco: unref short failure
[h264 @ 0x559bf100bc40] mmco: unref short failure
[h264 @ 0x55a03973f8c0] mmco: unref short failure
[h264 @ 0x56241be64580] mmco: unref short failure
[h264 @ 0x56241be64580] mmco: unref short failure
[h264 @ 0x559bebfd5b40] mmco: unref short failure
[h264 @ 0x559bebfd5b40] mmco: unref short failure
[h264 @ 0x559bebfd5b40] mmco: unref short failure
[h264 @ 0x55a036aa1300] mmco: unref short failure
[h264 @ 0x559be9007580] mmco: unref short failure
[h264 @ 0x559be9007580] mmco: unref short failure
[h264 @ 0x556b2dc2bc80] mmco: unref short failure
[h264 @ 0x556b3029df00] mmco: unref short failure
[h264 @ 0x562418d6b540] mmco: unref short failure
[h264 @ 0x562418d6b540] mmco: unref short failure
[h264 @ 0x559beb0ead80] mmco: unref short failure
[h264 @ 0x559beb0ead80] mmco: unref short failure
 20%|██        | 397/1945 [2:04:40<12:09:45, 28.29s/it][h264 @ 0x559bf63b3540] mmco: unref short failure
 20%|██        | 398/1945 [2:04:49<9:36:09, 22.35s/it] [h264 @ 0x556b2ebda080] mmco: unref short failure
 21%|██        | 399/1945 [2:04:57<7:42:10, 17.94s/it]09/09/2024 19:10:19 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 19:10:19 - INFO - __main__ -   start running ret%tv validation...
[h264 @ 0x56241724a840] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a0358f2780] mmco: unref short failure
[h264 @ 0x55a0358f2780] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a0358f2780] mmco: unref short failure
[h264 @ 0x55a0358f2780] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556b2d9acb40] mmco: unref short failure
[h264 @ 0x556b2fcca840] mmco: unref short failure
[h264 @ 0x556b2fcca840] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x562418fdf5c0] mmco: unref short failure
[h264 @ 0x562418fdf5c0] mmco: unref short failure
[h264 @ 0x556b38c739c0] mmco: unref short failure
[h264 @ 0x559bf064a300] mmco: unref short failure
[h264 @ 0x559bf064a300] mmco: unref short failure
[h264 @ 0x556b349bfc00] mmco: unref short failure
[h264 @ 0x556b349bfc00] mmco: unref short failure
[h264 @ 0x55a03c32e180] mmco: unref short failure
[h264 @ 0x559becebaa40] mmco: unref short failure
[h264 @ 0x559becebaa40] mmco: unref short failure
[h264 @ 0x56241deb8040] mmco: unref short failure
[h264 @ 0x56241deb8040] mmco: unref short failure
[h264 @ 0x56241deb8040] mmco: unref short failure
[h264 @ 0x56241deb8040] mmco: unref short failure
[h264 @ 0x556b34df95c0] mmco: unref short failure
[h264 @ 0x56241a5ba6c0] mmco: unref short failure
[h264 @ 0x56241a5ba6c0] mmco: unref short failure
[h264 @ 0x556b34616700] mmco: unref short failure
[h264 @ 0x559befc2bc00] mmco: unref short failure
[h264 @ 0x55a03a2cea00] mmco: unref short failure
[h264 @ 0x55a03a2cea00] mmco: unref short failure
[h264 @ 0x559bf34fcd40] mmco: unref short failure
[h264 @ 0x559bf34fcd40] mmco: unref short failure
[h264 @ 0x56241a743b00] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:52,  1.95it/s][A
  1%|          | 2/221 [00:01<01:51,  1.97it/s][A
  1%|▏         | 3/221 [00:01<01:20,  2.69it/s][A
  2%|▏         | 4/221 [00:01<01:00,  3.59it/s][A
  2%|▏         | 5/221 [00:01<00:49,  4.33it/s][A
  3%|▎         | 6/221 [00:01<00:45,  4.74it/s][A
  3%|▎         | 7/221 [00:01<00:45,  4.70it/s][A
  4%|▎         | 8/221 [00:02<01:00,  3.51it/s][A
  4%|▍         | 9/221 [00:02<01:01,  3.43it/s][A
  5%|▍         | 10/221 [00:03<01:11,  2.94it/s][A
  5%|▍         | 11/221 [00:03<00:58,  3.57it/s][A[h264 @ 0x56241a392e80] mmco: unref short failure

  5%|▌         | 12/221 [00:03<01:10,  2.96it/s][A
  6%|▌         | 13/221 [00:04<01:10,  2.96it/s][A
  6%|▋         | 14/221 [00:04<01:29,  2.31it/s][A
  7%|▋         | 15/221 [00:04<01:15,  2.75it/s][A
  7%|▋         | 16/221 [00:05<01:14,  2.74it/s][A
  8%|▊         | 17/221 [00:06<01:38,  2.06it/s][A
  8%|▊         | 18/221 [00:06<01:27,  2.33it/s][A
  9%|▊         | 19/221 [00:06<01:07,  3.01it/s][A
  9%|▉         | 20/221 [00:06<01:00,  3.31it/s][A
 10%|▉         | 21/221 [00:06<00:55,  3.63it/s][A
 10%|▉         | 22/221 [00:07<00:48,  4.11it/s][A
 11%|█         | 24/221 [00:07<00:34,  5.68it/s][A
 11%|█▏        | 25/221 [00:07<00:34,  5.66it/s][A
 12%|█▏        | 26/221 [00:07<00:47,  4.11it/s][A
 12%|█▏        | 27/221 [00:07<00:39,  4.89it/s][A
 13%|█▎        | 28/221 [00:08<00:53,  3.61it/s][A
 13%|█▎        | 29/221 [00:09<01:23,  2.30it/s][A
 14%|█▎        | 30/221 [00:09<01:12,  2.63it/s][A
 14%|█▍        | 31/221 [00:09<01:03,  3.01it/s][A
 15%|█▍        | 33/221 [00:09<00:45,  4.16it/s][A
 15%|█▌        | 34/221 [00:10<00:41,  4.52it/s][A
 16%|█▌        | 35/221 [00:10<00:41,  4.46it/s][A
 16%|█▋        | 36/221 [00:10<00:43,  4.24it/s][A
 17%|█▋        | 37/221 [00:11<00:55,  3.32it/s][A
 17%|█▋        | 38/221 [00:11<00:59,  3.06it/s][A
 18%|█▊        | 39/221 [00:11<00:59,  3.04it/s][A
 18%|█▊        | 40/221 [00:12<00:57,  3.13it/s][A
 19%|█▉        | 42/221 [00:12<00:54,  3.30it/s][A
 20%|█▉        | 44/221 [00:12<00:36,  4.84it/s][A
 20%|██        | 45/221 [00:13<01:00,  2.91it/s][A
 21%|██        | 46/221 [00:13<01:00,  2.89it/s][A
 21%|██▏       | 47/221 [00:14<01:01,  2.82it/s][A
 22%|██▏       | 49/221 [00:15<01:06,  2.58it/s][A[h264 @ 0x556b3192c300] mmco: unref short failure

 23%|██▎       | 50/221 [00:15<01:07,  2.54it/s][A
 24%|██▎       | 52/221 [00:15<00:48,  3.47it/s][A
 24%|██▍       | 53/221 [00:16<00:41,  4.01it/s][A[h264 @ 0x556b31a97380] mmco: unref short failure

 24%|██▍       | 54/221 [00:17<01:35,  1.76it/s][A[h264 @ 0x56241793ccc0] mmco: unref short failure

 25%|██▍       | 55/221 [00:17<01:25,  1.94it/s][A[h264 @ 0x559bed3ad340] mmco: unref short failure
[h264 @ 0x559bed3ad340] mmco: unref short failure
[h264 @ 0x559bed3ad340] mmco: unref short failure
[h264 @ 0x559bed3ad340] mmco: unref short failure

 25%|██▌       | 56/221 [00:18<01:10,  2.33it/s][A
 26%|██▌       | 57/221 [00:18<00:58,  2.80it/s][A
 26%|██▌       | 58/221 [00:18<00:50,  3.23it/s][A
 27%|██▋       | 59/221 [00:18<00:44,  3.66it/s][A
 27%|██▋       | 60/221 [00:19<01:10,  2.27it/s][A
 28%|██▊       | 61/221 [00:19<00:58,  2.73it/s][A
 28%|██▊       | 62/221 [00:19<00:52,  3.05it/s][A[h264 @ 0x55a039728240] mmco: unref short failure

 29%|██▊       | 63/221 [00:20<00:45,  3.45it/s][A
 29%|██▉       | 64/221 [00:20<00:38,  4.12it/s][A
 29%|██▉       | 65/221 [00:20<00:34,  4.50it/s][A
 30%|██▉       | 66/221 [00:20<00:38,  4.03it/s][A
 30%|███       | 67/221 [00:21<00:46,  3.33it/s][A
 31%|███       | 68/221 [00:21<00:38,  3.97it/s][A
 31%|███       | 69/221 [00:21<00:49,  3.10it/s][A
 32%|███▏      | 70/221 [00:21<00:40,  3.71it/s][A
 32%|███▏      | 71/221 [00:22<00:51,  2.89it/s][A
 33%|███▎      | 72/221 [00:22<00:44,  3.33it/s][A
 33%|███▎      | 73/221 [00:23<00:46,  3.22it/s][A
 33%|███▎      | 74/221 [00:23<00:38,  3.83it/s][A
 34%|███▍      | 75/221 [00:23<00:43,  3.35it/s][A
 34%|███▍      | 76/221 [00:23<00:35,  4.10it/s][A
 35%|███▍      | 77/221 [00:23<00:32,  4.42it/s][A
 35%|███▌      | 78/221 [00:24<00:29,  4.92it/s][A
 36%|███▌      | 79/221 [00:24<00:41,  3.42it/s][A
 36%|███▌      | 80/221 [00:24<00:37,  3.71it/s][A
 37%|███▋      | 81/221 [00:24<00:37,  3.72it/s][A
 37%|███▋      | 82/221 [00:25<01:01,  2.25it/s][A
 38%|███▊      | 83/221 [00:26<01:01,  2.23it/s][A
 38%|███▊      | 84/221 [00:26<00:51,  2.66it/s][A
 39%|███▉      | 86/221 [00:26<00:37,  3.61it/s][A
 39%|███▉      | 87/221 [00:27<00:43,  3.05it/s][A
 40%|███▉      | 88/221 [00:27<00:45,  2.91it/s][A
 40%|████      | 89/221 [00:28<00:50,  2.63it/s][A
 41%|████      | 90/221 [00:28<00:42,  3.07it/s][A
 41%|████      | 91/221 [00:28<00:36,  3.55it/s][A
 42%|████▏     | 92/221 [00:28<00:35,  3.69it/s][A
 42%|████▏     | 93/221 [00:29<00:42,  3.03it/s][A
 43%|████▎     | 94/221 [00:29<00:35,  3.59it/s][A
 43%|████▎     | 95/221 [00:29<00:35,  3.60it/s][A
 43%|████▎     | 96/221 [00:29<00:30,  4.12it/s][A
 44%|████▍     | 97/221 [00:29<00:26,  4.70it/s][A
 44%|████▍     | 98/221 [00:30<00:28,  4.36it/s][A
 45%|████▌     | 100/221 [00:30<00:22,  5.39it/s][A
 46%|████▌     | 102/221 [00:30<00:20,  5.70it/s][A
 47%|████▋     | 103/221 [00:30<00:19,  6.10it/s][A
 47%|████▋     | 104/221 [00:31<00:17,  6.67it/s][A
 48%|████▊     | 105/221 [00:31<00:18,  6.37it/s][A
 48%|████▊     | 106/221 [00:31<00:32,  3.51it/s][A
 48%|████▊     | 107/221 [00:32<00:29,  3.88it/s][A
 49%|████▉     | 108/221 [00:32<00:27,  4.17it/s][A
 49%|████▉     | 109/221 [00:32<00:27,  4.10it/s][A
 50%|████▉     | 110/221 [00:32<00:27,  3.97it/s][A
 50%|█████     | 111/221 [00:33<00:34,  3.20it/s][A
 51%|█████     | 112/221 [00:33<00:28,  3.85it/s][A
 51%|█████     | 113/221 [00:33<00:30,  3.53it/s][A
 52%|█████▏    | 115/221 [00:33<00:19,  5.47it/s][A
 52%|█████▏    | 116/221 [00:36<01:27,  1.20it/s][A
 53%|█████▎    | 117/221 [00:36<01:10,  1.47it/s][A
 53%|█████▎    | 118/221 [00:37<00:58,  1.77it/s][A
 54%|█████▍    | 119/221 [00:37<00:49,  2.08it/s][A
 54%|█████▍    | 120/221 [00:37<00:43,  2.31it/s][A
 55%|█████▌    | 122/221 [00:37<00:28,  3.41it/s][A
 56%|█████▌    | 123/221 [00:38<00:25,  3.89it/s][A
 56%|█████▌    | 124/221 [00:38<00:23,  4.19it/s][A
 57%|█████▋    | 125/221 [00:38<00:26,  3.65it/s][A
 57%|█████▋    | 126/221 [00:38<00:24,  3.88it/s][A
 57%|█████▋    | 127/221 [00:39<00:32,  2.92it/s][A
 58%|█████▊    | 128/221 [00:39<00:32,  2.90it/s][A
 58%|█████▊    | 129/221 [00:40<00:28,  3.25it/s][A
 59%|█████▉    | 130/221 [00:40<00:26,  3.50it/s][A
 59%|█████▉    | 131/221 [00:40<00:20,  4.30it/s][A
 60%|█████▉    | 132/221 [00:40<00:18,  4.82it/s][A
 60%|██████    | 133/221 [00:40<00:24,  3.55it/s][A
 61%|██████    | 134/221 [00:41<00:22,  3.93it/s][A
 61%|██████    | 135/221 [00:41<00:23,  3.64it/s][A
 62%|██████▏   | 136/221 [00:41<00:25,  3.39it/s][A
 62%|██████▏   | 137/221 [00:42<00:22,  3.81it/s][A
 62%|██████▏   | 138/221 [00:42<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:42<00:29,  2.82it/s][A
 63%|██████▎   | 140/221 [00:43<00:26,  3.05it/s][A
 64%|██████▍   | 141/221 [00:43<00:22,  3.53it/s][A
 64%|██████▍   | 142/221 [00:43<00:21,  3.75it/s][A
 65%|██████▍   | 143/221 [00:43<00:20,  3.78it/s][A
 65%|██████▌   | 144/221 [00:44<00:19,  4.03it/s][A
 66%|██████▌   | 146/221 [00:44<00:12,  5.87it/s][A
[h264 @ 0x556b357d7ec0] mmco: unref short failure
[h264 @ 0x556b357d7ec0] mmco: unref short failure
 67%|██████▋   | 147/221 [00:44<00:12,  5.74it/s][A
 67%|██████▋   | 148/221 [00:44<00:15,  4.70it/s][A
 67%|██████▋   | 149/221 [00:44<00:13,  5.29it/s][A
 68%|██████▊   | 150/221 [00:45<00:13,  5.35it/s][A
 68%|██████▊   | 151/221 [00:45<00:26,  2.68it/s][A[h264 @ 0x559bf45038c0] mmco: unref short failure

 69%|██████▉   | 152/221 [00:47<00:50,  1.35it/s][A
 69%|██████▉   | 153/221 [00:47<00:41,  1.63it/s][A
 70%|██████▉   | 154/221 [00:48<00:35,  1.88it/s][A
 70%|███████   | 155/221 [00:48<00:26,  2.45it/s][A
 71%|███████   | 156/221 [00:48<00:21,  3.00it/s][A
 71%|███████   | 157/221 [00:48<00:25,  2.52it/s][A
 71%|███████▏  | 158/221 [00:49<00:22,  2.85it/s][A
 72%|███████▏  | 159/221 [00:49<00:18,  3.27it/s][A
 72%|███████▏  | 160/221 [00:49<00:18,  3.25it/s][A
 73%|███████▎  | 161/221 [00:49<00:15,  3.98it/s][A
 73%|███████▎  | 162/221 [00:50<00:19,  3.01it/s][A
 74%|███████▍  | 163/221 [00:50<00:17,  3.30it/s][A
 74%|███████▍  | 164/221 [00:50<00:16,  3.50it/s][A
 75%|███████▍  | 165/221 [00:50<00:12,  4.31it/s][A
 75%|███████▌  | 166/221 [00:51<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:51<00:13,  4.11it/s][A
 76%|███████▌  | 168/221 [00:51<00:16,  3.24it/s][A
 76%|███████▋  | 169/221 [00:52<00:14,  3.66it/s][A
 77%|███████▋  | 170/221 [00:52<00:14,  3.61it/s][A
 77%|███████▋  | 171/221 [00:52<00:14,  3.41it/s][A
 78%|███████▊  | 172/221 [00:52<00:12,  4.00it/s][A
 78%|███████▊  | 173/221 [00:53<00:11,  4.32it/s][A
 79%|███████▊  | 174/221 [00:53<00:10,  4.42it/s][A
 79%|███████▉  | 175/221 [00:53<00:12,  3.65it/s][A
 80%|███████▉  | 176/221 [00:53<00:11,  4.03it/s][A[h264 @ 0x556b3476a500] mmco: unref short failure

 80%|████████  | 177/221 [00:54<00:09,  4.72it/s][A
 81%|████████  | 178/221 [00:54<00:08,  5.12it/s][A
 81%|████████  | 179/221 [00:54<00:09,  4.21it/s][A
 82%|████████▏ | 181/221 [00:54<00:07,  5.47it/s][A
 82%|████████▏ | 182/221 [00:54<00:06,  5.66it/s][A
 83%|████████▎ | 183/221 [00:55<00:06,  5.77it/s][A
 83%|████████▎ | 184/221 [00:55<00:07,  5.05it/s][A
 84%|████████▍ | 186/221 [00:55<00:07,  4.72it/s][A
 85%|████████▍ | 187/221 [00:55<00:06,  5.16it/s][A
 85%|████████▌ | 188/221 [00:56<00:06,  4.92it/s][A
 86%|████████▌ | 189/221 [00:56<00:07,  4.43it/s][A
 86%|████████▌ | 190/221 [00:56<00:08,  3.61it/s][A
 87%|████████▋ | 192/221 [00:57<00:06,  4.30it/s][A
 88%|████████▊ | 194/221 [00:57<00:07,  3.55it/s][A
 88%|████████▊ | 195/221 [00:58<00:06,  3.88it/s][A
 89%|████████▊ | 196/221 [00:58<00:08,  2.92it/s][A
 89%|████████▉ | 197/221 [00:58<00:06,  3.48it/s][A
 90%|████████▉ | 198/221 [00:59<00:06,  3.77it/s][A
 90%|█████████ | 199/221 [00:59<00:04,  4.50it/s][A
 90%|█████████ | 200/221 [00:59<00:05,  4.05it/s][A
 91%|█████████ | 201/221 [00:59<00:04,  4.23it/s][A
 91%|█████████▏| 202/221 [00:59<00:04,  4.39it/s][A
 92%|█████████▏| 203/221 [01:00<00:03,  4.82it/s][A
 92%|█████████▏| 204/221 [01:00<00:03,  4.35it/s][A
 93%|█████████▎| 206/221 [01:00<00:03,  3.94it/s][A
 94%|█████████▎| 207/221 [01:01<00:03,  4.15it/s][A
 94%|█████████▍| 208/221 [01:01<00:02,  4.61it/s][A
 95%|█████████▍| 209/221 [01:01<00:02,  4.66it/s][A
 95%|█████████▌| 211/221 [01:01<00:02,  4.79it/s][A
 96%|█████████▌| 212/221 [01:01<00:01,  5.08it/s][A
 96%|█████████▋| 213/221 [01:02<00:01,  4.87it/s][A
 97%|█████████▋| 214/221 [01:02<00:01,  4.78it/s][A
 97%|█████████▋| 215/221 [01:02<00:01,  4.63it/s][A
 98%|█████████▊| 216/221 [01:02<00:01,  4.17it/s][A
 98%|█████████▊| 217/221 [01:03<00:01,  3.73it/s][A
 99%|█████████▊| 218/221 [01:03<00:00,  3.55it/s][A
 99%|█████████▉| 219/221 [01:03<00:00,  3.83it/s][A
100%|█████████▉| 220/221 [01:06<00:00,  1.01it/s][A
100%|██████████| 221/221 [01:06<00:00,  1.34it/s][A100%|██████████| 221/221 [01:06<00:00,  3.31it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:51,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:52,  3.60it/s][A
 14%|█▍        | 32/221 [00:08<00:51,  3.65it/s][A
 15%|█▍        | 33/221 [00:08<00:50,  3.69it/s][A
 15%|█▌        | 34/221 [00:09<00:50,  3.72it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.74it/s][A
 16%|█▋        | 36/221 [00:09<00:49,  3.75it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.77it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.77it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.78it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.78it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.78it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:47,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:14<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:23<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:28<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:42<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:47<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:52<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:57<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:29,  7.40it/s][A
  1%|          | 2/221 [00:00<00:50,  4.36it/s][A
  1%|▏         | 3/221 [00:00<00:58,  3.72it/s][A
  2%|▏         | 4/221 [00:00<00:51,  4.22it/s][A
  2%|▏         | 5/221 [00:01<00:47,  4.55it/s][A
  3%|▎         | 7/221 [00:01<00:42,  5.01it/s][A
  4%|▎         | 8/221 [00:01<00:49,  4.33it/s][A
  4%|▍         | 9/221 [00:02<00:48,  4.33it/s][A
  5%|▍         | 10/221 [00:02<01:07,  3.14it/s][A
  5%|▍         | 11/221 [00:02<01:02,  3.38it/s][A
  5%|▌         | 12/221 [00:02<00:53,  3.88it/s][A
  6%|▌         | 13/221 [00:03<01:23,  2.50it/s][A
  7%|▋         | 15/221 [00:04<00:58,  3.53it/s][A
  7%|▋         | 16/221 [00:04<01:05,  3.12it/s][A
  8%|▊         | 17/221 [00:05<01:25,  2.39it/s][A
  8%|▊         | 18/221 [00:05<01:14,  2.72it/s][A
  9%|▊         | 19/221 [00:05<01:07,  3.01it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.72it/s][A
 10%|▉         | 21/221 [00:05<00:48,  4.16it/s][A
 10%|▉         | 22/221 [00:06<00:44,  4.44it/s][A
 11%|█         | 24/221 [00:06<00:35,  5.51it/s][A
 11%|█▏        | 25/221 [00:06<00:38,  5.03it/s][A
 12%|█▏        | 26/221 [00:06<00:41,  4.67it/s][A
 13%|█▎        | 28/221 [00:07<00:47,  4.08it/s][A
 13%|█▎        | 29/221 [00:07<00:43,  4.45it/s][A
 14%|█▎        | 30/221 [00:07<00:45,  4.17it/s][A
 14%|█▍        | 31/221 [00:08<00:42,  4.43it/s][A
 15%|█▍        | 33/221 [00:08<00:34,  5.45it/s][A
 15%|█▌        | 34/221 [00:08<00:31,  5.85it/s][A
 16%|█▌        | 35/221 [00:08<00:34,  5.41it/s][A
 16%|█▋        | 36/221 [00:09<00:42,  4.33it/s][A
 17%|█▋        | 37/221 [00:09<00:42,  4.33it/s][A
 17%|█▋        | 38/221 [00:09<00:47,  3.88it/s][A
 18%|█▊        | 39/221 [00:09<00:41,  4.38it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.84it/s][A
 19%|█▊        | 41/221 [00:10<00:39,  4.57it/s][A
 19%|█▉        | 42/221 [00:10<00:43,  4.14it/s][A
 19%|█▉        | 43/221 [00:10<00:48,  3.68it/s][A
 20%|█▉        | 44/221 [00:11<00:44,  3.96it/s][A
 20%|██        | 45/221 [00:11<00:43,  4.08it/s][A
 21%|██        | 46/221 [00:11<00:39,  4.49it/s][A
 21%|██▏       | 47/221 [00:11<00:38,  4.46it/s][A
 22%|██▏       | 48/221 [00:11<00:34,  4.97it/s][A
 22%|██▏       | 49/221 [00:12<00:34,  4.99it/s][A
 23%|██▎       | 50/221 [00:12<00:41,  4.17it/s][A
 23%|██▎       | 51/221 [00:12<00:39,  4.30it/s][A
 24%|██▎       | 52/221 [00:12<00:36,  4.67it/s][A
 24%|██▍       | 53/221 [00:12<00:30,  5.51it/s][A
 24%|██▍       | 54/221 [00:13<00:50,  3.34it/s][A
 25%|██▍       | 55/221 [00:13<00:48,  3.39it/s][A
 25%|██▌       | 56/221 [00:13<00:41,  3.95it/s][A
 26%|██▌       | 57/221 [00:14<00:41,  3.98it/s][A
 26%|██▌       | 58/221 [00:14<00:40,  4.00it/s][A
 27%|██▋       | 59/221 [00:14<00:38,  4.20it/s][A
 27%|██▋       | 60/221 [00:14<00:40,  4.00it/s][A
 28%|██▊       | 61/221 [00:15<00:37,  4.32it/s][A
 28%|██▊       | 62/221 [00:15<00:37,  4.28it/s][A
 29%|██▊       | 63/221 [00:15<00:35,  4.41it/s][A
 29%|██▉       | 64/221 [00:15<00:44,  3.53it/s][A
 29%|██▉       | 65/221 [00:16<00:37,  4.19it/s][A
 30%|██▉       | 66/221 [00:16<00:45,  3.41it/s][A
 30%|███       | 67/221 [00:16<00:51,  2.99it/s][A
 31%|███       | 68/221 [00:17<00:42,  3.56it/s][A
 31%|███       | 69/221 [00:17<00:56,  2.67it/s][A
 32%|███▏      | 70/221 [00:17<00:45,  3.30it/s][A
 32%|███▏      | 71/221 [00:17<00:41,  3.62it/s][A
 33%|███▎      | 72/221 [00:18<00:47,  3.14it/s][A
 33%|███▎      | 73/221 [00:18<00:49,  2.97it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.81it/s][A
 34%|███▍      | 76/221 [00:19<00:35,  4.09it/s][A
 35%|███▍      | 77/221 [00:19<00:32,  4.37it/s][A
 35%|███▌      | 78/221 [00:19<00:28,  4.98it/s][A
 36%|███▌      | 79/221 [00:20<00:42,  3.32it/s][A
 36%|███▌      | 80/221 [00:20<00:37,  3.72it/s][A
 37%|███▋      | 81/221 [00:20<00:36,  3.88it/s][A
 37%|███▋      | 82/221 [00:20<00:35,  3.87it/s][A
 38%|███▊      | 83/221 [00:21<00:39,  3.47it/s][A
 38%|███▊      | 84/221 [00:21<00:34,  4.01it/s][A
 39%|███▉      | 86/221 [00:21<00:27,  4.87it/s][A
 39%|███▉      | 87/221 [00:22<00:41,  3.22it/s][A
 40%|███▉      | 88/221 [00:22<00:46,  2.84it/s][A
 40%|████      | 89/221 [00:23<00:43,  3.02it/s][A
 41%|████      | 90/221 [00:23<00:42,  3.09it/s][A
 41%|████      | 91/221 [00:23<00:34,  3.72it/s][A
 42%|████▏     | 92/221 [00:23<00:35,  3.66it/s][A
 42%|████▏     | 93/221 [00:24<00:54,  2.35it/s][A
 43%|████▎     | 94/221 [00:24<00:47,  2.65it/s][A
 43%|████▎     | 95/221 [00:25<00:42,  2.93it/s][A
 43%|████▎     | 96/221 [00:25<00:36,  3.38it/s][A
 44%|████▍     | 97/221 [00:25<00:33,  3.70it/s][A
 44%|████▍     | 98/221 [00:25<00:31,  3.94it/s][A
 45%|████▍     | 99/221 [00:25<00:27,  4.42it/s][A
 45%|████▌     | 100/221 [00:26<00:27,  4.42it/s][A
 46%|████▌     | 101/221 [00:26<00:29,  4.09it/s][A
 46%|████▌     | 102/221 [00:27<00:46,  2.56it/s][A
 47%|████▋     | 103/221 [00:27<00:36,  3.22it/s][A
 47%|████▋     | 104/221 [00:27<00:32,  3.56it/s][A
 48%|████▊     | 105/221 [00:27<00:31,  3.69it/s][A
 48%|████▊     | 106/221 [00:28<00:38,  2.97it/s][A
 48%|████▊     | 107/221 [00:28<00:36,  3.14it/s][A
 49%|████▉     | 108/221 [00:28<00:33,  3.36it/s][A
 49%|████▉     | 109/221 [00:28<00:27,  4.15it/s][A
 50%|████▉     | 110/221 [00:29<00:26,  4.19it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.72it/s][A
 51%|█████     | 112/221 [00:29<00:30,  3.63it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.75it/s][A
 52%|█████▏    | 115/221 [00:30<00:22,  4.69it/s][A
 52%|█████▏    | 116/221 [00:30<00:23,  4.45it/s][A
 53%|█████▎    | 117/221 [00:30<00:25,  4.13it/s][A
 53%|█████▎    | 118/221 [00:30<00:23,  4.30it/s][A
 54%|█████▍    | 119/221 [00:31<00:29,  3.43it/s][A
 54%|█████▍    | 120/221 [00:31<00:27,  3.65it/s][A
 55%|█████▍    | 121/221 [00:31<00:22,  4.44it/s][A
 55%|█████▌    | 122/221 [00:32<00:24,  4.11it/s][A
 56%|█████▌    | 123/221 [00:32<00:24,  4.04it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.80it/s][A
 57%|█████▋    | 125/221 [00:32<00:28,  3.34it/s][A
 57%|█████▋    | 126/221 [00:33<00:26,  3.65it/s][A
 57%|█████▋    | 127/221 [00:33<00:31,  3.02it/s][A
 58%|█████▊    | 128/221 [00:33<00:28,  3.23it/s][A
 58%|█████▊    | 129/221 [00:34<00:22,  4.04it/s][A
 59%|█████▉    | 130/221 [00:34<00:21,  4.27it/s][A
 60%|█████▉    | 132/221 [00:34<00:21,  4.10it/s][A
 60%|██████    | 133/221 [00:35<00:22,  3.88it/s][A
 61%|██████    | 134/221 [00:35<00:24,  3.49it/s][A
 61%|██████    | 135/221 [00:35<00:29,  2.95it/s][A
 62%|██████▏   | 136/221 [00:36<00:26,  3.17it/s][A
 62%|██████▏   | 137/221 [00:36<00:23,  3.52it/s][A
 62%|██████▏   | 138/221 [00:36<00:25,  3.30it/s][A
 63%|██████▎   | 139/221 [00:37<00:29,  2.79it/s][A
 63%|██████▎   | 140/221 [00:37<00:27,  2.97it/s][A
 64%|██████▍   | 141/221 [00:37<00:23,  3.44it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.80it/s][A
 65%|██████▍   | 143/221 [00:38<00:28,  2.71it/s][A
 65%|██████▌   | 144/221 [00:38<00:29,  2.59it/s][A
 66%|██████▌   | 146/221 [00:39<00:18,  4.12it/s][A
 67%|██████▋   | 147/221 [00:39<00:18,  3.93it/s][A
 67%|██████▋   | 148/221 [00:39<00:22,  3.31it/s][A
 67%|██████▋   | 149/221 [00:40<00:21,  3.35it/s][A
 68%|██████▊   | 150/221 [00:40<00:19,  3.55it/s][A
 68%|██████▊   | 151/221 [00:40<00:23,  3.02it/s][A
 69%|██████▉   | 152/221 [00:41<00:37,  1.83it/s][A
 69%|██████▉   | 153/221 [00:42<00:29,  2.28it/s][A
 70%|██████▉   | 154/221 [00:42<00:25,  2.65it/s][A
 70%|███████   | 155/221 [00:42<00:23,  2.78it/s][A
 71%|███████   | 156/221 [00:42<00:23,  2.72it/s][A
 71%|███████   | 157/221 [00:43<00:22,  2.81it/s][A
 71%|███████▏  | 158/221 [00:43<00:21,  2.88it/s][A
 72%|███████▏  | 160/221 [00:43<00:16,  3.61it/s][A
 73%|███████▎  | 161/221 [00:44<00:15,  3.82it/s][A
 73%|███████▎  | 162/221 [00:44<00:13,  4.24it/s][A
 74%|███████▍  | 163/221 [00:44<00:13,  4.17it/s][A
 74%|███████▍  | 164/221 [00:44<00:12,  4.63it/s][A
 75%|███████▍  | 165/221 [00:44<00:11,  4.68it/s][A
 75%|███████▌  | 166/221 [00:45<00:12,  4.48it/s][A
 76%|███████▌  | 167/221 [00:45<00:10,  5.20it/s][A
 76%|███████▌  | 168/221 [00:45<00:10,  4.91it/s][A
 76%|███████▋  | 169/221 [00:45<00:10,  5.13it/s][A
 77%|███████▋  | 170/221 [00:46<00:14,  3.47it/s][A
 77%|███████▋  | 171/221 [00:46<00:14,  3.51it/s][A
 78%|███████▊  | 172/221 [00:46<00:12,  4.05it/s][A
 78%|███████▊  | 173/221 [00:47<00:14,  3.31it/s][A
 79%|███████▊  | 174/221 [00:47<00:17,  2.63it/s][A
 79%|███████▉  | 175/221 [00:47<00:16,  2.83it/s][A
 80%|███████▉  | 176/221 [00:48<00:13,  3.22it/s][A
 80%|████████  | 177/221 [00:48<00:11,  3.68it/s][A
 81%|████████  | 178/221 [00:48<00:11,  3.86it/s][A
 81%|████████  | 179/221 [00:48<00:11,  3.72it/s][A
 81%|████████▏ | 180/221 [00:49<00:09,  4.30it/s][A
 82%|████████▏ | 181/221 [00:49<00:08,  4.47it/s][A
 82%|████████▏ | 182/221 [00:49<00:11,  3.39it/s][A
 83%|████████▎ | 183/221 [00:50<00:11,  3.37it/s][A
 83%|████████▎ | 184/221 [00:50<00:10,  3.63it/s][A
 84%|████████▎ | 185/221 [00:50<00:08,  4.35it/s][A
 84%|████████▍ | 186/221 [00:50<00:10,  3.43it/s][A
 85%|████████▍ | 187/221 [00:51<00:10,  3.37it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.31it/s][A
 86%|████████▌ | 189/221 [00:51<00:09,  3.48it/s][A
 86%|████████▌ | 190/221 [00:52<00:10,  3.06it/s][A
 86%|████████▋ | 191/221 [00:52<00:08,  3.63it/s][A
 87%|████████▋ | 192/221 [00:52<00:07,  3.68it/s][A
 88%|████████▊ | 194/221 [00:52<00:06,  3.94it/s][A
 88%|████████▊ | 195/221 [00:53<00:06,  4.03it/s][A
 89%|████████▊ | 196/221 [00:53<00:08,  3.05it/s][A
 89%|████████▉ | 197/221 [00:54<00:07,  3.14it/s][A
 90%|████████▉ | 198/221 [00:54<00:08,  2.79it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.28it/s][A
 90%|█████████ | 200/221 [00:55<00:07,  2.83it/s][A
 91%|█████████ | 201/221 [00:55<00:06,  3.10it/s][A
 91%|█████████▏| 202/221 [00:55<00:06,  3.00it/s][A
 92%|█████████▏| 203/221 [00:55<00:05,  3.35it/s][A
 92%|█████████▏| 204/221 [00:56<00:05,  2.84it/s][A
 93%|█████████▎| 205/221 [00:56<00:04,  3.61it/s][A
 93%|█████████▎| 206/221 [00:56<00:04,  3.10it/s][A
 94%|█████████▎| 207/221 [00:57<00:03,  3.83it/s][A
 94%|█████████▍| 208/221 [00:57<00:03,  3.72it/s][A
 95%|█████████▍| 209/221 [00:57<00:03,  3.98it/s][A
 95%|█████████▌| 211/221 [00:58<00:02,  4.30it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  4.10it/s][A
 96%|█████████▋| 213/221 [00:58<00:01,  4.26it/s][A
 97%|█████████▋| 214/221 [00:59<00:02,  3.27it/s][A
 97%|█████████▋| 215/221 [00:59<00:01,  3.62it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.57it/s][A
 98%|█████████▊| 217/221 [00:59<00:01,  3.35it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.34it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.10it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.53it/s][A
100%|██████████| 221/221 [01:00<00:00,  3.80it/s][A100%|██████████| 221/221 [01:00<00:00,  3.63it/s]
09/09/2024 19:15:50 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 399--===========

09/09/2024 19:15:50 - INFO - __main__ -   {'area_r1': 39.9, 'area_recall': '39.9/66.2/75.7', 'area_ravg': 60.6}
09/09/2024 19:15:50 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 399--===========

09/09/2024 19:15:50 - INFO - __main__ -   {'forward_r1': 37.1, 'forward_recall': '37.1/64.6/74.4', 'forward_ravg': 58.7}
09/09/2024 19:15:50 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 399--===========

09/09/2024 19:15:50 - INFO - __main__ -   {'area_video_r1': 40.3, 'area_video_recall': '40.3/68.4/78.1', 'area_video_ravg': 62.3}
09/09/2024 19:15:50 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/09/2024 19:15:50 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 19:15:50 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 399--===========

09/09/2024 19:15:50 - INFO - __main__ -   {'area_video_r1': 53.1, 'area_video_recall': '53.1/75.2/82.4', 'area_video_ravg': 70.2, 'area_video_back_r1': 50.1, 'area_video_back_recall': '50.1/74.9/81.8', 'area_video_back_ravg': 68.9}
09/09/2024 19:15:50 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 399=======

09/09/2024 19:15:50 - INFO - __main__ -   {'area_video_r1': 53.1, 'area_video_recall': '53.1/75.2/82.4', 'area_video_ravg': 70.2, 'area_video_back_r1': 50.1, 'area_video_back_recall': '50.1/74.9/81.8', 'area_video_back_ravg': 68.9}
09/09/2024 19:15:50 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 399--===========

09/09/2024 19:15:50 - INFO - __main__ -   {'video_r1': 42.5, 'video_recall': '42.5/70.6/81.0', 'video_ravg': 64.7}
09/09/2024 19:15:50 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 19:15:50 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 19:15:50 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 399--===========

09/09/2024 19:15:50 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/09/2024 19:15:50 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/09/2024 19:15:50 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/09/2024 19:16:23 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.012673496268689632, 'loss_ret%tv%ta--finetune_area/loss_area': 1.1966443061828613, 'loss_ret%tv%ta--finetune_area/total_loss': 1.2093178033828735}
 21%|██        | 400/1945 [2:11:03<52:35:23, 122.54s/it][h264 @ 0x556b2d23ca00] mmco: unref short failure
 21%|██        | 401/1945 [2:11:07<37:19:45, 87.04s/it]  21%|██        | 402/1945 [2:11:12<26:42:12, 62.30s/it][h264 @ 0x559bf05109c0] mmco: unref short failure
 21%|██        | 403/1945 [2:11:17<19:19:19, 45.11s/it] 21%|██        | 404/1945 [2:11:22<14:12:23, 33.19s/it][h264 @ 0x559bf9178540] mmco: unref short failure
 21%|██        | 405/1945 [2:11:29<10:48:14, 25.26s/it][h264 @ 0x556b357e7540] mmco: unref short failure
[h264 @ 0x559beadd9700] mmco: unref short failure
 21%|██        | 406/1945 [2:11:36<8:26:55, 19.76s/it] [h264 @ 0x55a033fa07c0] mmco: unref short failure
 21%|██        | 407/1945 [2:11:43<6:51:13, 16.04s/it][h264 @ 0x556b35299300] mmco: unref short failure
[h264 @ 0x556b35299300] mmco: unref short failure
[h264 @ 0x559bf5e41780] mmco: unref short failure
 21%|██        | 408/1945 [2:11:51<5:46:10, 13.51s/it][h264 @ 0x556b3caf5280] mmco: unref short failure
[h264 @ 0x556b3caf5280] mmco: unref short failure
 21%|██        | 409/1945 [2:11:58<4:57:38, 11.63s/it][h264 @ 0x562428603600] mmco: unref short failure
 21%|██        | 410/1945 [2:12:07<4:32:22, 10.65s/it][h264 @ 0x556b3a9c0fc0] mmco: unref short failure
 21%|██        | 411/1945 [2:12:15<4:13:43,  9.92s/it][h264 @ 0x556b33801980] mmco: unref short failure
 21%|██        | 412/1945 [2:12:22<3:49:36,  8.99s/it][h264 @ 0x56241608d580] mmco: unref short failure
[h264 @ 0x56241608d580] mmco: unref short failure
[h264 @ 0x559bec1360c0] mmco: unref short failure
 21%|██        | 413/1945 [2:12:29<3:36:11,  8.47s/it][h264 @ 0x56241bd8ddc0] mmco: unref short failure
[h264 @ 0x56241bd8ddc0] mmco: unref short failure
[h264 @ 0x56241bd8ddc0] mmco: unref short failure
[h264 @ 0x56241bd8ddc0] mmco: unref short failure
[h264 @ 0x556b2f176bc0] mmco: unref short failure
[h264 @ 0x559bebf06e80] mmco: unref short failure
[h264 @ 0x559bebf06e80] mmco: unref short failure
 21%|██▏       | 414/1945 [2:12:38<3:38:40,  8.57s/it][h264 @ 0x55a036db9340] mmco: unref short failure
[h264 @ 0x55a036db9340] mmco: unref short failure
[h264 @ 0x55a036db9340] mmco: unref short failure
[h264 @ 0x55a036db9340] mmco: unref short failure
[h264 @ 0x562424784340] mmco: unref short failure
[h264 @ 0x562424784340] mmco: unref short failure
 21%|██▏       | 415/1945 [2:12:46<3:35:40,  8.46s/it][h264 @ 0x55a045df8980] mmco: unref short failure
[h264 @ 0x55a045df8980] mmco: unref short failure
[h264 @ 0x55a036218ac0] mmco: unref short failure
[h264 @ 0x55a036218ac0] mmco: unref short failure
 21%|██▏       | 416/1945 [2:12:55<3:39:20,  8.61s/it][h264 @ 0x556b3b5d7200] mmco: unref short failure
[h264 @ 0x556b3b5d7200] mmco: unref short failure
[h264 @ 0x556b3b5d7200] mmco: unref short failure
[h264 @ 0x556b3b5d7200] mmco: unref short failure
[h264 @ 0x559bf477e380] mmco: unref short failure
[h264 @ 0x559bf477e380] mmco: unref short failure
[h264 @ 0x559bf477e380] mmco: unref short failure
[h264 @ 0x559bf477e380] mmco: unref short failure
[h264 @ 0x559bf477e380] mmco: unref short failure
 21%|██▏       | 417/1945 [2:13:02<3:28:40,  8.19s/it] 21%|██▏       | 418/1945 [2:13:09<3:22:22,  7.95s/it][h264 @ 0x556b2dd8e2c0] mmco: unref short failure
 22%|██▏       | 419/1945 [2:13:18<3:29:07,  8.22s/it][h264 @ 0x559bf4f9ff80] mmco: unref short failure
[h264 @ 0x559bf4f9ff80] mmco: unref short failure
[h264 @ 0x55a03dca63c0] mmco: unref short failure
 22%|██▏       | 420/1945 [2:13:32<4:09:26,  9.81s/it][h264 @ 0x556b2dd07240] mmco: unref short failure
[h264 @ 0x559bee94f080] mmco: unref short failure
[h264 @ 0x559bee94f080] mmco: unref short failure
[h264 @ 0x55a0368cb540] mmco: unref short failure
[h264 @ 0x559bfa3f0800] mmco: unref short failure
 22%|██▏       | 421/1945 [2:13:39<3:51:26,  9.11s/it] 22%|██▏       | 422/1945 [2:13:48<3:50:24,  9.08s/it][h264 @ 0x55a039861500] mmco: unref short failure
[h264 @ 0x556b323f2680] mmco: unref short failure
 22%|██▏       | 423/1945 [2:13:55<3:29:15,  8.25s/it][h264 @ 0x556b452d9640] mmco: unref short failure
[h264 @ 0x556b452d9640] mmco: unref short failure
[h264 @ 0x559bec370c40] mmco: unref short failure
[h264 @ 0x559bec370c40] mmco: unref short failure
[h264 @ 0x556b31847800] mmco: unref short failure
[h264 @ 0x556b31847800] mmco: unref short failure
[h264 @ 0x55a03c0ca780] mmco: unref short failure
[h264 @ 0x55a03c0ca780] mmco: unref short failure
[h264 @ 0x55a03c0ca780] mmco: unref short failure
[h264 @ 0x55a03c0ca780] mmco: unref short failure
[h264 @ 0x556b301da700] mmco: unref short failure
[h264 @ 0x556b301da700] mmco: unref short failure
[h264 @ 0x55a04448fd40] mmco: unref short failure
[h264 @ 0x55a0450a4c80] mmco: unref short failure
[h264 @ 0x556b34ebf740] mmco: unref short failure
[h264 @ 0x556b34ebf740] mmco: unref short failure
[h264 @ 0x56241e207500] mmco: unref short failure
[h264 @ 0x559bf8cfd780] mmco: unref short failure
[h264 @ 0x559bf8cfd780] mmco: unref short failure
[h264 @ 0x562424537700] mmco: unref short failure
[h264 @ 0x562424537700] mmco: unref short failure
[h264 @ 0x562424537700] mmco: unref short failure
[h264 @ 0x562424537700] mmco: unref short failure
[h264 @ 0x562424537700] mmco: unref short failure
[h264 @ 0x562424537700] mmco: unref short failure
[h264 @ 0x562424537700] mmco: unref short failure
[h264 @ 0x562424537700] mmco: unref short failure
 22%|██▏       | 424/1945 [2:14:38<7:53:12, 18.67s/it][h264 @ 0x559bed3ca5c0] mmco: unref short failure
[h264 @ 0x559bed3ca5c0] mmco: unref short failure
[h264 @ 0x559be98fa140] mmco: unref short failure
[h264 @ 0x559be98fa140] mmco: unref short failure
 22%|██▏       | 425/1945 [2:14:50<7:09:28, 16.95s/it][h264 @ 0x562418cc2780] mmco: unref short failure
[h264 @ 0x562418cc2780] mmco: unref short failure
 22%|██▏       | 426/1945 [2:15:08<7:11:56, 17.06s/it][h264 @ 0x559bfc31bec0] mmco: unref short failure
[h264 @ 0x5624243c46c0] mmco: unref short failure
[h264 @ 0x56241d8c0740] mmco: unref short failure
[h264 @ 0x56241d8c0740] mmco: unref short failure
[h264 @ 0x559bec033100] mmco: unref short failure
[h264 @ 0x559bf3625000] mmco: unref short failure
[h264 @ 0x559bf3625000] mmco: unref short failure
 22%|██▏       | 427/1945 [2:15:25<7:14:06, 17.16s/it][h264 @ 0x556b3e8f4840] mmco: unref short failure
[h264 @ 0x556b3e8f4840] mmco: unref short failure
 22%|██▏       | 428/1945 [2:15:35<6:14:59, 14.83s/it][h264 @ 0x56242a1d5480] mmco: unref short failure
 22%|██▏       | 429/1945 [2:15:42<5:20:07, 12.67s/it] 22%|██▏       | 430/1945 [2:15:49<4:34:17, 10.86s/it][h264 @ 0x556b3a4a4440] mmco: unref short failure
[h264 @ 0x556b3a4a4440] mmco: unref short failure
 22%|██▏       | 431/1945 [2:15:56<4:09:18,  9.88s/it][h264 @ 0x5624219afa40] mmco: unref short failure
[h264 @ 0x5624219afa40] mmco: unref short failure
[h264 @ 0x55a040e85ec0] mmco: unref short failure
[h264 @ 0x55a040e85ec0] mmco: unref short failure
[h264 @ 0x5624169bcd00] mmco: unref short failure
[h264 @ 0x5624169bcd00] mmco: unref short failure
[h264 @ 0x56241d050200] mmco: unref short failure
[h264 @ 0x56241d050200] mmco: unref short failure
[h264 @ 0x556b40db9480] mmco: unref short failure
[h264 @ 0x55a03b2efa80] mmco: unref short failure
[h264 @ 0x559bf8d36040] mmco: unref short failure
[h264 @ 0x559bf8d36040] mmco: unref short failure
[h264 @ 0x55a03fb72ac0] mmco: unref short failure
[h264 @ 0x55a03fb72ac0] mmco: unref short failure
[h264 @ 0x556b42a4b8c0] mmco: unref short failure
[h264 @ 0x556b330206c0] mmco: unref short failure
[h264 @ 0x556b330206c0] mmco: unref short failure
[h264 @ 0x55a03c07ad80] mmco: unref short failure
[h264 @ 0x559bef10d9c0] mmco: unref short failure
 22%|██▏       | 432/1945 [2:16:39<8:13:01, 19.55s/it][h264 @ 0x55a03ba0e040] mmco: unref short failure
[h264 @ 0x56241ee46340] mmco: unref short failure
[h264 @ 0x56241ee46340] mmco: unref short failure
[h264 @ 0x56241ee46340] mmco: unref short failure
 22%|██▏       | 433/1945 [2:16:56<7:57:49, 18.96s/it][h264 @ 0x559bf6af6740] mmco: unref short failure
[h264 @ 0x559bf6af6740] mmco: unref short failure
[h264 @ 0x559bf6af6740] mmco: unref short failure
[h264 @ 0x559bf6af6740] mmco: unref short failure
[h264 @ 0x556b3dc1c840] mmco: unref short failure
[h264 @ 0x55a042b86c00] mmco: unref short failure
[h264 @ 0x559c03f9a880] mmco: unref short failure
[h264 @ 0x559c03f9a880] mmco: unref short failure
 22%|██▏       | 434/1945 [2:17:14<7:47:21, 18.56s/it][h264 @ 0x559bff5b1a80] mmco: unref short failure
[h264 @ 0x559bff5b1a80] mmco: unref short failure
 22%|██▏       | 435/1945 [2:17:21<6:18:41, 15.05s/it][h264 @ 0x559bef10d500] mmco: unref short failure
[h264 @ 0x55a03fb63100] mmco: unref short failure
[h264 @ 0x559beae0ae80] mmco: unref short failure
[h264 @ 0x559beae0ae80] mmco: unref short failure
[h264 @ 0x559bfc051b80] mmco: unref short failure
 22%|██▏       | 436/1945 [2:17:42<7:03:43, 16.85s/it] 22%|██▏       | 437/1945 [2:17:48<5:47:08, 13.81s/it][h264 @ 0x562418037d00] mmco: unref short failure
[h264 @ 0x562418037d00] mmco: unref short failure
 23%|██▎       | 438/1945 [2:17:55<4:54:46, 11.74s/it] 23%|██▎       | 439/1945 [2:18:03<4:24:07, 10.52s/it][h264 @ 0x556b3138e1c0] mmco: unref short failure
[h264 @ 0x556b3138e1c0] mmco: unref short failure
[h264 @ 0x556b402c3940] mmco: unref short failure
[h264 @ 0x556b402c3940] mmco: unref short failure
[h264 @ 0x556b402c3940] mmco: unref short failure
[h264 @ 0x556b402c3940] mmco: unref short failure
[h264 @ 0x556b402c3940] mmco: unref short failure
[h264 @ 0x556b402c3940] mmco: unref short failure
[h264 @ 0x556b34ebf280] mmco: unref short failure
[h264 @ 0x556b2f3974c0] mmco: unref short failure
[h264 @ 0x556b2f3974c0] mmco: unref short failure
[h264 @ 0x556b2daf0d80] mmco: unref short failure
[h264 @ 0x562422fa5a40] mmco: unref short failure
[h264 @ 0x562422fa5a40] mmco: unref short failure
[h264 @ 0x562422fa5a40] mmco: unref short failure
[h264 @ 0x562422fa5a40] mmco: unref short failure
[h264 @ 0x56241bd1afc0] mmco: unref short failure
[h264 @ 0x56241bd1afc0] mmco: unref short failure
[h264 @ 0x56242df25500] mmco: unref short failure
[h264 @ 0x56242df25500] mmco: unref short failure
 23%|██▎       | 440/1945 [2:18:36<7:15:26, 17.36s/it][h264 @ 0x56241789bf80] mmco: unref short failure
[h264 @ 0x56242df69840] mmco: unref short failure
[h264 @ 0x56242df69840] mmco: unref short failure
[h264 @ 0x559bea235900] mmco: unref short failure
[h264 @ 0x55a03eb994c0] mmco: unref short failure
[h264 @ 0x55a0464adac0] mmco: unref short failure
[h264 @ 0x55a0464adac0] mmco: unref short failure
[h264 @ 0x55a034a39300] mmco: unref short failure
[h264 @ 0x55a034a39300] mmco: unref short failure
 23%|██▎       | 441/1945 [2:18:59<7:58:24, 19.09s/it][h264 @ 0x556b37e49340] mmco: unref short failure
[h264 @ 0x556b37e49340] mmco: unref short failure
[h264 @ 0x55a03c924a80] mmco: unref short failure
[h264 @ 0x56241900ba80] mmco: unref short failure
 23%|██▎       | 442/1945 [2:19:12<7:10:58, 17.20s/it][h264 @ 0x559bef10d740] mmco: unref short failure
[h264 @ 0x556b440ae280] mmco: unref short failure
[h264 @ 0x556b440ae280] mmco: unref short failure
[h264 @ 0x56242d860c80] mmco: unref short failure
[h264 @ 0x56242d860c80] mmco: unref short failure
[h264 @ 0x559c04013c40] mmco: unref short failure
[h264 @ 0x559c04013c40] mmco: unref short failure
 23%|██▎       | 443/1945 [2:19:39<8:19:15, 19.94s/it][h264 @ 0x55a0342154c0] mmco: unref short failure
 23%|██▎       | 444/1945 [2:19:46<6:48:38, 16.33s/it][h264 @ 0x55a0342154c0] mmco: unref short failure
[h264 @ 0x562426b93e40] mmco: unref short failure
[h264 @ 0x562426b93e40] mmco: unref short failure
[h264 @ 0x56241cece040] mmco: unref short failure
[h264 @ 0x56241cece040] mmco: unref short failure
 23%|██▎       | 445/1945 [2:19:54<5:45:15, 13.81s/it][h264 @ 0x56242339c580] mmco: unref short failure
[h264 @ 0x56242339c580] mmco: unref short failure
[h264 @ 0x559bfebb1f40] mmco: unref short failure
[h264 @ 0x559bfebb1f40] mmco: unref short failure
 23%|██▎       | 446/1945 [2:20:03<5:04:30, 12.19s/it][h264 @ 0x55a035d769c0] mmco: unref short failure
[h264 @ 0x55a035d769c0] mmco: unref short failure
 23%|██▎       | 447/1945 [2:20:10<4:23:36, 10.56s/it][h264 @ 0x56242df69100] mmco: unref short failure
[h264 @ 0x56242df69100] mmco: unref short failure
[h264 @ 0x562421ed6e40] mmco: unref short failure
[h264 @ 0x562421ed6e40] mmco: unref short failure
[h264 @ 0x556b39aec340] mmco: unref short failure
[h264 @ 0x556b39aec340] mmco: unref short failure
[h264 @ 0x556b37c3d680] mmco: unref short failure
 23%|██▎       | 448/1945 [2:20:33<6:01:11, 14.48s/it][h264 @ 0x559c03ba9d80] mmco: unref short failure
[h264 @ 0x556b338f70c0] mmco: unref short failure
[h264 @ 0x556b338f70c0] mmco: unref short failure
[h264 @ 0x562428a22ec0] mmco: unref short failure
[h264 @ 0x55a046fbb5c0] mmco: unref short failure
 23%|██▎       | 449/1945 [2:20:55<6:56:07, 16.69s/it]09/09/2024 19:26:17 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 19:26:17 - INFO - __main__ -   start running ret%tv validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a0435e8180] mmco: unref short failure
[h264 @ 0x55a0435e8180] mmco: unref short failure
[h264 @ 0x55a0435e8180] mmco: unref short failure
[h264 @ 0x55a0435e8180] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559bf0753980] mmco: unref short failure
[h264 @ 0x559bf0753980] mmco: unref short failure
[h264 @ 0x562420133000] mmco: unref short failure
[h264 @ 0x55a032bac040] mmco: unref short failure
[h264 @ 0x55a032bac040] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x562425d67640] mmco: unref short failure
[h264 @ 0x562425d67640] mmco: unref short failure
[h264 @ 0x559be9c61bc0] mmco: unref short failure
[h264 @ 0x559be9c61bc0] mmco: unref short failure
[h264 @ 0x562420f974c0] mmco: unref short failure
[h264 @ 0x562420f974c0] mmco: unref short failure
[h264 @ 0x56242edab880] mmco: unref short failure
[h264 @ 0x556b4274f0c0] mmco: unref short failure
[h264 @ 0x562425cb3b00] mmco: unref short failure
[h264 @ 0x556b3190d840] mmco: unref short failure
[h264 @ 0x556b3190d840] mmco: unref short failure
[h264 @ 0x56242f839d40] mmco: unref short failure
[h264 @ 0x56242f839d40] mmco: unref short failure
[h264 @ 0x559beb5d54c0] mmco: unref short failure
[h264 @ 0x559beb5d54c0] mmco: unref short failure
[h264 @ 0x559beb5d52c0] mmco: unref short failure
[h264 @ 0x559beb5d52c0] mmco: unref short failure
[h264 @ 0x55a0346ff400] mmco: unref short failure
[h264 @ 0x562427239280] mmco: unref short failure
[h264 @ 0x562427239280] mmco: unref short failure
[h264 @ 0x55a038f0f4c0] mmco: unref short failure
[h264 @ 0x559bf133bbc0] mmco: unref short failure
[h264 @ 0x559bf133bbc0] mmco: unref short failure
[h264 @ 0x559bf133bbc0] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:05,  1.75it/s][A
  1%|          | 2/221 [00:01<02:13,  1.64it/s][A
  1%|▏         | 3/221 [00:01<01:47,  2.03it/s][A
  2%|▏         | 4/221 [00:01<01:27,  2.47it/s][A
  2%|▏         | 5/221 [00:02<01:12,  2.98it/s][A
  3%|▎         | 6/221 [00:02<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:02<00:52,  4.06it/s][A
  4%|▎         | 8/221 [00:02<01:03,  3.33it/s][A
  4%|▍         | 9/221 [00:03<01:05,  3.23it/s][A
  5%|▍         | 10/221 [00:03<01:13,  2.86it/s][A
  5%|▍         | 11/221 [00:03<01:08,  3.07it/s][A
  5%|▌         | 12/221 [00:04<01:34,  2.21it/s][A
  6%|▌         | 13/221 [00:04<01:29,  2.33it/s][A
  6%|▋         | 14/221 [00:06<02:08,  1.61it/s][A
  7%|▋         | 15/221 [00:06<01:42,  2.00it/s][A
  7%|▋         | 16/221 [00:06<01:41,  2.02it/s][A
  8%|▊         | 17/221 [00:07<02:07,  1.60it/s][A
  8%|▊         | 18/221 [00:07<01:46,  1.91it/s][A
  9%|▊         | 19/221 [00:08<01:21,  2.49it/s][A[h264 @ 0x556b2eb09600] mmco: unref short failure

  9%|▉         | 20/221 [00:08<01:12,  2.78it/s][A
 10%|▉         | 21/221 [00:08<01:00,  3.31it/s][A
 10%|▉         | 22/221 [00:08<00:52,  3.77it/s][A
 10%|█         | 23/221 [00:08<00:42,  4.61it/s][A
 11%|█         | 24/221 [00:08<00:36,  5.38it/s][A
 11%|█▏        | 25/221 [00:09<00:39,  4.93it/s][A[h264 @ 0x55a04059f180] mmco: unref short failure
[h264 @ 0x55a04059f180] mmco: unref short failure

 12%|█▏        | 26/221 [00:09<00:56,  3.45it/s][A
 12%|█▏        | 27/221 [00:09<00:49,  3.91it/s][A
 13%|█▎        | 28/221 [00:10<01:02,  3.08it/s][A
 13%|█▎        | 29/221 [00:11<01:28,  2.18it/s][A[h264 @ 0x556b3b281700] mmco: unref short failure
[h264 @ 0x556b3b281700] mmco: unref short failure

 14%|█▎        | 30/221 [00:11<01:20,  2.38it/s][A
 14%|█▍        | 31/221 [00:11<01:11,  2.66it/s][A
 14%|█▍        | 32/221 [00:11<00:55,  3.38it/s][A
 15%|█▍        | 33/221 [00:11<00:49,  3.76it/s][A
 15%|█▌        | 34/221 [00:12<00:44,  4.17it/s][A[h264 @ 0x559bf7f76280] mmco: unref short failure

 16%|█▌        | 35/221 [00:12<00:42,  4.34it/s][A
 16%|█▋        | 36/221 [00:12<00:48,  3.83it/s][A
 17%|█▋        | 37/221 [00:13<01:05,  2.80it/s][A
 17%|█▋        | 38/221 [00:13<01:07,  2.72it/s][A
 18%|█▊        | 39/221 [00:13<01:02,  2.92it/s][A
 18%|█▊        | 40/221 [00:14<01:05,  2.78it/s][A
 19%|█▊        | 41/221 [00:14<00:52,  3.45it/s][A
 19%|█▉        | 42/221 [00:14<01:04,  2.76it/s][A
 19%|█▉        | 43/221 [00:15<00:56,  3.15it/s][A
 20%|█▉        | 44/221 [00:15<00:44,  3.94it/s][A
 20%|██        | 45/221 [00:16<01:08,  2.58it/s][A
 21%|██        | 46/221 [00:16<01:08,  2.54it/s][A
 21%|██▏       | 47/221 [00:16<01:12,  2.40it/s][A
 22%|██▏       | 48/221 [00:16<00:56,  3.08it/s][A
 22%|██▏       | 49/221 [00:17<01:25,  2.02it/s][A
 23%|██▎       | 50/221 [00:18<01:21,  2.09it/s][A
 23%|██▎       | 51/221 [00:18<01:11,  2.39it/s][A
 24%|██▎       | 52/221 [00:18<01:02,  2.70it/s][A
 24%|██▍       | 53/221 [00:19<00:51,  3.28it/s][A
 24%|██▍       | 54/221 [00:20<02:08,  1.30it/s][A
 25%|██▍       | 55/221 [00:21<01:45,  1.57it/s][A
 25%|██▌       | 56/221 [00:21<01:25,  1.92it/s][A
 26%|██▌       | 57/221 [00:21<01:13,  2.24it/s][A
 26%|██▌       | 58/221 [00:21<01:01,  2.63it/s][A
 27%|██▋       | 59/221 [00:22<01:01,  2.65it/s][A
 27%|██▋       | 60/221 [00:23<01:17,  2.08it/s][A
 28%|██▊       | 61/221 [00:23<01:06,  2.42it/s][A
 28%|██▊       | 62/221 [00:23<01:04,  2.45it/s][A
 29%|██▊       | 63/221 [00:23<00:53,  2.95it/s][A
 29%|██▉       | 64/221 [00:24<00:46,  3.41it/s][A
 29%|██▉       | 65/221 [00:24<00:46,  3.34it/s][A
 30%|██▉       | 66/221 [00:24<00:48,  3.17it/s][A
 30%|███       | 67/221 [00:25<00:55,  2.79it/s][A
 31%|███       | 68/221 [00:25<00:45,  3.37it/s][A
 31%|███       | 69/221 [00:25<01:00,  2.52it/s][A
 32%|███▏      | 70/221 [00:26<00:49,  3.05it/s][A
 32%|███▏      | 71/221 [00:26<01:04,  2.32it/s][A
 33%|███▎      | 72/221 [00:27<00:56,  2.64it/s][A[h264 @ 0x55a03351f9c0] mmco: unref short failure
[h264 @ 0x559bf999c240] mmco: unref short failure
[h264 @ 0x559bf999c240] mmco: unref short failure

 33%|███▎      | 73/221 [00:27<00:58,  2.54it/s][A
 33%|███▎      | 74/221 [00:27<00:46,  3.15it/s][A
 34%|███▍      | 75/221 [00:28<00:50,  2.90it/s][A
 34%|███▍      | 76/221 [00:28<00:39,  3.64it/s][A
 35%|███▍      | 77/221 [00:28<00:35,  4.04it/s][A
 35%|███▌      | 78/221 [00:28<00:34,  4.17it/s][A
 36%|███▌      | 79/221 [00:29<00:49,  2.88it/s][A
 36%|███▌      | 80/221 [00:29<00:48,  2.89it/s][A
 37%|███▋      | 81/221 [00:29<00:46,  3.02it/s][A
 37%|███▋      | 82/221 [00:30<01:04,  2.17it/s][A
 38%|███▊      | 83/221 [00:31<01:06,  2.08it/s][A
 38%|███▊      | 84/221 [00:31<00:54,  2.51it/s][A
 38%|███▊      | 85/221 [00:31<00:46,  2.90it/s][A
 39%|███▉      | 86/221 [00:31<00:49,  2.74it/s][A
 39%|███▉      | 87/221 [00:32<00:55,  2.43it/s][A
 40%|███▉      | 88/221 [00:32<00:57,  2.32it/s][A
 40%|████      | 89/221 [00:33<01:05,  2.01it/s][A
 41%|████      | 90/221 [00:33<00:56,  2.31it/s][A
 41%|████      | 91/221 [00:34<00:45,  2.83it/s][A
 42%|████▏     | 92/221 [00:34<00:41,  3.12it/s][A
 42%|████▏     | 93/221 [00:34<00:45,  2.83it/s][A
 43%|████▎     | 94/221 [00:34<00:38,  3.28it/s][A
 43%|████▎     | 95/221 [00:35<00:40,  3.11it/s][A
 43%|████▎     | 96/221 [00:35<00:42,  2.98it/s][A
 44%|████▍     | 97/221 [00:35<00:37,  3.27it/s][A
 44%|████▍     | 98/221 [00:36<00:35,  3.42it/s][A
 45%|████▍     | 99/221 [00:36<00:29,  4.14it/s][A
 45%|████▌     | 100/221 [00:36<00:28,  4.24it/s][A
 46%|████▌     | 101/221 [00:36<00:24,  4.85it/s][A
 46%|████▌     | 102/221 [00:36<00:29,  4.04it/s][A
 47%|████▋     | 103/221 [00:37<00:25,  4.70it/s][A
 47%|████▋     | 104/221 [00:37<00:22,  5.31it/s][A
 48%|████▊     | 105/221 [00:37<00:23,  4.85it/s][A
 48%|████▊     | 106/221 [00:38<00:46,  2.49it/s][A
 48%|████▊     | 107/221 [00:38<00:39,  2.88it/s][A
 49%|████▉     | 108/221 [00:38<00:33,  3.39it/s][A
 49%|████▉     | 109/221 [00:39<00:33,  3.39it/s][A
 50%|████▉     | 110/221 [00:39<00:32,  3.40it/s][A
 50%|█████     | 111/221 [00:39<00:36,  3.02it/s][A
 51%|█████     | 112/221 [00:39<00:33,  3.30it/s][A[h264 @ 0x556b2e6974c0] mmco: unref short failure
[h264 @ 0x556b2e6974c0] mmco: unref short failure

 51%|█████     | 113/221 [00:40<00:34,  3.16it/s][A
 52%|█████▏    | 114/221 [00:40<00:27,  3.94it/s][A
 52%|█████▏    | 115/221 [00:40<00:25,  4.16it/s][A
 52%|█████▏    | 116/221 [00:43<01:51,  1.06s/it][A
 53%|█████▎    | 117/221 [00:43<01:29,  1.17it/s][A
 53%|█████▎    | 118/221 [00:44<01:11,  1.45it/s][A
 54%|█████▍    | 119/221 [00:44<00:57,  1.78it/s][A
 54%|█████▍    | 120/221 [00:44<00:49,  2.03it/s][A
 55%|█████▍    | 121/221 [00:44<00:38,  2.58it/s][A
 55%|█████▌    | 122/221 [00:45<00:33,  2.98it/s][A
 56%|█████▌    | 123/221 [00:45<00:27,  3.59it/s][A
 56%|█████▌    | 124/221 [00:45<00:24,  4.00it/s][A
 57%|█████▋    | 125/221 [00:45<00:27,  3.49it/s][A
 57%|█████▋    | 126/221 [00:46<00:25,  3.75it/s][A
 57%|█████▋    | 127/221 [00:46<00:31,  2.95it/s][A
 58%|█████▊    | 128/221 [00:46<00:30,  3.03it/s][A
 58%|█████▊    | 129/221 [00:47<00:25,  3.60it/s][A
 59%|█████▉    | 130/221 [00:47<00:24,  3.71it/s][A
 59%|█████▉    | 131/221 [00:47<00:20,  4.42it/s][A
 60%|█████▉    | 132/221 [00:47<00:17,  5.09it/s][A
 60%|██████    | 133/221 [00:47<00:22,  3.98it/s][A
 61%|██████    | 134/221 [00:48<00:20,  4.33it/s][A
 61%|██████    | 135/221 [00:48<00:19,  4.50it/s][A[h264 @ 0x559bfe17b840] mmco: unref short failure

[h264 @ 0x559bfe17b840] mmco: unref short failure
 62%|██████▏   | 136/221 [00:48<00:22,  3.73it/s][A
 62%|██████▏   | 137/221 [00:48<00:20,  4.10it/s][A
 62%|██████▏   | 138/221 [00:49<00:22,  3.62it/s][A
 63%|██████▎   | 139/221 [00:49<00:25,  3.19it/s][A
 63%|██████▎   | 140/221 [00:49<00:24,  3.29it/s][A
 64%|██████▍   | 141/221 [00:50<00:21,  3.64it/s][A
 64%|██████▍   | 142/221 [00:50<00:22,  3.57it/s][A
 65%|██████▍   | 143/221 [00:50<00:25,  3.07it/s][A
 65%|██████▌   | 144/221 [00:51<00:25,  3.06it/s][A
 66%|██████▌   | 145/221 [00:51<00:23,  3.22it/s][A
 66%|██████▌   | 146/221 [00:51<00:19,  3.81it/s][A
 67%|██████▋   | 147/221 [00:51<00:20,  3.61it/s][A
 67%|██████▋   | 148/221 [00:52<00:25,  2.92it/s][A
 67%|██████▋   | 149/221 [00:52<00:22,  3.17it/s][A
 68%|██████▊   | 150/221 [00:53<00:21,  3.25it/s][A[h264 @ 0x559bf92a8980] mmco: unref short failure

 68%|██████▊   | 151/221 [00:53<00:30,  2.26it/s][A
 69%|██████▉   | 152/221 [00:55<00:48,  1.43it/s][A[h264 @ 0x556b442a3280] mmco: unref short failure
[h264 @ 0x556b442a3280] mmco: unref short failure

 69%|██████▉   | 153/221 [00:55<00:40,  1.70it/s][A
 70%|██████▉   | 154/221 [00:55<00:34,  1.97it/s][A
 70%|███████   | 155/221 [00:55<00:26,  2.52it/s][A
 71%|███████   | 156/221 [00:56<00:21,  2.96it/s][A
 71%|███████   | 157/221 [00:56<00:28,  2.23it/s][A
 71%|███████▏  | 158/221 [00:57<00:24,  2.53it/s][A
 72%|███████▏  | 159/221 [00:57<00:20,  2.98it/s][A
 72%|███████▏  | 160/221 [00:57<00:19,  3.12it/s][A
 73%|███████▎  | 161/221 [00:57<00:15,  3.88it/s][A
 73%|███████▎  | 162/221 [00:58<00:20,  2.88it/s][A
 74%|███████▍  | 163/221 [00:58<00:19,  3.04it/s][A
 74%|███████▍  | 164/221 [00:58<00:18,  3.12it/s][A
 75%|███████▌  | 166/221 [00:59<00:15,  3.54it/s][A[h264 @ 0x556b45694a80] mmco: unref short failure

 76%|███████▌  | 167/221 [00:59<00:14,  3.82it/s][A
 76%|███████▌  | 168/221 [00:59<00:17,  3.11it/s][A
 76%|███████▋  | 169/221 [01:00<00:15,  3.41it/s][A
 77%|███████▋  | 170/221 [01:00<00:15,  3.34it/s][A
 77%|███████▋  | 171/221 [01:00<00:15,  3.14it/s][A
 78%|███████▊  | 172/221 [01:01<00:13,  3.55it/s][A
 78%|███████▊  | 173/221 [01:01<00:13,  3.57it/s][A
 79%|███████▊  | 174/221 [01:01<00:12,  3.64it/s][A
 79%|███████▉  | 175/221 [01:02<00:15,  3.00it/s][A
 80%|███████▉  | 176/221 [01:02<00:14,  3.16it/s][A
 80%|████████  | 177/221 [01:02<00:12,  3.55it/s][A
 81%|████████  | 178/221 [01:02<00:12,  3.49it/s][A
 81%|████████  | 179/221 [01:03<00:13,  3.22it/s][A
 82%|████████▏ | 181/221 [01:03<00:09,  4.33it/s][A
 82%|████████▏ | 182/221 [01:03<00:08,  4.83it/s][A
 83%|████████▎ | 183/221 [01:03<00:07,  5.30it/s][A
 83%|████████▎ | 184/221 [01:04<00:08,  4.57it/s][A
 84%|████████▍ | 186/221 [01:04<00:07,  4.44it/s][A
 85%|████████▍ | 187/221 [01:04<00:07,  4.84it/s][A
 85%|████████▌ | 188/221 [01:04<00:06,  4.77it/s][A
 86%|████████▌ | 189/221 [01:05<00:07,  4.14it/s][A
 86%|████████▌ | 190/221 [01:05<00:08,  3.66it/s][A
 87%|████████▋ | 192/221 [01:05<00:06,  4.33it/s][A[h264 @ 0x556b36a4a580] mmco: unref short failure
[h264 @ 0x556b36a4a580] mmco: unref short failure

 88%|████████▊ | 194/221 [01:06<00:08,  3.25it/s][A
 88%|████████▊ | 195/221 [01:06<00:07,  3.56it/s][A
 89%|████████▊ | 196/221 [01:07<00:09,  2.77it/s][A
 89%|████████▉ | 197/221 [01:07<00:07,  3.37it/s][A
 90%|████████▉ | 198/221 [01:07<00:06,  3.30it/s][A
 90%|█████████ | 199/221 [01:08<00:05,  3.95it/s][A
 90%|█████████ | 200/221 [01:08<00:05,  3.69it/s][A
 91%|█████████ | 201/221 [01:08<00:05,  3.97it/s][A
 91%|█████████▏| 202/221 [01:08<00:04,  4.32it/s][A
 92%|█████████▏| 203/221 [01:09<00:04,  4.48it/s][A
 92%|█████████▏| 204/221 [01:09<00:04,  4.20it/s][A
 93%|█████████▎| 206/221 [01:09<00:03,  3.76it/s][A
 94%|█████████▎| 207/221 [01:10<00:03,  4.14it/s][A
 94%|█████████▍| 208/221 [01:10<00:02,  4.67it/s][A
 95%|█████████▍| 209/221 [01:10<00:02,  4.52it/s][A
 95%|█████████▌| 211/221 [01:10<00:02,  4.27it/s][A
 96%|█████████▌| 212/221 [01:11<00:01,  4.90it/s][A
 96%|█████████▋| 213/221 [01:11<00:01,  4.69it/s][A
 97%|█████████▋| 214/221 [01:11<00:01,  4.43it/s][A
 97%|█████████▋| 215/221 [01:11<00:01,  4.39it/s][A
 98%|█████████▊| 216/221 [01:12<00:01,  3.95it/s][A
 98%|█████████▊| 217/221 [01:12<00:01,  3.59it/s][A
 99%|█████████▊| 218/221 [01:12<00:00,  3.68it/s][A
 99%|█████████▉| 219/221 [01:12<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [01:15<00:01,  1.09s/it][A
100%|██████████| 221/221 [01:16<00:00,  1.23it/s][A100%|██████████| 221/221 [01:16<00:00,  2.90it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.78it/s][A
  1%|          | 2/221 [00:00<00:57,  3.78it/s][A
  1%|▏         | 3/221 [00:00<00:58,  3.75it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.75it/s][A
  2%|▏         | 5/221 [00:01<00:57,  3.73it/s][A
  3%|▎         | 6/221 [00:01<00:57,  3.75it/s][A
  3%|▎         | 7/221 [00:01<00:57,  3.75it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.76it/s][A
  4%|▍         | 9/221 [00:02<00:56,  3.76it/s][A
  5%|▍         | 10/221 [00:02<00:56,  3.76it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.76it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.77it/s][A
  6%|▌         | 13/221 [00:03<00:55,  3.77it/s][A
  6%|▋         | 14/221 [00:03<00:55,  3.74it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.75it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.75it/s][A
  8%|▊         | 17/221 [00:04<00:54,  3.76it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.77it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.77it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.77it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.77it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.78it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.78it/s][A
 11%|█         | 24/221 [00:06<00:52,  3.78it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.78it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.78it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.78it/s][A
 13%|█▎        | 28/221 [00:07<00:51,  3.78it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:09<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:50,  3.53it/s][A
 20%|██        | 45/221 [00:11<00:48,  3.61it/s][A
 21%|██        | 46/221 [00:12<00:47,  3.66it/s][A
 21%|██▏       | 47/221 [00:12<00:47,  3.70it/s][A
 22%|██▏       | 48/221 [00:12<00:46,  3.72it/s][A
 22%|██▏       | 49/221 [00:13<00:45,  3.74it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.76it/s][A
 23%|██▎       | 51/221 [00:13<00:45,  3.77it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.77it/s][A
 24%|██▍       | 53/221 [00:14<00:44,  3.78it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.78it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.78it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:18<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:23<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:28<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:32<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:42<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:46<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:47<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:52<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:56<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:57<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.78it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:28,  7.67it/s][A
  1%|          | 2/221 [00:00<00:51,  4.25it/s][A
  1%|▏         | 3/221 [00:00<00:58,  3.75it/s][A
  2%|▏         | 4/221 [00:00<00:52,  4.17it/s][A
  2%|▏         | 5/221 [00:01<00:49,  4.39it/s][A
  3%|▎         | 7/221 [00:01<00:43,  4.97it/s][A
  4%|▎         | 8/221 [00:01<00:49,  4.32it/s][A
  4%|▍         | 9/221 [00:02<00:49,  4.31it/s][A
  5%|▍         | 10/221 [00:02<01:07,  3.11it/s][A
  5%|▍         | 11/221 [00:02<01:03,  3.32it/s][A
  5%|▌         | 12/221 [00:03<00:54,  3.85it/s][A
  6%|▌         | 13/221 [00:03<01:26,  2.40it/s][A
  7%|▋         | 15/221 [00:04<01:00,  3.40it/s][A
  7%|▋         | 16/221 [00:04<01:06,  3.09it/s][A
  8%|▊         | 17/221 [00:05<01:25,  2.39it/s][A
  8%|▊         | 18/221 [00:05<01:14,  2.73it/s][A
  9%|▊         | 19/221 [00:05<01:05,  3.08it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.76it/s][A
 10%|▉         | 21/221 [00:05<00:46,  4.32it/s][A
 10%|▉         | 22/221 [00:06<00:44,  4.48it/s][A
 11%|█         | 24/221 [00:06<00:34,  5.63it/s][A
 11%|█▏        | 25/221 [00:06<00:36,  5.32it/s][A
 12%|█▏        | 26/221 [00:06<00:39,  4.97it/s][A
 13%|█▎        | 28/221 [00:07<00:43,  4.39it/s][A
 13%|█▎        | 29/221 [00:07<00:40,  4.74it/s][A
 14%|█▎        | 30/221 [00:07<00:44,  4.33it/s][A
 14%|█▍        | 31/221 [00:07<00:41,  4.60it/s][A
 15%|█▍        | 33/221 [00:08<00:33,  5.65it/s][A
 15%|█▌        | 34/221 [00:08<00:32,  5.82it/s][A
 16%|█▌        | 35/221 [00:08<00:33,  5.48it/s][A
 16%|█▋        | 36/221 [00:08<00:40,  4.53it/s][A
 17%|█▋        | 37/221 [00:09<00:39,  4.61it/s][A
 17%|█▋        | 38/221 [00:09<00:44,  4.16it/s][A
 18%|█▊        | 39/221 [00:09<00:40,  4.45it/s][A
 18%|█▊        | 40/221 [00:09<00:48,  3.72it/s][A
 19%|█▊        | 41/221 [00:10<00:40,  4.45it/s][A
 19%|█▉        | 42/221 [00:10<00:40,  4.40it/s][A
 19%|█▉        | 43/221 [00:10<00:45,  3.89it/s][A
 20%|█▉        | 44/221 [00:10<00:42,  4.18it/s][A
 20%|██        | 45/221 [00:11<00:43,  4.08it/s][A
 21%|██        | 46/221 [00:11<00:39,  4.43it/s][A
 21%|██▏       | 47/221 [00:11<00:37,  4.66it/s][A
 22%|██▏       | 48/221 [00:11<00:32,  5.28it/s][A
 22%|██▏       | 49/221 [00:11<00:33,  5.17it/s][A
 23%|██▎       | 50/221 [00:12<00:39,  4.28it/s][A
 23%|██▎       | 51/221 [00:12<00:38,  4.46it/s][A
 24%|██▎       | 52/221 [00:12<00:36,  4.61it/s][A
 24%|██▍       | 53/221 [00:12<00:31,  5.35it/s][A
 24%|██▍       | 54/221 [00:13<00:51,  3.21it/s][A
 25%|██▍       | 55/221 [00:13<00:51,  3.19it/s][A
 25%|██▌       | 56/221 [00:13<00:42,  3.85it/s][A
 26%|██▌       | 57/221 [00:14<00:43,  3.73it/s][A
 26%|██▌       | 58/221 [00:14<00:44,  3.66it/s][A
 27%|██▋       | 59/221 [00:14<00:40,  4.03it/s][A
 27%|██▋       | 60/221 [00:14<00:40,  4.02it/s][A
 28%|██▊       | 61/221 [00:14<00:36,  4.43it/s][A
 28%|██▊       | 62/221 [00:15<00:37,  4.27it/s][A
 29%|██▊       | 63/221 [00:15<00:36,  4.31it/s][A
 29%|██▉       | 64/221 [00:15<00:46,  3.39it/s][A
 29%|██▉       | 65/221 [00:15<00:37,  4.17it/s][A
 30%|██▉       | 66/221 [00:16<00:50,  3.10it/s][A
 30%|███       | 67/221 [00:16<00:58,  2.65it/s][A
 31%|███       | 68/221 [00:17<00:48,  3.18it/s][A
 31%|███       | 69/221 [00:17<01:02,  2.43it/s][A
 32%|███▏      | 70/221 [00:17<00:49,  3.06it/s][A
 32%|███▏      | 71/221 [00:18<00:44,  3.37it/s][A
 33%|███▎      | 72/221 [00:18<00:49,  3.03it/s][A
 33%|███▎      | 73/221 [00:18<00:50,  2.91it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.77it/s][A
 34%|███▍      | 76/221 [00:19<00:36,  4.00it/s][A
 35%|███▍      | 77/221 [00:19<00:35,  4.10it/s][A
 35%|███▌      | 78/221 [00:19<00:32,  4.44it/s][A
 36%|███▌      | 79/221 [00:20<00:42,  3.32it/s][A
 36%|███▌      | 80/221 [00:20<00:39,  3.58it/s][A
 37%|███▋      | 81/221 [00:20<00:36,  3.87it/s][A
 37%|███▋      | 82/221 [00:21<00:34,  3.98it/s][A
 38%|███▊      | 83/221 [00:21<00:38,  3.59it/s][A
 38%|███▊      | 84/221 [00:21<00:35,  3.90it/s][A
 39%|███▉      | 86/221 [00:21<00:28,  4.71it/s][A
 39%|███▉      | 87/221 [00:22<00:41,  3.21it/s][A
 40%|███▉      | 88/221 [00:22<00:46,  2.84it/s][A
 40%|████      | 89/221 [00:23<00:42,  3.11it/s][A
 41%|████      | 90/221 [00:23<00:42,  3.09it/s][A
 41%|████      | 91/221 [00:23<00:34,  3.74it/s][A
 42%|████▏     | 92/221 [00:23<00:35,  3.66it/s][A
 42%|████▏     | 93/221 [00:24<00:55,  2.32it/s][A
 43%|████▎     | 94/221 [00:25<00:48,  2.62it/s][A
 43%|████▎     | 95/221 [00:25<00:43,  2.90it/s][A
 43%|████▎     | 96/221 [00:25<00:38,  3.23it/s][A
 44%|████▍     | 97/221 [00:25<00:33,  3.65it/s][A
 44%|████▍     | 98/221 [00:25<00:31,  3.88it/s][A
 45%|████▍     | 99/221 [00:26<00:28,  4.31it/s][A
 45%|████▌     | 100/221 [00:26<00:28,  4.28it/s][A
 46%|████▌     | 101/221 [00:26<00:29,  4.02it/s][A
 46%|████▌     | 102/221 [00:27<00:48,  2.46it/s][A
 47%|████▋     | 103/221 [00:27<00:38,  3.08it/s][A
 47%|████▋     | 104/221 [00:27<00:33,  3.53it/s][A
 48%|████▊     | 105/221 [00:27<00:32,  3.62it/s][A
 48%|████▊     | 106/221 [00:28<00:42,  2.69it/s][A
 48%|████▊     | 107/221 [00:28<00:38,  3.00it/s][A
 49%|████▉     | 108/221 [00:29<00:34,  3.30it/s][A
 49%|████▉     | 109/221 [00:29<00:27,  4.00it/s][A
 50%|████▉     | 110/221 [00:29<00:27,  4.06it/s][A
 50%|█████     | 111/221 [00:29<00:26,  4.10it/s][A
 51%|█████     | 112/221 [00:29<00:27,  3.91it/s][A
 51%|█████     | 113/221 [00:30<00:27,  3.99it/s][A
 52%|█████▏    | 115/221 [00:30<00:21,  4.85it/s][A
 52%|█████▏    | 116/221 [00:30<00:22,  4.59it/s][A
 53%|█████▎    | 117/221 [00:31<00:24,  4.17it/s][A
 53%|█████▎    | 118/221 [00:31<00:24,  4.22it/s][A
 54%|█████▍    | 119/221 [00:31<00:30,  3.32it/s][A
 54%|█████▍    | 120/221 [00:31<00:27,  3.68it/s][A
 55%|█████▍    | 121/221 [00:32<00:22,  4.48it/s][A
 55%|█████▌    | 122/221 [00:32<00:23,  4.14it/s][A
 56%|█████▌    | 123/221 [00:32<00:24,  3.94it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.75it/s][A
 57%|█████▋    | 125/221 [00:33<00:27,  3.45it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:29,  3.21it/s][A
 58%|█████▊    | 128/221 [00:34<00:26,  3.45it/s][A
 58%|█████▊    | 129/221 [00:34<00:21,  4.24it/s][A
 59%|█████▉    | 130/221 [00:34<00:21,  4.33it/s][A
 60%|█████▉    | 132/221 [00:34<00:20,  4.40it/s][A
 60%|██████    | 133/221 [00:35<00:21,  4.14it/s][A
 61%|██████    | 134/221 [00:35<00:24,  3.58it/s][A
 61%|██████    | 135/221 [00:35<00:27,  3.12it/s][A
 62%|██████▏   | 136/221 [00:36<00:25,  3.36it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.75it/s][A
 62%|██████▏   | 138/221 [00:36<00:23,  3.49it/s][A
 63%|██████▎   | 139/221 [00:37<00:28,  2.86it/s][A
 63%|██████▎   | 140/221 [00:37<00:27,  2.97it/s][A
 64%|██████▍   | 141/221 [00:37<00:23,  3.46it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.77it/s][A
 65%|██████▍   | 143/221 [00:38<00:29,  2.64it/s][A
 65%|██████▌   | 144/221 [00:39<00:30,  2.52it/s][A
 66%|██████▌   | 146/221 [00:39<00:18,  4.14it/s][A
 67%|██████▋   | 147/221 [00:39<00:18,  3.96it/s][A
 67%|██████▋   | 148/221 [00:39<00:22,  3.26it/s][A
 67%|██████▋   | 149/221 [00:40<00:22,  3.25it/s][A
 68%|██████▊   | 150/221 [00:40<00:20,  3.39it/s][A
 68%|██████▊   | 151/221 [00:40<00:22,  3.06it/s][A
 69%|██████▉   | 152/221 [00:41<00:34,  1.97it/s][A
 69%|██████▉   | 153/221 [00:41<00:27,  2.43it/s][A
 70%|██████▉   | 154/221 [00:42<00:23,  2.82it/s][A
 70%|███████   | 155/221 [00:42<00:21,  3.10it/s][A
 71%|███████   | 156/221 [00:42<00:21,  2.96it/s][A
 71%|███████   | 157/221 [00:43<00:21,  3.01it/s][A
 71%|███████▏  | 158/221 [00:43<00:20,  3.06it/s][A
 72%|███████▏  | 160/221 [00:43<00:15,  3.88it/s][A
 73%|███████▎  | 161/221 [00:44<00:14,  4.10it/s][A
 73%|███████▎  | 162/221 [00:44<00:13,  4.49it/s][A
 74%|███████▍  | 163/221 [00:44<00:13,  4.34it/s][A
 74%|███████▍  | 164/221 [00:44<00:11,  4.82it/s][A
 75%|███████▍  | 165/221 [00:44<00:11,  4.82it/s][A
 75%|███████▌  | 166/221 [00:45<00:11,  4.74it/s][A
 76%|███████▌  | 167/221 [00:45<00:09,  5.44it/s][A
 76%|███████▌  | 168/221 [00:45<00:10,  5.06it/s][A
 76%|███████▋  | 169/221 [00:45<00:09,  5.27it/s][A
 77%|███████▋  | 170/221 [00:45<00:13,  3.71it/s][A
 77%|███████▋  | 171/221 [00:46<00:13,  3.74it/s][A
 78%|███████▊  | 172/221 [00:46<00:11,  4.09it/s][A
 78%|███████▊  | 173/221 [00:46<00:13,  3.50it/s][A
 79%|███████▊  | 174/221 [00:47<00:17,  2.66it/s][A
 79%|███████▉  | 175/221 [00:47<00:16,  2.75it/s][A
 80%|███████▉  | 176/221 [00:47<00:14,  3.13it/s][A
 80%|████████  | 177/221 [00:48<00:12,  3.57it/s][A
 81%|████████  | 178/221 [00:48<00:12,  3.51it/s][A
 81%|████████  | 179/221 [00:48<00:11,  3.61it/s][A
 81%|████████▏ | 180/221 [00:48<00:09,  4.15it/s][A
 82%|████████▏ | 181/221 [00:49<00:09,  4.38it/s][A
 82%|████████▏ | 182/221 [00:49<00:10,  3.64it/s][A
 83%|████████▎ | 183/221 [00:49<00:10,  3.75it/s][A
 83%|████████▎ | 184/221 [00:49<00:09,  3.88it/s][A
 84%|████████▎ | 185/221 [00:50<00:07,  4.72it/s][A
 84%|████████▍ | 186/221 [00:50<00:09,  3.60it/s][A
 85%|████████▍ | 187/221 [00:50<00:09,  3.56it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.46it/s][A
 86%|████████▌ | 189/221 [00:51<00:09,  3.50it/s][A
 86%|████████▌ | 190/221 [00:51<00:09,  3.26it/s][A
 86%|████████▋ | 191/221 [00:51<00:08,  3.72it/s][A
 87%|████████▋ | 192/221 [00:52<00:08,  3.60it/s][A
 88%|████████▊ | 194/221 [00:52<00:06,  3.88it/s][A
 88%|████████▊ | 195/221 [00:52<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:53<00:09,  2.77it/s][A
 89%|████████▉ | 197/221 [00:53<00:08,  2.99it/s][A
 90%|████████▉ | 198/221 [00:54<00:08,  2.59it/s][A
 90%|█████████ | 199/221 [00:54<00:07,  2.99it/s][A
 90%|█████████ | 200/221 [00:55<00:07,  2.66it/s][A
 91%|█████████ | 201/221 [00:55<00:06,  2.99it/s][A
 91%|█████████▏| 202/221 [00:55<00:06,  2.94it/s][A
 92%|█████████▏| 203/221 [00:55<00:05,  3.24it/s][A
 92%|█████████▏| 204/221 [00:56<00:06,  2.76it/s][A
 93%|█████████▎| 205/221 [00:56<00:04,  3.50it/s][A
 93%|█████████▎| 206/221 [00:56<00:04,  3.18it/s][A
 94%|█████████▎| 207/221 [00:56<00:03,  3.91it/s][A
 94%|█████████▍| 208/221 [00:57<00:03,  3.47it/s][A
 95%|█████████▍| 209/221 [00:57<00:03,  3.60it/s][A
 95%|█████████▌| 211/221 [00:57<00:02,  4.04it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  3.89it/s][A
 96%|█████████▋| 213/221 [00:58<00:01,  4.04it/s][A
 97%|█████████▋| 214/221 [00:58<00:02,  3.15it/s][A
 97%|█████████▋| 215/221 [00:59<00:01,  3.48it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.52it/s][A
 98%|█████████▊| 217/221 [00:59<00:01,  3.34it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.29it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.15it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.58it/s][A
100%|██████████| 221/221 [01:00<00:00,  3.88it/s][A100%|██████████| 221/221 [01:00<00:00,  3.63it/s]
09/09/2024 19:32:01 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 449--===========

09/09/2024 19:32:01 - INFO - __main__ -   {'area_r1': 40.5, 'area_recall': '40.5/66.2/75.3', 'area_ravg': 60.7}
09/09/2024 19:32:01 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 449--===========

09/09/2024 19:32:01 - INFO - __main__ -   {'forward_r1': 36.7, 'forward_recall': '36.7/64.1/75.0', 'forward_ravg': 58.6}
09/09/2024 19:32:01 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 449--===========

09/09/2024 19:32:01 - INFO - __main__ -   {'area_video_r1': 40.4, 'area_video_recall': '40.4/68.2/77.9', 'area_video_ravg': 62.2}
09/09/2024 19:32:01 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/09/2024 19:32:01 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 19:32:01 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 449--===========

09/09/2024 19:32:01 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/09/2024 19:32:01 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/09/2024 19:32:01 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/09/2024 19:32:01 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 449--===========

09/09/2024 19:32:01 - INFO - __main__ -   {'video_r1': 43.0, 'video_recall': '43.0/70.4/81.3', 'video_ravg': 64.9}
09/09/2024 19:32:01 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 19:32:01 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 19:32:01 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 449--===========

09/09/2024 19:32:01 - INFO - __main__ -   {'video_r1': 52.8, 'video_recall': '52.8/75.9/82.4', 'video_ravg': 70.4}
09/09/2024 19:32:01 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/09/2024 19:32:01 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/09/2024 19:32:27 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.009182373993098736, 'loss_ret%tv%ta--finetune_area/loss_area': 1.1417804956436157, 'loss_ret%tv%ta--finetune_area/total_loss': 1.1509628295898438}
 23%|██▎       | 450/1945 [2:27:07<51:14:04, 123.37s/it][h264 @ 0x556b3ba63240] mmco: unref short failure
[h264 @ 0x559bea3c61c0] mmco: unref short failure
[h264 @ 0x559bea3c61c0] mmco: unref short failure
 23%|██▎       | 451/1945 [2:27:11<36:21:09, 87.60s/it] [h264 @ 0x556b321fc200] mmco: unref short failure
[h264 @ 0x559bf13cd440] mmco: unref short failure
[h264 @ 0x556b4001d080] mmco: unref short failure
[h264 @ 0x556b4001d080] mmco: unref short failure
 23%|██▎       | 452/1945 [2:27:16<25:59:24, 62.67s/it][h264 @ 0x56243469ce80] mmco: unref short failure
[h264 @ 0x55a046f35cc0] mmco: unref short failure
[h264 @ 0x55a046f35cc0] mmco: unref short failure
[h264 @ 0x55a04997fdc0] mmco: unref short failure
[h264 @ 0x55a04997fdc0] mmco: unref short failure
[h264 @ 0x556b39634d40] mmco: unref short failure
not have audios 7wavFXW3AFw.7
 23%|██▎       | 453/1945 [2:27:21<18:47:54, 45.36s/it] 23%|██▎       | 454/1945 [2:27:27<13:52:39, 33.51s/it][h264 @ 0x56242f844cc0] mmco: unref short failure
[h264 @ 0x56242f844cc0] mmco: unref short failure
[h264 @ 0x56242f1f70c0] mmco: unref short failure
[h264 @ 0x56242f1f70c0] mmco: unref short failure
 23%|██▎       | 455/1945 [2:27:33<10:29:28, 25.35s/it][h264 @ 0x559c00048c40] mmco: unref short failure
 23%|██▎       | 456/1945 [2:27:40<8:09:18, 19.72s/it]  23%|██▎       | 457/1945 [2:27:47<6:36:34, 15.99s/it][h264 @ 0x55a048d100c0] mmco: unref short failure
[h264 @ 0x55a04da76180] mmco: unref short failure
[h264 @ 0x55a04da76180] mmco: unref short failure
 24%|██▎       | 458/1945 [2:27:55<5:40:34, 13.74s/it][h264 @ 0x55a0390bb040] mmco: unref short failure
[h264 @ 0x55a0390bb040] mmco: unref short failure
[h264 @ 0x56242ef7e140] mmco: unref short failure
[h264 @ 0x556b2f503600] mmco: unref short failure
[h264 @ 0x556b2f503600] mmco: unref short failure
 24%|██▎       | 459/1945 [2:28:02<4:49:47, 11.70s/it][h264 @ 0x55a0345c7b80] mmco: unref short failure
[h264 @ 0x55a0345c7b80] mmco: unref short failure
 24%|██▎       | 460/1945 [2:28:09<4:11:51, 10.18s/it][h264 @ 0x559bf13ead80] mmco: unref short failure
 24%|██▎       | 461/1945 [2:28:18<4:00:22,  9.72s/it] 24%|██▍       | 462/1945 [2:28:25<3:43:11,  9.03s/it][h264 @ 0x56242fc02240] mmco: unref short failure
[h264 @ 0x56242fc02240] mmco: unref short failure
[h264 @ 0x56242fc02240] mmco: unref short failure
[h264 @ 0x56242fc02240] mmco: unref short failure
[h264 @ 0x56242fc02240] mmco: unref short failure
[h264 @ 0x56242fc02240] mmco: unref short failure
[h264 @ 0x556b3383b0c0] mmco: unref short failure
[h264 @ 0x556b3383b0c0] mmco: unref short failure
[h264 @ 0x556b3383b0c0] mmco: unref short failure
[h264 @ 0x559c02dfddc0] mmco: unref short failure
[h264 @ 0x559c02dfddc0] mmco: unref short failure
[h264 @ 0x559c02dfddc0] mmco: unref short failure
[h264 @ 0x559c02dfddc0] mmco: unref short failure
 24%|██▍       | 463/1945 [2:28:33<3:35:06,  8.71s/it][h264 @ 0x55a03a0a5400] mmco: unref short failure
[h264 @ 0x556b41adb440] mmco: unref short failure
[h264 @ 0x556b41adb440] mmco: unref short failure
 24%|██▍       | 464/1945 [2:28:41<3:26:36,  8.37s/it][h264 @ 0x559be984d940] mmco: unref short failure
[h264 @ 0x5624217fe500] mmco: unref short failure
[h264 @ 0x5624217fe500] mmco: unref short failure
[h264 @ 0x556b3566e040] mmco: unref short failure
[h264 @ 0x556b318cc840] mmco: unref short failure
 24%|██▍       | 465/1945 [2:28:48<3:17:12,  7.99s/it][h264 @ 0x556b2f9fc000] mmco: unref short failure
[h264 @ 0x556b2f9fc000] mmco: unref short failure
 24%|██▍       | 466/1945 [2:28:54<3:06:36,  7.57s/it][h264 @ 0x562427c07280] mmco: unref short failure
[h264 @ 0x562427c07280] mmco: unref short failure
 24%|██▍       | 467/1945 [2:29:02<3:05:23,  7.53s/it] 24%|██▍       | 468/1945 [2:29:09<3:02:28,  7.41s/it][h264 @ 0x562428ff6200] mmco: unref short failure
[h264 @ 0x562428ff6200] mmco: unref short failure
[h264 @ 0x562427f3a540] mmco: unref short failure
[h264 @ 0x5624249fd900] mmco: unref short failure
[h264 @ 0x559c00e32480] mmco: unref short failure
[h264 @ 0x56241f042d40] mmco: unref short failure
 24%|██▍       | 469/1945 [2:29:24<4:00:33,  9.78s/it][h264 @ 0x559bffdc4480] mmco: unref short failure
[h264 @ 0x5624256f4dc0] mmco: unref short failure
 24%|██▍       | 470/1945 [2:29:33<3:52:37,  9.46s/it][h264 @ 0x556b433d0740] mmco: unref short failure
 24%|██▍       | 471/1945 [2:29:42<3:49:51,  9.36s/it][h264 @ 0x559c00dbe840] mmco: unref short failure
[h264 @ 0x559c00dbe840] mmco: unref short failure
[h264 @ 0x559c01c9ea40] mmco: unref short failure
 24%|██▍       | 472/1945 [2:29:50<3:42:14,  9.05s/it][h264 @ 0x562421665080] mmco: unref short failure
 24%|██▍       | 473/1945 [2:29:59<3:39:11,  8.93s/it][h264 @ 0x559bf48662c0] mmco: unref short failure
[h264 @ 0x559beb145a80] mmco: unref short failure
[h264 @ 0x559beb145a80] mmco: unref short failure
[h264 @ 0x562425cb3d80] mmco: unref short failure
[h264 @ 0x556b38a1c200] mmco: unref short failure
[h264 @ 0x562425e64380] mmco: unref short failure
[h264 @ 0x556b40db4240] mmco: unref short failure
[h264 @ 0x55a03727f800] mmco: unref short failure
[h264 @ 0x55a03727f800] mmco: unref short failure
 24%|██▍       | 474/1945 [2:30:42<7:49:51, 19.16s/it][h264 @ 0x56242e666f40] mmco: unref short failure
[h264 @ 0x56242e666f40] mmco: unref short failure
[h264 @ 0x56242e666f40] mmco: unref short failure
[h264 @ 0x56242e666f40] mmco: unref short failure
[h264 @ 0x56242a427680] mmco: unref short failure
[h264 @ 0x56242a427680] mmco: unref short failure
[h264 @ 0x556b3a987440] mmco: unref short failure
[h264 @ 0x556b3a987440] mmco: unref short failure
[h264 @ 0x559c00627a80] mmco: unref short failure
[h264 @ 0x559c00627a80] mmco: unref short failure
[h264 @ 0x562433ef6580] mmco: unref short failure
[h264 @ 0x562433ef6580] mmco: unref short failure
 24%|██▍       | 475/1945 [2:31:09<8:46:29, 21.49s/it][h264 @ 0x55a0324ac380] mmco: unref short failure
[h264 @ 0x55a0324ac380] mmco: unref short failure
 24%|██▍       | 476/1945 [2:31:16<7:00:27, 17.17s/it][h264 @ 0x559c01d0aac0] mmco: unref short failure
[h264 @ 0x559c01d0aac0] mmco: unref short failure
[h264 @ 0x5624272b6ec0] mmco: unref short failure
[h264 @ 0x5624272b6ec0] mmco: unref short failure
[h264 @ 0x5624272b6ec0] mmco: unref short failure
[h264 @ 0x5624272b6ec0] mmco: unref short failure
 25%|██▍       | 477/1945 [2:31:35<7:13:14, 17.71s/it][h264 @ 0x556b3f663f40] mmco: unref short failure
[h264 @ 0x56242336c380] mmco: unref short failure
[h264 @ 0x556b3569be40] mmco: unref short failure
[h264 @ 0x556b3569be40] mmco: unref short failure
[h264 @ 0x559bff5b7c80] mmco: unref short failure
[h264 @ 0x559bff5b7c80] mmco: unref short failure
[h264 @ 0x559bff5b7c80] mmco: unref short failure
[h264 @ 0x55a034cbc300] mmco: unref short failure
[h264 @ 0x56242e666f40] mmco: unref short failure
[h264 @ 0x56242e666f40] mmco: unref short failure
 25%|██▍       | 478/1945 [2:31:44<6:05:54, 14.97s/it][h264 @ 0x5624336e0240] mmco: unref short failure
[h264 @ 0x5624336e0240] mmco: unref short failure
[h264 @ 0x5624336e0240] mmco: unref short failure
[h264 @ 0x5624336e0240] mmco: unref short failure
[h264 @ 0x559be8fd3a00] mmco: unref short failure
[h264 @ 0x559be8fd3a00] mmco: unref short failure
[h264 @ 0x556b442a3700] mmco: unref short failure
[h264 @ 0x556b442a3700] mmco: unref short failure
 25%|██▍       | 479/1945 [2:31:50<5:06:17, 12.54s/it][h264 @ 0x562416f9a380] mmco: unref short failure
[h264 @ 0x556b2f4e8f80] mmco: unref short failure
 25%|██▍       | 480/1945 [2:31:59<4:34:29, 11.24s/it][h264 @ 0x559bf1032300] mmco: unref short failure
[h264 @ 0x559bf1032300] mmco: unref short failure
[h264 @ 0x556b40c074c0] mmco: unref short failure
[h264 @ 0x556b40c074c0] mmco: unref short failure
[h264 @ 0x56242c3fc400] mmco: unref short failure
[h264 @ 0x56242c3fc400] mmco: unref short failure
 25%|██▍       | 481/1945 [2:32:06<4:04:33, 10.02s/it][h264 @ 0x559bf38a8980] mmco: unref short failure
[h264 @ 0x559bf38a8980] mmco: unref short failure
[h264 @ 0x559bf38a8980] mmco: unref short failure
[h264 @ 0x559bf38a8980] mmco: unref short failure
[h264 @ 0x556b400a5440] mmco: unref short failure
[h264 @ 0x559bfda74f40] mmco: unref short failure
[h264 @ 0x559bfda74f40] mmco: unref short failure
[h264 @ 0x556b45078440] mmco: unref short failure
[h264 @ 0x556b45078440] mmco: unref short failure
[h264 @ 0x556b3967b8c0] mmco: unref short failure
[h264 @ 0x55a04a3f0f00] mmco: unref short failure
[h264 @ 0x55a04a3f0f00] mmco: unref short failure
[h264 @ 0x55a04c71dc80] mmco: unref short failure
[h264 @ 0x55a04c71dc80] mmco: unref short failure
[h264 @ 0x562434d97d00] mmco: unref short failure
[h264 @ 0x562434d983c0] mmco: unref short failure
[h264 @ 0x562434d983c0] mmco: unref short failure
 25%|██▍       | 482/1945 [2:32:42<7:16:24, 17.90s/it][h264 @ 0x556b3cfe9140] mmco: unref short failure
[h264 @ 0x556b3cfe9140] mmco: unref short failure
[h264 @ 0x559c04597940] mmco: unref short failure
[h264 @ 0x559c04597940] mmco: unref short failure
[h264 @ 0x556b3154b100] mmco: unref short failure
[h264 @ 0x556b31c90e00] mmco: unref short failure
 25%|██▍       | 483/1945 [2:33:06<7:57:34, 19.60s/it][h264 @ 0x562427709500] mmco: unref short failure
[h264 @ 0x562427709500] mmco: unref short failure
[h264 @ 0x559c05f94000] mmco: unref short failure
[h264 @ 0x55a03c681940] mmco: unref short failure
[h264 @ 0x559c04d95bc0] mmco: unref short failure
[h264 @ 0x559c04d95bc0] mmco: unref short failure
 25%|██▍       | 484/1945 [2:33:12<6:21:01, 15.65s/it][h264 @ 0x55a0423286c0] mmco: unref short failure
[h264 @ 0x55a0423286c0] mmco: unref short failure
[h264 @ 0x559bfe17b640] mmco: unref short failure
[h264 @ 0x56242ccccc40] mmco: unref short failure
[h264 @ 0x559c08050900] mmco: unref short failure
[h264 @ 0x562433700440] mmco: unref short failure
[h264 @ 0x562433700440] mmco: unref short failure
[h264 @ 0x556b37ba0c00] mmco: unref short failure
[h264 @ 0x55a03dbb6b80] mmco: unref short failure
[h264 @ 0x55a03dbb6b80] mmco: unref short failure
[h264 @ 0x56242112a3c0] mmco: unref short failure
[h264 @ 0x56242112a3c0] mmco: unref short failure
[h264 @ 0x56242112a3c0] mmco: unref short failure
[h264 @ 0x56242112a3c0] mmco: unref short failure
[h264 @ 0x56242d83f940] mmco: unref short failure
[h264 @ 0x55a03e7db480] mmco: unref short failure
[h264 @ 0x55a03e7db480] mmco: unref short failure
[h264 @ 0x562435cb4880] mmco: unref short failure
[h264 @ 0x562435cb4880] mmco: unref short failure
[h264 @ 0x56241c88b180] mmco: unref short failure
[h264 @ 0x56241c88b180] mmco: unref short failure
[h264 @ 0x55a032611b80] mmco: unref short failure
[h264 @ 0x55a032611b80] mmco: unref short failure
 25%|██▍       | 485/1945 [2:33:32<6:55:11, 17.06s/it][h264 @ 0x55a041e63d00] mmco: unref short failure
[h264 @ 0x55a041e63d00] mmco: unref short failure
 25%|██▍       | 486/1945 [2:33:41<5:51:07, 14.44s/it][h264 @ 0x559bfea67240] mmco: unref short failure
[h264 @ 0x559bfea67240] mmco: unref short failure
[h264 @ 0x562426f69140] mmco: unref short failure
[h264 @ 0x56241f6b2600] mmco: unref short failure
[h264 @ 0x56242e0c7800] mmco: unref short failure
[h264 @ 0x56242e0c7800] mmco: unref short failure
[h264 @ 0x55a038dfeb40] mmco: unref short failure
 25%|██▌       | 487/1945 [2:33:54<5:38:37, 13.93s/it][h264 @ 0x559bef8f0000] mmco: unref short failure
[h264 @ 0x559bef8f0000] mmco: unref short failure
[h264 @ 0x55a037721c40] mmco: unref short failure
[h264 @ 0x55a037721c40] mmco: unref short failure
 25%|██▌       | 488/1945 [2:34:01<4:47:18, 11.83s/it][h264 @ 0x556b3f71b240] mmco: unref short failure
[h264 @ 0x559c00781fc0] mmco: unref short failure
[h264 @ 0x55a042424940] mmco: unref short failure
[h264 @ 0x559bec31c380] mmco: unref short failure
 25%|██▌       | 489/1945 [2:34:12<4:45:24, 11.76s/it][h264 @ 0x559bf2a40940] mmco: unref short failure
[h264 @ 0x556b363b6e80] mmco: unref short failure
[h264 @ 0x556b363b6e80] mmco: unref short failure
[h264 @ 0x55a04e406740] mmco: unref short failure
[h264 @ 0x55a04e406740] mmco: unref short failure
[h264 @ 0x55a03f6bbfc0] mmco: unref short failure
[h264 @ 0x55a03f6bbfc0] mmco: unref short failure
[h264 @ 0x55a03f6bbfc0] mmco: unref short failure
[h264 @ 0x559c00781fc0] mmco: unref short failure
[h264 @ 0x559c00781fc0] mmco: unref short failure
[h264 @ 0x559bf6145a80] mmco: unref short failure
[h264 @ 0x559bf6145a80] mmco: unref short failure
 25%|██▌       | 490/1945 [2:34:43<7:06:47, 17.60s/it][h264 @ 0x56242b363500] mmco: unref short failure
[h264 @ 0x56242b363500] mmco: unref short failure
[h264 @ 0x559c024f6bc0] mmco: unref short failure
[h264 @ 0x559c024f6bc0] mmco: unref short failure
[h264 @ 0x55a03a460600] mmco: unref short failure
[h264 @ 0x55a03a460600] mmco: unref short failure
[h264 @ 0x556b3e78d600] mmco: unref short failure
[h264 @ 0x556b3e78d600] mmco: unref short failure
[h264 @ 0x55a032c48000] mmco: unref short failure
[h264 @ 0x55a042418180] mmco: unref short failure
[h264 @ 0x55a042418180] mmco: unref short failure
[h264 @ 0x556b406f7300] mmco: unref short failure
 25%|██▌       | 491/1945 [2:35:06<7:46:18, 19.24s/it][h264 @ 0x55a04550f680] mmco: unref short failure
[h264 @ 0x556b2d9809c0] mmco: unref short failure
[h264 @ 0x556b2d9809c0] mmco: unref short failure
[h264 @ 0x55a0512220c0] mmco: unref short failure
[h264 @ 0x55a0512220c0] mmco: unref short failure
 25%|██▌       | 492/1945 [2:35:16<6:37:31, 16.42s/it][h264 @ 0x559c0ad46900] mmco: unref short failure
[h264 @ 0x559bf939bf80] mmco: unref short failure
[h264 @ 0x559bf939bf80] mmco: unref short failure
[h264 @ 0x559bf939bf80] mmco: unref short failure
[h264 @ 0x559bf939bf80] mmco: unref short failure
[h264 @ 0x56242993d000] mmco: unref short failure
[h264 @ 0x56242993d000] mmco: unref short failure
[h264 @ 0x562428faf000] mmco: unref short failure
[h264 @ 0x562428faf000] mmco: unref short failure
 25%|██▌       | 493/1945 [2:35:34<6:47:42, 16.85s/it][h264 @ 0x556b4458cb40] mmco: unref short failure
 25%|██▌       | 494/1945 [2:35:43<5:49:36, 14.46s/it][h264 @ 0x55a04991fd40] mmco: unref short failure
 25%|██▌       | 495/1945 [2:35:50<4:54:31, 12.19s/it][h264 @ 0x559bfc2afe40] mmco: unref short failure
[h264 @ 0x559bfc2afe40] mmco: unref short failure
[h264 @ 0x559bfc2afe40] mmco: unref short failure
[h264 @ 0x559bfc2afe40] mmco: unref short failure
[h264 @ 0x56241f709780] mmco: unref short failure
 26%|██▌       | 496/1945 [2:36:03<4:59:28, 12.40s/it][h264 @ 0x56243472ecc0] mmco: unref short failure
[h264 @ 0x556b366e0a40] mmco: unref short failure
[h264 @ 0x556b366e0a40] mmco: unref short failure
[h264 @ 0x556b366e0a40] mmco: unref short failure
[h264 @ 0x556b366e0a40] mmco: unref short failure
 26%|██▌       | 497/1945 [2:36:11<4:28:41, 11.13s/it][h264 @ 0x556b2ca69000] mmco: unref short failure
[h264 @ 0x556b2ca69000] mmco: unref short failure
[h264 @ 0x559c0372af80] mmco: unref short failure
[h264 @ 0x559c0068d3c0] mmco: unref short failure
[h264 @ 0x559c028a31c0] mmco: unref short failure
[h264 @ 0x559c028a31c0] mmco: unref short failure
[h264 @ 0x556b37423e00] mmco: unref short failure
[h264 @ 0x556b3c8d9700] mmco: unref short failure
[h264 @ 0x556b3c8d9700] mmco: unref short failure
[h264 @ 0x556b3c8d9700] mmco: unref short failure
[h264 @ 0x556b3c8d9700] mmco: unref short failure
[h264 @ 0x562417ac1e00] mmco: unref short failure
[h264 @ 0x562417ac1e00] mmco: unref short failure
[h264 @ 0x559c01d0a180] mmco: unref short failure
[h264 @ 0x559c01d0a180] mmco: unref short failure
[h264 @ 0x562431a7f440] mmco: unref short failure
[h264 @ 0x562431a7f440] mmco: unref short failure
[h264 @ 0x562431a7f440] mmco: unref short failure
[h264 @ 0x562431a7f440] mmco: unref short failure
[h264 @ 0x562431a7f440] mmco: unref short failure
[h264 @ 0x562431a7f440] mmco: unref short failure
[h264 @ 0x556b474e0a80] mmco: unref short failure
[h264 @ 0x556b474e0a80] mmco: unref short failure
[h264 @ 0x55a035e48240] mmco: unref short failure
[h264 @ 0x556b2f80fc40] mmco: unref short failure
[h264 @ 0x556b49fe3cc0] mmco: unref short failure
[h264 @ 0x556b492143c0] mmco: unref short failure
 26%|██▌       | 498/1945 [2:36:50<7:53:00, 19.61s/it][h264 @ 0x559c059eb780] mmco: unref short failure
[h264 @ 0x559c059eb780] mmco: unref short failure
[h264 @ 0x556b3e23f900] mmco: unref short failure
[h264 @ 0x556b3e23f900] mmco: unref short failure
[h264 @ 0x56242cefae00] mmco: unref short failure
[h264 @ 0x56242cefae00] mmco: unref short failure
[h264 @ 0x55a035b0f740] mmco: unref short failure
 26%|██▌       | 499/1945 [2:37:09<7:45:38, 19.32s/it]09/09/2024 19:42:31 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 19:42:31 - INFO - __main__ -   start running ret%tv validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x562426e6fbc0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559bf3b18a40] mmco: unref short failure
[h264 @ 0x559bf3b18a40] mmco: unref short failure
[h264 @ 0x56241946ed80] mmco: unref short failure
[h264 @ 0x556b49fe3ec0] mmco: unref short failure
[h264 @ 0x556b49fe3ec0] mmco: unref short failure
[h264 @ 0x559bfd5fe840] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a03900d8c0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x562426034d00] mmco: unref short failure
[h264 @ 0x562426034d00] mmco: unref short failure
[h264 @ 0x559bf8c00c00] mmco: unref short failure
[h264 @ 0x559bf8c00c00] mmco: unref short failure
[h264 @ 0x559bf8c00c00] mmco: unref short failure
[h264 @ 0x56242b2d7140] mmco: unref short failure
[h264 @ 0x56242b2d7140] mmco: unref short failure
[h264 @ 0x556b45002840] mmco: unref short failure
[h264 @ 0x562421b80580] mmco: unref short failure
[h264 @ 0x556b3b348840] mmco: unref short failure
[h264 @ 0x56242c1b3f80] mmco: unref short failure
[h264 @ 0x56242c1b3f80] mmco: unref short failure
[h264 @ 0x562425dd45c0] mmco: unref short failure
[h264 @ 0x562425dd45c0] mmco: unref short failure
[h264 @ 0x556b312dea40] mmco: unref short failure
[h264 @ 0x562431eeae80] mmco: unref short failure
[h264 @ 0x559bfa446f00] mmco: unref short failure
[h264 @ 0x56241d775d00] mmco: unref short failure
[h264 @ 0x56241d775d00] mmco: unref short failure
[h264 @ 0x559c03f6de40] mmco: unref short failure
[h264 @ 0x559c0377f540] mmco: unref short failure
[h264 @ 0x556b4a5a6b00] mmco: unref short failure
[h264 @ 0x5624207e7100] mmco: unref short failure
[h264 @ 0x559c04b24c80] mmco: unref short failure
[h264 @ 0x559c04b24c80] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:28,  2.49it/s][A[h264 @ 0x559bef945c00] mmco: unref short failure

  1%|          | 2/221 [00:01<01:58,  1.84it/s][A
  1%|▏         | 3/221 [00:01<01:18,  2.76it/s][A
  2%|▏         | 4/221 [00:01<01:10,  3.08it/s][A
  2%|▏         | 5/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:53,  3.99it/s][A
  3%|▎         | 7/221 [00:02<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<01:13,  2.91it/s][A
  4%|▍         | 9/221 [00:02<01:09,  3.04it/s][A
  5%|▍         | 10/221 [00:03<01:13,  2.87it/s][A
  5%|▍         | 11/221 [00:03<00:59,  3.54it/s][A
  5%|▌         | 12/221 [00:03<01:07,  3.10it/s][A
  6%|▌         | 13/221 [00:04<01:03,  3.27it/s][A
  6%|▋         | 14/221 [00:04<01:30,  2.28it/s][A
  7%|▋         | 15/221 [00:05<01:21,  2.51it/s][A
  7%|▋         | 16/221 [00:05<01:18,  2.60it/s][A
  8%|▊         | 17/221 [00:06<01:40,  2.03it/s][A
  8%|▊         | 18/221 [00:06<01:38,  2.06it/s][A
  9%|▊         | 19/221 [00:07<01:27,  2.30it/s][A
  9%|▉         | 20/221 [00:07<01:13,  2.73it/s][A
 10%|▉         | 21/221 [00:07<01:05,  3.05it/s][A
 10%|▉         | 22/221 [00:07<00:57,  3.44it/s][A
 10%|█         | 23/221 [00:07<00:48,  4.10it/s][A
 11%|█         | 24/221 [00:08<00:41,  4.69it/s][A
 11%|█▏        | 25/221 [00:08<00:47,  4.11it/s][A
 12%|█▏        | 26/221 [00:08<01:06,  2.93it/s][A[h264 @ 0x56243096cec0] mmco: unref short failure
[h264 @ 0x56243096cec0] mmco: unref short failure

 12%|█▏        | 27/221 [00:09<01:02,  3.12it/s][A
 13%|█▎        | 28/221 [00:09<01:22,  2.35it/s][A[h264 @ 0x56241c58ee80] mmco: unref short failure

 13%|█▎        | 29/221 [00:10<01:44,  1.84it/s][A
 14%|█▎        | 30/221 [00:10<01:32,  2.08it/s][A
 14%|█▍        | 31/221 [00:11<01:23,  2.28it/s][A
 14%|█▍        | 32/221 [00:11<01:11,  2.63it/s][A
 15%|█▍        | 33/221 [00:11<01:08,  2.73it/s][A
 15%|█▌        | 34/221 [00:12<01:10,  2.66it/s][A
 16%|█▌        | 35/221 [00:12<01:04,  2.88it/s][A
 16%|█▋        | 36/221 [00:12<01:00,  3.08it/s][A
 17%|█▋        | 37/221 [00:13<01:15,  2.43it/s][A[h264 @ 0x556b481fcb40] mmco: unref short failure
[h264 @ 0x556b481fcb40] mmco: unref short failure

 17%|█▋        | 38/221 [00:13<01:15,  2.44it/s][A
 18%|█▊        | 39/221 [00:14<01:07,  2.69it/s][A
 18%|█▊        | 40/221 [00:14<01:05,  2.77it/s][A
 19%|█▊        | 41/221 [00:14<00:54,  3.27it/s][A
 19%|█▉        | 42/221 [00:15<00:59,  3.02it/s][A
 19%|█▉        | 43/221 [00:15<00:53,  3.35it/s][A
 20%|█▉        | 44/221 [00:15<00:45,  3.88it/s][A
 20%|██        | 45/221 [00:16<01:26,  2.03it/s][A
 21%|██        | 46/221 [00:16<01:19,  2.20it/s][A
 21%|██▏       | 47/221 [00:17<01:20,  2.16it/s][A
 22%|██▏       | 48/221 [00:17<01:03,  2.70it/s][A
 22%|██▏       | 49/221 [00:18<01:25,  2.01it/s][A
 23%|██▎       | 50/221 [00:18<01:23,  2.05it/s][A
 23%|██▎       | 51/221 [00:18<01:06,  2.54it/s][A
 24%|██▎       | 52/221 [00:19<01:01,  2.75it/s][A
 24%|██▍       | 53/221 [00:19<00:50,  3.32it/s][A
 24%|██▍       | 54/221 [00:20<01:51,  1.50it/s][A
 25%|██▍       | 55/221 [00:21<01:32,  1.79it/s][A
 25%|██▌       | 56/221 [00:21<01:14,  2.21it/s][A
 26%|██▌       | 57/221 [00:21<00:59,  2.76it/s][A
 26%|██▌       | 58/221 [00:21<00:49,  3.32it/s][A
 27%|██▋       | 59/221 [00:21<00:45,  3.55it/s][A
 27%|██▋       | 60/221 [00:22<00:58,  2.75it/s][A
 28%|██▊       | 61/221 [00:22<00:49,  3.23it/s][A[h264 @ 0x559c089dc7c0] mmco: unref short failure
[h264 @ 0x559c089dc7c0] mmco: unref short failure

 28%|██▊       | 62/221 [00:23<00:51,  3.10it/s][A
 29%|██▊       | 63/221 [00:23<00:46,  3.40it/s][A
 29%|██▉       | 64/221 [00:23<00:39,  4.02it/s][A
 29%|██▉       | 65/221 [00:23<00:41,  3.75it/s][A
 30%|██▉       | 66/221 [00:24<00:52,  2.95it/s][A
 30%|███       | 67/221 [00:24<00:59,  2.58it/s][A
 31%|███       | 68/221 [00:25<00:53,  2.84it/s][A[h264 @ 0x55a04577c440] mmco: unref short failure

 31%|███       | 69/221 [00:25<01:05,  2.31it/s][A
 32%|███▏      | 70/221 [00:25<00:56,  2.69it/s][A
 32%|███▏      | 71/221 [00:26<01:16,  1.97it/s][A
 33%|███▎      | 72/221 [00:27<01:07,  2.21it/s][A[h264 @ 0x55a0331d2bc0] mmco: unref short failure

 33%|███▎      | 73/221 [00:27<01:06,  2.21it/s][A
 33%|███▎      | 74/221 [00:27<00:57,  2.54it/s][A
 34%|███▍      | 75/221 [00:28<01:00,  2.43it/s][A
 34%|███▍      | 76/221 [00:28<00:53,  2.69it/s][A
 35%|███▍      | 77/221 [00:29<00:59,  2.43it/s][A
 35%|███▌      | 78/221 [00:29<00:59,  2.42it/s][A
 36%|███▌      | 79/221 [00:29<01:04,  2.21it/s][A
 36%|███▌      | 80/221 [00:30<00:52,  2.68it/s][A
 37%|███▋      | 81/221 [00:30<00:50,  2.76it/s][A
 37%|███▋      | 82/221 [00:31<01:18,  1.76it/s][A
 38%|███▊      | 83/221 [00:31<01:13,  1.89it/s][A
 38%|███▊      | 84/221 [00:32<00:58,  2.32it/s][A
 38%|███▊      | 85/221 [00:32<00:46,  2.91it/s][A
 39%|███▉      | 86/221 [00:32<00:45,  2.99it/s][A
 39%|███▉      | 87/221 [00:33<00:51,  2.58it/s][A
 40%|███▉      | 88/221 [00:33<00:48,  2.74it/s][A[h264 @ 0x556b400b6240] mmco: unref short failure

 40%|████      | 89/221 [00:34<01:03,  2.08it/s][A
 41%|████      | 90/221 [00:34<00:52,  2.47it/s][A
 41%|████      | 91/221 [00:34<00:42,  3.08it/s][A
 42%|████▏     | 92/221 [00:34<00:37,  3.45it/s][A
 42%|████▏     | 93/221 [00:35<00:40,  3.12it/s][A[h264 @ 0x556b318cb040] mmco: unref short failure

 43%|████▎     | 94/221 [00:35<00:35,  3.56it/s][A
 43%|████▎     | 95/221 [00:35<00:33,  3.73it/s][A
 43%|████▎     | 96/221 [00:35<00:29,  4.20it/s][A
 44%|████▍     | 97/221 [00:35<00:26,  4.62it/s][A
 44%|████▍     | 98/221 [00:36<00:27,  4.48it/s][A
 45%|████▍     | 99/221 [00:36<00:25,  4.78it/s][A
 45%|████▌     | 100/221 [00:36<00:23,  5.19it/s][A
 46%|████▌     | 101/221 [00:36<00:21,  5.65it/s][A
 46%|████▌     | 102/221 [00:36<00:27,  4.26it/s][A
 47%|████▋     | 103/221 [00:37<00:24,  4.80it/s][A
 47%|████▋     | 104/221 [00:37<00:21,  5.51it/s][A
 48%|████▊     | 105/221 [00:37<00:22,  5.07it/s][A[h264 @ 0x559bff8a6f40] mmco: unref short failure
[h264 @ 0x559bff8a6f40] mmco: unref short failure

 48%|████▊     | 106/221 [00:38<00:40,  2.85it/s][A
 48%|████▊     | 107/221 [00:38<00:32,  3.48it/s][A
 49%|████▉     | 108/221 [00:38<00:28,  4.02it/s][A
 49%|████▉     | 109/221 [00:38<00:28,  3.90it/s][A
 50%|████▉     | 110/221 [00:38<00:27,  4.00it/s][A
 50%|█████     | 111/221 [00:39<00:31,  3.50it/s][A
 51%|█████     | 112/221 [00:39<00:28,  3.83it/s][A
 51%|█████     | 113/221 [00:39<00:31,  3.43it/s][A
 52%|█████▏    | 115/221 [00:40<00:20,  5.07it/s][A
 52%|█████▏    | 116/221 [00:43<01:32,  1.13it/s][A
 53%|█████▎    | 117/221 [00:43<01:16,  1.36it/s][A
 53%|█████▎    | 118/221 [00:43<01:04,  1.60it/s][A
 54%|█████▍    | 119/221 [00:43<00:53,  1.92it/s][A
 54%|█████▍    | 120/221 [00:44<00:47,  2.15it/s][A
 55%|█████▍    | 121/221 [00:44<00:36,  2.72it/s][A
 55%|█████▌    | 122/221 [00:44<00:30,  3.24it/s][A
 56%|█████▌    | 123/221 [00:44<00:24,  3.96it/s][A
 56%|█████▌    | 124/221 [00:44<00:23,  4.16it/s][A
 57%|█████▋    | 125/221 [00:45<00:25,  3.69it/s][A
 57%|█████▋    | 126/221 [00:45<00:23,  3.97it/s][A
 57%|█████▋    | 127/221 [00:45<00:30,  3.08it/s][A
 58%|█████▊    | 128/221 [00:46<00:29,  3.11it/s][A
 58%|█████▊    | 129/221 [00:46<00:24,  3.68it/s][A
 59%|█████▉    | 130/221 [00:46<00:23,  3.86it/s][A
 59%|█████▉    | 131/221 [00:46<00:19,  4.61it/s][A
 60%|█████▉    | 132/221 [00:46<00:17,  5.00it/s][A[h264 @ 0x55a04b245100] mmco: unref short failure
[h264 @ 0x55a04b245100] mmco: unref short failure

 60%|██████    | 133/221 [00:47<00:22,  3.96it/s][A
 61%|██████    | 134/221 [00:47<00:21,  3.96it/s][A
 61%|██████    | 135/221 [00:47<00:20,  4.12it/s][A
 62%|██████▏   | 136/221 [00:48<00:23,  3.57it/s][A
 62%|██████▏   | 137/221 [00:48<00:20,  4.14it/s][A
 62%|██████▏   | 138/221 [00:48<00:22,  3.68it/s][A
 63%|██████▎   | 139/221 [00:49<00:25,  3.25it/s][A
 63%|██████▎   | 140/221 [00:49<00:24,  3.31it/s][A
 64%|██████▍   | 141/221 [00:49<00:21,  3.78it/s][A
 64%|██████▍   | 142/221 [00:49<00:21,  3.75it/s][A
 65%|██████▍   | 143/221 [00:50<00:23,  3.28it/s][A
 65%|██████▌   | 144/221 [00:50<00:22,  3.46it/s][A
 66%|██████▌   | 145/221 [00:50<00:17,  4.31it/s][A
 66%|██████▌   | 146/221 [00:50<00:17,  4.26it/s][A
 67%|██████▋   | 147/221 [00:50<00:17,  4.24it/s][A
 67%|██████▋   | 148/221 [00:51<00:19,  3.74it/s][A
 67%|██████▋   | 149/221 [00:51<00:15,  4.59it/s][A
 68%|██████▊   | 150/221 [00:51<00:15,  4.71it/s][A
 68%|██████▊   | 151/221 [00:52<00:27,  2.52it/s][A
 69%|██████▉   | 152/221 [00:53<00:44,  1.55it/s][A
 69%|██████▉   | 153/221 [00:54<00:37,  1.80it/s][A
 70%|██████▉   | 154/221 [00:54<00:32,  2.04it/s][A
 70%|███████   | 155/221 [00:54<00:26,  2.53it/s][A
 71%|███████   | 156/221 [00:54<00:21,  3.03it/s][A
 71%|███████   | 157/221 [00:55<00:33,  1.92it/s][A
 71%|███████▏  | 158/221 [00:55<00:26,  2.36it/s][A
 72%|███████▏  | 159/221 [00:56<00:21,  2.84it/s][A
 72%|███████▏  | 160/221 [00:56<00:21,  2.88it/s][A
 73%|███████▎  | 161/221 [00:56<00:19,  3.12it/s][A
 73%|███████▎  | 162/221 [00:57<00:25,  2.34it/s][A
 74%|███████▍  | 163/221 [00:57<00:21,  2.73it/s][A
 74%|███████▍  | 164/221 [00:58<00:26,  2.15it/s][A
 75%|███████▍  | 165/221 [00:58<00:20,  2.79it/s][A
 75%|███████▌  | 166/221 [00:58<00:19,  2.79it/s][A
 76%|███████▌  | 167/221 [00:58<00:16,  3.26it/s][A
 76%|███████▌  | 168/221 [00:59<00:23,  2.30it/s][A
 76%|███████▋  | 169/221 [00:59<00:18,  2.79it/s][A
 77%|███████▋  | 170/221 [01:00<00:17,  2.89it/s][A
 77%|███████▋  | 171/221 [01:00<00:16,  3.05it/s][A
 78%|███████▊  | 172/221 [01:00<00:14,  3.45it/s][A
 78%|███████▊  | 173/221 [01:00<00:11,  4.28it/s][A
 79%|███████▊  | 174/221 [01:00<00:11,  4.21it/s][A
 79%|███████▉  | 175/221 [01:01<00:14,  3.21it/s][A
 80%|███████▉  | 176/221 [01:01<00:13,  3.33it/s][A
 80%|████████  | 177/221 [01:01<00:10,  4.05it/s][A
 81%|████████  | 178/221 [01:02<00:10,  4.25it/s][A
 81%|████████  | 179/221 [01:02<00:11,  3.76it/s][A
 82%|████████▏ | 181/221 [01:02<00:07,  5.02it/s][A
 82%|████████▏ | 182/221 [01:02<00:07,  5.00it/s][A
 83%|████████▎ | 183/221 [01:03<00:07,  5.17it/s][A
 83%|████████▎ | 184/221 [01:03<00:07,  4.80it/s][A
 84%|████████▍ | 186/221 [01:03<00:07,  4.61it/s][A
 85%|████████▍ | 187/221 [01:03<00:06,  5.09it/s][A
 85%|████████▌ | 188/221 [01:04<00:06,  5.19it/s][A
 86%|████████▌ | 189/221 [01:04<00:07,  4.49it/s][A[h264 @ 0x556b3d89a140] mmco: unref short failure

 86%|████████▌ | 190/221 [01:04<00:07,  3.91it/s][A
 87%|████████▋ | 192/221 [01:04<00:05,  4.93it/s][A
 88%|████████▊ | 194/221 [01:05<00:06,  4.15it/s][A
 88%|████████▊ | 195/221 [01:05<00:05,  4.36it/s][A
 89%|████████▊ | 196/221 [01:06<00:07,  3.17it/s][A
 90%|████████▉ | 198/221 [01:06<00:06,  3.72it/s][A
 90%|█████████ | 199/221 [01:06<00:05,  4.24it/s][A
 90%|█████████ | 200/221 [01:07<00:05,  3.91it/s][A
 91%|█████████ | 201/221 [01:07<00:04,  4.14it/s][A
 91%|█████████▏| 202/221 [01:07<00:04,  4.25it/s][A
 92%|█████████▏| 203/221 [01:07<00:03,  4.82it/s][A
 92%|█████████▏| 204/221 [01:08<00:03,  4.29it/s][A
 93%|█████████▎| 205/221 [01:08<00:03,  5.07it/s][A
 93%|█████████▎| 206/221 [01:08<00:04,  3.71it/s][A
 94%|█████████▎| 207/221 [01:08<00:03,  4.23it/s][A
 94%|█████████▍| 208/221 [01:08<00:02,  4.90it/s][A
 95%|█████████▍| 209/221 [01:09<00:02,  4.81it/s][A
 95%|█████████▌| 211/221 [01:09<00:01,  5.12it/s][A
 96%|█████████▌| 212/221 [01:09<00:01,  5.57it/s][A
 96%|█████████▋| 213/221 [01:09<00:01,  5.12it/s][A
 97%|█████████▋| 214/221 [01:10<00:01,  4.97it/s][A
 97%|█████████▋| 215/221 [01:10<00:01,  4.90it/s][A
 98%|█████████▊| 216/221 [01:10<00:01,  4.33it/s][A
 98%|█████████▊| 217/221 [01:10<00:01,  3.82it/s][A
 99%|█████████▊| 218/221 [01:11<00:00,  3.84it/s][A
 99%|█████████▉| 219/221 [01:11<00:00,  4.04it/s][A
100%|█████████▉| 220/221 [01:14<00:01,  1.10s/it][A
100%|██████████| 221/221 [01:14<00:00,  1.22it/s][A100%|██████████| 221/221 [01:14<00:00,  2.96it/s]
[h264 @ 0x559be9d7a800] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.78it/s][A
  1%|          | 2/221 [00:00<00:58,  3.76it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.77it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.75it/s][A
  2%|▏         | 5/221 [00:01<00:57,  3.76it/s][A
  3%|▎         | 6/221 [00:01<00:57,  3.76it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.76it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.76it/s][A
  4%|▍         | 9/221 [00:02<00:56,  3.77it/s][A
  5%|▍         | 10/221 [00:02<00:56,  3.77it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.77it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.77it/s][A
  6%|▌         | 13/221 [00:03<00:55,  3.78it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.78it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.78it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.78it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:51,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:14<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:46,  3.51it/s][A
 26%|██▌       | 58/221 [00:15<00:45,  3.59it/s][A
 27%|██▋       | 59/221 [00:15<00:44,  3.65it/s][A
 27%|██▋       | 60/221 [00:15<00:43,  3.69it/s][A
 28%|██▊       | 61/221 [00:16<00:43,  3.72it/s][A
 28%|██▊       | 62/221 [00:16<00:42,  3.74it/s][A
 29%|██▊       | 63/221 [00:16<00:42,  3.76it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.77it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.77it/s][A
 30%|██▉       | 66/221 [00:17<00:41,  3.78it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.78it/s][A
 31%|███       | 68/221 [00:18<00:40,  3.78it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:23<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:28<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:32<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:42<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:47<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:52<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:56<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:57<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.78it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:26,  8.15it/s][A
  1%|          | 2/221 [00:00<00:50,  4.36it/s][A
  1%|▏         | 3/221 [00:00<00:55,  3.93it/s][A
  2%|▏         | 4/221 [00:00<00:48,  4.49it/s][A
  2%|▏         | 5/221 [00:01<00:46,  4.67it/s][A
  3%|▎         | 7/221 [00:01<00:42,  5.08it/s][A
  4%|▎         | 8/221 [00:01<00:47,  4.44it/s][A
  4%|▍         | 9/221 [00:01<00:48,  4.41it/s][A
  5%|▍         | 10/221 [00:02<01:06,  3.16it/s][A
  5%|▍         | 11/221 [00:02<01:00,  3.48it/s][A
  5%|▌         | 12/221 [00:02<00:51,  4.02it/s][A
  6%|▌         | 13/221 [00:03<01:26,  2.41it/s][A
  7%|▋         | 15/221 [00:03<00:59,  3.49it/s][A
  7%|▋         | 16/221 [00:04<01:07,  3.05it/s][A
  8%|▊         | 17/221 [00:05<01:26,  2.37it/s][A
  8%|▊         | 18/221 [00:05<01:14,  2.72it/s][A
  9%|▊         | 19/221 [00:05<01:06,  3.03it/s][A
  9%|▉         | 20/221 [00:05<00:54,  3.68it/s][A
 10%|▉         | 21/221 [00:05<00:47,  4.19it/s][A
 10%|▉         | 22/221 [00:06<00:44,  4.48it/s][A
 11%|█         | 24/221 [00:06<00:34,  5.64it/s][A
 11%|█▏        | 25/221 [00:06<00:37,  5.28it/s][A
 12%|█▏        | 26/221 [00:06<00:39,  4.90it/s][A
 12%|█▏        | 27/221 [00:06<00:35,  5.39it/s][A
 13%|█▎        | 28/221 [00:07<00:49,  3.87it/s][A
 13%|█▎        | 29/221 [00:07<00:43,  4.37it/s][A
 14%|█▎        | 30/221 [00:07<00:45,  4.19it/s][A
 14%|█▍        | 31/221 [00:07<00:41,  4.54it/s][A
 15%|█▍        | 33/221 [00:08<00:32,  5.73it/s][A
 15%|█▌        | 34/221 [00:08<00:31,  5.95it/s][A
 16%|█▌        | 35/221 [00:08<00:35,  5.18it/s][A
 16%|█▋        | 36/221 [00:08<00:40,  4.53it/s][A
 17%|█▋        | 37/221 [00:09<00:40,  4.56it/s][A
 17%|█▋        | 38/221 [00:09<00:44,  4.13it/s][A
 18%|█▊        | 39/221 [00:09<00:39,  4.56it/s][A
 18%|█▊        | 40/221 [00:09<00:48,  3.70it/s][A
 19%|█▊        | 41/221 [00:10<00:40,  4.41it/s][A
 19%|█▉        | 42/221 [00:10<00:41,  4.28it/s][A
 19%|█▉        | 43/221 [00:10<00:45,  3.91it/s][A
 20%|█▉        | 44/221 [00:10<00:42,  4.14it/s][A
 20%|██        | 45/221 [00:11<00:41,  4.22it/s][A
 21%|██        | 46/221 [00:11<00:37,  4.66it/s][A
 21%|██▏       | 47/221 [00:11<00:37,  4.66it/s][A
 22%|██▏       | 48/221 [00:11<00:33,  5.13it/s][A
 22%|██▏       | 49/221 [00:11<00:36,  4.75it/s][A
 23%|██▎       | 50/221 [00:12<00:41,  4.07it/s][A
 23%|██▎       | 51/221 [00:12<00:39,  4.32it/s][A
 24%|██▎       | 52/221 [00:12<00:37,  4.49it/s][A
 24%|██▍       | 53/221 [00:12<00:32,  5.16it/s][A
 24%|██▍       | 54/221 [00:13<00:52,  3.18it/s][A
 25%|██▍       | 55/221 [00:13<00:47,  3.49it/s][A
 25%|██▌       | 56/221 [00:13<00:39,  4.18it/s][A
 26%|██▌       | 57/221 [00:13<00:39,  4.18it/s][A
 26%|██▌       | 58/221 [00:14<00:39,  4.12it/s][A
 27%|██▋       | 59/221 [00:14<00:37,  4.36it/s][A
 27%|██▋       | 60/221 [00:14<00:38,  4.19it/s][A
 28%|██▊       | 61/221 [00:14<00:34,  4.58it/s][A
 28%|██▊       | 62/221 [00:15<00:36,  4.41it/s][A
 29%|██▊       | 63/221 [00:15<00:35,  4.48it/s][A
 29%|██▉       | 64/221 [00:15<00:46,  3.40it/s][A
 29%|██▉       | 65/221 [00:15<00:37,  4.18it/s][A
 30%|██▉       | 66/221 [00:16<00:46,  3.32it/s][A
 30%|███       | 67/221 [00:16<00:54,  2.83it/s][A
 31%|███       | 68/221 [00:16<00:45,  3.37it/s][A
 31%|███       | 69/221 [00:17<00:58,  2.60it/s][A
 32%|███▏      | 70/221 [00:17<00:46,  3.28it/s][A
 32%|███▏      | 71/221 [00:17<00:42,  3.51it/s][A
 33%|███▎      | 72/221 [00:18<00:49,  3.00it/s][A
 33%|███▎      | 73/221 [00:18<00:49,  3.00it/s][A
 33%|███▎      | 74/221 [00:18<00:39,  3.73it/s][A
 34%|███▍      | 75/221 [00:18<00:38,  3.78it/s][A
 34%|███▍      | 76/221 [00:19<00:35,  4.03it/s][A
 35%|███▍      | 77/221 [00:19<00:34,  4.12it/s][A
 35%|███▌      | 78/221 [00:19<00:31,  4.55it/s][A
 36%|███▌      | 79/221 [00:20<00:45,  3.10it/s][A
 36%|███▌      | 80/221 [00:20<00:39,  3.55it/s][A
 37%|███▋      | 81/221 [00:20<00:36,  3.86it/s][A
 37%|███▋      | 82/221 [00:20<00:36,  3.84it/s][A
 38%|███▊      | 83/221 [00:21<00:39,  3.53it/s][A
 38%|███▊      | 84/221 [00:21<00:36,  3.76it/s][A
 39%|███▉      | 86/221 [00:21<00:32,  4.16it/s][A
 39%|███▉      | 87/221 [00:22<00:45,  2.93it/s][A
 40%|███▉      | 88/221 [00:22<00:50,  2.63it/s][A
 40%|████      | 89/221 [00:23<00:46,  2.83it/s][A
 41%|████      | 90/221 [00:23<00:45,  2.91it/s][A
 41%|████      | 91/221 [00:23<00:36,  3.52it/s][A
 42%|████▏     | 92/221 [00:23<00:37,  3.46it/s][A
 42%|████▏     | 93/221 [00:24<00:56,  2.27it/s][A
 43%|████▎     | 94/221 [00:25<00:50,  2.52it/s][A
 43%|████▎     | 95/221 [00:25<00:43,  2.89it/s][A
 43%|████▎     | 96/221 [00:25<00:38,  3.27it/s][A
 44%|████▍     | 97/221 [00:25<00:33,  3.69it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.83it/s][A
 45%|████▍     | 99/221 [00:26<00:28,  4.29it/s][A
 45%|████▌     | 100/221 [00:26<00:27,  4.42it/s][A
 46%|████▌     | 101/221 [00:26<00:30,  3.94it/s][A
 46%|████▌     | 102/221 [00:27<00:43,  2.76it/s][A
 47%|████▋     | 103/221 [00:27<00:34,  3.44it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.80it/s][A
 48%|████▊     | 105/221 [00:27<00:28,  4.02it/s][A
 48%|████▊     | 106/221 [00:28<00:39,  2.94it/s][A
 48%|████▊     | 107/221 [00:28<00:35,  3.18it/s][A
 49%|████▉     | 108/221 [00:28<00:32,  3.51it/s][A
 49%|████▉     | 109/221 [00:28<00:26,  4.17it/s][A
 50%|████▉     | 110/221 [00:29<00:25,  4.30it/s][A
 50%|█████     | 111/221 [00:29<00:27,  3.98it/s][A
 51%|█████     | 112/221 [00:29<00:27,  3.92it/s][A
 51%|█████     | 113/221 [00:29<00:26,  4.11it/s][A
 52%|█████▏    | 115/221 [00:30<00:21,  4.88it/s][A
 52%|█████▏    | 116/221 [00:30<00:23,  4.56it/s][A
 53%|█████▎    | 117/221 [00:30<00:24,  4.23it/s][A
 53%|█████▎    | 118/221 [00:31<00:23,  4.31it/s][A
 54%|█████▍    | 119/221 [00:31<00:31,  3.28it/s][A
 54%|█████▍    | 120/221 [00:31<00:27,  3.63it/s][A
 55%|█████▍    | 121/221 [00:31<00:22,  4.35it/s][A
 55%|█████▌    | 122/221 [00:32<00:24,  4.07it/s][A
 56%|█████▌    | 123/221 [00:32<00:23,  4.11it/s][A
 56%|█████▌    | 124/221 [00:32<00:26,  3.71it/s][A
 57%|█████▋    | 125/221 [00:33<00:27,  3.44it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.75it/s][A
 57%|█████▋    | 127/221 [00:33<00:30,  3.13it/s][A
 58%|█████▊    | 128/221 [00:33<00:27,  3.40it/s][A
 58%|█████▊    | 129/221 [00:34<00:21,  4.19it/s][A
 59%|█████▉    | 130/221 [00:34<00:22,  4.06it/s][A
 60%|█████▉    | 132/221 [00:34<00:21,  4.13it/s][A
 60%|██████    | 133/221 [00:35<00:21,  4.06it/s][A
 61%|██████    | 134/221 [00:35<00:24,  3.62it/s][A
 61%|██████    | 135/221 [00:35<00:27,  3.14it/s][A
 62%|██████▏   | 136/221 [00:36<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.82it/s][A
 62%|██████▏   | 138/221 [00:36<00:23,  3.53it/s][A
 63%|██████▎   | 139/221 [00:37<00:30,  2.72it/s][A
 63%|██████▎   | 140/221 [00:37<00:27,  2.90it/s][A
 64%|██████▍   | 141/221 [00:37<00:23,  3.35it/s][A
 64%|██████▍   | 142/221 [00:37<00:21,  3.68it/s][A
 65%|██████▍   | 143/221 [00:38<00:30,  2.55it/s][A
 65%|██████▌   | 144/221 [00:38<00:31,  2.43it/s][A
 66%|██████▌   | 146/221 [00:39<00:18,  4.02it/s][A
 67%|██████▋   | 147/221 [00:39<00:18,  3.91it/s][A
 67%|██████▋   | 148/221 [00:39<00:21,  3.34it/s][A
 67%|██████▋   | 149/221 [00:40<00:21,  3.39it/s][A
 68%|██████▊   | 150/221 [00:40<00:20,  3.44it/s][A
 68%|██████▊   | 151/221 [00:40<00:22,  3.16it/s][A
 69%|██████▉   | 152/221 [00:41<00:35,  1.95it/s][A
 69%|██████▉   | 153/221 [00:41<00:27,  2.44it/s][A
 70%|██████▉   | 154/221 [00:42<00:23,  2.80it/s][A
 70%|███████   | 155/221 [00:42<00:21,  3.04it/s][A
 71%|███████   | 156/221 [00:42<00:23,  2.78it/s][A
 71%|███████   | 157/221 [00:43<00:22,  2.89it/s][A
 71%|███████▏  | 158/221 [00:43<00:21,  2.93it/s][A
 72%|███████▏  | 159/221 [00:43<00:16,  3.71it/s][A
 72%|███████▏  | 160/221 [00:43<00:16,  3.74it/s][A
 73%|███████▎  | 161/221 [00:44<00:15,  3.97it/s][A
 73%|███████▎  | 162/221 [00:44<00:13,  4.37it/s][A
 74%|███████▍  | 163/221 [00:44<00:13,  4.25it/s][A
 74%|███████▍  | 164/221 [00:44<00:11,  4.96it/s][A
 75%|███████▍  | 165/221 [00:44<00:10,  5.16it/s][A
 75%|███████▌  | 166/221 [00:44<00:11,  4.96it/s][A
 76%|███████▌  | 167/221 [00:45<00:09,  5.59it/s][A
 76%|███████▌  | 168/221 [00:45<00:10,  5.23it/s][A
 76%|███████▋  | 169/221 [00:45<00:09,  5.33it/s][A
 77%|███████▋  | 170/221 [00:46<00:15,  3.29it/s][A
 77%|███████▋  | 171/221 [00:46<00:14,  3.44it/s][A
 78%|███████▊  | 172/221 [00:46<00:12,  3.85it/s][A
 78%|███████▊  | 173/221 [00:46<00:14,  3.38it/s][A
 79%|███████▊  | 174/221 [00:47<00:18,  2.60it/s][A
 79%|███████▉  | 175/221 [00:47<00:17,  2.64it/s][A
 80%|███████▉  | 176/221 [00:48<00:15,  2.97it/s][A
 80%|████████  | 177/221 [00:48<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:48<00:11,  3.69it/s][A
 81%|████████  | 179/221 [00:48<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:48<00:09,  4.50it/s][A
 82%|████████▏ | 181/221 [00:49<00:08,  4.52it/s][A
 82%|████████▏ | 182/221 [00:49<00:11,  3.40it/s][A
 83%|████████▎ | 183/221 [00:49<00:10,  3.50it/s][A
 83%|████████▎ | 184/221 [00:50<00:09,  3.72it/s][A
 84%|████████▎ | 185/221 [00:50<00:07,  4.52it/s][A
 84%|████████▍ | 186/221 [00:50<00:10,  3.46it/s][A
 85%|████████▍ | 187/221 [00:50<00:09,  3.44it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.38it/s][A
 86%|████████▌ | 189/221 [00:51<00:09,  3.55it/s][A
 86%|████████▌ | 190/221 [00:51<00:09,  3.23it/s][A
 86%|████████▋ | 191/221 [00:51<00:08,  3.75it/s][A
 87%|████████▋ | 192/221 [00:52<00:07,  3.68it/s][A
 88%|████████▊ | 194/221 [00:52<00:06,  4.09it/s][A
 88%|████████▊ | 195/221 [00:52<00:06,  4.03it/s][A
 89%|████████▊ | 196/221 [00:53<00:08,  3.10it/s][A
 89%|████████▉ | 197/221 [00:53<00:07,  3.27it/s][A
 90%|████████▉ | 198/221 [00:54<00:08,  2.83it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.15it/s][A
 90%|█████████ | 200/221 [00:54<00:07,  2.63it/s][A
 91%|█████████ | 201/221 [00:55<00:06,  2.93it/s][A
 91%|█████████▏| 202/221 [00:55<00:06,  2.86it/s][A
 92%|█████████▏| 203/221 [00:55<00:05,  3.31it/s][A
 92%|█████████▏| 204/221 [00:56<00:06,  2.70it/s][A
 93%|█████████▎| 205/221 [00:56<00:04,  3.44it/s][A
 93%|█████████▎| 206/221 [00:57<00:05,  2.57it/s][A
 94%|█████████▎| 207/221 [00:57<00:04,  3.30it/s][A
 94%|█████████▍| 208/221 [00:57<00:03,  3.61it/s][A
 95%|█████████▍| 209/221 [00:57<00:03,  3.71it/s][A
 95%|█████████▌| 211/221 [00:58<00:02,  4.12it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  3.89it/s][A
 96%|█████████▋| 213/221 [00:58<00:01,  4.07it/s][A
 97%|█████████▋| 214/221 [00:59<00:02,  3.19it/s][A
 97%|█████████▋| 215/221 [00:59<00:01,  3.55it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.62it/s][A
 98%|█████████▊| 217/221 [00:59<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.28it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.09it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.49it/s][A
100%|██████████| 221/221 [01:00<00:00,  3.77it/s][A100%|██████████| 221/221 [01:00<00:00,  3.63it/s]
09/09/2024 19:48:15 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 499--===========

09/09/2024 19:48:15 - INFO - __main__ -   {'area_r1': 40.2, 'area_recall': '40.2/65.3/75.7', 'area_ravg': 60.4}
09/09/2024 19:48:15 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 499--===========

09/09/2024 19:48:15 - INFO - __main__ -   {'forward_r1': 36.4, 'forward_recall': '36.4/65.4/74.5', 'forward_ravg': 58.8}
09/09/2024 19:48:15 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 499--===========

09/09/2024 19:48:15 - INFO - __main__ -   {'area_video_r1': 40.3, 'area_video_recall': '40.3/67.6/77.7', 'area_video_ravg': 61.9}
09/09/2024 19:48:15 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/09/2024 19:48:15 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 19:48:15 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 499--===========

09/09/2024 19:48:15 - INFO - __main__ -   {'area_video_r1': 51.7, 'area_video_recall': '51.7/74.8/81.9', 'area_video_ravg': 69.5, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.1/81.2', 'area_video_back_ravg': 68.3}
09/09/2024 19:48:15 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/09/2024 19:48:15 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/09/2024 19:48:15 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 499--===========

09/09/2024 19:48:15 - INFO - __main__ -   {'video_r1': 41.9, 'video_recall': '41.9/70.9/81.8', 'video_ravg': 64.9}
09/09/2024 19:48:15 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 19:48:15 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 19:48:15 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 499--===========

09/09/2024 19:48:15 - INFO - __main__ -   {'video_r1': 51.1, 'video_recall': '51.1/75.6/82.7', 'video_ravg': 69.8}
09/09/2024 19:48:15 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/09/2024 19:48:15 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/09/2024 19:48:36 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.013446243479847908, 'loss_ret%tv%ta--finetune_area/loss_area': 1.320259928703308, 'loss_ret%tv%ta--finetune_area/total_loss': 1.3337061405181885}
 26%|██▌       | 500/1945 [2:43:17<49:43:39, 123.89s/it] 26%|██▌       | 501/1945 [2:43:21<35:17:34, 87.99s/it] [h264 @ 0x55a044e486c0] mmco: unref short failure
 26%|██▌       | 502/1945 [2:43:26<25:13:48, 62.94s/it][h264 @ 0x55a044fd40c0] mmco: unref short failure
[h264 @ 0x55a044fd40c0] mmco: unref short failure
[h264 @ 0x559bffa53340] mmco: unref short failure
[h264 @ 0x559bffa53340] mmco: unref short failure
 26%|██▌       | 503/1945 [2:43:31<18:15:46, 45.59s/it][h264 @ 0x556b4a286e00] mmco: unref short failure
[h264 @ 0x556b4a286e00] mmco: unref short failure
 26%|██▌       | 504/1945 [2:43:36<13:26:49, 33.59s/it][h264 @ 0x556b34ca6480] mmco: unref short failure
 26%|██▌       | 505/1945 [2:43:43<10:10:46, 25.45s/it][h264 @ 0x559c05f27b80] mmco: unref short failure
 26%|██▌       | 506/1945 [2:43:49<7:54:11, 19.77s/it] [h264 @ 0x55a04f6c7980] mmco: unref short failure
 26%|██▌       | 507/1945 [2:43:56<6:20:01, 15.86s/it] 26%|██▌       | 508/1945 [2:44:03<5:18:24, 13.29s/it][h264 @ 0x559c024f6740] mmco: unref short failure
 26%|██▌       | 509/1945 [2:44:11<4:40:51, 11.74s/it][h264 @ 0x556b46ed2640] mmco: unref short failure
[h264 @ 0x556b44733940] mmco: unref short failure
[h264 @ 0x556b44733940] mmco: unref short failure
 26%|██▌       | 510/1945 [2:44:18<4:07:24, 10.34s/it][h264 @ 0x562432dd5080] mmco: unref short failure
[h264 @ 0x562432dd5080] mmco: unref short failure
 26%|██▋       | 511/1945 [2:44:26<3:44:09,  9.38s/it][h264 @ 0x556b306614c0] mmco: unref short failure
[h264 @ 0x556b306614c0] mmco: unref short failure
 26%|██▋       | 512/1945 [2:44:34<3:33:35,  8.94s/it][h264 @ 0x562427c00f80] mmco: unref short failure
[h264 @ 0x562427c00f80] mmco: unref short failure
 26%|██▋       | 513/1945 [2:44:41<3:23:03,  8.51s/it][h264 @ 0x55a047a0b4c0] mmco: unref short failure
[h264 @ 0x55a047a0b4c0] mmco: unref short failure
[h264 @ 0x5624335e2340] mmco: unref short failure
 26%|██▋       | 514/1945 [2:44:49<3:15:37,  8.20s/it][h264 @ 0x556b474a2d00] mmco: unref short failure
[h264 @ 0x556b474a2d00] mmco: unref short failure
[h264 @ 0x556b43e9bd00] mmco: unref short failure
[h264 @ 0x556b43e9bd00] mmco: unref short failure
 26%|██▋       | 515/1945 [2:44:57<3:19:36,  8.38s/it] 27%|██▋       | 516/1945 [2:45:05<3:12:02,  8.06s/it][h264 @ 0x559bfa2ee380] mmco: unref short failure
[h264 @ 0x559bfa2ee380] mmco: unref short failure
[h264 @ 0x562420859b40] mmco: unref short failure
[h264 @ 0x562420859b40] mmco: unref short failure
 27%|██▋       | 517/1945 [2:45:19<3:56:52,  9.95s/it][h264 @ 0x559bea258a80] mmco: unref short failure
[h264 @ 0x559bea258a80] mmco: unref short failure
[h264 @ 0x559bea258a80] mmco: unref short failure
[h264 @ 0x559bf7170000] mmco: unref short failure
 27%|██▋       | 518/1945 [2:45:26<3:35:59,  9.08s/it][h264 @ 0x559c01b7fa00] mmco: unref short failure
 27%|██▋       | 519/1945 [2:45:33<3:19:56,  8.41s/it][h264 @ 0x56242e20e340] mmco: unref short failure
 27%|██▋       | 520/1945 [2:45:39<3:05:06,  7.79s/it] 27%|██▋       | 521/1945 [2:45:49<3:21:34,  8.49s/it][h264 @ 0x55a04f98ac00] mmco: unref short failure
[h264 @ 0x55a04f98ac00] mmco: unref short failure
[h264 @ 0x559bf3f8c080] mmco: unref short failure
 27%|██▋       | 522/1945 [2:46:01<3:45:37,  9.51s/it][h264 @ 0x559bebefac00] mmco: unref short failure
[h264 @ 0x562431c06ec0] mmco: unref short failure
[h264 @ 0x562431c06ec0] mmco: unref short failure
 27%|██▋       | 523/1945 [2:46:09<3:35:28,  9.09s/it][h264 @ 0x55a03b3a3980] mmco: unref short failure
[h264 @ 0x556b4864d580] mmco: unref short failure
[h264 @ 0x556b4864d580] mmco: unref short failure
[h264 @ 0x559bee072500] mmco: unref short failure
[h264 @ 0x559c0643a2c0] mmco: unref short failure
[h264 @ 0x556b4550a380] mmco: unref short failure
[h264 @ 0x562421229fc0] mmco: unref short failure
[h264 @ 0x562421229fc0] mmco: unref short failure
[h264 @ 0x559c04a85d00] mmco: unref short failure
[h264 @ 0x559c04a85d00] mmco: unref short failure
[h264 @ 0x559c04a85d00] mmco: unref short failure
[h264 @ 0x559c04a85d00] mmco: unref short failure
[h264 @ 0x55a039d178c0] mmco: unref short failure
[h264 @ 0x55a039d178c0] mmco: unref short failure
[h264 @ 0x55a04c5f2e00] mmco: unref short failure
[h264 @ 0x5624208e7380] mmco: unref short failure
[h264 @ 0x5624208e7380] mmco: unref short failure
[h264 @ 0x55a0497ba180] mmco: unref short failure
[h264 @ 0x55a0497ba180] mmco: unref short failure
[h264 @ 0x556b389bfb80] mmco: unref short failure
[h264 @ 0x559c0be76600] mmco: unref short failure
[h264 @ 0x556b3138ab80] mmco: unref short failure
 27%|██▋       | 524/1945 [2:46:51<7:23:42, 18.73s/it][h264 @ 0x559bfd23dfc0] mmco: unref short failure
[h264 @ 0x559bfd23dfc0] mmco: unref short failure
[h264 @ 0x55a044ba7300] mmco: unref short failure
[h264 @ 0x55a04c13ea80] mmco: unref short failure
[h264 @ 0x56243375c2c0] mmco: unref short failure
[h264 @ 0x56243375c2c0] mmco: unref short failure
[h264 @ 0x559bff1db980] mmco: unref short failure
[h264 @ 0x559bff1db980] mmco: unref short failure
 27%|██▋       | 525/1945 [2:47:17<8:15:49, 20.95s/it] 27%|██▋       | 526/1945 [2:47:24<6:38:28, 16.85s/it][h264 @ 0x556b47825600] mmco: unref short failure
[h264 @ 0x556b47825600] mmco: unref short failure
[h264 @ 0x562420820a40] mmco: unref short failure
[h264 @ 0x562420820a40] mmco: unref short failure
[h264 @ 0x559c023e80c0] mmco: unref short failure
[h264 @ 0x559c023e80c0] mmco: unref short failure
[h264 @ 0x559c0b4e7180] mmco: unref short failure
[h264 @ 0x559c0b4e7180] mmco: unref short failure
 27%|██▋       | 527/1945 [2:47:33<5:40:00, 14.39s/it][h264 @ 0x559be9481780] mmco: unref short failure
[h264 @ 0x559be9481780] mmco: unref short failure
[h264 @ 0x559c08472840] mmco: unref short failure
[h264 @ 0x559c08472840] mmco: unref short failure
[h264 @ 0x556b33ff5980] mmco: unref short failure
[h264 @ 0x556b33ff5980] mmco: unref short failure
[h264 @ 0x56242b30a2c0] mmco: unref short failure
[h264 @ 0x56242b30a2c0] mmco: unref short failure
[h264 @ 0x556b447747c0] mmco: unref short failure
 27%|██▋       | 528/1945 [2:47:49<5:50:58, 14.86s/it][h264 @ 0x559bed69e840] mmco: unref short failure
[h264 @ 0x559bed69e840] mmco: unref short failure
[h264 @ 0x55a0467636c0] mmco: unref short failure
[h264 @ 0x562432791600] mmco: unref short failure
[h264 @ 0x559bfe66aa80] mmco: unref short failure
[h264 @ 0x559bfe66aa80] mmco: unref short failure
[h264 @ 0x556b4255eb40] mmco: unref short failure
[h264 @ 0x5624329649c0] mmco: unref short failure
[h264 @ 0x5624329649c0] mmco: unref short failure
[h264 @ 0x55a051dcc8c0] mmco: unref short failure
[h264 @ 0x559c089bfcc0] mmco: unref short failure
[h264 @ 0x559c089bfcc0] mmco: unref short failure
 27%|██▋       | 529/1945 [2:48:19<7:40:51, 19.53s/it][h264 @ 0x556b2e405900] mmco: unref short failure
[h264 @ 0x556b2e405900] mmco: unref short failure
[h264 @ 0x556b2e405900] mmco: unref short failure
[h264 @ 0x556b2e405900] mmco: unref short failure
 27%|██▋       | 530/1945 [2:48:27<6:15:33, 15.92s/it][h264 @ 0x559bf9df2fc0] mmco: unref short failure
[h264 @ 0x559bf9df2fc0] mmco: unref short failure
[h264 @ 0x559bee06a4c0] mmco: unref short failure
[h264 @ 0x559bee06a4c0] mmco: unref short failure
[h264 @ 0x559bee06a4c0] mmco: unref short failure
[h264 @ 0x559bee06a4c0] mmco: unref short failure
[h264 @ 0x55a04e5fd700] mmco: unref short failure
 27%|██▋       | 531/1945 [2:48:34<5:14:52, 13.36s/it][h264 @ 0x55a03b462f00] mmco: unref short failure
[h264 @ 0x556b3c8ce680] mmco: unref short failure
[h264 @ 0x556b3c8ce680] mmco: unref short failure
[h264 @ 0x562426d971c0] mmco: unref short failure
 27%|██▋       | 532/1945 [2:49:02<7:00:54, 17.87s/it][h264 @ 0x556b34d5a840] mmco: unref short failure
[h264 @ 0x562421942540] mmco: unref short failure
[h264 @ 0x562421942540] mmco: unref short failure
[h264 @ 0x556b34d5af40] mmco: unref short failure
[h264 @ 0x556b34d5af40] mmco: unref short failure
[h264 @ 0x562421942080] mmco: unref short failure
[h264 @ 0x562421942080] mmco: unref short failure
[h264 @ 0x559beb142bc0] mmco: unref short failure
[h264 @ 0x559beb142bc0] mmco: unref short failure
[h264 @ 0x562432e6db00] mmco: unref short failure
[h264 @ 0x562432e6db00] mmco: unref short failure
[h264 @ 0x562432e6db00] mmco: unref short failure
[h264 @ 0x562432e6db00] mmco: unref short failure
[h264 @ 0x562432e6db00] mmco: unref short failure
[h264 @ 0x562432e6db00] mmco: unref short failure
[h264 @ 0x55a042c177c0] mmco: unref short failure
[h264 @ 0x55a042c177c0] mmco: unref short failure
 27%|██▋       | 533/1945 [2:49:24<7:29:38, 19.11s/it][h264 @ 0x562425247480] mmco: unref short failure
[h264 @ 0x56241afcc000] mmco: unref short failure
[h264 @ 0x56241afcc000] mmco: unref short failure
[h264 @ 0x56241afcc900] mmco: unref short failure
[h264 @ 0x56241afcc900] mmco: unref short failure
 27%|██▋       | 534/1945 [2:49:31<6:01:17, 15.36s/it][h264 @ 0x55a03506bc40] mmco: unref short failure
[h264 @ 0x556b35651180] mmco: unref short failure
[h264 @ 0x556b35651180] mmco: unref short failure
[h264 @ 0x559bfd395600] mmco: unref short failure
[h264 @ 0x559bfd395600] mmco: unref short failure
[h264 @ 0x56242c9c17c0] mmco: unref short failure
 28%|██▊       | 535/1945 [2:49:38<5:05:35, 13.00s/it][h264 @ 0x55a045467080] mmco: unref short failure
[h264 @ 0x55a044b644c0] mmco: unref short failure
[h264 @ 0x556b3a88ea40] mmco: unref short failure
 28%|██▊       | 536/1945 [2:49:51<5:02:31, 12.88s/it][h264 @ 0x56241f62fac0] mmco: unref short failure
[h264 @ 0x56241f62fac0] mmco: unref short failure
[h264 @ 0x56241f62fac0] mmco: unref short failure
[h264 @ 0x559c0845e4c0] mmco: unref short failure
[h264 @ 0x559c0845e4c0] mmco: unref short failure
[h264 @ 0x559bfd51b880] mmco: unref short failure
[h264 @ 0x559bfd51b880] mmco: unref short failure
 28%|██▊       | 537/1945 [2:50:24<7:22:51, 18.87s/it][h264 @ 0x55a04bc7b940] mmco: unref short failure
[h264 @ 0x556b35650f40] mmco: unref short failure
[h264 @ 0x556b35650f40] mmco: unref short failure
 28%|██▊       | 538/1945 [2:50:31<5:57:42, 15.25s/it][h264 @ 0x55a03c309940] mmco: unref short failure
[h264 @ 0x55a03c309940] mmco: unref short failure
[h264 @ 0x55a052d86ac0] mmco: unref short failure
[h264 @ 0x556b40c89780] mmco: unref short failure
 28%|██▊       | 539/1945 [2:50:39<5:09:44, 13.22s/it][h264 @ 0x56241b643c40] mmco: unref short failure
[h264 @ 0x56241b643c40] mmco: unref short failure
[h264 @ 0x559be982e000] mmco: unref short failure
[h264 @ 0x559be982e000] mmco: unref short failure
[h264 @ 0x55a04fe29400] mmco: unref short failure
[h264 @ 0x562434bf1040] mmco: unref short failure
[h264 @ 0x562434bf1040] mmco: unref short failure
[h264 @ 0x556b4452c380] mmco: unref short failure
[h264 @ 0x556b4452c380] mmco: unref short failure
[h264 @ 0x55a04e68a3c0] mmco: unref short failure
[h264 @ 0x55a04e68a3c0] mmco: unref short failure
[h264 @ 0x562419479cc0] mmco: unref short failure
[h264 @ 0x562419479cc0] mmco: unref short failure
[h264 @ 0x559bf8aa3340] mmco: unref short failure
[h264 @ 0x559bf8aa3340] mmco: unref short failure
[h264 @ 0x559bfad10740] mmco: unref short failure
[h264 @ 0x559bfad10740] mmco: unref short failure
[h264 @ 0x559bfe66ac80] mmco: unref short failure
[h264 @ 0x559bfe66ac80] mmco: unref short failure
[h264 @ 0x559bfe66ac80] mmco: unref short failure
[h264 @ 0x559bfe66ac80] mmco: unref short failure
[h264 @ 0x559bfe66ac80] mmco: unref short failure
[h264 @ 0x559bfe66ac80] mmco: unref short failure
[h264 @ 0x559bfe66ac80] mmco: unref short failure
[h264 @ 0x559bfe66ac80] mmco: unref short failure
[h264 @ 0x559bfe66ac80] mmco: unref short failure
[h264 @ 0x559bfe66ac80] mmco: unref short failure
[h264 @ 0x559bfe66ac80] mmco: unref short failure
[h264 @ 0x559bfe66ac80] mmco: unref short failure
 28%|██▊       | 540/1945 [2:51:02<6:14:34, 16.00s/it][h264 @ 0x559bf7396000] mmco: unref short failure
[h264 @ 0x559bf7396000] mmco: unref short failure
[h264 @ 0x559c05c6eb40] mmco: unref short failure
[h264 @ 0x559c05c6eb40] mmco: unref short failure
[h264 @ 0x55a052d7a4c0] mmco: unref short failure
[h264 @ 0x55a052d7a4c0] mmco: unref short failure
[h264 @ 0x55a052d7a4c0] mmco: unref short failure
[h264 @ 0x55a052d7a4c0] mmco: unref short failure
 28%|██▊       | 541/1945 [2:51:24<7:00:01, 17.95s/it][h264 @ 0x559bfe66cfc0] mmco: unref short failure
[h264 @ 0x559bfe66cfc0] mmco: unref short failure
 28%|██▊       | 542/1945 [2:51:31<5:43:50, 14.70s/it] 28%|██▊       | 543/1945 [2:51:39<4:56:40, 12.70s/it][h264 @ 0x559c07514580] mmco: unref short failure
[h264 @ 0x559c07514580] mmco: unref short failure
[h264 @ 0x559c0be696c0] mmco: unref short failure
[h264 @ 0x556b33c378c0] mmco: unref short failure
[h264 @ 0x556b3f80dcc0] mmco: unref short failure
 28%|██▊       | 544/1945 [2:51:51<4:51:11, 12.47s/it][h264 @ 0x562424ca8200] mmco: unref short failure
[h264 @ 0x562424ca8200] mmco: unref short failure
[h264 @ 0x55a040430440] mmco: unref short failure
[h264 @ 0x56241e489080] mmco: unref short failure
[h264 @ 0x55a0453f84c0] mmco: unref short failure
[h264 @ 0x556b4cefca40] mmco: unref short failure
[h264 @ 0x556b2de5dc80] mmco: unref short failure
[h264 @ 0x556b2de5dc80] mmco: unref short failure
 28%|██▊       | 545/1945 [2:52:27<7:32:15, 19.38s/it][h264 @ 0x56242c18b740] mmco: unref short failure
[h264 @ 0x559be9efdbc0] mmco: unref short failure
 28%|██▊       | 546/1945 [2:52:34<6:07:36, 15.77s/it][h264 @ 0x556b3693e380] mmco: unref short failure
[h264 @ 0x556b3693e380] mmco: unref short failure
[h264 @ 0x556b3693e380] mmco: unref short failure
 28%|██▊       | 547/1945 [2:52:41<5:05:50, 13.13s/it][h264 @ 0x559be9711500] mmco: unref short failure
[h264 @ 0x559be9711500] mmco: unref short failure
[h264 @ 0x562425aa4980] mmco: unref short failure
[h264 @ 0x562425aa4980] mmco: unref short failure
 28%|██▊       | 548/1945 [2:52:58<5:33:29, 14.32s/it][h264 @ 0x5624343d7300] mmco: unref short failure
[h264 @ 0x5624343d7300] mmco: unref short failure
[h264 @ 0x55a04d516580] mmco: unref short failure
[h264 @ 0x55a04d516580] mmco: unref short failure
[h264 @ 0x562434e23640] mmco: unref short failure
[h264 @ 0x562434e23640] mmco: unref short failure
[h264 @ 0x559bf9324340] mmco: unref short failure
[h264 @ 0x562424631d80] mmco: unref short failure
[h264 @ 0x562424631d80] mmco: unref short failure
[h264 @ 0x559bf4b12240] mmco: unref short failure
[h264 @ 0x556b460702c0] mmco: unref short failure
[h264 @ 0x556b460702c0] mmco: unref short failure
[h264 @ 0x559c0285cac0] mmco: unref short failure
[h264 @ 0x559c0285cac0] mmco: unref short failure
[h264 @ 0x5624194c2080] mmco: unref short failure
[h264 @ 0x5624194c2080] mmco: unref short failure
[h264 @ 0x5624194c2080] mmco: unref short failure
[h264 @ 0x5624194c2080] mmco: unref short failure
 28%|██▊       | 549/1945 [2:53:28<7:24:53, 19.12s/it]09/09/2024 19:58:51 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 19:58:51 - INFO - __main__ -   start running ret%tv validation...
[h264 @ 0x556b2d587bc0] mmco: unref short failure
[h264 @ 0x556b2d587bc0] mmco: unref short failure
[h264 @ 0x556b3dc835c0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556b2eb86d00] mmco: unref short failure
[h264 @ 0x556b2eb86d00] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x5624177d4680] mmco: unref short failure
[h264 @ 0x559bf1fb45c0] mmco: unref short failure
[h264 @ 0x556b30bb2700] mmco: unref short failure
[h264 @ 0x556b30bb2700] mmco: unref short failure
[h264 @ 0x556b3f54d380] mmco: unref short failure
[h264 @ 0x559c0524c2c0] mmco: unref short failure
[h264 @ 0x559c0524c2c0] mmco: unref short failure
[h264 @ 0x556b4d957dc0] mmco: unref short failure
[h264 @ 0x556b4d957dc0] mmco: unref short failure
[h264 @ 0x55a0387cd380] mmco: unref short failure
[h264 @ 0x55a0387cd380] mmco: unref short failure
[h264 @ 0x55a0358d2000] mmco: unref short failure
[h264 @ 0x55a0358d2000] mmco: unref short failure
[h264 @ 0x559bebb2aa00] mmco: unref short failure
[h264 @ 0x559bebb2aa00] mmco: unref short failure
[h264 @ 0x556b349d2e00] mmco: unref short failure
[h264 @ 0x556b31cc3140] mmco: unref short failure
[h264 @ 0x556b31cc3140] mmco: unref short failure
[h264 @ 0x556b2f599280] mmco: unref short failure
[h264 @ 0x56241cc0a1c0] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:40,  1.37it/s][A
  1%|          | 2/221 [00:01<02:04,  1.76it/s][A
  1%|▏         | 3/221 [00:01<01:32,  2.37it/s][A
  2%|▏         | 4/221 [00:01<01:09,  3.11it/s][A
  2%|▏         | 5/221 [00:01<00:59,  3.64it/s][A
  3%|▎         | 6/221 [00:01<00:50,  4.27it/s][A
  3%|▎         | 7/221 [00:02<00:54,  3.90it/s][A
  4%|▎         | 8/221 [00:02<01:08,  3.12it/s][A
  4%|▍         | 9/221 [00:02<01:02,  3.39it/s][A
  5%|▍         | 10/221 [00:03<01:08,  3.10it/s][A
  5%|▍         | 11/221 [00:03<00:56,  3.69it/s][A
  5%|▌         | 12/221 [00:03<00:58,  3.55it/s][A[h264 @ 0x556b509996c0] mmco: unref short failure

  6%|▌         | 13/221 [00:04<01:05,  3.19it/s][A
  6%|▋         | 14/221 [00:04<01:35,  2.17it/s][A
  7%|▋         | 15/221 [00:05<01:20,  2.55it/s][A
  7%|▋         | 16/221 [00:05<01:18,  2.62it/s][A
  8%|▊         | 17/221 [00:06<01:37,  2.10it/s][A
  8%|▊         | 18/221 [00:06<01:29,  2.28it/s][A
  9%|▊         | 19/221 [00:06<01:14,  2.72it/s][A
  9%|▉         | 20/221 [00:07<01:06,  3.04it/s][A
 10%|▉         | 21/221 [00:07<00:59,  3.38it/s][A
 10%|▉         | 22/221 [00:07<00:52,  3.80it/s][A
 10%|█         | 23/221 [00:07<00:44,  4.47it/s][A
 11%|█         | 24/221 [00:07<00:39,  5.02it/s][A
 11%|█▏        | 25/221 [00:07<00:39,  5.01it/s][A
 12%|█▏        | 26/221 [00:08<00:59,  3.25it/s][A
 12%|█▏        | 27/221 [00:08<00:48,  4.00it/s][A[h264 @ 0x55a032ed0400] mmco: unref short failure
[h264 @ 0x55a032ed0400] mmco: unref short failure

 13%|█▎        | 28/221 [00:09<01:02,  3.07it/s][A
 13%|█▎        | 29/221 [00:10<01:51,  1.72it/s][A
 14%|█▎        | 30/221 [00:10<01:29,  2.13it/s][A
 14%|█▍        | 31/221 [00:10<01:20,  2.36it/s][A
 15%|█▍        | 33/221 [00:11<00:56,  3.35it/s][A
 15%|█▌        | 34/221 [00:11<00:51,  3.66it/s][A
 16%|█▌        | 35/221 [00:11<00:45,  4.06it/s][A
 16%|█▋        | 36/221 [00:11<00:49,  3.70it/s][A
 17%|█▋        | 37/221 [00:12<01:07,  2.71it/s][A
 17%|█▋        | 38/221 [00:12<01:15,  2.43it/s][A
 18%|█▊        | 39/221 [00:13<01:19,  2.28it/s][A
 18%|█▊        | 40/221 [00:13<01:11,  2.53it/s][A
 19%|█▊        | 41/221 [00:13<00:57,  3.14it/s][A
 19%|█▉        | 42/221 [00:14<01:00,  2.95it/s][A
 19%|█▉        | 43/221 [00:14<00:54,  3.29it/s][A[h264 @ 0x55a034bae280] mmco: unref short failure

 20%|█▉        | 44/221 [00:14<00:49,  3.57it/s][A
 20%|██        | 45/221 [00:15<01:28,  1.99it/s][A
 21%|██        | 46/221 [00:16<01:20,  2.17it/s][A
 21%|██▏       | 47/221 [00:16<01:22,  2.10it/s][A
 22%|██▏       | 49/221 [00:17<01:12,  2.36it/s][A
 23%|██▎       | 50/221 [00:17<01:17,  2.21it/s][A
 23%|██▎       | 51/221 [00:18<01:07,  2.51it/s][A
 24%|██▎       | 52/221 [00:18<01:01,  2.74it/s][A
 24%|██▍       | 53/221 [00:18<00:49,  3.37it/s][A
 24%|██▍       | 54/221 [00:19<01:44,  1.60it/s][A
 25%|██▍       | 55/221 [00:20<01:30,  1.84it/s][A
 25%|██▌       | 56/221 [00:20<01:15,  2.19it/s][A
 26%|██▌       | 57/221 [00:20<00:59,  2.75it/s][A
 26%|██▌       | 58/221 [00:20<00:53,  3.03it/s][A
 27%|██▋       | 59/221 [00:21<00:49,  3.25it/s][A
 27%|██▋       | 60/221 [00:21<00:55,  2.88it/s][A
 28%|██▊       | 61/221 [00:21<00:47,  3.33it/s][A
 28%|██▊       | 62/221 [00:22<00:46,  3.41it/s][A
 29%|██▊       | 63/221 [00:22<00:42,  3.68it/s][A
 29%|██▉       | 64/221 [00:22<00:39,  4.00it/s][A
 29%|██▉       | 65/221 [00:22<00:36,  4.23it/s][A
 30%|██▉       | 66/221 [00:23<00:42,  3.69it/s][A
 30%|███       | 67/221 [00:23<00:45,  3.37it/s][A
 31%|███       | 68/221 [00:23<00:40,  3.81it/s][A
 31%|███       | 69/221 [00:24<00:54,  2.78it/s][A
 32%|███▏      | 70/221 [00:24<00:48,  3.13it/s][A
 32%|███▏      | 71/221 [00:25<01:07,  2.23it/s][A
 33%|███▎      | 72/221 [00:25<00:55,  2.68it/s][A
 33%|███▎      | 73/221 [00:25<00:55,  2.68it/s][A
 33%|███▎      | 74/221 [00:26<00:49,  2.95it/s][A
 34%|███▍      | 75/221 [00:26<00:53,  2.71it/s][A
 34%|███▍      | 76/221 [00:26<00:43,  3.35it/s][A
 35%|███▍      | 77/221 [00:26<00:37,  3.86it/s][A
 35%|███▌      | 78/221 [00:26<00:35,  4.08it/s][A[h264 @ 0x559bee671f80] mmco: unref short failure
[h264 @ 0x559bee671f80] mmco: unref short failure

 36%|███▌      | 79/221 [00:27<00:51,  2.76it/s][A
 36%|███▌      | 80/221 [00:27<00:45,  3.07it/s][A
 37%|███▋      | 81/221 [00:28<00:45,  3.09it/s][A
 37%|███▋      | 82/221 [00:29<01:16,  1.82it/s][A
 38%|███▊      | 83/221 [00:29<01:09,  1.99it/s][A
 38%|███▊      | 84/221 [00:29<01:00,  2.28it/s][A
 38%|███▊      | 85/221 [00:30<00:51,  2.63it/s][A
 39%|███▉      | 86/221 [00:30<00:48,  2.78it/s][A
 39%|███▉      | 87/221 [00:30<00:51,  2.59it/s][A
 40%|███▉      | 88/221 [00:31<00:48,  2.75it/s][A[h264 @ 0x55a04c6d05c0] mmco: unref short failure
[h264 @ 0x55a04c6d05c0] mmco: unref short failure

 40%|████      | 89/221 [00:31<01:02,  2.10it/s][A
 41%|████      | 90/221 [00:32<00:56,  2.33it/s][A
 41%|████      | 91/221 [00:32<00:44,  2.90it/s][A
 42%|████▏     | 92/221 [00:32<00:39,  3.28it/s][A
 42%|████▏     | 93/221 [00:33<00:40,  3.12it/s][A
 43%|████▎     | 94/221 [00:33<00:35,  3.55it/s][A
 43%|████▎     | 95/221 [00:33<00:35,  3.60it/s][A
 43%|████▎     | 96/221 [00:33<00:32,  3.86it/s][A
 44%|████▍     | 97/221 [00:33<00:26,  4.67it/s][A
 44%|████▍     | 98/221 [00:33<00:24,  5.00it/s][A
 45%|████▍     | 99/221 [00:34<00:27,  4.46it/s][A
 45%|████▌     | 100/221 [00:34<00:24,  4.89it/s][A
 46%|████▌     | 101/221 [00:34<00:21,  5.68it/s][A
 46%|████▌     | 102/221 [00:34<00:23,  4.96it/s][A
 47%|████▋     | 103/221 [00:34<00:21,  5.51it/s][A
 47%|████▋     | 104/221 [00:35<00:22,  5.21it/s][A
 48%|████▊     | 105/221 [00:35<00:22,  5.18it/s][A
 48%|████▊     | 106/221 [00:36<00:39,  2.90it/s][A
 48%|████▊     | 107/221 [00:36<00:33,  3.41it/s][A
 49%|████▉     | 108/221 [00:36<00:30,  3.67it/s][A
 49%|████▉     | 109/221 [00:36<00:32,  3.50it/s][A
 50%|████▉     | 110/221 [00:37<00:32,  3.43it/s][A
 50%|█████     | 111/221 [00:37<00:36,  3.02it/s][A
 51%|█████     | 112/221 [00:37<00:30,  3.59it/s][A
 51%|█████     | 113/221 [00:37<00:30,  3.51it/s][A
 52%|█████▏    | 114/221 [00:38<00:25,  4.21it/s][A
 52%|█████▏    | 115/221 [00:38<00:21,  4.85it/s][A
 52%|█████▏    | 116/221 [00:41<01:47,  1.03s/it][A
 53%|█████▎    | 117/221 [00:41<01:24,  1.23it/s][A
 53%|█████▎    | 118/221 [00:41<01:05,  1.56it/s][A
 54%|█████▍    | 119/221 [00:41<00:51,  1.97it/s][A
 54%|█████▍    | 120/221 [00:42<00:44,  2.26it/s][A
 55%|█████▌    | 122/221 [00:42<00:28,  3.46it/s][A
 56%|█████▌    | 123/221 [00:42<00:24,  4.01it/s][A
 56%|█████▌    | 124/221 [00:42<00:23,  4.16it/s][A
 57%|█████▋    | 125/221 [00:43<00:25,  3.78it/s][A
 57%|█████▋    | 126/221 [00:43<00:26,  3.58it/s][A
 57%|█████▋    | 127/221 [00:43<00:34,  2.70it/s][A
 58%|█████▊    | 128/221 [00:44<00:32,  2.83it/s][A
 58%|█████▊    | 129/221 [00:44<00:26,  3.43it/s][A
 59%|█████▉    | 130/221 [00:44<00:25,  3.55it/s][A
 60%|█████▉    | 132/221 [00:44<00:19,  4.66it/s][A
 60%|██████    | 133/221 [00:45<00:21,  4.17it/s][A
 61%|██████    | 134/221 [00:45<00:19,  4.46it/s][A
 61%|██████    | 135/221 [00:45<00:18,  4.69it/s][A
 62%|██████▏   | 136/221 [00:45<00:21,  3.98it/s][A
 62%|██████▏   | 137/221 [00:46<00:20,  4.13it/s][A
 62%|██████▏   | 138/221 [00:46<00:23,  3.53it/s][A
 63%|██████▎   | 139/221 [00:46<00:24,  3.31it/s][A
 63%|██████▎   | 140/221 [00:47<00:25,  3.18it/s][A[h264 @ 0x55a03e38b640] mmco: unref short failure

 64%|██████▍   | 141/221 [00:47<00:23,  3.34it/s][A
 64%|██████▍   | 142/221 [00:47<00:22,  3.48it/s][A[h264 @ 0x55a032e37300] mmco: unref short failure

 65%|██████▍   | 143/221 [00:48<00:25,  3.11it/s][A
 65%|██████▌   | 144/221 [00:48<00:21,  3.65it/s][A
 66%|██████▌   | 146/221 [00:48<00:13,  5.41it/s][A
 67%|██████▋   | 147/221 [00:48<00:13,  5.41it/s][A
 67%|██████▋   | 148/221 [00:48<00:13,  5.29it/s][A
 68%|██████▊   | 150/221 [00:49<00:11,  6.19it/s][A
 68%|██████▊   | 151/221 [00:50<00:23,  2.99it/s][A[h264 @ 0x559bebcf4300] mmco: unref short failure

 69%|██████▉   | 152/221 [00:51<00:36,  1.90it/s][A
 69%|██████▉   | 153/221 [00:51<00:31,  2.18it/s][A
 70%|██████▉   | 154/221 [00:51<00:29,  2.28it/s][A
 70%|███████   | 155/221 [00:51<00:22,  2.89it/s][A
 71%|███████   | 156/221 [00:52<00:19,  3.35it/s][A[h264 @ 0x562418ba7f80] mmco: unref short failure
[h264 @ 0x562418ba7f80] mmco: unref short failure
[h264 @ 0x562418ba7f80] mmco: unref short failure
[h264 @ 0x562418ba7f80] mmco: unref short failure

 71%|███████   | 157/221 [00:53<00:31,  2.04it/s][A
 71%|███████▏  | 158/221 [00:53<00:25,  2.49it/s][A
 72%|███████▏  | 159/221 [00:53<00:19,  3.12it/s][A[h264 @ 0x55a0337d47c0] mmco: unref short failure

 72%|███████▏  | 160/221 [00:53<00:17,  3.45it/s][A
 73%|███████▎  | 161/221 [00:53<00:15,  3.82it/s][A
 73%|███████▎  | 162/221 [00:54<00:16,  3.51it/s][A
 74%|███████▍  | 163/221 [00:54<00:15,  3.80it/s][A
 74%|███████▍  | 164/221 [00:54<00:20,  2.77it/s][A
 75%|███████▌  | 166/221 [00:55<00:15,  3.47it/s][A
 76%|███████▌  | 167/221 [00:55<00:13,  3.95it/s][A
 76%|███████▌  | 168/221 [00:56<00:20,  2.63it/s][A
 76%|███████▋  | 169/221 [00:56<00:17,  3.06it/s][A
 77%|███████▋  | 170/221 [00:56<00:16,  3.09it/s][A
 77%|███████▋  | 171/221 [00:57<00:15,  3.21it/s][A
 78%|███████▊  | 172/221 [00:57<00:13,  3.61it/s][A
 79%|███████▊  | 174/221 [00:57<00:12,  3.91it/s][A
 79%|███████▉  | 175/221 [00:58<00:14,  3.17it/s][A
 80%|███████▉  | 176/221 [00:58<00:12,  3.54it/s][A
 80%|████████  | 177/221 [00:58<00:10,  4.25it/s][A
 81%|████████  | 178/221 [00:58<00:10,  4.25it/s][A
 81%|████████  | 179/221 [00:59<00:11,  3.70it/s][A[h264 @ 0x559c05fa0d80] mmco: unref short failure

 82%|████████▏ | 181/221 [00:59<00:07,  5.08it/s][A
 82%|████████▏ | 182/221 [00:59<00:07,  5.49it/s][A
 83%|████████▎ | 183/221 [00:59<00:06,  5.60it/s][A
 83%|████████▎ | 184/221 [00:59<00:07,  5.26it/s][A
 84%|████████▍ | 186/221 [01:00<00:06,  5.22it/s][A
 85%|████████▍ | 187/221 [01:00<00:06,  5.60it/s][A
 85%|████████▌ | 188/221 [01:00<00:06,  5.31it/s][A[h264 @ 0x559bf5babbc0] mmco: unref short failure
[h264 @ 0x559bf5babbc0] mmco: unref short failure

 86%|████████▌ | 189/221 [01:00<00:07,  4.32it/s][A
 86%|████████▌ | 190/221 [01:01<00:07,  3.99it/s][A
 87%|████████▋ | 192/221 [01:01<00:05,  5.10it/s][A[h264 @ 0x55a04c397140] mmco: unref short failure
[h264 @ 0x55a04c397140] mmco: unref short failure

 88%|████████▊ | 194/221 [01:02<00:06,  4.01it/s][A
 88%|████████▊ | 195/221 [01:02<00:06,  4.33it/s][A
 89%|████████▊ | 196/221 [01:02<00:08,  2.95it/s][A
 90%|████████▉ | 198/221 [01:03<00:06,  3.45it/s][A
 90%|█████████ | 199/221 [01:03<00:05,  4.00it/s][A
 90%|█████████ | 200/221 [01:03<00:05,  3.78it/s][A
 91%|█████████ | 201/221 [01:04<00:04,  4.01it/s][A
 91%|█████████▏| 202/221 [01:04<00:04,  4.40it/s][A
 92%|█████████▏| 203/221 [01:04<00:03,  4.99it/s][A
 92%|█████████▏| 204/221 [01:04<00:03,  4.44it/s][A
 93%|█████████▎| 206/221 [01:05<00:03,  4.15it/s][A
 94%|█████████▎| 207/221 [01:05<00:03,  4.26it/s][A
 94%|█████████▍| 208/221 [01:05<00:02,  4.64it/s][A
 95%|█████████▍| 209/221 [01:05<00:02,  4.43it/s][A
 95%|█████████▌| 211/221 [01:06<00:02,  4.79it/s][A
 96%|█████████▌| 212/221 [01:06<00:01,  5.30it/s][A[h264 @ 0x56241dc308c0] mmco: unref short failure

 96%|█████████▋| 213/221 [01:06<00:01,  4.80it/s][A
 97%|█████████▋| 214/221 [01:06<00:01,  4.26it/s][A
 97%|█████████▋| 215/221 [01:07<00:01,  4.48it/s][A
 98%|█████████▊| 216/221 [01:07<00:01,  4.14it/s][A
 98%|█████████▊| 217/221 [01:07<00:01,  3.70it/s][A
 99%|█████████▊| 218/221 [01:07<00:00,  3.93it/s][A
 99%|█████████▉| 219/221 [01:08<00:00,  4.05it/s][A
100%|█████████▉| 220/221 [01:11<00:01,  1.04s/it][A
100%|██████████| 221/221 [01:11<00:00,  1.30it/s][A100%|██████████| 221/221 [01:11<00:00,  3.11it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.78it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:57,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:52,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:41,  3.52it/s][A
 34%|███▍      | 76/221 [00:20<00:40,  3.60it/s][A
 35%|███▍      | 77/221 [00:20<00:39,  3.65it/s][A
 35%|███▌      | 78/221 [00:20<00:38,  3.69it/s][A
 36%|███▌      | 79/221 [00:20<00:38,  3.72it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.74it/s][A
 37%|███▋      | 81/221 [00:21<00:37,  3.76it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.77it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.77it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.78it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.78it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.78it/s][A
 39%|███▉      | 87/221 [00:23<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:28<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:42<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:47<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:52<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:56<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:57<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:27,  7.96it/s][A
  1%|          | 2/221 [00:00<00:52,  4.19it/s][A
  1%|▏         | 3/221 [00:00<00:58,  3.75it/s][A
  2%|▏         | 4/221 [00:00<00:50,  4.30it/s][A
  2%|▏         | 5/221 [00:01<00:47,  4.54it/s][A
  3%|▎         | 7/221 [00:01<00:42,  5.00it/s][A
  4%|▎         | 8/221 [00:01<00:48,  4.44it/s][A
  4%|▍         | 9/221 [00:01<00:47,  4.47it/s][A
  5%|▍         | 10/221 [00:02<01:09,  3.05it/s][A
  5%|▍         | 11/221 [00:02<01:01,  3.42it/s][A
  5%|▌         | 12/221 [00:02<00:52,  3.96it/s][A
  6%|▌         | 13/221 [00:03<01:30,  2.30it/s][A
  6%|▋         | 14/221 [00:03<01:09,  2.97it/s][A
  7%|▋         | 15/221 [00:04<00:59,  3.45it/s][A
  7%|▋         | 16/221 [00:04<01:06,  3.08it/s][A
  8%|▊         | 17/221 [00:05<01:30,  2.25it/s][A
  8%|▊         | 18/221 [00:05<01:16,  2.66it/s][A
  9%|▊         | 19/221 [00:05<01:08,  2.97it/s][A
  9%|▉         | 20/221 [00:05<00:54,  3.72it/s][A
 10%|▉         | 21/221 [00:05<00:46,  4.26it/s][A
 10%|▉         | 22/221 [00:06<00:45,  4.37it/s][A
 11%|█         | 24/221 [00:06<00:35,  5.60it/s][A
 11%|█▏        | 25/221 [00:06<00:37,  5.22it/s][A
 12%|█▏        | 26/221 [00:06<00:39,  4.90it/s][A
 12%|█▏        | 27/221 [00:06<00:34,  5.61it/s][A
 13%|█▎        | 28/221 [00:07<00:49,  3.89it/s][A
 13%|█▎        | 29/221 [00:07<00:44,  4.34it/s][A
 14%|█▎        | 30/221 [00:07<00:46,  4.10it/s][A
 14%|█▍        | 31/221 [00:08<00:42,  4.47it/s][A
 15%|█▍        | 33/221 [00:08<00:33,  5.65it/s][A
 15%|█▌        | 34/221 [00:08<00:32,  5.83it/s][A
 16%|█▌        | 35/221 [00:08<00:34,  5.43it/s][A
 16%|█▋        | 36/221 [00:09<00:40,  4.56it/s][A
 17%|█▋        | 37/221 [00:09<00:39,  4.61it/s][A
 17%|█▋        | 38/221 [00:09<00:43,  4.22it/s][A
 18%|█▊        | 39/221 [00:09<00:39,  4.62it/s][A
 18%|█▊        | 40/221 [00:10<00:45,  3.97it/s][A
 19%|█▊        | 41/221 [00:10<00:37,  4.80it/s][A
 19%|█▉        | 42/221 [00:10<00:39,  4.55it/s][A
 19%|█▉        | 43/221 [00:10<00:42,  4.17it/s][A
 20%|█▉        | 44/221 [00:10<00:40,  4.37it/s][A
 20%|██        | 45/221 [00:11<00:40,  4.35it/s][A
 21%|██        | 46/221 [00:11<00:37,  4.65it/s][A
 21%|██▏       | 47/221 [00:11<00:37,  4.68it/s][A
 22%|██▏       | 48/221 [00:11<00:32,  5.34it/s][A
 22%|██▏       | 49/221 [00:11<00:33,  5.21it/s][A
 23%|██▎       | 50/221 [00:12<00:41,  4.09it/s][A
 23%|██▎       | 51/221 [00:12<00:40,  4.18it/s][A
 24%|██▎       | 52/221 [00:12<00:36,  4.63it/s][A
 24%|██▍       | 53/221 [00:12<00:31,  5.25it/s][A
 24%|██▍       | 54/221 [00:13<00:51,  3.23it/s][A
 25%|██▍       | 55/221 [00:13<00:50,  3.31it/s][A
 25%|██▌       | 56/221 [00:13<00:41,  3.99it/s][A
 26%|██▌       | 57/221 [00:13<00:41,  3.97it/s][A
 26%|██▌       | 58/221 [00:14<00:41,  3.97it/s][A
 27%|██▋       | 59/221 [00:14<00:37,  4.30it/s][A
 27%|██▋       | 60/221 [00:14<00:38,  4.19it/s][A
 28%|██▊       | 61/221 [00:14<00:35,  4.53it/s][A
 28%|██▊       | 62/221 [00:15<00:36,  4.33it/s][A
 29%|██▊       | 63/221 [00:15<00:35,  4.39it/s][A
 29%|██▉       | 64/221 [00:15<00:44,  3.51it/s][A
 29%|██▉       | 65/221 [00:15<00:37,  4.16it/s][A
 30%|██▉       | 66/221 [00:16<00:48,  3.18it/s][A
 30%|███       | 67/221 [00:16<00:56,  2.73it/s][A
 31%|███       | 68/221 [00:17<00:47,  3.22it/s][A
 31%|███       | 69/221 [00:17<01:04,  2.37it/s][A
 32%|███▏      | 70/221 [00:17<00:49,  3.05it/s][A
 32%|███▏      | 71/221 [00:18<00:44,  3.36it/s][A
 33%|███▎      | 72/221 [00:18<00:47,  3.14it/s][A
 33%|███▎      | 73/221 [00:18<00:46,  3.15it/s][A
 33%|███▎      | 74/221 [00:18<00:37,  3.96it/s][A
 34%|███▍      | 75/221 [00:19<00:37,  3.93it/s][A
 34%|███▍      | 76/221 [00:19<00:34,  4.16it/s][A
 35%|███▍      | 77/221 [00:19<00:34,  4.23it/s][A
 35%|███▌      | 78/221 [00:19<00:31,  4.61it/s][A
 36%|███▌      | 79/221 [00:20<00:44,  3.16it/s][A
 36%|███▌      | 80/221 [00:20<00:39,  3.54it/s][A
 37%|███▋      | 81/221 [00:20<00:37,  3.71it/s][A
 37%|███▋      | 82/221 [00:20<00:37,  3.74it/s][A
 38%|███▊      | 83/221 [00:21<00:38,  3.54it/s][A
 38%|███▊      | 84/221 [00:21<00:35,  3.83it/s][A
 39%|███▉      | 86/221 [00:21<00:31,  4.34it/s][A
 39%|███▉      | 87/221 [00:22<00:44,  3.01it/s][A
 40%|███▉      | 88/221 [00:22<00:49,  2.71it/s][A
 40%|████      | 89/221 [00:23<00:44,  2.95it/s][A
 41%|████      | 90/221 [00:23<00:43,  3.01it/s][A
 41%|████      | 91/221 [00:23<00:35,  3.66it/s][A
 42%|████▏     | 92/221 [00:23<00:35,  3.61it/s][A
 42%|████▏     | 93/221 [00:24<00:55,  2.31it/s][A
 43%|████▎     | 94/221 [00:25<00:48,  2.62it/s][A
 43%|████▎     | 95/221 [00:25<00:42,  2.97it/s][A
 43%|████▎     | 96/221 [00:25<00:37,  3.31it/s][A
 44%|████▍     | 97/221 [00:25<00:33,  3.73it/s][A
 44%|████▍     | 98/221 [00:25<00:31,  3.96it/s][A
 45%|████▍     | 99/221 [00:26<00:28,  4.30it/s][A
 45%|████▌     | 100/221 [00:26<00:28,  4.31it/s][A
 46%|████▌     | 101/221 [00:26<00:30,  3.89it/s][A
 46%|████▌     | 102/221 [00:27<00:45,  2.64it/s][A
 47%|████▋     | 103/221 [00:27<00:35,  3.31it/s][A
 47%|████▋     | 104/221 [00:27<00:31,  3.74it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.83it/s][A
 48%|████▊     | 106/221 [00:28<00:41,  2.74it/s][A
 48%|████▊     | 107/221 [00:28<00:38,  2.99it/s][A
 49%|████▉     | 108/221 [00:28<00:33,  3.35it/s][A
 49%|████▉     | 109/221 [00:29<00:27,  4.09it/s][A
 50%|████▉     | 110/221 [00:29<00:26,  4.15it/s][A
 50%|█████     | 111/221 [00:29<00:28,  3.88it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.85it/s][A
 51%|█████     | 113/221 [00:29<00:25,  4.25it/s][A
 52%|█████▏    | 115/221 [00:30<00:21,  4.89it/s][A
 52%|█████▏    | 116/221 [00:30<00:22,  4.58it/s][A
 53%|█████▎    | 117/221 [00:30<00:24,  4.22it/s][A
 53%|█████▎    | 118/221 [00:31<00:23,  4.30it/s][A
 54%|█████▍    | 119/221 [00:31<00:29,  3.43it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.77it/s][A
 55%|█████▍    | 121/221 [00:31<00:22,  4.47it/s][A
 55%|█████▌    | 122/221 [00:32<00:23,  4.18it/s][A
 56%|█████▌    | 123/221 [00:32<00:23,  4.14it/s][A
 56%|█████▌    | 124/221 [00:32<00:24,  3.90it/s][A
 57%|█████▋    | 125/221 [00:33<00:26,  3.57it/s][A
 57%|█████▋    | 126/221 [00:33<00:24,  3.91it/s][A
 57%|█████▋    | 127/221 [00:33<00:28,  3.33it/s][A
 58%|█████▊    | 128/221 [00:33<00:26,  3.50it/s][A
 58%|█████▊    | 129/221 [00:33<00:21,  4.32it/s][A
 59%|█████▉    | 130/221 [00:34<00:21,  4.17it/s][A
 60%|█████▉    | 132/221 [00:34<00:20,  4.33it/s][A
 60%|██████    | 133/221 [00:34<00:21,  4.05it/s][A
 61%|██████    | 134/221 [00:35<00:24,  3.52it/s][A
 61%|██████    | 135/221 [00:35<00:26,  3.22it/s][A
 62%|██████▏   | 136/221 [00:35<00:24,  3.46it/s][A
 62%|██████▏   | 137/221 [00:36<00:21,  3.88it/s][A
 62%|██████▏   | 138/221 [00:36<00:23,  3.58it/s][A
 63%|██████▎   | 139/221 [00:37<00:30,  2.69it/s][A
 63%|██████▎   | 140/221 [00:37<00:28,  2.88it/s][A
 64%|██████▍   | 141/221 [00:37<00:25,  3.18it/s][A
 64%|██████▍   | 142/221 [00:37<00:22,  3.56it/s][A
 65%|██████▍   | 143/221 [00:38<00:32,  2.38it/s][A
 65%|██████▌   | 144/221 [00:38<00:32,  2.38it/s][A
 66%|██████▌   | 146/221 [00:39<00:19,  3.94it/s][A
 67%|██████▋   | 147/221 [00:39<00:19,  3.82it/s][A
 67%|██████▋   | 148/221 [00:39<00:20,  3.58it/s][A
 67%|██████▋   | 149/221 [00:40<00:20,  3.53it/s][A
 68%|██████▊   | 150/221 [00:40<00:19,  3.63it/s][A
 68%|██████▊   | 151/221 [00:40<00:20,  3.35it/s][A
 69%|██████▉   | 152/221 [00:41<00:33,  2.06it/s][A
 69%|██████▉   | 153/221 [00:41<00:25,  2.62it/s][A
 70%|██████▉   | 154/221 [00:41<00:22,  2.97it/s][A
 70%|███████   | 155/221 [00:42<00:20,  3.19it/s][A
 71%|███████   | 156/221 [00:42<00:22,  2.85it/s][A
 71%|███████   | 157/221 [00:42<00:22,  2.90it/s][A
 71%|███████▏  | 158/221 [00:43<00:21,  2.93it/s][A
 72%|███████▏  | 159/221 [00:43<00:16,  3.70it/s][A
 72%|███████▏  | 160/221 [00:43<00:16,  3.78it/s][A
 73%|███████▎  | 161/221 [00:43<00:14,  4.00it/s][A
 73%|███████▎  | 162/221 [00:43<00:12,  4.67it/s][A
 74%|███████▍  | 163/221 [00:44<00:13,  4.29it/s][A
 74%|███████▍  | 164/221 [00:44<00:11,  4.98it/s][A
 75%|███████▍  | 165/221 [00:44<00:10,  5.28it/s][A
 75%|███████▌  | 166/221 [00:44<00:11,  4.99it/s][A
 76%|███████▌  | 167/221 [00:44<00:09,  5.77it/s][A
 76%|███████▌  | 168/221 [00:45<00:10,  5.29it/s][A
 76%|███████▋  | 169/221 [00:45<00:09,  5.48it/s][A
 77%|███████▋  | 170/221 [00:45<00:15,  3.33it/s][A
 77%|███████▋  | 171/221 [00:46<00:14,  3.52it/s][A
 78%|███████▊  | 172/221 [00:46<00:12,  4.02it/s][A
 78%|███████▊  | 173/221 [00:46<00:13,  3.60it/s][A
 79%|███████▊  | 174/221 [00:47<00:17,  2.66it/s][A
 79%|███████▉  | 175/221 [00:47<00:17,  2.70it/s][A
 80%|███████▉  | 176/221 [00:47<00:14,  3.08it/s][A
 80%|████████  | 177/221 [00:47<00:12,  3.48it/s][A
 81%|████████  | 178/221 [00:48<00:11,  3.61it/s][A
 81%|████████  | 179/221 [00:48<00:11,  3.71it/s][A
 81%|████████▏ | 180/221 [00:48<00:09,  4.36it/s][A
 82%|████████▏ | 181/221 [00:48<00:08,  4.47it/s][A
 82%|████████▏ | 182/221 [00:49<00:11,  3.44it/s][A
 83%|████████▎ | 183/221 [00:49<00:10,  3.47it/s][A
 83%|████████▎ | 184/221 [00:49<00:09,  3.71it/s][A
 84%|████████▎ | 185/221 [00:49<00:07,  4.54it/s][A
 84%|████████▍ | 186/221 [00:50<00:09,  3.59it/s][A
 85%|████████▍ | 187/221 [00:50<00:09,  3.65it/s][A
 85%|████████▌ | 188/221 [00:50<00:09,  3.51it/s][A
 86%|████████▌ | 189/221 [00:51<00:08,  3.71it/s][A
 86%|████████▌ | 190/221 [00:51<00:09,  3.41it/s][A
 86%|████████▋ | 191/221 [00:51<00:07,  3.96it/s][A
 87%|████████▋ | 192/221 [00:51<00:07,  3.68it/s][A
 88%|████████▊ | 194/221 [00:52<00:07,  3.81it/s][A
 88%|████████▊ | 195/221 [00:52<00:06,  3.91it/s][A
 89%|████████▊ | 196/221 [00:53<00:09,  2.67it/s][A
 89%|████████▉ | 197/221 [00:53<00:08,  2.90it/s][A
 90%|████████▉ | 198/221 [00:54<00:08,  2.62it/s][A
 90%|█████████ | 199/221 [00:54<00:07,  2.98it/s][A
 90%|█████████ | 200/221 [00:54<00:07,  2.63it/s][A
 91%|█████████ | 201/221 [00:55<00:06,  2.98it/s][A
 91%|█████████▏| 202/221 [00:55<00:06,  2.90it/s][A
 92%|█████████▏| 203/221 [00:55<00:05,  3.21it/s][A
 92%|█████████▏| 204/221 [00:56<00:06,  2.70it/s][A
 93%|█████████▎| 205/221 [00:56<00:04,  3.44it/s][A
 93%|█████████▎| 206/221 [00:56<00:04,  3.17it/s][A
 94%|█████████▎| 207/221 [00:56<00:03,  3.96it/s][A
 94%|█████████▍| 208/221 [00:57<00:03,  3.73it/s][A
 95%|█████████▍| 209/221 [00:57<00:03,  3.59it/s][A
 95%|█████████▌| 211/221 [00:57<00:02,  4.10it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  3.92it/s][A
 96%|█████████▋| 213/221 [00:58<00:01,  4.04it/s][A
 97%|█████████▋| 214/221 [00:58<00:02,  3.00it/s][A
 97%|█████████▋| 215/221 [00:59<00:01,  3.45it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.63it/s][A
 98%|█████████▊| 217/221 [00:59<00:01,  3.41it/s][A
 99%|█████████▊| 218/221 [00:59<00:00,  3.20it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  2.97it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.39it/s][A
100%|██████████| 221/221 [01:00<00:00,  3.70it/s][A100%|██████████| 221/221 [01:00<00:00,  3.64it/s]
09/09/2024 20:04:30 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 549--===========

09/09/2024 20:04:30 - INFO - __main__ -   {'area_r1': 40.0, 'area_recall': '40.0/66.2/76.8', 'area_ravg': 61.0}
09/09/2024 20:04:30 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 549--===========

09/09/2024 20:04:30 - INFO - __main__ -   {'forward_r1': 36.2, 'forward_recall': '36.2/65.5/76.0', 'forward_ravg': 59.2}
09/09/2024 20:04:30 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 549--===========

09/09/2024 20:04:30 - INFO - __main__ -   {'area_video_r1': 38.9, 'area_video_recall': '38.9/66.9/78.1', 'area_video_ravg': 61.3}
09/09/2024 20:04:30 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/09/2024 20:04:30 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 20:04:30 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 549--===========

09/09/2024 20:04:30 - INFO - __main__ -   {'area_video_r1': 52.3, 'area_video_recall': '52.3/75.3/82.8', 'area_video_ravg': 70.1, 'area_video_back_r1': 50.1, 'area_video_back_recall': '50.1/74.5/82.4', 'area_video_back_ravg': 69.0}
09/09/2024 20:04:30 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/09/2024 20:04:30 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/09/2024 20:04:30 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 549--===========

09/09/2024 20:04:30 - INFO - __main__ -   {'video_r1': 42.6, 'video_recall': '42.6/70.0/81.9', 'video_ravg': 64.9}
09/09/2024 20:04:30 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 20:04:30 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 20:04:30 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 549--===========

09/09/2024 20:04:30 - INFO - __main__ -   {'video_r1': 51.5, 'video_recall': '51.5/75.5/82.5', 'video_ravg': 69.8}
09/09/2024 20:04:30 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/09/2024 20:04:30 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/09/2024 20:04:51 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.008071932010352612, 'loss_ret%tv%ta--finetune_area/loss_area': 1.1420378684997559, 'loss_ret%tv%ta--finetune_area/total_loss': 1.1501097679138184}
[h264 @ 0x559c0358c840] mmco: unref short failure
[h264 @ 0x559c0358c840] mmco: unref short failure
 28%|██▊       | 550/1945 [2:59:31<47:23:12, 122.29s/it][h264 @ 0x559bf9324340] mmco: unref short failure
 28%|██▊       | 551/1945 [2:59:36<33:37:24, 86.83s/it]  28%|██▊       | 552/1945 [2:59:40<24:05:01, 62.24s/it] 28%|██▊       | 553/1945 [2:59:47<17:33:13, 45.40s/it] 28%|██▊       | 554/1945 [2:59:52<12:57:16, 33.53s/it][h264 @ 0x55a0450f3000] mmco: unref short failure
[h264 @ 0x55a0450f3000] mmco: unref short failure
[h264 @ 0x562417627000] mmco: unref short failure
[h264 @ 0x562417627000] mmco: unref short failure
 29%|██▊       | 555/1945 [2:59:59<9:47:33, 25.36s/it] [h264 @ 0x55a04b8eb0c0] mmco: unref short failure
[h264 @ 0x55a04b8eb0c0] mmco: unref short failure
[h264 @ 0x55a04b8eb0c0] mmco: unref short failure
[h264 @ 0x55a04b8eb0c0] mmco: unref short failure
 29%|██▊       | 556/1945 [3:00:05<7:37:41, 19.77s/it][h264 @ 0x55a04b8eb0c0] mmco: unref short failure
[h264 @ 0x55a04b8eb0c0] mmco: unref short failure
[h264 @ 0x562429840880] mmco: unref short failure
[h264 @ 0x562429840880] mmco: unref short failure
[h264 @ 0x556b2fd95780] mmco: unref short failure
 29%|██▊       | 557/1945 [3:00:14<6:17:38, 16.32s/it][h264 @ 0x56242084fa40] mmco: unref short failure
[h264 @ 0x56241cb37980] mmco: unref short failure
[h264 @ 0x55a047817440] mmco: unref short failure
[h264 @ 0x559bfc038a80] mmco: unref short failure
[h264 @ 0x559bfc038a80] mmco: unref short failure
[h264 @ 0x56242e5ee740] mmco: unref short failure
[h264 @ 0x56242e5ee740] mmco: unref short failure
[h264 @ 0x56242b448dc0] mmco: unref short failure
 29%|██▊       | 558/1945 [3:00:21<5:13:55, 13.58s/it][h264 @ 0x559c035fe480] mmco: unref short failure
[h264 @ 0x559c035fe480] mmco: unref short failure
[h264 @ 0x559c035fe480] mmco: unref short failure
[h264 @ 0x559bf3339540] mmco: unref short failure
[h264 @ 0x559bf3339540] mmco: unref short failure
[h264 @ 0x559bf3339540] mmco: unref short failure
[h264 @ 0x559bf3339540] mmco: unref short failure
 29%|██▊       | 559/1945 [3:00:28<4:30:28, 11.71s/it] 29%|██▉       | 560/1945 [3:00:35<3:56:48, 10.26s/it][h264 @ 0x55a03c2c4e40] mmco: unref short failure
[h264 @ 0x562424cc1980] mmco: unref short failure
 29%|██▉       | 561/1945 [3:00:43<3:37:50,  9.44s/it][h264 @ 0x56242173f000] mmco: unref short failure
[h264 @ 0x56242173f000] mmco: unref short failure
[h264 @ 0x556b2c9b8980] mmco: unref short failure
[h264 @ 0x556b2c9b8980] mmco: unref short failure
 29%|██▉       | 562/1945 [3:00:51<3:29:05,  9.07s/it] 29%|██▉       | 563/1945 [3:00:58<3:14:26,  8.44s/it][h264 @ 0x55a03abb2cc0] mmco: unref short failure
[h264 @ 0x559c0a3be300] mmco: unref short failure
 29%|██▉       | 564/1945 [3:01:05<3:08:46,  8.20s/it] 29%|██▉       | 565/1945 [3:01:12<2:58:36,  7.77s/it][h264 @ 0x559bf609e440] mmco: unref short failure
[h264 @ 0x559bf609e440] mmco: unref short failure
[h264 @ 0x559bf609e440] mmco: unref short failure
[h264 @ 0x559bf609e440] mmco: unref short failure
 29%|██▉       | 566/1945 [3:01:19<2:52:25,  7.50s/it] 29%|██▉       | 567/1945 [3:01:26<2:48:54,  7.35s/it] 29%|██▉       | 568/1945 [3:01:35<3:02:18,  7.94s/it][h264 @ 0x56241baf79c0] mmco: unref short failure
 29%|██▉       | 569/1945 [3:01:46<3:16:56,  8.59s/it][h264 @ 0x56241c70d000] mmco: unref short failure
 29%|██▉       | 570/1945 [3:01:53<3:09:43,  8.28s/it][h264 @ 0x562434a8d840] mmco: unref short failure
[h264 @ 0x562434a8d840] mmco: unref short failure
[h264 @ 0x55a04878a8c0] mmco: unref short failure
[h264 @ 0x55a04878a8c0] mmco: unref short failure
 29%|██▉       | 571/1945 [3:02:09<4:03:27, 10.63s/it][h264 @ 0x56241a68cc00] mmco: unref short failure
 29%|██▉       | 572/1945 [3:02:17<3:43:55,  9.79s/it][h264 @ 0x55a03c343bc0] mmco: unref short failure
[h264 @ 0x55a03c343bc0] mmco: unref short failure
 29%|██▉       | 573/1945 [3:02:24<3:23:53,  8.92s/it][h264 @ 0x559c0a9c1b80] mmco: unref short failure
[h264 @ 0x559c0a9c1b80] mmco: unref short failure
[h264 @ 0x556b306a84c0] mmco: unref short failure
[h264 @ 0x556b306a84c0] mmco: unref short failure
[h264 @ 0x556b2d5e6f40] mmco: unref short failure
[h264 @ 0x556b2d5e6f40] mmco: unref short failure
[h264 @ 0x5624210c6500] mmco: unref short failure
[h264 @ 0x5624210c6500] mmco: unref short failure
[h264 @ 0x559c08234ac0] mmco: unref short failure
[h264 @ 0x559c08234ac0] mmco: unref short failure
[h264 @ 0x562432590c40] mmco: unref short failure
[h264 @ 0x562432590c40] mmco: unref short failure
[h264 @ 0x56241dc30440] mmco: unref short failure
[h264 @ 0x559bec27c840] mmco: unref short failure
[h264 @ 0x559bec27c840] mmco: unref short failure
[h264 @ 0x559c00504d00] mmco: unref short failure
[h264 @ 0x559c00504d00] mmco: unref short failure
[h264 @ 0x559be98df640] mmco: unref short failure
[h264 @ 0x559be98df640] mmco: unref short failure
[h264 @ 0x559c01ea6000] mmco: unref short failure
[h264 @ 0x559c01ea6000] mmco: unref short failure
[h264 @ 0x556b2ee5e640] mmco: unref short failure
[h264 @ 0x556b2ee5e640] mmco: unref short failure
[h264 @ 0x559c0100aac0] mmco: unref short failure
[h264 @ 0x556b4c1ba740] mmco: unref short failure
[h264 @ 0x556b318b3640] mmco: unref short failure
[h264 @ 0x556b318b3640] mmco: unref short failure
[h264 @ 0x562426f42a00] mmco: unref short failure
[h264 @ 0x562426f42a00] mmco: unref short failure
 30%|██▉       | 574/1945 [3:03:07<7:20:32, 19.28s/it] 30%|██▉       | 575/1945 [3:03:29<7:38:45, 20.09s/it][h264 @ 0x559bffa10280] mmco: unref short failure
[h264 @ 0x562429d50380] mmco: unref short failure
[h264 @ 0x562429d50380] mmco: unref short failure
 30%|██▉       | 576/1945 [3:03:37<6:14:19, 16.41s/it][h264 @ 0x559beb046e80] mmco: unref short failure
[h264 @ 0x559beb046e80] mmco: unref short failure
 30%|██▉       | 577/1945 [3:03:45<5:17:48, 13.94s/it][h264 @ 0x556b2cb0c3c0] mmco: unref short failure
[h264 @ 0x556b2cb0c3c0] mmco: unref short failure
[h264 @ 0x556b2cb0c3c0] mmco: unref short failure
[h264 @ 0x559bee462d00] mmco: unref short failure
[h264 @ 0x559bf1a66240] mmco: unref short failure
[h264 @ 0x556b37af2100] mmco: unref short failure
[h264 @ 0x556b37af2100] mmco: unref short failure
[h264 @ 0x556b349b1080] mmco: unref short failure
[h264 @ 0x556b349b1080] mmco: unref short failure
 30%|██▉       | 578/1945 [3:04:00<5:23:02, 14.18s/it][h264 @ 0x562435bbe5c0] mmco: unref short failure
[h264 @ 0x562435bbe5c0] mmco: unref short failure
[h264 @ 0x556b37af1a40] mmco: unref short failure
[h264 @ 0x556b37af1a40] mmco: unref short failure
 30%|██▉       | 579/1945 [3:04:10<4:55:27, 12.98s/it] 30%|██▉       | 580/1945 [3:04:18<4:18:38, 11.37s/it][h264 @ 0x55a03a7a8740] mmco: unref short failure
[h264 @ 0x55a03a7a8740] mmco: unref short failure
[h264 @ 0x55a03972a180] mmco: unref short failure
[h264 @ 0x55a03972a180] mmco: unref short failure
[h264 @ 0x55a03972a180] mmco: unref short failure
[h264 @ 0x55a03972a180] mmco: unref short failure
 30%|██▉       | 581/1945 [3:04:25<3:50:27, 10.14s/it][h264 @ 0x556b368777c0] mmco: unref short failure
[h264 @ 0x562427c09600] mmco: unref short failure
[h264 @ 0x562427c09600] mmco: unref short failure
[h264 @ 0x562434bf1040] mmco: unref short failure
[h264 @ 0x562434bf1040] mmco: unref short failure
[h264 @ 0x55a03c9d5540] mmco: unref short failure
[h264 @ 0x55a046872600] mmco: unref short failure
[h264 @ 0x559bfe66aec0] mmco: unref short failure
[h264 @ 0x556b475f01c0] mmco: unref short failure
[h264 @ 0x556b475f01c0] mmco: unref short failure
[h264 @ 0x562432964500] mmco: unref short failure
[h264 @ 0x562432964500] mmco: unref short failure
[h264 @ 0x559bed72e040] mmco: unref short failure
[h264 @ 0x559bf3239240] mmco: unref short failure
 30%|██▉       | 582/1945 [3:05:06<7:19:58, 19.37s/it][h264 @ 0x55a034b99c80] mmco: unref short failure
[h264 @ 0x55a034b99c80] mmco: unref short failure
[h264 @ 0x559bebb2a780] mmco: unref short failure
[h264 @ 0x55a034b9c7c0] mmco: unref short failure
[h264 @ 0x55a032ecfd40] mmco: unref short failure
[h264 @ 0x556b308f4ac0] mmco: unref short failure
[h264 @ 0x556b43ca3680] mmco: unref short failure
[h264 @ 0x556b43ca3680] mmco: unref short failure
[h264 @ 0x559bebcfac00] mmco: unref short failure
[h264 @ 0x55a0332dac00] mmco: unref short failure
[h264 @ 0x559c0e410740] mmco: unref short failure
[h264 @ 0x559c0e410740] mmco: unref short failure
 30%|██▉       | 583/1945 [3:05:31<8:01:01, 21.19s/it][h264 @ 0x5624236df1c0] mmco: unref short failure
[h264 @ 0x5624236df1c0] mmco: unref short failure
[h264 @ 0x556b2cca1980] mmco: unref short failure
[h264 @ 0x556b2cca1980] mmco: unref short failure
[h264 @ 0x55a03ce84000] mmco: unref short failure
[h264 @ 0x55a052d86ac0] mmco: unref short failure
 30%|███       | 584/1945 [3:05:48<7:26:33, 19.69s/it][h264 @ 0x559bf5bac280] mmco: unref short failure
[h264 @ 0x559bf5bac280] mmco: unref short failure
 30%|███       | 585/1945 [3:05:55<5:59:52, 15.88s/it][h264 @ 0x55a04f867940] mmco: unref short failure
[h264 @ 0x556b3dc07080] mmco: unref short failure
[h264 @ 0x556b3dc07080] mmco: unref short failure
 30%|███       | 586/1945 [3:06:05<5:20:47, 14.16s/it][h264 @ 0x562421a03c80] mmco: unref short failure
[h264 @ 0x562421a03c80] mmco: unref short failure
[h264 @ 0x559bee6b1e80] mmco: unref short failure
[h264 @ 0x562416a46d40] mmco: unref short failure
[h264 @ 0x562416a46d40] mmco: unref short failure
[h264 @ 0x562416a46d40] mmco: unref short failure
[h264 @ 0x562416a46d40] mmco: unref short failure
[h264 @ 0x55a04f201e40] mmco: unref short failure
[h264 @ 0x55a04f201e40] mmco: unref short failure
 30%|███       | 587/1945 [3:06:15<4:55:29, 13.06s/it][h264 @ 0x556b4d9dcd00] mmco: unref short failure
 30%|███       | 588/1945 [3:06:23<4:20:35, 11.52s/it][h264 @ 0x55a04d549680] mmco: unref short failure
[h264 @ 0x55a04d549680] mmco: unref short failure
[h264 @ 0x55a0332da580] mmco: unref short failure
[h264 @ 0x56241ee246c0] mmco: unref short failure
[h264 @ 0x56241ee246c0] mmco: unref short failure
[h264 @ 0x5624318f7b00] mmco: unref short failure
 30%|███       | 589/1945 [3:06:31<3:55:45, 10.43s/it][h264 @ 0x556b2d552f80] mmco: unref short failure
[h264 @ 0x556b2d552f80] mmco: unref short failure
[h264 @ 0x55a034934140] mmco: unref short failure
[h264 @ 0x55a034934140] mmco: unref short failure
[h264 @ 0x559c0be69940] mmco: unref short failure
[h264 @ 0x559c0be69940] mmco: unref short failure
[h264 @ 0x559bf599e540] mmco: unref short failure
[h264 @ 0x559c05d93980] mmco: unref short failure
[h264 @ 0x559c0918e240] mmco: unref short failure
[h264 @ 0x559c0918e240] mmco: unref short failure
[h264 @ 0x559c0918e240] mmco: unref short failure
[h264 @ 0x559c0918e240] mmco: unref short failure
[h264 @ 0x559bf0941dc0] mmco: unref short failure
[h264 @ 0x559bf0941dc0] mmco: unref short failure
[h264 @ 0x56241c724600] mmco: unref short failure
[h264 @ 0x559be8f00c00] mmco: unref short failure
[h264 @ 0x559be8f00c00] mmco: unref short failure
[h264 @ 0x55a04878a8c0] mmco: unref short failure
[h264 @ 0x55a04878a8c0] mmco: unref short failure
[h264 @ 0x55a0521cda80] mmco: unref short failure
[h264 @ 0x559bf093bd40] mmco: unref short failure
[h264 @ 0x559be9184040] mmco: unref short failure
[h264 @ 0x559be9184040] mmco: unref short failure
[h264 @ 0x559be9184040] mmco: unref short failure
 30%|███       | 590/1945 [3:07:07<6:46:34, 18.00s/it][h264 @ 0x556b39515440] mmco: unref short failure
[h264 @ 0x556b39515440] mmco: unref short failure
[h264 @ 0x5624319d13c0] mmco: unref short failure
[h264 @ 0x556b32b2a7c0] mmco: unref short failure
[h264 @ 0x556b32b2a7c0] mmco: unref short failure
[h264 @ 0x559bf43d8a80] mmco: unref short failure
[h264 @ 0x559bf43d8a80] mmco: unref short failure
[h264 @ 0x55a03dc1c380] mmco: unref short failure
[h264 @ 0x55a03dc1c380] mmco: unref short failure
[h264 @ 0x55a03dc1c380] mmco: unref short failure
[h264 @ 0x55a03dc1c380] mmco: unref short failure
[h264 @ 0x55a043e32000] mmco: unref short failure
[h264 @ 0x55a043e32000] mmco: unref short failure
 30%|███       | 591/1945 [3:07:32<7:37:52, 20.29s/it][h264 @ 0x556b2f7b9880] mmco: unref short failure
[h264 @ 0x556b2f7b9880] mmco: unref short failure
[h264 @ 0x559c0bc2a400] mmco: unref short failure
[h264 @ 0x559c0bc2a400] mmco: unref short failure
 30%|███       | 592/1945 [3:07:48<7:06:09, 18.90s/it][h264 @ 0x556b30dd42c0] mmco: unref short failure
[h264 @ 0x559beba89480] mmco: unref short failure
[h264 @ 0x559beba89480] mmco: unref short failure
 30%|███       | 593/1945 [3:07:59<6:14:58, 16.64s/it] 31%|███       | 594/1945 [3:08:07<5:12:52, 13.89s/it] 31%|███       | 595/1945 [3:08:15<4:31:09, 12.05s/it][h264 @ 0x56241731a540] mmco: unref short failure
 31%|███       | 596/1945 [3:08:22<3:57:47, 10.58s/it][h264 @ 0x556b2f274400] mmco: unref short failure
 31%|███       | 597/1945 [3:08:29<3:32:13,  9.45s/it][h264 @ 0x55a051c75380] mmco: unref short failure
[h264 @ 0x55a051c75380] mmco: unref short failure
[h264 @ 0x55a040e76cc0] mmco: unref short failure
[h264 @ 0x55a040e76cc0] mmco: unref short failure
[h264 @ 0x55a040e76cc0] mmco: unref short failure
[h264 @ 0x55a040e76cc0] mmco: unref short failure
[h264 @ 0x556b312eb100] mmco: unref short failure
[h264 @ 0x55a04552dd80] mmco: unref short failure
[h264 @ 0x556b2efb1b00] mmco: unref short failure
[h264 @ 0x559bf39a8b00] mmco: unref short failure
not have audios ua_Kowav7hg.20
 31%|███       | 598/1945 [3:09:05<6:31:16, 17.43s/it][h264 @ 0x556b4d9dcd00] mmco: unref short failure
[h264 @ 0x556b4993d3c0] mmco: unref short failure
[h264 @ 0x55a03567ce80] mmco: unref short failure
[h264 @ 0x55a03567ce80] mmco: unref short failure
[h264 @ 0x55a04d399f80] mmco: unref short failure
[h264 @ 0x55a04d399f80] mmco: unref short failure
[h264 @ 0x559be993aa40] mmco: unref short failure
 31%|███       | 599/1945 [3:09:28<7:08:55, 19.12s/it]09/09/2024 20:14:50 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 20:14:50 - INFO - __main__ -   start running ret%tv validation...
[h264 @ 0x556b32087e00] mmco: unref short failure
[h264 @ 0x556b32087e00] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559c06fd4180] mmco: unref short failure
[h264 @ 0x56241e250a40] mmco: unref short failure
[h264 @ 0x5624205a46c0] mmco: unref short failure
[h264 @ 0x5624205a46c0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559be9f048c0] mmco: unref short failure
[h264 @ 0x559be9f048c0] mmco: unref short failure
[h264 @ 0x556b2e349c40] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x56241cb86540] mmco: unref short failure
[h264 @ 0x56241cb86540] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x562434720300] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a03718e940] mmco: unref short failure
[h264 @ 0x562432f16580] mmco: unref short failure
[h264 @ 0x55a04a480e40] mmco: unref short failure
[h264 @ 0x55a04a480e40] mmco: unref short failure
[h264 @ 0x55a037105ac0] mmco: unref short failure
[h264 @ 0x559bff8592c0] mmco: unref short failure
[h264 @ 0x559bf03febc0] mmco: unref short failure
[h264 @ 0x559bf3d9ecc0] mmco: unref short failure
[h264 @ 0x559bf3d9ecc0] mmco: unref short failure
[h264 @ 0x559bec69bc00] mmco: unref short failure
[h264 @ 0x559bec69bc00] mmco: unref short failure
[h264 @ 0x559bf5730f80] mmco: unref short failure
[h264 @ 0x556b41956d40] mmco: unref short failure
[h264 @ 0x556b41956d40] mmco: unref short failure
[h264 @ 0x559beaf74e00] mmco: unref short failure
[h264 @ 0x556b3ea41d80] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:58,  1.86it/s][A
  1%|          | 2/221 [00:01<02:03,  1.78it/s][A
  1%|▏         | 3/221 [00:01<01:30,  2.40it/s][A
  2%|▏         | 4/221 [00:01<01:11,  3.03it/s][A
  2%|▏         | 5/221 [00:01<01:00,  3.60it/s][A
  3%|▎         | 6/221 [00:01<00:49,  4.35it/s][A
  3%|▎         | 7/221 [00:02<00:48,  4.39it/s][A[h264 @ 0x556b2e24bb40] mmco: unref short failure
[h264 @ 0x556b2e24bb40] mmco: unref short failure

  4%|▎         | 8/221 [00:02<01:17,  2.75it/s][A
  4%|▍         | 9/221 [00:03<01:10,  3.00it/s][A
  5%|▍         | 10/221 [00:03<01:18,  2.70it/s][A
  5%|▌         | 12/221 [00:03<01:01,  3.40it/s][A
  6%|▌         | 13/221 [00:04<00:55,  3.77it/s][A
  6%|▋         | 14/221 [00:05<01:57,  1.76it/s][A
  7%|▋         | 15/221 [00:05<01:41,  2.02it/s][A
  7%|▋         | 16/221 [00:06<01:37,  2.11it/s][A
  8%|▊         | 17/221 [00:06<01:27,  2.32it/s][A
  8%|▊         | 18/221 [00:06<01:20,  2.53it/s][A[h264 @ 0x55a034933f40] mmco: unref short failure
[h264 @ 0x55a034933f40] mmco: unref short failure

  9%|▊         | 19/221 [00:06<01:04,  3.14it/s][A[h264 @ 0x559bf56a3b40] mmco: unref short failure

  9%|▉         | 20/221 [00:07<01:00,  3.34it/s][A
 10%|▉         | 21/221 [00:07<00:58,  3.42it/s][A
 10%|▉         | 22/221 [00:07<00:54,  3.68it/s][A
 11%|█         | 24/221 [00:07<00:39,  5.05it/s][A
 11%|█▏        | 25/221 [00:08<00:38,  5.09it/s][A
 12%|█▏        | 26/221 [00:08<00:39,  4.89it/s][A
 12%|█▏        | 27/221 [00:08<00:34,  5.62it/s][A
 13%|█▎        | 28/221 [00:08<00:51,  3.73it/s][A
 13%|█▎        | 29/221 [00:09<00:45,  4.22it/s][A
 14%|█▎        | 30/221 [00:09<00:57,  3.30it/s][A
 14%|█▍        | 31/221 [00:09<00:56,  3.33it/s][A
 14%|█▍        | 32/221 [00:10<00:52,  3.62it/s][A
 15%|█▍        | 33/221 [00:10<00:55,  3.40it/s][A
 15%|█▌        | 34/221 [00:10<00:44,  4.17it/s][A
 16%|█▌        | 35/221 [00:10<00:39,  4.72it/s][A
 16%|█▋        | 36/221 [00:11<00:46,  4.00it/s][A
 17%|█▋        | 37/221 [00:11<01:04,  2.83it/s][A[h264 @ 0x556b3dc34bc0] mmco: unref short failure
[h264 @ 0x556b3dc34bc0] mmco: unref short failure

 17%|█▋        | 38/221 [00:12<01:06,  2.77it/s][A
 18%|█▊        | 39/221 [00:12<00:52,  3.49it/s][A
 18%|█▊        | 40/221 [00:12<00:56,  3.19it/s][A
 19%|█▊        | 41/221 [00:12<00:45,  4.00it/s][A[h264 @ 0x556b3fad0dc0] mmco: unref short failure
[h264 @ 0x556b3fad0dc0] mmco: unref short failure

 19%|█▉        | 42/221 [00:13<00:59,  3.02it/s][A
 19%|█▉        | 43/221 [00:13<00:53,  3.30it/s][A
 20%|█▉        | 44/221 [00:13<00:47,  3.76it/s][A[h264 @ 0x55a032ee2940] mmco: unref short failure

 20%|██        | 45/221 [00:14<01:24,  2.08it/s][A
 21%|██        | 46/221 [00:14<01:21,  2.16it/s][A
 21%|██▏       | 47/221 [00:15<01:30,  1.92it/s][A
 22%|██▏       | 48/221 [00:15<01:20,  2.14it/s][A
 22%|██▏       | 49/221 [00:16<01:06,  2.58it/s][A
 23%|██▎       | 50/221 [00:16<00:55,  3.06it/s][A
 23%|██▎       | 51/221 [00:16<00:51,  3.30it/s][A
 24%|██▎       | 52/221 [00:16<00:44,  3.84it/s][A
 24%|██▍       | 53/221 [00:16<00:39,  4.21it/s][A
 24%|██▍       | 54/221 [00:18<01:41,  1.65it/s][A
 25%|██▍       | 55/221 [00:18<01:27,  1.90it/s][A
 25%|██▌       | 56/221 [00:18<01:12,  2.27it/s][A
 26%|██▌       | 57/221 [00:19<00:59,  2.76it/s][A
 27%|██▋       | 59/221 [00:19<00:42,  3.80it/s][A
 27%|██▋       | 60/221 [00:19<00:52,  3.08it/s][A
 28%|██▊       | 61/221 [00:20<00:49,  3.24it/s][A
 28%|██▊       | 62/221 [00:20<00:44,  3.60it/s][A
 29%|██▊       | 63/221 [00:20<00:42,  3.70it/s][A
 29%|██▉       | 64/221 [00:20<00:38,  4.08it/s][A
 29%|██▉       | 65/221 [00:21<00:36,  4.26it/s][A
 30%|██▉       | 66/221 [00:21<00:47,  3.27it/s][A[h264 @ 0x55a037e60800] mmco: unref short failure

 30%|███       | 67/221 [00:22<00:54,  2.82it/s][A
 31%|███       | 68/221 [00:22<00:46,  3.27it/s][A
 31%|███       | 69/221 [00:24<02:04,  1.22it/s][A
 32%|███▏      | 70/221 [00:24<01:34,  1.61it/s][A
 32%|███▏      | 71/221 [00:25<01:56,  1.29it/s][A[h264 @ 0x556b3b2fa140] mmco: unref short failure
[h264 @ 0x556b3b2fa140] mmco: unref short failure

 33%|███▎      | 72/221 [00:25<01:33,  1.60it/s][A
 33%|███▎      | 73/221 [00:26<01:21,  1.81it/s][A
 33%|███▎      | 74/221 [00:26<01:06,  2.21it/s][A
 34%|███▍      | 75/221 [00:26<01:01,  2.37it/s][A
 34%|███▍      | 76/221 [00:26<00:49,  2.95it/s][A
 35%|███▍      | 77/221 [00:27<00:42,  3.36it/s][A[h264 @ 0x556b475859c0] mmco: unref short failure

 35%|███▌      | 78/221 [00:27<00:41,  3.46it/s][A[h264 @ 0x559bea1f5ec0] mmco: unref short failure
[h264 @ 0x559bea1f5ec0] mmco: unref short failure

 36%|███▌      | 79/221 [00:28<00:57,  2.45it/s][A
 36%|███▌      | 80/221 [00:28<00:48,  2.91it/s][A
 37%|███▋      | 81/221 [00:28<00:47,  2.96it/s][A
 37%|███▋      | 82/221 [00:28<00:40,  3.43it/s][A
 38%|███▊      | 83/221 [00:28<00:34,  4.05it/s][A
 38%|███▊      | 84/221 [00:29<00:37,  3.62it/s][A[h264 @ 0x55a03579a000] mmco: unref short failure

 38%|███▊      | 85/221 [00:29<00:32,  4.25it/s][A
 39%|███▉      | 86/221 [00:29<00:31,  4.33it/s][A
 39%|███▉      | 87/221 [00:30<00:48,  2.74it/s][A
 40%|███▉      | 88/221 [00:30<00:52,  2.52it/s][A
 40%|████      | 89/221 [00:32<01:27,  1.50it/s][A
 41%|████      | 90/221 [00:32<01:14,  1.76it/s][A
 41%|████      | 91/221 [00:32<01:01,  2.11it/s][A
 42%|████▏     | 92/221 [00:32<00:53,  2.43it/s][A
 42%|████▏     | 93/221 [00:33<00:49,  2.59it/s][A
 43%|████▎     | 94/221 [00:33<00:45,  2.78it/s][A
 43%|████▎     | 95/221 [00:33<00:39,  3.19it/s][A
 43%|████▎     | 96/221 [00:34<00:44,  2.84it/s][A
 44%|████▍     | 97/221 [00:34<00:42,  2.89it/s][A
 44%|████▍     | 98/221 [00:34<00:42,  2.87it/s][A
 45%|████▍     | 99/221 [00:34<00:34,  3.58it/s][A
 45%|████▌     | 100/221 [00:35<00:31,  3.86it/s][A
 46%|████▌     | 101/221 [00:35<00:28,  4.21it/s][A
 46%|████▌     | 102/221 [00:35<00:33,  3.54it/s][A
 47%|████▋     | 103/221 [00:35<00:30,  3.93it/s][A
 47%|████▋     | 104/221 [00:36<00:24,  4.72it/s][A
 48%|████▊     | 105/221 [00:36<00:25,  4.61it/s][A
 48%|████▊     | 106/221 [00:37<00:48,  2.40it/s][A
 48%|████▊     | 107/221 [00:37<00:37,  3.02it/s][A
 49%|████▉     | 108/221 [00:37<00:32,  3.47it/s][A
 49%|████▉     | 109/221 [00:37<00:30,  3.67it/s][A
 50%|████▉     | 110/221 [00:38<00:31,  3.47it/s][A
 50%|█████     | 111/221 [00:38<00:35,  3.07it/s][A
 51%|█████     | 112/221 [00:38<00:30,  3.56it/s][A[h264 @ 0x556b458c3dc0] mmco: unref short failure
[h264 @ 0x556b458c3dc0] mmco: unref short failure
[h264 @ 0x556b458c3dc0] mmco: unref short failure
[h264 @ 0x556b458c3dc0] mmco: unref short failure
[h264 @ 0x556b458c3dc0] mmco: unref short failure
[h264 @ 0x556b458c3dc0] mmco: unref short failure

 51%|█████     | 113/221 [00:38<00:32,  3.35it/s][A
 52%|█████▏    | 115/221 [00:39<00:21,  4.98it/s][A
 52%|█████▏    | 116/221 [00:42<01:36,  1.08it/s][A
 53%|█████▎    | 117/221 [00:42<01:21,  1.28it/s][A
 53%|█████▎    | 118/221 [00:42<01:05,  1.57it/s][A
 54%|█████▍    | 119/221 [00:43<00:51,  1.98it/s][A
 54%|█████▍    | 120/221 [00:43<00:46,  2.19it/s][A
 55%|█████▍    | 121/221 [00:43<00:39,  2.53it/s][A
 55%|█████▌    | 122/221 [00:43<00:34,  2.90it/s][A
 56%|█████▌    | 123/221 [00:44<00:28,  3.47it/s][A
 56%|█████▌    | 124/221 [00:44<00:24,  3.88it/s][A
 57%|█████▋    | 125/221 [00:44<00:28,  3.40it/s][A
 57%|█████▋    | 126/221 [00:44<00:29,  3.23it/s][A[h264 @ 0x559bef527880] mmco: unref short failure
[h264 @ 0x559bef527880] mmco: unref short failure

 57%|█████▋    | 127/221 [00:45<00:40,  2.34it/s][A
 58%|█████▊    | 128/221 [00:45<00:36,  2.57it/s][A
 58%|█████▊    | 129/221 [00:46<00:29,  3.07it/s][A
 59%|█████▉    | 130/221 [00:46<00:28,  3.25it/s][A
 60%|█████▉    | 132/221 [00:46<00:19,  4.53it/s][A
 60%|██████    | 133/221 [00:47<00:23,  3.75it/s][A
 61%|██████    | 134/221 [00:47<00:22,  3.82it/s][A
 61%|██████    | 135/221 [00:47<00:21,  3.94it/s][A
 62%|██████▏   | 136/221 [00:47<00:24,  3.51it/s][A
 62%|██████▏   | 137/221 [00:48<00:21,  4.00it/s][A
 62%|██████▏   | 138/221 [00:48<00:22,  3.63it/s][A
 63%|██████▎   | 139/221 [00:48<00:24,  3.34it/s][A
 63%|██████▎   | 140/221 [00:49<00:24,  3.30it/s][A[h264 @ 0x55a037e60800] mmco: unref short failure

 64%|██████▍   | 141/221 [00:49<00:20,  3.82it/s][A
 64%|██████▍   | 142/221 [00:49<00:23,  3.39it/s][A
 65%|██████▍   | 143/221 [00:50<00:25,  3.02it/s][A
 65%|██████▌   | 144/221 [00:50<00:23,  3.26it/s][A
 66%|██████▌   | 146/221 [00:50<00:16,  4.65it/s][A
 67%|██████▋   | 147/221 [00:50<00:14,  4.95it/s][A
 67%|██████▋   | 148/221 [00:50<00:16,  4.37it/s][A
 68%|██████▊   | 150/221 [00:51<00:13,  5.16it/s][A
 68%|██████▊   | 151/221 [00:52<00:25,  2.73it/s][A
 69%|██████▉   | 152/221 [00:52<00:24,  2.78it/s][A
 69%|██████▉   | 153/221 [00:52<00:23,  2.92it/s][A
 70%|██████▉   | 154/221 [00:53<00:22,  2.93it/s][A
 70%|███████   | 155/221 [00:53<00:18,  3.58it/s][A
 71%|███████   | 156/221 [00:53<00:15,  4.13it/s][A
 71%|███████   | 157/221 [00:54<00:23,  2.68it/s][A
 71%|███████▏  | 158/221 [00:54<00:21,  2.99it/s][A
 72%|███████▏  | 159/221 [00:54<00:17,  3.49it/s][A
 72%|███████▏  | 160/221 [00:54<00:16,  3.75it/s][A
 73%|███████▎  | 161/221 [00:54<00:13,  4.38it/s][A
 73%|███████▎  | 162/221 [00:54<00:11,  5.04it/s][A
 74%|███████▍  | 163/221 [00:55<00:12,  4.66it/s][A
 74%|███████▍  | 164/221 [00:55<00:10,  5.50it/s][A
 75%|███████▍  | 165/221 [00:55<00:08,  6.28it/s][A
 75%|███████▌  | 166/221 [00:55<00:11,  4.67it/s][A
 76%|███████▌  | 167/221 [00:56<00:11,  4.76it/s][A
 76%|███████▌  | 168/221 [00:57<00:26,  2.03it/s][A
 76%|███████▋  | 169/221 [00:57<00:20,  2.50it/s][A
 77%|███████▋  | 170/221 [00:57<00:17,  2.86it/s][A
 77%|███████▋  | 171/221 [00:57<00:16,  3.03it/s][A
 78%|███████▊  | 172/221 [00:58<00:15,  3.21it/s][A
 78%|███████▊  | 173/221 [00:58<00:12,  3.91it/s][A
 79%|███████▉  | 175/221 [00:58<00:09,  5.04it/s][A
 80%|███████▉  | 176/221 [00:58<00:10,  4.38it/s][A
 80%|████████  | 177/221 [00:58<00:09,  4.86it/s][A
 81%|████████  | 178/221 [00:59<00:09,  4.68it/s][A
 81%|████████  | 179/221 [00:59<00:10,  3.82it/s][A
 82%|████████▏ | 181/221 [00:59<00:08,  4.85it/s][A
 82%|████████▏ | 182/221 [01:00<00:07,  5.06it/s][A
 83%|████████▎ | 183/221 [01:00<00:07,  4.97it/s][A
 83%|████████▎ | 184/221 [01:00<00:08,  4.33it/s][A
 84%|████████▎ | 185/221 [01:00<00:07,  4.62it/s][A
 84%|████████▍ | 186/221 [01:01<00:10,  3.45it/s][A
 85%|████████▍ | 187/221 [01:01<00:08,  3.98it/s][A[h264 @ 0x55a03422d900] mmco: unref short failure
[h264 @ 0x55a03422d900] mmco: unref short failure

 85%|████████▌ | 188/221 [01:01<00:08,  3.92it/s][A
 86%|████████▌ | 189/221 [01:01<00:07,  4.25it/s][A
 86%|████████▌ | 190/221 [01:02<00:08,  3.57it/s][A
 87%|████████▋ | 192/221 [01:02<00:06,  4.63it/s][A
 88%|████████▊ | 194/221 [01:03<00:07,  3.57it/s][A
 88%|████████▊ | 195/221 [01:03<00:06,  4.02it/s][A
 89%|████████▊ | 196/221 [01:03<00:05,  4.69it/s][A
 89%|████████▉ | 197/221 [01:03<00:04,  5.23it/s][A
 90%|████████▉ | 198/221 [01:04<00:06,  3.52it/s][A
 90%|█████████ | 199/221 [01:04<00:05,  4.11it/s][A
 90%|█████████ | 200/221 [01:04<00:05,  3.58it/s][A
 91%|█████████ | 201/221 [01:04<00:05,  3.94it/s][A
 91%|█████████▏| 202/221 [01:05<00:04,  4.11it/s][A
 92%|█████████▏| 203/221 [01:05<00:04,  4.44it/s][A
 92%|█████████▏| 204/221 [01:05<00:03,  5.24it/s][A
 93%|█████████▎| 206/221 [01:06<00:04,  3.65it/s][A
 94%|█████████▍| 208/221 [01:06<00:02,  4.90it/s][A
 95%|█████████▍| 209/221 [01:06<00:02,  5.45it/s][A
 95%|█████████▌| 210/221 [01:06<00:01,  5.94it/s][A
 95%|█████████▌| 211/221 [01:06<00:02,  4.93it/s][A
 96%|█████████▌| 212/221 [01:06<00:01,  5.57it/s][A
 97%|█████████▋| 214/221 [01:07<00:01,  4.59it/s][A
 97%|█████████▋| 215/221 [01:07<00:01,  4.68it/s][A
 98%|█████████▊| 216/221 [01:07<00:01,  4.30it/s][A
 98%|█████████▊| 217/221 [01:08<00:01,  3.84it/s][A
 99%|█████████▊| 218/221 [01:08<00:00,  3.84it/s][A
 99%|█████████▉| 219/221 [01:08<00:00,  3.95it/s][A
100%|█████████▉| 220/221 [01:10<00:00,  1.51it/s][A
100%|██████████| 221/221 [01:10<00:00,  1.92it/s][A100%|██████████| 221/221 [01:10<00:00,  3.13it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:51,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:22<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:36,  3.52it/s][A
 42%|████▏     | 92/221 [00:24<00:35,  3.59it/s][A
 42%|████▏     | 93/221 [00:24<00:35,  3.65it/s][A
 43%|████▎     | 94/221 [00:24<00:34,  3.69it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.72it/s][A
 43%|████▎     | 96/221 [00:25<00:33,  3.74it/s][A
 44%|████▍     | 97/221 [00:25<00:33,  3.76it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.77it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.77it/s][A
 45%|████▌     | 100/221 [00:26<00:32,  3.78it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.78it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:28<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:42<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:47<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:52<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:57<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:32,  6.73it/s][A
  1%|          | 2/221 [00:00<00:54,  4.03it/s][A
  1%|▏         | 3/221 [00:00<01:00,  3.63it/s][A
  2%|▏         | 4/221 [00:00<00:51,  4.20it/s][A
  2%|▏         | 5/221 [00:01<00:47,  4.54it/s][A
  3%|▎         | 7/221 [00:01<00:43,  4.97it/s][A
  4%|▎         | 8/221 [00:01<00:50,  4.24it/s][A
  4%|▍         | 9/221 [00:02<00:48,  4.34it/s][A
  5%|▍         | 10/221 [00:02<01:03,  3.33it/s][A
  5%|▍         | 11/221 [00:02<00:58,  3.61it/s][A
  5%|▌         | 12/221 [00:02<00:50,  4.11it/s][A
  6%|▌         | 13/221 [00:03<01:30,  2.29it/s][A
  7%|▋         | 15/221 [00:04<01:02,  3.31it/s][A
  7%|▋         | 16/221 [00:04<01:05,  3.12it/s][A
  8%|▊         | 17/221 [00:05<01:26,  2.35it/s][A
  8%|▊         | 18/221 [00:05<01:14,  2.73it/s][A
  9%|▊         | 19/221 [00:05<01:05,  3.08it/s][A
  9%|▉         | 20/221 [00:05<00:52,  3.82it/s][A
 10%|▉         | 21/221 [00:05<00:46,  4.32it/s][A
 10%|▉         | 22/221 [00:06<00:43,  4.58it/s][A
 11%|█         | 24/221 [00:06<00:34,  5.77it/s][A
 11%|█▏        | 25/221 [00:06<00:36,  5.34it/s][A
 12%|█▏        | 26/221 [00:06<00:41,  4.71it/s][A
 12%|█▏        | 27/221 [00:06<00:36,  5.32it/s][A
 13%|█▎        | 28/221 [00:07<00:46,  4.14it/s][A
 13%|█▎        | 29/221 [00:07<00:44,  4.34it/s][A
 14%|█▎        | 30/221 [00:07<00:48,  3.97it/s][A
 14%|█▍        | 31/221 [00:08<00:45,  4.21it/s][A
 15%|█▍        | 33/221 [00:08<00:34,  5.47it/s][A
 15%|█▌        | 34/221 [00:08<00:33,  5.55it/s][A
 16%|█▌        | 35/221 [00:08<00:36,  5.07it/s][A
 16%|█▋        | 36/221 [00:08<00:41,  4.44it/s][A
 17%|█▋        | 37/221 [00:09<00:40,  4.52it/s][A
 17%|█▋        | 38/221 [00:09<00:43,  4.19it/s][A
 18%|█▊        | 39/221 [00:09<00:39,  4.59it/s][A
 18%|█▊        | 40/221 [00:09<00:45,  3.95it/s][A
 19%|█▊        | 41/221 [00:10<00:40,  4.49it/s][A
 19%|█▉        | 42/221 [00:10<00:38,  4.62it/s][A
 19%|█▉        | 43/221 [00:10<00:45,  3.88it/s][A
 20%|█▉        | 44/221 [00:10<00:44,  3.99it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.77it/s][A
 21%|██        | 46/221 [00:11<00:40,  4.30it/s][A
 21%|██▏       | 47/221 [00:11<00:38,  4.47it/s][A
 22%|██▏       | 48/221 [00:11<00:34,  4.98it/s][A
 22%|██▏       | 49/221 [00:11<00:35,  4.91it/s][A
 23%|██▎       | 50/221 [00:12<00:46,  3.69it/s][A
 23%|██▎       | 51/221 [00:12<00:43,  3.88it/s][A
 24%|██▎       | 52/221 [00:12<00:39,  4.29it/s][A
 24%|██▍       | 53/221 [00:12<00:32,  5.14it/s][A
 24%|██▍       | 54/221 [00:13<00:51,  3.27it/s][A
 25%|██▍       | 55/221 [00:13<00:47,  3.52it/s][A
 25%|██▌       | 56/221 [00:13<00:40,  4.11it/s][A
 26%|██▌       | 57/221 [00:14<00:40,  4.01it/s][A
 26%|██▌       | 58/221 [00:14<00:42,  3.85it/s][A
 27%|██▋       | 59/221 [00:14<00:39,  4.12it/s][A
 27%|██▋       | 60/221 [00:14<00:38,  4.18it/s][A
 28%|██▊       | 61/221 [00:14<00:34,  4.66it/s][A
 28%|██▊       | 62/221 [00:15<00:35,  4.46it/s][A
 29%|██▊       | 63/221 [00:15<00:35,  4.42it/s][A
 29%|██▉       | 64/221 [00:15<00:44,  3.54it/s][A
 29%|██▉       | 65/221 [00:16<00:37,  4.12it/s][A
 30%|██▉       | 66/221 [00:16<00:49,  3.12it/s][A
 30%|███       | 67/221 [00:16<00:56,  2.70it/s][A
 31%|███       | 68/221 [00:17<00:47,  3.24it/s][A
 31%|███       | 69/221 [00:17<01:03,  2.40it/s][A
 32%|███▏      | 70/221 [00:17<00:48,  3.09it/s][A
 32%|███▏      | 71/221 [00:18<00:44,  3.38it/s][A
 33%|███▎      | 72/221 [00:18<00:50,  2.98it/s][A
 33%|███▎      | 73/221 [00:18<00:49,  3.00it/s][A
 33%|███▎      | 74/221 [00:19<00:39,  3.76it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.77it/s][A
 34%|███▍      | 76/221 [00:19<00:35,  4.03it/s][A
 35%|███▍      | 77/221 [00:19<00:34,  4.12it/s][A
 35%|███▌      | 78/221 [00:19<00:33,  4.27it/s][A
 36%|███▌      | 79/221 [00:20<00:46,  3.03it/s][A
 36%|███▌      | 80/221 [00:20<00:40,  3.51it/s][A
 37%|███▋      | 81/221 [00:20<00:37,  3.69it/s][A
 37%|███▋      | 82/221 [00:21<00:39,  3.56it/s][A
 38%|███▊      | 83/221 [00:21<00:42,  3.28it/s][A
 38%|███▊      | 84/221 [00:21<00:38,  3.52it/s][A
 39%|███▉      | 86/221 [00:22<00:32,  4.12it/s][A
 39%|███▉      | 87/221 [00:22<00:44,  3.00it/s][A
 40%|███▉      | 88/221 [00:23<00:50,  2.64it/s][A
 40%|████      | 89/221 [00:23<00:46,  2.85it/s][A
 41%|████      | 90/221 [00:23<00:45,  2.89it/s][A
 41%|████      | 91/221 [00:24<00:37,  3.50it/s][A
 42%|████▏     | 92/221 [00:24<00:37,  3.45it/s][A
 42%|████▏     | 93/221 [00:25<00:52,  2.43it/s][A
 43%|████▎     | 94/221 [00:25<00:46,  2.74it/s][A
 43%|████▎     | 95/221 [00:25<00:41,  3.03it/s][A
 43%|████▎     | 96/221 [00:25<00:36,  3.40it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.84it/s][A
 44%|████▍     | 98/221 [00:26<00:31,  3.90it/s][A
 45%|████▍     | 99/221 [00:26<00:28,  4.33it/s][A
 45%|████▌     | 100/221 [00:26<00:27,  4.33it/s][A
 46%|████▌     | 101/221 [00:26<00:29,  4.09it/s][A
 46%|████▌     | 102/221 [00:27<00:43,  2.76it/s][A
 47%|████▋     | 103/221 [00:27<00:34,  3.43it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.90it/s][A
 48%|████▊     | 105/221 [00:28<00:29,  3.94it/s][A
 48%|████▊     | 106/221 [00:28<00:39,  2.92it/s][A
 48%|████▊     | 107/221 [00:28<00:36,  3.15it/s][A
 49%|████▉     | 108/221 [00:29<00:33,  3.38it/s][A
 49%|████▉     | 109/221 [00:29<00:27,  4.12it/s][A
 50%|████▉     | 110/221 [00:29<00:28,  3.87it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.69it/s][A
 51%|█████     | 112/221 [00:30<00:28,  3.83it/s][A
 51%|█████     | 113/221 [00:30<00:25,  4.25it/s][A
 52%|█████▏    | 115/221 [00:30<00:21,  4.97it/s][A
 52%|█████▏    | 116/221 [00:30<00:22,  4.61it/s][A
 53%|█████▎    | 117/221 [00:31<00:24,  4.23it/s][A
 53%|█████▎    | 118/221 [00:31<00:23,  4.36it/s][A
 54%|█████▍    | 119/221 [00:31<00:28,  3.56it/s][A
 54%|█████▍    | 120/221 [00:31<00:25,  3.96it/s][A
 55%|█████▍    | 121/221 [00:32<00:21,  4.64it/s][A
 55%|█████▌    | 122/221 [00:32<00:23,  4.25it/s][A
 56%|█████▌    | 123/221 [00:32<00:23,  4.19it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.83it/s][A
 57%|█████▋    | 125/221 [00:33<00:29,  3.26it/s][A
 57%|█████▋    | 126/221 [00:33<00:26,  3.62it/s][A
 57%|█████▋    | 127/221 [00:34<00:31,  3.00it/s][A
 58%|█████▊    | 128/221 [00:34<00:28,  3.25it/s][A
 58%|█████▊    | 129/221 [00:34<00:23,  3.95it/s][A
 59%|█████▉    | 130/221 [00:34<00:23,  3.92it/s][A
 60%|█████▉    | 132/221 [00:35<00:21,  4.18it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.80it/s][A
 61%|██████    | 134/221 [00:35<00:26,  3.25it/s][A
 61%|██████    | 135/221 [00:36<00:26,  3.20it/s][A
 62%|██████▏   | 136/221 [00:36<00:24,  3.46it/s][A
 62%|██████▏   | 137/221 [00:36<00:21,  3.92it/s][A
 62%|██████▏   | 138/221 [00:36<00:23,  3.61it/s][A
 63%|██████▎   | 139/221 [00:37<00:29,  2.75it/s][A
 63%|██████▎   | 140/221 [00:37<00:28,  2.89it/s][A
 64%|██████▍   | 141/221 [00:37<00:23,  3.35it/s][A
 64%|██████▍   | 142/221 [00:38<00:21,  3.70it/s][A
 65%|██████▍   | 143/221 [00:38<00:29,  2.63it/s][A
 65%|██████▌   | 144/221 [00:39<00:30,  2.56it/s][A
 66%|██████▌   | 146/221 [00:39<00:18,  4.05it/s][A
 67%|██████▋   | 147/221 [00:39<00:18,  3.91it/s][A
 67%|██████▋   | 148/221 [00:40<00:23,  3.17it/s][A
 67%|██████▋   | 149/221 [00:40<00:22,  3.25it/s][A
 68%|██████▊   | 150/221 [00:40<00:20,  3.39it/s][A
 68%|██████▊   | 151/221 [00:41<00:23,  2.99it/s][A
 69%|██████▉   | 152/221 [00:42<00:36,  1.91it/s][A
 69%|██████▉   | 153/221 [00:42<00:27,  2.44it/s][A
 70%|██████▉   | 154/221 [00:42<00:23,  2.91it/s][A
 70%|███████   | 155/221 [00:42<00:21,  3.14it/s][A
 71%|███████   | 156/221 [00:43<00:21,  2.98it/s][A
 71%|███████   | 157/221 [00:43<00:20,  3.08it/s][A
 71%|███████▏  | 158/221 [00:43<00:20,  3.12it/s][A
 72%|███████▏  | 159/221 [00:43<00:15,  3.91it/s][A
 72%|███████▏  | 160/221 [00:43<00:14,  4.17it/s][A
 73%|███████▎  | 161/221 [00:44<00:15,  3.98it/s][A
 73%|███████▎  | 162/221 [00:44<00:13,  4.48it/s][A
 74%|███████▍  | 163/221 [00:44<00:13,  4.30it/s][A
 74%|███████▍  | 164/221 [00:44<00:11,  4.99it/s][A
 75%|███████▍  | 165/221 [00:45<00:11,  4.85it/s][A
 75%|███████▌  | 166/221 [00:45<00:11,  4.71it/s][A
 76%|███████▌  | 167/221 [00:45<00:10,  5.33it/s][A
 76%|███████▌  | 168/221 [00:45<00:10,  5.07it/s][A
 76%|███████▋  | 169/221 [00:45<00:09,  5.27it/s][A
 77%|███████▋  | 170/221 [00:46<00:15,  3.19it/s][A
 77%|███████▋  | 171/221 [00:46<00:15,  3.31it/s][A
 78%|███████▊  | 172/221 [00:46<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:47<00:13,  3.43it/s][A
 79%|███████▊  | 174/221 [00:47<00:17,  2.64it/s][A
 79%|███████▉  | 175/221 [00:48<00:16,  2.74it/s][A
 80%|███████▉  | 176/221 [00:48<00:15,  2.88it/s][A
 80%|████████  | 177/221 [00:48<00:13,  3.28it/s][A
 81%|████████  | 178/221 [00:48<00:12,  3.48it/s][A
 81%|████████  | 179/221 [00:49<00:11,  3.67it/s][A
 81%|████████▏ | 180/221 [00:49<00:09,  4.39it/s][A
 82%|████████▏ | 181/221 [00:49<00:09,  4.26it/s][A
 82%|████████▏ | 182/221 [00:49<00:11,  3.55it/s][A
 83%|████████▎ | 183/221 [00:50<00:11,  3.25it/s][A
 83%|████████▎ | 184/221 [00:50<00:10,  3.52it/s][A
 84%|████████▎ | 185/221 [00:50<00:08,  4.06it/s][A
 84%|████████▍ | 186/221 [00:51<00:10,  3.32it/s][A
 85%|████████▍ | 187/221 [00:51<00:09,  3.56it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.46it/s][A
 86%|████████▌ | 189/221 [00:51<00:08,  3.62it/s][A
 86%|████████▌ | 190/221 [00:52<00:10,  3.08it/s][A
 86%|████████▋ | 191/221 [00:52<00:08,  3.68it/s][A
 87%|████████▋ | 192/221 [00:52<00:08,  3.59it/s][A
 88%|████████▊ | 194/221 [00:53<00:06,  4.03it/s][A
 88%|████████▊ | 195/221 [00:53<00:06,  4.10it/s][A
 89%|████████▊ | 196/221 [00:53<00:07,  3.19it/s][A
 89%|████████▉ | 197/221 [00:54<00:07,  3.24it/s][A
 90%|████████▉ | 198/221 [00:54<00:08,  2.72it/s][A
 90%|█████████ | 199/221 [00:54<00:07,  3.13it/s][A
 90%|█████████ | 200/221 [00:55<00:07,  2.66it/s][A
 91%|█████████ | 201/221 [00:55<00:06,  3.07it/s][A
 91%|█████████▏| 202/221 [00:56<00:06,  2.80it/s][A
 92%|█████████▏| 203/221 [00:56<00:05,  3.06it/s][A
 92%|█████████▏| 204/221 [00:56<00:06,  2.79it/s][A
 93%|█████████▎| 206/221 [00:57<00:04,  3.17it/s][A
 94%|█████████▎| 207/221 [00:57<00:03,  3.75it/s][A
 94%|█████████▍| 208/221 [00:57<00:03,  3.81it/s][A
 95%|█████████▍| 209/221 [00:57<00:03,  3.64it/s][A
 95%|█████████▌| 211/221 [00:58<00:02,  4.06it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  3.95it/s][A
 96%|█████████▋| 213/221 [00:58<00:01,  4.14it/s][A
 97%|█████████▋| 214/221 [00:59<00:02,  2.92it/s][A
 97%|█████████▋| 215/221 [00:59<00:01,  3.33it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.57it/s][A
 98%|█████████▊| 217/221 [01:00<00:01,  3.37it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.32it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.31it/s][A
100%|█████████▉| 220/221 [01:01<00:00,  3.68it/s][A
100%|██████████| 221/221 [01:01<00:00,  3.95it/s][A100%|██████████| 221/221 [01:01<00:00,  3.61it/s]
09/09/2024 20:20:41 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 599--===========

09/09/2024 20:20:41 - INFO - __main__ -   {'area_r1': 39.7, 'area_recall': '39.7/64.1/74.4', 'area_ravg': 59.4}
09/09/2024 20:20:41 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 599--===========

09/09/2024 20:20:41 - INFO - __main__ -   {'forward_r1': 37.2, 'forward_recall': '37.2/65.2/75.5', 'forward_ravg': 59.3}
09/09/2024 20:20:41 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 599--===========

09/09/2024 20:20:41 - INFO - __main__ -   {'area_video_r1': 41.0, 'area_video_recall': '41.0/67.0/78.1', 'area_video_ravg': 62.0}
09/09/2024 20:20:41 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/09/2024 20:20:41 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 20:20:41 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 599--===========

09/09/2024 20:20:41 - INFO - __main__ -   {'area_video_r1': 52.7, 'area_video_recall': '52.7/75.2/83.1', 'area_video_ravg': 70.4, 'area_video_back_r1': 49.9, 'area_video_back_recall': '49.9/74.3/81.9', 'area_video_back_ravg': 68.7}
09/09/2024 20:20:41 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/09/2024 20:20:41 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/09/2024 20:20:41 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 599--===========

09/09/2024 20:20:41 - INFO - __main__ -   {'video_r1': 42.9, 'video_recall': '42.9/70.4/81.8', 'video_ravg': 65.0}
09/09/2024 20:20:41 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 20:20:41 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 20:20:41 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 599--===========

09/09/2024 20:20:41 - INFO - __main__ -   {'video_r1': 52.5, 'video_recall': '52.5/75.6/82.9', 'video_ravg': 70.3}
09/09/2024 20:20:41 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/09/2024 20:20:41 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/09/2024 20:21:03 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.009090397506952286, 'loss_ret%tv%ta--finetune_area/loss_area': 1.3731889724731445, 'loss_ret%tv%ta--finetune_area/total_loss': 1.382279396057129}
 31%|███       | 600/1945 [3:15:44<47:09:16, 126.21s/it][h264 @ 0x5624172d31c0] mmco: unref short failure
 31%|███       | 601/1945 [3:15:48<33:27:03, 89.60s/it]  31%|███       | 602/1945 [3:15:53<23:55:06, 64.12s/it] 31%|███       | 603/1945 [3:15:58<17:22:38, 46.62s/it] 31%|███       | 604/1945 [3:16:05<12:50:44, 34.48s/it][h264 @ 0x55a04c6fe340] mmco: unref short failure
 31%|███       | 605/1945 [3:16:11<9:43:55, 26.15s/it] [h264 @ 0x556b312de140] mmco: unref short failure
[h264 @ 0x556b312de140] mmco: unref short failure
[h264 @ 0x556b2d1f1880] mmco: unref short failure
[h264 @ 0x556b2d1f1880] mmco: unref short failure
 31%|███       | 606/1945 [3:16:18<7:31:12, 20.22s/it][h264 @ 0x55a03c64d600] mmco: unref short failure
[h264 @ 0x55a03cac6600] mmco: unref short failure
[h264 @ 0x55a03cac6600] mmco: unref short failure
[h264 @ 0x55a03cac6600] mmco: unref short failure
 31%|███       | 607/1945 [3:16:26<6:12:18, 16.70s/it][h264 @ 0x562419ab8f80] mmco: unref short failure
[h264 @ 0x55a03b181380] mmco: unref short failure
[h264 @ 0x55a03b181380] mmco: unref short failure
[h264 @ 0x55a03b181380] mmco: unref short failure
[h264 @ 0x55a03b181380] mmco: unref short failure
[h264 @ 0x55a03b181380] mmco: unref short failure
[h264 @ 0x55a03b181380] mmco: unref short failure
[h264 @ 0x55a03b181380] mmco: unref short failure
[h264 @ 0x55a03b181380] mmco: unref short failure
 31%|███▏      | 608/1945 [3:16:33<5:08:48, 13.86s/it][h264 @ 0x55a04036b4c0] mmco: unref short failure
[h264 @ 0x55a04036b4c0] mmco: unref short failure
[h264 @ 0x562437e24440] mmco: unref short failure
 31%|███▏      | 609/1945 [3:16:41<4:25:52, 11.94s/it][h264 @ 0x556b2e349a40] mmco: unref short failure
[h264 @ 0x559bec309600] mmco: unref short failure
[h264 @ 0x559bec309600] mmco: unref short failure
[h264 @ 0x5624184be500] mmco: unref short failure
[h264 @ 0x562416f59180] mmco: unref short failure
[h264 @ 0x562416f59180] mmco: unref short failure
 31%|███▏      | 610/1945 [3:16:49<3:58:40, 10.73s/it][h264 @ 0x55a052e5e100] mmco: unref short failure
[h264 @ 0x55a052e5e100] mmco: unref short failure
[h264 @ 0x559bf1a66240] mmco: unref short failure
[h264 @ 0x559bf1a66240] mmco: unref short failure
[h264 @ 0x56241c1e8400] mmco: unref short failure
[h264 @ 0x56241c1e8400] mmco: unref short failure
 31%|███▏      | 611/1945 [3:16:56<3:36:47,  9.75s/it] 31%|███▏      | 612/1945 [3:17:04<3:22:21,  9.11s/it][h264 @ 0x55a03677e7c0] mmco: unref short failure
[h264 @ 0x55a03677e7c0] mmco: unref short failure
[h264 @ 0x55a032488480] mmco: unref short failure
[h264 @ 0x55a032488480] mmco: unref short failure
 32%|███▏      | 613/1945 [3:17:12<3:13:13,  8.70s/it][h264 @ 0x55a035e0a2c0] mmco: unref short failure
 32%|███▏      | 614/1945 [3:17:19<3:03:40,  8.28s/it][h264 @ 0x559bf349a600] mmco: unref short failure
[h264 @ 0x556b31d29480] mmco: unref short failure
[h264 @ 0x556b31d29480] mmco: unref short failure
 32%|███▏      | 615/1945 [3:17:27<3:01:53,  8.21s/it][h264 @ 0x55a035e09c40] mmco: unref short failure
[h264 @ 0x55a035e09c40] mmco: unref short failure
[h264 @ 0x55a0349b47c0] mmco: unref short failure
[h264 @ 0x556b2ec147c0] mmco: unref short failure
[h264 @ 0x559bf093b680] mmco: unref short failure
[h264 @ 0x559bf093b680] mmco: unref short failure
[h264 @ 0x559bf093b680] mmco: unref short failure
[h264 @ 0x559bf093b680] mmco: unref short failure
 32%|███▏      | 616/1945 [3:17:35<2:59:50,  8.12s/it][h264 @ 0x55a04173be80] mmco: unref short failure
[h264 @ 0x55a04173be80] mmco: unref short failure
[h264 @ 0x55a04173be80] mmco: unref short failure
[h264 @ 0x55a04173be80] mmco: unref short failure
[h264 @ 0x5624172d2d40] mmco: unref short failure
[h264 @ 0x5624172d2d40] mmco: unref short failure
[h264 @ 0x55a033107180] mmco: unref short failure
[h264 @ 0x55a033107180] mmco: unref short failure
 32%|███▏      | 617/1945 [3:17:44<3:03:36,  8.30s/it][h264 @ 0x55a0515bab40] mmco: unref short failure
[h264 @ 0x55a039b98d00] mmco: unref short failure
[h264 @ 0x55a039b98d00] mmco: unref short failure
[h264 @ 0x55a04f36ee80] mmco: unref short failure
[h264 @ 0x559be9ff1400] mmco: unref short failure
[h264 @ 0x559be9ff1400] mmco: unref short failure
[h264 @ 0x556b2ee5ed00] mmco: unref short failure
 32%|███▏      | 618/1945 [3:17:57<3:36:35,  9.79s/it] 32%|███▏      | 619/1945 [3:18:04<3:21:20,  9.11s/it] 32%|███▏      | 620/1945 [3:18:14<3:25:03,  9.29s/it][h264 @ 0x556b2e964cc0] mmco: unref short failure
[h264 @ 0x556b2e964cc0] mmco: unref short failure
 32%|███▏      | 621/1945 [3:18:21<3:08:09,  8.53s/it][h264 @ 0x559bf2fafd40] mmco: unref short failure
[h264 @ 0x559bf2fafd40] mmco: unref short failure
[h264 @ 0x559bf2fafd40] mmco: unref short failure
[h264 @ 0x559bed4be0c0] mmco: unref short failure
[h264 @ 0x55a04d2e96c0] mmco: unref short failure
 32%|███▏      | 622/1945 [3:18:28<3:00:47,  8.20s/it][h264 @ 0x55a033106f00] mmco: unref short failure
[h264 @ 0x55a03e858140] mmco: unref short failure
[h264 @ 0x562418ecf900] mmco: unref short failure
[h264 @ 0x562431cee1c0] mmco: unref short failure
[h264 @ 0x562431cee1c0] mmco: unref short failure
[h264 @ 0x562431cee1c0] mmco: unref short failure
[h264 @ 0x562431cee1c0] mmco: unref short failure
[h264 @ 0x556b47586080] mmco: unref short failure
 32%|███▏      | 623/1945 [3:18:39<3:15:42,  8.88s/it][h264 @ 0x56241c413d00] mmco: unref short failure
[h264 @ 0x556b305cc700] mmco: unref short failure
[h264 @ 0x556b305cc700] mmco: unref short failure
[h264 @ 0x56242a27e6c0] mmco: unref short failure
not have audios 8-qwaveiHMM.3
[h264 @ 0x556b2fe87740] mmco: unref short failure
[h264 @ 0x559becda5840] mmco: unref short failure
[h264 @ 0x559becda5840] mmco: unref short failure
[h264 @ 0x556b361bcfc0] mmco: unref short failure
[h264 @ 0x556b361bcfc0] mmco: unref short failure
[h264 @ 0x556b32b2a7c0] mmco: unref short failure
[h264 @ 0x556b32b2a7c0] mmco: unref short failure
[h264 @ 0x559c0819bfc0] mmco: unref short failure
[h264 @ 0x559c0819bfc0] mmco: unref short failure
 32%|███▏      | 624/1945 [3:19:21<6:58:45, 19.02s/it][h264 @ 0x559c008c8280] mmco: unref short failure
[h264 @ 0x559c008c8280] mmco: unref short failure
[h264 @ 0x55a04ea6bdc0] mmco: unref short failure
[h264 @ 0x55a037d61ec0] mmco: unref short failure
[h264 @ 0x55a037d61ec0] mmco: unref short failure
[h264 @ 0x55a04d41a3c0] mmco: unref short failure
[h264 @ 0x55a04d41a3c0] mmco: unref short failure
 32%|███▏      | 625/1945 [3:19:37<6:35:16, 17.97s/it][h264 @ 0x559be9ed9dc0] mmco: unref short failure
[h264 @ 0x559be9ed9dc0] mmco: unref short failure
[h264 @ 0x556b3d660480] mmco: unref short failure
[h264 @ 0x562417f94980] mmco: unref short failure
[h264 @ 0x562417f94980] mmco: unref short failure
[h264 @ 0x55a04ead5dc0] mmco: unref short failure
[h264 @ 0x55a04ead5dc0] mmco: unref short failure
[h264 @ 0x562434d01d80] mmco: unref short failure
[h264 @ 0x562434d01d80] mmco: unref short failure
[h264 @ 0x556b3a851300] mmco: unref short failure
[h264 @ 0x556b3a851300] mmco: unref short failure
[h264 @ 0x556b3dcbbf80] mmco: unref short failure
[h264 @ 0x556b3dcbbf80] mmco: unref short failure
 32%|███▏      | 626/1945 [3:19:55<6:37:34, 18.09s/it][h264 @ 0x55a04e87ab00] mmco: unref short failure
[h264 @ 0x55a04e87ab00] mmco: unref short failure
 32%|███▏      | 627/1945 [3:20:03<5:29:23, 15.00s/it][h264 @ 0x562434deb400] mmco: unref short failure
[h264 @ 0x562434deb400] mmco: unref short failure
[h264 @ 0x562419ec2e80] mmco: unref short failure
[h264 @ 0x562419ec2e80] mmco: unref short failure
[h264 @ 0x559bfc886d00] mmco: unref short failure
[h264 @ 0x556b402582c0] mmco: unref short failure
[h264 @ 0x556b402582c0] mmco: unref short failure
[h264 @ 0x556b402582c0] mmco: unref short failure
[h264 @ 0x556b402582c0] mmco: unref short failure
 32%|███▏      | 628/1945 [3:20:12<4:51:24, 13.28s/it][h264 @ 0x5624177d4c80] mmco: unref short failure
[h264 @ 0x55a050fc7480] mmco: unref short failure
[h264 @ 0x55a050fc7480] mmco: unref short failure
[h264 @ 0x556b379ac4c0] mmco: unref short failure
[h264 @ 0x556b379ac4c0] mmco: unref short failure
[h264 @ 0x556b2fa90e40] mmco: unref short failure
[h264 @ 0x556b2fa90e40] mmco: unref short failure
 32%|███▏      | 629/1945 [3:20:23<4:35:37, 12.57s/it] 32%|███▏      | 630/1945 [3:20:31<4:02:29, 11.06s/it][h264 @ 0x56241a684e00] mmco: unref short failure
[h264 @ 0x56242acffe40] mmco: unref short failure
[h264 @ 0x56242acffe40] mmco: unref short failure
[h264 @ 0x55a03b878740] mmco: unref short failure
[h264 @ 0x55a03b878740] mmco: unref short failure
[h264 @ 0x562422a25d40] mmco: unref short failure
[h264 @ 0x55a033734240] mmco: unref short failure
[h264 @ 0x55a041b02580] mmco: unref short failure
[h264 @ 0x559c031feec0] mmco: unref short failure
[h264 @ 0x556b33e147c0] mmco: unref short failure
[h264 @ 0x556b33e147c0] mmco: unref short failure
[h264 @ 0x556b33e147c0] mmco: unref short failure
[h264 @ 0x56241ef4a700] mmco: unref short failure
[h264 @ 0x56241ef4a700] mmco: unref short failure
[h264 @ 0x556b481fd680] mmco: unref short failure
[h264 @ 0x556b3328d440] mmco: unref short failure
[h264 @ 0x556b3328d440] mmco: unref short failure
 32%|███▏      | 631/1945 [3:21:05<6:37:25, 18.15s/it][h264 @ 0x55a033e4f440] mmco: unref short failure
[h264 @ 0x556b489894c0] mmco: unref short failure
[h264 @ 0x556b489894c0] mmco: unref short failure
 32%|███▏      | 632/1945 [3:21:27<7:02:49, 19.32s/it][h264 @ 0x562417f95040] mmco: unref short failure
[h264 @ 0x556b41f74a00] mmco: unref short failure
[h264 @ 0x556b41f74a00] mmco: unref short failure
[h264 @ 0x556b2de56880] mmco: unref short failure
[h264 @ 0x556b2de56880] mmco: unref short failure
[h264 @ 0x556b32c78180] mmco: unref short failure
[h264 @ 0x559becda55c0] mmco: unref short failure
[h264 @ 0x559becda55c0] mmco: unref short failure
 33%|███▎      | 633/1945 [3:21:38<6:04:55, 16.69s/it][h264 @ 0x562426fe9700] mmco: unref short failure
[h264 @ 0x55a041b02100] mmco: unref short failure
[h264 @ 0x55a041b02100] mmco: unref short failure
[h264 @ 0x56242899b900] mmco: unref short failure
[h264 @ 0x56242899b900] mmco: unref short failure
[h264 @ 0x556b4b049ec0] mmco: unref short failure
[h264 @ 0x559be9884500] mmco: unref short failure
[h264 @ 0x559be9884500] mmco: unref short failure
 33%|███▎      | 634/1945 [3:22:04<7:06:34, 19.52s/it] 33%|███▎      | 635/1945 [3:22:11<5:44:39, 15.79s/it] 33%|███▎      | 636/1945 [3:22:19<4:49:37, 13.28s/it] 33%|███▎      | 637/1945 [3:22:28<4:21:25, 11.99s/it][h264 @ 0x56241bad8700] mmco: unref short failure
[h264 @ 0x55a042ae8780] mmco: unref short failure
[h264 @ 0x562418cde080] mmco: unref short failure
 33%|███▎      | 638/1945 [3:22:35<3:48:39, 10.50s/it][h264 @ 0x559c091900c0] mmco: unref short failure
[h264 @ 0x559c091900c0] mmco: unref short failure
[h264 @ 0x562422c58280] mmco: unref short failure
[h264 @ 0x556b38c05940] mmco: unref short failure
[h264 @ 0x556b38c05940] mmco: unref short failure
[h264 @ 0x55a0515ba200] mmco: unref short failure
[h264 @ 0x55a0515ba200] mmco: unref short failure
[h264 @ 0x55a0515ba200] mmco: unref short failure
[h264 @ 0x55a0515ba200] mmco: unref short failure
[h264 @ 0x55a0515ba200] mmco: unref short failure
[h264 @ 0x55a0515ba200] mmco: unref short failure
[h264 @ 0x55a04d515c80] mmco: unref short failure
[h264 @ 0x55a0349b4580] mmco: unref short failure
 33%|███▎      | 639/1945 [3:23:10<6:31:18, 17.98s/it][h264 @ 0x562429398800] mmco: unref short failure
[h264 @ 0x559c02ce7b80] mmco: unref short failure
[h264 @ 0x559c02ce7b80] mmco: unref short failure
[h264 @ 0x556b3db4c8c0] mmco: unref short failure
 33%|███▎      | 640/1945 [3:23:33<7:02:09, 19.41s/it][h264 @ 0x5624259aab00] mmco: unref short failure
[h264 @ 0x5624259aab00] mmco: unref short failure
[h264 @ 0x556b40cb4900] mmco: unref short failure
 33%|███▎      | 641/1945 [3:23:46<6:23:51, 17.66s/it][h264 @ 0x559c0311d700] mmco: unref short failure
[h264 @ 0x559c0311d700] mmco: unref short failure
[h264 @ 0x559bf2faf8c0] mmco: unref short failure
[h264 @ 0x559bf2faf8c0] mmco: unref short failure
[h264 @ 0x559bf2faf8c0] mmco: unref short failure
[h264 @ 0x559bf2faf8c0] mmco: unref short failure
[h264 @ 0x556b448f2f80] mmco: unref short failure
[h264 @ 0x556b448f2f80] mmco: unref short failure
[h264 @ 0x556b448f2f80] mmco: unref short failure
[h264 @ 0x556b448f2f80] mmco: unref short failure
[h264 @ 0x5624180ae980] mmco: unref short failure
 33%|███▎      | 642/1945 [3:24:04<6:23:31, 17.66s/it][h264 @ 0x556b308f5140] mmco: unref short failure
[h264 @ 0x556b308f5140] mmco: unref short failure
 33%|███▎      | 643/1945 [3:24:11<5:10:22, 14.30s/it][h264 @ 0x559bed06c7c0] mmco: unref short failure
[h264 @ 0x55a0369bc540] mmco: unref short failure
[h264 @ 0x55a0369bc540] mmco: unref short failure
 33%|███▎      | 644/1945 [3:24:26<5:18:08, 14.67s/it][h264 @ 0x556b40258500] mmco: unref short failure
 33%|███▎      | 645/1945 [3:24:33<4:28:05, 12.37s/it][h264 @ 0x56242782a7c0] mmco: unref short failure
[h264 @ 0x56242782a7c0] mmco: unref short failure
[h264 @ 0x5624335ed780] mmco: unref short failure
[h264 @ 0x5624335ed780] mmco: unref short failure
[h264 @ 0x559bfe66d240] mmco: unref short failure
[h264 @ 0x559bfe66d240] mmco: unref short failure
[h264 @ 0x562431192b40] mmco: unref short failure
[h264 @ 0x562431192b40] mmco: unref short failure
[h264 @ 0x559c0918fcc0] mmco: unref short failure
 33%|███▎      | 646/1945 [3:24:40<3:51:05, 10.67s/it][h264 @ 0x562417ef3440] mmco: unref short failure
[h264 @ 0x562417ef3440] mmco: unref short failure
[h264 @ 0x55a03627f540] mmco: unref short failure
[h264 @ 0x55a03627f540] mmco: unref short failure
[h264 @ 0x562421188d00] mmco: unref short failure
[h264 @ 0x562421188d00] mmco: unref short failure
[h264 @ 0x55a051057dc0] mmco: unref short failure
[h264 @ 0x55a04d516300] mmco: unref short failure
[h264 @ 0x559c0415a580] mmco: unref short failure
[h264 @ 0x559c0415a580] mmco: unref short failure
[h264 @ 0x556b312362c0] mmco: unref short failure
[h264 @ 0x556b312362c0] mmco: unref short failure
[h264 @ 0x559bf0dde640] mmco: unref short failure
[h264 @ 0x559bf0dde640] mmco: unref short failure
[h264 @ 0x559bf0dde640] mmco: unref short failure
[h264 @ 0x559bf0dde640] mmco: unref short failure
[h264 @ 0x556b300c3f80] mmco: unref short failure
[h264 @ 0x556b300c3f80] mmco: unref short failure
[h264 @ 0x559bea2b86c0] mmco: unref short failure
[h264 @ 0x559bea2b86c0] mmco: unref short failure
[h264 @ 0x5624172f0d40] mmco: unref short failure
[h264 @ 0x5624172f0d40] mmco: unref short failure
 33%|███▎      | 647/1945 [3:25:26<7:42:46, 21.39s/it][h264 @ 0x559be9a36f80] mmco: unref short failure
[h264 @ 0x559be9a36f80] mmco: unref short failure
 33%|███▎      | 648/1945 [3:25:34<6:11:30, 17.19s/it][h264 @ 0x556b31e06ac0] mmco: unref short failure
[h264 @ 0x55a04ab08fc0] mmco: unref short failure
[h264 @ 0x55a04ab08fc0] mmco: unref short failure
[h264 @ 0x556b31e06ac0] mmco: unref short failure
[h264 @ 0x556b31e06ac0] mmco: unref short failure
[h264 @ 0x556b2de56b00] mmco: unref short failure
[h264 @ 0x556b2de56b00] mmco: unref short failure
[h264 @ 0x55a0396b7240] mmco: unref short failure
[h264 @ 0x556b3db4c240] mmco: unref short failure
 33%|███▎      | 649/1945 [3:25:46<5:42:57, 15.88s/it]09/09/2024 20:31:09 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 20:31:09 - INFO - __main__ -   start running ret%tv validation...
[h264 @ 0x556b3d660680] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556b4c0d76c0] mmco: unref short failure
[h264 @ 0x556b4c0d76c0] mmco: unref short failure
[h264 @ 0x556b350f74c0] mmco: unref short failure
[h264 @ 0x556b350f74c0] mmco: unref short failure
[h264 @ 0x55a03e874f00] mmco: unref short failure
[h264 @ 0x55a03e874f00] mmco: unref short failure
[h264 @ 0x556b3f3ecc80] mmco: unref short failure
[h264 @ 0x556b3f3ecc80] mmco: unref short failure
[h264 @ 0x556b3f3ecc80] mmco: unref short failure
[h264 @ 0x556b3f3ecc80] mmco: unref short failure
[h264 @ 0x559bf1da7cc0] mmco: unref short failure
[h264 @ 0x559bf1da7cc0] mmco: unref short failure
[h264 @ 0x556b3edeca40] mmco: unref short failure
[h264 @ 0x556b361bcfc0] mmco: unref short failure
[h264 @ 0x556b361bcfc0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x5624343e6a00] mmco: unref short failure
[h264 @ 0x5624343e6a00] mmco: unref short failure
[h264 @ 0x556b31d23940] mmco: unref short failure
[h264 @ 0x556b4770a740] mmco: unref short failure
[h264 @ 0x562417475f80] mmco: unref short failure
[h264 @ 0x562417475f80] mmco: unref short failure
[h264 @ 0x562428fcd280] mmco: unref short failure
[h264 @ 0x559be98e5380] mmco: unref short failure
[h264 @ 0x562428fcd480] mmco: unref short failure
[h264 @ 0x562428fcd480] mmco: unref short failure
[h264 @ 0x556b308f4ac0] mmco: unref short failure
[h264 @ 0x556b308f4ac0] mmco: unref short failure
[h264 @ 0x55a041ac00c0] mmco: unref short failure
[h264 @ 0x55a041ac00c0] mmco: unref short failure
[h264 @ 0x55a041ac00c0] mmco: unref short failure
[h264 @ 0x55a041ac00c0] mmco: unref short failure
[h264 @ 0x556b3038eb40] mmco: unref short failure
[h264 @ 0x556b3038eb40] mmco: unref short failure
[h264 @ 0x556b41481e00] mmco: unref short failure
[h264 @ 0x556b41481e00] mmco: unref short failure
[h264 @ 0x556b48da0240] mmco: unref short failure
[h264 @ 0x55a050f93a80] mmco: unref short failure
[h264 @ 0x55a050f93a80] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A[h264 @ 0x556b39ac4a40] mmco: unref short failure
[h264 @ 0x556b39ac4a40] mmco: unref short failure

  0%|          | 1/221 [00:00<01:49,  2.01it/s][A
  1%|          | 2/221 [00:01<02:02,  1.79it/s][A
  1%|▏         | 3/221 [00:01<01:23,  2.62it/s][A
  2%|▏         | 4/221 [00:01<00:59,  3.64it/s][A
  2%|▏         | 5/221 [00:01<00:52,  4.11it/s][A
  3%|▎         | 6/221 [00:01<00:42,  5.04it/s][A
  3%|▎         | 7/221 [00:01<00:45,  4.67it/s][A
  4%|▎         | 8/221 [00:02<01:11,  2.98it/s][A
  4%|▍         | 9/221 [00:02<01:15,  2.80it/s][A
  5%|▍         | 10/221 [00:03<01:33,  2.25it/s][A
  5%|▍         | 11/221 [00:03<01:11,  2.94it/s][A[h264 @ 0x556b2cec2740] mmco: unref short failure
[h264 @ 0x556b2cec2740] mmco: unref short failure

  5%|▌         | 12/221 [00:04<01:16,  2.72it/s][A
  6%|▌         | 13/221 [00:04<01:06,  3.12it/s][A
  6%|▋         | 14/221 [00:05<01:41,  2.04it/s][A
  7%|▋         | 15/221 [00:05<01:25,  2.41it/s][A
  7%|▋         | 16/221 [00:05<01:25,  2.40it/s][A
  8%|▊         | 17/221 [00:06<01:15,  2.69it/s][A
  8%|▊         | 18/221 [00:06<01:13,  2.75it/s][A
  9%|▊         | 19/221 [00:06<01:00,  3.34it/s][A
  9%|▉         | 20/221 [00:06<00:50,  3.98it/s][A
 10%|▉         | 21/221 [00:06<00:44,  4.48it/s][A
 10%|▉         | 22/221 [00:07<00:48,  4.07it/s][A
 10%|█         | 23/221 [00:07<00:43,  4.58it/s][A
 11%|█         | 24/221 [00:07<00:42,  4.66it/s][A
 11%|█▏        | 25/221 [00:07<00:39,  4.95it/s][A
 12%|█▏        | 26/221 [00:08<00:47,  4.14it/s][A
 12%|█▏        | 27/221 [00:08<00:45,  4.26it/s][A
 13%|█▎        | 28/221 [00:08<01:01,  3.14it/s][A
 13%|█▎        | 29/221 [00:08<00:48,  3.94it/s][A
 14%|█▎        | 30/221 [00:09<00:45,  4.23it/s][A
 14%|█▍        | 31/221 [00:09<00:53,  3.57it/s][A
 14%|█▍        | 32/221 [00:09<00:45,  4.17it/s][A
 15%|█▍        | 33/221 [00:09<00:50,  3.70it/s][A
 15%|█▌        | 34/221 [00:10<00:42,  4.37it/s][A
 16%|█▌        | 35/221 [00:10<00:37,  4.97it/s][A
 16%|█▋        | 36/221 [00:10<00:40,  4.52it/s][A
 17%|█▋        | 37/221 [00:11<01:09,  2.64it/s][A
 17%|█▋        | 38/221 [00:11<01:10,  2.59it/s][A
 18%|█▊        | 39/221 [00:11<00:55,  3.30it/s][A
 18%|█▊        | 40/221 [00:12<00:58,  3.10it/s][A
 19%|█▊        | 41/221 [00:12<00:50,  3.56it/s][A
 19%|█▉        | 42/221 [00:12<00:56,  3.20it/s][A
 19%|█▉        | 43/221 [00:12<00:52,  3.41it/s][A
 20%|██        | 45/221 [00:14<01:12,  2.43it/s][A
 21%|██        | 46/221 [00:14<01:14,  2.36it/s][A
 21%|██▏       | 47/221 [00:15<01:28,  1.97it/s][A
 22%|██▏       | 48/221 [00:15<01:11,  2.43it/s][A
 22%|██▏       | 49/221 [00:15<01:01,  2.78it/s][A
 23%|██▎       | 50/221 [00:15<00:54,  3.13it/s][A
 23%|██▎       | 51/221 [00:15<00:44,  3.81it/s][A
 24%|██▎       | 52/221 [00:16<00:41,  4.12it/s][A
 24%|██▍       | 53/221 [00:16<00:35,  4.67it/s][A
 24%|██▍       | 54/221 [00:18<01:59,  1.39it/s][A
 25%|██▍       | 55/221 [00:18<01:48,  1.53it/s][A
 25%|██▌       | 56/221 [00:18<01:27,  1.88it/s][A
 26%|██▌       | 57/221 [00:19<01:10,  2.31it/s][A
 26%|██▌       | 58/221 [00:19<00:54,  2.98it/s][A
 27%|██▋       | 59/221 [00:19<00:49,  3.25it/s][A
 27%|██▋       | 60/221 [00:20<01:00,  2.65it/s][A
 28%|██▊       | 61/221 [00:20<00:51,  3.11it/s][A
 28%|██▊       | 62/221 [00:20<00:53,  2.98it/s][A
 29%|██▊       | 63/221 [00:20<00:46,  3.42it/s][A
 29%|██▉       | 64/221 [00:21<00:42,  3.73it/s][A
 29%|██▉       | 65/221 [00:21<00:38,  4.02it/s][A[h264 @ 0x559be9e8edc0] mmco: unref short failure

 30%|██▉       | 66/221 [00:21<00:53,  2.91it/s][A
 30%|███       | 67/221 [00:22<01:00,  2.55it/s][A
 31%|███       | 68/221 [00:22<00:49,  3.08it/s][A
 31%|███       | 69/221 [00:23<01:06,  2.28it/s][A
 32%|███▏      | 70/221 [00:23<00:53,  2.84it/s][A[h264 @ 0x559be9a36840] mmco: unref short failure

 32%|███▏      | 71/221 [00:25<02:13,  1.12it/s][A
 33%|███▎      | 72/221 [00:25<01:47,  1.38it/s][A
 33%|███▎      | 73/221 [00:26<01:43,  1.43it/s][A
 33%|███▎      | 74/221 [00:26<01:19,  1.86it/s][A[h264 @ 0x559bfcbad6c0] mmco: unref short failure
[h264 @ 0x559bfcbad6c0] mmco: unref short failure
[h264 @ 0x559bfcbad6c0] mmco: unref short failure
[h264 @ 0x559bfcbad6c0] mmco: unref short failure

 34%|███▍      | 75/221 [00:26<01:09,  2.10it/s][A
 34%|███▍      | 76/221 [00:27<00:53,  2.70it/s][A
 35%|███▍      | 77/221 [00:27<00:44,  3.24it/s][A
 35%|███▌      | 78/221 [00:27<00:43,  3.26it/s][A
 36%|███▌      | 79/221 [00:28<00:58,  2.43it/s][A
 36%|███▌      | 80/221 [00:28<00:51,  2.76it/s][A
 37%|███▋      | 81/221 [00:28<00:50,  2.80it/s][A
 37%|███▋      | 82/221 [00:28<00:41,  3.32it/s][A
 38%|███▊      | 83/221 [00:29<00:34,  3.99it/s][A
 38%|███▊      | 84/221 [00:29<00:29,  4.65it/s][A
 38%|███▊      | 85/221 [00:29<00:24,  5.53it/s][A
 39%|███▉      | 86/221 [00:29<00:25,  5.39it/s][A
 39%|███▉      | 87/221 [00:30<00:41,  3.27it/s][A
 40%|███▉      | 88/221 [00:30<00:45,  2.91it/s][A[h264 @ 0x556b3094f4c0] mmco: unref short failure
[h264 @ 0x556b3094f4c0] mmco: unref short failure

 40%|████      | 89/221 [00:32<01:49,  1.21it/s][A
 41%|████      | 90/221 [00:32<01:29,  1.46it/s][A
 41%|████      | 91/221 [00:33<01:07,  1.91it/s][A[h264 @ 0x562434bf14c0] mmco: unref short failure
[h264 @ 0x562434bf14c0] mmco: unref short failure

 42%|████▏     | 92/221 [00:33<00:59,  2.16it/s][A
 42%|████▏     | 93/221 [00:33<00:58,  2.20it/s][A
 43%|████▎     | 94/221 [00:33<00:49,  2.57it/s][A
 43%|████▎     | 95/221 [00:34<00:40,  3.08it/s][A
 43%|████▎     | 96/221 [00:34<00:34,  3.57it/s][A
 44%|████▍     | 97/221 [00:34<00:29,  4.25it/s][A
 44%|████▍     | 98/221 [00:34<00:33,  3.69it/s][A
 45%|████▍     | 99/221 [00:35<00:29,  4.09it/s][A
 45%|████▌     | 100/221 [00:35<00:28,  4.22it/s][A
 46%|████▌     | 101/221 [00:35<00:24,  4.96it/s][A
 46%|████▌     | 102/221 [00:35<00:32,  3.62it/s][A
 47%|████▋     | 103/221 [00:35<00:27,  4.28it/s][A
 47%|████▋     | 104/221 [00:36<00:24,  4.73it/s][A
 48%|████▊     | 105/221 [00:36<00:26,  4.46it/s][A
 48%|████▊     | 106/221 [00:37<00:51,  2.25it/s][A
 48%|████▊     | 107/221 [00:37<00:39,  2.86it/s][A
 49%|████▉     | 108/221 [00:37<00:31,  3.53it/s][A
 49%|████▉     | 109/221 [00:37<00:35,  3.12it/s][A
 50%|████▉     | 110/221 [00:38<00:35,  3.15it/s][A
 50%|█████     | 111/221 [00:38<00:39,  2.78it/s][A
 51%|█████     | 112/221 [00:38<00:33,  3.21it/s][A
 51%|█████     | 113/221 [00:39<00:34,  3.17it/s][A
 52%|█████▏    | 114/221 [00:39<00:27,  3.92it/s][A
 52%|█████▏    | 115/221 [00:39<00:22,  4.75it/s][A[h264 @ 0x556b361bcfc0] mmco: unref short failure

 52%|█████▏    | 116/221 [00:43<02:12,  1.26s/it][A
 53%|█████▎    | 117/221 [00:43<01:41,  1.02it/s][A
 53%|█████▎    | 118/221 [00:43<01:19,  1.30it/s][A
 54%|█████▍    | 119/221 [00:44<01:02,  1.63it/s][A
 54%|█████▍    | 120/221 [00:44<00:53,  1.88it/s][A
 55%|█████▍    | 121/221 [00:44<00:45,  2.22it/s][A
 55%|█████▌    | 122/221 [00:44<00:37,  2.64it/s][A
 56%|█████▌    | 123/221 [00:45<00:30,  3.26it/s][A
 56%|█████▌    | 124/221 [00:45<00:26,  3.71it/s][A
 57%|█████▋    | 125/221 [00:45<00:26,  3.60it/s][A
 57%|█████▋    | 126/221 [00:45<00:31,  3.05it/s][A
 57%|█████▋    | 127/221 [00:46<00:38,  2.45it/s][A
 58%|█████▊    | 128/221 [00:46<00:37,  2.46it/s][A
 58%|█████▊    | 129/221 [00:47<00:33,  2.71it/s][A
 59%|█████▉    | 130/221 [00:47<00:31,  2.88it/s][A
 59%|█████▉    | 131/221 [00:47<00:28,  3.20it/s][A
 60%|█████▉    | 132/221 [00:47<00:24,  3.60it/s][A
 60%|██████    | 133/221 [00:48<00:28,  3.05it/s][A
 61%|██████    | 134/221 [00:48<00:27,  3.20it/s][A
 61%|██████    | 135/221 [00:48<00:25,  3.39it/s][A
 62%|██████▏   | 136/221 [00:49<00:28,  3.01it/s][A
 62%|██████▏   | 137/221 [00:49<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:49<00:27,  3.04it/s][A
 63%|██████▎   | 139/221 [00:50<00:29,  2.78it/s][A
 63%|██████▎   | 140/221 [00:50<00:28,  2.87it/s][A
 64%|██████▍   | 141/221 [00:50<00:24,  3.33it/s][A
 64%|██████▍   | 142/221 [00:51<00:25,  3.15it/s][A
 65%|██████▍   | 143/221 [00:51<00:29,  2.63it/s][A
 65%|██████▌   | 144/221 [00:52<00:25,  2.97it/s][A
 66%|██████▌   | 145/221 [00:52<00:20,  3.71it/s][A
 66%|██████▌   | 146/221 [00:52<00:16,  4.43it/s][A
 67%|██████▋   | 147/221 [00:52<00:15,  4.72it/s][A
 67%|██████▋   | 148/221 [00:52<00:17,  4.27it/s][A
 67%|██████▋   | 149/221 [00:52<00:14,  4.98it/s][A
 68%|██████▊   | 150/221 [00:52<00:13,  5.45it/s][A
 68%|██████▊   | 151/221 [00:54<00:33,  2.09it/s][A
 69%|██████▉   | 152/221 [00:54<00:33,  2.04it/s][A
 69%|██████▉   | 153/221 [00:54<00:28,  2.35it/s][A
 70%|██████▉   | 154/221 [00:55<00:28,  2.39it/s][A
 70%|███████   | 155/221 [00:55<00:22,  2.93it/s][A
 71%|███████   | 156/221 [00:55<00:20,  3.14it/s][A[h264 @ 0x56241d504dc0] mmco: unref short failure

 71%|███████   | 157/221 [00:57<00:49,  1.30it/s][A
 71%|███████▏  | 158/221 [00:57<00:38,  1.64it/s][A
 72%|███████▏  | 159/221 [00:57<00:29,  2.13it/s][A
 72%|███████▏  | 160/221 [00:58<00:24,  2.49it/s][A
 73%|███████▎  | 161/221 [00:58<00:20,  2.98it/s][A
 73%|███████▎  | 162/221 [00:58<00:17,  3.35it/s][A
 74%|███████▍  | 163/221 [00:58<00:16,  3.48it/s][A
 74%|███████▍  | 164/221 [00:58<00:13,  4.15it/s][A
 75%|███████▍  | 165/221 [00:59<00:11,  4.95it/s][A
 75%|███████▌  | 166/221 [00:59<00:13,  4.03it/s][A
 76%|███████▌  | 167/221 [00:59<00:14,  3.71it/s][A
 76%|███████▌  | 168/221 [01:01<00:43,  1.21it/s][A
 76%|███████▋  | 169/221 [01:02<00:32,  1.58it/s][A
 77%|███████▋  | 170/221 [01:02<00:26,  1.92it/s][A
 77%|███████▋  | 171/221 [01:02<00:22,  2.23it/s][A
 78%|███████▊  | 172/221 [01:02<00:19,  2.54it/s][A
 78%|███████▊  | 173/221 [01:03<00:15,  3.20it/s][A
 79%|███████▊  | 174/221 [01:03<00:11,  4.00it/s][A
 79%|███████▉  | 175/221 [01:03<00:10,  4.36it/s][A
 80%|███████▉  | 176/221 [01:03<00:10,  4.28it/s][A
 80%|████████  | 177/221 [01:03<00:08,  5.02it/s][A
 81%|████████  | 178/221 [01:03<00:10,  4.25it/s][A
 81%|████████  | 179/221 [01:04<00:12,  3.45it/s][A
 82%|████████▏ | 181/221 [01:04<00:08,  4.47it/s][A
 82%|████████▏ | 182/221 [01:04<00:08,  4.60it/s][A
 83%|████████▎ | 183/221 [01:05<00:07,  4.82it/s][A
 83%|████████▎ | 184/221 [01:05<00:09,  4.07it/s][A
 84%|████████▎ | 185/221 [01:05<00:09,  3.92it/s][A
 84%|████████▍ | 186/221 [01:06<00:10,  3.20it/s][A
 85%|████████▍ | 187/221 [01:06<00:08,  3.85it/s][A
 85%|████████▌ | 188/221 [01:06<00:08,  3.78it/s][A
 86%|████████▌ | 189/221 [01:06<00:08,  3.96it/s][A
 86%|████████▌ | 190/221 [01:07<00:08,  3.74it/s][A
 87%|████████▋ | 192/221 [01:07<00:06,  4.83it/s][A
 88%|████████▊ | 194/221 [01:08<00:07,  3.68it/s][A
 88%|████████▊ | 195/221 [01:08<00:06,  3.98it/s][A
 89%|████████▊ | 196/221 [01:08<00:05,  4.55it/s][A
 89%|████████▉ | 197/221 [01:08<00:04,  5.21it/s][A
 90%|████████▉ | 198/221 [01:08<00:05,  3.83it/s][A
 90%|█████████ | 199/221 [01:09<00:04,  4.47it/s][A
 90%|█████████ | 200/221 [01:09<00:05,  3.82it/s][A
 91%|█████████ | 201/221 [01:09<00:04,  4.21it/s][A
 91%|█████████▏| 202/221 [01:09<00:04,  4.46it/s][A
 92%|█████████▏| 203/221 [01:09<00:03,  5.06it/s][A
 92%|█████████▏| 204/221 [01:10<00:03,  5.60it/s][A
 93%|█████████▎| 205/221 [01:10<00:02,  5.51it/s][A
 93%|█████████▎| 206/221 [01:10<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:11<00:02,  4.84it/s][A
 95%|█████████▍| 209/221 [01:11<00:02,  5.52it/s][A
 95%|█████████▌| 211/221 [01:11<00:01,  5.45it/s][A
 96%|█████████▌| 212/221 [01:11<00:01,  5.98it/s][A
 97%|█████████▋| 214/221 [01:12<00:01,  4.80it/s][A
 97%|█████████▋| 215/221 [01:12<00:01,  4.94it/s][A
 98%|█████████▊| 216/221 [01:12<00:01,  4.37it/s][A
 98%|█████████▊| 217/221 [01:13<00:01,  3.65it/s][A
 99%|█████████▊| 218/221 [01:13<00:00,  3.71it/s][A
 99%|█████████▉| 219/221 [01:13<00:00,  3.72it/s][A
100%|█████████▉| 220/221 [01:16<00:00,  1.04it/s][A
100%|██████████| 221/221 [01:16<00:00,  1.34it/s][A100%|██████████| 221/221 [01:16<00:00,  2.89it/s]
[h264 @ 0x559be9882d00] mmco: unref short failure
[h264 @ 0x56241ee57f00] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:04,  3.39it/s][A
  1%|          | 2/221 [00:00<01:00,  3.61it/s][A
  1%|▏         | 3/221 [00:00<00:59,  3.68it/s][A
  2%|▏         | 4/221 [00:01<00:58,  3.70it/s][A
  2%|▏         | 5/221 [00:01<00:57,  3.72it/s][A
  3%|▎         | 6/221 [00:01<00:57,  3.74it/s][A
  3%|▎         | 7/221 [00:01<00:57,  3.75it/s][A[h264 @ 0x55a044b644c0] mmco: unref short failure

  4%|▎         | 8/221 [00:02<00:56,  3.75it/s][A
  4%|▍         | 9/221 [00:02<00:56,  3.76it/s][A
  5%|▍         | 10/221 [00:02<00:56,  3.76it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.77it/s][A
  5%|▌         | 12/221 [00:03<00:56,  3.72it/s][A[h264 @ 0x56242f3dc600] mmco: unref short failure

  6%|▌         | 13/221 [00:03<00:56,  3.71it/s][A
  6%|▋         | 14/221 [00:03<00:55,  3.73it/s][A
  7%|▋         | 15/221 [00:04<00:55,  3.74it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.75it/s][A
  8%|▊         | 17/221 [00:04<00:54,  3.75it/s][h264 @ 0x559be9882b00] mmco: unref short failure
[A[h264 @ 0x559be9882b00] mmco: unref short failure

  8%|▊         | 18/221 [00:04<00:54,  3.74it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.75it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.76it/s][A
 10%|▉         | 21/221 [00:05<00:53,  3.76it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.77it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.77it/s][A
 11%|█         | 24/221 [00:06<00:52,  3.77it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.78it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.78it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.78it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.78it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:09<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:14<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:18<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:23<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.78it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.78it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:28<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:32<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:23,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:42<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:47<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:52<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:56<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:57<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:24,  9.11it/s][A
  1%|          | 2/221 [00:00<00:52,  4.16it/s][A
  1%|▏         | 3/221 [00:00<00:58,  3.74it/s][A
  2%|▏         | 4/221 [00:00<00:49,  4.39it/s][A
  2%|▏         | 5/221 [00:01<00:43,  4.94it/s][A
  3%|▎         | 7/221 [00:01<00:40,  5.33it/s][A
  4%|▎         | 8/221 [00:01<00:49,  4.29it/s][A
  4%|▍         | 9/221 [00:01<00:48,  4.36it/s][A
  5%|▍         | 10/221 [00:02<01:05,  3.24it/s][A
  5%|▍         | 11/221 [00:02<01:00,  3.50it/s][A
  5%|▌         | 12/221 [00:02<00:51,  4.02it/s][A
  6%|▌         | 13/221 [00:03<01:29,  2.33it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.35it/s][A
  7%|▋         | 16/221 [00:04<01:04,  3.18it/s][A
  8%|▊         | 17/221 [00:05<01:26,  2.36it/s][A
  8%|▊         | 18/221 [00:05<01:12,  2.80it/s][A
  9%|▊         | 19/221 [00:05<01:01,  3.26it/s][A
  9%|▉         | 20/221 [00:05<00:50,  4.01it/s][A
 10%|▉         | 21/221 [00:05<00:44,  4.51it/s][A
 10%|▉         | 22/221 [00:05<00:44,  4.48it/s][A
 11%|█         | 24/221 [00:06<00:33,  5.88it/s][A
 11%|█▏        | 25/221 [00:06<00:35,  5.52it/s][A
 12%|█▏        | 26/221 [00:06<00:37,  5.16it/s][A
 12%|█▏        | 27/221 [00:06<00:34,  5.66it/s][A
 13%|█▎        | 28/221 [00:07<00:44,  4.35it/s][A
 13%|█▎        | 29/221 [00:07<00:42,  4.48it/s][A
 14%|█▎        | 30/221 [00:07<00:44,  4.25it/s][A
 14%|█▍        | 31/221 [00:07<00:41,  4.57it/s][A
 15%|█▍        | 33/221 [00:08<00:32,  5.71it/s][A
 15%|█▌        | 34/221 [00:08<00:33,  5.62it/s][A
 16%|█▌        | 35/221 [00:08<00:36,  5.17it/s][A
 16%|█▋        | 36/221 [00:08<00:41,  4.50it/s][A
 17%|█▋        | 37/221 [00:08<00:39,  4.64it/s][A
 17%|█▋        | 38/221 [00:09<00:41,  4.39it/s][A
 18%|█▊        | 39/221 [00:09<00:40,  4.53it/s][A
 18%|█▊        | 40/221 [00:09<00:50,  3.58it/s][A
 19%|█▊        | 41/221 [00:09<00:40,  4.39it/s][A
 19%|█▉        | 42/221 [00:10<00:39,  4.51it/s][A
 19%|█▉        | 43/221 [00:10<00:45,  3.95it/s][A
 20%|█▉        | 44/221 [00:10<00:43,  4.06it/s][A
 20%|██        | 45/221 [00:11<00:47,  3.68it/s][A
 21%|██        | 46/221 [00:11<00:41,  4.21it/s][A
 21%|██▏       | 47/221 [00:11<00:40,  4.27it/s][A
 22%|██▏       | 48/221 [00:11<00:35,  4.89it/s][A
 22%|██▏       | 49/221 [00:11<00:34,  4.93it/s][A
 23%|██▎       | 50/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:12<00:40,  4.15it/s][A
 24%|██▎       | 52/221 [00:12<00:36,  4.60it/s][A
 24%|██▍       | 53/221 [00:12<00:31,  5.33it/s][A
 24%|██▍       | 54/221 [00:13<00:55,  3.01it/s][A
 25%|██▍       | 55/221 [00:13<00:50,  3.26it/s][A
 25%|██▌       | 56/221 [00:13<00:41,  3.98it/s][A
 26%|██▌       | 57/221 [00:13<00:41,  3.92it/s][A
 26%|██▌       | 58/221 [00:14<00:43,  3.72it/s][A
 27%|██▋       | 59/221 [00:14<00:39,  4.09it/s][A
 27%|██▋       | 60/221 [00:14<00:37,  4.24it/s][A
 28%|██▊       | 61/221 [00:14<00:33,  4.71it/s][A
 28%|██▊       | 62/221 [00:15<00:37,  4.28it/s][A
 29%|██▊       | 63/221 [00:15<00:37,  4.18it/s][A
 29%|██▉       | 64/221 [00:15<00:46,  3.37it/s][A
 29%|██▉       | 65/221 [00:15<00:38,  4.05it/s][A
 30%|██▉       | 66/221 [00:16<00:52,  2.95it/s][A
 30%|███       | 67/221 [00:17<01:05,  2.36it/s][A
 31%|███       | 68/221 [00:17<00:52,  2.90it/s][A
 31%|███       | 69/221 [00:18<01:13,  2.06it/s][A
 32%|███▏      | 70/221 [00:18<00:56,  2.69it/s][A
 32%|███▏      | 71/221 [00:18<00:48,  3.10it/s][A
 33%|███▎      | 72/221 [00:18<00:50,  2.96it/s][A
 33%|███▎      | 73/221 [00:19<00:50,  2.93it/s][A
 33%|███▎      | 74/221 [00:19<00:39,  3.71it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.78it/s][A
 34%|███▍      | 76/221 [00:19<00:35,  4.04it/s][A
 35%|███▍      | 77/221 [00:19<00:35,  4.01it/s][A
 35%|███▌      | 78/221 [00:20<00:33,  4.32it/s][A
 36%|███▌      | 79/221 [00:20<00:45,  3.14it/s][A
 36%|███▌      | 80/221 [00:20<00:39,  3.54it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.84it/s][A
 37%|███▋      | 82/221 [00:21<00:37,  3.69it/s][A
 38%|███▊      | 83/221 [00:21<00:42,  3.27it/s][A
 38%|███▊      | 84/221 [00:21<00:37,  3.62it/s][A
 39%|███▉      | 86/221 [00:22<00:32,  4.15it/s][A
 39%|███▉      | 87/221 [00:22<00:45,  2.96it/s][A
 40%|███▉      | 88/221 [00:23<00:49,  2.69it/s][A
 40%|████      | 89/221 [00:23<00:44,  2.98it/s][A
 41%|████      | 90/221 [00:24<00:45,  2.90it/s][A
 41%|████      | 91/221 [00:24<00:35,  3.62it/s][A
 42%|████▏     | 92/221 [00:24<00:36,  3.55it/s][A
 42%|████▏     | 93/221 [00:25<00:56,  2.28it/s][A
 43%|████▎     | 94/221 [00:25<00:50,  2.53it/s][A
 43%|████▎     | 95/221 [00:25<00:44,  2.85it/s][A
 43%|████▎     | 96/221 [00:25<00:39,  3.19it/s][A
 44%|████▍     | 97/221 [00:26<00:33,  3.69it/s][A
 44%|████▍     | 98/221 [00:26<00:32,  3.76it/s][A
 45%|████▍     | 99/221 [00:26<00:29,  4.20it/s][A
 45%|████▌     | 100/221 [00:26<00:28,  4.23it/s][A
 46%|████▌     | 101/221 [00:27<00:28,  4.17it/s][A
 46%|████▌     | 102/221 [00:27<00:51,  2.31it/s][A
 47%|████▋     | 103/221 [00:28<00:39,  2.96it/s][A
 47%|████▋     | 104/221 [00:28<00:34,  3.42it/s][A
 48%|████▊     | 105/221 [00:28<00:34,  3.41it/s][A
 48%|████▊     | 106/221 [00:29<00:42,  2.71it/s][A
 48%|████▊     | 107/221 [00:29<00:37,  3.01it/s][A
 49%|████▉     | 108/221 [00:29<00:34,  3.32it/s][A
 49%|████▉     | 109/221 [00:29<00:27,  4.14it/s][A
 50%|████▉     | 110/221 [00:29<00:27,  3.97it/s][A
 50%|█████     | 111/221 [00:30<00:27,  3.99it/s][A
 51%|█████     | 112/221 [00:30<00:27,  3.93it/s][A
 51%|█████     | 113/221 [00:30<00:24,  4.49it/s][A
 52%|█████▏    | 115/221 [00:30<00:20,  5.16it/s][A
 52%|█████▏    | 116/221 [00:31<00:21,  4.79it/s][A
 53%|█████▎    | 117/221 [00:31<00:23,  4.51it/s][A
 53%|█████▎    | 118/221 [00:31<00:22,  4.54it/s][A
 54%|█████▍    | 119/221 [00:32<00:28,  3.56it/s][A
 54%|█████▍    | 120/221 [00:32<00:25,  4.03it/s][A
 55%|█████▍    | 121/221 [00:32<00:21,  4.75it/s][A
 55%|█████▌    | 122/221 [00:32<00:22,  4.31it/s][A
 56%|█████▌    | 123/221 [00:32<00:22,  4.31it/s][A
 56%|█████▌    | 124/221 [00:33<00:23,  4.14it/s][A
 57%|█████▋    | 125/221 [00:33<00:26,  3.66it/s][A
 57%|█████▋    | 126/221 [00:33<00:22,  4.18it/s][A
 57%|█████▋    | 127/221 [00:34<00:29,  3.18it/s][A
 58%|█████▊    | 128/221 [00:34<00:26,  3.47it/s][A
 58%|█████▊    | 129/221 [00:34<00:22,  4.18it/s][A
 59%|█████▉    | 130/221 [00:34<00:21,  4.28it/s][A
 60%|█████▉    | 132/221 [00:35<00:20,  4.25it/s][A
 60%|██████    | 133/221 [00:35<00:22,  3.95it/s][A
 61%|██████    | 134/221 [00:36<00:29,  3.00it/s][A
 61%|██████    | 135/221 [00:36<00:27,  3.08it/s][A
 62%|██████▏   | 136/221 [00:36<00:25,  3.37it/s][A
 62%|██████▏   | 137/221 [00:36<00:21,  3.89it/s][A
 62%|██████▏   | 138/221 [00:37<00:22,  3.65it/s][A
 63%|██████▎   | 139/221 [00:37<00:30,  2.67it/s][A
 63%|██████▎   | 140/221 [00:37<00:28,  2.85it/s][A
 64%|██████▍   | 141/221 [00:38<00:23,  3.41it/s][A
 64%|██████▍   | 142/221 [00:38<00:21,  3.74it/s][A
 65%|██████▍   | 143/221 [00:39<00:32,  2.43it/s][A
 65%|██████▌   | 144/221 [00:39<00:32,  2.40it/s][A
 66%|██████▌   | 146/221 [00:39<00:19,  3.84it/s][A
 67%|██████▋   | 147/221 [00:39<00:19,  3.76it/s][A
 67%|██████▋   | 148/221 [00:40<00:23,  3.07it/s][A
 67%|██████▋   | 149/221 [00:40<00:22,  3.20it/s][A
 68%|██████▊   | 150/221 [00:40<00:20,  3.44it/s][A
 68%|██████▊   | 151/221 [00:41<00:23,  2.95it/s][A
 69%|██████▉   | 152/221 [00:42<00:40,  1.71it/s][A
 69%|██████▉   | 153/221 [00:42<00:30,  2.23it/s][A
 70%|██████▉   | 154/221 [00:42<00:24,  2.69it/s][A
 70%|███████   | 155/221 [00:43<00:21,  3.11it/s][A
 71%|███████   | 156/221 [00:43<00:22,  2.87it/s][A
 71%|███████   | 157/221 [00:43<00:21,  2.99it/s][A
 71%|███████▏  | 158/221 [00:44<00:20,  3.06it/s][A
 72%|███████▏  | 160/221 [00:44<00:15,  4.04it/s][A
 73%|███████▎  | 161/221 [00:44<00:15,  3.90it/s][A
 73%|███████▎  | 162/221 [00:44<00:13,  4.29it/s][A
 74%|███████▍  | 163/221 [00:45<00:13,  4.19it/s][A
 74%|███████▍  | 164/221 [00:45<00:11,  4.93it/s][A
 75%|███████▍  | 165/221 [00:45<00:11,  4.90it/s][A
 75%|███████▌  | 166/221 [00:45<00:11,  4.75it/s][A
 76%|███████▌  | 167/221 [00:45<00:10,  5.39it/s][A
 76%|███████▌  | 168/221 [00:46<00:10,  5.01it/s][A
 76%|███████▋  | 169/221 [00:46<00:09,  5.42it/s][A
 77%|███████▋  | 170/221 [00:46<00:14,  3.43it/s][A
 77%|███████▋  | 171/221 [00:47<00:14,  3.48it/s][A
 78%|███████▊  | 172/221 [00:47<00:13,  3.75it/s][A
 78%|███████▊  | 173/221 [00:47<00:13,  3.43it/s][A
 79%|███████▊  | 174/221 [00:48<00:18,  2.57it/s][A
 79%|███████▉  | 175/221 [00:48<00:16,  2.76it/s][A
 80%|███████▉  | 176/221 [00:48<00:14,  3.12it/s][A
 80%|████████  | 177/221 [00:48<00:12,  3.57it/s][A
 81%|████████  | 178/221 [00:49<00:12,  3.50it/s][A
 81%|████████  | 179/221 [00:49<00:11,  3.68it/s][A
 81%|████████▏ | 180/221 [00:49<00:09,  4.36it/s][A
 82%|████████▏ | 181/221 [00:49<00:09,  4.42it/s][A
 82%|████████▏ | 182/221 [00:50<00:11,  3.27it/s][A
 83%|████████▎ | 183/221 [00:50<00:11,  3.37it/s][A
 83%|████████▎ | 184/221 [00:50<00:10,  3.58it/s][A
 84%|████████▎ | 185/221 [00:50<00:08,  4.16it/s][A
 84%|████████▍ | 186/221 [00:51<00:09,  3.53it/s][A
 85%|████████▍ | 187/221 [00:51<00:09,  3.74it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.54it/s][A
 86%|████████▌ | 189/221 [00:52<00:08,  3.65it/s][A
 86%|████████▌ | 190/221 [00:52<00:09,  3.35it/s][A
 86%|████████▋ | 191/221 [00:52<00:07,  3.90it/s][A
 87%|████████▋ | 192/221 [00:52<00:07,  3.78it/s][A
 88%|████████▊ | 194/221 [00:53<00:06,  4.34it/s][A
 88%|████████▊ | 195/221 [00:53<00:06,  4.27it/s][A
 89%|████████▊ | 196/221 [00:54<00:08,  3.03it/s][A
 89%|████████▉ | 197/221 [00:54<00:07,  3.23it/s][A
 90%|████████▉ | 198/221 [00:54<00:08,  2.72it/s][A
 90%|█████████ | 199/221 [00:55<00:07,  3.13it/s][A
 90%|█████████ | 200/221 [00:55<00:08,  2.59it/s][A
 91%|█████████ | 201/221 [00:55<00:06,  2.99it/s][A
 91%|█████████▏| 202/221 [00:56<00:06,  2.85it/s][A
 92%|█████████▏| 203/221 [00:56<00:05,  3.14it/s][A
 92%|█████████▏| 204/221 [00:56<00:06,  2.78it/s][A
 93%|█████████▎| 206/221 [00:57<00:04,  3.32it/s][A
 94%|█████████▎| 207/221 [00:57<00:03,  3.90it/s][A
 94%|█████████▍| 208/221 [00:57<00:03,  3.75it/s][A
 95%|█████████▍| 209/221 [00:58<00:03,  3.63it/s][A
 95%|█████████▌| 211/221 [00:58<00:02,  4.16it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  4.07it/s][A
 96%|█████████▋| 213/221 [00:59<00:01,  4.15it/s][A
 97%|█████████▋| 214/221 [00:59<00:02,  2.87it/s][A
 97%|█████████▋| 215/221 [00:59<00:01,  3.31it/s][A
 98%|█████████▊| 216/221 [01:00<00:01,  3.47it/s][A
 98%|█████████▊| 217/221 [01:00<00:01,  3.34it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.34it/s][A
 99%|█████████▉| 219/221 [01:01<00:00,  3.29it/s][A
100%|█████████▉| 220/221 [01:01<00:00,  3.70it/s][A
100%|██████████| 221/221 [01:01<00:00,  3.73it/s][A100%|██████████| 221/221 [01:01<00:00,  3.59it/s]
09/09/2024 20:36:54 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 649--===========

09/09/2024 20:36:54 - INFO - __main__ -   {'area_r1': 39.5, 'area_recall': '39.5/65.2/75.7', 'area_ravg': 60.1}
09/09/2024 20:36:54 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 649--===========

09/09/2024 20:36:54 - INFO - __main__ -   {'forward_r1': 37.1, 'forward_recall': '37.1/65.8/76.2', 'forward_ravg': 59.7}
09/09/2024 20:36:54 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 649--===========

09/09/2024 20:36:54 - INFO - __main__ -   {'area_video_r1': 40.5, 'area_video_recall': '40.5/66.7/78.5', 'area_video_ravg': 61.9}
09/09/2024 20:36:54 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/09/2024 20:36:54 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 20:36:54 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 649--===========

09/09/2024 20:36:54 - INFO - __main__ -   {'area_video_r1': 52.3, 'area_video_recall': '52.3/74.5/82.2', 'area_video_ravg': 69.7, 'area_video_back_r1': 49.7, 'area_video_back_recall': '49.7/74.7/81.2', 'area_video_back_ravg': 68.5}
09/09/2024 20:36:54 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/09/2024 20:36:54 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/09/2024 20:36:54 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 649--===========

09/09/2024 20:36:54 - INFO - __main__ -   {'video_r1': 42.6, 'video_recall': '42.6/70.1/82.0', 'video_ravg': 64.9}
09/09/2024 20:36:54 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 20:36:54 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 20:36:54 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 649--===========

09/09/2024 20:36:54 - INFO - __main__ -   {'video_r1': 51.7, 'video_recall': '51.7/74.5/82.6', 'video_ravg': 69.6}
09/09/2024 20:36:54 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/09/2024 20:36:54 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/09/2024 20:37:15 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.0075563485734164715, 'loss_ret%tv%ta--finetune_area/loss_area': 1.0901212692260742, 'loss_ret%tv%ta--finetune_area/total_loss': 1.0976775884628296}
 33%|███▎      | 650/1945 [3:31:56<43:52:43, 121.98s/it] 33%|███▎      | 651/1945 [3:32:00<31:08:01, 86.62s/it]  34%|███▎      | 652/1945 [3:32:05<22:16:53, 62.04s/it][h264 @ 0x55a03dd81cc0] mmco: unref short failure
[h264 @ 0x556b3183d400] mmco: unref short failure
 34%|███▎      | 653/1945 [3:32:10<16:08:51, 44.99s/it][h264 @ 0x559bff1c4440] mmco: unref short failure
[h264 @ 0x562416bc4ac0] mmco: unref short failure
[h264 @ 0x562416bc4ac0] mmco: unref short failure
[h264 @ 0x562416bc4ac0] mmco: unref short failure
[h264 @ 0x562416bc4ac0] mmco: unref short failure
 34%|███▎      | 654/1945 [3:32:16<11:54:53, 33.23s/it] 34%|███▎      | 655/1945 [3:32:22<8:57:19, 24.99s/it] [h264 @ 0x562418e2f700] mmco: unref short failure
[h264 @ 0x562418e2f700] mmco: unref short failure
[h264 @ 0x556b4b63f400] mmco: unref short failure
[h264 @ 0x562421705640] mmco: unref short failure
[h264 @ 0x562421705640] mmco: unref short failure
[h264 @ 0x56241877ef00] mmco: unref short failure
 34%|███▎      | 656/1945 [3:32:28<6:57:54, 19.45s/it][h264 @ 0x559bf0b70980] mmco: unref short failure
 34%|███▍      | 657/1945 [3:32:35<5:35:15, 15.62s/it][h264 @ 0x559bf5763000] mmco: unref short failure
[h264 @ 0x559bf5763000] mmco: unref short failure
 34%|███▍      | 658/1945 [3:32:42<4:41:08, 13.11s/it][h264 @ 0x562418431d80] mmco: unref short failure
[h264 @ 0x562418431d80] mmco: unref short failure
 34%|███▍      | 659/1945 [3:32:49<3:58:49, 11.14s/it][h264 @ 0x556b4e6bc0c0] mmco: unref short failure
[h264 @ 0x556b4e6bc0c0] mmco: unref short failure
[h264 @ 0x562417366e40] mmco: unref short failure
 34%|███▍      | 660/1945 [3:32:55<3:28:34,  9.74s/it] 34%|███▍      | 661/1945 [3:33:03<3:16:39,  9.19s/it][h264 @ 0x55a05254be80] mmco: unref short failure
[h264 @ 0x55a05254be80] mmco: unref short failure
 34%|███▍      | 662/1945 [3:33:10<3:01:53,  8.51s/it][h264 @ 0x5624181e1640] mmco: unref short failure
[h264 @ 0x5624181e1640] mmco: unref short failure
[h264 @ 0x55a043222c40] mmco: unref short failure
[h264 @ 0x55a043222c40] mmco: unref short failure
 34%|███▍      | 663/1945 [3:33:16<2:48:06,  7.87s/it][h264 @ 0x556b38c6ecc0] mmco: unref short failure
[h264 @ 0x556b2d908d00] mmco: unref short failure
[h264 @ 0x562424cbaf80] mmco: unref short failure
[h264 @ 0x562424cbaf80] mmco: unref short failure
 34%|███▍      | 664/1945 [3:33:26<2:59:03,  8.39s/it] 34%|███▍      | 665/1945 [3:33:33<2:49:02,  7.92s/it][h264 @ 0x556b49786000] mmco: unref short failure
[h264 @ 0x559bf72e2000] mmco: unref short failure
[h264 @ 0x559bf72e2000] mmco: unref short failure
 34%|███▍      | 666/1945 [3:33:39<2:41:38,  7.58s/it][h264 @ 0x5624214f5dc0] mmco: unref short failure
[h264 @ 0x5624214f5dc0] mmco: unref short failure
[h264 @ 0x556b2d908a80] mmco: unref short failure
[h264 @ 0x556b2d908a80] mmco: unref short failure
[h264 @ 0x55a037f8dc80] mmco: unref short failure
[h264 @ 0x55a037f8dc80] mmco: unref short failure
 34%|███▍      | 667/1945 [3:34:00<4:04:37, 11.48s/it] 34%|███▍      | 668/1945 [3:34:08<3:39:40, 10.32s/it][h264 @ 0x556b464adfc0] mmco: unref short failure
[h264 @ 0x556b3c0243c0] mmco: unref short failure
[h264 @ 0x556b3c0243c0] mmco: unref short failure
[h264 @ 0x559bf0b83ec0] mmco: unref short failure
 34%|███▍      | 669/1945 [3:34:16<3:29:37,  9.86s/it][h264 @ 0x56242b311f80] mmco: unref short failure
[h264 @ 0x56242b311f80] mmco: unref short failure
[h264 @ 0x56242b311f80] mmco: unref short failure
[h264 @ 0x56242b311f80] mmco: unref short failure
 34%|███▍      | 670/1945 [3:34:24<3:12:51,  9.08s/it][h264 @ 0x56241692e240] mmco: unref short failure
 34%|███▍      | 671/1945 [3:34:34<3:22:07,  9.52s/it] 35%|███▍      | 672/1945 [3:34:41<3:03:34,  8.65s/it][h264 @ 0x562416bd5ec0] mmco: unref short failure
 35%|███▍      | 673/1945 [3:34:49<2:58:25,  8.42s/it][h264 @ 0x556b43f69d80] mmco: unref short failure
[h264 @ 0x556b43f69d80] mmco: unref short failure
[h264 @ 0x55a033703180] mmco: unref short failure
[h264 @ 0x55a033703180] mmco: unref short failure
[h264 @ 0x56241e8c6200] mmco: unref short failure
[h264 @ 0x56242a27e8c0] mmco: unref short failure
[h264 @ 0x56242a27e8c0] mmco: unref short failure
[h264 @ 0x562427279c40] mmco: unref short failure
[h264 @ 0x562427279c40] mmco: unref short failure
[h264 @ 0x562427279c40] mmco: unref short failure
[h264 @ 0x562427279c40] mmco: unref short failure
[h264 @ 0x559bea62ed40] mmco: unref short failure
[h264 @ 0x559bea62ed40] mmco: unref short failure
[h264 @ 0x559be9bcdf00] mmco: unref short failure
[h264 @ 0x556b38b55f80] mmco: unref short failure
[h264 @ 0x556b38b55f80] mmco: unref short failure
[h264 @ 0x55a0512015c0] mmco: unref short failure
[h264 @ 0x56242727a0c0] mmco: unref short failure
[h264 @ 0x55a04ce43740] mmco: unref short failure
 35%|███▍      | 674/1945 [3:35:30<6:28:28, 18.34s/it][h264 @ 0x55a0332d5480] mmco: unref short failure
[h264 @ 0x556b439e1f80] mmco: unref short failure
[h264 @ 0x559bf3f7ed40] mmco: unref short failure
 35%|███▍      | 675/1945 [3:35:59<7:36:30, 21.57s/it][h264 @ 0x55a04957a080] mmco: unref short failure
[h264 @ 0x55a04957a080] mmco: unref short failure
[h264 @ 0x55a04957a080] mmco: unref short failure
[h264 @ 0x55a04957a080] mmco: unref short failure
[h264 @ 0x556b36884340] mmco: unref short failure
[h264 @ 0x556b36884340] mmco: unref short failure
[h264 @ 0x55a04f83b380] mmco: unref short failure
[h264 @ 0x55a04f83b380] mmco: unref short failure
[h264 @ 0x559c09c86700] mmco: unref short failure
[h264 @ 0x559c09c86700] mmco: unref short failure
 35%|███▍      | 676/1945 [3:36:08<6:11:37, 17.57s/it][h264 @ 0x559bea1f5cc0] mmco: unref short failure
 35%|███▍      | 677/1945 [3:36:17<5:17:31, 15.03s/it][h264 @ 0x559beb4e2e00] mmco: unref short failure
[h264 @ 0x556b2db9e200] mmco: unref short failure
[h264 @ 0x559bec26f600] mmco: unref short failure
[h264 @ 0x559bec26f600] mmco: unref short failure
[h264 @ 0x559bec26f600] mmco: unref short failure
[h264 @ 0x559bec26f600] mmco: unref short failure
[h264 @ 0x559bf98a3ac0] mmco: unref short failure
 35%|███▍      | 678/1945 [3:36:24<4:30:35, 12.81s/it][h264 @ 0x559bf98a3ac0] mmco: unref short failure
[h264 @ 0x55a044f0d000] mmco: unref short failure
[h264 @ 0x55a044f0d000] mmco: unref short failure
 35%|███▍      | 679/1945 [3:36:36<4:21:56, 12.41s/it][h264 @ 0x56241ee57f00] mmco: unref short failure
[h264 @ 0x56241ee57f00] mmco: unref short failure
 35%|███▍      | 680/1945 [3:36:44<3:53:33, 11.08s/it][h264 @ 0x562418c27f80] mmco: unref short failure
[h264 @ 0x559bf8197ec0] mmco: unref short failure
[h264 @ 0x55a044b644c0] mmco: unref short failure
[h264 @ 0x55a04eb87cc0] mmco: unref short failure
[h264 @ 0x55a04eb87cc0] mmco: unref short failure
 35%|███▌      | 681/1945 [3:36:52<3:34:31, 10.18s/it][h264 @ 0x55a04eb87cc0] mmco: unref short failure
[h264 @ 0x55a04eb87cc0] mmco: unref short failure
[h264 @ 0x5624230d3100] mmco: unref short failure
[h264 @ 0x559beaefba40] mmco: unref short failure
[h264 @ 0x55a03c2da2c0] mmco: unref short failure
[h264 @ 0x55a03c2da2c0] mmco: unref short failure
[h264 @ 0x556b4e9d7180] mmco: unref short failure
[h264 @ 0x556b4e9d7180] mmco: unref short failure
[h264 @ 0x556b43a40c40] mmco: unref short failure
[h264 @ 0x56242d738240] mmco: unref short failure
[h264 @ 0x56242d738240] mmco: unref short failure
[h264 @ 0x56242c4accc0] mmco: unref short failure
[h264 @ 0x56242727a080] mmco: unref short failure
[h264 @ 0x56242727a080] mmco: unref short failure
[h264 @ 0x556b42dd3dc0] mmco: unref short failure
[h264 @ 0x556b3ef99840] mmco: unref short failure
[h264 @ 0x556b3ef99840] mmco: unref short failure
[h264 @ 0x55a03dcdc740] mmco: unref short failure
[h264 @ 0x55a03dcdc740] mmco: unref short failure
 35%|███▌      | 682/1945 [3:37:37<7:12:40, 20.55s/it][h264 @ 0x556b47672e00] mmco: unref short failure
[h264 @ 0x56241f05f380] mmco: unref short failure
[h264 @ 0x56241f05f380] mmco: unref short failure
[h264 @ 0x559beaae3080] mmco: unref short failure
[h264 @ 0x559c0063b240] mmco: unref short failure
 35%|███▌      | 683/1945 [3:38:01<7:35:33, 21.66s/it][h264 @ 0x56242e89aa40] mmco: unref short failure
[h264 @ 0x56242e89aa40] mmco: unref short failure
[h264 @ 0x55a0371e0d00] mmco: unref short failure
[h264 @ 0x56242c93e780] mmco: unref short failure
[h264 @ 0x56242c93e780] mmco: unref short failure
[h264 @ 0x56242c93e780] mmco: unref short failure
[h264 @ 0x56242c93e780] mmco: unref short failure
[h264 @ 0x559be9c24ec0] mmco: unref short failure
[h264 @ 0x559be9c24ec0] mmco: unref short failure
[h264 @ 0x556b36884f40] mmco: unref short failure
[h264 @ 0x556b36884f40] mmco: unref short failure
[h264 @ 0x56241d05f0c0] mmco: unref short failure
 35%|███▌      | 684/1945 [3:38:08<6:02:56, 17.27s/it][h264 @ 0x562424758d40] mmco: unref short failure
[h264 @ 0x562424759400] mmco: unref short failure
[h264 @ 0x562424759400] mmco: unref short failure
[h264 @ 0x556b40214c80] mmco: unref short failure
[h264 @ 0x556b40214c80] mmco: unref short failure
 35%|███▌      | 685/1945 [3:38:22<5:43:39, 16.36s/it][h264 @ 0x55a03a684900] mmco: unref short failure
[h264 @ 0x55a0508e3140] mmco: unref short failure
[h264 @ 0x55a0508e3140] mmco: unref short failure
 35%|███▌      | 686/1945 [3:38:35<5:21:43, 15.33s/it] 35%|███▌      | 687/1945 [3:38:43<4:33:22, 13.04s/it][h264 @ 0x56242acef6c0] mmco: unref short failure
[h264 @ 0x562435979940] mmco: unref short failure
 35%|███▌      | 688/1945 [3:38:51<4:05:58, 11.74s/it][h264 @ 0x559be9e9f100] mmco: unref short failure
[h264 @ 0x559be9e9f100] mmco: unref short failure
[h264 @ 0x559be9e9f100] mmco: unref short failure
[h264 @ 0x56242bca8080] mmco: unref short failure
[h264 @ 0x55a047d49fc0] mmco: unref short failure
[h264 @ 0x55a047d49fc0] mmco: unref short failure
 35%|███▌      | 689/1945 [3:38:59<3:42:44, 10.64s/it][h264 @ 0x556b36148440] mmco: unref short failure
[h264 @ 0x556b36148440] mmco: unref short failure
[h264 @ 0x55a0380552c0] mmco: unref short failure
[h264 @ 0x556b312b12c0] mmco: unref short failure
[h264 @ 0x55a03a684900] mmco: unref short failure
[h264 @ 0x55a03a684900] mmco: unref short failure
[h264 @ 0x55a03a684900] mmco: unref short failure
[h264 @ 0x55a03a684900] mmco: unref short failure
[h264 @ 0x559bf26784c0] mmco: unref short failure
[h264 @ 0x55a03bbe1840] mmco: unref short failure
[h264 @ 0x556b38b97fc0] mmco: unref short failure
[h264 @ 0x556b38b97fc0] mmco: unref short failure
[h264 @ 0x55a042a8db00] mmco: unref short failure
[h264 @ 0x556b475f2580] mmco: unref short failure
[h264 @ 0x5624316d7d00] mmco: unref short failure
[h264 @ 0x5624316d7d00] mmco: unref short failure
[h264 @ 0x556b35c005c0] mmco: unref short failure
[h264 @ 0x559bea263680] mmco: unref short failure
[h264 @ 0x556b4d9cfe00] mmco: unref short failure
 35%|███▌      | 690/1945 [3:39:39<6:46:30, 19.44s/it][h264 @ 0x559bf2fdf240] mmco: unref short failure
[h264 @ 0x559bf2fdf240] mmco: unref short failure
[h264 @ 0x55a04b3af980] mmco: unref short failure
 36%|███▌      | 691/1945 [3:40:01<7:00:02, 20.10s/it][h264 @ 0x559bed2afc00] mmco: unref short failure
[h264 @ 0x559bed2afc00] mmco: unref short failure
 36%|███▌      | 692/1945 [3:40:09<5:46:21, 16.59s/it][h264 @ 0x559c0cdfbc40] mmco: unref short failure
[h264 @ 0x559c0cdfbc40] mmco: unref short failure
 36%|███▌      | 693/1945 [3:40:24<5:31:00, 15.86s/it][h264 @ 0x559c008f5800] mmco: unref short failure
[h264 @ 0x559bffcf3ac0] mmco: unref short failure
[h264 @ 0x559bffcf3ac0] mmco: unref short failure
[h264 @ 0x562431337a40] mmco: unref short failure
[h264 @ 0x562431337a40] mmco: unref short failure
[h264 @ 0x559c027f7c00] mmco: unref short failure
[h264 @ 0x55a0427f51c0] mmco: unref short failure
[h264 @ 0x559bffddc340] mmco: unref short failure
[h264 @ 0x559bffddc340] mmco: unref short failure
[h264 @ 0x559bffddc340] mmco: unref short failure
[h264 @ 0x559bffddc340] mmco: unref short failure
 36%|███▌      | 694/1945 [3:40:40<5:34:29, 16.04s/it][h264 @ 0x5624186434c0] mmco: unref short failure
[h264 @ 0x5624186434c0] mmco: unref short failure
[h264 @ 0x5624186434c0] mmco: unref short failure
 36%|███▌      | 695/1945 [3:40:48<4:41:25, 13.51s/it][h264 @ 0x56241f7f7740] mmco: unref short failure
[h264 @ 0x56241f7f7740] mmco: unref short failure
[h264 @ 0x556b30eb5080] mmco: unref short failure
[h264 @ 0x556b30eb5080] mmco: unref short failure
[h264 @ 0x55a0508e3340] mmco: unref short failure
[h264 @ 0x55a0508e3340] mmco: unref short failure
 36%|███▌      | 696/1945 [3:40:55<4:02:38, 11.66s/it][h264 @ 0x556b318c2680] mmco: unref short failure
 36%|███▌      | 697/1945 [3:41:03<3:36:31, 10.41s/it][h264 @ 0x556b40215040] mmco: unref short failure
[h264 @ 0x55a04d280340] mmco: unref short failure
[h264 @ 0x55a0394d8240] mmco: unref short failure
[h264 @ 0x55a0394d8240] mmco: unref short failure
[h264 @ 0x562437f60140] mmco: unref short failure
[h264 @ 0x562437f60140] mmco: unref short failure
[h264 @ 0x556b488dbe80] mmco: unref short failure
[h264 @ 0x556b488dbe80] mmco: unref short failure
[h264 @ 0x55a039355d40] mmco: unref short failure
[h264 @ 0x55a039355d40] mmco: unref short failure
 36%|███▌      | 698/1945 [3:41:46<7:05:14, 20.46s/it][h264 @ 0x55a04e8948c0] mmco: unref short failure
[h264 @ 0x55a04e8948c0] mmco: unref short failure
[h264 @ 0x559beb1d3b80] mmco: unref short failure
[h264 @ 0x559beb1d3b80] mmco: unref short failure
[h264 @ 0x556b4770ba40] mmco: unref short failure
[h264 @ 0x556b4770ba40] mmco: unref short failure
 36%|███▌      | 699/1945 [3:42:07<7:06:32, 20.54s/it]09/09/2024 20:47:29 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 20:47:29 - INFO - __main__ -   start running ret%tv validation...
[h264 @ 0x55a03e1515c0] mmco: unref short failure
[h264 @ 0x556b44ddf840] mmco: unref short failure
[h264 @ 0x559bff1b2cc0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559c04dcd340] mmco: unref short failure
[h264 @ 0x559c04dcd340] mmco: unref short failure
[h264 @ 0x55a04a5e3780] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559bf0ead340] mmco: unref short failure
[h264 @ 0x559bf0ead340] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x56243431f1c0] mmco: unref short failure
[h264 @ 0x56243431f1c0] mmco: unref short failure
[h264 @ 0x56243431f1c0] mmco: unref short failure
[h264 @ 0x56243431f1c0] mmco: unref short failure
[h264 @ 0x556b3692d980] mmco: unref short failure
[h264 @ 0x559be972cb00] mmco: unref short failure
[h264 @ 0x559be972cb00] mmco: unref short failure
[h264 @ 0x559be8fae140] mmco: unref short failure
[h264 @ 0x559be8fae140] mmco: unref short failure
[h264 @ 0x559c008f5800] mmco: unref short failure
[h264 @ 0x559c008f5800] mmco: unref short failure
[h264 @ 0x562427588800] mmco: unref short failure
[h264 @ 0x562427588800] mmco: unref short failure
[h264 @ 0x55a0416c7a00] mmco: unref short failure
[h264 @ 0x55a03afc27c0] mmco: unref short failure
[h264 @ 0x55a03afc27c0] mmco: unref short failure
[h264 @ 0x55a03afc27c0] mmco: unref short failure
[h264 @ 0x559c00751d00] mmco: unref short failure
[h264 @ 0x55a0416c7a00] mmco: unref short failure
[h264 @ 0x55a0416c7a00] mmco: unref short failure
[h264 @ 0x56242cef5940] mmco: unref short failure
[h264 @ 0x56242cef5940] mmco: unref short failure
[h264 @ 0x559c05684d40] mmco: unref short failure
[h264 @ 0x559c05684d40] mmco: unref short failure
[h264 @ 0x556b44c6eb80] mmco: unref short failure
[h264 @ 0x556b44c6eb80] mmco: unref short failure
[h264 @ 0x556b44c6eb80] mmco: unref short failure
[h264 @ 0x556b44c6eb80] mmco: unref short failure
[h264 @ 0x559bee33c080] mmco: unref short failure
[h264 @ 0x559beaf33440] mmco: unref short failure
[h264 @ 0x559beaf33440] mmco: unref short failure
[h264 @ 0x55a04c565d00] mmco: unref short failure
[h264 @ 0x55a04c565d00] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:41,  2.16it/s][A
  1%|          | 2/221 [00:00<01:39,  2.21it/s][A
  1%|▏         | 3/221 [00:01<01:12,  3.00it/s][A
  2%|▏         | 5/221 [00:01<00:47,  4.54it/s][A
  3%|▎         | 6/221 [00:01<00:54,  3.94it/s][A
  3%|▎         | 7/221 [00:02<00:59,  3.59it/s][A
  4%|▎         | 8/221 [00:02<01:09,  3.09it/s][A
  4%|▍         | 9/221 [00:02<01:05,  3.23it/s][A
  5%|▍         | 10/221 [00:03<01:16,  2.75it/s][A
  5%|▍         | 11/221 [00:03<01:02,  3.38it/s][A[h264 @ 0x559c04b41a40] mmco: unref short failure

  5%|▌         | 12/221 [00:04<01:26,  2.43it/s][A
  6%|▌         | 13/221 [00:04<01:09,  2.98it/s][A
  6%|▋         | 14/221 [00:05<02:02,  1.69it/s][A
  7%|▋         | 15/221 [00:05<01:42,  2.00it/s][A
  7%|▋         | 16/221 [00:06<01:31,  2.24it/s][A
  8%|▊         | 17/221 [00:06<01:15,  2.69it/s][A
  8%|▊         | 18/221 [00:06<01:15,  2.68it/s][A
  9%|▊         | 19/221 [00:06<01:02,  3.22it/s][A
  9%|▉         | 20/221 [00:06<00:53,  3.77it/s][A
 10%|▉         | 21/221 [00:07<00:46,  4.28it/s][A
 10%|▉         | 22/221 [00:07<00:46,  4.26it/s][A
 10%|█         | 23/221 [00:07<00:44,  4.44it/s][A
 11%|█         | 24/221 [00:07<00:39,  5.01it/s][A
 11%|█▏        | 25/221 [00:07<00:34,  5.62it/s][A
 12%|█▏        | 26/221 [00:08<00:43,  4.52it/s][A
 13%|█▎        | 28/221 [00:08<00:43,  4.40it/s][A
 13%|█▎        | 29/221 [00:08<00:39,  4.82it/s][A
 14%|█▎        | 30/221 [00:09<00:47,  4.01it/s][A
 14%|█▍        | 31/221 [00:09<00:45,  4.21it/s][A
 14%|█▍        | 32/221 [00:09<00:39,  4.79it/s][A
 15%|█▍        | 33/221 [00:09<00:42,  4.42it/s][A
 15%|█▌        | 34/221 [00:09<00:36,  5.06it/s][A
 16%|█▌        | 35/221 [00:09<00:33,  5.50it/s][A
 16%|█▋        | 36/221 [00:10<00:42,  4.37it/s][A
 17%|█▋        | 37/221 [00:11<01:17,  2.38it/s][A
 17%|█▋        | 38/221 [00:11<01:15,  2.42it/s][A
 18%|█▊        | 40/221 [00:11<00:57,  3.15it/s][A
 19%|█▊        | 41/221 [00:12<00:47,  3.78it/s][A
 19%|█▉        | 42/221 [00:12<00:54,  3.29it/s][A
 19%|█▉        | 43/221 [00:12<00:55,  3.23it/s][A
 20%|█▉        | 44/221 [00:13<00:58,  3.00it/s][A
 20%|██        | 45/221 [00:14<01:27,  2.00it/s][A
 21%|██        | 46/221 [00:14<01:23,  2.09it/s][A[h264 @ 0x559c08548a00] mmco: unref short failure
[h264 @ 0x559c08548a00] mmco: unref short failure
[h264 @ 0x55a032fdf100] mmco: unref short failure
[h264 @ 0x55a032fdf100] mmco: unref short failure
[h264 @ 0x55a032fdf100] mmco: unref short failure
[h264 @ 0x55a032fdf100] mmco: unref short failure
[h264 @ 0x55a032fdf100] mmco: unref short failure
[h264 @ 0x55a032fdf100] mmco: unref short failure

 21%|██▏       | 47/221 [00:15<01:36,  1.81it/s][A
 22%|██▏       | 48/221 [00:15<01:14,  2.31it/s][A
 22%|██▏       | 49/221 [00:15<00:58,  2.92it/s][A
 23%|██▎       | 50/221 [00:15<00:46,  3.69it/s][A
 24%|██▎       | 52/221 [00:15<00:33,  5.08it/s][A
 24%|██▍       | 53/221 [00:16<00:30,  5.54it/s][A
 24%|██▍       | 54/221 [00:17<01:38,  1.70it/s][A
 25%|██▍       | 55/221 [00:18<01:23,  2.00it/s][A[h264 @ 0x556b49a12dc0] mmco: unref short failure

 25%|██▌       | 56/221 [00:18<01:12,  2.27it/s][A
 26%|██▌       | 57/221 [00:18<01:14,  2.21it/s][A
 26%|██▌       | 58/221 [00:19<01:02,  2.60it/s][A
 27%|██▋       | 59/221 [00:19<00:52,  3.08it/s][A[h264 @ 0x56242758ae80] mmco: unref short failure
[h264 @ 0x56242758ae80] mmco: unref short failure
[h264 @ 0x56242758ae80] mmco: unref short failure
[h264 @ 0x56242758ae80] mmco: unref short failure
[h264 @ 0x56242758ae80] mmco: unref short failure
[h264 @ 0x56242758ae80] mmco: unref short failure

 27%|██▋       | 60/221 [00:19<01:02,  2.59it/s][A[h264 @ 0x556b3a2a72c0] mmco: unref short failure

 28%|██▊       | 61/221 [00:19<00:53,  2.98it/s][A
 28%|██▊       | 62/221 [00:20<00:52,  3.04it/s][A
 29%|██▊       | 63/221 [00:20<00:45,  3.45it/s][A
 29%|██▉       | 64/221 [00:20<00:47,  3.30it/s][A
 29%|██▉       | 65/221 [00:20<00:41,  3.73it/s][A
 30%|██▉       | 66/221 [00:21<00:53,  2.92it/s][A[h264 @ 0x55a0416c7a00] mmco: unref short failure
[h264 @ 0x55a0416c7a00] mmco: unref short failure

[h264 @ 0x562422ce9480] mmco: unref short failure
 30%|███       | 67/221 [00:21<00:56,  2.74it/s][A
 31%|███       | 68/221 [00:22<00:48,  3.13it/s][A
 31%|███       | 69/221 [00:22<01:01,  2.47it/s][A
 32%|███▏      | 70/221 [00:22<00:48,  3.08it/s][A
 32%|███▏      | 71/221 [00:24<01:30,  1.66it/s][A
 33%|███▎      | 72/221 [00:24<01:17,  1.93it/s][A
 33%|███▎      | 73/221 [00:24<01:06,  2.22it/s][A
 33%|███▎      | 74/221 [00:24<00:52,  2.82it/s][A
 34%|███▍      | 75/221 [00:25<00:50,  2.90it/s][A[h264 @ 0x556b41ea2bc0] mmco: unref short failure

 34%|███▍      | 76/221 [00:25<00:43,  3.33it/s][A
 35%|███▍      | 77/221 [00:25<00:39,  3.63it/s][A
 35%|███▌      | 78/221 [00:25<00:38,  3.70it/s][A[h264 @ 0x562429464d40] mmco: unref short failure
[h264 @ 0x562429464d40] mmco: unref short failure
[h264 @ 0x562429464d40] mmco: unref short failure
[h264 @ 0x562429464d40] mmco: unref short failure

 36%|███▌      | 79/221 [00:26<00:51,  2.78it/s][A
 36%|███▌      | 80/221 [00:26<00:41,  3.40it/s][A
 37%|███▋      | 81/221 [00:26<00:39,  3.56it/s][A[h264 @ 0x556b45a4dd80] mmco: unref short failure
[h264 @ 0x556b45a4dd80] mmco: unref short failure

 37%|███▋      | 82/221 [00:27<00:34,  4.00it/s][A
 38%|███▊      | 83/221 [00:27<00:31,  4.35it/s][A
 38%|███▊      | 84/221 [00:27<00:30,  4.56it/s][A
 39%|███▉      | 86/221 [00:27<00:24,  5.58it/s][A
 39%|███▉      | 87/221 [00:28<00:35,  3.77it/s][A
 40%|███▉      | 88/221 [00:28<00:35,  3.72it/s][A
 40%|████      | 89/221 [00:30<01:26,  1.53it/s][A
 41%|████      | 90/221 [00:30<01:17,  1.68it/s][A
 41%|████      | 91/221 [00:30<01:04,  2.02it/s][A
 42%|████▏     | 92/221 [00:31<00:57,  2.24it/s][A
 42%|████▏     | 93/221 [00:31<01:02,  2.04it/s][A
 43%|████▎     | 94/221 [00:32<00:55,  2.30it/s][A
 43%|████▎     | 95/221 [00:32<00:46,  2.69it/s][A
 43%|████▎     | 96/221 [00:32<00:41,  3.03it/s][A
 44%|████▍     | 97/221 [00:32<00:33,  3.71it/s][A
 44%|████▍     | 98/221 [00:32<00:31,  3.87it/s][A
 45%|████▍     | 99/221 [00:32<00:26,  4.66it/s][A
 45%|████▌     | 100/221 [00:33<00:26,  4.63it/s][A
 46%|████▌     | 101/221 [00:33<00:24,  4.88it/s][A
 46%|████▌     | 102/221 [00:33<00:33,  3.58it/s][A
 47%|████▋     | 103/221 [00:34<00:31,  3.69it/s][A
 47%|████▋     | 104/221 [00:34<00:26,  4.49it/s][A
 48%|████▊     | 105/221 [00:34<00:26,  4.30it/s][A
 48%|████▊     | 106/221 [00:35<00:52,  2.19it/s][A
 48%|████▊     | 107/221 [00:35<00:43,  2.63it/s][A
 49%|████▉     | 108/221 [00:35<00:36,  3.12it/s][A
 49%|████▉     | 109/221 [00:36<00:35,  3.17it/s][A
 50%|████▉     | 110/221 [00:36<00:32,  3.43it/s][A
 50%|█████     | 111/221 [00:36<00:37,  2.94it/s][A
 51%|█████     | 112/221 [00:37<00:32,  3.37it/s][A
 51%|█████     | 113/221 [00:37<00:36,  2.94it/s][A
 52%|█████▏    | 114/221 [00:37<00:28,  3.72it/s][A
 52%|█████▏    | 115/221 [00:37<00:24,  4.35it/s][A[h264 @ 0x559bf1fa91c0] mmco: unref short failure
[h264 @ 0x559bf1fa91c0] mmco: unref short failure

 52%|█████▏    | 116/221 [00:41<02:30,  1.43s/it][A
 53%|█████▎    | 117/221 [00:42<01:52,  1.08s/it][A
 53%|█████▎    | 118/221 [00:42<01:25,  1.21it/s][A
 54%|█████▍    | 119/221 [00:42<01:05,  1.57it/s][A
 54%|█████▍    | 120/221 [00:42<00:53,  1.90it/s][A
 55%|█████▍    | 121/221 [00:42<00:40,  2.50it/s][A
 55%|█████▌    | 122/221 [00:43<00:33,  2.97it/s][A
 56%|█████▌    | 123/221 [00:43<00:27,  3.56it/s][A
 56%|█████▌    | 124/221 [00:43<00:23,  4.14it/s][A
 57%|█████▋    | 125/221 [00:43<00:25,  3.71it/s][A
 57%|█████▋    | 126/221 [00:44<00:29,  3.24it/s][A
 57%|█████▋    | 127/221 [00:44<00:38,  2.44it/s][A
 58%|█████▊    | 128/221 [00:45<00:36,  2.54it/s][A
 58%|█████▊    | 129/221 [00:45<00:29,  3.16it/s][A
 59%|█████▉    | 130/221 [00:45<00:25,  3.52it/s][A
 59%|█████▉    | 131/221 [00:45<00:21,  4.25it/s][A
 60%|█████▉    | 132/221 [00:45<00:18,  4.74it/s][A[h264 @ 0x5624226ebe40] mmco: unref short failure
[h264 @ 0x5624226ebe40] mmco: unref short failure

 60%|██████    | 133/221 [00:46<00:23,  3.77it/s][A
 61%|██████    | 134/221 [00:46<00:21,  3.99it/s][A
 61%|██████    | 135/221 [00:46<00:22,  3.89it/s][A
 62%|██████▏   | 136/221 [00:47<00:25,  3.32it/s][A
 62%|██████▏   | 137/221 [00:47<00:22,  3.79it/s][A[h264 @ 0x559bf15e16c0] mmco: unref short failure

 62%|██████▏   | 138/221 [00:47<00:23,  3.48it/s][A
 63%|██████▎   | 139/221 [00:47<00:25,  3.24it/s][A
 63%|██████▎   | 140/221 [00:48<00:26,  3.05it/s][A
 64%|██████▍   | 141/221 [00:48<00:22,  3.55it/s][A
 64%|██████▍   | 142/221 [00:48<00:24,  3.28it/s][A
 65%|██████▍   | 143/221 [00:49<00:26,  2.90it/s][A
 65%|██████▌   | 144/221 [00:49<00:21,  3.55it/s][A
 66%|██████▌   | 145/221 [00:49<00:17,  4.38it/s][A
 66%|██████▌   | 146/221 [00:49<00:15,  4.78it/s][A
 67%|██████▋   | 147/221 [00:49<00:14,  5.14it/s][A
 67%|██████▋   | 148/221 [00:50<00:14,  4.90it/s][A
 68%|██████▊   | 150/221 [00:50<00:12,  5.89it/s][A[h264 @ 0x556b44743600] mmco: unref short failure

 68%|██████▊   | 151/221 [00:51<00:28,  2.43it/s][A
 69%|██████▉   | 152/221 [00:51<00:27,  2.50it/s][A
 69%|██████▉   | 153/221 [00:52<00:26,  2.61it/s][A[h264 @ 0x562430d9ef80] mmco: unref short failure

 70%|██████▉   | 154/221 [00:52<00:25,  2.58it/s][A
 70%|███████   | 155/221 [00:52<00:20,  3.23it/s][A
 71%|███████   | 156/221 [00:52<00:17,  3.76it/s][A[h264 @ 0x556b43f5ef00] mmco: unref short failure
[h264 @ 0x556b43f5ef00] mmco: unref short failure
[h264 @ 0x562434be5440] mmco: unref short failure
[h264 @ 0x562434be5440] mmco: unref short failure

 71%|███████   | 157/221 [00:55<01:09,  1.09s/it][A
 71%|███████▏  | 158/221 [00:56<00:50,  1.25it/s][A
 72%|███████▏  | 159/221 [00:56<00:37,  1.65it/s][A
 72%|███████▏  | 160/221 [00:56<00:29,  2.03it/s][A
 73%|███████▎  | 162/221 [00:56<00:23,  2.56it/s][A
 74%|███████▍  | 163/221 [00:57<00:20,  2.84it/s][A
 74%|███████▍  | 164/221 [00:57<00:16,  3.49it/s][A
 75%|███████▌  | 166/221 [00:57<00:13,  4.02it/s][A
 76%|███████▌  | 167/221 [00:57<00:12,  4.38it/s][A
 76%|███████▌  | 168/221 [01:00<00:48,  1.10it/s][A
 76%|███████▋  | 169/221 [01:01<00:38,  1.36it/s][A
 77%|███████▋  | 170/221 [01:01<00:30,  1.66it/s][A
 77%|███████▋  | 171/221 [01:01<00:24,  2.03it/s][A
 78%|███████▊  | 172/221 [01:01<00:20,  2.36it/s][A
 79%|███████▊  | 174/221 [01:01<00:12,  3.76it/s][A
 79%|███████▉  | 175/221 [01:02<00:13,  3.52it/s][A[h264 @ 0x56243671ec80] mmco: unref short failure

 80%|███████▉  | 176/221 [01:02<00:12,  3.55it/s][A
 80%|████████  | 177/221 [01:02<00:10,  4.03it/s][A
 81%|████████  | 178/221 [01:02<00:10,  3.96it/s][A
 81%|████████  | 179/221 [01:03<00:18,  2.31it/s][A
 82%|████████▏ | 181/221 [01:04<00:11,  3.39it/s][A
 82%|████████▏ | 182/221 [01:04<00:10,  3.71it/s][A
 83%|████████▎ | 183/221 [01:04<00:09,  4.05it/s][A
 83%|████████▎ | 184/221 [01:04<00:09,  3.81it/s][A
 84%|████████▎ | 185/221 [01:04<00:08,  4.32it/s][A
 84%|████████▍ | 186/221 [01:05<00:10,  3.49it/s][A
 85%|████████▍ | 187/221 [01:05<00:08,  4.11it/s][A
 85%|████████▌ | 188/221 [01:05<00:08,  3.90it/s][A
 86%|████████▌ | 189/221 [01:06<00:07,  4.01it/s][A
 86%|████████▌ | 190/221 [01:06<00:08,  3.85it/s][A
 87%|████████▋ | 192/221 [01:06<00:05,  5.09it/s][A
 87%|████████▋ | 193/221 [01:06<00:04,  5.75it/s][A
 88%|████████▊ | 194/221 [01:07<00:08,  3.26it/s][A
 88%|████████▊ | 195/221 [01:07<00:06,  3.74it/s][A
 89%|████████▉ | 197/221 [01:07<00:04,  5.12it/s][A
 90%|████████▉ | 198/221 [01:08<00:05,  4.51it/s][A
 90%|█████████ | 199/221 [01:08<00:04,  5.01it/s][A
 90%|█████████ | 200/221 [01:08<00:05,  4.16it/s][A
 91%|█████████ | 201/221 [01:08<00:04,  4.45it/s][A
 91%|█████████▏| 202/221 [01:08<00:03,  4.76it/s][A
 92%|█████████▏| 203/221 [01:09<00:03,  5.32it/s][A
 93%|█████████▎| 205/221 [01:09<00:02,  6.94it/s][A
 93%|█████████▎| 206/221 [01:09<00:03,  4.35it/s][A
 94%|█████████▍| 208/221 [01:09<00:02,  5.57it/s][A
 95%|█████████▍| 209/221 [01:10<00:01,  6.02it/s][A
 95%|█████████▌| 211/221 [01:10<00:01,  5.68it/s][A
 96%|█████████▌| 212/221 [01:10<00:01,  6.07it/s][A
 97%|█████████▋| 214/221 [01:11<00:01,  5.06it/s][A
 97%|█████████▋| 215/221 [01:11<00:01,  5.12it/s][A
 98%|█████████▊| 216/221 [01:11<00:01,  4.72it/s][A
 98%|█████████▊| 217/221 [01:11<00:01,  3.83it/s][A
 99%|█████████▊| 218/221 [01:12<00:00,  4.01it/s][A
 99%|█████████▉| 219/221 [01:12<00:00,  4.07it/s][A[h264 @ 0x559bea263240] mmco: unref short failure
[h264 @ 0x559bea263240] mmco: unref short failure

100%|█████████▉| 220/221 [01:15<00:01,  1.12s/it][A
100%|██████████| 221/221 [01:15<00:00,  1.20it/s][A100%|██████████| 221/221 [01:15<00:00,  2.92it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:51,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:22<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.78it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.78it/s][A
 57%|█████▋    | 125/221 [00:32<00:25,  3.78it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:51<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:57<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:27,  7.96it/s][A
  1%|          | 2/221 [00:00<00:53,  4.09it/s][A
  1%|▏         | 3/221 [00:00<00:59,  3.65it/s][A
  2%|▏         | 4/221 [00:00<00:49,  4.39it/s][A
  2%|▏         | 5/221 [00:01<00:45,  4.70it/s][A
  3%|▎         | 7/221 [00:01<00:40,  5.24it/s][A
  4%|▎         | 8/221 [00:01<00:47,  4.47it/s][A
  4%|▍         | 9/221 [00:01<00:46,  4.56it/s][A
  5%|▍         | 10/221 [00:02<01:03,  3.32it/s][A
  5%|▍         | 11/221 [00:02<00:58,  3.62it/s][A
  5%|▌         | 12/221 [00:02<00:50,  4.13it/s][A
  6%|▌         | 13/221 [00:03<01:22,  2.51it/s][A
  6%|▋         | 14/221 [00:03<01:05,  3.15it/s][A
  7%|▋         | 15/221 [00:03<00:58,  3.54it/s][A
  7%|▋         | 16/221 [00:04<01:04,  3.19it/s][A
  8%|▊         | 17/221 [00:05<01:28,  2.30it/s][A
  8%|▊         | 18/221 [00:05<01:15,  2.69it/s][A
  9%|▊         | 19/221 [00:05<01:06,  3.02it/s][A
  9%|▉         | 20/221 [00:05<00:52,  3.80it/s][A
 10%|▉         | 21/221 [00:05<00:46,  4.33it/s][A
 10%|▉         | 22/221 [00:05<00:44,  4.50it/s][A
 11%|█         | 24/221 [00:06<00:33,  5.85it/s][A
 11%|█▏        | 25/221 [00:06<00:34,  5.63it/s][A
 12%|█▏        | 26/221 [00:06<00:37,  5.25it/s][A
 12%|█▏        | 27/221 [00:06<00:33,  5.78it/s][A
 13%|█▎        | 28/221 [00:07<00:45,  4.20it/s][A
 13%|█▎        | 29/221 [00:07<00:44,  4.32it/s][A
 14%|█▎        | 30/221 [00:07<00:51,  3.69it/s][A
 14%|█▍        | 31/221 [00:07<00:47,  4.00it/s][A
 15%|█▍        | 33/221 [00:08<00:35,  5.23it/s][A
 15%|█▌        | 34/221 [00:08<00:36,  5.15it/s][A
 16%|█▌        | 35/221 [00:08<00:39,  4.71it/s][A
 16%|█▋        | 36/221 [00:08<00:42,  4.32it/s][A
 17%|█▋        | 37/221 [00:09<00:40,  4.57it/s][A
 17%|█▋        | 38/221 [00:09<00:43,  4.20it/s][A
 18%|█▊        | 39/221 [00:09<00:39,  4.65it/s][A
 18%|█▊        | 40/221 [00:09<00:50,  3.62it/s][A
 19%|█▊        | 41/221 [00:10<00:42,  4.19it/s][A
 19%|█▉        | 42/221 [00:10<00:41,  4.36it/s][A
 19%|█▉        | 43/221 [00:10<00:46,  3.85it/s][A
 20%|█▉        | 44/221 [00:10<00:44,  3.94it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.76it/s][A
 21%|██        | 46/221 [00:11<00:39,  4.48it/s][A
 21%|██▏       | 47/221 [00:11<00:37,  4.63it/s][A
 22%|██▏       | 48/221 [00:11<00:33,  5.11it/s][A
 22%|██▏       | 49/221 [00:11<00:33,  5.19it/s][A
 23%|██▎       | 50/221 [00:12<00:44,  3.87it/s][A
 23%|██▎       | 51/221 [00:12<00:40,  4.22it/s][A
 24%|██▎       | 52/221 [00:12<00:40,  4.21it/s][A
 24%|██▍       | 53/221 [00:12<00:36,  4.54it/s][A
 24%|██▍       | 54/221 [00:13<00:53,  3.14it/s][A
 25%|██▍       | 55/221 [00:13<00:48,  3.41it/s][A
 25%|██▌       | 56/221 [00:13<00:39,  4.16it/s][A
 26%|██▌       | 57/221 [00:14<00:40,  4.04it/s][A
 26%|██▌       | 58/221 [00:14<00:44,  3.68it/s][A
 27%|██▋       | 59/221 [00:14<00:39,  4.07it/s][A
 27%|██▋       | 60/221 [00:14<00:41,  3.89it/s][A
 28%|██▊       | 61/221 [00:14<00:35,  4.53it/s][A
 28%|██▊       | 62/221 [00:15<00:36,  4.35it/s][A
 29%|██▊       | 63/221 [00:15<00:37,  4.22it/s][A
 29%|██▉       | 64/221 [00:15<00:50,  3.14it/s][A
 29%|██▉       | 65/221 [00:16<00:41,  3.74it/s][A
 30%|██▉       | 66/221 [00:16<00:50,  3.07it/s][A
 30%|███       | 67/221 [00:17<00:57,  2.69it/s][A
 31%|███       | 68/221 [00:17<00:48,  3.19it/s][A
 31%|███       | 69/221 [00:17<01:06,  2.29it/s][A
 32%|███▏      | 70/221 [00:18<00:50,  2.97it/s][A
 32%|███▏      | 71/221 [00:18<00:44,  3.38it/s][A
 33%|███▎      | 72/221 [00:18<00:49,  3.00it/s][A
 33%|███▎      | 73/221 [00:19<00:47,  3.09it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.85it/s][A
 34%|███▍      | 75/221 [00:19<00:37,  3.85it/s][A
 34%|███▍      | 76/221 [00:19<00:35,  4.10it/s][A
 35%|███▍      | 77/221 [00:19<00:36,  3.91it/s][A
 35%|███▌      | 78/221 [00:20<00:33,  4.24it/s][A
 36%|███▌      | 79/221 [00:20<00:44,  3.22it/s][A
 36%|███▌      | 80/221 [00:20<00:39,  3.61it/s][A
 37%|███▋      | 81/221 [00:20<00:37,  3.73it/s][A
 37%|███▋      | 82/221 [00:21<00:38,  3.62it/s][A
 38%|███▊      | 83/221 [00:21<00:40,  3.39it/s][A
 38%|███▊      | 84/221 [00:21<00:38,  3.55it/s][A
 39%|███▉      | 86/221 [00:22<00:33,  4.07it/s][A
 39%|███▉      | 87/221 [00:22<00:41,  3.20it/s][A
 40%|███▉      | 88/221 [00:23<00:48,  2.74it/s][A
 40%|████      | 89/221 [00:23<00:43,  3.03it/s][A
 41%|████      | 90/221 [00:23<00:44,  2.95it/s][A
 41%|████      | 91/221 [00:24<00:36,  3.52it/s][A
 42%|████▏     | 92/221 [00:24<00:38,  3.34it/s][A
 42%|████▏     | 93/221 [00:25<00:52,  2.42it/s][A
 43%|████▎     | 94/221 [00:25<00:49,  2.58it/s][A
 43%|████▎     | 95/221 [00:25<00:43,  2.88it/s][A
 43%|████▎     | 96/221 [00:25<00:39,  3.20it/s][A
 44%|████▍     | 97/221 [00:26<00:33,  3.68it/s][A
 44%|████▍     | 98/221 [00:26<00:34,  3.57it/s][A
 45%|████▍     | 99/221 [00:26<00:30,  3.97it/s][A
 45%|████▌     | 100/221 [00:26<00:30,  4.03it/s][A
 46%|████▌     | 101/221 [00:27<00:31,  3.85it/s][A
 46%|████▌     | 102/221 [00:27<00:47,  2.50it/s][A
 47%|████▋     | 103/221 [00:27<00:37,  3.15it/s][A
 47%|████▋     | 104/221 [00:28<00:32,  3.59it/s][A
 48%|████▊     | 105/221 [00:28<00:34,  3.33it/s][A
 48%|████▊     | 106/221 [00:28<00:40,  2.81it/s][A
 48%|████▊     | 107/221 [00:29<00:35,  3.18it/s][A
 49%|████▉     | 108/221 [00:29<00:32,  3.45it/s][A
 49%|████▉     | 109/221 [00:29<00:26,  4.28it/s][A
 50%|████▉     | 110/221 [00:29<00:25,  4.30it/s][A
 50%|█████     | 111/221 [00:30<00:27,  3.94it/s][A
 51%|█████     | 112/221 [00:30<00:27,  4.01it/s][A
 51%|█████     | 113/221 [00:30<00:24,  4.41it/s][A
 52%|█████▏    | 115/221 [00:30<00:20,  5.12it/s][A
 52%|█████▏    | 116/221 [00:31<00:21,  4.78it/s][A
 53%|█████▎    | 117/221 [00:31<00:22,  4.57it/s][A
 53%|█████▎    | 118/221 [00:31<00:22,  4.56it/s][A
 54%|█████▍    | 119/221 [00:31<00:29,  3.43it/s][A
 54%|█████▍    | 120/221 [00:32<00:24,  4.05it/s][A
 55%|█████▍    | 121/221 [00:32<00:20,  4.77it/s][A
 55%|█████▌    | 122/221 [00:32<00:22,  4.32it/s][A
 56%|█████▌    | 123/221 [00:32<00:22,  4.28it/s][A
 56%|█████▌    | 124/221 [00:32<00:23,  4.17it/s][A
 57%|█████▋    | 125/221 [00:33<00:25,  3.69it/s][A
 57%|█████▋    | 126/221 [00:33<00:23,  3.97it/s][A
 57%|█████▋    | 127/221 [00:34<00:29,  3.20it/s][A
 58%|█████▊    | 128/221 [00:34<00:26,  3.48it/s][A
 58%|█████▊    | 129/221 [00:34<00:21,  4.30it/s][A
 59%|█████▉    | 130/221 [00:34<00:23,  3.89it/s][A
 60%|█████▉    | 132/221 [00:35<00:20,  4.37it/s][A
 60%|██████    | 133/221 [00:35<00:22,  3.95it/s][A
 61%|██████    | 134/221 [00:35<00:26,  3.32it/s][A
 61%|██████    | 135/221 [00:36<00:27,  3.15it/s][A
 62%|██████▏   | 136/221 [00:36<00:24,  3.43it/s][A
 62%|██████▏   | 137/221 [00:36<00:21,  3.99it/s][A
 62%|██████▏   | 138/221 [00:36<00:22,  3.76it/s][A
 63%|██████▎   | 139/221 [00:37<00:30,  2.67it/s][A
 63%|██████▎   | 140/221 [00:37<00:28,  2.80it/s][A
 64%|██████▍   | 141/221 [00:37<00:24,  3.26it/s][A
 64%|██████▍   | 142/221 [00:38<00:21,  3.61it/s][A
 65%|██████▍   | 143/221 [00:38<00:28,  2.75it/s][A
 65%|██████▌   | 144/221 [00:39<00:28,  2.69it/s][A
 66%|██████▌   | 146/221 [00:39<00:17,  4.23it/s][A
 67%|██████▋   | 147/221 [00:39<00:18,  4.05it/s][A
 67%|██████▋   | 148/221 [00:40<00:22,  3.27it/s][A
 67%|██████▋   | 149/221 [00:40<00:22,  3.26it/s][A
 68%|██████▊   | 150/221 [00:40<00:21,  3.31it/s][A
 68%|██████▊   | 151/221 [00:41<00:22,  3.05it/s][A
 69%|██████▉   | 152/221 [00:41<00:33,  2.06it/s][A
 69%|██████▉   | 153/221 [00:42<00:26,  2.61it/s][A
 70%|██████▉   | 154/221 [00:42<00:21,  3.07it/s][A
 70%|███████   | 155/221 [00:42<00:19,  3.38it/s][A
 71%|███████   | 156/221 [00:42<00:20,  3.11it/s][A
 71%|███████   | 157/221 [00:43<00:20,  3.17it/s][A
 71%|███████▏  | 158/221 [00:43<00:19,  3.22it/s][A
 72%|███████▏  | 159/221 [00:43<00:15,  3.99it/s][A
 72%|███████▏  | 160/221 [00:43<00:14,  4.31it/s][A
 73%|███████▎  | 161/221 [00:44<00:14,  4.14it/s][A
 73%|███████▎  | 162/221 [00:44<00:12,  4.64it/s][A
 74%|███████▍  | 163/221 [00:44<00:13,  4.40it/s][A
 74%|███████▍  | 164/221 [00:44<00:11,  5.05it/s][A
 75%|███████▍  | 165/221 [00:44<00:10,  5.19it/s][A
 75%|███████▌  | 166/221 [00:44<00:11,  4.93it/s][A
 76%|███████▌  | 167/221 [00:45<00:09,  5.52it/s][A
 76%|███████▌  | 168/221 [00:45<00:10,  5.23it/s][A
 76%|███████▋  | 169/221 [00:45<00:09,  5.73it/s][A
 77%|███████▋  | 170/221 [00:45<00:13,  3.66it/s][A
 77%|███████▋  | 171/221 [00:46<00:13,  3.74it/s][A
 78%|███████▊  | 172/221 [00:46<00:12,  3.86it/s][A
 78%|███████▊  | 173/221 [00:46<00:13,  3.63it/s][A
 79%|███████▊  | 174/221 [00:47<00:16,  2.83it/s][A
 79%|███████▉  | 175/221 [00:47<00:16,  2.82it/s][A
 80%|███████▉  | 176/221 [00:47<00:14,  3.14it/s][A
 80%|████████  | 177/221 [00:48<00:12,  3.48it/s][A
 81%|████████  | 178/221 [00:48<00:11,  3.61it/s][A
 81%|████████  | 179/221 [00:48<00:11,  3.80it/s][A
 81%|████████▏ | 180/221 [00:48<00:09,  4.45it/s][A
 82%|████████▏ | 181/221 [00:48<00:08,  4.48it/s][A
 82%|████████▏ | 182/221 [00:49<00:11,  3.48it/s][A
 83%|████████▎ | 183/221 [00:49<00:11,  3.17it/s][A
 83%|████████▎ | 184/221 [00:50<00:11,  3.26it/s][A
 84%|████████▎ | 185/221 [00:50<00:09,  3.86it/s][A
 84%|████████▍ | 186/221 [00:50<00:11,  3.13it/s][A
 85%|████████▍ | 187/221 [00:50<00:09,  3.45it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.38it/s][A
 86%|████████▌ | 189/221 [00:51<00:08,  3.56it/s][A
 86%|████████▌ | 190/221 [00:51<00:09,  3.26it/s][A
 86%|████████▋ | 191/221 [00:51<00:07,  3.76it/s][A
 87%|████████▋ | 192/221 [00:52<00:07,  3.77it/s][A
 88%|████████▊ | 194/221 [00:52<00:06,  4.23it/s][A
 88%|████████▊ | 195/221 [00:52<00:06,  4.11it/s][A
 89%|████████▊ | 196/221 [00:53<00:07,  3.25it/s][A
 89%|████████▉ | 197/221 [00:53<00:07,  3.41it/s][A
 90%|████████▉ | 198/221 [00:54<00:08,  2.87it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.19it/s][A
 90%|█████████ | 200/221 [00:54<00:07,  2.74it/s][A
 91%|█████████ | 201/221 [00:55<00:06,  3.10it/s][A
 91%|█████████▏| 202/221 [00:55<00:06,  3.06it/s][A
 92%|█████████▏| 203/221 [00:55<00:05,  3.33it/s][A
 92%|█████████▏| 204/221 [00:56<00:05,  2.99it/s][A
 93%|█████████▎| 206/221 [00:56<00:04,  3.35it/s][A
 94%|█████████▎| 207/221 [00:56<00:03,  3.97it/s][A
 94%|█████████▍| 208/221 [00:57<00:03,  3.56it/s][A
 95%|█████████▍| 209/221 [00:57<00:03,  3.51it/s][A
 95%|█████████▌| 211/221 [00:57<00:02,  3.98it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  3.72it/s][A
 96%|█████████▋| 213/221 [00:58<00:02,  3.98it/s][A
 97%|█████████▋| 214/221 [00:58<00:02,  2.69it/s][A
 97%|█████████▋| 215/221 [00:59<00:01,  3.14it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.35it/s][A
 98%|█████████▊| 217/221 [00:59<00:01,  3.32it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.38it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.34it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.70it/s][A
100%|██████████| 221/221 [01:00<00:00,  3.87it/s][A100%|██████████| 221/221 [01:00<00:00,  3.64it/s]
09/09/2024 20:53:12 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 699--===========

09/09/2024 20:53:12 - INFO - __main__ -   {'area_r1': 39.5, 'area_recall': '39.5/66.2/75.0', 'area_ravg': 60.2}
09/09/2024 20:53:12 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 699--===========

09/09/2024 20:53:12 - INFO - __main__ -   {'forward_r1': 37.6, 'forward_recall': '37.6/66.2/76.7', 'forward_ravg': 60.1}
09/09/2024 20:53:12 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 699--===========

09/09/2024 20:53:12 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/66.5/78.3', 'area_video_ravg': 61.8}
09/09/2024 20:53:12 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/09/2024 20:53:12 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 20:53:12 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 699--===========

09/09/2024 20:53:12 - INFO - __main__ -   {'area_video_r1': 52.4, 'area_video_recall': '52.4/74.8/82.7', 'area_video_ravg': 69.9, 'area_video_back_r1': 50.0, 'area_video_back_recall': '50.0/74.8/81.9', 'area_video_back_ravg': 68.9}
09/09/2024 20:53:12 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/09/2024 20:53:12 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/09/2024 20:53:12 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 699--===========

09/09/2024 20:53:12 - INFO - __main__ -   {'video_r1': 43.3, 'video_recall': '43.3/71.4/82.1', 'video_ravg': 65.6}
09/09/2024 20:53:12 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 20:53:12 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 20:53:12 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 699--===========

09/09/2024 20:53:12 - INFO - __main__ -   {'video_r1': 52.3, 'video_recall': '52.3/75.2/82.6', 'video_ravg': 70.0}
09/09/2024 20:53:12 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/09/2024 20:53:12 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/09/2024 20:53:35 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.010694792494177818, 'loss_ret%tv%ta--finetune_area/loss_area': 1.2149817943572998, 'loss_ret%tv%ta--finetune_area/total_loss': 1.2256765365600586}
[h264 @ 0x55a036fbabc0] mmco: unref short failure
[h264 @ 0x55a036fbabc0] mmco: unref short failure
 36%|███▌      | 700/1945 [3:48:15<43:10:59, 124.87s/it][h264 @ 0x559bf9fbfd40] mmco: unref short failure
[h264 @ 0x559bf9fbfd40] mmco: unref short failure
 36%|███▌      | 701/1945 [3:48:20<30:37:36, 88.63s/it] [h264 @ 0x55a04deeb240] mmco: unref short failure
[h264 @ 0x55a04deeb240] mmco: unref short failure
[h264 @ 0x55a04deeb240] mmco: unref short failure
[h264 @ 0x55a04deeb240] mmco: unref short failure
[h264 @ 0x55a04deeb240] mmco: unref short failure
[h264 @ 0x55a04deeb240] mmco: unref short failure
 36%|███▌      | 702/1945 [3:48:24<21:54:39, 63.46s/it][h264 @ 0x556b2d275f00] mmco: unref short failure
 36%|███▌      | 703/1945 [3:48:29<15:51:39, 45.97s/it] 36%|███▌      | 704/1945 [3:48:35<11:42:43, 33.98s/it] 36%|███▌      | 705/1945 [3:48:41<8:47:40, 25.53s/it]  36%|███▋      | 706/1945 [3:48:49<6:54:38, 20.08s/it][h264 @ 0x55a033014ac0] mmco: unref short failure
[h264 @ 0x55a033014ac0] mmco: unref short failure
[h264 @ 0x55a033014ac0] mmco: unref short failure
[h264 @ 0x55a033014ac0] mmco: unref short failure
 36%|███▋      | 707/1945 [3:48:56<5:38:17, 16.39s/it][h264 @ 0x559c00862e80] mmco: unref short failure
[h264 @ 0x559c00862e80] mmco: unref short failure
 36%|███▋      | 708/1945 [3:49:03<4:36:35, 13.42s/it][h264 @ 0x556b394ae840] mmco: unref short failure
[h264 @ 0x556b394ae840] mmco: unref short failure
[h264 @ 0x556b394ae840] mmco: unref short failure
[h264 @ 0x556b394ae840] mmco: unref short failure
[h264 @ 0x55a04824e800] mmco: unref short failure
 36%|███▋      | 709/1945 [3:49:10<3:59:25, 11.62s/it][h264 @ 0x55a04824e800] mmco: unref short failure
[h264 @ 0x55a034c70640] mmco: unref short failure
 37%|███▋      | 710/1945 [3:49:20<3:45:10, 10.94s/it][h264 @ 0x5624256d5080] mmco: unref short failure
[h264 @ 0x5624256d5080] mmco: unref short failure
[h264 @ 0x5624256d5080] mmco: unref short failure
[h264 @ 0x5624256d5080] mmco: unref short failure
 37%|███▋      | 711/1945 [3:49:27<3:22:27,  9.84s/it][h264 @ 0x556b3d591240] mmco: unref short failure
 37%|███▋      | 712/1945 [3:49:34<3:04:30,  8.98s/it] 37%|███▋      | 713/1945 [3:49:41<2:51:38,  8.36s/it] 37%|███▋      | 714/1945 [3:49:48<2:41:30,  7.87s/it][h264 @ 0x556b44c6eb80] mmco: unref short failure
[h264 @ 0x556b44c6eb80] mmco: unref short failure
[h264 @ 0x556b44c6eb80] mmco: unref short failure
[h264 @ 0x556b44c6eb80] mmco: unref short failure
[h264 @ 0x559be8fde040] mmco: unref short failure
 37%|███▋      | 715/1945 [3:49:54<2:34:07,  7.52s/it][h264 @ 0x556b41897140] mmco: unref short failure
 37%|███▋      | 716/1945 [3:50:01<2:30:16,  7.34s/it][h264 @ 0x5624229ed040] mmco: unref short failure
 37%|███▋      | 717/1945 [3:50:13<2:57:28,  8.67s/it][h264 @ 0x55a0508c3a80] mmco: unref short failure
[h264 @ 0x55a0508c3a80] mmco: unref short failure
 37%|███▋      | 718/1945 [3:50:21<2:50:50,  8.35s/it][h264 @ 0x55a037f8dc80] mmco: unref short failure
[h264 @ 0x55a037f8dc80] mmco: unref short failure
 37%|███▋      | 719/1945 [3:50:29<2:48:29,  8.25s/it][h264 @ 0x56241bc21580] mmco: unref short failure
[h264 @ 0x56241bc21580] mmco: unref short failure
 37%|███▋      | 720/1945 [3:50:36<2:42:11,  7.94s/it][h264 @ 0x55a03843e400] mmco: unref short failure
[h264 @ 0x55a03843e400] mmco: unref short failure
[h264 @ 0x55a03843e400] mmco: unref short failure
 37%|███▋      | 721/1945 [3:50:46<2:53:58,  8.53s/it][h264 @ 0x556b41fbcf40] mmco: unref short failure
[h264 @ 0x559c05e504c0] mmco: unref short failure
[h264 @ 0x559c05e504c0] mmco: unref short failure
[h264 @ 0x559bf1f202c0] mmco: unref short failure
[h264 @ 0x559bf1f202c0] mmco: unref short failure
 37%|███▋      | 722/1945 [3:51:00<3:29:44, 10.29s/it][h264 @ 0x55a04662df80] mmco: unref short failure
 37%|███▋      | 723/1945 [3:51:08<3:15:52,  9.62s/it][h264 @ 0x559bea83c200] mmco: unref short failure
[h264 @ 0x559bea83c200] mmco: unref short failure
[h264 @ 0x559bfad06000] mmco: unref short failure
[h264 @ 0x556b33f990c0] mmco: unref short failure
[h264 @ 0x556b33f990c0] mmco: unref short failure
[h264 @ 0x559c056dad40] mmco: unref short failure
[h264 @ 0x559c056dad40] mmco: unref short failure
[h264 @ 0x556b2d9ddd00] mmco: unref short failure
[h264 @ 0x556b49de8ac0] mmco: unref short failure
[h264 @ 0x556b49de8ac0] mmco: unref short failure
[h264 @ 0x559c090d12c0] mmco: unref short failure
[h264 @ 0x559c090d12c0] mmco: unref short failure
[h264 @ 0x556b487f5680] mmco: unref short failure
[h264 @ 0x556b487f5680] mmco: unref short failure
 37%|███▋      | 724/1945 [3:51:54<6:58:00, 20.54s/it][h264 @ 0x556b2d853800] mmco: unref short failure
[h264 @ 0x556b2d853800] mmco: unref short failure
[h264 @ 0x556b2d853800] mmco: unref short failure
[h264 @ 0x556b2d853800] mmco: unref short failure
[h264 @ 0x556b3a81fac0] mmco: unref short failure
[h264 @ 0x55a040e172c0] mmco: unref short failure
[h264 @ 0x55a040e172c0] mmco: unref short failure
[h264 @ 0x55a040e172c0] mmco: unref short failure
[h264 @ 0x55a040e172c0] mmco: unref short failure
[h264 @ 0x5624236f7140] mmco: unref short failure
 37%|███▋      | 725/1945 [3:52:12<6:39:23, 19.64s/it][h264 @ 0x55a033faf900] mmco: unref short failure
[h264 @ 0x55a033faf900] mmco: unref short failure
[h264 @ 0x559bf1ba7400] mmco: unref short failure
[h264 @ 0x55a03de6d380] mmco: unref short failure
[h264 @ 0x55a03492a7c0] mmco: unref short failure
[h264 @ 0x559bef329440] mmco: unref short failure
 37%|███▋      | 726/1945 [3:52:22<5:42:47, 16.87s/it] 37%|███▋      | 727/1945 [3:52:29<4:40:34, 13.82s/it][h264 @ 0x55a032fab240] mmco: unref short failure
[h264 @ 0x55a032fab240] mmco: unref short failure
[h264 @ 0x55a032fab240] mmco: unref short failure
[h264 @ 0x55a032fab240] mmco: unref short failure
 37%|███▋      | 728/1945 [3:52:36<4:02:07, 11.94s/it][h264 @ 0x556b49042d00] mmco: unref short failure
[h264 @ 0x556b49042d00] mmco: unref short failure
 37%|███▋      | 729/1945 [3:52:44<3:34:35, 10.59s/it][h264 @ 0x559bfacc3280] mmco: unref short failure
[h264 @ 0x559bfacc3280] mmco: unref short failure
[h264 @ 0x55a040fe2bc0] mmco: unref short failure
[h264 @ 0x556b4c394780] mmco: unref short failure
 38%|███▊      | 730/1945 [3:52:58<3:58:05, 11.76s/it][h264 @ 0x559c098a3ac0] mmco: unref short failure
[h264 @ 0x559c098a3ac0] mmco: unref short failure
[h264 @ 0x56243766e600] mmco: unref short failure
[h264 @ 0x55a044f0e780] mmco: unref short failure
 38%|███▊      | 731/1945 [3:53:06<3:32:53, 10.52s/it][h264 @ 0x556b4270b840] mmco: unref short failure
[h264 @ 0x562434c0de80] mmco: unref short failure
[h264 @ 0x56242ccc4e40] mmco: unref short failure
[h264 @ 0x55a033043f00] mmco: unref short failure
[h264 @ 0x559be9768500] mmco: unref short failure
[h264 @ 0x55a054522cc0] mmco: unref short failure
[h264 @ 0x55a054522cc0] mmco: unref short failure
[h264 @ 0x5624318e5700] mmco: unref short failure
[h264 @ 0x5624318e5700] mmco: unref short failure
[h264 @ 0x559c05aefb80] mmco: unref short failure
[h264 @ 0x55a0355cb9c0] mmco: unref short failure
[h264 @ 0x56242ed94a80] mmco: unref short failure
[h264 @ 0x556b4fd94a00] mmco: unref short failure
[h264 @ 0x556b4fd94a00] mmco: unref short failure
[h264 @ 0x556b30dbd440] mmco: unref short failure
[h264 @ 0x556b30dbd440] mmco: unref short failure
[h264 @ 0x55a03de6d380] mmco: unref short failure
[h264 @ 0x55a03de6d380] mmco: unref short failure
 38%|███▊      | 732/1945 [3:53:56<7:35:16, 22.52s/it][h264 @ 0x556b2cd5ca00] mmco: unref short failure
[h264 @ 0x556b2cd5ca00] mmco: unref short failure
[h264 @ 0x55a03973bf40] mmco: unref short failure
 38%|███▊      | 733/1945 [3:54:10<6:37:43, 19.69s/it][h264 @ 0x562418b16ac0] mmco: unref short failure
[h264 @ 0x562418b16ac0] mmco: unref short failure
[h264 @ 0x55a03c957b00] mmco: unref short failure
[h264 @ 0x556b2e2a6e40] mmco: unref short failure
[h264 @ 0x556b2e2a6e40] mmco: unref short failure
[h264 @ 0x559c0be42e40] mmco: unref short failure
[h264 @ 0x559c0be42e40] mmco: unref short failure
[h264 @ 0x559c0be42e40] mmco: unref short failure
[h264 @ 0x559c0be42e40] mmco: unref short failure
[h264 @ 0x559c0be42e40] mmco: unref short failure
[h264 @ 0x559c0be42e40] mmco: unref short failure
 38%|███▊      | 734/1945 [3:54:23<5:56:59, 17.69s/it][h264 @ 0x559bfa7b2540] mmco: unref short failure
[h264 @ 0x556b334dba40] mmco: unref short failure
[h264 @ 0x556b334dba40] mmco: unref short failure
[h264 @ 0x556b334dba40] mmco: unref short failure
[h264 @ 0x556b334dba40] mmco: unref short failure
[h264 @ 0x562424c18a80] mmco: unref short failure
 38%|███▊      | 735/1945 [3:54:38<5:40:53, 16.90s/it][h264 @ 0x56241baabe00] mmco: unref short failure
[h264 @ 0x56241baabe00] mmco: unref short failure
[h264 @ 0x55a050f04b80] mmco: unref short failure
[h264 @ 0x55a050f04b80] mmco: unref short failure
 38%|███▊      | 736/1945 [3:54:45<4:43:06, 14.05s/it] 38%|███▊      | 737/1945 [3:54:51<3:56:36, 11.75s/it][h264 @ 0x559bf3ec5d00] mmco: unref short failure
[h264 @ 0x559bf34fd000] mmco: unref short failure
[h264 @ 0x559bf34fd000] mmco: unref short failure
[h264 @ 0x55a04a5e3580] mmco: unref short failure
 38%|███▊      | 738/1945 [3:55:02<3:50:02, 11.44s/it][h264 @ 0x559bf7ede440] mmco: unref short failure
[h264 @ 0x559bf7ede440] mmco: unref short failure
[h264 @ 0x559bf7ede440] mmco: unref short failure
[h264 @ 0x559bf7ede440] mmco: unref short failure
[h264 @ 0x556b4b867400] mmco: unref short failure
[h264 @ 0x556b4b867400] mmco: unref short failure
[h264 @ 0x556b372d5bc0] mmco: unref short failure
[h264 @ 0x556b372d5bc0] mmco: unref short failure
[h264 @ 0x559bfa3e9800] mmco: unref short failure
[h264 @ 0x559bfa3e9800] mmco: unref short failure
 38%|███▊      | 739/1945 [3:55:11<3:35:52, 10.74s/it][h264 @ 0x562436513d00] mmco: unref short failure
[h264 @ 0x562436513d00] mmco: unref short failure
[h264 @ 0x562436513d00] mmco: unref short failure
[h264 @ 0x562436513d00] mmco: unref short failure
[h264 @ 0x562436513d00] mmco: unref short failure
[h264 @ 0x562436513d00] mmco: unref short failure
[h264 @ 0x559be9ac2280] mmco: unref short failure
[h264 @ 0x559be9ac2280] mmco: unref short failure
[h264 @ 0x556b2d5df640] mmco: unref short failure
[h264 @ 0x55a032437cc0] mmco: unref short failure
[h264 @ 0x559bea19dbc0] mmco: unref short failure
[h264 @ 0x559bea19dbc0] mmco: unref short failure
[h264 @ 0x55a033ca4a80] mmco: unref short failure
[h264 @ 0x562426698a80] mmco: unref short failure
[h264 @ 0x562426698a80] mmco: unref short failure
[h264 @ 0x562426698a80] mmco: unref short failure
[h264 @ 0x562426698a80] mmco: unref short failure
[h264 @ 0x55a03251c040] mmco: unref short failure
[h264 @ 0x556b2db219c0] mmco: unref short failure
[h264 @ 0x556b2db219c0] mmco: unref short failure
[h264 @ 0x556b2db219c0] mmco: unref short failure
[h264 @ 0x556b2db219c0] mmco: unref short failure
[h264 @ 0x562435953800] mmco: unref short failure
[h264 @ 0x55a03b22cc00] mmco: unref short failure
[h264 @ 0x55a03b22cc00] mmco: unref short failure
[h264 @ 0x55a034871580] mmco: unref short failure
[h264 @ 0x55a034871580] mmco: unref short failure
[h264 @ 0x559bfebb9200] mmco: unref short failure
[h264 @ 0x556b2d5df640] mmco: unref short failure
[h264 @ 0x556b2d5df640] mmco: unref short failure
[h264 @ 0x559c0acbf700] mmco: unref short failure
[h264 @ 0x559c0acbf700] mmco: unref short failure
 38%|███▊      | 740/1945 [3:56:04<7:48:02, 23.30s/it][h264 @ 0x5624207d1980] mmco: unref short failure
[h264 @ 0x5624207d1980] mmco: unref short failure
 38%|███▊      | 741/1945 [3:56:12<6:15:04, 18.69s/it][h264 @ 0x559bf4cec980] mmco: unref short failure
[h264 @ 0x559bf4cec980] mmco: unref short failure
[h264 @ 0x562427812c00] mmco: unref short failure
[h264 @ 0x562427812c00] mmco: unref short failure
[h264 @ 0x562418b16cc0] mmco: unref short failure
[h264 @ 0x562418b16cc0] mmco: unref short failure
[h264 @ 0x55a0427d7740] mmco: unref short failure
[h264 @ 0x55a0427d7740] mmco: unref short failure
 38%|███▊      | 742/1945 [3:56:28<5:58:22, 17.87s/it][h264 @ 0x556b39ad9f80] mmco: unref short failure
[h264 @ 0x556b39ad9f80] mmco: unref short failure
[h264 @ 0x55a04f95a240] mmco: unref short failure
[h264 @ 0x56241af4e480] mmco: unref short failure
[h264 @ 0x56241af4e480] mmco: unref short failure
 38%|███▊      | 743/1945 [3:56:38<5:12:01, 15.58s/it][h264 @ 0x556b3206f6c0] mmco: unref short failure
[h264 @ 0x556b3206f6c0] mmco: unref short failure
[h264 @ 0x562429bef580] mmco: unref short failure
[h264 @ 0x556b3b348e40] mmco: unref short failure
[h264 @ 0x556b3b348e40] mmco: unref short failure
[h264 @ 0x55a046562580] mmco: unref short failure
 38%|███▊      | 744/1945 [3:56:46<4:25:44, 13.28s/it][h264 @ 0x56241f0a6d80] mmco: unref short failure
[h264 @ 0x562419eec900] mmco: unref short failure
[h264 @ 0x5624234a9180] mmco: unref short failure
[h264 @ 0x5624234a9180] mmco: unref short failure
[h264 @ 0x55a0417db4c0] mmco: unref short failure
 38%|███▊      | 745/1945 [3:56:54<3:55:03, 11.75s/it][h264 @ 0x556b355d4500] mmco: unref short failure
[h264 @ 0x556b355d4500] mmco: unref short failure
[h264 @ 0x562422063e00] mmco: unref short failure
[h264 @ 0x562422063e00] mmco: unref short failure
[h264 @ 0x562422063e00] mmco: unref short failure
[h264 @ 0x562422063e00] mmco: unref short failure
[h264 @ 0x55a054117b40] mmco: unref short failure
[h264 @ 0x55a054117b40] mmco: unref short failure
[h264 @ 0x55a054117b40] mmco: unref short failure
[h264 @ 0x55a054117b40] mmco: unref short failure
 38%|███▊      | 746/1945 [3:57:10<4:19:37, 12.99s/it][h264 @ 0x559c090d12c0] mmco: unref short failure
[h264 @ 0x559c090d12c0] mmco: unref short failure
[h264 @ 0x559c090d12c0] mmco: unref short failure
 38%|███▊      | 747/1945 [3:57:17<3:41:43, 11.10s/it][h264 @ 0x556b4270b840] mmco: unref short failure
[h264 @ 0x55a038448f00] mmco: unref short failure
[h264 @ 0x55a038448f00] mmco: unref short failure
[h264 @ 0x5624315c1d80] mmco: unref short failure
[h264 @ 0x5624315c1d80] mmco: unref short failure
[h264 @ 0x556b4017efc0] mmco: unref short failure
[h264 @ 0x56241dabaf40] mmco: unref short failure
[h264 @ 0x56241dabaf40] mmco: unref short failure
[h264 @ 0x5624207d1980] mmco: unref short failure
[h264 @ 0x559bf34fd000] mmco: unref short failure
[h264 @ 0x559bf34fd000] mmco: unref short failure
[h264 @ 0x559be96b6bc0] mmco: unref short failure
[h264 @ 0x56242cc49980] mmco: unref short failure
[h264 @ 0x559bea91aec0] mmco: unref short failure
[h264 @ 0x559bf8561c80] mmco: unref short failure
[h264 @ 0x559bf8561c80] mmco: unref short failure
 38%|███▊      | 748/1945 [3:58:00<6:55:42, 20.84s/it][h264 @ 0x562436510440] mmco: unref short failure
[h264 @ 0x562436510440] mmco: unref short failure
[h264 @ 0x556b3f58cac0] mmco: unref short failure
[h264 @ 0x556b3f58cac0] mmco: unref short failure
[h264 @ 0x556b3f58cac0] mmco: unref short failure
[h264 @ 0x556b3f58cac0] mmco: unref short failure
[h264 @ 0x556b4b2902c0] mmco: unref short failure
[h264 @ 0x56242fab0680] mmco: unref short failure
 39%|███▊      | 749/1945 [3:58:16<6:23:15, 19.23s/it]09/09/2024 21:03:38 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 21:03:38 - INFO - __main__ -   start running ret%tv validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559c0a3be040] mmco: unref short failure
[h264 @ 0x559c0a3be040] mmco: unref short failure
[h264 @ 0x559c0a3be040] mmco: unref short failure
[h264 @ 0x559c0a3be040] mmco: unref short failure
[h264 @ 0x56241b690b40] mmco: unref short failure
[h264 @ 0x559bf0736840] mmco: unref short failure
[h264 @ 0x559bf0736840] mmco: unref short failure
[h264 @ 0x556b4d2fe540] mmco: unref short failure
[h264 @ 0x556b4d2fe540] mmco: unref short failure
[h264 @ 0x556b4d2fe540] mmco: unref short failure
[h264 @ 0x556b4d2fe540] mmco: unref short failure
[h264 @ 0x556b4d2fe540] mmco: unref short failure
[h264 @ 0x556b4d2fe540] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559beb49b300] mmco: unref short failure
[h264 @ 0x559beb49b300] mmco: unref short failure
[h264 @ 0x559beb49b300] mmco: unref short failure
[h264 @ 0x559beb49b300] mmco: unref short failure
[h264 @ 0x559bff8b4400] mmco: unref short failure
[h264 @ 0x55a04902e200] mmco: unref short failure
[h264 @ 0x559be98be040] mmco: unref short failure
[h264 @ 0x559be98be040] mmco: unref short failure
[h264 @ 0x55a0360edcc0] mmco: unref short failure
[h264 @ 0x55a0372dd500] mmco: unref short failure
[h264 @ 0x55a0372dd500] mmco: unref short failure
[h264 @ 0x559bfc894080] mmco: unref short failure
[h264 @ 0x556b392caf80] mmco: unref short failure
[h264 @ 0x556b392caf80] mmco: unref short failure
[h264 @ 0x556b392caf80] mmco: unref short failure
[h264 @ 0x556b392caf80] mmco: unref short failure
[h264 @ 0x556b392caf80] mmco: unref short failure
[h264 @ 0x556b392caf80] mmco: unref short failure
[h264 @ 0x55a04ce2a9c0] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:40,  2.19it/s][A
  1%|          | 2/221 [00:01<01:58,  1.84it/s][A
  1%|▏         | 3/221 [00:01<01:36,  2.26it/s][A
  2%|▏         | 4/221 [00:01<01:24,  2.56it/s][A[h264 @ 0x562436444b40] mmco: unref short failure
[h264 @ 0x562436444b40] mmco: unref short failure

  2%|▏         | 5/221 [00:01<01:10,  3.06it/s][A
  3%|▎         | 6/221 [00:02<01:08,  3.12it/s][A
  3%|▎         | 7/221 [00:02<01:02,  3.41it/s][A
  4%|▎         | 8/221 [00:02<01:09,  3.05it/s][A
  4%|▍         | 9/221 [00:03<01:01,  3.44it/s][A
  5%|▍         | 10/221 [00:03<01:08,  3.07it/s][A
  5%|▍         | 11/221 [00:03<00:58,  3.58it/s][A
  5%|▌         | 12/221 [00:04<01:08,  3.06it/s][A
  6%|▌         | 13/221 [00:04<01:05,  3.18it/s][A
  6%|▋         | 14/221 [00:05<01:36,  2.15it/s][A
  7%|▋         | 15/221 [00:05<01:25,  2.40it/s][A
  7%|▋         | 16/221 [00:05<01:20,  2.53it/s][A
  8%|▊         | 17/221 [00:06<01:29,  2.27it/s][A
  8%|▊         | 18/221 [00:06<01:20,  2.52it/s][A
  9%|▊         | 19/221 [00:06<01:04,  3.16it/s][A
  9%|▉         | 20/221 [00:06<00:52,  3.83it/s][A
 10%|▉         | 21/221 [00:07<00:50,  3.97it/s][A
 10%|▉         | 22/221 [00:07<00:59,  3.36it/s][A
 10%|█         | 23/221 [00:07<00:52,  3.74it/s][A
 11%|█         | 24/221 [00:08<00:46,  4.22it/s][A
 11%|█▏        | 25/221 [00:08<00:55,  3.55it/s][A
 12%|█▏        | 26/221 [00:08<01:08,  2.83it/s][A
 12%|█▏        | 27/221 [00:09<01:01,  3.14it/s][A
 13%|█▎        | 28/221 [00:09<01:22,  2.35it/s][A
 13%|█▎        | 29/221 [00:10<01:59,  1.60it/s][A[h264 @ 0x55a044d00d00] mmco: unref short failure
[h264 @ 0x55a044d00d00] mmco: unref short failure

 14%|█▎        | 30/221 [00:11<01:45,  1.82it/s][A
 14%|█▍        | 31/221 [00:11<01:28,  2.14it/s][A
 14%|█▍        | 32/221 [00:11<01:19,  2.36it/s][A[h264 @ 0x559c02d1e280] mmco: unref short failure

 15%|█▍        | 33/221 [00:12<01:18,  2.40it/s][A
 15%|█▌        | 34/221 [00:12<01:10,  2.65it/s][A
 16%|█▌        | 35/221 [00:12<00:55,  3.37it/s][A
 16%|█▋        | 36/221 [00:12<00:49,  3.73it/s][A
 17%|█▋        | 37/221 [00:13<01:07,  2.73it/s][A
 17%|█▋        | 38/221 [00:13<01:14,  2.46it/s][A
 18%|█▊        | 39/221 [00:14<01:11,  2.54it/s][A
 18%|█▊        | 40/221 [00:14<01:05,  2.76it/s][A
 19%|█▊        | 41/221 [00:14<00:52,  3.41it/s][A
 19%|█▉        | 42/221 [00:14<00:51,  3.51it/s][A
 19%|█▉        | 43/221 [00:15<00:45,  3.89it/s][A
 20%|█▉        | 44/221 [00:15<00:37,  4.69it/s][A
 20%|██        | 45/221 [00:15<01:02,  2.82it/s][A[h264 @ 0x56242492b500] mmco: unref short failure
[h264 @ 0x56242492b500] mmco: unref short failure

 21%|██        | 46/221 [00:16<01:20,  2.17it/s][A
 21%|██▏       | 47/221 [00:17<01:33,  1.87it/s][A
 22%|██▏       | 48/221 [00:17<01:20,  2.16it/s][A
 22%|██▏       | 49/221 [00:18<01:28,  1.95it/s][A[h264 @ 0x556b4ae16380] mmco: unref short failure
[h264 @ 0x556b4ae16380] mmco: unref short failure

 23%|██▎       | 50/221 [00:18<01:22,  2.08it/s][A
 23%|██▎       | 51/221 [00:18<01:07,  2.53it/s][A
 24%|██▎       | 52/221 [00:19<00:53,  3.15it/s][A[h264 @ 0x56242a1d8380] mmco: unref short failure

 24%|██▍       | 53/221 [00:19<00:45,  3.65it/s][A
 24%|██▍       | 54/221 [00:20<01:32,  1.80it/s][A
 25%|██▍       | 55/221 [00:20<01:19,  2.08it/s][A
 25%|██▌       | 56/221 [00:20<01:07,  2.44it/s][A
 26%|██▌       | 57/221 [00:21<00:56,  2.89it/s][A
 26%|██▌       | 58/221 [00:21<00:45,  3.57it/s][A
 27%|██▋       | 59/221 [00:21<00:41,  3.94it/s][A
 27%|██▋       | 60/221 [00:21<00:50,  3.20it/s][A
 28%|██▊       | 61/221 [00:22<00:44,  3.57it/s][A
 28%|██▊       | 62/221 [00:22<00:45,  3.51it/s][A
 29%|██▊       | 63/221 [00:22<00:44,  3.53it/s][A
 29%|██▉       | 64/221 [00:23<00:48,  3.27it/s][A
 29%|██▉       | 65/221 [00:23<00:45,  3.47it/s][A
 30%|██▉       | 66/221 [00:23<00:50,  3.08it/s][A
 30%|███       | 67/221 [00:24<00:52,  2.92it/s][A
 31%|███       | 68/221 [00:24<00:43,  3.55it/s][A
 31%|███       | 69/221 [00:24<00:52,  2.92it/s][A
 32%|███▏      | 70/221 [00:24<00:41,  3.62it/s][A
 32%|███▏      | 71/221 [00:26<01:29,  1.68it/s][A
 33%|███▎      | 72/221 [00:26<01:11,  2.08it/s][A
 33%|███▎      | 73/221 [00:26<01:03,  2.35it/s][A
 33%|███▎      | 74/221 [00:26<00:49,  2.99it/s][A
 34%|███▍      | 75/221 [00:27<00:47,  3.05it/s][A
 34%|███▍      | 76/221 [00:27<00:39,  3.71it/s][A
 35%|███▍      | 77/221 [00:27<00:37,  3.89it/s][A[h264 @ 0x556b4a13a600] mmco: unref short failure
[h264 @ 0x556b4a13a600] mmco: unref short failure

 35%|███▌      | 78/221 [00:27<00:39,  3.64it/s][A
 36%|███▌      | 79/221 [00:28<00:46,  3.02it/s][A
 36%|███▌      | 80/221 [00:28<00:38,  3.64it/s][A
 37%|███▋      | 81/221 [00:28<00:36,  3.88it/s][A
 37%|███▋      | 82/221 [00:29<01:03,  2.18it/s][A[h264 @ 0x559be9102880] mmco: unref short failure

 38%|███▊      | 83/221 [00:30<01:03,  2.17it/s][A
 38%|███▊      | 84/221 [00:30<00:52,  2.61it/s][A
 38%|███▊      | 85/221 [00:30<00:43,  3.11it/s][A
 39%|███▉      | 86/221 [00:30<00:38,  3.54it/s][A
 39%|███▉      | 87/221 [00:31<00:45,  2.96it/s][A
 40%|███▉      | 88/221 [00:31<00:43,  3.04it/s][A
 40%|████      | 89/221 [00:33<01:53,  1.16it/s][A
 41%|████      | 90/221 [00:33<01:31,  1.43it/s][A
 41%|████      | 91/221 [00:33<01:09,  1.86it/s][A
 42%|████▏     | 92/221 [00:34<00:56,  2.29it/s][A
 42%|████▏     | 93/221 [00:34<00:53,  2.38it/s][A
 43%|████▎     | 94/221 [00:34<00:45,  2.78it/s][A
 43%|████▎     | 95/221 [00:34<00:41,  3.06it/s][A
 43%|████▎     | 96/221 [00:35<00:36,  3.42it/s][A
 44%|████▍     | 97/221 [00:35<00:29,  4.20it/s][A
 44%|████▍     | 98/221 [00:35<00:26,  4.60it/s][A
 45%|████▌     | 100/221 [00:35<00:21,  5.68it/s][A
 46%|████▌     | 101/221 [00:35<00:19,  6.21it/s][A[h264 @ 0x56241af4e480] mmco: unref short failure
[h264 @ 0x56241af4e480] mmco: unref short failure

 46%|████▌     | 102/221 [00:36<00:28,  4.16it/s][A
 47%|████▋     | 103/221 [00:36<00:27,  4.35it/s][A
 47%|████▋     | 104/221 [00:36<00:30,  3.88it/s][A
 48%|████▊     | 105/221 [00:37<00:29,  3.95it/s][A
 48%|████▊     | 106/221 [00:37<00:41,  2.76it/s][A
 48%|████▊     | 107/221 [00:37<00:36,  3.16it/s][A
 49%|████▉     | 108/221 [00:38<00:30,  3.73it/s][A
 49%|████▉     | 109/221 [00:38<00:27,  4.11it/s][A
 50%|████▉     | 110/221 [00:38<00:25,  4.44it/s][A
 50%|█████     | 111/221 [00:38<00:31,  3.50it/s][A[h264 @ 0x56242364a3c0] mmco: unref short failure
[h264 @ 0x56242364a3c0] mmco: unref short failure

 51%|█████     | 112/221 [00:39<00:27,  3.92it/s][A
 51%|█████     | 113/221 [00:39<00:29,  3.65it/s][A
 52%|█████▏    | 115/221 [00:39<00:19,  5.32it/s][A
 52%|█████▏    | 116/221 [00:43<01:55,  1.10s/it][A
 53%|█████▎    | 117/221 [00:43<01:32,  1.13it/s][A[h264 @ 0x55a044d00d00] mmco: unref short failure
[h264 @ 0x55a044d00d00] mmco: unref short failure

 53%|█████▎    | 118/221 [00:44<01:16,  1.35it/s][A
 54%|█████▍    | 119/221 [00:44<01:01,  1.66it/s][A
 54%|█████▍    | 120/221 [00:44<00:51,  1.98it/s][A
 55%|█████▌    | 122/221 [00:44<00:31,  3.11it/s][A
 56%|█████▌    | 123/221 [00:44<00:26,  3.66it/s][A
 56%|█████▌    | 124/221 [00:45<00:23,  4.10it/s][A
 57%|█████▋    | 125/221 [00:45<00:23,  4.09it/s][A
 57%|█████▋    | 126/221 [00:45<00:26,  3.61it/s][A
 57%|█████▋    | 127/221 [00:46<00:28,  3.29it/s][A
 58%|█████▊    | 128/221 [00:46<00:29,  3.12it/s][A
 58%|█████▊    | 129/221 [00:46<00:26,  3.51it/s][A
 59%|█████▉    | 130/221 [00:46<00:23,  3.85it/s][A
 60%|█████▉    | 132/221 [00:47<00:17,  5.10it/s][A
 60%|██████    | 133/221 [00:47<00:22,  3.99it/s][A
 61%|██████    | 134/221 [00:47<00:20,  4.29it/s][A
 61%|██████    | 135/221 [00:47<00:19,  4.46it/s][A
 62%|██████▏   | 136/221 [00:48<00:22,  3.84it/s][A
 62%|██████▏   | 137/221 [00:48<00:19,  4.28it/s][A
 62%|██████▏   | 138/221 [00:48<00:22,  3.64it/s][A
 63%|██████▎   | 139/221 [00:49<00:23,  3.50it/s][A
 63%|██████▎   | 140/221 [00:49<00:23,  3.41it/s][A
 64%|██████▍   | 141/221 [00:49<00:20,  3.90it/s][A
 64%|██████▍   | 142/221 [00:49<00:20,  3.86it/s][A
 65%|██████▍   | 143/221 [00:50<00:22,  3.41it/s][A
 65%|██████▌   | 144/221 [00:50<00:18,  4.21it/s][A
 66%|██████▌   | 146/221 [00:50<00:12,  6.01it/s][A
 67%|██████▋   | 148/221 [00:50<00:12,  6.02it/s][A
 67%|██████▋   | 149/221 [00:50<00:11,  6.51it/s][A
 68%|██████▊   | 150/221 [00:50<00:10,  6.80it/s][A[h264 @ 0x559bf3ec5d00] mmco: unref short failure
[h264 @ 0x559bf3ec5d00] mmco: unref short failure

 68%|██████▊   | 151/221 [00:51<00:21,  3.22it/s][A
 69%|██████▉   | 152/221 [00:52<00:28,  2.40it/s][A
 69%|██████▉   | 153/221 [00:52<00:27,  2.51it/s][A
 70%|██████▉   | 154/221 [00:53<00:28,  2.39it/s][A
 70%|███████   | 155/221 [00:53<00:24,  2.66it/s][A
 71%|███████   | 156/221 [00:53<00:20,  3.12it/s][A[h264 @ 0x56242ebe7d80] mmco: unref short failure
[h264 @ 0x55a03e39b6c0] mmco: unref short failure
[h264 @ 0x55a03e39b6c0] mmco: unref short failure
[h264 @ 0x55a04d8fcc40] mmco: unref short failure
[h264 @ 0x55a04d8fcc40] mmco: unref short failure

 71%|███████   | 157/221 [00:55<00:54,  1.18it/s][A
 71%|███████▏  | 158/221 [00:56<00:39,  1.59it/s][A
 72%|███████▏  | 159/221 [00:56<00:29,  2.09it/s][A
 72%|███████▏  | 160/221 [00:56<00:23,  2.56it/s][A[h264 @ 0x55a04012a940] mmco: unref short failure

 73%|███████▎  | 162/221 [00:56<00:21,  2.74it/s][A
 74%|███████▍  | 163/221 [00:57<00:18,  3.11it/s][A[h264 @ 0x559c02cd9840] mmco: unref short failure
[h264 @ 0x559c02cd9840] mmco: unref short failure

 74%|███████▍  | 164/221 [00:57<00:21,  2.60it/s][A
 75%|███████▍  | 165/221 [00:57<00:17,  3.23it/s][A
 75%|███████▌  | 166/221 [00:58<00:16,  3.28it/s][A
 76%|███████▌  | 167/221 [00:58<00:14,  3.84it/s][A[h264 @ 0x55a04f38a640] mmco: unref short failure

 76%|███████▌  | 168/221 [01:00<00:50,  1.06it/s][A
 76%|███████▋  | 169/221 [01:01<00:37,  1.40it/s][A
 77%|███████▋  | 170/221 [01:01<00:29,  1.70it/s][A
 77%|███████▋  | 171/221 [01:01<00:24,  2.08it/s][A
 78%|███████▊  | 172/221 [01:01<00:19,  2.51it/s][A
 79%|███████▊  | 174/221 [01:02<00:13,  3.50it/s][A
 79%|███████▉  | 175/221 [01:02<00:16,  2.84it/s][A
 80%|███████▉  | 176/221 [01:02<00:14,  3.13it/s][A
 81%|████████  | 178/221 [01:03<00:11,  3.74it/s][A
 81%|████████  | 179/221 [01:03<00:13,  3.15it/s][A
 82%|████████▏ | 181/221 [01:03<00:09,  4.23it/s][A
 82%|████████▏ | 182/221 [01:04<00:09,  4.32it/s][A
 83%|████████▎ | 183/221 [01:04<00:08,  4.57it/s][A
 83%|████████▎ | 184/221 [01:04<00:08,  4.25it/s][A
 84%|████████▎ | 185/221 [01:04<00:07,  5.00it/s][A
 84%|████████▍ | 186/221 [01:05<00:07,  4.39it/s][A
 85%|████████▍ | 187/221 [01:05<00:07,  4.83it/s][A
 85%|████████▌ | 188/221 [01:05<00:07,  4.53it/s][A
 86%|████████▌ | 189/221 [01:05<00:08,  3.91it/s][A[h264 @ 0x559bec44db40] mmco: unref short failure
[h264 @ 0x559bec44db40] mmco: unref short failure

 86%|████████▌ | 190/221 [01:06<00:07,  3.93it/s][A
 87%|████████▋ | 192/221 [01:06<00:05,  5.22it/s][A
 88%|████████▊ | 194/221 [01:07<00:07,  3.58it/s][A
 89%|████████▊ | 196/221 [01:08<00:08,  2.92it/s][A
 90%|████████▉ | 198/221 [01:08<00:06,  3.39it/s][A
 90%|█████████ | 200/221 [01:08<00:05,  3.88it/s][A
 91%|█████████ | 201/221 [01:08<00:04,  4.08it/s][A
 91%|█████████▏| 202/221 [01:09<00:04,  4.40it/s][A
 92%|█████████▏| 204/221 [01:09<00:03,  5.03it/s][A
 93%|█████████▎| 206/221 [01:09<00:03,  4.49it/s][A
 94%|█████████▎| 207/221 [01:10<00:02,  4.91it/s][A
 94%|█████████▍| 208/221 [01:10<00:02,  5.37it/s][A
 95%|█████████▍| 209/221 [01:10<00:02,  5.59it/s][A
 95%|█████████▌| 211/221 [01:10<00:01,  5.67it/s][A
 96%|█████████▌| 212/221 [01:10<00:01,  6.25it/s][A
 96%|█████████▋| 213/221 [01:11<00:01,  5.64it/s][A
 97%|█████████▋| 214/221 [01:11<00:01,  4.84it/s][A
 97%|█████████▋| 215/221 [01:11<00:01,  4.61it/s][A
 98%|█████████▊| 216/221 [01:11<00:01,  4.48it/s][A
 98%|█████████▊| 217/221 [01:12<00:01,  3.67it/s][A
 99%|█████████▊| 218/221 [01:12<00:00,  4.06it/s][A
 99%|█████████▉| 219/221 [01:12<00:00,  4.19it/s][A[h264 @ 0x56241b4c1f40] mmco: unref short failure

100%|█████████▉| 220/221 [01:16<00:01,  1.20s/it][A
100%|██████████| 221/221 [01:16<00:00,  1.13it/s][A100%|██████████| 221/221 [01:16<00:00,  2.90it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:00,  3.63it/s][A
  1%|          | 2/221 [00:00<00:59,  3.71it/s][A
  1%|▏         | 3/221 [00:00<00:58,  3.74it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.75it/s][A
  2%|▏         | 5/221 [00:01<00:57,  3.76it/s][A
  3%|▎         | 6/221 [00:01<00:57,  3.76it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.76it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.77it/s][A
  4%|▍         | 9/221 [00:02<00:56,  3.77it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.77it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.77it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.78it/s][A
  6%|▌         | 13/221 [00:03<00:55,  3.78it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.78it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.78it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:51,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:14<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:22<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:38<00:20,  3.78it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.78it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.78it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:19,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:52<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:57<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:34,  6.45it/s][A
  1%|          | 2/221 [00:00<00:53,  4.07it/s][A
  1%|▏         | 3/221 [00:00<00:58,  3.75it/s][A
  2%|▏         | 4/221 [00:00<00:49,  4.37it/s][A
  2%|▏         | 5/221 [00:01<00:45,  4.77it/s][A
  3%|▎         | 7/221 [00:01<00:40,  5.32it/s][A
  4%|▎         | 8/221 [00:01<00:47,  4.51it/s][A
  4%|▍         | 9/221 [00:01<00:46,  4.58it/s][A
  5%|▍         | 10/221 [00:02<01:04,  3.25it/s][A
  5%|▍         | 11/221 [00:02<00:59,  3.56it/s][A
  5%|▌         | 12/221 [00:02<00:49,  4.19it/s][A
  6%|▌         | 13/221 [00:03<01:26,  2.40it/s][A
  6%|▋         | 14/221 [00:03<01:07,  3.05it/s][A
  7%|▋         | 15/221 [00:04<01:00,  3.41it/s][A
  7%|▋         | 16/221 [00:04<01:05,  3.13it/s][A
  8%|▊         | 17/221 [00:05<01:27,  2.32it/s][A
  8%|▊         | 18/221 [00:05<01:15,  2.71it/s][A
  9%|▊         | 19/221 [00:05<01:05,  3.09it/s][A
  9%|▉         | 20/221 [00:05<00:51,  3.88it/s][A
 10%|▉         | 21/221 [00:05<00:45,  4.44it/s][A
 10%|▉         | 22/221 [00:05<00:43,  4.60it/s][A
 11%|█         | 24/221 [00:06<00:32,  5.99it/s][A
 11%|█▏        | 25/221 [00:06<00:35,  5.50it/s][A
 12%|█▏        | 26/221 [00:06<00:37,  5.22it/s][A
 12%|█▏        | 27/221 [00:06<00:32,  5.98it/s][A
 13%|█▎        | 28/221 [00:07<00:42,  4.53it/s][A
 13%|█▎        | 29/221 [00:07<00:42,  4.47it/s][A
 14%|█▎        | 30/221 [00:07<00:46,  4.07it/s][A
 14%|█▍        | 31/221 [00:07<00:43,  4.38it/s][A
 15%|█▍        | 33/221 [00:08<00:34,  5.41it/s][A
 15%|█▌        | 34/221 [00:08<00:35,  5.28it/s][A
 16%|█▌        | 35/221 [00:08<00:39,  4.68it/s][A
 16%|█▋        | 36/221 [00:08<00:43,  4.28it/s][A
 17%|█▋        | 37/221 [00:09<00:40,  4.57it/s][A
 17%|█▋        | 38/221 [00:09<00:44,  4.16it/s][A
 18%|█▊        | 39/221 [00:09<00:41,  4.43it/s][A
 18%|█▊        | 40/221 [00:09<00:50,  3.59it/s][A
 19%|█▊        | 41/221 [00:10<00:43,  4.16it/s][A
 19%|█▉        | 42/221 [00:10<00:39,  4.50it/s][A
 19%|█▉        | 43/221 [00:10<00:45,  3.92it/s][A
 20%|█▉        | 44/221 [00:10<00:44,  4.00it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:11<00:41,  4.22it/s][A
 21%|██▏       | 47/221 [00:11<00:40,  4.31it/s][A
 22%|██▏       | 48/221 [00:11<00:36,  4.79it/s][A
 22%|██▏       | 49/221 [00:11<00:35,  4.83it/s][A
 23%|██▎       | 50/221 [00:12<00:44,  3.81it/s][A
 23%|██▎       | 51/221 [00:12<00:40,  4.17it/s][A
 24%|██▎       | 52/221 [00:12<00:40,  4.18it/s][A
 24%|██▍       | 53/221 [00:12<00:37,  4.51it/s][A
 24%|██▍       | 54/221 [00:13<00:55,  3.03it/s][A
 25%|██▍       | 55/221 [00:13<00:50,  3.30it/s][A
 25%|██▌       | 56/221 [00:13<00:42,  3.90it/s][A
 26%|██▌       | 57/221 [00:14<00:42,  3.86it/s][A
 26%|██▌       | 58/221 [00:14<00:46,  3.48it/s][A
 27%|██▋       | 59/221 [00:14<00:42,  3.83it/s][A
 27%|██▋       | 60/221 [00:14<00:40,  3.99it/s][A
 28%|██▊       | 61/221 [00:15<00:36,  4.43it/s][A
 28%|██▊       | 62/221 [00:15<00:37,  4.25it/s][A
 29%|██▊       | 63/221 [00:15<00:36,  4.33it/s][A
 29%|██▉       | 64/221 [00:16<00:49,  3.14it/s][A
 29%|██▉       | 65/221 [00:16<00:44,  3.53it/s][A
 30%|██▉       | 66/221 [00:16<00:55,  2.79it/s][A
 30%|███       | 67/221 [00:17<01:05,  2.36it/s][A
 31%|███       | 68/221 [00:17<00:53,  2.87it/s][A
 31%|███       | 69/221 [00:18<01:10,  2.17it/s][A
 32%|███▏      | 70/221 [00:18<00:53,  2.82it/s][A
 32%|███▏      | 71/221 [00:18<00:46,  3.23it/s][A
 33%|███▎      | 72/221 [00:18<00:50,  2.94it/s][A
 33%|███▎      | 73/221 [00:19<00:49,  2.97it/s][A
 33%|███▎      | 74/221 [00:19<00:40,  3.64it/s][A
 34%|███▍      | 75/221 [00:19<00:39,  3.74it/s][A
 34%|███▍      | 76/221 [00:19<00:35,  4.05it/s][A
 35%|███▍      | 77/221 [00:20<00:36,  3.97it/s][A
 35%|███▌      | 78/221 [00:20<00:36,  3.94it/s][A
 36%|███▌      | 79/221 [00:20<00:46,  3.04it/s][A
 36%|███▌      | 80/221 [00:21<00:40,  3.49it/s][A
 37%|███▋      | 81/221 [00:21<00:37,  3.73it/s][A
 37%|███▋      | 82/221 [00:21<00:38,  3.57it/s][A
 38%|███▊      | 83/221 [00:22<00:42,  3.28it/s][A
 38%|███▊      | 84/221 [00:22<00:39,  3.45it/s][A
 39%|███▉      | 86/221 [00:22<00:34,  3.96it/s][A
 39%|███▉      | 87/221 [00:23<00:43,  3.07it/s][A
 40%|███▉      | 88/221 [00:23<00:51,  2.60it/s][A
 40%|████      | 89/221 [00:24<00:46,  2.87it/s][A
 41%|████      | 90/221 [00:24<00:48,  2.68it/s][A
 41%|████      | 91/221 [00:24<00:39,  3.31it/s][A
 42%|████▏     | 92/221 [00:24<00:41,  3.09it/s][A
 42%|████▏     | 93/221 [00:25<00:55,  2.31it/s][A
 43%|████▎     | 94/221 [00:25<00:48,  2.61it/s][A
 43%|████▎     | 95/221 [00:26<00:43,  2.91it/s][A
 43%|████▎     | 96/221 [00:26<00:38,  3.23it/s][A
 44%|████▍     | 97/221 [00:26<00:33,  3.69it/s][A
 44%|████▍     | 98/221 [00:26<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:27<00:28,  4.26it/s][A
 45%|████▌     | 100/221 [00:27<00:28,  4.28it/s][A
 46%|████▌     | 101/221 [00:27<00:27,  4.30it/s][A
 46%|████▌     | 102/221 [00:28<00:45,  2.62it/s][A
 47%|████▋     | 103/221 [00:28<00:35,  3.30it/s][A
 47%|████▋     | 104/221 [00:28<00:32,  3.64it/s][A
 48%|████▊     | 105/221 [00:28<00:31,  3.72it/s][A
 48%|████▊     | 106/221 [00:29<00:41,  2.77it/s][A
 48%|████▊     | 107/221 [00:29<00:37,  3.06it/s][A
 49%|████▉     | 108/221 [00:29<00:33,  3.33it/s][A
 50%|████▉     | 110/221 [00:30<00:27,  4.01it/s][A
 50%|█████     | 111/221 [00:30<00:28,  3.83it/s][A
 51%|█████     | 112/221 [00:30<00:28,  3.89it/s][A
 51%|█████     | 113/221 [00:30<00:25,  4.32it/s][A
 52%|█████▏    | 115/221 [00:31<00:20,  5.06it/s][A
 52%|█████▏    | 116/221 [00:31<00:22,  4.71it/s][A
 53%|█████▎    | 117/221 [00:31<00:23,  4.49it/s][A
 53%|█████▎    | 118/221 [00:31<00:22,  4.50it/s][A
 54%|█████▍    | 119/221 [00:32<00:28,  3.58it/s][A
 54%|█████▍    | 120/221 [00:32<00:25,  4.00it/s][A
 55%|█████▍    | 121/221 [00:32<00:21,  4.69it/s][A
 55%|█████▌    | 122/221 [00:32<00:22,  4.44it/s][A
 56%|█████▌    | 123/221 [00:33<00:22,  4.32it/s][A
 56%|█████▌    | 124/221 [00:33<00:23,  4.17it/s][A
 57%|█████▋    | 125/221 [00:33<00:26,  3.63it/s][A
 57%|█████▋    | 126/221 [00:34<00:24,  3.92it/s][A
 57%|█████▋    | 127/221 [00:34<00:29,  3.16it/s][A
 58%|█████▊    | 128/221 [00:34<00:27,  3.41it/s][A
 58%|█████▊    | 129/221 [00:34<00:22,  4.07it/s][A
 59%|█████▉    | 130/221 [00:35<00:24,  3.78it/s][A
 60%|█████▉    | 132/221 [00:35<00:22,  3.96it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.72it/s][A
 61%|██████    | 134/221 [00:36<00:27,  3.20it/s][A
 61%|██████    | 135/221 [00:36<00:25,  3.38it/s][A
 62%|██████▏   | 136/221 [00:36<00:23,  3.61it/s][A
 62%|██████▏   | 137/221 [00:37<00:20,  4.12it/s][A
 62%|██████▏   | 138/221 [00:37<00:21,  3.82it/s][A
 63%|██████▎   | 139/221 [00:37<00:29,  2.80it/s][A
 63%|██████▎   | 140/221 [00:38<00:27,  2.96it/s][A
 64%|██████▍   | 141/221 [00:38<00:22,  3.55it/s][A
 64%|██████▍   | 142/221 [00:38<00:20,  3.85it/s][A
 65%|██████▍   | 143/221 [00:39<00:30,  2.58it/s][A
 65%|██████▌   | 144/221 [00:39<00:30,  2.55it/s][A
 66%|██████▌   | 146/221 [00:39<00:18,  4.10it/s][A
 67%|██████▋   | 147/221 [00:40<00:18,  3.97it/s][A
 67%|██████▋   | 148/221 [00:40<00:23,  3.13it/s][A
 67%|██████▋   | 149/221 [00:40<00:22,  3.25it/s][A
 68%|██████▊   | 150/221 [00:41<00:20,  3.49it/s][A
 68%|██████▊   | 151/221 [00:41<00:23,  3.04it/s][A
 69%|██████▉   | 152/221 [00:42<00:36,  1.89it/s][A
 69%|██████▉   | 153/221 [00:42<00:27,  2.43it/s][A
 70%|██████▉   | 154/221 [00:42<00:23,  2.90it/s][A
 70%|███████   | 155/221 [00:43<00:20,  3.25it/s][A
 71%|███████   | 156/221 [00:43<00:22,  2.93it/s][A
 71%|███████   | 157/221 [00:43<00:21,  2.99it/s][A
 71%|███████▏  | 158/221 [00:44<00:20,  3.08it/s][A
 72%|███████▏  | 159/221 [00:44<00:16,  3.84it/s][A
 72%|███████▏  | 160/221 [00:44<00:14,  4.09it/s][A
 73%|███████▎  | 161/221 [00:44<00:15,  3.90it/s][A
 73%|███████▎  | 162/221 [00:44<00:12,  4.55it/s][A
 74%|███████▍  | 163/221 [00:45<00:13,  4.34it/s][A
 74%|███████▍  | 164/221 [00:45<00:11,  5.15it/s][A
 75%|███████▍  | 165/221 [00:45<00:10,  5.31it/s][A
 75%|███████▌  | 166/221 [00:45<00:10,  5.05it/s][A
 76%|███████▌  | 167/221 [00:45<00:09,  5.63it/s][A
 76%|███████▌  | 168/221 [00:45<00:10,  5.14it/s][A
 76%|███████▋  | 169/221 [00:46<00:09,  5.48it/s][A
 77%|███████▋  | 170/221 [00:46<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:46<00:13,  3.70it/s][A
 78%|███████▊  | 172/221 [00:47<00:12,  3.97it/s][A
 78%|███████▊  | 173/221 [00:47<00:13,  3.58it/s][A
 79%|███████▊  | 174/221 [00:48<00:17,  2.69it/s][A
 79%|███████▉  | 175/221 [00:48<00:16,  2.83it/s][A
 80%|███████▉  | 176/221 [00:48<00:14,  3.19it/s][A
 80%|████████  | 177/221 [00:48<00:12,  3.54it/s][A
 81%|████████  | 178/221 [00:49<00:12,  3.47it/s][A
 81%|████████  | 179/221 [00:49<00:11,  3.66it/s][A
 81%|████████▏ | 180/221 [00:49<00:09,  4.32it/s][A
 82%|████████▏ | 181/221 [00:49<00:09,  4.32it/s][A
 82%|████████▏ | 182/221 [00:50<00:11,  3.35it/s][A
 83%|████████▎ | 183/221 [00:50<00:11,  3.24it/s][A
 83%|████████▎ | 184/221 [00:50<00:10,  3.51it/s][A
 84%|████████▎ | 185/221 [00:50<00:08,  4.06it/s][A
 84%|████████▍ | 186/221 [00:51<00:10,  3.20it/s][A
 85%|████████▍ | 187/221 [00:51<00:09,  3.51it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.47it/s][A
 86%|████████▌ | 189/221 [00:52<00:08,  3.74it/s][A
 86%|████████▌ | 190/221 [00:52<00:09,  3.40it/s][A
 86%|████████▋ | 191/221 [00:52<00:07,  3.96it/s][A
 87%|████████▋ | 192/221 [00:52<00:07,  3.81it/s][A
 87%|████████▋ | 193/221 [00:52<00:06,  4.56it/s][A
 88%|████████▊ | 194/221 [00:53<00:06,  3.93it/s][A
 88%|████████▊ | 195/221 [00:53<00:06,  4.21it/s][A
 89%|████████▊ | 196/221 [00:53<00:07,  3.41it/s][A
 89%|████████▉ | 197/221 [00:54<00:06,  3.58it/s][A
 90%|████████▉ | 198/221 [00:54<00:08,  2.86it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.35it/s][A
 90%|█████████ | 200/221 [00:55<00:07,  2.85it/s][A
 91%|█████████ | 201/221 [00:55<00:06,  3.24it/s][A
 91%|█████████▏| 202/221 [00:55<00:06,  3.09it/s][A
 92%|█████████▏| 203/221 [00:56<00:05,  3.45it/s][A
 92%|█████████▏| 204/221 [00:56<00:05,  2.93it/s][A
 93%|█████████▎| 205/221 [00:56<00:04,  3.71it/s][A
 93%|█████████▎| 206/221 [00:57<00:04,  3.36it/s][A
 94%|█████████▎| 207/221 [00:57<00:03,  4.08it/s][A
 94%|█████████▍| 208/221 [00:57<00:03,  4.01it/s][A
 95%|█████████▍| 209/221 [00:57<00:02,  4.03it/s][A
 95%|█████████▌| 211/221 [00:58<00:02,  4.31it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  4.04it/s][A
 96%|█████████▋| 213/221 [00:58<00:01,  4.24it/s][A
 97%|█████████▋| 214/221 [00:59<00:02,  2.77it/s][A
 97%|█████████▋| 215/221 [00:59<00:01,  3.20it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.38it/s][A
 98%|█████████▊| 217/221 [01:00<00:01,  3.28it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.45it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.31it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.72it/s][A
100%|██████████| 221/221 [01:01<00:00,  3.85it/s][A100%|██████████| 221/221 [01:01<00:00,  3.62it/s]
09/09/2024 21:09:18 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 749--===========

09/09/2024 21:09:18 - INFO - __main__ -   {'area_r1': 41.4, 'area_recall': '41.4/65.0/75.7', 'area_ravg': 60.7}
09/09/2024 21:09:18 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 749--===========

09/09/2024 21:09:18 - INFO - __main__ -   {'forward_r1': 37.6, 'forward_recall': '37.6/66.5/76.8', 'forward_ravg': 60.3}
09/09/2024 21:09:18 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 749--===========

09/09/2024 21:09:18 - INFO - __main__ -   {'area_video_r1': 39.9, 'area_video_recall': '39.9/67.8/78.2', 'area_video_ravg': 62.0}
09/09/2024 21:09:18 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/09/2024 21:09:18 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 21:09:18 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 749--===========

09/09/2024 21:09:18 - INFO - __main__ -   {'area_video_r1': 52.4, 'area_video_recall': '52.4/75.0/83.5', 'area_video_ravg': 70.3, 'area_video_back_r1': 49.3, 'area_video_back_recall': '49.3/74.7/81.6', 'area_video_back_ravg': 68.5}
09/09/2024 21:09:18 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/09/2024 21:09:18 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/09/2024 21:09:18 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 749--===========

09/09/2024 21:09:18 - INFO - __main__ -   {'video_r1': 43.3, 'video_recall': '43.3/70.8/82.4', 'video_ravg': 65.5}
09/09/2024 21:09:18 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 21:09:18 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 21:09:18 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 749--===========

09/09/2024 21:09:18 - INFO - __main__ -   {'video_r1': 51.7, 'video_recall': '51.7/75.2/83.1', 'video_ravg': 70.0}
09/09/2024 21:09:18 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/09/2024 21:09:18 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/09/2024 21:09:39 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.007740587927401066, 'loss_ret%tv%ta--finetune_area/loss_area': 1.132927656173706, 'loss_ret%tv%ta--finetune_area/total_loss': 1.140668272972107}
 39%|███▊      | 750/1945 [4:04:19<40:40:04, 122.51s/it][h264 @ 0x559c07957100] mmco: unref short failure
[h264 @ 0x559c07957100] mmco: unref short failure
 39%|███▊      | 751/1945 [4:04:23<28:52:05, 87.04s/it] [h264 @ 0x55a04cb76e00] mmco: unref short failure
[h264 @ 0x55a04cb76e00] mmco: unref short failure
 39%|███▊      | 752/1945 [4:04:28<20:39:00, 62.31s/it][h264 @ 0x559c00826240] mmco: unref short failure
[h264 @ 0x559c00826240] mmco: unref short failure
[h264 @ 0x56241cdcfe40] mmco: unref short failure
[h264 @ 0x56241cdcfe40] mmco: unref short failure
 39%|███▊      | 753/1945 [4:04:33<14:57:17, 45.17s/it][h264 @ 0x55a04a4b8fc0] mmco: unref short failure
[h264 @ 0x55a04a4b8fc0] mmco: unref short failure
[h264 @ 0x55a04a4b8fc0] mmco: unref short failure
[h264 @ 0x55a04a4b8fc0] mmco: unref short failure
 39%|███▉      | 754/1945 [4:04:39<11:01:47, 33.34s/it][h264 @ 0x556b2d267180] mmco: unref short failure
[h264 @ 0x556b2d267180] mmco: unref short failure
 39%|███▉      | 755/1945 [4:04:46<8:24:22, 25.43s/it] [h264 @ 0x55a04ce2a9c0] mmco: unref short failure
[h264 @ 0x55a03cdea600] mmco: unref short failure
[h264 @ 0x55a0332de240] mmco: unref short failure
 39%|███▉      | 756/1945 [4:04:53<6:36:08, 19.99s/it][h264 @ 0x5624328c41c0] mmco: unref short failure
[h264 @ 0x562419e7ee80] mmco: unref short failure
[h264 @ 0x562419e7ee80] mmco: unref short failure
[h264 @ 0x55a038008080] mmco: unref short failure
 39%|███▉      | 757/1945 [4:05:01<5:25:11, 16.42s/it][h264 @ 0x559c01182200] mmco: unref short failure
[h264 @ 0x559c01182200] mmco: unref short failure
[h264 @ 0x5624328fc940] mmco: unref short failure
[h264 @ 0x56241aadda40] mmco: unref short failure
[h264 @ 0x56241aadda40] mmco: unref short failure
[h264 @ 0x55a049c0fa40] mmco: unref short failure
[h264 @ 0x55a0414bf040] mmco: unref short failure
[h264 @ 0x55a0414bf040] mmco: unref short failure
 39%|███▉      | 758/1945 [4:05:09<4:33:50, 13.84s/it][h264 @ 0x556b2d9ced40] mmco: unref short failure
[h264 @ 0x556b2d9ced40] mmco: unref short failure
[h264 @ 0x55a034a9b600] mmco: unref short failure
[h264 @ 0x559bf43819c0] mmco: unref short failure
[h264 @ 0x559bf43819c0] mmco: unref short failure
 39%|███▉      | 759/1945 [4:05:17<4:00:16, 12.16s/it][h264 @ 0x56241e1ee740] mmco: unref short failure
[h264 @ 0x56241e1ee740] mmco: unref short failure
[h264 @ 0x55a033c19700] mmco: unref short failure
[h264 @ 0x55a033c19700] mmco: unref short failure
[h264 @ 0x56241b1496c0] mmco: unref short failure
[h264 @ 0x56241b1496c0] mmco: unref short failure
[h264 @ 0x55a034fee780] mmco: unref short failure
 39%|███▉      | 760/1945 [4:05:26<3:38:54, 11.08s/it] 39%|███▉      | 761/1945 [4:05:33<3:16:10,  9.94s/it] 39%|███▉      | 762/1945 [4:05:41<3:01:47,  9.22s/it] 39%|███▉      | 763/1945 [4:05:48<2:48:14,  8.54s/it][h264 @ 0x55a037afb1c0] mmco: unref short failure
[h264 @ 0x55a037afb1c0] mmco: unref short failure
[h264 @ 0x55a035029840] mmco: unref short failure
[h264 @ 0x556b41c2aa80] mmco: unref short failure
[h264 @ 0x556b41c2aa80] mmco: unref short failure
[h264 @ 0x556b41c2aa80] mmco: unref short failure
[h264 @ 0x5624207d1980] mmco: unref short failure
 39%|███▉      | 764/1945 [4:05:55<2:43:29,  8.31s/it][h264 @ 0x56241db31dc0] mmco: unref short failure
[h264 @ 0x56241db31dc0] mmco: unref short failure
[h264 @ 0x55a039a397c0] mmco: unref short failure
[h264 @ 0x55a039a397c0] mmco: unref short failure
[h264 @ 0x556b4a2cc2c0] mmco: unref short failure
[h264 @ 0x556b4a2cc2c0] mmco: unref short failure
[h264 @ 0x556b4a2cc2c0] mmco: unref short failure
[h264 @ 0x556b4a2cc2c0] mmco: unref short failure
 39%|███▉      | 765/1945 [4:06:03<2:40:04,  8.14s/it][h264 @ 0x559bf6338400] mmco: unref short failure
[h264 @ 0x556b30d81b00] mmco: unref short failure
[h264 @ 0x556b30d81b00] mmco: unref short failure
 39%|███▉      | 766/1945 [4:06:11<2:36:41,  7.97s/it][h264 @ 0x55a035f81dc0] mmco: unref short failure
[h264 @ 0x55a035f81dc0] mmco: unref short failure
 39%|███▉      | 767/1945 [4:06:18<2:32:12,  7.75s/it] 39%|███▉      | 768/1945 [4:06:25<2:25:43,  7.43s/it][h264 @ 0x556b2d0bbe80] mmco: unref short failure
[h264 @ 0x556b2d0bbe80] mmco: unref short failure
 40%|███▉      | 769/1945 [4:06:31<2:20:46,  7.18s/it] 40%|███▉      | 770/1945 [4:06:44<2:55:17,  8.95s/it][h264 @ 0x556b2d7b5480] mmco: unref short failure
[h264 @ 0x556b2d7b5480] mmco: unref short failure
[h264 @ 0x562422f94480] mmco: unref short failure
 40%|███▉      | 771/1945 [4:06:50<2:36:25,  7.99s/it][h264 @ 0x559bed115540] mmco: unref short failure
[h264 @ 0x556b3711f600] mmco: unref short failure
[h264 @ 0x556b3711f600] mmco: unref short failure
[h264 @ 0x556b2d853800] mmco: unref short failure
 40%|███▉      | 772/1945 [4:06:56<2:20:44,  7.20s/it] 40%|███▉      | 773/1945 [4:07:01<2:10:13,  6.67s/it][h264 @ 0x55a032495dc0] mmco: unref short failure
[h264 @ 0x55a0333be480] mmco: unref short failure
[h264 @ 0x556b2d757a40] mmco: unref short failure
[h264 @ 0x556b4d2fe540] mmco: unref short failure
[h264 @ 0x55a047782940] mmco: unref short failure
[h264 @ 0x55a047782940] mmco: unref short failure
[h264 @ 0x55a03b344540] mmco: unref short failure
[h264 @ 0x55a03b344540] mmco: unref short failure
[h264 @ 0x559bf4544e40] mmco: unref short failure
[h264 @ 0x559bf4544e40] mmco: unref short failure
[h264 @ 0x55a0396a2680] mmco: unref short failure
[h264 @ 0x55a0396a2680] mmco: unref short failure
 40%|███▉      | 774/1945 [4:07:23<3:37:58, 11.17s/it][h264 @ 0x55a04f95a240] mmco: unref short failure
[h264 @ 0x55a04f95a240] mmco: unref short failure
 40%|███▉      | 775/1945 [4:07:30<3:14:02,  9.95s/it] 40%|███▉      | 776/1945 [4:07:34<2:37:51,  8.10s/it] 40%|███▉      | 777/1945 [4:07:37<2:12:35,  6.81s/it]/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556b2d7ac940] mmco: unref short failure
[h264 @ 0x556b2d7ac940] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a03360db40] mmco: unref short failure
[h264 @ 0x55a03360db40] mmco: unref short failure
[h264 @ 0x559be99220c0] mmco: unref short failure
[h264 @ 0x556b2cd30f00] mmco: unref short failure
[h264 @ 0x55a032d038c0] mmco: unref short failure
[h264 @ 0x559be95af0c0] mmco: unref short failure
[h264 @ 0x559be958ea40] mmco: unref short failure
[h264 @ 0x559be958ea40] mmco: unref short failure
[h264 @ 0x5624172b14c0] mmco: unref short failure
[h264 @ 0x559be94fc680] mmco: unref short failure
[h264 @ 0x559be94fc680] mmco: unref short failure
[h264 @ 0x559be905cc80] mmco: unref short failure
[h264 @ 0x559be905cc80] mmco: unref short failure
[h264 @ 0x559be9207700] mmco: unref short failure
[h264 @ 0x559be9207700] mmco: unref short failure
[h264 @ 0x556b30001d40] mmco: unref short failure
[h264 @ 0x556b30001d40] mmco: unref short failure
[h264 @ 0x562416654340] mmco: unref short failure
[h264 @ 0x562416654340] mmco: unref short failure
[h264 @ 0x559bebca5c00] mmco: unref short failure
[h264 @ 0x559bebca5c00] mmco: unref short failure
[h264 @ 0x55a0345d4180] mmco: unref short failure
[h264 @ 0x5624175c6d80] mmco: unref short failure
[h264 @ 0x5624175c6d80] mmco: unref short failure
[h264 @ 0x559beb1a0c40] mmco: unref short failure
[h264 @ 0x556b2dc52c80] mmco: unref short failure
[h264 @ 0x556b2dc52c80] mmco: unref short failure
[h264 @ 0x55a0372df140] mmco: unref short failure
[h264 @ 0x55a036d80400] mmco: unref short failure
[h264 @ 0x562418551a40] mmco: unref short failure
[h264 @ 0x562418551a40] mmco: unref short failure
[h264 @ 0x559bebca5980] mmco: unref short failure
[h264 @ 0x559bebca5980] mmco: unref short failure
[h264 @ 0x559bf2de1140] mmco: unref short failure
[h264 @ 0x556b30d73080] mmco: unref short failure
[h264 @ 0x556b3394d4c0] mmco: unref short failure
[h264 @ 0x559bf046c640] mmco: unref short failure
[h264 @ 0x559bf046c640] mmco: unref short failure
[h264 @ 0x55a034106a40] mmco: unref short failure
[h264 @ 0x55a034106a40] mmco: unref short failure
[h264 @ 0x55a034106a40] mmco: unref short failure
[h264 @ 0x55a034106a40] mmco: unref short failure
[h264 @ 0x55a036392a00] mmco: unref short failure
[h264 @ 0x55a036392a00] mmco: unref short failure
[h264 @ 0x559beef98c80] mmco: unref short failure
[h264 @ 0x559beef98c80] mmco: unref short failure
 40%|████      | 778/1945 [4:10:00<15:27:36, 47.69s/it][h264 @ 0x55a033408440] mmco: unref short failure
[h264 @ 0x55a033408440] mmco: unref short failure
 40%|████      | 779/1945 [4:10:07<11:30:03, 35.51s/it][h264 @ 0x562418321b80] mmco: unref short failure
[h264 @ 0x562418321b80] mmco: unref short failure
[h264 @ 0x556b318a0100] mmco: unref short failure
[h264 @ 0x556b318a0100] mmco: unref short failure
 40%|████      | 780/1945 [4:10:15<8:47:01, 27.14s/it] [h264 @ 0x559be9c4bec0] mmco: unref short failure
[h264 @ 0x559beee27d80] mmco: unref short failure
[h264 @ 0x559beee27d80] mmco: unref short failure
[h264 @ 0x559bea2e7ac0] mmco: unref short failure
 40%|████      | 781/1945 [4:10:22<6:48:19, 21.05s/it][h264 @ 0x559be9b1f900] mmco: unref short failure
 40%|████      | 782/1945 [4:10:30<5:29:43, 17.01s/it][h264 @ 0x559bee14c440] mmco: unref short failure
[h264 @ 0x559bee14c440] mmco: unref short failure
 40%|████      | 783/1945 [4:10:37<4:31:38, 14.03s/it] 40%|████      | 784/1945 [4:10:44<3:53:00, 12.04s/it][h264 @ 0x556b2ddc5cc0] mmco: unref short failure
[h264 @ 0x556b2ddc5cc0] mmco: unref short failure
 40%|████      | 785/1945 [4:10:51<3:24:06, 10.56s/it][h264 @ 0x55a037650a80] mmco: unref short failure
[h264 @ 0x55a03476ca40] mmco: unref short failure
[h264 @ 0x55a03476ca40] mmco: unref short failure
[h264 @ 0x556b30db6d40] mmco: unref short failure
[h264 @ 0x56241fe765c0] mmco: unref short failure
[h264 @ 0x559be9f74bc0] mmco: unref short failure
[h264 @ 0x559be9f74bc0] mmco: unref short failure
[h264 @ 0x5624191a4f80] mmco: unref short failure
[h264 @ 0x5624191a4f80] mmco: unref short failure
[h264 @ 0x55a034c3b800] mmco: unref short failure
[h264 @ 0x559be9f6b540] mmco: unref short failure
[h264 @ 0x559be9f6b540] mmco: unref short failure
[h264 @ 0x55a035c5e300] mmco: unref short failure
[h264 @ 0x55a035c5e300] mmco: unref short failure
[h264 @ 0x56241e340180] mmco: unref short failure
[h264 @ 0x562417b1f2c0] mmco: unref short failure
[h264 @ 0x562417b1f2c0] mmco: unref short failure
[h264 @ 0x556b370357c0] mmco: unref short failure
[h264 @ 0x556b370357c0] mmco: unref short failure
[h264 @ 0x556b30203600] mmco: unref short failure
[h264 @ 0x556b30203600] mmco: unref short failure
[h264 @ 0x56241957c1c0] mmco: unref short failure
[h264 @ 0x55a0340cc140] mmco: unref short failure
[h264 @ 0x55a0330bc9c0] mmco: unref short failure
[h264 @ 0x55a0330bc9c0] mmco: unref short failure
 40%|████      | 786/1945 [4:11:56<8:40:46, 26.96s/it] 40%|████      | 787/1945 [4:12:04<6:46:08, 21.04s/it][h264 @ 0x55a03372c940] mmco: unref short failure
[h264 @ 0x55a03372c940] mmco: unref short failure
 41%|████      | 788/1945 [4:12:11<5:25:21, 16.87s/it][h264 @ 0x55a0369ad9c0] mmco: unref short failure
[h264 @ 0x55a0369ad9c0] mmco: unref short failure
[h264 @ 0x55a03770b180] mmco: unref short failure
[h264 @ 0x55a03770b180] mmco: unref short failure
[h264 @ 0x562418004440] mmco: unref short failure
[h264 @ 0x559bed48e640] mmco: unref short failure
 41%|████      | 789/1945 [4:12:18<4:29:21, 13.98s/it][h264 @ 0x559bf376d000] mmco: unref short failure
[h264 @ 0x55a036cf59c0] mmco: unref short failure
[h264 @ 0x56241a3e4e00] mmco: unref short failure
[h264 @ 0x56241a3e4e00] mmco: unref short failure
[h264 @ 0x56241a3e4e00] mmco: unref short failure
[h264 @ 0x56241a3e4e00] mmco: unref short failure
[h264 @ 0x56241a3e4e00] mmco: unref short failure
[h264 @ 0x56241a3e4e00] mmco: unref short failure
[h264 @ 0x56241a3e4e00] mmco: unref short failure
[h264 @ 0x56241a3e4e00] mmco: unref short failure
[h264 @ 0x56241a3e4e00] mmco: unref short failure
[h264 @ 0x56241a3e4e00] mmco: unref short failure
 41%|████      | 790/1945 [4:12:25<3:51:13, 12.01s/it] 41%|████      | 791/1945 [4:12:33<3:25:19, 10.68s/it] 41%|████      | 792/1945 [4:12:41<3:09:48,  9.88s/it] 41%|████      | 793/1945 [4:12:48<2:53:26,  9.03s/it][h264 @ 0x556b31c62fc0] mmco: unref short failure
[h264 @ 0x559bea5a27c0] mmco: unref short failure
[h264 @ 0x56241a172a00] mmco: unref short failure
[h264 @ 0x56241a172a00] mmco: unref short failure
[h264 @ 0x55a034c30c80] mmco: unref short failure
[h264 @ 0x559bec9ba8c0] mmco: unref short failure
[h264 @ 0x56241fb476c0] mmco: unref short failure
[h264 @ 0x56241fb476c0] mmco: unref short failure
[h264 @ 0x556b3984d9c0] mmco: unref short failure
[h264 @ 0x55a0373bd740] mmco: unref short failure
[h264 @ 0x5624190e9040] mmco: unref short failure
[h264 @ 0x55a039181180] mmco: unref short failure
[h264 @ 0x556b33bd6600] mmco: unref short failure
[h264 @ 0x556b33bd6600] mmco: unref short failure
[h264 @ 0x556b33bd6600] mmco: unref short failure
[h264 @ 0x556b33bd6600] mmco: unref short failure
[h264 @ 0x556b33bd6600] mmco: unref short failure
[h264 @ 0x56241ed549c0] mmco: unref short failure
[h264 @ 0x56241ed549c0] mmco: unref short failure
 41%|████      | 794/1945 [4:14:01<9:00:55, 28.20s/it][h264 @ 0x55a03eae2e40] mmco: unref short failure
[h264 @ 0x55a03eae2e40] mmco: unref short failure
 41%|████      | 795/1945 [4:14:08<6:58:17, 21.82s/it][h264 @ 0x55a0340a3380] mmco: unref short failure
[h264 @ 0x55a0340a3380] mmco: unref short failure
 41%|████      | 796/1945 [4:14:15<5:30:59, 17.28s/it][h264 @ 0x556b2f4cad00] mmco: unref short failure
[h264 @ 0x556b2f4cad00] mmco: unref short failure
[h264 @ 0x556b2f4cad00] mmco: unref short failure
not have audios 8-qwaveiHMM.3
 41%|████      | 797/1945 [4:14:23<4:37:24, 14.50s/it] 41%|████      | 798/1945 [4:14:30<3:56:11, 12.36s/it][h264 @ 0x55a0433520c0] mmco: unref short failure
[h264 @ 0x55a0433520c0] mmco: unref short failure
[h264 @ 0x55a0433520c0] mmco: unref short failure
[h264 @ 0x55a0433520c0] mmco: unref short failure
[h264 @ 0x55a039cf3300] mmco: unref short failure
[h264 @ 0x55a039cf3300] mmco: unref short failure
[h264 @ 0x55a036988600] mmco: unref short failure
[h264 @ 0x55a036988600] mmco: unref short failure
 41%|████      | 799/1945 [4:14:38<3:32:39, 11.13s/it]09/09/2024 21:20:00 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 21:20:00 - INFO - __main__ -   start running ret%tv validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556b31dcb480] mmco: unref short failure
[h264 @ 0x556b30914240] mmco: unref short failure
[h264 @ 0x556b30914240] mmco: unref short failure
[h264 @ 0x556b30914240] mmco: unref short failure
[h264 @ 0x556b30914240] mmco: unref short failure
[h264 @ 0x5624175d1000] mmco: unref short failure
[h264 @ 0x5624175d1000] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559bf0ff87c0] mmco: unref short failure
[h264 @ 0x559bf0ff87c0] mmco: unref short failure
[h264 @ 0x55a03b8c8f40] mmco: unref short failure
[h264 @ 0x55a03b8c8f40] mmco: unref short failure
[h264 @ 0x559bf4b02500] mmco: unref short failure
[h264 @ 0x559bf4b02500] mmco: unref short failure
[h264 @ 0x55a041e14500] mmco: unref short failure
[h264 @ 0x55a041e14500] mmco: unref short failure
[h264 @ 0x56241ad69c00] mmco: unref short failure
[h264 @ 0x56241def0d40] mmco: unref short failure
[h264 @ 0x55a040cccec0] mmco: unref short failure
[h264 @ 0x56241a6c28c0] mmco: unref short failure
[h264 @ 0x56241a6c28c0] mmco: unref short failure
[h264 @ 0x559bf7eb5240] mmco: unref short failure
[h264 @ 0x559bf7eb5240] mmco: unref short failure
[h264 @ 0x556b3e0407c0] mmco: unref short failure
[h264 @ 0x556b3e0407c0] mmco: unref short failure
[h264 @ 0x556b3e0407c0] mmco: unref short failure
[h264 @ 0x556b3e0407c0] mmco: unref short failure
[h264 @ 0x559bf859b880] mmco: unref short failure
[h264 @ 0x559bebd72d00] mmco: unref short failure
[h264 @ 0x559bebd72d00] mmco: unref short failure
[h264 @ 0x559bebd72d00] mmco: unref short failure
[h264 @ 0x559bebd72d00] mmco: unref short failure
[h264 @ 0x55a03ebef700] mmco: unref short failure
[h264 @ 0x55a03ebef700] mmco: unref short failure
[h264 @ 0x56241f372dc0] mmco: unref short failure
[h264 @ 0x56241f372dc0] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:25,  2.57it/s][A
  1%|          | 2/221 [00:00<01:22,  2.66it/s][A[h264 @ 0x562426fba1c0] mmco: unref short failure
[h264 @ 0x562426fba1c0] mmco: unref short failure

  1%|▏         | 3/221 [00:00<01:01,  3.56it/s][A
  2%|▏         | 5/221 [00:01<00:38,  5.62it/s][A
  3%|▎         | 7/221 [00:01<00:31,  6.70it/s][A
  4%|▎         | 8/221 [00:01<00:45,  4.72it/s][A
  4%|▍         | 9/221 [00:01<00:42,  4.96it/s][A
  5%|▍         | 10/221 [00:02<00:57,  3.64it/s][A
  5%|▍         | 11/221 [00:02<00:49,  4.27it/s][A
  5%|▌         | 12/221 [00:02<00:57,  3.62it/s][A
  6%|▌         | 13/221 [00:03<00:55,  3.76it/s][A[h264 @ 0x556b30a22340] mmco: unref short failure
[h264 @ 0x556b30a22340] mmco: unref short failure

  6%|▋         | 14/221 [00:04<02:15,  1.53it/s][A
  7%|▋         | 15/221 [00:04<01:45,  1.94it/s][A
  7%|▋         | 16/221 [00:05<01:35,  2.15it/s][A
  8%|▊         | 17/221 [00:05<01:49,  1.86it/s][A
  8%|▊         | 18/221 [00:06<01:30,  2.24it/s][A
  9%|▊         | 19/221 [00:06<01:09,  2.92it/s][A
  9%|▉         | 20/221 [00:06<00:56,  3.57it/s][A
 10%|▉         | 21/221 [00:06<00:46,  4.27it/s][A
 10%|▉         | 22/221 [00:06<00:42,  4.74it/s][A
 11%|█         | 24/221 [00:06<00:30,  6.51it/s][A
 11%|█▏        | 25/221 [00:07<00:29,  6.55it/s][A
 12%|█▏        | 26/221 [00:07<00:46,  4.23it/s][A
 12%|█▏        | 27/221 [00:07<00:39,  4.89it/s][A
 13%|█▎        | 28/221 [00:08<00:52,  3.65it/s][A[h264 @ 0x55a0355b9500] mmco: unref short failure

 13%|█▎        | 29/221 [00:09<02:01,  1.58it/s][A
 14%|█▎        | 30/221 [00:09<01:35,  1.99it/s][A
 14%|█▍        | 31/221 [00:09<01:16,  2.48it/s][A
 15%|█▍        | 33/221 [00:10<00:53,  3.52it/s][A[h264 @ 0x562421b043c0] mmco: unref short failure

 15%|█▌        | 34/221 [00:10<00:51,  3.60it/s][A
 16%|█▌        | 35/221 [00:10<00:45,  4.05it/s][A
 16%|█▋        | 36/221 [00:10<00:42,  4.33it/s][A
 17%|█▋        | 37/221 [00:11<00:56,  3.24it/s][A
 17%|█▋        | 38/221 [00:11<00:56,  3.23it/s][A
 18%|█▊        | 39/221 [00:11<00:55,  3.27it/s][A
 18%|█▊        | 40/221 [00:12<00:53,  3.37it/s][A
 19%|█▊        | 41/221 [00:12<00:43,  4.18it/s][A
 19%|█▉        | 42/221 [00:12<00:44,  3.99it/s][A
 20%|█▉        | 44/221 [00:12<00:30,  5.73it/s][A
 20%|██        | 45/221 [00:13<00:53,  3.26it/s][A
 21%|██        | 46/221 [00:13<00:53,  3.30it/s][A
 21%|██▏       | 47/221 [00:14<01:02,  2.77it/s][A[h264 @ 0x556b2d574580] mmco: unref short failure
[h264 @ 0x556b2d574580] mmco: unref short failure

 22%|██▏       | 48/221 [00:14<00:54,  3.15it/s][A
 22%|██▏       | 49/221 [00:15<01:11,  2.40it/s][A[h264 @ 0x559becf3d980] mmco: unref short failure
[h264 @ 0x559becf3d980] mmco: unref short failure

 23%|██▎       | 50/221 [00:15<01:22,  2.07it/s][A
 24%|██▎       | 52/221 [00:16<00:56,  3.01it/s][A
 24%|██▍       | 53/221 [00:16<00:47,  3.52it/s][A
 24%|██▍       | 54/221 [00:17<01:14,  2.23it/s][A
 25%|██▍       | 55/221 [00:17<01:08,  2.41it/s][A
 25%|██▌       | 56/221 [00:17<01:02,  2.64it/s][A
 26%|██▌       | 57/221 [00:17<00:51,  3.19it/s][A
 26%|██▌       | 58/221 [00:18<00:41,  3.97it/s][A
 27%|██▋       | 59/221 [00:18<00:35,  4.55it/s][A
 27%|██▋       | 60/221 [00:18<00:41,  3.87it/s][A
 28%|██▊       | 61/221 [00:18<00:40,  3.98it/s][A
 28%|██▊       | 62/221 [00:19<00:38,  4.17it/s][A
 29%|██▊       | 63/221 [00:19<00:36,  4.38it/s][A
 29%|██▉       | 64/221 [00:19<00:30,  5.11it/s][A
 29%|██▉       | 65/221 [00:19<00:28,  5.52it/s][A
 30%|██▉       | 66/221 [00:19<00:34,  4.55it/s][A[h264 @ 0x55a03596d800] mmco: unref short failure
[h264 @ 0x55a03596d800] mmco: unref short failure

 30%|███       | 67/221 [00:20<00:40,  3.84it/s][A
 31%|███       | 68/221 [00:20<00:35,  4.36it/s][A
 31%|███       | 69/221 [00:20<00:48,  3.11it/s][A
 32%|███▏      | 70/221 [00:21<00:42,  3.55it/s][A
 32%|███▏      | 71/221 [00:21<01:07,  2.23it/s][A
 33%|███▎      | 72/221 [00:22<00:57,  2.59it/s][A
 33%|███▎      | 73/221 [00:22<00:52,  2.80it/s][A
 33%|███▎      | 74/221 [00:22<00:42,  3.43it/s][A
 34%|███▍      | 75/221 [00:22<00:43,  3.36it/s][A
 34%|███▍      | 76/221 [00:22<00:35,  4.09it/s][A
 35%|███▍      | 77/221 [00:23<00:30,  4.78it/s][A
 35%|███▌      | 78/221 [00:23<00:30,  4.64it/s][A
 36%|███▌      | 79/221 [00:23<00:40,  3.54it/s][A
 36%|███▌      | 80/221 [00:23<00:33,  4.25it/s][A[h264 @ 0x556b2ee573c0] mmco: unref short failure
[h264 @ 0x556b2ee573c0] mmco: unref short failure

 37%|███▋      | 81/221 [00:24<00:38,  3.68it/s][A
 37%|███▋      | 82/221 [00:25<01:19,  1.75it/s][A
 38%|███▊      | 83/221 [00:25<01:10,  1.95it/s][A
 38%|███▊      | 84/221 [00:26<00:54,  2.52it/s][A
 39%|███▉      | 86/221 [00:26<00:34,  3.88it/s][A
 39%|███▉      | 87/221 [00:26<00:40,  3.30it/s][A
 40%|███▉      | 88/221 [00:26<00:38,  3.48it/s][A
 40%|████      | 89/221 [00:28<01:42,  1.29it/s][A
 41%|████      | 90/221 [00:29<01:21,  1.61it/s][A
 42%|████▏     | 92/221 [00:29<00:52,  2.48it/s][A
 42%|████▏     | 93/221 [00:29<00:50,  2.53it/s][A
 43%|████▎     | 94/221 [00:30<00:44,  2.83it/s][A
 43%|████▎     | 95/221 [00:30<00:42,  2.99it/s][A
 43%|████▎     | 96/221 [00:30<00:37,  3.33it/s][A
 44%|████▍     | 97/221 [00:30<00:30,  4.02it/s][A
 44%|████▍     | 98/221 [00:30<00:27,  4.42it/s][A
 45%|████▌     | 100/221 [00:31<00:21,  5.70it/s][A
 46%|████▌     | 102/221 [00:31<00:20,  5.69it/s][A[h264 @ 0x55a03fe443c0] mmco: unref short failure
[h264 @ 0x55a03fe443c0] mmco: unref short failure
[h264 @ 0x55a03fe443c0] mmco: unref short failure

 47%|████▋     | 103/221 [00:31<00:20,  5.78it/s][A
 47%|████▋     | 104/221 [00:31<00:24,  4.84it/s][A
 48%|████▊     | 105/221 [00:32<00:26,  4.45it/s][A
 48%|████▊     | 106/221 [00:32<00:35,  3.20it/s][A
 48%|████▊     | 107/221 [00:32<00:29,  3.87it/s][A
 49%|████▉     | 108/221 [00:32<00:25,  4.48it/s][A
 49%|████▉     | 109/221 [00:33<00:23,  4.67it/s][A
 50%|████▉     | 110/221 [00:33<00:25,  4.33it/s][A
 50%|█████     | 111/221 [00:33<00:29,  3.74it/s][A
 51%|█████     | 112/221 [00:33<00:26,  4.10it/s][A
 51%|█████     | 113/221 [00:34<00:30,  3.56it/s][A[h264 @ 0x562423e01700] mmco: unref short failure

 52%|█████▏    | 115/221 [00:34<00:20,  5.15it/s][A[h264 @ 0x5624241f20c0] mmco: unref short failure

[h264 @ 0x559bea059e40] mmco: unref short failure
 52%|█████▏    | 116/221 [00:38<02:01,  1.16s/it][A[h264 @ 0x559bea059e40] mmco: unref short failure
[h264 @ 0x559bea059e40] mmco: unref short failure
[h264 @ 0x559bea059e40] mmco: unref short failure
[h264 @ 0x559bea059e40] mmco: unref short failure

 53%|█████▎    | 117/221 [00:38<01:37,  1.06it/s][A
 53%|█████▎    | 118/221 [00:39<01:19,  1.29it/s][A
 54%|█████▍    | 119/221 [00:39<01:00,  1.68it/s][A
 54%|█████▍    | 120/221 [00:39<00:50,  2.01it/s][A
 55%|█████▌    | 122/221 [00:39<00:33,  2.98it/s][A
 56%|█████▌    | 123/221 [00:40<00:27,  3.53it/s][A
 56%|█████▌    | 124/221 [00:40<00:24,  3.95it/s][A
 57%|█████▋    | 125/221 [00:40<00:24,  3.86it/s][A[h264 @ 0x56241d005c80] mmco: unref short failure
[h264 @ 0x56241d005c80] mmco: unref short failure

 57%|█████▋    | 126/221 [00:40<00:24,  3.88it/s][A[h264 @ 0x559beab81700] mmco: unref short failure
[h264 @ 0x559beab81700] mmco: unref short failure
[h264 @ 0x559beab81700] mmco: unref short failure
[h264 @ 0x559beab81700] mmco: unref short failure

 57%|█████▋    | 127/221 [00:41<00:27,  3.37it/s][A
 58%|█████▊    | 128/221 [00:41<00:27,  3.35it/s][A
 58%|█████▊    | 129/221 [00:41<00:24,  3.78it/s][A
 59%|█████▉    | 130/221 [00:41<00:22,  4.09it/s][A
 59%|█████▉    | 131/221 [00:41<00:18,  4.90it/s][A
 60%|█████▉    | 132/221 [00:42<00:17,  5.20it/s][A
 60%|██████    | 133/221 [00:42<00:22,  3.84it/s][A
 61%|██████    | 134/221 [00:42<00:20,  4.23it/s][A
 61%|██████    | 135/221 [00:42<00:19,  4.36it/s][A
 62%|██████▏   | 136/221 [00:43<00:23,  3.59it/s][A
 62%|██████▏   | 137/221 [00:43<00:21,  3.83it/s][A
 62%|██████▏   | 138/221 [00:43<00:24,  3.44it/s][A
 63%|██████▎   | 139/221 [00:44<00:24,  3.35it/s][A
 63%|██████▎   | 140/221 [00:44<00:25,  3.13it/s][A
 64%|██████▍   | 141/221 [00:44<00:22,  3.53it/s][A
 64%|██████▍   | 142/221 [00:45<00:24,  3.28it/s][A
 65%|██████▍   | 143/221 [00:45<00:26,  2.98it/s][A
 65%|██████▌   | 144/221 [00:45<00:22,  3.44it/s][A[h264 @ 0x556b35b69600] mmco: unref short failure

 66%|██████▌   | 146/221 [00:45<00:15,  4.81it/s][A
 67%|██████▋   | 147/221 [00:46<00:14,  5.26it/s][A
 67%|██████▋   | 148/221 [00:46<00:14,  5.17it/s][A
 67%|██████▋   | 149/221 [00:46<00:13,  5.35it/s][A
 68%|██████▊   | 150/221 [00:46<00:13,  5.37it/s][A
 68%|██████▊   | 151/221 [00:47<00:24,  2.90it/s][A
 69%|██████▉   | 152/221 [00:48<00:33,  2.05it/s][A[h264 @ 0x56241ac20480] mmco: unref short failure
[h264 @ 0x56241ac20480] mmco: unref short failure

 69%|██████▉   | 153/221 [00:48<00:29,  2.31it/s][A
 70%|██████▉   | 154/221 [00:48<00:27,  2.41it/s][A
 70%|███████   | 155/221 [00:48<00:21,  3.09it/s][A
 71%|███████   | 156/221 [00:49<00:17,  3.78it/s][A
 71%|███████   | 157/221 [00:50<00:41,  1.55it/s][A
 72%|███████▏  | 159/221 [00:50<00:25,  2.45it/s][A
 72%|███████▏  | 160/221 [00:51<00:21,  2.82it/s][A
 73%|███████▎  | 161/221 [00:51<00:21,  2.85it/s][A
 73%|███████▎  | 162/221 [00:52<00:26,  2.25it/s][A
 74%|███████▍  | 163/221 [00:52<00:21,  2.64it/s][A
 74%|███████▍  | 164/221 [00:53<00:29,  1.92it/s][A
 75%|███████▍  | 165/221 [00:53<00:24,  2.32it/s][A[h264 @ 0x562426fba640] mmco: unref short failure
[h264 @ 0x562426fba640] mmco: unref short failure

 75%|███████▌  | 166/221 [00:53<00:21,  2.54it/s][A
 76%|███████▌  | 167/221 [00:53<00:17,  3.13it/s][A[h264 @ 0x556b379e3fc0] mmco: unref short failure
[h264 @ 0x562422dd0e00] mmco: unref short failure

 76%|███████▌  | 168/221 [00:55<00:36,  1.45it/s][A
 76%|███████▋  | 169/221 [00:55<00:27,  1.89it/s][A
 77%|███████▋  | 170/221 [00:55<00:23,  2.15it/s][A
 77%|███████▋  | 171/221 [00:56<00:19,  2.58it/s][A
 78%|███████▊  | 172/221 [00:56<00:17,  2.82it/s][A
 78%|███████▊  | 173/221 [00:56<00:14,  3.33it/s][A
 79%|███████▊  | 174/221 [00:56<00:13,  3.43it/s][A
 79%|███████▉  | 175/221 [00:57<00:20,  2.26it/s][A
 80%|███████▉  | 176/221 [00:57<00:16,  2.65it/s][A[h264 @ 0x556b31eb8200] mmco: unref short failure
[h264 @ 0x556b31eb8200] mmco: unref short failure

 81%|████████  | 178/221 [00:58<00:12,  3.31it/s][A
 81%|████████  | 179/221 [00:58<00:14,  2.95it/s][A
 81%|████████▏ | 180/221 [00:58<00:11,  3.45it/s][A
 82%|████████▏ | 181/221 [00:59<00:10,  3.82it/s][A
 82%|████████▏ | 182/221 [00:59<00:09,  4.31it/s][A
 83%|████████▎ | 183/221 [00:59<00:08,  4.58it/s][A
 83%|████████▎ | 184/221 [00:59<00:08,  4.25it/s][A
 84%|████████▎ | 185/221 [00:59<00:08,  4.46it/s][A
 84%|████████▍ | 186/221 [01:00<00:08,  4.14it/s][A
 85%|████████▍ | 187/221 [01:00<00:07,  4.46it/s][A
 85%|████████▌ | 188/221 [01:00<00:08,  3.99it/s][A
 86%|████████▌ | 189/221 [01:01<00:10,  3.19it/s][A
 86%|████████▌ | 190/221 [01:01<00:09,  3.34it/s][A
 86%|████████▋ | 191/221 [01:01<00:07,  4.04it/s][A
 87%|████████▋ | 192/221 [01:01<00:06,  4.43it/s][A
 87%|████████▋ | 193/221 [01:01<00:05,  5.10it/s][A
 88%|████████▊ | 194/221 [01:02<00:08,  3.29it/s][A
 88%|████████▊ | 195/221 [01:02<00:06,  3.94it/s][A
 89%|████████▊ | 196/221 [01:03<00:09,  2.68it/s][A
 89%|████████▉ | 197/221 [01:03<00:07,  3.38it/s][A
 90%|████████▉ | 198/221 [01:03<00:06,  3.44it/s][A
 90%|█████████ | 199/221 [01:03<00:05,  4.02it/s][A
 90%|█████████ | 200/221 [01:04<00:05,  3.93it/s][A
 91%|█████████ | 201/221 [01:04<00:04,  4.14it/s][A[h264 @ 0x55a03305dc80] mmco: unref short failure

 91%|█████████▏| 202/221 [01:04<00:04,  4.57it/s][A
 92%|█████████▏| 203/221 [01:04<00:03,  5.19it/s][A
 92%|█████████▏| 204/221 [01:04<00:03,  4.47it/s][A[h264 @ 0x559beacbfa40] mmco: unref short failure
[h264 @ 0x559beacbfa40] mmco: unref short failure

 93%|█████████▎| 206/221 [01:05<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [01:05<00:03,  3.99it/s][A
 94%|█████████▍| 208/221 [01:05<00:02,  4.56it/s][A
 95%|█████████▍| 209/221 [01:05<00:02,  4.71it/s][A
 95%|█████████▌| 211/221 [01:06<00:02,  4.98it/s][A
 96%|█████████▌| 212/221 [01:06<00:01,  5.04it/s][A
 96%|█████████▋| 213/221 [01:06<00:01,  4.76it/s][A
 97%|█████████▋| 214/221 [01:07<00:01,  4.48it/s][A
 97%|█████████▋| 215/221 [01:07<00:01,  4.90it/s][A[h264 @ 0x556b3bea1940] mmco: unref short failure

 98%|█████████▊| 216/221 [01:07<00:01,  4.72it/s][A
not have audios ua_Kowav7hg.20
 98%|█████████▊| 217/221 [01:07<00:01,  3.95it/s][A
 99%|█████████▊| 218/221 [01:07<00:00,  4.28it/s][A
 99%|█████████▉| 219/221 [01:08<00:00,  4.50it/s][A
100%|█████████▉| 220/221 [01:12<00:01,  1.37s/it][A
100%|██████████| 221/221 [01:12<00:00,  1.01s/it][A100%|██████████| 221/221 [01:12<00:00,  3.05it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:57,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:51,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:22<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:19,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.78it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.78it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:51<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:57<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:34,  6.33it/s][A
  1%|          | 2/221 [00:00<00:52,  4.14it/s][A
  1%|▏         | 3/221 [00:00<00:58,  3.70it/s][A
  2%|▏         | 4/221 [00:00<00:49,  4.36it/s][A
  2%|▏         | 5/221 [00:01<00:45,  4.73it/s][A
  3%|▎         | 7/221 [00:01<00:40,  5.27it/s][A
  4%|▎         | 8/221 [00:01<00:48,  4.37it/s][A
  4%|▍         | 9/221 [00:01<00:47,  4.49it/s][A
  5%|▍         | 10/221 [00:02<01:04,  3.27it/s][A
  5%|▍         | 11/221 [00:02<00:59,  3.56it/s][A
  5%|▌         | 12/221 [00:02<00:50,  4.12it/s][A
  6%|▌         | 13/221 [00:03<01:25,  2.42it/s][A
  6%|▋         | 14/221 [00:03<01:07,  3.05it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.35it/s][A
  7%|▋         | 16/221 [00:04<01:06,  3.07it/s][A
  8%|▊         | 17/221 [00:05<01:28,  2.31it/s][A
  8%|▊         | 18/221 [00:05<01:15,  2.68it/s][A
  9%|▊         | 19/221 [00:05<01:03,  3.16it/s][A
  9%|▉         | 20/221 [00:05<00:50,  3.95it/s][A
 10%|▉         | 21/221 [00:05<00:44,  4.47it/s][A
 10%|▉         | 22/221 [00:05<00:42,  4.71it/s][A
 11%|█         | 24/221 [00:06<00:33,  5.95it/s][A
 11%|█▏        | 25/221 [00:06<00:34,  5.62it/s][A
 12%|█▏        | 26/221 [00:06<00:36,  5.29it/s][A
 12%|█▏        | 27/221 [00:06<00:33,  5.78it/s][A
 13%|█▎        | 28/221 [00:07<00:42,  4.56it/s][A
 13%|█▎        | 29/221 [00:07<00:42,  4.55it/s][A
 14%|█▎        | 30/221 [00:07<00:46,  4.07it/s][A
 14%|█▍        | 31/221 [00:07<00:44,  4.29it/s][A
 15%|█▍        | 33/221 [00:08<00:35,  5.33it/s][A
 15%|█▌        | 34/221 [00:08<00:35,  5.23it/s][A
 16%|█▌        | 35/221 [00:08<00:38,  4.81it/s][A
 16%|█▋        | 36/221 [00:08<00:40,  4.55it/s][A
 17%|█▋        | 37/221 [00:08<00:37,  4.91it/s][A
 17%|█▋        | 38/221 [00:09<00:40,  4.56it/s][A
 18%|█▊        | 39/221 [00:09<00:36,  4.93it/s][A
 18%|█▊        | 40/221 [00:09<00:46,  3.87it/s][A
 19%|█▊        | 41/221 [00:09<00:39,  4.58it/s][A
 19%|█▉        | 42/221 [00:10<00:38,  4.68it/s][A
 19%|█▉        | 43/221 [00:10<00:44,  4.00it/s][A
 20%|█▉        | 44/221 [00:10<00:43,  4.08it/s][A
 20%|██        | 45/221 [00:10<00:46,  3.82it/s][A
 21%|██        | 46/221 [00:11<00:40,  4.33it/s][A
 21%|██▏       | 47/221 [00:11<00:40,  4.29it/s][A
 22%|██▏       | 48/221 [00:11<00:36,  4.75it/s][A
 22%|██▏       | 49/221 [00:11<00:35,  4.90it/s][A
 23%|██▎       | 50/221 [00:12<00:45,  3.78it/s][A
 23%|██▎       | 51/221 [00:12<00:40,  4.21it/s][A
 24%|██▎       | 52/221 [00:12<00:41,  4.10it/s][A
 24%|██▍       | 53/221 [00:12<00:38,  4.34it/s][A
 24%|██▍       | 54/221 [00:13<00:55,  3.03it/s][A
 25%|██▍       | 55/221 [00:13<00:49,  3.33it/s][A
 25%|██▌       | 56/221 [00:13<00:42,  3.90it/s][A
 26%|██▌       | 57/221 [00:13<00:42,  3.87it/s][A
 26%|██▌       | 58/221 [00:14<00:47,  3.40it/s][A
 27%|██▋       | 59/221 [00:14<00:42,  3.77it/s][A
 27%|██▋       | 60/221 [00:14<00:40,  4.02it/s][A
 28%|██▊       | 61/221 [00:14<00:36,  4.41it/s][A
 28%|██▊       | 62/221 [00:15<00:38,  4.10it/s][A
 29%|██▊       | 63/221 [00:15<00:37,  4.23it/s][A
 29%|██▉       | 64/221 [00:15<00:47,  3.28it/s][A
 29%|██▉       | 65/221 [00:16<00:40,  3.81it/s][A
 30%|██▉       | 66/221 [00:16<00:52,  2.95it/s][A
 30%|███       | 67/221 [00:17<01:03,  2.42it/s][A
 31%|███       | 68/221 [00:17<00:51,  2.95it/s][A
 31%|███       | 69/221 [00:18<01:10,  2.15it/s][A
 32%|███▏      | 70/221 [00:18<00:54,  2.79it/s][A
 32%|███▏      | 71/221 [00:18<00:47,  3.18it/s][A
 33%|███▎      | 72/221 [00:18<00:51,  2.88it/s][A
 33%|███▎      | 73/221 [00:19<00:50,  2.93it/s][A
 33%|███▎      | 74/221 [00:19<00:40,  3.63it/s][A
 34%|███▍      | 75/221 [00:19<00:39,  3.69it/s][A
 34%|███▍      | 76/221 [00:19<00:36,  3.97it/s][A
 35%|███▍      | 77/221 [00:20<00:36,  3.99it/s][A
 35%|███▌      | 78/221 [00:20<00:35,  4.01it/s][A
 36%|███▌      | 79/221 [00:20<00:45,  3.11it/s][A
 36%|███▌      | 80/221 [00:20<00:40,  3.48it/s][A
 37%|███▋      | 81/221 [00:21<00:38,  3.68it/s][A
 37%|███▋      | 82/221 [00:21<00:39,  3.56it/s][A
 38%|███▊      | 83/221 [00:21<00:42,  3.22it/s][A
 38%|███▊      | 84/221 [00:22<00:40,  3.38it/s][A
 38%|███▊      | 85/221 [00:22<00:32,  4.13it/s][A
 39%|███▉      | 86/221 [00:22<00:36,  3.73it/s][A
 39%|███▉      | 87/221 [00:23<00:46,  2.85it/s][A
 40%|███▉      | 88/221 [00:23<00:53,  2.49it/s][A
 40%|████      | 89/221 [00:23<00:46,  2.81it/s][A
 41%|████      | 90/221 [00:24<00:49,  2.66it/s][A
 41%|████      | 91/221 [00:24<00:39,  3.31it/s][A
 42%|████▏     | 92/221 [00:24<00:41,  3.12it/s][A
 42%|████▏     | 93/221 [00:25<00:56,  2.27it/s][A
 43%|████▎     | 94/221 [00:25<00:49,  2.58it/s][A
 43%|████▎     | 95/221 [00:26<00:43,  2.87it/s][A
 43%|████▎     | 96/221 [00:26<00:37,  3.33it/s][A
 44%|████▍     | 97/221 [00:26<00:32,  3.76it/s][A
 44%|████▍     | 98/221 [00:26<00:31,  3.88it/s][A
 45%|████▍     | 99/221 [00:26<00:28,  4.31it/s][A
 45%|████▌     | 100/221 [00:27<00:28,  4.30it/s][A
 46%|████▌     | 101/221 [00:27<00:27,  4.30it/s][A
 46%|████▌     | 102/221 [00:28<00:47,  2.53it/s][A
 47%|████▋     | 103/221 [00:28<00:36,  3.20it/s][A
 47%|████▋     | 104/221 [00:28<00:32,  3.60it/s][A
 48%|████▊     | 105/221 [00:28<00:30,  3.78it/s][A
 48%|████▊     | 106/221 [00:29<00:39,  2.88it/s][A
 48%|████▊     | 107/221 [00:29<00:35,  3.20it/s][A
 49%|████▉     | 108/221 [00:29<00:33,  3.39it/s][A
 49%|████▉     | 109/221 [00:29<00:26,  4.20it/s][A
 50%|████▉     | 110/221 [00:29<00:26,  4.26it/s][A
 50%|█████     | 111/221 [00:30<00:26,  4.11it/s][A
 51%|█████     | 112/221 [00:30<00:26,  4.07it/s][A
 51%|█████     | 113/221 [00:30<00:23,  4.56it/s][A
 52%|█████▏    | 115/221 [00:30<00:19,  5.33it/s][A
 52%|█████▏    | 116/221 [00:31<00:21,  4.84it/s][A
 53%|█████▎    | 117/221 [00:31<00:22,  4.56it/s][A
 53%|█████▎    | 118/221 [00:31<00:22,  4.50it/s][A
 54%|█████▍    | 119/221 [00:32<00:28,  3.60it/s][A
 54%|█████▍    | 120/221 [00:32<00:25,  3.98it/s][A
 55%|█████▍    | 121/221 [00:32<00:21,  4.62it/s][A
 55%|█████▌    | 122/221 [00:32<00:22,  4.37it/s][A
 56%|█████▌    | 123/221 [00:32<00:23,  4.21it/s][A
 56%|█████▌    | 124/221 [00:33<00:22,  4.23it/s][A
 57%|█████▋    | 125/221 [00:33<00:26,  3.66it/s][A
 57%|█████▋    | 126/221 [00:33<00:24,  3.93it/s][A
 57%|█████▋    | 127/221 [00:34<00:30,  3.11it/s][A
 58%|█████▊    | 128/221 [00:34<00:27,  3.35it/s][A
 58%|█████▊    | 129/221 [00:34<00:22,  4.00it/s][A
 59%|█████▉    | 130/221 [00:34<00:23,  3.79it/s][A
 59%|█████▉    | 131/221 [00:35<00:19,  4.65it/s][A
 60%|█████▉    | 132/221 [00:35<00:21,  4.18it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.76it/s][A
 61%|██████    | 134/221 [00:36<00:27,  3.17it/s][A
 61%|██████    | 135/221 [00:36<00:28,  3.05it/s][A
 62%|██████▏   | 136/221 [00:36<00:25,  3.36it/s][A
 62%|██████▏   | 137/221 [00:36<00:21,  3.96it/s][A
 62%|██████▏   | 138/221 [00:37<00:22,  3.71it/s][A
 63%|██████▎   | 139/221 [00:37<00:29,  2.75it/s][A
 63%|██████▎   | 140/221 [00:38<00:27,  2.91it/s][A
 64%|██████▍   | 141/221 [00:38<00:23,  3.37it/s][A
 64%|██████▍   | 142/221 [00:38<00:21,  3.73it/s][A
 65%|██████▍   | 143/221 [00:39<00:29,  2.62it/s][A
 65%|██████▌   | 144/221 [00:39<00:30,  2.50it/s][A
 66%|██████▌   | 146/221 [00:39<00:18,  4.01it/s][A
 67%|██████▋   | 147/221 [00:39<00:19,  3.87it/s][A
 67%|██████▋   | 148/221 [00:40<00:24,  3.00it/s][A
 67%|██████▋   | 149/221 [00:40<00:23,  3.12it/s][A
 68%|██████▊   | 150/221 [00:40<00:20,  3.44it/s][A
 68%|██████▊   | 151/221 [00:41<00:23,  2.99it/s][A
 69%|██████▉   | 152/221 [00:42<00:35,  1.95it/s][A
 69%|██████▉   | 153/221 [00:42<00:27,  2.50it/s][A
 70%|██████▉   | 154/221 [00:42<00:22,  2.97it/s][A
 70%|███████   | 155/221 [00:42<00:19,  3.41it/s][A
 71%|███████   | 156/221 [00:43<00:21,  3.02it/s][A
 71%|███████   | 157/221 [00:43<00:20,  3.08it/s][A
 71%|███████▏  | 158/221 [00:43<00:19,  3.17it/s][A
 72%|███████▏  | 159/221 [00:43<00:15,  3.93it/s][A
 72%|███████▏  | 160/221 [00:44<00:14,  4.21it/s][A
 73%|███████▎  | 161/221 [00:44<00:15,  3.89it/s][A
 73%|███████▎  | 162/221 [00:44<00:13,  4.39it/s][A
 74%|███████▍  | 163/221 [00:44<00:13,  4.29it/s][A
 74%|███████▍  | 164/221 [00:45<00:11,  4.97it/s][A
 75%|███████▍  | 165/221 [00:45<00:11,  5.07it/s][A
 75%|███████▌  | 166/221 [00:45<00:11,  4.85it/s][A
 76%|███████▌  | 167/221 [00:45<00:09,  5.56it/s][A
 76%|███████▌  | 168/221 [00:45<00:10,  5.16it/s][A
 76%|███████▋  | 169/221 [00:45<00:09,  5.55it/s][A
 77%|███████▋  | 170/221 [00:46<00:14,  3.46it/s][A
 77%|███████▋  | 171/221 [00:46<00:13,  3.67it/s][A
 78%|███████▊  | 172/221 [00:46<00:12,  4.04it/s][A
 78%|███████▊  | 173/221 [00:47<00:13,  3.55it/s][A
 79%|███████▊  | 174/221 [00:47<00:17,  2.75it/s][A
 79%|███████▉  | 175/221 [00:48<00:16,  2.83it/s][A
 80%|███████▉  | 176/221 [00:48<00:14,  3.17it/s][A
 80%|████████  | 177/221 [00:48<00:12,  3.53it/s][A
 81%|████████  | 178/221 [00:48<00:12,  3.46it/s][A
 81%|████████  | 179/221 [00:49<00:11,  3.65it/s][A
 81%|████████▏ | 180/221 [00:49<00:09,  4.30it/s][A
 82%|████████▏ | 181/221 [00:49<00:09,  4.22it/s][A
 82%|████████▏ | 182/221 [00:49<00:11,  3.34it/s][A
 83%|████████▎ | 183/221 [00:50<00:12,  3.10it/s][A
 83%|████████▎ | 184/221 [00:50<00:11,  3.36it/s][A
 84%|████████▎ | 185/221 [00:50<00:09,  3.91it/s][A
 84%|████████▍ | 186/221 [00:51<00:10,  3.23it/s][A
 85%|████████▍ | 187/221 [00:51<00:09,  3.49it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.43it/s][A
 86%|████████▌ | 189/221 [00:51<00:08,  3.68it/s][A
 86%|████████▌ | 190/221 [00:52<00:09,  3.33it/s][A
 86%|████████▋ | 191/221 [00:52<00:07,  3.82it/s][A
 87%|████████▋ | 192/221 [00:52<00:07,  3.71it/s][A
 87%|████████▋ | 193/221 [00:52<00:06,  4.52it/s][A
 88%|████████▊ | 194/221 [00:53<00:06,  3.91it/s][A
 88%|████████▊ | 195/221 [00:53<00:06,  4.14it/s][A
 89%|████████▊ | 196/221 [00:53<00:08,  3.10it/s][A
 89%|████████▉ | 197/221 [00:54<00:07,  3.36it/s][A
 90%|████████▉ | 198/221 [00:54<00:08,  2.80it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.31it/s][A
 90%|█████████ | 200/221 [00:55<00:07,  2.67it/s][A
 91%|█████████ | 201/221 [00:55<00:06,  3.09it/s][A
 91%|█████████▏| 202/221 [00:55<00:06,  3.03it/s][A
 92%|█████████▏| 203/221 [00:56<00:05,  3.44it/s][A
 92%|█████████▏| 204/221 [00:56<00:05,  3.02it/s][A
 93%|█████████▎| 205/221 [00:56<00:04,  3.82it/s][A
 93%|█████████▎| 206/221 [00:57<00:04,  3.35it/s][A
 94%|█████████▎| 207/221 [00:57<00:03,  3.95it/s][A
 94%|█████████▍| 208/221 [00:57<00:03,  3.81it/s][A
 95%|█████████▍| 209/221 [00:57<00:03,  3.62it/s][A
 95%|█████████▌| 211/221 [00:58<00:02,  4.02it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  3.82it/s][A
 96%|█████████▋| 213/221 [00:58<00:01,  4.08it/s][A
 97%|█████████▋| 214/221 [00:59<00:02,  2.73it/s][A
 97%|█████████▋| 215/221 [00:59<00:01,  3.06it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.17it/s][A
 98%|█████████▊| 217/221 [01:00<00:01,  3.16it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.28it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.30it/s][A
100%|█████████▉| 220/221 [01:01<00:00,  3.61it/s][A
100%|██████████| 221/221 [01:01<00:00,  3.73it/s][A100%|██████████| 221/221 [01:01<00:00,  3.61it/s]
09/09/2024 21:25:43 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 799--===========

09/09/2024 21:25:43 - INFO - __main__ -   {'area_r1': 40.7, 'area_recall': '40.7/64.5/74.5', 'area_ravg': 59.9}
09/09/2024 21:25:43 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 799--===========

09/09/2024 21:25:43 - INFO - __main__ -   {'forward_r1': 36.9, 'forward_recall': '36.9/66.3/76.4', 'forward_ravg': 59.8}
09/09/2024 21:25:43 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 799--===========

09/09/2024 21:25:43 - INFO - __main__ -   {'area_video_r1': 39.6, 'area_video_recall': '39.6/67.8/77.5', 'area_video_ravg': 61.6}
09/09/2024 21:25:43 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/09/2024 21:25:43 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 21:25:43 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 799--===========

09/09/2024 21:25:43 - INFO - __main__ -   {'area_video_r1': 52.8, 'area_video_recall': '52.8/75.2/82.9', 'area_video_ravg': 70.3, 'area_video_back_r1': 49.1, 'area_video_back_recall': '49.1/74.5/81.4', 'area_video_back_ravg': 68.4}
09/09/2024 21:25:43 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/09/2024 21:25:43 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/09/2024 21:25:43 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 799--===========

09/09/2024 21:25:43 - INFO - __main__ -   {'video_r1': 43.1, 'video_recall': '43.1/71.3/81.8', 'video_ravg': 65.4}
09/09/2024 21:25:43 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 21:25:43 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 21:25:43 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 799--===========

09/09/2024 21:25:43 - INFO - __main__ -   {'video_r1': 52.3, 'video_recall': '52.3/75.1/82.8', 'video_ravg': 70.1}
09/09/2024 21:25:43 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/09/2024 21:25:43 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/09/2024 21:26:04 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.005764178466051817, 'loss_ret%tv%ta--finetune_area/loss_area': 1.085916519165039, 'loss_ret%tv%ta--finetune_area/total_loss': 1.091680645942688}
[h264 @ 0x55a033148100] mmco: unref short failure
[h264 @ 0x55a033148100] mmco: unref short failure
 41%|████      | 800/1945 [4:20:45<37:29:12, 117.86s/it] 41%|████      | 801/1945 [4:20:49<26:36:25, 83.73s/it] [h264 @ 0x556b2dd30240] mmco: unref short failure
[h264 @ 0x559beca27780] mmco: unref short failure
[h264 @ 0x559beca27780] mmco: unref short failure
 41%|████      | 802/1945 [4:20:54<19:03:10, 60.01s/it][h264 @ 0x556b31c2de00] mmco: unref short failure
[h264 @ 0x556b31c2de00] mmco: unref short failure
[h264 @ 0x56241ac35800] mmco: unref short failure
 41%|████▏     | 803/1945 [4:21:00<13:52:22, 43.73s/it] 41%|████▏     | 804/1945 [4:21:05<10:14:01, 32.29s/it][h264 @ 0x556b32968ec0] mmco: unref short failure
[h264 @ 0x556b32968ec0] mmco: unref short failure
 41%|████▏     | 805/1945 [4:21:11<7:41:42, 24.30s/it]  41%|████▏     | 806/1945 [4:21:18<6:03:39, 19.16s/it] 41%|████▏     | 807/1945 [4:21:26<5:01:12, 15.88s/it][h264 @ 0x55a03d284ec0] mmco: unref short failure
[h264 @ 0x56241cf18980] mmco: unref short failure
[h264 @ 0x56241cf18980] mmco: unref short failure
[h264 @ 0x556b2cdf5ec0] mmco: unref short failure
[h264 @ 0x55a04551b900] mmco: unref short failure
 42%|████▏     | 808/1945 [4:21:33<4:10:41, 13.23s/it][h264 @ 0x56242d08fb40] mmco: unref short failure
 42%|████▏     | 809/1945 [4:21:40<3:35:55, 11.40s/it][h264 @ 0x56242e572b80] mmco: unref short failure
[h264 @ 0x56242e572b80] mmco: unref short failure
[h264 @ 0x55a045a95740] mmco: unref short failure
[h264 @ 0x55a045a95740] mmco: unref short failure
[h264 @ 0x556b3df5d080] mmco: unref short failure
[h264 @ 0x559bf22f1900] mmco: unref short failure
 42%|████▏     | 810/1945 [4:21:47<3:10:31, 10.07s/it][h264 @ 0x556b322b9b40] mmco: unref short failure
[h264 @ 0x556b322b9b40] mmco: unref short failure
 42%|████▏     | 811/1945 [4:21:54<2:50:54,  9.04s/it][h264 @ 0x55a0425cdac0] mmco: unref short failure
[h264 @ 0x55a0425cdac0] mmco: unref short failure
[h264 @ 0x556b36390f40] mmco: unref short failure
[h264 @ 0x556b36390f40] mmco: unref short failure
 42%|████▏     | 812/1945 [4:22:02<2:44:07,  8.69s/it] 42%|████▏     | 813/1945 [4:22:09<2:36:14,  8.28s/it][h264 @ 0x55a036b6c3c0] mmco: unref short failure
[h264 @ 0x559bed824540] mmco: unref short failure
[h264 @ 0x55a03dd6f600] mmco: unref short failure
[h264 @ 0x55a03dd6f600] mmco: unref short failure
[h264 @ 0x55a03dd6f600] mmco: unref short failure
[h264 @ 0x55a03dd6f600] mmco: unref short failure
[h264 @ 0x55a03dd6f600] mmco: unref short failure
[h264 @ 0x55a03dd6f600] mmco: unref short failure
 42%|████▏     | 814/1945 [4:22:17<2:34:42,  8.21s/it] 42%|████▏     | 815/1945 [4:22:24<2:27:28,  7.83s/it] 42%|████▏     | 816/1945 [4:22:31<2:23:13,  7.61s/it][h264 @ 0x55a03639da80] mmco: unref short failure
[h264 @ 0x55a03639da80] mmco: unref short failure
[h264 @ 0x55a03639da80] mmco: unref short failure
[h264 @ 0x55a03639da80] mmco: unref short failure
[h264 @ 0x562423965440] mmco: unref short failure
[h264 @ 0x562423965440] mmco: unref short failure
[h264 @ 0x562426af7440] mmco: unref short failure
[h264 @ 0x562426af7440] mmco: unref short failure
 42%|████▏     | 817/1945 [4:22:39<2:24:29,  7.69s/it] 42%|████▏     | 818/1945 [4:22:47<2:27:19,  7.84s/it][h264 @ 0x559bf56c9240] mmco: unref short failure
 42%|████▏     | 819/1945 [4:23:01<2:57:08,  9.44s/it] 42%|████▏     | 820/1945 [4:23:08<2:44:19,  8.76s/it][h264 @ 0x556b30b83440] mmco: unref short failure
 42%|████▏     | 821/1945 [4:23:21<3:09:13, 10.10s/it][h264 @ 0x5624202b1400] mmco: unref short failure
[h264 @ 0x562426a16700] mmco: unref short failure
[h264 @ 0x562426a16700] mmco: unref short failure
 42%|████▏     | 822/1945 [4:23:28<2:54:13,  9.31s/it][h264 @ 0x559bf75c2780] mmco: unref short failure
[h264 @ 0x559bf75c2780] mmco: unref short failure
[h264 @ 0x559bf75c2780] mmco: unref short failure
[h264 @ 0x559bf75c2780] mmco: unref short failure
[h264 @ 0x562424029ec0] mmco: unref short failure
[h264 @ 0x562424029ec0] mmco: unref short failure
 42%|████▏     | 823/1945 [4:23:42<3:19:15, 10.66s/it][h264 @ 0x559bf896e940] mmco: unref short failure
[h264 @ 0x559bf896e940] mmco: unref short failure
[h264 @ 0x556b33b1d840] mmco: unref short failure
 42%|████▏     | 824/1945 [4:24:14<5:18:04, 17.02s/it][h264 @ 0x556b3f309840] mmco: unref short failure
[h264 @ 0x556b3f309840] mmco: unref short failure
[h264 @ 0x556b32f758c0] mmco: unref short failure
[h264 @ 0x556b32f758c0] mmco: unref short failure
[h264 @ 0x556b42fb0d80] mmco: unref short failure
[h264 @ 0x556b42fb0d80] mmco: unref short failure
[h264 @ 0x556b3e3f59c0] mmco: unref short failure
[h264 @ 0x55a034b2fdc0] mmco: unref short failure
[h264 @ 0x55a034b2fdc0] mmco: unref short failure
[h264 @ 0x559bfdd3c200] mmco: unref short failure
[h264 @ 0x559bfdd3c200] mmco: unref short failure
[h264 @ 0x559bfce896c0] mmco: unref short failure
[h264 @ 0x559bfce896c0] mmco: unref short failure
 42%|████▏     | 825/1945 [4:24:41<6:12:05, 19.93s/it][h264 @ 0x56241c169e40] mmco: unref short failure
[h264 @ 0x562421579d00] mmco: unref short failure
 42%|████▏     | 826/1945 [4:24:48<5:02:08, 16.20s/it][h264 @ 0x559bec5df4c0] mmco: unref short failure
[h264 @ 0x559bec5df4c0] mmco: unref short failure
[h264 @ 0x559bec5df4c0] mmco: unref short failure
[h264 @ 0x559bec5df4c0] mmco: unref short failure
[h264 @ 0x55a03bffed40] mmco: unref short failure
[h264 @ 0x55a03bffed40] mmco: unref short failure
[h264 @ 0x559bf64f2e00] mmco: unref short failure
[h264 @ 0x55a033d055c0] mmco: unref short failure
[h264 @ 0x55a033d055c0] mmco: unref short failure
[h264 @ 0x55a033d055c0] mmco: unref short failure
[h264 @ 0x55a033d055c0] mmco: unref short failure
 43%|████▎     | 827/1945 [4:25:02<4:47:01, 15.40s/it][h264 @ 0x556b345cff00] mmco: unref short failure
[h264 @ 0x556b345cff00] mmco: unref short failure
[h264 @ 0x55a03dcab100] mmco: unref short failure
[h264 @ 0x55a039a62d40] mmco: unref short failure
[h264 @ 0x55a039a62d40] mmco: unref short failure
 43%|████▎     | 828/1945 [4:25:10<4:08:18, 13.34s/it][h264 @ 0x559bea059c40] mmco: unref short failure
[h264 @ 0x559bea059c40] mmco: unref short failure
[h264 @ 0x556b325ad080] mmco: unref short failure
[h264 @ 0x556b325ad080] mmco: unref short failure
[h264 @ 0x556b38063c00] mmco: unref short failure
[h264 @ 0x559bf89620c0] mmco: unref short failure
[h264 @ 0x559bf89620c0] mmco: unref short failure
 43%|████▎     | 829/1945 [4:25:19<3:43:36, 12.02s/it] 43%|████▎     | 830/1945 [4:25:30<3:35:40, 11.61s/it][h264 @ 0x55a03e757640] mmco: unref short failure
[h264 @ 0x55a03e757640] mmco: unref short failure
[h264 @ 0x559bf9cef200] mmco: unref short failure
 43%|████▎     | 831/1945 [4:25:38<3:18:36, 10.70s/it][h264 @ 0x556b30df8a40] mmco: unref short failure
[h264 @ 0x556b30df8a40] mmco: unref short failure
[h264 @ 0x56241b50ee40] mmco: unref short failure
[h264 @ 0x56241b50ee40] mmco: unref short failure
[h264 @ 0x556b325e2f80] mmco: unref short failure
[h264 @ 0x556b325e2f80] mmco: unref short failure
[h264 @ 0x562421576740] mmco: unref short failure
[h264 @ 0x556b431daa40] mmco: unref short failure
[h264 @ 0x556b431daa40] mmco: unref short failure
[h264 @ 0x5624183c5140] mmco: unref short failure
[h264 @ 0x5624183c5140] mmco: unref short failure
[h264 @ 0x562426fba3c0] mmco: unref short failure
[h264 @ 0x562426fba3c0] mmco: unref short failure
[h264 @ 0x55a033153b40] mmco: unref short failure
[h264 @ 0x55a033153b40] mmco: unref short failure
[h264 @ 0x55a033153b40] mmco: unref short failure
[h264 @ 0x55a033153b40] mmco: unref short failure
 43%|████▎     | 832/1945 [4:26:15<5:44:37, 18.58s/it][h264 @ 0x55a0480b5280] mmco: unref short failure
[h264 @ 0x55a0480b5280] mmco: unref short failure
[h264 @ 0x56241665f900] mmco: unref short failure
[h264 @ 0x56241665f900] mmco: unref short failure
[h264 @ 0x55a0480b5280] mmco: unref short failure
[h264 @ 0x56241b53e440] mmco: unref short failure
[h264 @ 0x55a04ade6640] mmco: unref short failure
[h264 @ 0x55a04ade6640] mmco: unref short failure
[h264 @ 0x55a04ade6640] mmco: unref short failure
[h264 @ 0x55a04ade6640] mmco: unref short failure
 43%|████▎     | 833/1945 [4:26:42<6:28:48, 20.98s/it][h264 @ 0x562417ce9640] mmco: unref short failure
[h264 @ 0x562417ce9640] mmco: unref short failure
[h264 @ 0x562417ce9640] mmco: unref short failure
[h264 @ 0x562417ce9640] mmco: unref short failure
 43%|████▎     | 834/1945 [4:26:49<5:10:48, 16.79s/it] 43%|████▎     | 835/1945 [4:27:02<4:46:45, 15.50s/it][h264 @ 0x556b2da4b3c0] mmco: unref short failure
[h264 @ 0x56241b554740] mmco: unref short failure
[h264 @ 0x56241b554740] mmco: unref short failure
[h264 @ 0x56241b554740] mmco: unref short failure
[h264 @ 0x56241b554740] mmco: unref short failure
[h264 @ 0x55a03b1da300] mmco: unref short failure
[h264 @ 0x55a03b1da300] mmco: unref short failure
 43%|████▎     | 836/1945 [4:27:09<4:02:14, 13.11s/it] 43%|████▎     | 837/1945 [4:27:17<3:30:45, 11.41s/it][h264 @ 0x556b3f448b80] mmco: unref short failure
[h264 @ 0x556b3f448b80] mmco: unref short failure
[h264 @ 0x55a049b58940] mmco: unref short failure
[h264 @ 0x55a042622cc0] mmco: unref short failure
 43%|████▎     | 838/1945 [4:27:26<3:18:20, 10.75s/it][h264 @ 0x556b33371ac0] mmco: unref short failure
[h264 @ 0x559bfe8328c0] mmco: unref short failure
[h264 @ 0x559bfe8328c0] mmco: unref short failure
[h264 @ 0x562417cca940] mmco: unref short failure
[h264 @ 0x562417cca940] mmco: unref short failure
[h264 @ 0x559bfb74ce40] mmco: unref short failure
[h264 @ 0x559bfb74ce40] mmco: unref short failure
[h264 @ 0x559bfa31ddc0] mmco: unref short failure
[h264 @ 0x559bfa31ddc0] mmco: unref short failure
[h264 @ 0x562418c9d680] mmco: unref short failure
[h264 @ 0x562418c9d680] mmco: unref short failure
 43%|████▎     | 839/1945 [4:27:45<4:04:52, 13.28s/it][h264 @ 0x55a03f7df340] mmco: unref short failure
[h264 @ 0x56242d1702c0] mmco: unref short failure
[h264 @ 0x56242d1702c0] mmco: unref short failure
[h264 @ 0x56242742e880] mmco: unref short failure
[h264 @ 0x56242b234c00] mmco: unref short failure
[h264 @ 0x559becf3d700] mmco: unref short failure
[h264 @ 0x559bf9b97400] mmco: unref short failure
[h264 @ 0x559bf9b97400] mmco: unref short failure
[h264 @ 0x55a045396f00] mmco: unref short failure
[h264 @ 0x559bfe832d40] mmco: unref short failure
[h264 @ 0x559bfe832d40] mmco: unref short failure
 43%|████▎     | 840/1945 [4:28:14<5:31:44, 18.01s/it][h264 @ 0x55a036f3c780] mmco: unref short failure
[h264 @ 0x55a036f3c780] mmco: unref short failure
[h264 @ 0x559bf9f44340] mmco: unref short failure
[h264 @ 0x56241acd4980] mmco: unref short failure
[h264 @ 0x56241acd4980] mmco: unref short failure
[h264 @ 0x55a0417a2380] mmco: unref short failure
[h264 @ 0x55a0417a2380] mmco: unref short failure
[h264 @ 0x55a045450c40] mmco: unref short failure
[h264 @ 0x556b35b69600] mmco: unref short failure
[h264 @ 0x56242a9d8080] mmco: unref short failure
[h264 @ 0x559bf913b3c0] mmco: unref short failure
[h264 @ 0x559bf913b3c0] mmco: unref short failure
[h264 @ 0x55a037b48140] mmco: unref short failure
[h264 @ 0x55a037b48140] mmco: unref short failure
[h264 @ 0x55a037b48140] mmco: unref short failure
[h264 @ 0x559bf77e5a40] mmco: unref short failure
 43%|████▎     | 841/1945 [4:28:45<6:45:38, 22.05s/it][h264 @ 0x559bfcf9fd80] mmco: unref short failure
[h264 @ 0x559bfcf9fd80] mmco: unref short failure
[h264 @ 0x559bfcf9fd80] mmco: unref short failure
[h264 @ 0x559bfcf9fd80] mmco: unref short failure
 43%|████▎     | 842/1945 [4:28:52<5:22:05, 17.52s/it] 43%|████▎     | 843/1945 [4:29:01<4:33:03, 14.87s/it][h264 @ 0x559bf997d000] mmco: unref short failure
[h264 @ 0x559bf997d000] mmco: unref short failure
[h264 @ 0x559bf997d000] mmco: unref short failure
[h264 @ 0x559bf997d000] mmco: unref short failure
 43%|████▎     | 844/1945 [4:29:11<4:04:18, 13.31s/it][h264 @ 0x559bf4cb7d00] mmco: unref short failure
[h264 @ 0x559bf4cb7d00] mmco: unref short failure
[h264 @ 0x559beb9f27c0] mmco: unref short failure
[h264 @ 0x559bfce2ba00] mmco: unref short failure
 43%|████▎     | 845/1945 [4:29:29<4:31:57, 14.83s/it][h264 @ 0x55a03da781c0] mmco: unref short failure
[h264 @ 0x55a03da781c0] mmco: unref short failure
[h264 @ 0x55a03da781c0] mmco: unref short failure
[h264 @ 0x55a03da781c0] mmco: unref short failure
[h264 @ 0x55a049c262c0] mmco: unref short failure
[h264 @ 0x55a049c262c0] mmco: unref short failure
 43%|████▎     | 846/1945 [4:29:36<3:48:51, 12.49s/it][h264 @ 0x562423638780] mmco: unref short failure
 44%|████▎     | 847/1945 [4:29:44<3:21:46, 11.03s/it][h264 @ 0x55a033153fc0] mmco: unref short failure
[h264 @ 0x55a033153fc0] mmco: unref short failure
[h264 @ 0x559bfcfa0440] mmco: unref short failure
[h264 @ 0x559bfcfa0440] mmco: unref short failure
[h264 @ 0x559bfcfa0440] mmco: unref short failure
[h264 @ 0x559bf913b840] mmco: unref short failure
[h264 @ 0x55a043dca300] mmco: unref short failure
[h264 @ 0x55a043dca300] mmco: unref short failure
[h264 @ 0x55a043dca300] mmco: unref short failure
[h264 @ 0x55a043dca300] mmco: unref short failure
[h264 @ 0x556b429fd1c0] mmco: unref short failure
 44%|████▎     | 848/1945 [4:30:15<5:11:02, 17.01s/it][h264 @ 0x55a03d2850c0] mmco: unref short failure
[h264 @ 0x55a03d2850c0] mmco: unref short failure
[h264 @ 0x55a03d2850c0] mmco: unref short failure
[h264 @ 0x55a03d2850c0] mmco: unref short failure
[h264 @ 0x559bea1babc0] mmco: unref short failure
[h264 @ 0x559bea1babc0] mmco: unref short failure
[h264 @ 0x56241cc6cdc0] mmco: unref short failure
[h264 @ 0x56241cc6cdc0] mmco: unref short failure
[h264 @ 0x559bf642c5c0] mmco: unref short failure
[h264 @ 0x55a04b982180] mmco: unref short failure
[h264 @ 0x55a044e9d6c0] mmco: unref short failure
[h264 @ 0x559bfdb1f800] mmco: unref short failure
[h264 @ 0x559bfdb1f800] mmco: unref short failure
 44%|████▎     | 849/1945 [4:30:47<6:34:43, 21.61s/it]09/09/2024 21:36:09 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 21:36:09 - INFO - __main__ -   start running ret%tv validation...
[h264 @ 0x559c02f59a80] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559bf38e9600] mmco: unref short failure
[h264 @ 0x562418937cc0] mmco: unref short failure
[h264 @ 0x562418937cc0] mmco: unref short failure
[h264 @ 0x562418937cc0] mmco: unref short failure
[h264 @ 0x562418937cc0] mmco: unref short failure
[h264 @ 0x559c006d74c0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559c04a6b000] mmco: unref short failure
[h264 @ 0x559c04a6b000] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556b3c69a100] mmco: unref short failure
[h264 @ 0x556b3c69a100] mmco: unref short failure
[h264 @ 0x556b2dff4500] mmco: unref short failure
[h264 @ 0x55a04b663000] mmco: unref short failure
[h264 @ 0x55a04847c440] mmco: unref short failure
[h264 @ 0x5624321b3840] mmco: unref short failure
[h264 @ 0x5624321b3840] mmco: unref short failure
[h264 @ 0x559bf133d2c0] mmco: unref short failure
[h264 @ 0x559bfdb1f340] mmco: unref short failure
[h264 @ 0x559bfdb1f340] mmco: unref short failure
[h264 @ 0x559bee8ecdc0] mmco: unref short failure
[h264 @ 0x562431d1b640] mmco: unref short failure
[h264 @ 0x56242d809740] mmco: unref short failure
[h264 @ 0x56242d809740] mmco: unref short failure
[h264 @ 0x556b2d4a99c0] mmco: unref short failure
[h264 @ 0x556b2d4a99c0] mmco: unref short failure
[h264 @ 0x559c00976880] mmco: unref short failure
[h264 @ 0x559c00976880] mmco: unref short failure
[h264 @ 0x56242a9ad940] mmco: unref short failure
[h264 @ 0x56242a9ad940] mmco: unref short failure
[h264 @ 0x56242a9ad940] mmco: unref short failure
[h264 @ 0x56242a9ad940] mmco: unref short failure
[h264 @ 0x556b46e34e40] mmco: unref short failure
[h264 @ 0x556b46e34e40] mmco: unref short failure
[h264 @ 0x562426a77940] mmco: unref short failure
[h264 @ 0x562426a77940] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A[h264 @ 0x559bfe7b88c0] mmco: unref short failure

  0%|          | 1/221 [00:00<01:34,  2.34it/s][A
  1%|          | 2/221 [00:00<01:27,  2.50it/s][A
  1%|▏         | 3/221 [00:00<01:03,  3.44it/s][A
  2%|▏         | 4/221 [00:01<00:52,  4.16it/s][A
  2%|▏         | 5/221 [00:01<00:43,  4.93it/s][A
  3%|▎         | 6/221 [00:01<00:37,  5.79it/s][A
  3%|▎         | 7/221 [00:01<00:49,  4.37it/s][A
  4%|▎         | 8/221 [00:02<01:08,  3.10it/s][A
  4%|▍         | 9/221 [00:02<00:57,  3.70it/s][A
  5%|▍         | 10/221 [00:02<00:57,  3.65it/s][A
  5%|▍         | 11/221 [00:02<00:47,  4.39it/s][A
  5%|▌         | 12/221 [00:03<01:11,  2.93it/s][A
  6%|▌         | 13/221 [00:03<01:06,  3.13it/s][A
  6%|▋         | 14/221 [00:04<01:45,  1.97it/s][A
  7%|▋         | 15/221 [00:04<01:32,  2.23it/s][A
  7%|▋         | 16/221 [00:05<01:24,  2.42it/s][A
  8%|▊         | 17/221 [00:06<01:44,  1.95it/s][A
  8%|▊         | 18/221 [00:06<01:30,  2.24it/s][A
  9%|▊         | 19/221 [00:06<01:13,  2.76it/s][A
  9%|▉         | 20/221 [00:06<01:00,  3.34it/s][A
 10%|▉         | 21/221 [00:06<00:50,  3.93it/s][A
 10%|▉         | 22/221 [00:06<00:46,  4.31it/s][A
 10%|█         | 23/221 [00:07<00:41,  4.82it/s][A
 11%|█         | 24/221 [00:07<00:37,  5.22it/s][A
 11%|█▏        | 25/221 [00:07<00:35,  5.45it/s][A
 12%|█▏        | 26/221 [00:07<00:52,  3.70it/s][A[h264 @ 0x559bfd8eac80] mmco: unref short failure
[h264 @ 0x559bfd8eac80] mmco: unref short failure

 12%|█▏        | 27/221 [00:08<01:08,  2.82it/s][A
 13%|█▎        | 28/221 [00:08<01:09,  2.76it/s][A
 13%|█▎        | 29/221 [00:10<01:59,  1.61it/s][A[h264 @ 0x56242d5514c0] mmco: unref short failure
[h264 @ 0x56242d5514c0] mmco: unref short failure
[h264 @ 0x56242d5514c0] mmco: unref short failure

 14%|█▎        | 30/221 [00:10<01:45,  1.81it/s][A
 14%|█▍        | 31/221 [00:10<01:23,  2.27it/s][A
 14%|█▍        | 32/221 [00:10<01:04,  2.94it/s][A
 15%|█▍        | 33/221 [00:10<00:56,  3.33it/s][A
 15%|█▌        | 34/221 [00:11<00:53,  3.47it/s][A
 16%|█▌        | 35/221 [00:11<00:47,  3.95it/s][A
 16%|█▋        | 36/221 [00:11<00:43,  4.27it/s][A
 17%|█▋        | 37/221 [00:12<01:00,  3.03it/s][A
 17%|█▋        | 38/221 [00:12<01:00,  3.02it/s][A[h264 @ 0x556b3e6ff480] mmco: unref short failure
[h264 @ 0x556b3e6ff480] mmco: unref short failure

 18%|█▊        | 39/221 [00:12<00:58,  3.11it/s][A
 18%|█▊        | 40/221 [00:13<00:59,  3.05it/s][A
 19%|█▊        | 41/221 [00:13<00:51,  3.52it/s][A
 19%|█▉        | 42/221 [00:13<00:51,  3.46it/s][A
 19%|█▉        | 43/221 [00:13<00:46,  3.81it/s][A
 20%|█▉        | 44/221 [00:13<00:43,  4.07it/s][A
 20%|██        | 45/221 [00:14<01:20,  2.18it/s][A
 21%|██        | 46/221 [00:15<01:08,  2.55it/s][A
 21%|██▏       | 47/221 [00:15<01:22,  2.10it/s][A
 22%|██▏       | 49/221 [00:16<01:08,  2.50it/s][A
 23%|██▎       | 50/221 [00:17<01:16,  2.24it/s][A
 23%|██▎       | 51/221 [00:17<01:05,  2.59it/s][A[h264 @ 0x56241ca83c80] mmco: unref short failure
[h264 @ 0x56241ca83c80] mmco: unref short failure

 24%|██▎       | 52/221 [00:17<00:59,  2.86it/s][A
 24%|██▍       | 53/221 [00:17<00:48,  3.46it/s][A
 24%|██▍       | 54/221 [00:18<01:16,  2.18it/s][A
 25%|██▍       | 55/221 [00:18<01:05,  2.55it/s][A
 25%|██▌       | 56/221 [00:19<00:56,  2.91it/s][A
 26%|██▌       | 57/221 [00:19<00:53,  3.09it/s][A
 26%|██▌       | 58/221 [00:19<00:42,  3.83it/s][A
 27%|██▋       | 59/221 [00:19<00:37,  4.37it/s][A
 27%|██▋       | 60/221 [00:19<00:44,  3.60it/s][A
 28%|██▊       | 61/221 [00:20<00:39,  4.05it/s][A
 28%|██▊       | 62/221 [00:20<00:37,  4.24it/s][A
 29%|██▊       | 63/221 [00:20<00:34,  4.53it/s][A
 29%|██▉       | 64/221 [00:20<00:29,  5.24it/s][A
 29%|██▉       | 65/221 [00:20<00:25,  6.09it/s][A
 30%|██▉       | 66/221 [00:21<00:34,  4.46it/s][A
 30%|███       | 67/221 [00:21<00:38,  4.02it/s][A
 31%|███       | 68/221 [00:21<00:33,  4.60it/s][A
 31%|███       | 69/221 [00:22<00:45,  3.33it/s][A
 32%|███▏      | 70/221 [00:22<00:42,  3.58it/s][A[h264 @ 0x556b3bf0d480] mmco: unref short failure

 32%|███▏      | 71/221 [00:22<01:02,  2.40it/s][A
 33%|███▎      | 72/221 [00:23<00:52,  2.86it/s][A
 33%|███▎      | 73/221 [00:23<00:49,  3.02it/s][A
 33%|███▎      | 74/221 [00:23<00:41,  3.54it/s][A
 34%|███▍      | 75/221 [00:23<00:42,  3.43it/s][A
 34%|███▍      | 76/221 [00:24<00:35,  4.07it/s][A
 35%|███▍      | 77/221 [00:24<00:33,  4.34it/s][A
 35%|███▌      | 78/221 [00:24<00:34,  4.17it/s][A
 36%|███▌      | 79/221 [00:25<00:49,  2.87it/s][A
 36%|███▌      | 80/221 [00:25<00:45,  3.10it/s][A
 37%|███▋      | 81/221 [00:25<00:39,  3.54it/s][A[h264 @ 0x559c0341b5c0] mmco: unref short failure
[h264 @ 0x559c0341b5c0] mmco: unref short failure

 37%|███▋      | 82/221 [00:27<01:25,  1.62it/s][A
 38%|███▊      | 83/221 [00:27<01:13,  1.89it/s][A
 38%|███▊      | 85/221 [00:27<00:46,  2.95it/s][A
 39%|███▉      | 86/221 [00:27<00:38,  3.47it/s][A
 39%|███▉      | 87/221 [00:28<00:42,  3.17it/s][A
 40%|███▉      | 88/221 [00:28<00:37,  3.51it/s][A[h264 @ 0x5624249ed800] mmco: unref short failure

 40%|████      | 89/221 [00:30<01:35,  1.39it/s][A
 41%|████      | 90/221 [00:30<01:15,  1.74it/s][A
 42%|████▏     | 92/221 [00:30<00:48,  2.68it/s][A
 42%|████▏     | 93/221 [00:31<00:50,  2.55it/s][A
 43%|████▎     | 94/221 [00:31<00:46,  2.75it/s][A
 43%|████▎     | 95/221 [00:31<00:41,  3.06it/s][A
 43%|████▎     | 96/221 [00:31<00:36,  3.46it/s][A
 44%|████▍     | 97/221 [00:31<00:29,  4.19it/s][A
 44%|████▍     | 98/221 [00:32<00:29,  4.11it/s][A
 45%|████▍     | 99/221 [00:32<00:25,  4.84it/s][A
 45%|████▌     | 100/221 [00:32<00:22,  5.43it/s][A
 46%|████▌     | 102/221 [00:32<00:22,  5.31it/s][A
 47%|████▋     | 103/221 [00:32<00:19,  5.93it/s][A
 48%|████▊     | 105/221 [00:33<00:19,  5.98it/s][A
 48%|████▊     | 106/221 [00:33<00:28,  4.02it/s][A
 48%|████▊     | 107/221 [00:33<00:28,  4.06it/s][A
 49%|████▉     | 108/221 [00:34<00:26,  4.33it/s][A
 49%|████▉     | 109/221 [00:34<00:23,  4.82it/s][A
 50%|████▉     | 110/221 [00:34<00:20,  5.44it/s][A
 50%|█████     | 111/221 [00:34<00:25,  4.24it/s][A
 51%|█████     | 112/221 [00:34<00:22,  4.78it/s][A
 51%|█████     | 113/221 [00:35<00:25,  4.22it/s][A
 52%|█████▏    | 115/221 [00:35<00:16,  6.36it/s][A
 52%|█████▏    | 116/221 [00:39<01:51,  1.06s/it][A
 53%|█████▎    | 117/221 [00:39<01:29,  1.16it/s][A
 53%|█████▎    | 118/221 [00:39<01:12,  1.41it/s][A
 54%|█████▍    | 119/221 [00:39<00:55,  1.85it/s][A
 54%|█████▍    | 120/221 [00:40<00:46,  2.19it/s][A
 55%|█████▌    | 122/221 [00:40<00:29,  3.34it/s][A
 56%|█████▌    | 123/221 [00:40<00:25,  3.78it/s][A
 56%|█████▌    | 124/221 [00:40<00:23,  4.07it/s][A
 57%|█████▋    | 125/221 [00:40<00:25,  3.82it/s][A[h264 @ 0x556b43210f80] mmco: unref short failure
[h264 @ 0x556b43210f80] mmco: unref short failure
[h264 @ 0x556b43210f80] mmco: unref short failure
[h264 @ 0x556b43210f80] mmco: unref short failure

 57%|█████▋    | 126/221 [00:41<00:25,  3.75it/s][A
 57%|█████▋    | 127/221 [00:41<00:27,  3.39it/s][A
 58%|█████▊    | 128/221 [00:41<00:28,  3.27it/s][A
 58%|█████▊    | 129/221 [00:42<00:23,  3.84it/s][A
 59%|█████▉    | 130/221 [00:42<00:21,  4.32it/s][A
 60%|█████▉    | 132/221 [00:42<00:14,  5.98it/s][A
 60%|██████    | 133/221 [00:42<00:18,  4.81it/s][A
 61%|██████    | 134/221 [00:43<00:17,  4.87it/s][A
 61%|██████    | 135/221 [00:43<00:21,  4.06it/s][A
 62%|██████▏   | 136/221 [00:43<00:23,  3.57it/s][A
 62%|██████▏   | 137/221 [00:43<00:21,  4.00it/s][A
 62%|██████▏   | 138/221 [00:44<00:24,  3.33it/s][A
 63%|██████▎   | 139/221 [00:44<00:24,  3.36it/s][A
 63%|██████▎   | 140/221 [00:44<00:23,  3.49it/s][A
 64%|██████▍   | 141/221 [00:45<00:20,  3.81it/s][A
 64%|██████▍   | 142/221 [00:45<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:45<00:23,  3.31it/s][A
 65%|██████▌   | 144/221 [00:45<00:19,  3.98it/s][A
 66%|██████▌   | 146/221 [00:46<00:12,  6.06it/s][A
 67%|██████▋   | 147/221 [00:46<00:11,  6.33it/s][A
 67%|██████▋   | 148/221 [00:46<00:12,  5.64it/s][A
 67%|██████▋   | 149/221 [00:46<00:11,  6.34it/s][A
 68%|██████▊   | 150/221 [00:46<00:10,  6.70it/s][A
 68%|██████▊   | 151/221 [00:47<00:20,  3.47it/s][A
 69%|██████▉   | 152/221 [00:48<00:30,  2.30it/s][A
 69%|██████▉   | 153/221 [00:48<00:26,  2.58it/s][A
 70%|██████▉   | 154/221 [00:48<00:25,  2.65it/s][A
 70%|███████   | 155/221 [00:48<00:19,  3.38it/s][A
 71%|███████   | 156/221 [00:48<00:15,  4.15it/s][A
 71%|███████   | 157/221 [00:50<00:45,  1.41it/s][A
 71%|███████▏  | 158/221 [00:50<00:33,  1.87it/s][A
 72%|███████▏  | 159/221 [00:50<00:25,  2.42it/s][A
 72%|███████▏  | 160/221 [00:51<00:20,  3.00it/s][A[h264 @ 0x55a04cd1d9c0] mmco: unref short failure

 73%|███████▎  | 162/221 [00:52<00:23,  2.48it/s][A
 74%|███████▍  | 163/221 [00:52<00:20,  2.82it/s][A
 74%|███████▍  | 164/221 [00:53<00:26,  2.12it/s][A
 75%|███████▌  | 166/221 [00:53<00:19,  2.79it/s][A
 76%|███████▌  | 167/221 [00:53<00:16,  3.18it/s][A[h264 @ 0x56241ec12cc0] mmco: unref short failure
[h264 @ 0x559c007c5c40] mmco: unref short failure
[h264 @ 0x559c007c5c40] mmco: unref short failure

 76%|███████▌  | 168/221 [00:56<00:55,  1.05s/it][A
 76%|███████▋  | 169/221 [00:57<00:41,  1.24it/s][A
 77%|███████▋  | 170/221 [00:57<00:34,  1.50it/s][A
 77%|███████▋  | 171/221 [00:57<00:25,  1.95it/s][A
 78%|███████▊  | 172/221 [00:57<00:20,  2.34it/s][A
 79%|███████▊  | 174/221 [00:57<00:13,  3.45it/s][A
 79%|███████▉  | 175/221 [00:58<00:17,  2.65it/s][A
 80%|███████▉  | 176/221 [00:58<00:14,  3.03it/s][A
 81%|████████  | 178/221 [00:59<00:11,  3.89it/s][A
 81%|████████  | 179/221 [00:59<00:12,  3.28it/s][A
 82%|████████▏ | 181/221 [00:59<00:09,  4.31it/s][A
 82%|████████▏ | 182/221 [00:59<00:08,  4.70it/s][A
 83%|████████▎ | 183/221 [01:00<00:07,  4.89it/s][A
 83%|████████▎ | 184/221 [01:00<00:08,  4.61it/s][A
 84%|████████▎ | 185/221 [01:00<00:06,  5.31it/s][A
 84%|████████▍ | 186/221 [01:00<00:07,  4.79it/s][A
 85%|████████▌ | 188/221 [01:01<00:06,  5.30it/s][A
 86%|████████▌ | 189/221 [01:01<00:09,  3.28it/s][A
 86%|████████▌ | 190/221 [01:01<00:08,  3.46it/s][A
 87%|████████▋ | 192/221 [01:02<00:06,  4.74it/s][A[h264 @ 0x55a034e17880] mmco: unref short failure
[h264 @ 0x55a034e17880] mmco: unref short failure

 88%|████████▊ | 194/221 [01:02<00:06,  4.28it/s][A
 89%|████████▊ | 196/221 [01:03<00:06,  4.12it/s][A
 90%|████████▉ | 198/221 [01:03<00:04,  4.72it/s][A
 90%|█████████ | 199/221 [01:03<00:04,  5.23it/s][A
 90%|█████████ | 200/221 [01:03<00:04,  4.82it/s][A
 91%|█████████ | 201/221 [01:04<00:03,  5.01it/s][A
 91%|█████████▏| 202/221 [01:04<00:03,  5.42it/s][A
 92%|█████████▏| 204/221 [01:04<00:02,  5.91it/s][A
 93%|█████████▎| 206/221 [01:05<00:03,  4.74it/s][A
 94%|█████████▎| 207/221 [01:05<00:02,  4.88it/s][A
 94%|█████████▍| 208/221 [01:05<00:02,  5.20it/s][A
 95%|█████████▍| 209/221 [01:05<00:02,  5.54it/s][A
 95%|█████████▌| 211/221 [01:05<00:01,  5.77it/s][A
 96%|█████████▌| 212/221 [01:05<00:01,  6.36it/s][A
 96%|█████████▋| 213/221 [01:06<00:01,  5.60it/s][A
 97%|█████████▋| 214/221 [01:06<00:01,  5.01it/s][A
 97%|█████████▋| 215/221 [01:06<00:01,  5.27it/s][A
 98%|█████████▊| 216/221 [01:06<00:00,  5.11it/s][A
 98%|█████████▊| 217/221 [01:07<00:00,  4.04it/s][A
 99%|█████████▊| 218/221 [01:07<00:00,  4.75it/s][A
 99%|█████████▉| 219/221 [01:07<00:00,  5.08it/s][A[h264 @ 0x55a03b578dc0] mmco: unref short failure
[h264 @ 0x556b4471af40] mmco: unref short failure
[h264 @ 0x556b4471af40] mmco: unref short failure

100%|█████████▉| 220/221 [01:11<00:01,  1.37s/it][A100%|██████████| 221/221 [01:11<00:00,  3.08it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:51,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:22<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:23,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:37<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:51<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:29,  7.41it/s][A
  1%|          | 2/221 [00:00<00:49,  4.41it/s][A
  1%|▏         | 3/221 [00:00<00:53,  4.10it/s][A
  2%|▏         | 4/221 [00:00<00:45,  4.79it/s][A
  2%|▏         | 5/221 [00:01<00:43,  4.99it/s][A
  3%|▎         | 7/221 [00:01<00:39,  5.45it/s][A
  4%|▎         | 8/221 [00:01<00:46,  4.58it/s][A
  4%|▍         | 9/221 [00:01<00:45,  4.63it/s][A
  5%|▍         | 10/221 [00:02<01:02,  3.36it/s][A
  5%|▍         | 11/221 [00:02<00:56,  3.70it/s][A
  5%|▌         | 12/221 [00:02<00:49,  4.26it/s][A
  6%|▌         | 13/221 [00:03<01:21,  2.55it/s][A
  6%|▋         | 14/221 [00:03<01:06,  3.11it/s][A
  7%|▋         | 15/221 [00:03<00:59,  3.47it/s][A
  7%|▋         | 16/221 [00:04<01:02,  3.28it/s][A
  8%|▊         | 17/221 [00:05<01:35,  2.14it/s][A
  8%|▊         | 18/221 [00:05<01:20,  2.53it/s][A
  9%|▊         | 19/221 [00:05<01:07,  3.00it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.77it/s][A
 10%|▉         | 21/221 [00:05<00:46,  4.34it/s][A
 10%|▉         | 22/221 [00:05<00:44,  4.46it/s][A
 11%|█         | 24/221 [00:06<00:36,  5.45it/s][A
 11%|█▏        | 25/221 [00:06<00:35,  5.51it/s][A
 12%|█▏        | 26/221 [00:06<00:38,  5.01it/s][A
 12%|█▏        | 27/221 [00:06<00:34,  5.64it/s][A
 13%|█▎        | 28/221 [00:07<00:44,  4.38it/s][A
 13%|█▎        | 29/221 [00:07<00:43,  4.45it/s][A
 14%|█▎        | 30/221 [00:07<00:47,  4.02it/s][A
 14%|█▍        | 31/221 [00:07<00:45,  4.21it/s][A
 15%|█▍        | 33/221 [00:08<00:35,  5.30it/s][A
 15%|█▌        | 34/221 [00:08<00:36,  5.13it/s][A
 16%|█▌        | 35/221 [00:08<00:41,  4.50it/s][A
 16%|█▋        | 36/221 [00:08<00:44,  4.13it/s][A
 17%|█▋        | 37/221 [00:09<00:41,  4.41it/s][A
 17%|█▋        | 38/221 [00:09<00:45,  4.03it/s][A
 18%|█▊        | 39/221 [00:09<00:40,  4.45it/s][A
 18%|█▊        | 40/221 [00:09<00:48,  3.75it/s][A
 19%|█▊        | 41/221 [00:10<00:41,  4.32it/s][A
 19%|█▉        | 42/221 [00:10<00:38,  4.62it/s][A
 19%|█▉        | 43/221 [00:10<00:44,  3.97it/s][A
 20%|█▉        | 44/221 [00:10<00:44,  3.99it/s][A
 20%|██        | 45/221 [00:11<00:48,  3.66it/s][A
 21%|██        | 46/221 [00:11<00:39,  4.46it/s][A
 21%|██▏       | 47/221 [00:11<00:39,  4.37it/s][A
 22%|██▏       | 48/221 [00:11<00:35,  4.89it/s][A
 22%|██▏       | 49/221 [00:11<00:35,  4.81it/s][A
 23%|██▎       | 50/221 [00:12<00:48,  3.53it/s][A
 23%|██▎       | 51/221 [00:12<00:42,  3.96it/s][A
 24%|██▎       | 52/221 [00:12<00:44,  3.82it/s][A
 24%|██▍       | 53/221 [00:12<00:39,  4.29it/s][A
 24%|██▍       | 54/221 [00:13<00:54,  3.04it/s][A
 25%|██▍       | 55/221 [00:13<00:49,  3.35it/s][A
 25%|██▌       | 56/221 [00:13<00:40,  4.06it/s][A
 26%|██▌       | 57/221 [00:14<00:39,  4.16it/s][A
 26%|██▌       | 58/221 [00:14<00:46,  3.51it/s][A
 27%|██▋       | 59/221 [00:14<00:41,  3.91it/s][A
 27%|██▋       | 60/221 [00:14<00:36,  4.36it/s][A
 28%|██▊       | 61/221 [00:15<00:33,  4.81it/s][A
 28%|██▊       | 62/221 [00:15<00:35,  4.53it/s][A
 29%|██▊       | 63/221 [00:15<00:36,  4.38it/s][A
 29%|██▉       | 64/221 [00:15<00:41,  3.78it/s][A
 29%|██▉       | 65/221 [00:16<00:36,  4.22it/s][A
 30%|██▉       | 66/221 [00:16<00:44,  3.45it/s][A
 30%|███       | 67/221 [00:16<00:53,  2.85it/s][A
 31%|███       | 68/221 [00:17<00:46,  3.27it/s][A
 31%|███       | 69/221 [00:18<01:11,  2.12it/s][A
 32%|███▏      | 70/221 [00:18<00:58,  2.60it/s][A
 32%|███▏      | 71/221 [00:18<00:49,  3.02it/s][A
 33%|███▎      | 72/221 [00:18<00:54,  2.71it/s][A
 33%|███▎      | 73/221 [00:19<00:54,  2.73it/s][A
 33%|███▎      | 74/221 [00:19<00:43,  3.36it/s][A
 34%|███▍      | 75/221 [00:19<00:41,  3.50it/s][A
 34%|███▍      | 76/221 [00:19<00:38,  3.81it/s][A
 35%|███▍      | 77/221 [00:20<00:38,  3.71it/s][A
 35%|███▌      | 78/221 [00:20<00:34,  4.09it/s][A
 36%|███▌      | 79/221 [00:20<00:45,  3.09it/s][A
 36%|███▌      | 80/221 [00:21<00:40,  3.46it/s][A
 37%|███▋      | 81/221 [00:21<00:37,  3.68it/s][A
 37%|███▋      | 82/221 [00:21<00:40,  3.43it/s][A
 38%|███▊      | 83/221 [00:21<00:42,  3.25it/s][A
 38%|███▊      | 84/221 [00:22<00:39,  3.49it/s][A
 38%|███▊      | 85/221 [00:22<00:32,  4.20it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.77it/s][A
 39%|███▉      | 87/221 [00:23<00:45,  2.94it/s][A
 40%|███▉      | 88/221 [00:23<00:50,  2.64it/s][A
 40%|████      | 89/221 [00:23<00:45,  2.91it/s][A
 41%|████      | 90/221 [00:24<00:47,  2.74it/s][A
 41%|████      | 91/221 [00:24<00:39,  3.31it/s][A
 42%|████▏     | 92/221 [00:24<00:41,  3.12it/s][A
 42%|████▏     | 93/221 [00:25<00:55,  2.30it/s][A
 43%|████▎     | 94/221 [00:25<00:49,  2.58it/s][A
 43%|████▎     | 95/221 [00:26<00:43,  2.91it/s][A
 43%|████▎     | 96/221 [00:26<00:38,  3.23it/s][A
 44%|████▍     | 97/221 [00:26<00:34,  3.61it/s][A
 44%|████▍     | 98/221 [00:26<00:33,  3.71it/s][A
 45%|████▍     | 99/221 [00:26<00:29,  4.12it/s][A
 45%|████▌     | 100/221 [00:27<00:28,  4.18it/s][A
 46%|████▌     | 101/221 [00:27<00:27,  4.29it/s][A
 46%|████▌     | 102/221 [00:28<00:44,  2.67it/s][A
 47%|████▋     | 103/221 [00:28<00:35,  3.34it/s][A
 47%|████▋     | 104/221 [00:28<00:31,  3.72it/s][A
 48%|████▊     | 105/221 [00:28<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:29<00:35,  3.21it/s][A
 48%|████▊     | 107/221 [00:29<00:31,  3.64it/s][A
 49%|████▉     | 108/221 [00:29<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:29<00:24,  4.62it/s][A
 50%|████▉     | 110/221 [00:29<00:23,  4.81it/s][A
 50%|█████     | 111/221 [00:30<00:25,  4.29it/s][A
 51%|█████     | 112/221 [00:30<00:25,  4.19it/s][A
 51%|█████     | 113/221 [00:30<00:23,  4.64it/s][A
 52%|█████▏    | 115/221 [00:30<00:19,  5.32it/s][A
 52%|█████▏    | 116/221 [00:31<00:22,  4.76it/s][A
 53%|█████▎    | 117/221 [00:31<00:23,  4.51it/s][A
 53%|█████▎    | 118/221 [00:31<00:22,  4.48it/s][A
 54%|█████▍    | 119/221 [00:31<00:29,  3.51it/s][A
 54%|█████▍    | 120/221 [00:32<00:25,  4.04it/s][A
 55%|█████▍    | 121/221 [00:32<00:21,  4.65it/s][A
 55%|█████▌    | 122/221 [00:32<00:23,  4.29it/s][A
 56%|█████▌    | 123/221 [00:32<00:23,  4.19it/s][A
 56%|█████▌    | 124/221 [00:33<00:25,  3.78it/s][A
 57%|█████▋    | 125/221 [00:33<00:28,  3.40it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.72it/s][A
 57%|█████▋    | 127/221 [00:34<00:30,  3.08it/s][A
 58%|█████▊    | 128/221 [00:34<00:28,  3.26it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.83it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.67it/s][A
 59%|█████▉    | 131/221 [00:34<00:19,  4.51it/s][A
 60%|█████▉    | 132/221 [00:35<00:22,  4.01it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.78it/s][A
 61%|██████    | 134/221 [00:36<00:30,  2.87it/s][A
 61%|██████    | 135/221 [00:36<00:30,  2.84it/s][A
 62%|██████▏   | 136/221 [00:36<00:26,  3.16it/s][A
 62%|██████▏   | 137/221 [00:36<00:23,  3.63it/s][A
 62%|██████▏   | 138/221 [00:37<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:37<00:30,  2.72it/s][A
 63%|██████▎   | 140/221 [00:38<00:28,  2.87it/s][A
 64%|██████▍   | 141/221 [00:38<00:24,  3.27it/s][A
 64%|██████▍   | 142/221 [00:38<00:21,  3.62it/s][A
 65%|██████▍   | 143/221 [00:39<00:29,  2.67it/s][A
 65%|██████▌   | 144/221 [00:39<00:29,  2.59it/s][A
 66%|██████▌   | 146/221 [00:39<00:18,  4.06it/s][A
 67%|██████▋   | 147/221 [00:39<00:19,  3.89it/s][A
 67%|██████▋   | 148/221 [00:40<00:22,  3.22it/s][A
 67%|██████▋   | 149/221 [00:40<00:21,  3.39it/s][A
 68%|██████▊   | 150/221 [00:40<00:20,  3.52it/s][A
 68%|██████▊   | 151/221 [00:41<00:22,  3.12it/s][A
 69%|██████▉   | 152/221 [00:42<00:33,  2.05it/s][A
 69%|██████▉   | 153/221 [00:42<00:26,  2.61it/s][A
 70%|██████▉   | 154/221 [00:42<00:21,  3.12it/s][A
 70%|███████   | 155/221 [00:42<00:18,  3.52it/s][A
 71%|███████   | 156/221 [00:43<00:19,  3.26it/s][A
 71%|███████   | 157/221 [00:43<00:19,  3.23it/s][A
 71%|███████▏  | 158/221 [00:43<00:19,  3.26it/s][A
 72%|███████▏  | 159/221 [00:43<00:15,  4.03it/s][A
 72%|███████▏  | 160/221 [00:44<00:14,  4.34it/s][A
 73%|███████▎  | 161/221 [00:44<00:15,  3.86it/s][A
 73%|███████▎  | 162/221 [00:44<00:13,  4.29it/s][A
 74%|███████▍  | 163/221 [00:44<00:13,  4.15it/s][A
 74%|███████▍  | 164/221 [00:44<00:11,  4.87it/s][A
 75%|███████▍  | 165/221 [00:45<00:11,  4.86it/s][A
 75%|███████▌  | 166/221 [00:45<00:11,  4.67it/s][A
 76%|███████▌  | 167/221 [00:45<00:10,  5.33it/s][A
 76%|███████▌  | 168/221 [00:45<00:11,  4.75it/s][A
 76%|███████▋  | 169/221 [00:45<00:09,  5.37it/s][A
 77%|███████▋  | 170/221 [00:46<00:15,  3.39it/s][A
 77%|███████▋  | 171/221 [00:46<00:13,  3.69it/s][A
 78%|███████▊  | 172/221 [00:46<00:12,  3.97it/s][A
 78%|███████▊  | 173/221 [00:47<00:13,  3.51it/s][A
 79%|███████▊  | 174/221 [00:47<00:16,  2.85it/s][A
 79%|███████▉  | 175/221 [00:48<00:15,  2.94it/s][A
 80%|███████▉  | 176/221 [00:48<00:14,  3.21it/s][A
 80%|████████  | 177/221 [00:48<00:12,  3.53it/s][A
 81%|████████  | 178/221 [00:48<00:11,  3.66it/s][A
 81%|████████  | 179/221 [00:48<00:11,  3.77it/s][A
 81%|████████▏ | 180/221 [00:49<00:09,  4.34it/s][A
 82%|████████▏ | 181/221 [00:49<00:09,  4.21it/s][A
 82%|████████▏ | 182/221 [00:49<00:10,  3.57it/s][A
 83%|████████▎ | 183/221 [00:50<00:12,  3.07it/s][A
 83%|████████▎ | 184/221 [00:50<00:11,  3.35it/s][A
 84%|████████▎ | 185/221 [00:50<00:08,  4.09it/s][A
 84%|████████▍ | 186/221 [00:51<00:11,  3.14it/s][A
 85%|████████▍ | 187/221 [00:51<00:09,  3.52it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.41it/s][A
 86%|████████▌ | 189/221 [00:51<00:08,  3.66it/s][A
 86%|████████▌ | 190/221 [00:52<00:09,  3.33it/s][A
 86%|████████▋ | 191/221 [00:52<00:07,  3.81it/s][A
 87%|████████▋ | 192/221 [00:52<00:07,  3.96it/s][A
 87%|████████▋ | 193/221 [00:52<00:05,  4.76it/s][A
 88%|████████▊ | 194/221 [00:52<00:06,  4.14it/s][A
 88%|████████▊ | 195/221 [00:53<00:06,  4.33it/s][A
 89%|████████▊ | 196/221 [00:53<00:07,  3.48it/s][A
 89%|████████▉ | 197/221 [00:53<00:06,  3.76it/s][A
 90%|████████▉ | 198/221 [00:54<00:07,  3.08it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.47it/s][A
 90%|█████████ | 200/221 [00:54<00:06,  3.01it/s][A
 91%|█████████ | 201/221 [00:55<00:05,  3.49it/s][A
 91%|█████████▏| 202/221 [00:55<00:05,  3.19it/s][A
 92%|█████████▏| 203/221 [00:55<00:05,  3.55it/s][A
 92%|█████████▏| 204/221 [00:56<00:05,  3.35it/s][A
 93%|█████████▎| 205/221 [00:56<00:03,  4.17it/s][A
 93%|█████████▎| 206/221 [00:56<00:04,  3.31it/s][A
 94%|█████████▎| 207/221 [00:56<00:03,  3.81it/s][A
 94%|█████████▍| 208/221 [00:56<00:03,  4.03it/s][A
 95%|█████████▍| 209/221 [00:57<00:02,  4.04it/s][A
 95%|█████████▌| 211/221 [00:57<00:02,  4.28it/s][A
 96%|█████████▌| 212/221 [00:57<00:02,  3.93it/s][A
 96%|█████████▋| 213/221 [00:58<00:01,  4.09it/s][A
 97%|█████████▋| 214/221 [00:58<00:02,  2.62it/s][A
 97%|█████████▋| 215/221 [00:59<00:02,  2.99it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.12it/s][A
 98%|█████████▊| 217/221 [00:59<00:01,  3.08it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.22it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.23it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.57it/s][A
100%|██████████| 221/221 [01:00<00:00,  3.75it/s][A100%|██████████| 221/221 [01:00<00:00,  3.64it/s]
09/09/2024 21:41:49 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 849--===========

09/09/2024 21:41:49 - INFO - __main__ -   {'area_r1': 40.8, 'area_recall': '40.8/63.7/74.7', 'area_ravg': 59.7}
09/09/2024 21:41:49 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 849--===========

09/09/2024 21:41:49 - INFO - __main__ -   {'forward_r1': 36.9, 'forward_recall': '36.9/65.5/76.5', 'forward_ravg': 59.6}
09/09/2024 21:41:49 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 849--===========

09/09/2024 21:41:49 - INFO - __main__ -   {'area_video_r1': 38.9, 'area_video_recall': '38.9/66.2/77.1', 'area_video_ravg': 60.7}
09/09/2024 21:41:49 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/09/2024 21:41:49 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 21:41:49 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 849--===========

09/09/2024 21:41:49 - INFO - __main__ -   {'area_video_r1': 52.4, 'area_video_recall': '52.4/74.4/82.0', 'area_video_ravg': 69.6, 'area_video_back_r1': 48.8, 'area_video_back_recall': '48.8/74.4/81.6', 'area_video_back_ravg': 68.3}
09/09/2024 21:41:49 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/09/2024 21:41:49 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/09/2024 21:41:49 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 849--===========

09/09/2024 21:41:49 - INFO - __main__ -   {'video_r1': 42.6, 'video_recall': '42.6/71.0/81.8', 'video_ravg': 65.2}
09/09/2024 21:41:49 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 21:41:49 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 21:41:49 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 849--===========

09/09/2024 21:41:49 - INFO - __main__ -   {'video_r1': 51.5, 'video_recall': '51.5/75.2/82.1', 'video_ravg': 69.6}
09/09/2024 21:41:49 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/09/2024 21:41:49 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/09/2024 21:42:10 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.005763177759945393, 'loss_ret%tv%ta--finetune_area/loss_area': 1.0117393732070923, 'loss_ret%tv%ta--finetune_area/total_loss': 1.0175025463104248}
 44%|████▎     | 850/1945 [4:36:51<37:47:20, 124.24s/it][h264 @ 0x55a04743b440] mmco: unref short failure
[h264 @ 0x55a04743b440] mmco: unref short failure
 44%|████▍     | 851/1945 [4:36:55<26:48:08, 88.20s/it]  44%|████▍     | 852/1945 [4:37:00<19:09:56, 63.13s/it] 44%|████▍     | 853/1945 [4:37:05<13:53:07, 45.78s/it][h264 @ 0x55a03fcfba40] mmco: unref short failure
[h264 @ 0x55a03fcfba40] mmco: unref short failure
 44%|████▍     | 854/1945 [4:37:10<10:13:34, 33.74s/it] 44%|████▍     | 855/1945 [4:37:17<7:43:10, 25.50s/it] [h264 @ 0x556b3d776c80] mmco: unref short failure
 44%|████▍     | 856/1945 [4:37:23<5:58:25, 19.75s/it][h264 @ 0x55a049df2e80] mmco: unref short failure
[h264 @ 0x55a049df2e80] mmco: unref short failure
[h264 @ 0x55a049df2e80] mmco: unref short failure
[h264 @ 0x55a049df2e80] mmco: unref short failure
 44%|████▍     | 857/1945 [4:37:31<4:52:18, 16.12s/it][h264 @ 0x556b3a6de380] mmco: unref short failure
 44%|████▍     | 858/1945 [4:37:39<4:06:44, 13.62s/it][h264 @ 0x559bfbdfda80] mmco: unref short failure
[h264 @ 0x559bfbdfda80] mmco: unref short failure
 44%|████▍     | 859/1945 [4:37:46<3:33:18, 11.79s/it][h264 @ 0x556b401d92c0] mmco: unref short failure
[h264 @ 0x559c033caf80] mmco: unref short failure
[h264 @ 0x55a045c71840] mmco: unref short failure
 44%|████▍     | 860/1945 [4:37:53<3:05:07, 10.24s/it][h264 @ 0x56241ae9bd40] mmco: unref short failure
[h264 @ 0x56241ae9bd40] mmco: unref short failure
 44%|████▍     | 861/1945 [4:38:00<2:46:40,  9.23s/it] 44%|████▍     | 862/1945 [4:38:07<2:34:29,  8.56s/it][h264 @ 0x55a049704b00] mmco: unref short failure
 44%|████▍     | 863/1945 [4:38:14<2:29:05,  8.27s/it][h264 @ 0x556b33b96880] mmco: unref short failure
 44%|████▍     | 864/1945 [4:38:21<2:22:49,  7.93s/it][h264 @ 0x56242a96df00] mmco: unref short failure
[h264 @ 0x56242a96df00] mmco: unref short failure
[h264 @ 0x55a047d00b40] mmco: unref short failure
 44%|████▍     | 865/1945 [4:38:29<2:19:19,  7.74s/it] 45%|████▍     | 866/1945 [4:38:35<2:14:45,  7.49s/it][h264 @ 0x55a04a303880] mmco: unref short failure
[h264 @ 0x55a04a303880] mmco: unref short failure
[h264 @ 0x559bfe7db840] mmco: unref short failure
[h264 @ 0x559bfe7db840] mmco: unref short failure
[h264 @ 0x559bf9831f40] mmco: unref short failure
[h264 @ 0x559bf9831f40] mmco: unref short failure
[h264 @ 0x559bf9831f40] mmco: unref short failure
[h264 @ 0x559bf9831f40] mmco: unref short failure
[h264 @ 0x55a045aecfc0] mmco: unref short failure
 45%|████▍     | 867/1945 [4:38:43<2:12:39,  7.38s/it][h264 @ 0x56242c39ad00] mmco: unref short failure
[h264 @ 0x56242c39ad00] mmco: unref short failure
[h264 @ 0x56242c39ad00] mmco: unref short failure
[h264 @ 0x56242c39ad00] mmco: unref short failure
[h264 @ 0x559c0080e340] mmco: unref short failure
[h264 @ 0x559c0080e340] mmco: unref short failure
[h264 @ 0x559c0080e340] mmco: unref short failure
[h264 @ 0x559bedd9d400] mmco: unref short failure
[h264 @ 0x559bedd9d400] mmco: unref short failure
[h264 @ 0x56242e2c4780] mmco: unref short failure
[h264 @ 0x56242e2c4780] mmco: unref short failure
[h264 @ 0x559bf5965d80] mmco: unref short failure
[h264 @ 0x559bf5965d80] mmco: unref short failure
[h264 @ 0x562430478f00] mmco: unref short failure
[h264 @ 0x562430478f00] mmco: unref short failure
[h264 @ 0x562430478f00] mmco: unref short failure
[h264 @ 0x562430478f00] mmco: unref short failure
[h264 @ 0x562430478f00] mmco: unref short failure
[h264 @ 0x562430478f00] mmco: unref short failure
[h264 @ 0x559bf859c2c0] mmco: unref short failure
[h264 @ 0x559bf859c2c0] mmco: unref short failure
 45%|████▍     | 868/1945 [4:38:57<2:48:13,  9.37s/it][h264 @ 0x559bfc24cdc0] mmco: unref short failure
[h264 @ 0x559bfc24cdc0] mmco: unref short failure
[h264 @ 0x559c03494480] mmco: unref short failure
[h264 @ 0x559c03494480] mmco: unref short failure
 45%|████▍     | 869/1945 [4:39:09<3:04:46, 10.30s/it][h264 @ 0x559bf873cc80] mmco: unref short failure
[h264 @ 0x559bf873cc80] mmco: unref short failure
[h264 @ 0x56242a224780] mmco: unref short failure
[h264 @ 0x56242a224780] mmco: unref short failure
[h264 @ 0x559bf39f1b00] mmco: unref short failure
 45%|████▍     | 870/1945 [4:39:15<2:41:53,  9.04s/it] 45%|████▍     | 871/1945 [4:39:22<2:27:57,  8.27s/it][h264 @ 0x556b3e0de140] mmco: unref short failure
 45%|████▍     | 872/1945 [4:39:30<2:30:53,  8.44s/it] 45%|████▍     | 873/1945 [4:39:41<2:42:43,  9.11s/it][h264 @ 0x559beffee200] mmco: unref short failure
[h264 @ 0x559beffee200] mmco: unref short failure
[h264 @ 0x55a04739ca80] mmco: unref short failure
[h264 @ 0x559c03f65180] mmco: unref short failure
[h264 @ 0x55a042ac2d40] mmco: unref short failure
[h264 @ 0x559c07cf06c0] mmco: unref short failure
[h264 @ 0x56241af93400] mmco: unref short failure
[h264 @ 0x56241af93400] mmco: unref short failure
[h264 @ 0x56241de98600] mmco: unref short failure
[h264 @ 0x56241de98600] mmco: unref short failure
[h264 @ 0x562416269a00] mmco: unref short failure
[h264 @ 0x562416269a00] mmco: unref short failure
[h264 @ 0x562416269a00] mmco: unref short failure
[h264 @ 0x562416269a00] mmco: unref short failure
[h264 @ 0x559bfebab4c0] mmco: unref short failure
[h264 @ 0x559bfebab4c0] mmco: unref short failure
[h264 @ 0x556b3bf0db00] mmco: unref short failure
[h264 @ 0x5624333dde80] mmco: unref short failure
 45%|████▍     | 874/1945 [4:40:18<5:11:27, 17.45s/it][h264 @ 0x556b47960b80] mmco: unref short failure
[h264 @ 0x556b47960b80] mmco: unref short failure
[h264 @ 0x556b34670600] mmco: unref short failure
[h264 @ 0x556b34670600] mmco: unref short failure
[h264 @ 0x5624317f1100] mmco: unref short failure
 45%|████▍     | 875/1945 [4:40:40<5:34:27, 18.76s/it][h264 @ 0x556b37b9c940] mmco: unref short failure
[h264 @ 0x556b37b9c940] mmco: unref short failure
[h264 @ 0x556b37b9c940] mmco: unref short failure
[h264 @ 0x556b37b9c940] mmco: unref short failure
[h264 @ 0x556b37b9c940] mmco: unref short failure
[h264 @ 0x556b37b9c940] mmco: unref short failure
[h264 @ 0x556b37b9c940] mmco: unref short failure
[h264 @ 0x556b37b9c940] mmco: unref short failure
[h264 @ 0x559c0114a500] mmco: unref short failure
[h264 @ 0x559c0114a500] mmco: unref short failure
[h264 @ 0x56242fb39580] mmco: unref short failure
[h264 @ 0x56242fb39580] mmco: unref short failure
 45%|████▌     | 876/1945 [4:40:55<5:15:38, 17.72s/it][h264 @ 0x562422f76740] mmco: unref short failure
[h264 @ 0x559c0284f740] mmco: unref short failure
[h264 @ 0x559c0284f740] mmco: unref short failure
[h264 @ 0x55a03dbf7dc0] mmco: unref short failure
[h264 @ 0x55a03dbf7dc0] mmco: unref short failure
 45%|████▌     | 877/1945 [4:41:08<4:49:00, 16.24s/it][h264 @ 0x559bf7e0d9c0] mmco: unref short failure
[h264 @ 0x55a04b1d5e00] mmco: unref short failure
[h264 @ 0x55a04b1d5e00] mmco: unref short failure
 45%|████▌     | 878/1945 [4:41:15<3:59:04, 13.44s/it] 45%|████▌     | 879/1945 [4:41:25<3:39:46, 12.37s/it][h264 @ 0x556b4ab9b680] mmco: unref short failure
[h264 @ 0x556b4ab9b680] mmco: unref short failure
[h264 @ 0x556b4ab9b680] mmco: unref short failure
[h264 @ 0x556b4ab9b680] mmco: unref short failure
[h264 @ 0x556b4ab9b680] mmco: unref short failure
[h264 @ 0x556b4ab9b680] mmco: unref short failure
[h264 @ 0x556b4ab9b680] mmco: unref short failure
[h264 @ 0x556b4ab9b680] mmco: unref short failure
 45%|████▌     | 880/1945 [4:41:35<3:26:40, 11.64s/it] 45%|████▌     | 881/1945 [4:41:42<3:02:03, 10.27s/it][h264 @ 0x559bf74d5f80] mmco: unref short failure
[h264 @ 0x556b2f40c800] mmco: unref short failure
[h264 @ 0x56242b91ee40] mmco: unref short failure
[h264 @ 0x56242b91ee40] mmco: unref short failure
 45%|████▌     | 882/1945 [4:42:18<5:18:55, 18.00s/it][h264 @ 0x55a04edd4b80] mmco: unref short failure
[h264 @ 0x56242f7a78c0] mmco: unref short failure
[h264 @ 0x56242f7a78c0] mmco: unref short failure
[h264 @ 0x56242f7a78c0] mmco: unref short failure
[h264 @ 0x56242f7a78c0] mmco: unref short failure
[h264 @ 0x556b399d28c0] mmco: unref short failure
[h264 @ 0x55a0466ced00] mmco: unref short failure
[h264 @ 0x55a04df4c280] mmco: unref short failure
[h264 @ 0x55a04df4c280] mmco: unref short failure
[h264 @ 0x556b432091c0] mmco: unref short failure
[h264 @ 0x556b432091c0] mmco: unref short failure
 45%|████▌     | 883/1945 [4:42:36<5:22:27, 18.22s/it][h264 @ 0x559bf96ba280] mmco: unref short failure
[h264 @ 0x559bf96ba280] mmco: unref short failure
[h264 @ 0x556b4b3fbc00] mmco: unref short failure
[h264 @ 0x556b4b3fbc00] mmco: unref short failure
[h264 @ 0x556b3bad9ac0] mmco: unref short failure
[h264 @ 0x559c01700bc0] mmco: unref short failure
[h264 @ 0x559c01700bc0] mmco: unref short failure
[h264 @ 0x556b4bd1d000] mmco: unref short failure
[h264 @ 0x55a03963ad00] mmco: unref short failure
[h264 @ 0x562421405ec0] mmco: unref short failure
 45%|████▌     | 884/1945 [4:42:53<5:13:13, 17.71s/it][h264 @ 0x55a04bb922c0] mmco: unref short failure
[h264 @ 0x55a04bb922c0] mmco: unref short failure
[h264 @ 0x562436e397c0] mmco: unref short failure
[h264 @ 0x56241dc12040] mmco: unref short failure
[h264 @ 0x56241dc12040] mmco: unref short failure
[h264 @ 0x556b3bada140] mmco: unref short failure
 46%|████▌     | 885/1945 [4:43:13<5:22:38, 18.26s/it][h264 @ 0x559bfcbda000] mmco: unref short failure
[h264 @ 0x559bfcbda000] mmco: unref short failure
 46%|████▌     | 886/1945 [4:43:21<4:28:54, 15.24s/it][h264 @ 0x56242910ef00] mmco: unref short failure
[h264 @ 0x55a035ea4280] mmco: unref short failure
[h264 @ 0x55a035ea4280] mmco: unref short failure
 46%|████▌     | 887/1945 [4:43:36<4:26:57, 15.14s/it][h264 @ 0x556b433bfec0] mmco: unref short failure
[h264 @ 0x556b433bfec0] mmco: unref short failure
[h264 @ 0x55a03b7eaf00] mmco: unref short failure
[h264 @ 0x55a03b7eaf00] mmco: unref short failure
 46%|████▌     | 888/1945 [4:43:43<3:47:50, 12.93s/it][h264 @ 0x55a04bca0980] mmco: unref short failure
[h264 @ 0x55a04bca0980] mmco: unref short failure
 46%|████▌     | 889/1945 [4:43:50<3:14:29, 11.05s/it][h264 @ 0x55a04a32f080] mmco: unref short failure
[h264 @ 0x55a0497af540] mmco: unref short failure
[h264 @ 0x55a0497af540] mmco: unref short failure
[h264 @ 0x56242f0ac940] mmco: unref short failure
[h264 @ 0x56242f0ac940] mmco: unref short failure
[h264 @ 0x55a04f176440] mmco: unref short failure
[h264 @ 0x55a04f176440] mmco: unref short failure
[h264 @ 0x556b43882e80] mmco: unref short failure
[h264 @ 0x56241c15de40] mmco: unref short failure
[h264 @ 0x559bfe8b8640] mmco: unref short failure
[h264 @ 0x559bfe8b8640] mmco: unref short failure
[h264 @ 0x559bfe8b8640] mmco: unref short failure
[h264 @ 0x5624366e1c00] mmco: unref short failure
[h264 @ 0x5624366e1c00] mmco: unref short failure
[h264 @ 0x5624260659c0] mmco: unref short failure
[h264 @ 0x56242d716d40] mmco: unref short failure
[h264 @ 0x56242d716d40] mmco: unref short failure
 46%|████▌     | 890/1945 [4:44:22<5:02:48, 17.22s/it][h264 @ 0x559bf54b45c0] mmco: unref short failure
[h264 @ 0x559bf54b4800] mmco: unref short failure
[h264 @ 0x556b2e3b2e40] mmco: unref short failure
[h264 @ 0x556b2e3b2e40] mmco: unref short failure
[h264 @ 0x559bf74e3e80] mmco: unref short failure
[h264 @ 0x55a04cf4fbc0] mmco: unref short failure
[h264 @ 0x55a04cf4fbc0] mmco: unref short failure
[h264 @ 0x556b37755c80] mmco: unref short failure
[h264 @ 0x559bf74593c0] mmco: unref short failure
[h264 @ 0x56241b1d1940] mmco: unref short failure
[h264 @ 0x56241b1d1940] mmco: unref short failure
[h264 @ 0x55a037e42140] mmco: unref short failure
[h264 @ 0x55a037e42140] mmco: unref short failure
[h264 @ 0x559bea4fa5c0] mmco: unref short failure
 46%|████▌     | 891/1945 [4:44:54<6:20:36, 21.67s/it] 46%|████▌     | 892/1945 [4:45:01<5:04:12, 17.33s/it][h264 @ 0x556b3a792d80] mmco: unref short failure
[h264 @ 0x556b3a792d80] mmco: unref short failure
[h264 @ 0x556b3d9ccb40] mmco: unref short failure
[h264 @ 0x56242b91ec40] mmco: unref short failure
[h264 @ 0x56242b91ec40] mmco: unref short failure
[h264 @ 0x559c0164cd40] mmco: unref short failure
[h264 @ 0x559c0164cd40] mmco: unref short failure
[h264 @ 0x559c0164cd40] mmco: unref short failure
[h264 @ 0x559c0164cd40] mmco: unref short failure
[h264 @ 0x5624244c5100] mmco: unref short failure
[h264 @ 0x5624244c5100] mmco: unref short failure
[h264 @ 0x556b42ee4540] mmco: unref short failure
[h264 @ 0x559c03f3bd40] mmco: unref short failure
 46%|████▌     | 893/1945 [4:45:21<5:17:27, 18.11s/it][h264 @ 0x562425761040] mmco: unref short failure
 46%|████▌     | 894/1945 [4:45:29<4:24:34, 15.10s/it][h264 @ 0x5624270fb680] mmco: unref short failure
 46%|████▌     | 895/1945 [4:45:45<4:27:11, 15.27s/it][h264 @ 0x55a049827340] mmco: unref short failure
[h264 @ 0x55a049827340] mmco: unref short failure
 46%|████▌     | 896/1945 [4:45:53<3:48:33, 13.07s/it][h264 @ 0x556b3fe6c4c0] mmco: unref short failure
[h264 @ 0x556b3fe6c4c0] mmco: unref short failure
 46%|████▌     | 897/1945 [4:46:00<3:17:02, 11.28s/it][h264 @ 0x559bf76cbf00] mmco: unref short failure
[h264 @ 0x559bf76cbf00] mmco: unref short failure
[h264 @ 0x559bf99d0f80] mmco: unref short failure
[h264 @ 0x559bf99d0f80] mmco: unref short failure
[h264 @ 0x56242ec49ec0] mmco: unref short failure
[h264 @ 0x56242ec49ec0] mmco: unref short failure
[h264 @ 0x562416ff0540] mmco: unref short failure
[h264 @ 0x562416ff0540] mmco: unref short failure
[h264 @ 0x556b33790ac0] mmco: unref short failure
[h264 @ 0x559c014a9000] mmco: unref short failure
[h264 @ 0x559bf64f2e00] mmco: unref short failure
[h264 @ 0x5624173523c0] mmco: unref short failure
[h264 @ 0x556b3330a340] mmco: unref short failure
[h264 @ 0x556b3330a340] mmco: unref short failure
[h264 @ 0x556b3330a340] mmco: unref short failure
[h264 @ 0x556b3330a340] mmco: unref short failure
[h264 @ 0x556b3330a340] mmco: unref short failure
[h264 @ 0x56241a6059c0] mmco: unref short failure
[h264 @ 0x56241a1730c0] mmco: unref short failure
[h264 @ 0x56241a1730c0] mmco: unref short failure
[h264 @ 0x56241a1730c0] mmco: unref short failure
[h264 @ 0x56241a1730c0] mmco: unref short failure
 46%|████▌     | 898/1945 [4:46:22<4:12:45, 14.49s/it][h264 @ 0x559bf88f5940] mmco: unref short failure
[h264 @ 0x559bf88f5940] mmco: unref short failure
[h264 @ 0x55a0474d5800] mmco: unref short failure
[h264 @ 0x55a0449fe140] mmco: unref short failure
[h264 @ 0x55a0449fe140] mmco: unref short failure
[h264 @ 0x55a0449fe140] mmco: unref short failure
[h264 @ 0x55a0449fe140] mmco: unref short failure
[h264 @ 0x56242d45e100] mmco: unref short failure
[h264 @ 0x56242d45e100] mmco: unref short failure
 46%|████▌     | 899/1945 [4:46:57<6:01:57, 20.76s/it]09/09/2024 21:52:19 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 21:52:19 - INFO - __main__ -   start running ret%tv validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559c00e63280] mmco: unref short failure
[h264 @ 0x559c00e63280] mmco: unref short failure
[h264 @ 0x55a03ff9d480] mmco: unref short failure
[h264 @ 0x55a03ff9d480] mmco: unref short failure
[h264 @ 0x556b48f1b040] mmco: unref short failure
[h264 @ 0x556b49efbb00] mmco: unref short failure
[h264 @ 0x556b49efbb00] mmco: unref short failure
[h264 @ 0x559bfe4da240] mmco: unref short failure
[h264 @ 0x559bfe4da240] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556b4471af40] mmco: unref short failure
[h264 @ 0x556b4471af40] mmco: unref short failure
[h264 @ 0x556b4471af40] mmco: unref short failure
[h264 @ 0x559c09c63400] mmco: unref short failure
[h264 @ 0x559c09c63400] mmco: unref short failure
[h264 @ 0x559c09c63400] mmco: unref short failure
[h264 @ 0x559c09c63400] mmco: unref short failure
[h264 @ 0x559c09c63400] mmco: unref short failure
[h264 @ 0x559c09c63400] mmco: unref short failure
[h264 @ 0x559c09c63400] mmco: unref short failure
[h264 @ 0x559c09c63400] mmco: unref short failure
[h264 @ 0x55a037347d80] mmco: unref short failure
[h264 @ 0x56241f261d80] mmco: unref short failure
[h264 @ 0x55a03eb06800] mmco: unref short failure
[h264 @ 0x56242dd3b240] mmco: unref short failure
[h264 @ 0x559c06791c40] mmco: unref short failure
[h264 @ 0x559c06791c40] mmco: unref short failure
[h264 @ 0x559c0727b840] mmco: unref short failure
[h264 @ 0x559c0727b840] mmco: unref short failure
[h264 @ 0x556b3c104080] mmco: unref short failure
[h264 @ 0x55a04c8a3dc0] mmco: unref short failure
[h264 @ 0x559bfc743f00] mmco: unref short failure
[h264 @ 0x559bfc743f00] mmco: unref short failure
[h264 @ 0x559bf8890440] mmco: unref short failure
[h264 @ 0x5624268e4200] mmco: unref short failure
[h264 @ 0x55a03a3ddc80] mmco: unref short failure
[h264 @ 0x559bea19d980] mmco: unref short failure
[h264 @ 0x559bea19d980] mmco: unref short failure
[h264 @ 0x56241f214b40] mmco: unref short failure
[h264 @ 0x56241f214b40] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:08,  1.71it/s][A
  1%|          | 2/221 [00:01<02:12,  1.65it/s][A
  1%|▏         | 3/221 [00:01<01:28,  2.45it/s][A
  2%|▏         | 4/221 [00:01<01:03,  3.43it/s][A
  2%|▏         | 5/221 [00:01<00:50,  4.24it/s][A
  3%|▎         | 6/221 [00:01<00:41,  5.17it/s][A
  3%|▎         | 7/221 [00:01<00:42,  5.04it/s][A
  4%|▎         | 8/221 [00:02<01:09,  3.05it/s][A
  4%|▍         | 9/221 [00:02<01:01,  3.45it/s][A[h264 @ 0x56242cfb13c0] mmco: unref short failure
[h264 @ 0x56242cfb13c0] mmco: unref short failure

  5%|▍         | 10/221 [00:03<01:10,  2.97it/s][A
  5%|▍         | 11/221 [00:03<00:56,  3.71it/s][A
  5%|▌         | 12/221 [00:04<01:28,  2.37it/s][A
  6%|▌         | 13/221 [00:04<01:10,  2.97it/s][A[h264 @ 0x56242a8c6bc0] mmco: unref short failure
[h264 @ 0x56242a8c6bc0] mmco: unref short failure
[h264 @ 0x55a040b11b80] mmco: unref short failure

  6%|▋         | 14/221 [00:06<02:45,  1.25it/s][A
  7%|▋         | 15/221 [00:06<02:06,  1.62it/s][A
  7%|▋         | 16/221 [00:06<01:51,  1.84it/s][A
  8%|▊         | 17/221 [00:06<01:34,  2.17it/s][A
  8%|▊         | 18/221 [00:07<01:21,  2.49it/s][A
  9%|▊         | 19/221 [00:07<01:07,  3.01it/s][A
  9%|▉         | 20/221 [00:07<00:56,  3.55it/s][A
 10%|▉         | 21/221 [00:07<00:50,  3.95it/s][A
 10%|▉         | 22/221 [00:07<00:47,  4.23it/s][A
 10%|█         | 23/221 [00:08<00:41,  4.81it/s][A
 11%|█         | 24/221 [00:08<00:40,  4.86it/s][A
 11%|█▏        | 25/221 [00:08<00:39,  4.94it/s][A
 12%|█▏        | 26/221 [00:08<00:44,  4.33it/s][A
 12%|█▏        | 27/221 [00:08<00:41,  4.62it/s][A
 13%|█▎        | 28/221 [00:09<00:55,  3.45it/s][h264 @ 0x55a048c14880] mmco: unref short failure
[h264 @ 0x55a048c14880] mmco: unref short failure
[A
 13%|█▎        | 29/221 [00:09<00:47,  4.06it/s][A
 14%|█▎        | 30/221 [00:09<00:46,  4.07it/s][A
 14%|█▍        | 31/221 [00:10<00:46,  4.11it/s][A
 15%|█▍        | 33/221 [00:10<00:38,  4.94it/s][A
 15%|█▌        | 34/221 [00:10<00:36,  5.10it/s][A
 16%|█▌        | 35/221 [00:10<00:32,  5.66it/s][A
 16%|█▋        | 36/221 [00:10<00:35,  5.27it/s][A
 17%|█▋        | 37/221 [00:11<00:59,  3.08it/s][A[h264 @ 0x55a03c0bc1c0] mmco: unref short failure

 17%|█▋        | 38/221 [00:11<01:06,  2.75it/s][A
 18%|█▊        | 39/221 [00:12<00:54,  3.35it/s][A
 18%|█▊        | 40/221 [00:12<00:53,  3.39it/s][A
 19%|█▊        | 41/221 [00:12<00:43,  4.15it/s][A
 19%|█▉        | 42/221 [00:12<00:47,  3.73it/s][A
 19%|█▉        | 43/221 [00:12<00:40,  4.37it/s][A
 20%|█▉        | 44/221 [00:13<00:34,  5.16it/s][A
 20%|██        | 45/221 [00:14<01:37,  1.80it/s][A
 21%|██        | 46/221 [00:14<01:27,  2.01it/s][A[h264 @ 0x556b3f079ec0] mmco: unref short failure

 21%|██▏       | 47/221 [00:15<01:38,  1.76it/s][A
 22%|██▏       | 49/221 [00:15<01:01,  2.78it/s][A
 23%|██▎       | 50/221 [00:16<00:55,  3.06it/s][A[h264 @ 0x56241dc12980] mmco: unref short failure
[h264 @ 0x56241dc12980] mmco: unref short failure

 23%|██▎       | 51/221 [00:16<01:21,  2.08it/s][A
 24%|██▎       | 52/221 [00:17<01:08,  2.46it/s][A
 24%|██▍       | 53/221 [00:17<00:57,  2.91it/s][A
 24%|██▍       | 54/221 [00:18<01:17,  2.15it/s][A
 25%|██▍       | 55/221 [00:18<01:07,  2.45it/s][A
 25%|██▌       | 56/221 [00:18<00:58,  2.83it/s][A
 26%|██▌       | 57/221 [00:18<00:52,  3.09it/s][A
 27%|██▋       | 59/221 [00:19<00:36,  4.44it/s][A
 27%|██▋       | 60/221 [00:19<00:45,  3.56it/s][A
 28%|██▊       | 61/221 [00:19<00:42,  3.78it/s][A
 28%|██▊       | 62/221 [00:19<00:38,  4.08it/s][A
 29%|██▊       | 63/221 [00:20<00:37,  4.19it/s][A
 29%|██▉       | 64/221 [00:20<00:33,  4.65it/s][A
 29%|██▉       | 65/221 [00:20<00:28,  5.47it/s][A
 30%|██▉       | 66/221 [00:20<00:35,  4.34it/s][A[h264 @ 0x56242ee9d480] mmco: unref short failure
[h264 @ 0x56242ee9d480] mmco: unref short failure

 30%|███       | 67/221 [00:21<00:36,  4.17it/s][A
 31%|███       | 68/221 [00:21<00:32,  4.72it/s][A
 31%|███       | 69/221 [00:21<00:50,  3.01it/s][A
 32%|███▏      | 70/221 [00:21<00:41,  3.64it/s][A[h264 @ 0x562432796a00] mmco: unref short failure
[h264 @ 0x562432796a00] mmco: unref short failure

 32%|███▏      | 71/221 [00:22<01:10,  2.12it/s][A
 33%|███▎      | 72/221 [00:23<00:59,  2.50it/s][A
 33%|███▎      | 73/221 [00:23<00:54,  2.72it/s][A
 33%|███▎      | 74/221 [00:23<00:49,  2.97it/s][A
 34%|███▍      | 75/221 [00:23<00:45,  3.21it/s][A
 34%|███▍      | 76/221 [00:24<00:37,  3.91it/s][A
 35%|███▍      | 77/221 [00:24<00:33,  4.29it/s][A
 35%|███▌      | 78/221 [00:24<00:35,  4.00it/s][A
 36%|███▌      | 79/221 [00:25<00:48,  2.94it/s][A
 36%|███▌      | 80/221 [00:25<00:38,  3.65it/s][A
 37%|███▋      | 81/221 [00:25<00:38,  3.60it/s][A
 37%|███▋      | 82/221 [00:25<00:35,  3.91it/s][A
 38%|███▊      | 83/221 [00:25<00:29,  4.64it/s][A
 38%|███▊      | 84/221 [00:25<00:26,  5.14it/s][A
 39%|███▉      | 86/221 [00:26<00:21,  6.19it/s][A
 39%|███▉      | 87/221 [00:26<00:34,  3.91it/s][A
 40%|███▉      | 88/221 [00:27<00:34,  3.85it/s][A[h264 @ 0x556b3d745e80] mmco: unref short failure
[h264 @ 0x556b3d745e80] mmco: unref short failure
[h264 @ 0x5624268e4200] mmco: unref short failure
[h264 @ 0x5624268e4200] mmco: unref short failure
[h264 @ 0x5624268e4200] mmco: unref short failure
[h264 @ 0x5624268e4200] mmco: unref short failure
[h264 @ 0x5624268e4200] mmco: unref short failure
[h264 @ 0x5624268e4200] mmco: unref short failure
[h264 @ 0x5624268e4200] mmco: unref short failure
[h264 @ 0x5624268e4200] mmco: unref short failure

 40%|████      | 89/221 [00:29<01:48,  1.22it/s][A
 41%|████      | 90/221 [00:29<01:26,  1.52it/s][A
 41%|████      | 91/221 [00:29<01:04,  2.01it/s][A
 42%|████▏     | 92/221 [00:29<00:52,  2.45it/s][A
 42%|████▏     | 93/221 [00:30<00:53,  2.39it/s][A
 43%|████▎     | 94/221 [00:30<00:46,  2.73it/s][A
 43%|████▎     | 95/221 [00:30<00:38,  3.29it/s][A
 43%|████▎     | 96/221 [00:30<00:35,  3.48it/s][A
 44%|████▍     | 97/221 [00:31<00:29,  4.19it/s][A
 44%|████▍     | 98/221 [00:31<00:28,  4.31it/s][A
 45%|████▍     | 99/221 [00:31<00:24,  4.93it/s][A
 45%|████▌     | 100/221 [00:31<00:24,  4.90it/s][A
 46%|████▌     | 101/221 [00:31<00:21,  5.69it/s][A
 46%|████▌     | 102/221 [00:32<00:27,  4.29it/s][A
 47%|████▋     | 103/221 [00:32<00:25,  4.71it/s][A
 48%|████▊     | 105/221 [00:32<00:20,  5.68it/s][A
 48%|████▊     | 106/221 [00:33<00:39,  2.90it/s][A
 48%|████▊     | 107/221 [00:33<00:33,  3.41it/s][A
 49%|████▉     | 108/221 [00:33<00:29,  3.80it/s][A
 49%|████▉     | 109/221 [00:33<00:27,  4.00it/s][A
 50%|████▉     | 110/221 [00:34<00:29,  3.76it/s][A
 50%|█████     | 111/221 [00:34<00:32,  3.34it/s][A
 51%|█████     | 112/221 [00:34<00:29,  3.70it/s][A
 51%|█████     | 113/221 [00:35<00:33,  3.23it/s][A
 52%|█████▏    | 115/221 [00:35<00:21,  4.83it/s][A[h264 @ 0x559bea182a40] mmco: unref short failure
[h264 @ 0x559bea182a40] mmco: unref short failure

 52%|█████▏    | 116/221 [00:39<01:52,  1.07s/it][A
 53%|█████▎    | 117/221 [00:39<01:31,  1.14it/s][A
 53%|█████▎    | 118/221 [00:39<01:16,  1.35it/s][A
 54%|█████▍    | 119/221 [00:39<00:58,  1.74it/s][A
 54%|█████▍    | 120/221 [00:40<00:48,  2.06it/s][A
 55%|█████▌    | 122/221 [00:40<00:31,  3.15it/s][A
 56%|█████▌    | 123/221 [00:40<00:28,  3.48it/s][A
 56%|█████▌    | 124/221 [00:40<00:25,  3.75it/s][A
 57%|█████▋    | 125/221 [00:41<00:25,  3.82it/s][A
 57%|█████▋    | 126/221 [00:41<00:26,  3.54it/s][A
 57%|█████▋    | 127/221 [00:41<00:29,  3.15it/s][A
 58%|█████▊    | 128/221 [00:42<00:28,  3.24it/s][A
 58%|█████▊    | 129/221 [00:42<00:24,  3.74it/s][A
 59%|█████▉    | 130/221 [00:42<00:25,  3.55it/s][A
 59%|█████▉    | 131/221 [00:42<00:21,  4.22it/s][A
 60%|█████▉    | 132/221 [00:42<00:18,  4.86it/s][A
 60%|██████    | 133/221 [00:43<00:23,  3.82it/s][A
 61%|██████    | 134/221 [00:43<00:22,  3.88it/s][A
 61%|██████    | 135/221 [00:43<00:22,  3.76it/s][A
 62%|██████▏   | 136/221 [00:44<00:25,  3.39it/s][A
 62%|██████▏   | 137/221 [00:44<00:21,  3.86it/s][A[h264 @ 0x56243387ef40] mmco: unref short failure

 62%|██████▏   | 138/221 [00:44<00:25,  3.27it/s][A
 63%|██████▎   | 139/221 [00:45<00:24,  3.32it/s][A
 63%|██████▎   | 140/221 [00:45<00:25,  3.22it/s][A
 64%|██████▍   | 141/221 [00:45<00:22,  3.56it/s][A
 64%|██████▍   | 142/221 [00:46<00:30,  2.58it/s][A
 65%|██████▍   | 143/221 [00:46<00:28,  2.74it/s][A
 66%|██████▌   | 145/221 [00:46<00:17,  4.32it/s][A
 67%|██████▋   | 147/221 [00:46<00:13,  5.49it/s][A
 67%|██████▋   | 148/221 [00:47<00:13,  5.34it/s][A
 68%|██████▊   | 150/221 [00:47<00:10,  6.80it/s][A
 68%|██████▊   | 151/221 [00:48<00:19,  3.59it/s][A
 69%|██████▉   | 152/221 [00:48<00:18,  3.72it/s][A
 69%|██████▉   | 153/221 [00:48<00:19,  3.49it/s][A
 70%|██████▉   | 154/221 [00:49<00:22,  3.00it/s][A[h264 @ 0x56241a0b14c0] mmco: unref short failure

 71%|███████   | 156/221 [00:49<00:16,  3.97it/s][A
 71%|███████   | 157/221 [00:51<00:44,  1.43it/s][A
 71%|███████▏  | 158/221 [00:51<00:35,  1.79it/s][A
 72%|███████▏  | 159/221 [00:51<00:28,  2.19it/s][A
 72%|███████▏  | 160/221 [00:51<00:22,  2.69it/s][A
 73%|███████▎  | 162/221 [00:52<00:18,  3.24it/s][A
 74%|███████▍  | 163/221 [00:52<00:17,  3.37it/s][A
 74%|███████▍  | 164/221 [00:52<00:14,  3.94it/s][A[h264 @ 0x556b336d96c0] mmco: unref short failure
[h264 @ 0x556b336d96c0] mmco: unref short failure

 75%|███████▌  | 166/221 [00:53<00:12,  4.29it/s][A
 76%|███████▌  | 167/221 [00:53<00:10,  4.93it/s][A
 76%|███████▌  | 168/221 [00:57<01:01,  1.16s/it][A
 76%|███████▋  | 169/221 [00:57<00:46,  1.12it/s][A
 77%|███████▋  | 170/221 [00:57<00:36,  1.40it/s][A
 77%|███████▋  | 171/221 [00:57<00:27,  1.80it/s][A
 78%|███████▊  | 172/221 [00:58<00:22,  2.13it/s][A
 79%|███████▊  | 174/221 [00:58<00:13,  3.45it/s][A
 79%|███████▉  | 175/221 [00:58<00:12,  3.57it/s][A
 80%|███████▉  | 176/221 [00:58<00:12,  3.65it/s][A
 81%|████████  | 178/221 [00:59<00:10,  3.98it/s][A
 81%|████████  | 179/221 [00:59<00:14,  2.99it/s][A
 82%|████████▏ | 181/221 [01:00<00:10,  3.94it/s][A
 82%|████████▏ | 182/221 [01:00<00:09,  4.31it/s][A
 83%|████████▎ | 183/221 [01:00<00:08,  4.52it/s][A
 83%|████████▎ | 184/221 [01:00<00:08,  4.15it/s][A
 84%|████████▎ | 185/221 [01:00<00:07,  4.85it/s][A
 84%|████████▍ | 186/221 [01:01<00:08,  3.90it/s][A
 85%|████████▍ | 187/221 [01:01<00:07,  4.50it/s][A
 85%|████████▌ | 188/221 [01:01<00:08,  4.05it/s][A
 86%|████████▌ | 189/221 [01:01<00:07,  4.24it/s][A
 86%|████████▌ | 190/221 [01:02<00:07,  4.24it/s][A
 87%|████████▋ | 192/221 [01:02<00:05,  5.32it/s][A
 88%|████████▊ | 194/221 [01:03<00:06,  4.30it/s][A
 88%|████████▊ | 195/221 [01:03<00:05,  4.64it/s][A
 89%|████████▉ | 197/221 [01:03<00:04,  5.99it/s][A
 90%|████████▉ | 198/221 [01:03<00:04,  5.51it/s][A
 90%|█████████ | 199/221 [01:03<00:03,  5.89it/s][A
 90%|█████████ | 200/221 [01:04<00:04,  4.74it/s][A
 91%|█████████ | 201/221 [01:04<00:03,  5.01it/s][A
 91%|█████████▏| 202/221 [01:04<00:03,  5.24it/s][A
 92%|█████████▏| 204/221 [01:04<00:02,  7.09it/s][A[h264 @ 0x5624203b9280] mmco: unref short failure

 93%|█████████▎| 206/221 [01:05<00:03,  4.50it/s][A
 94%|█████████▍| 208/221 [01:05<00:02,  5.81it/s][A
 95%|█████████▍| 209/221 [01:05<00:01,  6.26it/s][A
 95%|█████████▌| 211/221 [01:05<00:01,  5.97it/s][A
 96%|█████████▋| 213/221 [01:06<00:01,  7.15it/s][A[h264 @ 0x556b336d9200] mmco: unref short failure
[h264 @ 0x556b336d9200] mmco: unref short failure

 97%|█████████▋| 214/221 [01:06<00:01,  5.00it/s][A
 97%|█████████▋| 215/221 [01:06<00:01,  5.30it/s][A
 98%|█████████▊| 216/221 [01:06<00:00,  5.15it/s][A
 98%|█████████▊| 217/221 [01:07<00:01,  3.87it/s][A
 99%|█████████▊| 218/221 [01:07<00:00,  4.27it/s][A
 99%|█████████▉| 219/221 [01:07<00:00,  4.45it/s][A
100%|█████████▉| 220/221 [01:11<00:01,  1.31s/it][A
100%|██████████| 221/221 [01:11<00:00,  1.03it/s][A100%|██████████| 221/221 [01:11<00:00,  3.07it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:57,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:52,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:22<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:19,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:51<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.78it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:57<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:25,  8.46it/s][A
  1%|          | 2/221 [00:00<00:43,  5.04it/s][A
  1%|▏         | 3/221 [00:00<00:53,  4.08it/s][A
  2%|▏         | 4/221 [00:00<00:46,  4.71it/s][A
  2%|▏         | 5/221 [00:01<00:42,  5.03it/s][A
  3%|▎         | 7/221 [00:01<00:39,  5.36it/s][A
  4%|▎         | 8/221 [00:01<00:47,  4.44it/s][A
  4%|▍         | 9/221 [00:01<00:45,  4.64it/s][A
  5%|▍         | 10/221 [00:02<01:04,  3.27it/s][A
  5%|▍         | 11/221 [00:02<00:57,  3.64it/s][A
  5%|▌         | 12/221 [00:02<00:49,  4.20it/s][A
  6%|▌         | 13/221 [00:03<01:28,  2.36it/s][A
  6%|▋         | 14/221 [00:03<01:10,  2.92it/s][A
  7%|▋         | 15/221 [00:03<01:02,  3.31it/s][A
  7%|▋         | 16/221 [00:04<01:07,  3.05it/s][A
  8%|▊         | 17/221 [00:05<01:34,  2.17it/s][A
  8%|▊         | 18/221 [00:05<01:19,  2.55it/s][A
  9%|▊         | 19/221 [00:05<01:07,  2.99it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.78it/s][A
 10%|▉         | 21/221 [00:05<00:46,  4.30it/s][A
 10%|▉         | 22/221 [00:06<00:43,  4.61it/s][A
 11%|█         | 24/221 [00:06<00:34,  5.76it/s][A
 11%|█▏        | 25/221 [00:06<00:34,  5.66it/s][A
 12%|█▏        | 26/221 [00:06<00:37,  5.22it/s][A
 12%|█▏        | 27/221 [00:06<00:33,  5.79it/s][A
 13%|█▎        | 28/221 [00:07<00:43,  4.43it/s][A
 13%|█▎        | 29/221 [00:07<00:43,  4.38it/s][A
 14%|█▎        | 30/221 [00:07<00:49,  3.84it/s][A
 14%|█▍        | 31/221 [00:07<00:47,  4.02it/s][A
 15%|█▍        | 33/221 [00:08<00:37,  5.08it/s][A
 15%|█▌        | 34/221 [00:08<00:38,  4.90it/s][A
 16%|█▌        | 35/221 [00:08<00:41,  4.48it/s][A
 16%|█▋        | 36/221 [00:09<00:43,  4.27it/s][A
 17%|█▋        | 37/221 [00:09<00:41,  4.41it/s][A
 17%|█▋        | 38/221 [00:09<00:44,  4.12it/s][A
 18%|█▊        | 39/221 [00:09<00:41,  4.42it/s][A
 18%|█▊        | 40/221 [00:10<00:49,  3.65it/s][A
 19%|█▊        | 41/221 [00:10<00:41,  4.34it/s][A
 19%|█▉        | 42/221 [00:10<00:37,  4.81it/s][A
 19%|█▉        | 43/221 [00:10<00:42,  4.16it/s][A
 20%|█▉        | 44/221 [00:10<00:42,  4.21it/s][A
 20%|██        | 45/221 [00:11<00:45,  3.84it/s][A
 21%|██        | 46/221 [00:11<00:40,  4.35it/s][A
 21%|██▏       | 47/221 [00:11<00:38,  4.46it/s][A
 22%|██▏       | 48/221 [00:11<00:33,  5.10it/s][A
 22%|██▏       | 49/221 [00:11<00:34,  5.05it/s][A
 23%|██▎       | 50/221 [00:12<00:47,  3.61it/s][A
 23%|██▎       | 51/221 [00:12<00:42,  3.99it/s][A
 24%|██▎       | 52/221 [00:12<00:45,  3.73it/s][A
 24%|██▍       | 53/221 [00:13<00:38,  4.38it/s][A
 24%|██▍       | 54/221 [00:13<00:52,  3.18it/s][A
 25%|██▍       | 55/221 [00:13<00:47,  3.47it/s][A
 25%|██▌       | 56/221 [00:13<00:40,  4.06it/s][A
 26%|██▌       | 57/221 [00:14<00:40,  4.06it/s][A
 26%|██▌       | 58/221 [00:14<00:47,  3.40it/s][A
 27%|██▋       | 59/221 [00:14<00:42,  3.85it/s][A
 27%|██▋       | 60/221 [00:14<00:39,  4.09it/s][A
 28%|██▊       | 61/221 [00:15<00:35,  4.49it/s][A
 28%|██▊       | 62/221 [00:15<00:35,  4.45it/s][A
 29%|██▊       | 63/221 [00:15<00:35,  4.50it/s][A
 29%|██▉       | 64/221 [00:16<00:46,  3.39it/s][A
 29%|██▉       | 65/221 [00:16<00:38,  4.05it/s][A
 30%|██▉       | 66/221 [00:16<00:49,  3.12it/s][A
 30%|███       | 67/221 [00:17<00:54,  2.83it/s][A
 31%|███       | 68/221 [00:17<00:45,  3.33it/s][A
 31%|███       | 69/221 [00:18<01:11,  2.12it/s][A
 32%|███▏      | 70/221 [00:18<00:54,  2.77it/s][A
 32%|███▏      | 71/221 [00:18<00:46,  3.19it/s][A
 33%|███▎      | 72/221 [00:18<00:52,  2.85it/s][A
 33%|███▎      | 73/221 [00:19<00:50,  2.94it/s][A
 33%|███▎      | 74/221 [00:19<00:41,  3.52it/s][A
 34%|███▍      | 75/221 [00:19<00:40,  3.63it/s][A
 34%|███▍      | 76/221 [00:19<00:36,  3.92it/s][A
 35%|███▍      | 77/221 [00:20<00:38,  3.78it/s][A
 35%|███▌      | 78/221 [00:20<00:34,  4.09it/s][A
 36%|███▌      | 79/221 [00:20<00:43,  3.23it/s][A
 36%|███▌      | 80/221 [00:20<00:38,  3.66it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.84it/s][A
 37%|███▋      | 82/221 [00:21<00:39,  3.50it/s][A
 38%|███▊      | 83/221 [00:21<00:42,  3.24it/s][A
 38%|███▊      | 84/221 [00:22<00:42,  3.26it/s][A
 38%|███▊      | 85/221 [00:22<00:33,  4.03it/s][A
 39%|███▉      | 86/221 [00:22<00:37,  3.57it/s][A
 39%|███▉      | 87/221 [00:23<00:48,  2.78it/s][A
 40%|███▉      | 88/221 [00:23<00:54,  2.46it/s][A
 40%|████      | 89/221 [00:23<00:47,  2.76it/s][A
 41%|████      | 90/221 [00:24<00:50,  2.60it/s][A
 41%|████      | 91/221 [00:24<00:39,  3.27it/s][A
 42%|████▏     | 92/221 [00:24<00:43,  2.97it/s][A
 42%|████▏     | 93/221 [00:25<00:55,  2.30it/s][A
 43%|████▎     | 94/221 [00:25<00:49,  2.58it/s][A
 43%|████▎     | 95/221 [00:26<00:43,  2.90it/s][A
 43%|████▎     | 96/221 [00:26<00:38,  3.22it/s][A
 44%|████▍     | 97/221 [00:26<00:34,  3.59it/s][A
 44%|████▍     | 98/221 [00:26<00:33,  3.70it/s][A
 45%|████▍     | 99/221 [00:27<00:30,  4.00it/s][A
 45%|████▌     | 100/221 [00:27<00:29,  4.08it/s][A
 46%|████▌     | 101/221 [00:27<00:30,  3.92it/s][A
 46%|████▌     | 102/221 [00:28<00:46,  2.55it/s][A
 47%|████▋     | 103/221 [00:28<00:36,  3.22it/s][A
 47%|████▋     | 104/221 [00:28<00:32,  3.58it/s][A
 48%|████▊     | 105/221 [00:28<00:31,  3.71it/s][A
 48%|████▊     | 106/221 [00:29<00:40,  2.82it/s][A
 48%|████▊     | 107/221 [00:29<00:35,  3.22it/s][A
 49%|████▉     | 108/221 [00:29<00:33,  3.39it/s][A
 49%|████▉     | 109/221 [00:29<00:26,  4.20it/s][A
 50%|████▉     | 110/221 [00:30<00:26,  4.26it/s][A
 50%|█████     | 111/221 [00:30<00:27,  4.00it/s][A
 51%|█████     | 112/221 [00:30<00:27,  3.98it/s][A
 51%|█████     | 113/221 [00:30<00:24,  4.48it/s][A
 52%|█████▏    | 115/221 [00:31<00:20,  5.14it/s][A
 52%|█████▏    | 116/221 [00:31<00:22,  4.72it/s][A
 53%|█████▎    | 117/221 [00:31<00:23,  4.46it/s][A
 53%|█████▎    | 118/221 [00:31<00:23,  4.45it/s][A
 54%|█████▍    | 119/221 [00:32<00:28,  3.61it/s][A
 54%|█████▍    | 120/221 [00:32<00:25,  4.01it/s][A
 55%|█████▍    | 121/221 [00:32<00:21,  4.73it/s][A
 55%|█████▌    | 122/221 [00:32<00:22,  4.34it/s][A
 56%|█████▌    | 123/221 [00:33<00:24,  4.06it/s][A
 56%|█████▌    | 124/221 [00:33<00:24,  4.00it/s][A
 57%|█████▋    | 125/221 [00:33<00:27,  3.46it/s][A
 57%|█████▋    | 126/221 [00:34<00:25,  3.75it/s][A
 57%|█████▋    | 127/221 [00:34<00:29,  3.19it/s][A
 58%|█████▊    | 128/221 [00:34<00:26,  3.46it/s][A
 58%|█████▊    | 129/221 [00:34<00:22,  4.05it/s][A
 59%|█████▉    | 130/221 [00:35<00:24,  3.67it/s][A
 59%|█████▉    | 131/221 [00:35<00:19,  4.52it/s][A
 60%|█████▉    | 132/221 [00:35<00:22,  3.91it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.72it/s][A
 61%|██████    | 134/221 [00:36<00:29,  2.94it/s][A
 61%|██████    | 135/221 [00:36<00:29,  2.93it/s][A
 62%|██████▏   | 136/221 [00:36<00:25,  3.28it/s][A
 62%|██████▏   | 137/221 [00:37<00:21,  3.85it/s][A
 62%|██████▏   | 138/221 [00:37<00:22,  3.66it/s][A
 63%|██████▎   | 139/221 [00:38<00:29,  2.75it/s][A
 63%|██████▎   | 140/221 [00:38<00:27,  2.89it/s][A
 64%|██████▍   | 141/221 [00:38<00:24,  3.29it/s][A
 64%|██████▍   | 142/221 [00:38<00:21,  3.67it/s][A
 65%|██████▍   | 143/221 [00:39<00:28,  2.75it/s][A
 65%|██████▌   | 144/221 [00:39<00:28,  2.72it/s][A
 66%|██████▌   | 146/221 [00:39<00:17,  4.26it/s][A
 67%|██████▋   | 147/221 [00:40<00:18,  4.08it/s][A
 67%|██████▋   | 148/221 [00:40<00:22,  3.30it/s][A
 67%|██████▋   | 149/221 [00:40<00:21,  3.34it/s][A
 68%|██████▊   | 150/221 [00:41<00:19,  3.60it/s][A
 68%|██████▊   | 151/221 [00:41<00:22,  3.12it/s][A
 69%|██████▉   | 152/221 [00:42<00:33,  2.05it/s][A
 69%|██████▉   | 153/221 [00:42<00:26,  2.56it/s][A
 70%|██████▉   | 154/221 [00:42<00:21,  3.05it/s][A
 70%|███████   | 155/221 [00:42<00:19,  3.34it/s][A
 71%|███████   | 156/221 [00:43<00:21,  2.96it/s][A
 71%|███████   | 157/221 [00:43<00:20,  3.05it/s][A
 71%|███████▏  | 158/221 [00:43<00:19,  3.20it/s][A
 72%|███████▏  | 159/221 [00:44<00:15,  3.93it/s][A
 72%|███████▏  | 160/221 [00:44<00:13,  4.38it/s][A
 73%|███████▎  | 161/221 [00:44<00:15,  3.96it/s][A
 73%|███████▎  | 162/221 [00:44<00:12,  4.67it/s][A
 74%|███████▍  | 163/221 [00:44<00:13,  4.44it/s][A
 74%|███████▍  | 164/221 [00:45<00:11,  5.14it/s][A
 75%|███████▍  | 165/221 [00:45<00:11,  5.04it/s][A
 75%|███████▌  | 166/221 [00:45<00:11,  4.79it/s][A
 76%|███████▌  | 167/221 [00:45<00:09,  5.63it/s][A
 76%|███████▌  | 168/221 [00:45<00:10,  5.04it/s][A
 76%|███████▋  | 169/221 [00:46<00:09,  5.66it/s][A
 77%|███████▋  | 170/221 [00:46<00:14,  3.64it/s][A
 77%|███████▋  | 171/221 [00:46<00:12,  3.87it/s][A
 78%|███████▊  | 172/221 [00:46<00:12,  4.02it/s][A
 78%|███████▊  | 173/221 [00:47<00:13,  3.59it/s][A
 79%|███████▊  | 174/221 [00:47<00:16,  2.84it/s][A
 79%|███████▉  | 175/221 [00:48<00:16,  2.87it/s][A
 80%|███████▉  | 176/221 [00:48<00:13,  3.23it/s][A
 80%|████████  | 177/221 [00:48<00:12,  3.57it/s][A
 81%|████████  | 178/221 [00:48<00:12,  3.48it/s][A
 81%|████████  | 179/221 [00:49<00:11,  3.67it/s][A
 81%|████████▏ | 180/221 [00:49<00:09,  4.32it/s][A
 82%|████████▏ | 181/221 [00:49<00:09,  4.24it/s][A
 82%|████████▏ | 182/221 [00:49<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:50<00:12,  3.04it/s][A
 83%|████████▎ | 184/221 [00:50<00:11,  3.31it/s][A
 84%|████████▎ | 185/221 [00:50<00:09,  3.80it/s][A
 84%|████████▍ | 186/221 [00:51<00:11,  2.96it/s][A
 85%|████████▍ | 187/221 [00:51<00:10,  3.36it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.35it/s][A
 86%|████████▌ | 189/221 [00:52<00:08,  3.59it/s][A
 86%|████████▌ | 190/221 [00:52<00:09,  3.27it/s][A
 86%|████████▋ | 191/221 [00:52<00:07,  3.81it/s][A
 87%|████████▋ | 192/221 [00:52<00:07,  3.82it/s][A
 88%|████████▊ | 194/221 [00:53<00:06,  4.32it/s][A
 88%|████████▊ | 195/221 [00:53<00:05,  4.34it/s][A
 89%|████████▊ | 196/221 [00:53<00:06,  3.57it/s][A
 89%|████████▉ | 197/221 [00:54<00:06,  3.77it/s][A
 90%|████████▉ | 198/221 [00:54<00:07,  3.08it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.51it/s][A
 90%|█████████ | 200/221 [00:55<00:07,  2.96it/s][A
 91%|█████████ | 201/221 [00:55<00:05,  3.40it/s][A
 91%|█████████▏| 202/221 [00:55<00:06,  3.11it/s][A
 92%|█████████▏| 203/221 [00:55<00:04,  3.61it/s][A
 92%|█████████▏| 204/221 [00:56<00:05,  3.17it/s][A
 93%|█████████▎| 206/221 [00:56<00:04,  3.41it/s][A
 94%|█████████▎| 207/221 [00:57<00:03,  3.81it/s][A
 94%|█████████▍| 208/221 [00:57<00:03,  3.74it/s][A
 95%|█████████▍| 209/221 [00:57<00:03,  3.87it/s][A
 95%|█████████▌| 210/221 [00:57<00:02,  4.53it/s][A
 95%|█████████▌| 211/221 [00:58<00:02,  3.96it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  3.78it/s][A
 96%|█████████▋| 213/221 [00:58<00:01,  4.08it/s][A
 97%|█████████▋| 214/221 [00:59<00:02,  2.51it/s][A
 97%|█████████▋| 215/221 [00:59<00:02,  2.97it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.09it/s][A
 98%|█████████▊| 217/221 [01:00<00:01,  3.11it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.30it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.25it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.64it/s][A
100%|██████████| 221/221 [01:01<00:00,  3.97it/s][A100%|██████████| 221/221 [01:01<00:00,  3.62it/s]
09/09/2024 21:58:10 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 899--===========

09/09/2024 21:58:10 - INFO - __main__ -   {'area_r1': 40.2, 'area_recall': '40.2/64.6/74.7', 'area_ravg': 59.8}
09/09/2024 21:58:10 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 899--===========

09/09/2024 21:58:10 - INFO - __main__ -   {'forward_r1': 37.1, 'forward_recall': '37.1/66.5/76.5', 'forward_ravg': 60.0}
09/09/2024 21:58:10 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 899--===========

09/09/2024 21:58:10 - INFO - __main__ -   {'area_video_r1': 38.1, 'area_video_recall': '38.1/66.1/77.0', 'area_video_ravg': 60.4}
09/09/2024 21:58:10 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/09/2024 21:58:10 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 21:58:10 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 899--===========

09/09/2024 21:58:10 - INFO - __main__ -   {'area_video_r1': 51.8, 'area_video_recall': '51.8/74.3/82.0', 'area_video_ravg': 69.4, 'area_video_back_r1': 49.1, 'area_video_back_recall': '49.1/74.0/82.2', 'area_video_back_ravg': 68.4}
09/09/2024 21:58:10 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/09/2024 21:58:10 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/09/2024 21:58:10 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 899--===========

09/09/2024 21:58:10 - INFO - __main__ -   {'video_r1': 43.0, 'video_recall': '43.0/71.3/82.0', 'video_ravg': 65.4}
09/09/2024 21:58:10 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 21:58:10 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 21:58:10 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 899--===========

09/09/2024 21:58:10 - INFO - __main__ -   {'video_r1': 51.0, 'video_recall': '51.0/74.5/82.1', 'video_ravg': 69.2}
09/09/2024 21:58:10 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/09/2024 21:58:10 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/09/2024 21:58:32 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.005716425366699696, 'loss_ret%tv%ta--finetune_area/loss_area': 0.9995777010917664, 'loss_ret%tv%ta--finetune_area/total_loss': 1.0052940845489502}
[h264 @ 0x559bf06b2f80] mmco: unref short failure
 46%|████▋     | 900/1945 [4:53:13<36:56:33, 127.27s/it] 46%|████▋     | 901/1945 [4:53:17<26:12:19, 90.36s/it] [h264 @ 0x55a04d29db40] mmco: unref short failure
[h264 @ 0x55a04d29db40] mmco: unref short failure
[h264 @ 0x56241a68a480] mmco: unref short failure
[h264 @ 0x56241a68a480] mmco: unref short failure
 46%|████▋     | 902/1945 [4:53:22<18:44:43, 64.70s/it] 46%|████▋     | 903/1945 [4:53:27<13:33:48, 46.86s/it][h264 @ 0x55a049788880] mmco: unref short failure
[h264 @ 0x55a049788880] mmco: unref short failure
[h264 @ 0x556b5097b0c0] mmco: unref short failure
[h264 @ 0x55a032e69580] mmco: unref short failure
[h264 @ 0x55a032e69580] mmco: unref short failure
[h264 @ 0x56242b2e7240] mmco: unref short failure
[h264 @ 0x562438993dc0] mmco: unref short failure
 46%|████▋     | 904/1945 [4:53:33<9:57:39, 34.45s/it] [h264 @ 0x556b431a5a40] mmco: unref short failure
 47%|████▋     | 905/1945 [4:53:39<7:28:51, 25.90s/it][h264 @ 0x559bf75c3e40] mmco: unref short failure
[h264 @ 0x559bf75c3e40] mmco: unref short failure
[h264 @ 0x556b2ec28000] mmco: unref short failure
[h264 @ 0x556b2ec28000] mmco: unref short failure
 47%|████▋     | 906/1945 [4:53:45<5:45:24, 19.95s/it][h264 @ 0x56242d029500] mmco: unref short failure
[h264 @ 0x56242d029500] mmco: unref short failure
[h264 @ 0x5624183f2080] mmco: unref short failure
 47%|████▋     | 907/1945 [4:53:51<4:36:36, 15.99s/it][h264 @ 0x556b344315c0] mmco: unref short failure
[h264 @ 0x556b451eb9c0] mmco: unref short failure
[h264 @ 0x562432c12700] mmco: unref short failure
[h264 @ 0x562432c12700] mmco: unref short failure
 47%|████▋     | 908/1945 [4:53:58<3:47:21, 13.15s/it] 47%|████▋     | 909/1945 [4:54:06<3:19:54, 11.58s/it][h264 @ 0x5624190c1180] mmco: unref short failure
 47%|████▋     | 910/1945 [4:54:14<3:00:25, 10.46s/it][h264 @ 0x556b44676640] mmco: unref short failure
[h264 @ 0x556b44676640] mmco: unref short failure
[h264 @ 0x556b41aabe00] mmco: unref short failure
[h264 @ 0x556b41aabe00] mmco: unref short failure
[h264 @ 0x559c023fad40] mmco: unref short failure
 47%|████▋     | 911/1945 [4:54:22<2:48:03,  9.75s/it] 47%|████▋     | 912/1945 [4:54:29<2:35:41,  9.04s/it][h264 @ 0x559bec9eb980] mmco: unref short failure
 47%|████▋     | 913/1945 [4:54:36<2:25:17,  8.45s/it][h264 @ 0x56241af43a80] mmco: unref short failure
[h264 @ 0x56241af43a80] mmco: unref short failure
[h264 @ 0x5624360ba100] mmco: unref short failure
[h264 @ 0x5624360ba100] mmco: unref short failure
[h264 @ 0x559c060f8900] mmco: unref short failure
[h264 @ 0x559c060f8900] mmco: unref short failure
 47%|████▋     | 914/1945 [4:54:43<2:15:25,  7.88s/it][h264 @ 0x556b31265780] mmco: unref short failure
[h264 @ 0x556b31265780] mmco: unref short failure
[h264 @ 0x5624382f9140] mmco: unref short failure
 47%|████▋     | 915/1945 [4:54:51<2:16:37,  7.96s/it][h264 @ 0x55a03c117d80] mmco: unref short failure
[h264 @ 0x562437c2f100] mmco: unref short failure
 47%|████▋     | 916/1945 [4:54:58<2:12:11,  7.71s/it][h264 @ 0x556b353d2c00] mmco: unref short failure
 47%|████▋     | 917/1945 [4:55:06<2:12:08,  7.71s/it] 47%|████▋     | 918/1945 [4:55:12<2:05:46,  7.35s/it][h264 @ 0x559bf7f63c40] mmco: unref short failure
[h264 @ 0x55a0426edc00] mmco: unref short failure
[h264 @ 0x55a0426edc00] mmco: unref short failure
[h264 @ 0x56241fa129c0] mmco: unref short failure
 47%|████▋     | 919/1945 [4:55:27<2:41:54,  9.47s/it][h264 @ 0x559c02dc7740] mmco: unref short failure
[h264 @ 0x556b428740c0] mmco: unref short failure
[h264 @ 0x56241e928e40] mmco: unref short failure
[h264 @ 0x56241e928e40] mmco: unref short failure
[h264 @ 0x556b4a81e780] mmco: unref short failure
[h264 @ 0x556b4a81e780] mmco: unref short failure
 47%|████▋     | 920/1945 [4:55:36<2:40:40,  9.41s/it][h264 @ 0x556b48c61080] mmco: unref short failure
[h264 @ 0x556b48c61080] mmco: unref short failure
 47%|████▋     | 921/1945 [4:55:44<2:33:24,  8.99s/it][h264 @ 0x559c015e2600] mmco: unref short failure
[h264 @ 0x559be97f2540] mmco: unref short failure
[h264 @ 0x559be97f2540] mmco: unref short failure
 47%|████▋     | 922/1945 [4:55:51<2:23:50,  8.44s/it][h264 @ 0x556b521830c0] mmco: unref short failure
[h264 @ 0x556b521830c0] mmco: unref short failure
[h264 @ 0x556b400cfd00] mmco: unref short failure
[h264 @ 0x559bff5bffc0] mmco: unref short failure
 47%|████▋     | 923/1945 [4:55:58<2:14:17,  7.88s/it][h264 @ 0x55a04efe92c0] mmco: unref short failure
[h264 @ 0x55a04efe92c0] mmco: unref short failure
[h264 @ 0x56242b82b440] mmco: unref short failure
[h264 @ 0x56242b82b440] mmco: unref short failure
[h264 @ 0x55a055ba3a00] mmco: unref short failure
[h264 @ 0x55a055ba3a00] mmco: unref short failure
[h264 @ 0x556b4abd7000] mmco: unref short failure
[h264 @ 0x559bf10dd7c0] mmco: unref short failure
[h264 @ 0x559bf10dd7c0] mmco: unref short failure
[h264 @ 0x559bf89b3ac0] mmco: unref short failure
[h264 @ 0x559bf89b3ac0] mmco: unref short failure
[h264 @ 0x559be97b5800] mmco: unref short failure
[h264 @ 0x559bf7f8ec00] mmco: unref short failure
[h264 @ 0x559be974e700] mmco: unref short failure
[h264 @ 0x559be974e700] mmco: unref short failure
[h264 @ 0x559be974e700] mmco: unref short failure
[h264 @ 0x559be974e700] mmco: unref short failure
[h264 @ 0x559bfc3f9dc0] mmco: unref short failure
[h264 @ 0x562423734b40] mmco: unref short failure
[h264 @ 0x562423734b40] mmco: unref short failure
[h264 @ 0x559bef6ae880] mmco: unref short failure
 48%|████▊     | 924/1945 [4:56:57<6:36:11, 23.28s/it][h264 @ 0x55a03c102d80] mmco: unref short failure
[h264 @ 0x559bfa0b0c80] mmco: unref short failure
[h264 @ 0x559bf2c78ac0] mmco: unref short failure
 48%|████▊     | 925/1945 [4:57:06<5:23:06, 19.01s/it][h264 @ 0x55a04424d540] mmco: unref short failure
[h264 @ 0x55a050eeadc0] mmco: unref short failure
 48%|████▊     | 926/1945 [4:57:13<4:20:37, 15.35s/it] 48%|████▊     | 927/1945 [4:57:28<4:17:56, 15.20s/it][h264 @ 0x562433ee6d80] mmco: unref short failure
[h264 @ 0x562433ee6d80] mmco: unref short failure
[h264 @ 0x55a03923bbc0] mmco: unref short failure
[h264 @ 0x55a03923bbc0] mmco: unref short failure
 48%|████▊     | 928/1945 [4:57:41<4:07:39, 14.61s/it][h264 @ 0x55a04f314500] mmco: unref short failure
 48%|████▊     | 929/1945 [4:57:51<3:42:55, 13.16s/it] 48%|████▊     | 930/1945 [4:57:58<3:12:10, 11.36s/it] 48%|████▊     | 931/1945 [4:58:06<2:57:45, 10.52s/it][h264 @ 0x562417a97c80] mmco: unref short failure
[h264 @ 0x56242b04cc40] mmco: unref short failure
[h264 @ 0x56242b04cc40] mmco: unref short failure
[h264 @ 0x559c07c07900] mmco: unref short failure
[h264 @ 0x559c07c07900] mmco: unref short failure
[h264 @ 0x559bf7ba2c00] mmco: unref short failure
[h264 @ 0x559bf420bcc0] mmco: unref short failure
[h264 @ 0x559bf420bcc0] mmco: unref short failure
[h264 @ 0x556b479e0fc0] mmco: unref short failure
[h264 @ 0x556b479e0fc0] mmco: unref short failure
[h264 @ 0x56241a3cce40] mmco: unref short failure
[h264 @ 0x56241c201f40] mmco: unref short failure
[h264 @ 0x56241c201f40] mmco: unref short failure
[h264 @ 0x559bf06beb40] mmco: unref short failure
[h264 @ 0x556b2e334e40] mmco: unref short failure
[h264 @ 0x556b2e334e40] mmco: unref short failure
[h264 @ 0x556b2e334e40] mmco: unref short failure
[h264 @ 0x556b2e334e40] mmco: unref short failure
[h264 @ 0x5624327747c0] mmco: unref short failure
 48%|████▊     | 932/1945 [4:58:59<6:32:20, 23.24s/it][h264 @ 0x556b44ad8980] mmco: unref short failure
[h264 @ 0x556b44ad8980] mmco: unref short failure
[h264 @ 0x56242e224880] mmco: unref short failure
[h264 @ 0x56242e224880] mmco: unref short failure
[h264 @ 0x56242e224880] mmco: unref short failure
[h264 @ 0x556b2f439d00] mmco: unref short failure
 48%|████▊     | 933/1945 [4:59:10<5:28:02, 19.45s/it][h264 @ 0x55a033185e00] mmco: unref short failure
[h264 @ 0x556b2ce03b80] mmco: unref short failure
 48%|████▊     | 934/1945 [4:59:17<4:25:19, 15.75s/it][h264 @ 0x5624185b3100] mmco: unref short failure
[h264 @ 0x5624185b3100] mmco: unref short failure
[h264 @ 0x556b2cfbe880] mmco: unref short failure
[h264 @ 0x556b2cfbe880] mmco: unref short failure
[h264 @ 0x559be91bc9c0] mmco: unref short failure
[h264 @ 0x56242c363dc0] mmco: unref short failure
[h264 @ 0x56242c363dc0] mmco: unref short failure
[h264 @ 0x556b5216d680] mmco: unref short failure
[h264 @ 0x556b35c26740] mmco: unref short failure
 48%|████▊     | 935/1945 [4:59:40<5:02:42, 17.98s/it][h264 @ 0x559be98ab140] mmco: unref short failure
[h264 @ 0x559be98ab140] mmco: unref short failure
[h264 @ 0x5624358f79c0] mmco: unref short failure
[h264 @ 0x55a056161ec0] mmco: unref short failure
 48%|████▊     | 936/1945 [4:59:47<4:06:40, 14.67s/it] 48%|████▊     | 937/1945 [4:59:56<3:36:36, 12.89s/it] 48%|████▊     | 938/1945 [5:00:04<3:10:27, 11.35s/it][h264 @ 0x55a04f674f00] mmco: unref short failure
[h264 @ 0x55a04f674f00] mmco: unref short failure
 48%|████▊     | 939/1945 [5:00:11<2:50:07, 10.15s/it][h264 @ 0x559c00b2c440] mmco: unref short failure
[h264 @ 0x55a035bedc80] mmco: unref short failure
[h264 @ 0x55a04dc93c00] mmco: unref short failure
[h264 @ 0x55a04dc93c00] mmco: unref short failure
[h264 @ 0x556b4cbeef80] mmco: unref short failure
[h264 @ 0x55a03e72e140] mmco: unref short failure
[h264 @ 0x55a03e72e140] mmco: unref short failure
[h264 @ 0x55a049826ec0] mmco: unref short failure
[h264 @ 0x55a042104e40] mmco: unref short failure
[h264 @ 0x55a042104e40] mmco: unref short failure
[h264 @ 0x559bf77b1800] mmco: unref short failure
[h264 @ 0x56241a3cc500] mmco: unref short failure
[h264 @ 0x559be9252f40] mmco: unref short failure
[h264 @ 0x559be9252f40] mmco: unref short failure
[h264 @ 0x56242f4a04c0] mmco: unref short failure
[h264 @ 0x56242f4a04c0] mmco: unref short failure
 48%|████▊     | 940/1945 [5:01:08<6:47:21, 24.32s/it][h264 @ 0x556b2d9f0b40] mmco: unref short failure
[h264 @ 0x556b2d9f0b40] mmco: unref short failure
[h264 @ 0x5624248a0b00] mmco: unref short failure
[h264 @ 0x5624248a0b00] mmco: unref short failure
[h264 @ 0x5624248a0b00] mmco: unref short failure
[h264 @ 0x5624248a0b00] mmco: unref short failure
[h264 @ 0x556b4c8f7dc0] mmco: unref short failure
 48%|████▊     | 941/1945 [5:01:15<5:19:57, 19.12s/it] 48%|████▊     | 942/1945 [5:01:24<4:25:58, 15.91s/it][h264 @ 0x559bec77fe40] mmco: unref short failure
[h264 @ 0x559bf2f7b680] mmco: unref short failure
[h264 @ 0x5624341cdb00] mmco: unref short failure
[h264 @ 0x5624341cdb00] mmco: unref short failure
[h264 @ 0x556b3c0922c0] mmco: unref short failure
[h264 @ 0x556b3c0922c0] mmco: unref short failure
[h264 @ 0x56241a758b80] mmco: unref short failure
[h264 @ 0x559beee3bac0] mmco: unref short failure
[h264 @ 0x559beee3bac0] mmco: unref short failure
[h264 @ 0x562436fb1600] mmco: unref short failure
 48%|████▊     | 943/1945 [5:01:42<4:38:03, 16.65s/it][h264 @ 0x562433020840] mmco: unref short failure
[h264 @ 0x55a034242140] mmco: unref short failure
[h264 @ 0x55a034242140] mmco: unref short failure
[h264 @ 0x556b2d722540] mmco: unref short failure
[h264 @ 0x556b2d722540] mmco: unref short failure
[h264 @ 0x55a034242140] mmco: unref short failure
[h264 @ 0x55a034242140] mmco: unref short failure
[h264 @ 0x55a03cb77100] mmco: unref short failure
 49%|████▊     | 944/1945 [5:01:50<3:51:57, 13.90s/it][h264 @ 0x56242e642c40] mmco: unref short failure
[h264 @ 0x56242e642c40] mmco: unref short failure
[h264 @ 0x55a0506c8d40] mmco: unref short failure
 49%|████▊     | 945/1945 [5:01:57<3:16:46, 11.81s/it][h264 @ 0x559bf558a080] mmco: unref short failure
[h264 @ 0x559bf558a080] mmco: unref short failure
 49%|████▊     | 946/1945 [5:02:03<2:50:02, 10.21s/it][h264 @ 0x55a033262f40] mmco: unref short failure
[h264 @ 0x55a033262f40] mmco: unref short failure
[h264 @ 0x556b3927a180] mmco: unref short failure
[h264 @ 0x5624248a0b00] mmco: unref short failure
[h264 @ 0x5624248a0b00] mmco: unref short failure
 49%|████▊     | 947/1945 [5:02:14<2:55:51, 10.57s/it][h264 @ 0x559bedf5d940] mmco: unref short failure
[h264 @ 0x5624224b7080] mmco: unref short failure
[h264 @ 0x5624224b7080] mmco: unref short failure
[h264 @ 0x556b4b32ab00] mmco: unref short failure
[h264 @ 0x556b4b32ab00] mmco: unref short failure
[h264 @ 0x556b3f426d40] mmco: unref short failure
[h264 @ 0x556b3f426d40] mmco: unref short failure
[h264 @ 0x559be8fc2c00] mmco: unref short failure
[h264 @ 0x559be8fc2c00] mmco: unref short failure
[h264 @ 0x556b2f87f100] mmco: unref short failure
[h264 @ 0x55a038bb8280] mmco: unref short failure
[h264 @ 0x556b4f88edc0] mmco: unref short failure
[h264 @ 0x55a056742dc0] mmco: unref short failure
 49%|████▊     | 948/1945 [5:03:15<7:06:46, 25.68s/it][h264 @ 0x556b41c9c080] mmco: unref short failure
[h264 @ 0x556b41c9c080] mmco: unref short failure
[h264 @ 0x55a032fd4080] mmco: unref short failure
[h264 @ 0x55a032fd4080] mmco: unref short failure
 49%|████▉     | 949/1945 [5:03:23<5:36:44, 20.29s/it]09/09/2024 22:08:45 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 22:08:45 - INFO - __main__ -   start running ret%tv validation...
[h264 @ 0x55a0510b4d40] mmco: unref short failure
[h264 @ 0x55a0510b4d40] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556b3254b940] mmco: unref short failure
[h264 @ 0x556b3254b940] mmco: unref short failure
[h264 @ 0x556b34abf080] mmco: unref short failure
[h264 @ 0x562417200080] mmco: unref short failure
[h264 @ 0x562417200080] mmco: unref short failure
[h264 @ 0x55a051fe11c0] mmco: unref short failure
[h264 @ 0x55a04eae4640] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559bed941b00] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556b49175a40] mmco: unref short failure
[h264 @ 0x556b49175a40] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559bed941b00] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559be9e96140] mmco: unref short failure
[h264 @ 0x559c09fcc880] mmco: unref short failure
[h264 @ 0x559c09423540] mmco: unref short failure
[h264 @ 0x559c09423540] mmco: unref short failure
[h264 @ 0x562418b14440] mmco: unref short failure
[h264 @ 0x559beec39d00] mmco: unref short failure
[h264 @ 0x559beec39d00] mmco: unref short failure
[h264 @ 0x5624396b9e00] mmco: unref short failure
[h264 @ 0x55a050132f40] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:33,  1.43it/s][A
  1%|          | 2/221 [00:01<02:05,  1.74it/s][A
  1%|▏         | 3/221 [00:01<01:33,  2.34it/s][A
  2%|▏         | 4/221 [00:01<01:25,  2.53it/s][A
  2%|▏         | 5/221 [00:02<01:13,  2.95it/s][A
  3%|▎         | 6/221 [00:02<01:06,  3.21it/s][A
  3%|▎         | 7/221 [00:02<01:04,  3.32it/s][A
  4%|▎         | 8/221 [00:03<01:26,  2.46it/s][A
  4%|▍         | 9/221 [00:03<01:13,  2.90it/s][A
  5%|▍         | 10/221 [00:03<01:18,  2.70it/s][A
  5%|▌         | 12/221 [00:04<01:07,  3.11it/s][A
  6%|▌         | 13/221 [00:04<01:01,  3.38it/s][A
  6%|▋         | 14/221 [00:07<03:17,  1.05it/s][A
  7%|▋         | 15/221 [00:07<02:36,  1.32it/s][A
  7%|▋         | 16/221 [00:08<02:19,  1.47it/s][A
  8%|▊         | 17/221 [00:08<01:52,  1.81it/s][A
  8%|▊         | 18/221 [00:08<01:33,  2.17it/s][A
  9%|▊         | 19/221 [00:08<01:13,  2.73it/s][A
  9%|▉         | 20/221 [00:08<00:58,  3.46it/s][A
 10%|▉         | 21/221 [00:08<00:50,  3.94it/s][A
 10%|▉         | 22/221 [00:09<00:48,  4.07it/s][A
 10%|█         | 23/221 [00:09<00:41,  4.72it/s][A
 11%|█         | 24/221 [00:09<00:36,  5.35it/s][A
 11%|█▏        | 25/221 [00:09<00:36,  5.31it/s][A
 12%|█▏        | 26/221 [00:09<00:40,  4.80it/s][A
 13%|█▎        | 28/221 [00:10<00:39,  4.93it/s][A
 14%|█▎        | 30/221 [00:10<00:34,  5.51it/s][A
 14%|█▍        | 31/221 [00:10<00:36,  5.17it/s][A
 15%|█▍        | 33/221 [00:11<00:37,  5.08it/s][A
 15%|█▌        | 34/221 [00:11<00:33,  5.51it/s][A
 16%|█▌        | 35/221 [00:11<00:32,  5.78it/s][A
 16%|█▋        | 36/221 [00:11<00:34,  5.31it/s][A
 17%|█▋        | 37/221 [00:12<00:51,  3.57it/s][A
 17%|█▋        | 38/221 [00:12<00:56,  3.26it/s][A
 18%|█▊        | 39/221 [00:12<00:47,  3.80it/s][A
 18%|█▊        | 40/221 [00:13<00:46,  3.91it/s][A
 19%|█▊        | 41/221 [00:13<00:38,  4.71it/s][A
 19%|█▉        | 42/221 [00:13<00:45,  3.92it/s][A
 19%|█▉        | 43/221 [00:13<00:39,  4.51it/s][A
 20%|█▉        | 44/221 [00:13<00:39,  4.52it/s][A
 20%|██        | 45/221 [00:15<01:29,  1.97it/s][A
 21%|██        | 46/221 [00:15<01:19,  2.19it/s][A
 21%|██▏       | 47/221 [00:16<01:44,  1.66it/s][A
 22%|██▏       | 49/221 [00:16<01:03,  2.72it/s][A
 23%|██▎       | 51/221 [00:16<00:48,  3.54it/s][A
 24%|██▎       | 52/221 [00:17<00:47,  3.56it/s][A
 24%|██▍       | 53/221 [00:17<00:42,  3.91it/s][A
 24%|██▍       | 54/221 [00:18<01:03,  2.64it/s][A
 25%|██▍       | 55/221 [00:18<01:01,  2.70it/s][A
 25%|██▌       | 56/221 [00:18<00:53,  3.10it/s][A
 26%|██▌       | 57/221 [00:18<00:44,  3.69it/s][A
 26%|██▌       | 58/221 [00:18<00:38,  4.21it/s][A
 27%|██▋       | 59/221 [00:19<00:36,  4.49it/s][A
 27%|██▋       | 60/221 [00:19<00:45,  3.53it/s][A
 28%|██▊       | 61/221 [00:19<00:43,  3.69it/s][A
 28%|██▊       | 62/221 [00:20<00:45,  3.50it/s][A
 29%|██▊       | 63/221 [00:20<00:41,  3.84it/s][A
 29%|██▉       | 64/221 [00:20<00:44,  3.53it/s][A
 29%|██▉       | 65/221 [00:20<00:37,  4.19it/s][A
 30%|██▉       | 66/221 [00:21<00:43,  3.56it/s][A
 30%|███       | 67/221 [00:21<00:44,  3.44it/s][A
 31%|███       | 68/221 [00:21<00:42,  3.64it/s][A
 31%|███       | 69/221 [00:22<00:54,  2.76it/s][A
 32%|███▏      | 70/221 [00:22<00:43,  3.48it/s][A
 32%|███▏      | 71/221 [00:23<01:16,  1.96it/s][A[h264 @ 0x559bec8eebc0] mmco: unref short failure
[h264 @ 0x559bec8eebc0] mmco: unref short failure
[h264 @ 0x559bec8eebc0] mmco: unref short failure

 33%|███▎      | 72/221 [00:23<01:08,  2.19it/s][A
 33%|███▎      | 73/221 [00:23<01:00,  2.43it/s][A
 33%|███▎      | 74/221 [00:24<00:48,  3.05it/s][A[h264 @ 0x556b4af67dc0] mmco: unref short failure
[h264 @ 0x556b4af67dc0] mmco: unref short failure

 34%|███▍      | 75/221 [00:24<00:46,  3.15it/s][A
 34%|███▍      | 76/221 [00:24<00:39,  3.67it/s][A
 35%|███▍      | 77/221 [00:24<00:36,  3.97it/s][A
 35%|███▌      | 78/221 [00:25<00:38,  3.71it/s][A[h264 @ 0x556b30f9d440] mmco: unref short failure
[h264 @ 0x556b30f9d440] mmco: unref short failure

 36%|███▌      | 79/221 [00:26<01:08,  2.07it/s][A
 36%|███▌      | 80/221 [00:26<00:55,  2.55it/s][A
 37%|███▋      | 81/221 [00:26<00:50,  2.75it/s][A
 37%|███▋      | 82/221 [00:26<00:43,  3.17it/s][A
 38%|███▊      | 83/221 [00:26<00:37,  3.70it/s][A
 38%|███▊      | 84/221 [00:27<00:31,  4.29it/s][A
 39%|███▉      | 86/221 [00:27<00:24,  5.42it/s][A
 39%|███▉      | 87/221 [00:27<00:37,  3.54it/s][A
 40%|███▉      | 88/221 [00:28<00:39,  3.34it/s][A[h264 @ 0x55a039391f80] mmco: unref short failure
[h264 @ 0x55a039391f80] mmco: unref short failure

 40%|████      | 89/221 [00:30<01:35,  1.38it/s][A
 41%|████      | 90/221 [00:30<01:16,  1.71it/s][A
 41%|████      | 91/221 [00:30<00:58,  2.22it/s][A
 42%|████▏     | 92/221 [00:30<00:47,  2.71it/s][A
 42%|████▏     | 93/221 [00:31<00:52,  2.45it/s][A
 43%|████▎     | 94/221 [00:31<00:45,  2.79it/s][A
 43%|████▎     | 95/221 [00:31<00:38,  3.28it/s][A
 43%|████▎     | 96/221 [00:31<00:38,  3.28it/s][A
 44%|████▍     | 98/221 [00:32<00:29,  4.10it/s][A
 45%|████▍     | 99/221 [00:32<00:25,  4.72it/s][A
 45%|████▌     | 100/221 [00:32<00:25,  4.78it/s][A
 46%|████▌     | 101/221 [00:32<00:21,  5.49it/s][A
 46%|████▌     | 102/221 [00:32<00:25,  4.64it/s][A
 47%|████▋     | 103/221 [00:33<00:22,  5.16it/s][A
 47%|████▋     | 104/221 [00:33<00:23,  5.01it/s][A
 48%|████▊     | 105/221 [00:33<00:25,  4.63it/s][A
 48%|████▊     | 106/221 [00:34<00:42,  2.68it/s][A
 48%|████▊     | 107/221 [00:34<00:33,  3.37it/s][A
 49%|████▉     | 108/221 [00:34<00:31,  3.57it/s][A
 49%|████▉     | 109/221 [00:35<00:41,  2.70it/s][A
 50%|████▉     | 110/221 [00:35<00:43,  2.56it/s][A
 50%|█████     | 111/221 [00:36<00:45,  2.42it/s][A
 51%|█████     | 112/221 [00:36<00:38,  2.87it/s][A
 51%|█████     | 113/221 [00:36<00:38,  2.81it/s][A
 52%|█████▏    | 115/221 [00:36<00:24,  4.28it/s][A[h264 @ 0x556b35b51500] mmco: unref short failure
[h264 @ 0x556b35b51500] mmco: unref short failure

 52%|█████▏    | 116/221 [00:40<01:47,  1.03s/it][A
 53%|█████▎    | 117/221 [00:40<01:27,  1.19it/s][A
 53%|█████▎    | 118/221 [00:40<01:11,  1.44it/s][A
 54%|█████▍    | 119/221 [00:41<00:54,  1.87it/s][A
 54%|█████▍    | 120/221 [00:41<00:45,  2.21it/s][A
 55%|█████▌    | 122/221 [00:41<00:30,  3.27it/s][A
 56%|█████▌    | 123/221 [00:41<00:25,  3.82it/s][A
 56%|█████▌    | 124/221 [00:41<00:23,  4.10it/s][A
 57%|█████▋    | 125/221 [00:42<00:23,  4.01it/s][A
 57%|█████▋    | 126/221 [00:42<00:25,  3.66it/s][A
 57%|█████▋    | 127/221 [00:42<00:28,  3.26it/s][A
 58%|█████▊    | 128/221 [00:43<00:28,  3.31it/s][A
 58%|█████▊    | 129/221 [00:43<00:25,  3.57it/s][A
 59%|█████▉    | 130/221 [00:43<00:23,  3.94it/s][A
 60%|█████▉    | 132/221 [00:43<00:18,  4.92it/s][A[h264 @ 0x55a033e55b00] mmco: unref short failure
[h264 @ 0x55a033e55b00] mmco: unref short failure

 60%|██████    | 133/221 [00:44<00:22,  3.94it/s][A
 61%|██████    | 134/221 [00:44<00:23,  3.73it/s][A
 61%|██████    | 135/221 [00:44<00:25,  3.40it/s][A[h264 @ 0x55a036174340] mmco: unref short failure

 62%|██████▏   | 136/221 [00:45<00:26,  3.22it/s][A
 62%|██████▏   | 137/221 [00:45<00:22,  3.66it/s][A
 62%|██████▏   | 138/221 [00:45<00:24,  3.33it/s][A
 63%|██████▎   | 139/221 [00:46<00:23,  3.49it/s][A
 63%|██████▎   | 140/221 [00:46<00:25,  3.22it/s][A
 64%|██████▍   | 141/221 [00:46<00:22,  3.60it/s][A
 64%|██████▍   | 142/221 [00:47<00:29,  2.71it/s][A
 65%|██████▍   | 143/221 [00:47<00:29,  2.62it/s][A
 65%|██████▌   | 144/221 [00:47<00:23,  3.25it/s][A
 66%|██████▌   | 146/221 [00:47<00:15,  4.98it/s][A
 67%|██████▋   | 147/221 [00:48<00:13,  5.32it/s][A[h264 @ 0x556b4fc77200] mmco: unref short failure
[h264 @ 0x556b4fc77200] mmco: unref short failure
[h264 @ 0x556b4fc77200] mmco: unref short failure
[h264 @ 0x556b4fc77200] mmco: unref short failure
[h264 @ 0x556b4fc77200] mmco: unref short failure

 67%|██████▋   | 148/221 [00:48<00:15,  4.80it/s][A[h264 @ 0x556b33e8fd80] mmco: unref short failure
[h264 @ 0x556b33e8fd80] mmco: unref short failure

 67%|██████▋   | 149/221 [00:48<00:12,  5.56it/s][A
 68%|██████▊   | 150/221 [00:48<00:11,  6.01it/s][A
 68%|██████▊   | 151/221 [00:49<00:23,  2.98it/s][A
 69%|██████▉   | 152/221 [00:49<00:21,  3.28it/s][A
 69%|██████▉   | 153/221 [00:49<00:21,  3.24it/s][A
 70%|██████▉   | 154/221 [00:50<00:22,  2.92it/s][A
 71%|███████   | 156/221 [00:50<00:15,  4.24it/s][A[h264 @ 0x556b3ee09780] mmco: unref short failure
[h264 @ 0x556b3ee09780] mmco: unref short failure
[h264 @ 0x556b3ee09780] mmco: unref short failure
[h264 @ 0x556b3ee09780] mmco: unref short failure

 71%|███████   | 157/221 [00:52<00:40,  1.60it/s][A
 71%|███████▏  | 158/221 [00:52<00:31,  1.99it/s][A
 72%|███████▏  | 159/221 [00:52<00:25,  2.43it/s][A
 72%|███████▏  | 160/221 [00:52<00:20,  2.91it/s][A
 73%|███████▎  | 161/221 [00:52<00:16,  3.60it/s][A
 73%|███████▎  | 162/221 [00:53<00:14,  4.03it/s][A
 74%|███████▍  | 163/221 [00:53<00:14,  4.07it/s][A
 74%|███████▍  | 164/221 [00:53<00:12,  4.61it/s][A[h264 @ 0x56241670ffc0] mmco: unref short failure
[h264 @ 0x56241670ffc0] mmco: unref short failure

 75%|███████▍  | 165/221 [00:53<00:10,  5.46it/s][A
 75%|███████▌  | 166/221 [00:53<00:13,  4.17it/s][A
 76%|███████▌  | 167/221 [00:54<00:11,  4.75it/s][A[h264 @ 0x559beec39d00] mmco: unref short failure
[h264 @ 0x55a04f1d8c80] mmco: unref short failure

 76%|███████▌  | 168/221 [00:58<01:10,  1.32s/it][A
 76%|███████▋  | 169/221 [00:58<00:51,  1.02it/s][A
 77%|███████▋  | 170/221 [00:58<00:38,  1.31it/s][A
 77%|███████▋  | 171/221 [00:58<00:29,  1.70it/s][A
 78%|███████▊  | 172/221 [00:58<00:24,  2.03it/s][A
 79%|███████▊  | 174/221 [00:59<00:14,  3.23it/s][A
 79%|███████▉  | 175/221 [00:59<00:13,  3.41it/s][A
 80%|███████▉  | 176/221 [00:59<00:12,  3.67it/s][A
 80%|████████  | 177/221 [00:59<00:10,  4.37it/s][A
 81%|████████  | 178/221 [01:00<00:11,  3.63it/s][A[h264 @ 0x559c09975980] mmco: unref short failure
[h264 @ 0x559c09975980] mmco: unref short failure

 81%|████████  | 179/221 [01:00<00:13,  3.06it/s][A
 82%|████████▏ | 181/221 [01:00<00:09,  4.21it/s][A
 82%|████████▏ | 182/221 [01:00<00:08,  4.72it/s][A
 83%|████████▎ | 183/221 [01:01<00:08,  4.74it/s][A
 83%|████████▎ | 184/221 [01:01<00:08,  4.17it/s][A
 84%|████████▎ | 185/221 [01:01<00:08,  4.31it/s][A
 84%|████████▍ | 186/221 [01:02<00:09,  3.52it/s][A
 85%|████████▍ | 187/221 [01:02<00:08,  4.23it/s][A
 85%|████████▌ | 188/221 [01:02<00:09,  3.54it/s][A
 86%|████████▌ | 189/221 [01:02<00:08,  3.87it/s][A
 86%|████████▌ | 190/221 [01:03<00:07,  3.93it/s][A
 87%|████████▋ | 192/221 [01:03<00:05,  5.11it/s][A
 88%|████████▊ | 194/221 [01:03<00:06,  4.29it/s][A
 88%|████████▊ | 195/221 [01:04<00:05,  4.76it/s][A
 89%|████████▉ | 197/221 [01:04<00:03,  6.09it/s][A
 90%|████████▉ | 198/221 [01:04<00:04,  5.23it/s][A
 90%|█████████ | 199/221 [01:04<00:03,  5.70it/s][A
 90%|█████████ | 200/221 [01:04<00:04,  4.67it/s][A
 91%|█████████ | 201/221 [01:05<00:04,  4.83it/s][A
 91%|█████████▏| 202/221 [01:05<00:03,  5.07it/s][A
 92%|█████████▏| 204/221 [01:05<00:02,  6.52it/s][A
 93%|█████████▎| 206/221 [01:06<00:03,  4.30it/s][A
 94%|█████████▍| 208/221 [01:06<00:02,  5.43it/s][A
 95%|█████████▌| 210/221 [01:06<00:01,  7.00it/s][A
 95%|█████████▌| 211/221 [01:06<00:01,  5.59it/s][A
 96%|█████████▌| 212/221 [01:06<00:01,  6.11it/s][A
 97%|█████████▋| 214/221 [01:07<00:01,  4.48it/s][A
 97%|█████████▋| 215/221 [01:07<00:01,  4.77it/s][A
 98%|█████████▊| 216/221 [01:07<00:01,  4.77it/s][A
 98%|█████████▊| 217/221 [01:08<00:01,  3.50it/s][A
 99%|█████████▊| 218/221 [01:08<00:00,  3.77it/s][A
 99%|█████████▉| 219/221 [01:08<00:00,  4.02it/s][A
100%|█████████▉| 220/221 [01:12<00:01,  1.15s/it][A
100%|██████████| 221/221 [01:12<00:00,  1.13it/s][A100%|██████████| 221/221 [01:12<00:00,  3.05it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:51,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:22<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:37<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:51<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:32,  6.72it/s][A
  1%|          | 2/221 [00:00<00:45,  4.78it/s][A
  1%|▏         | 3/221 [00:00<00:52,  4.16it/s][A
  2%|▏         | 4/221 [00:00<00:44,  4.84it/s][A
  2%|▏         | 5/221 [00:00<00:41,  5.21it/s][A
  3%|▎         | 7/221 [00:01<00:39,  5.44it/s][A
  4%|▎         | 8/221 [00:01<00:45,  4.64it/s][A
  4%|▍         | 9/221 [00:01<00:45,  4.63it/s][A
  5%|▍         | 10/221 [00:02<01:05,  3.24it/s][A
  5%|▍         | 11/221 [00:02<00:57,  3.65it/s][A
  5%|▌         | 12/221 [00:02<00:49,  4.21it/s][A
  6%|▌         | 13/221 [00:03<01:26,  2.39it/s][A
  7%|▋         | 15/221 [00:03<01:01,  3.34it/s][A
  7%|▋         | 16/221 [00:04<01:04,  3.16it/s][A
  8%|▊         | 17/221 [00:04<01:20,  2.54it/s][A
  8%|▊         | 18/221 [00:05<01:09,  2.90it/s][A
  9%|▊         | 19/221 [00:05<01:00,  3.36it/s][A
 10%|▉         | 21/221 [00:05<00:43,  4.58it/s][A
 10%|▉         | 22/221 [00:05<00:40,  4.91it/s][A
 11%|█         | 24/221 [00:05<00:33,  5.80it/s][A
 11%|█▏        | 25/221 [00:06<00:34,  5.70it/s][A
 12%|█▏        | 26/221 [00:06<00:35,  5.44it/s][A
 12%|█▏        | 27/221 [00:06<00:33,  5.72it/s][A
 13%|█▎        | 28/221 [00:06<00:39,  4.90it/s][A
 13%|█▎        | 29/221 [00:07<00:42,  4.53it/s][A
 14%|█▎        | 30/221 [00:07<00:46,  4.13it/s][A
 14%|█▍        | 31/221 [00:07<00:44,  4.27it/s][A
 15%|█▍        | 33/221 [00:07<00:35,  5.25it/s][A
 15%|█▌        | 34/221 [00:07<00:34,  5.36it/s][A
 16%|█▌        | 35/221 [00:08<00:41,  4.44it/s][A
 16%|█▋        | 36/221 [00:08<00:45,  4.04it/s][A
 17%|█▋        | 37/221 [00:08<00:40,  4.49it/s][A
 17%|█▋        | 38/221 [00:09<00:42,  4.29it/s][A
 18%|█▊        | 39/221 [00:09<00:38,  4.73it/s][A
 18%|█▊        | 40/221 [00:09<00:46,  3.86it/s][A
 19%|█▊        | 41/221 [00:09<00:39,  4.55it/s][A
 19%|█▉        | 42/221 [00:09<00:36,  4.93it/s][A
 19%|█▉        | 43/221 [00:10<00:44,  4.03it/s][A
 20%|█▉        | 44/221 [00:10<00:45,  3.90it/s][A
 20%|██        | 45/221 [00:10<00:47,  3.73it/s][A
 21%|██        | 46/221 [00:10<00:41,  4.23it/s][A
 21%|██▏       | 47/221 [00:11<00:40,  4.28it/s][A
 22%|██▏       | 48/221 [00:11<00:36,  4.74it/s][A
 22%|██▏       | 49/221 [00:11<00:36,  4.68it/s][A
 23%|██▎       | 50/221 [00:12<00:47,  3.56it/s][A
 23%|██▎       | 51/221 [00:12<00:42,  3.96it/s][A
 24%|██▎       | 52/221 [00:12<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:12<00:38,  4.33it/s][A
 24%|██▍       | 54/221 [00:13<00:54,  3.08it/s][A
 25%|██▍       | 55/221 [00:13<00:48,  3.45it/s][A
 25%|██▌       | 56/221 [00:13<00:40,  4.04it/s][A
 26%|██▌       | 57/221 [00:13<00:41,  3.99it/s][A
 26%|██▌       | 58/221 [00:14<00:48,  3.34it/s][A
 27%|██▋       | 59/221 [00:14<00:43,  3.70it/s][A
 27%|██▋       | 60/221 [00:14<00:41,  3.92it/s][A
 28%|██▊       | 61/221 [00:14<00:36,  4.40it/s][A
 28%|██▊       | 62/221 [00:15<00:38,  4.09it/s][A
 29%|██▊       | 63/221 [00:15<00:35,  4.39it/s][A
 29%|██▉       | 64/221 [00:15<00:46,  3.36it/s][A
 29%|██▉       | 65/221 [00:15<00:40,  3.84it/s][A
 30%|██▉       | 66/221 [00:16<00:51,  3.03it/s][A
 30%|███       | 67/221 [00:16<00:55,  2.79it/s][A
 31%|███       | 68/221 [00:16<00:46,  3.32it/s][A
 31%|███       | 69/221 [00:17<01:07,  2.27it/s][A
 32%|███▏      | 70/221 [00:17<00:51,  2.95it/s][A
 32%|███▏      | 71/221 [00:18<00:44,  3.34it/s][A
 33%|███▎      | 72/221 [00:18<00:53,  2.81it/s][A
 33%|███▎      | 73/221 [00:18<00:51,  2.90it/s][A
 33%|███▎      | 74/221 [00:19<00:42,  3.45it/s][A
 34%|███▍      | 75/221 [00:19<00:41,  3.54it/s][A
 34%|███▍      | 76/221 [00:19<00:38,  3.80it/s][A
 35%|███▍      | 77/221 [00:19<00:41,  3.49it/s][A
 35%|███▌      | 78/221 [00:20<00:36,  3.96it/s][A
 36%|███▌      | 79/221 [00:20<00:45,  3.15it/s][A
 36%|███▌      | 80/221 [00:20<00:38,  3.62it/s][A
 37%|███▋      | 81/221 [00:20<00:37,  3.78it/s][A
 37%|███▋      | 82/221 [00:21<00:40,  3.41it/s][A
 38%|███▊      | 83/221 [00:21<00:44,  3.10it/s][A
 38%|███▊      | 84/221 [00:21<00:41,  3.32it/s][A
 38%|███▊      | 85/221 [00:22<00:33,  4.10it/s][A
 39%|███▉      | 86/221 [00:22<00:37,  3.61it/s][A
 39%|███▉      | 87/221 [00:22<00:48,  2.75it/s][A
 40%|███▉      | 88/221 [00:23<00:53,  2.49it/s][A
 40%|████      | 89/221 [00:23<00:48,  2.73it/s][A
 41%|████      | 90/221 [00:24<00:49,  2.63it/s][A
 41%|████      | 91/221 [00:24<00:39,  3.27it/s][A
 42%|████▏     | 92/221 [00:24<00:41,  3.09it/s][A
 42%|████▏     | 93/221 [00:25<00:58,  2.17it/s][A
 43%|████▎     | 94/221 [00:25<00:51,  2.47it/s][A
 43%|████▎     | 95/221 [00:25<00:45,  2.77it/s][A
 43%|████▎     | 96/221 [00:26<00:41,  3.02it/s][A
 44%|████▍     | 97/221 [00:26<00:35,  3.52it/s][A
 44%|████▍     | 98/221 [00:26<00:35,  3.50it/s][A
 45%|████▍     | 99/221 [00:26<00:30,  3.96it/s][A
 45%|████▌     | 100/221 [00:27<00:29,  4.05it/s][A
 46%|████▌     | 101/221 [00:27<00:30,  3.97it/s][A
 46%|████▌     | 102/221 [00:28<00:45,  2.62it/s][A
 47%|████▋     | 103/221 [00:28<00:35,  3.30it/s][A
 47%|████▋     | 104/221 [00:28<00:32,  3.63it/s][A
 48%|████▊     | 105/221 [00:28<00:30,  3.81it/s][A
 48%|████▊     | 106/221 [00:29<00:37,  3.08it/s][A
 48%|████▊     | 107/221 [00:29<00:32,  3.49it/s][A
 49%|████▉     | 108/221 [00:29<00:32,  3.49it/s][A
 49%|████▉     | 109/221 [00:29<00:26,  4.28it/s][A
 50%|████▉     | 110/221 [00:29<00:25,  4.30it/s][A
 50%|█████     | 111/221 [00:30<00:26,  4.13it/s][A
 51%|█████     | 112/221 [00:30<00:26,  4.08it/s][A
 51%|█████     | 113/221 [00:30<00:23,  4.59it/s][A
 52%|█████▏    | 115/221 [00:30<00:19,  5.44it/s][A
 52%|█████▏    | 116/221 [00:31<00:21,  4.83it/s][A
 53%|█████▎    | 117/221 [00:31<00:22,  4.60it/s][A
 53%|█████▎    | 118/221 [00:31<00:22,  4.55it/s][A
 54%|█████▍    | 119/221 [00:32<00:27,  3.64it/s][A
 54%|█████▍    | 120/221 [00:32<00:24,  4.12it/s][A
 55%|█████▍    | 121/221 [00:32<00:21,  4.73it/s][A
 55%|█████▌    | 122/221 [00:32<00:23,  4.30it/s][A
 56%|█████▌    | 123/221 [00:32<00:23,  4.23it/s][A
 56%|█████▌    | 124/221 [00:33<00:22,  4.39it/s][A
 57%|█████▋    | 125/221 [00:33<00:26,  3.56it/s][A
 57%|█████▋    | 126/221 [00:33<00:24,  3.90it/s][A
 57%|█████▋    | 127/221 [00:34<00:30,  3.05it/s][A
 58%|█████▊    | 128/221 [00:34<00:27,  3.34it/s][A
 58%|█████▊    | 129/221 [00:34<00:22,  4.05it/s][A
 59%|█████▉    | 130/221 [00:34<00:22,  3.97it/s][A
 59%|█████▉    | 131/221 [00:34<00:18,  4.84it/s][A
 60%|█████▉    | 132/221 [00:35<00:22,  3.89it/s][A
 60%|██████    | 133/221 [00:35<00:24,  3.64it/s][A
 61%|██████    | 134/221 [00:36<00:31,  2.72it/s][A
 61%|██████    | 135/221 [00:36<00:31,  2.69it/s][A
 62%|██████▏   | 136/221 [00:36<00:27,  3.05it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.70it/s][A
 62%|██████▏   | 138/221 [00:37<00:23,  3.55it/s][A
 63%|██████▎   | 139/221 [00:37<00:28,  2.90it/s][A
 63%|██████▎   | 140/221 [00:37<00:27,  2.98it/s][A
 64%|██████▍   | 141/221 [00:38<00:23,  3.38it/s][A
 64%|██████▍   | 142/221 [00:38<00:21,  3.73it/s][A
 65%|██████▍   | 143/221 [00:39<00:29,  2.67it/s][A
 65%|██████▌   | 144/221 [00:39<00:30,  2.54it/s][A
 66%|██████▌   | 146/221 [00:39<00:18,  4.02it/s][A
 67%|██████▋   | 147/221 [00:39<00:19,  3.88it/s][A
 67%|██████▋   | 148/221 [00:40<00:24,  2.98it/s][A
 67%|██████▋   | 149/221 [00:40<00:22,  3.16it/s][A
 68%|██████▊   | 150/221 [00:40<00:21,  3.37it/s][A
 68%|██████▊   | 151/221 [00:41<00:24,  2.89it/s][A
 69%|██████▉   | 152/221 [00:42<00:33,  2.08it/s][A
 69%|██████▉   | 153/221 [00:42<00:25,  2.65it/s][A
 70%|██████▉   | 154/221 [00:42<00:21,  3.12it/s][A
 70%|███████   | 155/221 [00:42<00:18,  3.49it/s][A
 71%|███████   | 156/221 [00:43<00:21,  3.05it/s][A
 71%|███████   | 157/221 [00:43<00:20,  3.11it/s][A
 71%|███████▏  | 158/221 [00:43<00:19,  3.24it/s][A
 72%|███████▏  | 159/221 [00:43<00:15,  3.95it/s][A
 72%|███████▏  | 160/221 [00:44<00:14,  4.20it/s][A
 73%|███████▎  | 161/221 [00:44<00:17,  3.44it/s][A
 73%|███████▎  | 162/221 [00:44<00:14,  4.12it/s][A
 74%|███████▍  | 163/221 [00:44<00:14,  4.10it/s][A
 74%|███████▍  | 164/221 [00:45<00:11,  4.80it/s][A
 75%|███████▍  | 165/221 [00:45<00:11,  4.83it/s][A
 75%|███████▌  | 166/221 [00:45<00:11,  4.74it/s][A
 76%|███████▌  | 167/221 [00:45<00:09,  5.54it/s][A
 76%|███████▌  | 168/221 [00:45<00:11,  4.77it/s][A
 76%|███████▋  | 169/221 [00:45<00:09,  5.49it/s][A
 77%|███████▋  | 170/221 [00:46<00:13,  3.70it/s][A
 77%|███████▋  | 171/221 [00:46<00:13,  3.67it/s][A
 78%|███████▊  | 172/221 [00:46<00:12,  3.92it/s][A
 78%|███████▊  | 173/221 [00:47<00:13,  3.43it/s][A
 79%|███████▊  | 174/221 [00:47<00:17,  2.72it/s][A
 79%|███████▉  | 175/221 [00:48<00:16,  2.84it/s][A
 80%|███████▉  | 176/221 [00:48<00:14,  3.18it/s][A
 80%|████████  | 177/221 [00:48<00:12,  3.57it/s][A
 81%|████████  | 178/221 [00:48<00:12,  3.39it/s][A
 81%|████████  | 179/221 [00:49<00:11,  3.59it/s][A
 81%|████████▏ | 180/221 [00:49<00:09,  4.15it/s][A
 82%|████████▏ | 181/221 [00:49<00:09,  4.03it/s][A
 82%|████████▏ | 182/221 [00:49<00:11,  3.48it/s][A
 83%|████████▎ | 183/221 [00:50<00:11,  3.24it/s][A
 83%|████████▎ | 184/221 [00:50<00:10,  3.49it/s][A
 84%|████████▎ | 185/221 [00:50<00:09,  3.89it/s][A
 84%|████████▍ | 186/221 [00:51<00:11,  3.02it/s][A
 85%|████████▍ | 187/221 [00:51<00:10,  3.40it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.37it/s][A
 86%|████████▌ | 189/221 [00:51<00:08,  3.60it/s][A
 86%|████████▌ | 190/221 [00:52<00:09,  3.23it/s][A
 86%|████████▋ | 191/221 [00:52<00:07,  3.89it/s][A
 87%|████████▋ | 192/221 [00:52<00:07,  3.88it/s][A
 87%|████████▋ | 193/221 [00:52<00:06,  4.63it/s][A
 88%|████████▊ | 194/221 [00:53<00:06,  3.97it/s][A
 88%|████████▊ | 195/221 [00:53<00:06,  4.19it/s][A
 89%|████████▊ | 196/221 [00:53<00:06,  3.58it/s][A
 89%|████████▉ | 197/221 [00:54<00:06,  3.68it/s][A
 90%|████████▉ | 198/221 [00:54<00:07,  3.03it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.43it/s][A
 90%|█████████ | 200/221 [00:55<00:06,  3.04it/s][A
 91%|█████████ | 201/221 [00:55<00:05,  3.52it/s][A
 91%|█████████▏| 202/221 [00:55<00:05,  3.21it/s][A
 92%|█████████▏| 203/221 [00:55<00:04,  3.68it/s][A
 92%|█████████▏| 204/221 [00:56<00:05,  3.13it/s][A
 93%|█████████▎| 205/221 [00:56<00:04,  3.94it/s][A
 93%|█████████▎| 206/221 [00:56<00:04,  3.44it/s][A
 94%|█████████▎| 207/221 [00:56<00:03,  3.93it/s][A
 94%|█████████▍| 208/221 [00:57<00:03,  4.20it/s][A
 95%|█████████▍| 209/221 [00:57<00:02,  4.27it/s][A
 95%|█████████▌| 210/221 [00:57<00:02,  5.01it/s][A
 95%|█████████▌| 211/221 [00:57<00:02,  4.21it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  3.66it/s][A
 96%|█████████▋| 213/221 [00:58<00:02,  3.99it/s][A
 97%|█████████▋| 214/221 [00:59<00:02,  2.38it/s][A
 97%|█████████▋| 215/221 [00:59<00:02,  2.78it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  2.97it/s][A
 98%|█████████▊| 217/221 [01:00<00:01,  3.02it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.03it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.15it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.60it/s][A
100%|██████████| 221/221 [01:01<00:00,  3.73it/s][A100%|██████████| 221/221 [01:01<00:00,  3.62it/s]
09/09/2024 22:14:28 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 949--===========

09/09/2024 22:14:28 - INFO - __main__ -   {'area_r1': 40.8, 'area_recall': '40.8/65.2/76.0', 'area_ravg': 60.7}
09/09/2024 22:14:28 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 949--===========

09/09/2024 22:14:28 - INFO - __main__ -   {'forward_r1': 37.9, 'forward_recall': '37.9/66.7/76.7', 'forward_ravg': 60.4}
09/09/2024 22:14:28 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 949--===========

09/09/2024 22:14:28 - INFO - __main__ -   {'area_video_r1': 37.6, 'area_video_recall': '37.6/65.5/77.0', 'area_video_ravg': 60.0}
09/09/2024 22:14:28 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/09/2024 22:14:28 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 22:14:28 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 949--===========

09/09/2024 22:14:28 - INFO - __main__ -   {'area_video_r1': 52.7, 'area_video_recall': '52.7/75.3/82.5', 'area_video_ravg': 70.2, 'area_video_back_r1': 48.4, 'area_video_back_recall': '48.4/74.9/81.9', 'area_video_back_ravg': 68.4}
09/09/2024 22:14:28 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/09/2024 22:14:28 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/09/2024 22:14:28 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 949--===========

09/09/2024 22:14:28 - INFO - __main__ -   {'video_r1': 43.4, 'video_recall': '43.4/71.8/81.8', 'video_ravg': 65.7}
09/09/2024 22:14:28 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 22:14:28 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 22:14:28 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 949--===========

09/09/2024 22:14:28 - INFO - __main__ -   {'video_r1': 52.4, 'video_recall': '52.4/75.8/83.0', 'video_ravg': 70.4}
09/09/2024 22:14:28 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/09/2024 22:14:28 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/09/2024 22:14:50 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.009486136958003044, 'loss_ret%tv%ta--finetune_area/loss_area': 1.0742521286010742, 'loss_ret%tv%ta--finetune_area/total_loss': 1.0837382078170776}
 49%|████▉     | 950/1945 [5:09:30<34:22:50, 124.39s/it][h264 @ 0x559be89399c0] mmco: unref short failure
[h264 @ 0x559be89399c0] mmco: unref short failure
 49%|████▉     | 951/1945 [5:09:35<24:23:27, 88.34s/it]  49%|████▉     | 952/1945 [5:09:40<17:28:29, 63.35s/it] 49%|████▉     | 953/1945 [5:09:45<12:38:17, 45.86s/it][h264 @ 0x559bf231d940] mmco: unref short failure
 49%|████▉     | 954/1945 [5:09:51<9:19:26, 33.87s/it] [h264 @ 0x559be90f0800] mmco: unref short failure
[h264 @ 0x559c03758540] mmco: unref short failure
[h264 @ 0x559c03758540] mmco: unref short failure
 49%|████▉     | 955/1945 [5:09:56<6:59:35, 25.43s/it][h264 @ 0x559bfbdfda80] mmco: unref short failure
[h264 @ 0x559bfbdfda80] mmco: unref short failure
 49%|████▉     | 956/1945 [5:10:03<5:25:02, 19.72s/it] 49%|████▉     | 957/1945 [5:10:10<4:23:22, 15.99s/it][h264 @ 0x56241738f740] mmco: unref short failure
[h264 @ 0x56241738f740] mmco: unref short failure
[h264 @ 0x56241e7298c0] mmco: unref short failure
[h264 @ 0x56241e7298c0] mmco: unref short failure
 49%|████▉     | 958/1945 [5:10:17<3:40:10, 13.38s/it][h264 @ 0x559be90f1240] mmco: unref short failure
[h264 @ 0x559be90f1240] mmco: unref short failure
[h264 @ 0x556b4eb4e9c0] mmco: unref short failure
[h264 @ 0x556b3c086c80] mmco: unref short failure
 49%|████▉     | 959/1945 [5:10:25<3:11:36, 11.66s/it][h264 @ 0x55a036e2d040] mmco: unref short failure
[h264 @ 0x55a036e2d040] mmco: unref short failure
 49%|████▉     | 960/1945 [5:10:32<2:50:23, 10.38s/it][h264 @ 0x559bfc7f41c0] mmco: unref short failure
 49%|████▉     | 961/1945 [5:10:40<2:39:07,  9.70s/it] 49%|████▉     | 962/1945 [5:10:49<2:32:15,  9.29s/it][h264 @ 0x559bea1250c0] mmco: unref short failure
[h264 @ 0x559bea1250c0] mmco: unref short failure
[h264 @ 0x559bea1250c0] mmco: unref short failure
 50%|████▉     | 963/1945 [5:10:56<2:22:57,  8.73s/it][h264 @ 0x562435dc2800] mmco: unref short failure
[h264 @ 0x562435dc2800] mmco: unref short failure
[h264 @ 0x556b2fd03e40] mmco: unref short failure
 50%|████▉     | 964/1945 [5:11:04<2:16:30,  8.35s/it] 50%|████▉     | 965/1945 [5:11:11<2:10:17,  7.98s/it][h264 @ 0x559bebd31940] mmco: unref short failure
[h264 @ 0x559bebd31940] mmco: unref short failure
[h264 @ 0x55a04ffd05c0] mmco: unref short failure
[h264 @ 0x55a04ffd05c0] mmco: unref short failure
[h264 @ 0x559bf2ed8d00] mmco: unref short failure
 50%|████▉     | 966/1945 [5:11:19<2:09:57,  7.96s/it][h264 @ 0x559be98129c0] mmco: unref short failure
[h264 @ 0x559be98129c0] mmco: unref short failure
[h264 @ 0x5624232fabc0] mmco: unref short failure
[h264 @ 0x5624232fabc0] mmco: unref short failure
[h264 @ 0x5624228e5bc0] mmco: unref short failure
 50%|████▉     | 967/1945 [5:11:26<2:06:22,  7.75s/it][h264 @ 0x556b5012ec80] mmco: unref short failure
[h264 @ 0x556b5012ec80] mmco: unref short failure
[h264 @ 0x559be95f1c80] mmco: unref short failure
[h264 @ 0x56241fb48c40] mmco: unref short failure
[h264 @ 0x56241fb48c40] mmco: unref short failure
[h264 @ 0x562421a01440] mmco: unref short failure
[h264 @ 0x562421a01440] mmco: unref short failure
[h264 @ 0x562421a01440] mmco: unref short failure
[h264 @ 0x56242259ee40] mmco: unref short failure
[h264 @ 0x55a054cf9380] mmco: unref short failure
[h264 @ 0x5624358e3680] mmco: unref short failure
 50%|████▉     | 968/1945 [5:11:34<2:08:20,  7.88s/it][h264 @ 0x556b2e916480] mmco: unref short failure
[h264 @ 0x559bec603cc0] mmco: unref short failure
[h264 @ 0x559bec603cc0] mmco: unref short failure
[h264 @ 0x5624191bb880] mmco: unref short failure
[h264 @ 0x559c09976280] mmco: unref short failure
[h264 @ 0x559c09976280] mmco: unref short failure
 50%|████▉     | 969/1945 [5:11:49<2:43:24, 10.05s/it][h264 @ 0x559c05093280] mmco: unref short failure
[h264 @ 0x559beee3b400] mmco: unref short failure
 50%|████▉     | 970/1945 [5:11:57<2:31:10,  9.30s/it][h264 @ 0x55a04262f380] mmco: unref short failure
[h264 @ 0x55a04262f380] mmco: unref short failure
 50%|████▉     | 971/1945 [5:12:05<2:24:23,  8.89s/it][h264 @ 0x55a03c077640] mmco: unref short failure
[h264 @ 0x55a03c077640] mmco: unref short failure
 50%|████▉     | 972/1945 [5:12:12<2:17:00,  8.45s/it] 50%|█████     | 973/1945 [5:12:20<2:13:06,  8.22s/it][h264 @ 0x559bef6e7800] mmco: unref short failure
[h264 @ 0x559bef6e7800] mmco: unref short failure
[h264 @ 0x56241e726b80] mmco: unref short failure
[h264 @ 0x559bef6e7800] mmco: unref short failure
[h264 @ 0x556b3e975000] mmco: unref short failure
[h264 @ 0x556b2d0ad380] mmco: unref short failure
[h264 @ 0x55a0363fce00] mmco: unref short failure
[h264 @ 0x55a0363fce00] mmco: unref short failure
[h264 @ 0x55a0363fce00] mmco: unref short failure
[h264 @ 0x55a0363fce00] mmco: unref short failure
[h264 @ 0x55a0363fce00] mmco: unref short failure
[h264 @ 0x55a0363fce00] mmco: unref short failure
[h264 @ 0x562435af1340] mmco: unref short failure
[h264 @ 0x55a0510b4f40] mmco: unref short failure
[h264 @ 0x55a0510b4f40] mmco: unref short failure
[h264 @ 0x55a0510b4f40] mmco: unref short failure
[h264 @ 0x55a0510b4f40] mmco: unref short failure
[h264 @ 0x556b2cf379c0] mmco: unref short failure
[h264 @ 0x556b2cf379c0] mmco: unref short failure
[h264 @ 0x55a0379dc800] mmco: unref short failure
[h264 @ 0x559bf2299700] mmco: unref short failure
[h264 @ 0x559bf2299700] mmco: unref short failure
[h264 @ 0x556b324d6140] mmco: unref short failure
[h264 @ 0x556b324d6140] mmco: unref short failure
[h264 @ 0x5624171b9ec0] mmco: unref short failure
[h264 @ 0x5624171b9ec0] mmco: unref short failure
[h264 @ 0x56241918a980] mmco: unref short failure
[h264 @ 0x56241918a980] mmco: unref short failure
[h264 @ 0x55a03dba0a00] mmco: unref short failure
[h264 @ 0x55a03dba0a00] mmco: unref short failure
[h264 @ 0x55a033014a00] mmco: unref short failure
[h264 @ 0x55a033014a00] mmco: unref short failure
[h264 @ 0x55a033014a00] mmco: unref short failure
[h264 @ 0x55a033014a00] mmco: unref short failure
[h264 @ 0x556b4da91e00] mmco: unref short failure
[h264 @ 0x556b4da91e00] mmco: unref short failure
 50%|█████     | 974/1945 [5:13:11<5:39:15, 20.96s/it][h264 @ 0x5624280f4d40] mmco: unref short failure
[h264 @ 0x556b454dbb80] mmco: unref short failure
[h264 @ 0x5624272c6e40] mmco: unref short failure
[h264 @ 0x5624272c6e40] mmco: unref short failure
[h264 @ 0x556b4fc77480] mmco: unref short failure
[h264 @ 0x5624272c6e40] mmco: unref short failure
[h264 @ 0x5624272c6e40] mmco: unref short failure
[h264 @ 0x5624241c7cc0] mmco: unref short failure
[h264 @ 0x5624241c7cc0] mmco: unref short failure
[h264 @ 0x5624241c7cc0] mmco: unref short failure
[h264 @ 0x5624241c7cc0] mmco: unref short failure
[h264 @ 0x559bf2d95900] mmco: unref short failure
[h264 @ 0x559bf740bb40] mmco: unref short failure
[h264 @ 0x56241c2c5000] mmco: unref short failure
 50%|█████     | 975/1945 [5:13:30<5:29:45, 20.40s/it][h264 @ 0x556b3b0df7c0] mmco: unref short failure
[h264 @ 0x556b3b0df7c0] mmco: unref short failure
 50%|█████     | 976/1945 [5:13:38<4:29:31, 16.69s/it][h264 @ 0x55a03aa25a00] mmco: unref short failure
[h264 @ 0x55a03aa25a00] mmco: unref short failure
[h264 @ 0x559bf86b9a80] mmco: unref short failure
[h264 @ 0x559bf86b9a80] mmco: unref short failure
[h264 @ 0x559c06813480] mmco: unref short failure
 50%|█████     | 977/1945 [5:13:48<3:58:20, 14.77s/it][h264 @ 0x559beec55540] mmco: unref short failure
[h264 @ 0x559beec55540] mmco: unref short failure
[h264 @ 0x559beec55540] mmco: unref short failure
[h264 @ 0x559beec55540] mmco: unref short failure
[h264 @ 0x556b2d76f940] mmco: unref short failure
 50%|█████     | 978/1945 [5:13:56<3:24:22, 12.68s/it][h264 @ 0x5624241b9540] mmco: unref short failure
[h264 @ 0x556b4b324b80] mmco: unref short failure
[h264 @ 0x556b4b324b80] mmco: unref short failure
[h264 @ 0x562439798440] mmco: unref short failure
 50%|█████     | 979/1945 [5:14:09<3:24:42, 12.71s/it][h264 @ 0x55a031e2fd40] mmco: unref short failure
[h264 @ 0x56242a6e54c0] mmco: unref short failure
 50%|█████     | 980/1945 [5:14:15<2:56:11, 10.95s/it][h264 @ 0x562416ed20c0] mmco: unref short failure
[h264 @ 0x56241d84e6c0] mmco: unref short failure
[h264 @ 0x559c01a1c400] mmco: unref short failure
[h264 @ 0x559c01a1c400] mmco: unref short failure
 50%|█████     | 981/1945 [5:14:23<2:40:41, 10.00s/it][h264 @ 0x559c023b9380] mmco: unref short failure
[h264 @ 0x556b31142940] mmco: unref short failure
[h264 @ 0x556b429d9c00] mmco: unref short failure
[h264 @ 0x556b429d9c00] mmco: unref short failure
[h264 @ 0x56241f8bb600] mmco: unref short failure
[h264 @ 0x55a03e795f40] mmco: unref short failure
[h264 @ 0x556b396ee740] mmco: unref short failure
[h264 @ 0x559bf2c77740] mmco: unref short failure
[h264 @ 0x559bf2c77740] mmco: unref short failure
[h264 @ 0x55a04e8a9180] mmco: unref short failure
[h264 @ 0x55a04e8a9180] mmco: unref short failure
 50%|█████     | 982/1945 [5:15:12<5:45:33, 21.53s/it][h264 @ 0x556b41a86e40] mmco: unref short failure
[h264 @ 0x55a0346d4840] mmco: unref short failure
[h264 @ 0x55a0346d4840] mmco: unref short failure
 51%|█████     | 983/1945 [5:15:41<6:20:44, 23.75s/it][h264 @ 0x559bf22bab40] mmco: unref short failure
[h264 @ 0x559bf22bab40] mmco: unref short failure
 51%|█████     | 984/1945 [5:15:48<5:03:19, 18.94s/it][h264 @ 0x55a04d4b9140] mmco: unref short failure
[h264 @ 0x55a04d4b9140] mmco: unref short failure
 51%|█████     | 985/1945 [5:15:55<4:03:26, 15.21s/it][h264 @ 0x56241cbca780] mmco: unref short failure
[h264 @ 0x56241cbca780] mmco: unref short failure
[h264 @ 0x559bed406b40] mmco: unref short failure
 51%|█████     | 986/1945 [5:16:03<3:30:13, 13.15s/it][h264 @ 0x562417274b40] mmco: unref short failure
[h264 @ 0x562417274b40] mmco: unref short failure
 51%|█████     | 987/1945 [5:16:10<3:00:28, 11.30s/it] 51%|█████     | 988/1945 [5:16:17<2:39:18,  9.99s/it][h264 @ 0x559c02aa8ec0] mmco: unref short failure
[h264 @ 0x559c02aa8ec0] mmco: unref short failure
[h264 @ 0x559c02aa8ec0] mmco: unref short failure
[h264 @ 0x559c02aa8ec0] mmco: unref short failure
 51%|█████     | 989/1945 [5:16:24<2:25:29,  9.13s/it][h264 @ 0x55a039d671c0] mmco: unref short failure
[h264 @ 0x556b2db27100] mmco: unref short failure
[h264 @ 0x55a0331f3d40] mmco: unref short failure
[h264 @ 0x55a0331f3d40] mmco: unref short failure
[h264 @ 0x556b49ecfec0] mmco: unref short failure
[h264 @ 0x556b49ecfec0] mmco: unref short failure
[h264 @ 0x55a032f70f00] mmco: unref short failure
[h264 @ 0x562419066340] mmco: unref short failure
[h264 @ 0x55a032f70f00] mmco: unref short failure
[h264 @ 0x562419066340] mmco: unref short failure
[h264 @ 0x56241d59e940] mmco: unref short failure
[h264 @ 0x56241d59e940] mmco: unref short failure
 51%|█████     | 990/1945 [5:17:11<5:26:19, 20.50s/it][h264 @ 0x559c08940980] mmco: unref short failure
[h264 @ 0x55a033c2f400] mmco: unref short failure
[h264 @ 0x55a033c2f400] mmco: unref short failure
[h264 @ 0x556b2ec83800] mmco: unref short failure
[h264 @ 0x556b4ab52dc0] mmco: unref short failure
 51%|█████     | 991/1945 [5:17:40<6:07:08, 23.09s/it] 51%|█████     | 992/1945 [5:17:48<4:53:05, 18.45s/it][h264 @ 0x55a041abe680] mmco: unref short failure
[h264 @ 0x556b2dcb2f40] mmco: unref short failure
[h264 @ 0x556b2dcb2f40] mmco: unref short failure
 51%|█████     | 993/1945 [5:17:56<4:02:17, 15.27s/it] 51%|█████     | 994/1945 [5:18:03<3:22:12, 12.76s/it][h264 @ 0x559bedc8cf40] mmco: unref short failure
[h264 @ 0x559bedc8cf40] mmco: unref short failure
[h264 @ 0x559bf9bc33c0] mmco: unref short failure
[h264 @ 0x56241670f900] mmco: unref short failure
 51%|█████     | 995/1945 [5:18:11<2:59:12, 11.32s/it][h264 @ 0x556b3e032b00] mmco: unref short failure
 51%|█████     | 996/1945 [5:18:18<2:41:02, 10.18s/it][h264 @ 0x556b397d7780] mmco: unref short failure
[h264 @ 0x556b397d7780] mmco: unref short failure
[h264 @ 0x556b397d7780] mmco: unref short failure
[h264 @ 0x556b397d7780] mmco: unref short failure
 51%|█████▏    | 997/1945 [5:18:27<2:34:01,  9.75s/it][h264 @ 0x559be8ec8b40] mmco: unref short failure
[h264 @ 0x559be8ec8b40] mmco: unref short failure
[h264 @ 0x556b2fa09580] mmco: unref short failure
[h264 @ 0x556b2fa09580] mmco: unref short failure
[h264 @ 0x556b2e8c48c0] mmco: unref short failure
[h264 @ 0x559bfe7b8b00] mmco: unref short failure
[h264 @ 0x559bfe7b8b00] mmco: unref short failure
[h264 @ 0x556b436d2c80] mmco: unref short failure
[h264 @ 0x556b436d2c80] mmco: unref short failure
[h264 @ 0x556b436d2c80] mmco: unref short failure
[h264 @ 0x556b436d2c80] mmco: unref short failure
[h264 @ 0x556b436d2c80] mmco: unref short failure
not have audios 7wavFXW3AFw.7
[h264 @ 0x55a0351afe00] mmco: unref short failure
[h264 @ 0x55a0351afe00] mmco: unref short failure
[h264 @ 0x556b3339a680] mmco: unref short failure
[h264 @ 0x562425d18540] mmco: unref short failure
[h264 @ 0x556b4c3bc780] mmco: unref short failure
[h264 @ 0x556b4c3bc780] mmco: unref short failure
 51%|█████▏    | 998/1945 [5:19:13<5:25:35, 20.63s/it][h264 @ 0x55a045b63ac0] mmco: unref short failure
[h264 @ 0x55a045b63ac0] mmco: unref short failure
[h264 @ 0x562424f00240] mmco: unref short failure
[h264 @ 0x562424f00240] mmco: unref short failure
[h264 @ 0x562424f00240] mmco: unref short failure
[h264 @ 0x562424f00240] mmco: unref short failure
[h264 @ 0x55a034ba12c0] mmco: unref short failure
[h264 @ 0x55a034ba12c0] mmco: unref short failure
[h264 @ 0x56242d5c2ec0] mmco: unref short failure
[h264 @ 0x56242d5c2ec0] mmco: unref short failure
[h264 @ 0x56242d5c2ec0] mmco: unref short failure
[h264 @ 0x56242d5c2ec0] mmco: unref short failure
[h264 @ 0x559c04df44c0] mmco: unref short failure
[h264 @ 0x55a036d08e00] mmco: unref short failure
[h264 @ 0x55a036d08e00] mmco: unref short failure
[h264 @ 0x559bfbe68e00] mmco: unref short failure
[h264 @ 0x556b397d7a00] mmco: unref short failure
[h264 @ 0x556b397d7a00] mmco: unref short failure
[h264 @ 0x556b397d7a00] mmco: unref short failure
[h264 @ 0x556b3e033440] mmco: unref short failure
[h264 @ 0x556b3e033440] mmco: unref short failure
[h264 @ 0x562417349280] mmco: unref short failure
[h264 @ 0x562417349280] mmco: unref short failure
[h264 @ 0x55a03a206900] mmco: unref short failure
[h264 @ 0x55a03a206900] mmco: unref short failure
[h264 @ 0x56241c2032c0] mmco: unref short failure
[h264 @ 0x56241c2032c0] mmco: unref short failure
[h264 @ 0x56241c2032c0] mmco: unref short failure
[h264 @ 0x56241c2032c0] mmco: unref short failure
[h264 @ 0x56241c202e40] mmco: unref short failure
[h264 @ 0x56241c202e40] mmco: unref short failure
[h264 @ 0x556b2e4d7780] mmco: unref short failure
[h264 @ 0x556b2e4d7780] mmco: unref short failure
[h264 @ 0x559bea10bf00] mmco: unref short failure
[h264 @ 0x559bea10bf00] mmco: unref short failure
 51%|█████▏    | 999/1945 [5:19:46<6:25:41, 24.46s/it]09/09/2024 22:25:09 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 22:25:09 - INFO - __main__ -   start running ret%tv validation...
[h264 @ 0x562424622380] mmco: unref short failure
[h264 @ 0x562424622380] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a0336de480] mmco: unref short failure
[h264 @ 0x55a0336de480] mmco: unref short failure
[h264 @ 0x55a04c2427c0] mmco: unref short failure
[h264 @ 0x55a04c2427c0] mmco: unref short failure
[h264 @ 0x559beb9d8fc0] mmco: unref short failure
[h264 @ 0x562429e47040] mmco: unref short failure
[h264 @ 0x55a036f73540] mmco: unref short failure
[h264 @ 0x559beee3b400] mmco: unref short failure
[h264 @ 0x559beee3b400] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a042d483c0] mmco: unref short failure
[h264 @ 0x55a042d483c0] mmco: unref short failure
[h264 @ 0x55a042d483c0] mmco: unref short failure
[h264 @ 0x55a042d483c0] mmco: unref short failure
[h264 @ 0x556b400be800] mmco: unref short failure
[h264 @ 0x55a03250a3c0] mmco: unref short failure
[h264 @ 0x559bee0b5c40] mmco: unref short failure
[h264 @ 0x559bee0b5c40] mmco: unref short failure
[h264 @ 0x556b3be7d9c0] mmco: unref short failure
[h264 @ 0x556b3be7d9c0] mmco: unref short failure
[h264 @ 0x562427fd02c0] mmco: unref short failure
[h264 @ 0x559bf2ffccc0] mmco: unref short failure
[h264 @ 0x559c08d1a000] mmco: unref short failure
[h264 @ 0x556b48217140] mmco: unref short failure
[h264 @ 0x559c05b9a900] mmco: unref short failure
[h264 @ 0x559c05b9a900] mmco: unref short failure
[h264 @ 0x556b30f9db80] mmco: unref short failure
[h264 @ 0x556b30f9db80] mmco: unref short failure
[h264 @ 0x556b30f9db80] mmco: unref short failure
[h264 @ 0x556b30f9db80] mmco: unref short failure
[h264 @ 0x556b42d29c40] mmco: unref short failure
[h264 @ 0x559bf039dd80] mmco: unref short failure
[h264 @ 0x559bf4f9e1c0] mmco: unref short failure
[h264 @ 0x55a03e86d600] mmco: unref short failure
[h264 @ 0x55a03e86d600] mmco: unref short failure
[h264 @ 0x55a03e86d600] mmco: unref short failure
[h264 @ 0x55a03e86d600] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:35,  1.42it/s][A
  1%|          | 2/221 [00:01<02:18,  1.58it/s][A
  1%|▏         | 3/221 [00:01<01:33,  2.32it/s][A
  2%|▏         | 4/221 [00:01<01:13,  2.97it/s][A
  2%|▏         | 5/221 [00:01<00:54,  3.96it/s][A
  3%|▎         | 6/221 [00:02<00:53,  4.04it/s][A
  3%|▎         | 7/221 [00:02<00:58,  3.64it/s][A
  4%|▎         | 8/221 [00:03<01:32,  2.29it/s][A
  4%|▍         | 9/221 [00:03<01:16,  2.78it/s][A
  5%|▍         | 10/221 [00:03<01:23,  2.53it/s][A
  5%|▍         | 11/221 [00:03<01:10,  2.98it/s][A
  5%|▌         | 12/221 [00:04<01:23,  2.50it/s][A
  6%|▌         | 13/221 [00:04<01:07,  3.08it/s][A[h264 @ 0x556b3fcee3c0] mmco: unref short failure
[h264 @ 0x556b3fcee3c0] mmco: unref short failure
[h264 @ 0x556b3fcee3c0] mmco: unref short failure

  6%|▋         | 14/221 [00:07<03:28,  1.01s/it][A
  7%|▋         | 15/221 [00:07<02:38,  1.30it/s][A[h264 @ 0x55a04d7ab5c0] mmco: unref short failure

  7%|▋         | 16/221 [00:07<02:16,  1.50it/s][A[h264 @ 0x55a04d7ab5c0] mmco: unref short failure

  8%|▊         | 17/221 [00:08<01:51,  1.83it/s][A
  8%|▊         | 18/221 [00:08<01:31,  2.22it/s][A
  9%|▊         | 19/221 [00:08<01:17,  2.60it/s][A
  9%|▉         | 20/221 [00:08<01:09,  2.90it/s][A
 10%|▉         | 21/221 [00:09<00:55,  3.61it/s][A[h264 @ 0x56241e713fc0] mmco: unref short failure
[h264 @ 0x56241e713fc0] mmco: unref short failure

 10%|▉         | 22/221 [00:09<00:52,  3.82it/s][A
 11%|█         | 24/221 [00:09<00:37,  5.22it/s][A
 11%|█▏        | 25/221 [00:09<00:37,  5.22it/s][A
 12%|█▏        | 26/221 [00:09<00:39,  4.93it/s][A
 12%|█▏        | 27/221 [00:10<00:38,  4.98it/s][A
 13%|█▎        | 28/221 [00:10<00:51,  3.71it/s][A
 13%|█▎        | 29/221 [00:10<00:47,  4.03it/s][A[h264 @ 0x562435da5940] mmco: unref short failure

 14%|█▎        | 30/221 [00:11<00:53,  3.59it/s][A
 14%|█▍        | 31/221 [00:11<00:51,  3.67it/s][A
 14%|█▍        | 32/221 [00:11<00:41,  4.51it/s][A
 15%|█▍        | 33/221 [00:11<00:47,  4.00it/s][A
 15%|█▌        | 34/221 [00:11<00:41,  4.55it/s][A
 16%|█▌        | 35/221 [00:12<00:36,  5.09it/s][A[h264 @ 0x55a0462abd00] mmco: unref short failure
[h264 @ 0x55a0462abd00] mmco: unref short failure

 16%|█▋        | 36/221 [00:12<00:37,  4.90it/s][A
 17%|█▋        | 37/221 [00:12<00:56,  3.23it/s][A
 17%|█▋        | 38/221 [00:13<00:59,  3.05it/s][A
 18%|█▊        | 40/221 [00:13<00:45,  3.94it/s][A
 19%|█▊        | 41/221 [00:13<00:38,  4.63it/s][A
 19%|█▉        | 42/221 [00:13<00:45,  3.98it/s][A
 19%|█▉        | 43/221 [00:14<00:39,  4.56it/s][A
 20%|██        | 45/221 [00:15<01:09,  2.53it/s][A
 21%|██        | 46/221 [00:15<01:08,  2.55it/s][A
 21%|██▏       | 47/221 [00:16<01:26,  2.02it/s][A
 22%|██▏       | 48/221 [00:16<01:13,  2.34it/s][A
 22%|██▏       | 49/221 [00:16<00:59,  2.91it/s][A
 23%|██▎       | 51/221 [00:17<00:41,  4.08it/s][A
 24%|██▎       | 52/221 [00:17<00:41,  4.04it/s][A
 24%|██▍       | 53/221 [00:17<00:38,  4.39it/s][A
 24%|██▍       | 54/221 [00:18<00:59,  2.81it/s][A
 25%|██▍       | 55/221 [00:18<00:59,  2.80it/s][A
 25%|██▌       | 56/221 [00:18<00:58,  2.84it/s][A
 26%|██▌       | 57/221 [00:19<00:48,  3.38it/s][A
 27%|██▋       | 59/221 [00:19<00:34,  4.74it/s][A
 27%|██▋       | 60/221 [00:19<00:38,  4.24it/s][A
 28%|██▊       | 61/221 [00:20<00:42,  3.75it/s][A
 28%|██▊       | 62/221 [00:20<00:43,  3.62it/s][A
 29%|██▊       | 63/221 [00:20<00:40,  3.94it/s][A[h264 @ 0x55a03272cb80] mmco: unref short failure
[h264 @ 0x55a03272cb80] mmco: unref short failure

 29%|██▉       | 64/221 [00:20<00:35,  4.41it/s][A
 29%|██▉       | 65/221 [00:20<00:30,  5.15it/s][A
 30%|██▉       | 66/221 [00:21<00:38,  3.99it/s][A
 30%|███       | 67/221 [00:21<00:37,  4.07it/s][A
 31%|███       | 69/221 [00:22<00:45,  3.37it/s][A
 32%|███▏      | 70/221 [00:22<00:39,  3.87it/s][A
 32%|███▏      | 71/221 [00:23<01:02,  2.39it/s][A
 33%|███▎      | 72/221 [00:23<00:54,  2.73it/s][A
 33%|███▎      | 73/221 [00:23<00:49,  2.98it/s][A
 33%|███▎      | 74/221 [00:23<00:40,  3.59it/s][A
 34%|███▍      | 75/221 [00:24<00:42,  3.44it/s][A
 34%|███▍      | 76/221 [00:24<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:24<00:34,  4.20it/s][A
 35%|███▌      | 78/221 [00:24<00:37,  3.86it/s][A
 36%|███▌      | 79/221 [00:25<00:47,  2.99it/s][A[h264 @ 0x56241738ce00] mmco: unref short failure
[h264 @ 0x56241738ce00] mmco: unref short failure
[h264 @ 0x56241738ce00] mmco: unref short failure
[h264 @ 0x56241738ce00] mmco: unref short failure

 36%|███▌      | 80/221 [00:25<00:37,  3.71it/s][A
 37%|███▋      | 81/221 [00:25<00:34,  4.07it/s][A
 37%|███▋      | 82/221 [00:25<00:34,  3.97it/s][A
 38%|███▊      | 83/221 [00:26<00:31,  4.42it/s][A
 38%|███▊      | 84/221 [00:26<00:27,  5.07it/s][A
 39%|███▉      | 86/221 [00:26<00:21,  6.19it/s][A[h264 @ 0x55a032dd6480] mmco: unref short failure
[h264 @ 0x55a032dd6480] mmco: unref short failure

 39%|███▉      | 87/221 [00:26<00:36,  3.67it/s][A
 40%|███▉      | 88/221 [00:27<00:37,  3.57it/s][A
 40%|████      | 89/221 [00:29<01:35,  1.38it/s][A
 41%|████      | 90/221 [00:29<01:14,  1.77it/s][A
 42%|████▏     | 92/221 [00:29<00:47,  2.71it/s][A
 42%|████▏     | 93/221 [00:30<00:50,  2.53it/s][A
 43%|████▎     | 94/221 [00:30<00:44,  2.88it/s][A
 43%|████▎     | 95/221 [00:30<00:35,  3.55it/s][A
 43%|████▎     | 96/221 [00:30<00:33,  3.75it/s][A
 44%|████▍     | 98/221 [00:30<00:26,  4.61it/s][A
 45%|████▍     | 99/221 [00:31<00:23,  5.12it/s][A
 45%|████▌     | 100/221 [00:31<00:22,  5.43it/s][A
 46%|████▌     | 102/221 [00:31<00:22,  5.34it/s][A
 47%|████▋     | 104/221 [00:31<00:17,  6.85it/s][A
 48%|████▊     | 105/221 [00:31<00:17,  6.58it/s][A[h264 @ 0x559bffbcd580] mmco: unref short failure

 48%|████▊     | 106/221 [00:32<00:37,  3.05it/s][A
 48%|████▊     | 107/221 [00:33<00:36,  3.14it/s][A
 49%|████▉     | 108/221 [00:33<00:31,  3.60it/s][A
 49%|████▉     | 109/221 [00:33<00:29,  3.82it/s][A
 50%|████▉     | 110/221 [00:33<00:26,  4.20it/s][A
 50%|█████     | 111/221 [00:34<00:29,  3.74it/s][A
 51%|█████     | 112/221 [00:34<00:26,  4.19it/s][A
 51%|█████     | 113/221 [00:34<00:28,  3.80it/s][A
 52%|█████▏    | 115/221 [00:34<00:17,  5.95it/s][A[h264 @ 0x56241d0f2dc0] mmco: unref short failure
[h264 @ 0x56241d0f2dc0] mmco: unref short failure

 52%|█████▏    | 116/221 [00:37<01:32,  1.14it/s][A
 53%|█████▎    | 117/221 [00:37<01:15,  1.38it/s][A
 53%|█████▎    | 118/221 [00:38<01:03,  1.62it/s][A
 54%|█████▍    | 119/221 [00:38<00:48,  2.10it/s][A
 54%|█████▍    | 120/221 [00:38<00:41,  2.45it/s][A
 55%|█████▌    | 122/221 [00:38<00:27,  3.64it/s][A
 56%|█████▌    | 123/221 [00:38<00:22,  4.27it/s][A
 56%|█████▌    | 124/221 [00:39<00:21,  4.46it/s][A
 57%|█████▋    | 125/221 [00:39<00:21,  4.49it/s][A
 57%|█████▋    | 126/221 [00:39<00:22,  4.23it/s][A
 57%|█████▋    | 127/221 [00:40<00:25,  3.69it/s][A
 58%|█████▊    | 128/221 [00:40<00:25,  3.66it/s][A
 58%|█████▊    | 129/221 [00:40<00:20,  4.43it/s][A
 59%|█████▉    | 130/221 [00:40<00:19,  4.74it/s][A
 60%|█████▉    | 132/221 [00:40<00:13,  6.59it/s][A
 60%|██████    | 133/221 [00:41<00:19,  4.61it/s][A
 61%|██████    | 134/221 [00:41<00:18,  4.64it/s][A
 61%|██████    | 135/221 [00:41<00:20,  4.19it/s][A
 62%|██████▏   | 136/221 [00:42<00:22,  3.73it/s][A
 62%|██████▏   | 137/221 [00:42<00:19,  4.23it/s][A
 62%|██████▏   | 138/221 [00:42<00:22,  3.69it/s][A
 63%|██████▎   | 139/221 [00:42<00:22,  3.59it/s][A
 63%|██████▎   | 140/221 [00:43<00:23,  3.40it/s][A
 64%|██████▍   | 141/221 [00:43<00:20,  3.83it/s][A
 64%|██████▍   | 142/221 [00:43<00:24,  3.20it/s][A
 65%|██████▍   | 143/221 [00:44<00:25,  3.07it/s][A
 65%|██████▌   | 144/221 [00:44<00:20,  3.82it/s][A
 66%|██████▌   | 146/221 [00:44<00:12,  5.90it/s][A
 67%|██████▋   | 147/221 [00:44<00:11,  6.26it/s][A
 67%|██████▋   | 148/221 [00:44<00:12,  5.75it/s][A
 68%|██████▊   | 150/221 [00:44<00:09,  7.52it/s][A
 68%|██████▊   | 151/221 [00:45<00:18,  3.80it/s][A[h264 @ 0x55a044a24780] mmco: unref short failure
[h264 @ 0x55a044a24780] mmco: unref short failure
[h264 @ 0x55a044a24780] mmco: unref short failure

 69%|██████▉   | 152/221 [00:45<00:16,  4.14it/s][A
 69%|██████▉   | 153/221 [00:46<00:17,  3.93it/s][A
 70%|██████▉   | 154/221 [00:46<00:18,  3.56it/s][A
 71%|███████   | 156/221 [00:46<00:14,  4.52it/s][A[h264 @ 0x556b2f5e98c0] mmco: unref short failure
[h264 @ 0x556b2f5e98c0] mmco: unref short failure
[h264 @ 0x556b2f5e98c0] mmco: unref short failure
[h264 @ 0x556b2f5e98c0] mmco: unref short failure

 71%|███████   | 157/221 [00:49<00:49,  1.29it/s][A
 71%|███████▏  | 158/221 [00:49<00:38,  1.65it/s][A[h264 @ 0x56241dc75380] mmco: unref short failure

 72%|███████▏  | 159/221 [00:49<00:31,  1.98it/s][A
 72%|███████▏  | 160/221 [00:49<00:24,  2.45it/s][A
 73%|███████▎  | 162/221 [00:49<00:16,  3.54it/s][A
 74%|███████▍  | 163/221 [00:50<00:15,  3.76it/s][A
 74%|███████▍  | 164/221 [00:50<00:12,  4.42it/s][A[h264 @ 0x559be9b27700] mmco: unref short failure

 75%|███████▌  | 166/221 [00:50<00:12,  4.57it/s][A
 76%|███████▌  | 168/221 [00:54<00:49,  1.08it/s][A
 76%|███████▋  | 169/221 [00:55<00:39,  1.31it/s][A
 77%|███████▋  | 170/221 [00:55<00:32,  1.56it/s][A
 77%|███████▋  | 171/221 [00:55<00:25,  1.92it/s][A
 78%|███████▊  | 172/221 [00:55<00:21,  2.25it/s][A
 79%|███████▊  | 174/221 [00:55<00:13,  3.46it/s][A
 79%|███████▉  | 175/221 [00:56<00:12,  3.55it/s][A
 80%|███████▉  | 176/221 [00:56<00:12,  3.70it/s][A
 81%|████████  | 178/221 [00:56<00:10,  4.17it/s][A
 81%|████████  | 179/221 [00:57<00:12,  3.39it/s][A
 82%|████████▏ | 181/221 [00:57<00:09,  4.35it/s][A
 82%|████████▏ | 182/221 [00:57<00:08,  4.82it/s][A
 83%|████████▎ | 183/221 [00:57<00:07,  5.05it/s][A
 83%|████████▎ | 184/221 [00:58<00:08,  4.48it/s][A
 84%|████████▎ | 185/221 [00:58<00:07,  4.56it/s][A
 84%|████████▍ | 186/221 [00:58<00:09,  3.54it/s][A
 85%|████████▍ | 187/221 [00:58<00:07,  4.32it/s][A
 85%|████████▌ | 188/221 [00:59<00:08,  3.82it/s][A
 86%|████████▌ | 189/221 [00:59<00:08,  3.91it/s][A
 86%|████████▌ | 190/221 [00:59<00:07,  4.02it/s][A
 87%|████████▋ | 192/221 [00:59<00:05,  5.20it/s][A
 88%|████████▊ | 194/221 [01:00<00:06,  4.30it/s][A
 88%|████████▊ | 195/221 [01:00<00:05,  4.78it/s][A
 89%|████████▉ | 197/221 [01:00<00:03,  6.12it/s][A
 90%|████████▉ | 198/221 [01:01<00:04,  5.43it/s][A
 90%|█████████ | 199/221 [01:01<00:03,  5.92it/s][A
 90%|█████████ | 200/221 [01:01<00:04,  4.79it/s][A
 91%|█████████ | 201/221 [01:01<00:04,  4.84it/s][A
 91%|█████████▏| 202/221 [01:01<00:03,  5.05it/s][A
 92%|█████████▏| 204/221 [01:02<00:02,  6.75it/s][A
 93%|█████████▎| 206/221 [01:02<00:03,  4.51it/s][A
 94%|█████████▍| 208/221 [01:02<00:02,  5.75it/s][A
 95%|█████████▌| 210/221 [01:02<00:01,  7.37it/s][A
 96%|█████████▌| 212/221 [01:03<00:01,  6.40it/s][A
 97%|█████████▋| 214/221 [01:04<00:01,  4.87it/s][A
 97%|█████████▋| 215/221 [01:04<00:01,  5.20it/s][A
 98%|█████████▊| 216/221 [01:04<00:00,  5.12it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.59it/s][A
 99%|█████████▊| 218/221 [01:05<00:00,  3.86it/s][A
 99%|█████████▉| 219/221 [01:05<00:00,  4.08it/s][A
100%|█████████▉| 220/221 [01:09<00:01,  1.18s/it][A
100%|██████████| 221/221 [01:09<00:00,  1.11it/s][A100%|██████████| 221/221 [01:09<00:00,  3.19it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:51,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:22<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:37<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:51<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:32,  6.73it/s][A
  1%|          | 2/221 [00:00<00:49,  4.46it/s][A
  1%|▏         | 3/221 [00:00<00:55,  3.96it/s][A
  2%|▏         | 4/221 [00:00<00:47,  4.57it/s][A
  2%|▏         | 5/221 [00:01<00:44,  4.81it/s][A
  3%|▎         | 7/221 [00:01<00:40,  5.31it/s][A
  4%|▎         | 8/221 [00:01<00:49,  4.33it/s][A
  4%|▍         | 9/221 [00:01<00:48,  4.41it/s][A
  5%|▍         | 10/221 [00:02<01:10,  3.01it/s][A
  5%|▍         | 11/221 [00:02<01:01,  3.40it/s][A
  5%|▌         | 12/221 [00:02<00:52,  3.97it/s][A
  6%|▌         | 13/221 [00:03<01:24,  2.46it/s][A
  6%|▋         | 14/221 [00:03<01:07,  3.06it/s][A
  7%|▋         | 15/221 [00:04<00:59,  3.45it/s][A
  7%|▋         | 16/221 [00:04<01:05,  3.12it/s][A
  8%|▊         | 17/221 [00:05<01:27,  2.33it/s][A
  8%|▊         | 18/221 [00:05<01:12,  2.81it/s][A
  9%|▊         | 19/221 [00:05<01:00,  3.33it/s][A
 10%|▉         | 21/221 [00:05<00:44,  4.54it/s][A
 10%|▉         | 22/221 [00:05<00:41,  4.76it/s][A
 11%|█         | 24/221 [00:06<00:35,  5.61it/s][A
 11%|█▏        | 25/221 [00:06<00:34,  5.60it/s][A
 12%|█▏        | 26/221 [00:06<00:36,  5.33it/s][A
 12%|█▏        | 27/221 [00:06<00:33,  5.83it/s][A
 13%|█▎        | 28/221 [00:07<00:42,  4.56it/s][A
 13%|█▎        | 29/221 [00:07<00:43,  4.45it/s][A
 14%|█▎        | 30/221 [00:07<00:46,  4.10it/s][A
 14%|█▍        | 31/221 [00:07<00:44,  4.25it/s][A
 15%|█▍        | 33/221 [00:08<00:35,  5.32it/s][A
 15%|█▌        | 34/221 [00:08<00:37,  4.99it/s][A
 16%|█▌        | 35/221 [00:08<00:43,  4.25it/s][A
 16%|█▋        | 36/221 [00:08<00:48,  3.82it/s][A
 17%|█▋        | 37/221 [00:09<00:42,  4.30it/s][A
 17%|█▋        | 38/221 [00:09<00:43,  4.16it/s][A
 18%|█▊        | 39/221 [00:09<00:39,  4.62it/s][A
 18%|█▊        | 40/221 [00:09<00:48,  3.75it/s][A
 19%|█▊        | 41/221 [00:10<00:40,  4.41it/s][A
 19%|█▉        | 42/221 [00:10<00:36,  4.85it/s][A
 19%|█▉        | 43/221 [00:10<00:43,  4.08it/s][A
 20%|█▉        | 44/221 [00:10<00:43,  4.04it/s][A
 20%|██        | 45/221 [00:11<00:47,  3.73it/s][A
 21%|██        | 46/221 [00:11<00:41,  4.25it/s][A
 21%|██▏       | 47/221 [00:11<00:40,  4.26it/s][A
 22%|██▏       | 48/221 [00:11<00:35,  4.88it/s][A
 22%|██▏       | 49/221 [00:11<00:36,  4.68it/s][A
 23%|██▎       | 50/221 [00:12<00:47,  3.61it/s][A
 23%|██▎       | 51/221 [00:12<00:40,  4.16it/s][A
 24%|██▎       | 52/221 [00:12<00:42,  3.98it/s][A
 24%|██▍       | 53/221 [00:12<00:37,  4.48it/s][A
 24%|██▍       | 54/221 [00:13<00:51,  3.24it/s][A
 25%|██▍       | 55/221 [00:13<00:47,  3.50it/s][A
 25%|██▌       | 56/221 [00:13<00:40,  4.06it/s][A
 26%|██▌       | 57/221 [00:14<00:41,  3.98it/s][A
 26%|██▌       | 58/221 [00:14<00:49,  3.31it/s][A
 27%|██▋       | 59/221 [00:14<00:43,  3.74it/s][A
 27%|██▋       | 60/221 [00:14<00:38,  4.15it/s][A
 28%|██▊       | 61/221 [00:14<00:35,  4.54it/s][A
 28%|██▊       | 62/221 [00:15<00:36,  4.38it/s][A
 29%|██▊       | 63/221 [00:15<00:35,  4.43it/s][A
 29%|██▉       | 64/221 [00:15<00:42,  3.67it/s][A
 29%|██▉       | 65/221 [00:16<00:37,  4.16it/s][A
 30%|██▉       | 66/221 [00:16<00:48,  3.22it/s][A
 30%|███       | 67/221 [00:16<00:52,  2.93it/s][A
 31%|███       | 68/221 [00:17<00:45,  3.33it/s][A
 31%|███       | 69/221 [00:17<01:10,  2.16it/s][A
 32%|███▏      | 70/221 [00:18<00:53,  2.81it/s][A
 32%|███▏      | 71/221 [00:18<00:46,  3.23it/s][A
 33%|███▎      | 72/221 [00:18<00:49,  2.99it/s][A
 33%|███▎      | 73/221 [00:18<00:49,  3.01it/s][A
 33%|███▎      | 74/221 [00:19<00:41,  3.54it/s][A
 34%|███▍      | 75/221 [00:19<00:40,  3.61it/s][A
 34%|███▍      | 76/221 [00:19<00:37,  3.89it/s][A
 35%|███▍      | 77/221 [00:19<00:38,  3.74it/s][A
 35%|███▌      | 78/221 [00:20<00:33,  4.22it/s][A
 36%|███▌      | 79/221 [00:20<00:42,  3.34it/s][A
 36%|███▌      | 80/221 [00:20<00:37,  3.77it/s][A
 37%|███▋      | 81/221 [00:20<00:35,  3.91it/s][A
 37%|███▋      | 82/221 [00:21<00:41,  3.33it/s][A
 38%|███▊      | 83/221 [00:21<00:43,  3.14it/s][A
 38%|███▊      | 84/221 [00:21<00:39,  3.51it/s][A
 38%|███▊      | 85/221 [00:22<00:32,  4.19it/s][A
 39%|███▉      | 86/221 [00:22<00:36,  3.72it/s][A
 39%|███▉      | 87/221 [00:22<00:47,  2.79it/s][A
 40%|███▉      | 88/221 [00:23<00:51,  2.56it/s][A
 40%|████      | 89/221 [00:23<00:45,  2.88it/s][A
 41%|████      | 90/221 [00:24<00:48,  2.73it/s][A
 41%|████      | 91/221 [00:24<00:38,  3.38it/s][A
 42%|████▏     | 92/221 [00:24<00:40,  3.15it/s][A
 42%|████▏     | 93/221 [00:25<00:54,  2.36it/s][A
 43%|████▎     | 94/221 [00:25<00:49,  2.57it/s][A
 43%|████▎     | 95/221 [00:25<00:43,  2.91it/s][A
 43%|████▎     | 96/221 [00:26<00:38,  3.24it/s][A
 44%|████▍     | 97/221 [00:26<00:33,  3.68it/s][A
 44%|████▍     | 98/221 [00:26<00:34,  3.59it/s][A
 45%|████▍     | 99/221 [00:26<00:31,  3.92it/s][A
 45%|████▌     | 100/221 [00:26<00:30,  4.00it/s][A
 46%|████▌     | 101/221 [00:27<00:30,  3.96it/s][A
 46%|████▌     | 102/221 [00:27<00:44,  2.65it/s][A
 47%|████▋     | 103/221 [00:27<00:35,  3.36it/s][A
 47%|████▋     | 104/221 [00:28<00:31,  3.71it/s][A
 48%|████▊     | 105/221 [00:28<00:30,  3.81it/s][A
 48%|████▊     | 106/221 [00:28<00:37,  3.10it/s][A
 48%|████▊     | 107/221 [00:29<00:32,  3.54it/s][A
 49%|████▉     | 108/221 [00:29<00:30,  3.65it/s][A
 50%|████▉     | 110/221 [00:29<00:25,  4.41it/s][A
 50%|█████     | 111/221 [00:29<00:26,  4.12it/s][A
 51%|█████     | 112/221 [00:30<00:26,  4.19it/s][A
 51%|█████     | 113/221 [00:30<00:23,  4.67it/s][A
 52%|█████▏    | 115/221 [00:30<00:19,  5.37it/s][A
 52%|█████▏    | 116/221 [00:30<00:21,  4.96it/s][A
 53%|█████▎    | 117/221 [00:31<00:22,  4.67it/s][A
 53%|█████▎    | 118/221 [00:31<00:21,  4.71it/s][A
 54%|█████▍    | 119/221 [00:31<00:27,  3.73it/s][A
 54%|█████▍    | 120/221 [00:31<00:24,  4.13it/s][A
 55%|█████▍    | 121/221 [00:32<00:21,  4.73it/s][A
 55%|█████▌    | 122/221 [00:32<00:22,  4.34it/s][A
 56%|█████▌    | 123/221 [00:32<00:23,  4.19it/s][A
 56%|█████▌    | 124/221 [00:32<00:23,  4.06it/s][A
 57%|█████▋    | 125/221 [00:33<00:27,  3.54it/s][A
 57%|█████▋    | 126/221 [00:33<00:23,  4.04it/s][A
 57%|█████▋    | 127/221 [00:33<00:29,  3.19it/s][A
 58%|█████▊    | 128/221 [00:34<00:27,  3.44it/s][A
 58%|█████▊    | 129/221 [00:34<00:22,  4.18it/s][A
 59%|█████▉    | 130/221 [00:34<00:23,  3.93it/s][A
 59%|█████▉    | 131/221 [00:34<00:18,  4.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:22,  3.94it/s][A
 60%|██████    | 133/221 [00:35<00:24,  3.58it/s][A
 61%|██████    | 134/221 [00:35<00:30,  2.84it/s][A
 61%|██████    | 135/221 [00:36<00:31,  2.72it/s][A
 62%|██████▏   | 136/221 [00:36<00:27,  3.07it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.72it/s][A
 62%|██████▏   | 138/221 [00:36<00:23,  3.60it/s][A
 63%|██████▎   | 139/221 [00:37<00:27,  2.96it/s][A
 63%|██████▎   | 140/221 [00:37<00:26,  3.07it/s][A
 64%|██████▍   | 141/221 [00:37<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:38<00:21,  3.75it/s][A
 65%|██████▍   | 143/221 [00:38<00:28,  2.73it/s][A
 65%|██████▌   | 144/221 [00:39<00:28,  2.73it/s][A
 66%|██████▌   | 146/221 [00:39<00:18,  4.15it/s][A
 67%|██████▋   | 147/221 [00:39<00:18,  4.06it/s][A
 67%|██████▋   | 148/221 [00:39<00:22,  3.29it/s][A
 67%|██████▋   | 149/221 [00:40<00:20,  3.43it/s][A
 68%|██████▊   | 150/221 [00:40<00:19,  3.57it/s][A
 68%|██████▊   | 151/221 [00:40<00:22,  3.12it/s][A
 69%|██████▉   | 152/221 [00:41<00:31,  2.16it/s][A
 69%|██████▉   | 153/221 [00:41<00:24,  2.76it/s][A
 70%|██████▉   | 154/221 [00:42<00:20,  3.22it/s][A
 70%|███████   | 155/221 [00:42<00:17,  3.71it/s][A
 71%|███████   | 156/221 [00:42<00:21,  3.00it/s][A
 71%|███████   | 157/221 [00:42<00:20,  3.08it/s][A
 71%|███████▏  | 158/221 [00:43<00:19,  3.30it/s][A
 72%|███████▏  | 159/221 [00:43<00:15,  3.95it/s][A
 72%|███████▏  | 160/221 [00:43<00:14,  4.33it/s][A
 73%|███████▎  | 161/221 [00:43<00:17,  3.49it/s][A
 73%|███████▎  | 162/221 [00:44<00:15,  3.93it/s][A
 74%|███████▍  | 163/221 [00:44<00:14,  3.93it/s][A
 74%|███████▍  | 164/221 [00:44<00:12,  4.68it/s][A
 75%|███████▍  | 165/221 [00:44<00:11,  4.75it/s][A
 75%|███████▌  | 166/221 [00:44<00:11,  4.62it/s][A
 76%|███████▌  | 167/221 [00:45<00:10,  5.35it/s][A
 76%|███████▌  | 168/221 [00:45<00:10,  4.98it/s][A
 76%|███████▋  | 169/221 [00:45<00:09,  5.68it/s][A
 77%|███████▋  | 170/221 [00:45<00:13,  3.77it/s][A
 77%|███████▋  | 171/221 [00:46<00:12,  4.00it/s][A
 78%|███████▊  | 172/221 [00:46<00:11,  4.17it/s][A
 78%|███████▊  | 173/221 [00:46<00:13,  3.67it/s][A
 79%|███████▊  | 174/221 [00:47<00:16,  2.88it/s][A
 79%|███████▉  | 175/221 [00:47<00:15,  2.90it/s][A
 80%|███████▉  | 176/221 [00:47<00:13,  3.23it/s][A
 80%|████████  | 177/221 [00:47<00:12,  3.56it/s][A
 81%|████████  | 178/221 [00:48<00:12,  3.57it/s][A
 81%|████████  | 179/221 [00:48<00:11,  3.74it/s][A
 81%|████████▏ | 180/221 [00:48<00:09,  4.28it/s][A
 82%|████████▏ | 181/221 [00:48<00:09,  4.18it/s][A
 82%|████████▏ | 182/221 [00:49<00:10,  3.70it/s][A
 83%|████████▎ | 183/221 [00:49<00:11,  3.21it/s][A
 83%|████████▎ | 184/221 [00:49<00:10,  3.38it/s][A
 84%|████████▎ | 185/221 [00:50<00:09,  3.93it/s][A
 84%|████████▍ | 186/221 [00:50<00:12,  2.89it/s][A
 85%|████████▍ | 187/221 [00:50<00:10,  3.28it/s][A
 85%|████████▌ | 188/221 [00:51<00:10,  3.30it/s][A
 86%|████████▌ | 189/221 [00:51<00:09,  3.52it/s][A
 86%|████████▌ | 190/221 [00:51<00:09,  3.20it/s][A
 86%|████████▋ | 191/221 [00:51<00:08,  3.70it/s][A
 87%|████████▋ | 192/221 [00:52<00:08,  3.60it/s][A
 87%|████████▋ | 193/221 [00:52<00:06,  4.35it/s][A
 88%|████████▊ | 194/221 [00:52<00:07,  3.64it/s][A
 88%|████████▊ | 195/221 [00:52<00:06,  3.91it/s][A
 89%|████████▊ | 196/221 [00:53<00:07,  3.46it/s][A
 89%|████████▉ | 197/221 [00:53<00:06,  3.75it/s][A
 90%|████████▉ | 198/221 [00:53<00:07,  3.06it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:54<00:06,  3.00it/s][A
 91%|█████████ | 201/221 [00:54<00:05,  3.45it/s][A
 91%|█████████▏| 202/221 [00:55<00:05,  3.21it/s][A
 92%|█████████▏| 203/221 [00:55<00:04,  3.71it/s][A
 92%|█████████▏| 204/221 [00:55<00:05,  3.28it/s][A
 93%|█████████▎| 205/221 [00:55<00:03,  4.08it/s][A
 93%|█████████▎| 206/221 [00:56<00:04,  3.50it/s][A
 94%|█████████▎| 207/221 [00:56<00:03,  3.80it/s][A
 94%|█████████▍| 208/221 [00:56<00:03,  4.00it/s][A
 95%|█████████▍| 209/221 [00:56<00:03,  3.98it/s][A
 95%|█████████▌| 210/221 [00:57<00:02,  4.84it/s][A
 95%|█████████▌| 211/221 [00:57<00:02,  4.10it/s][A
 96%|█████████▌| 212/221 [00:57<00:02,  3.61it/s][A
 96%|█████████▋| 213/221 [00:57<00:02,  3.92it/s][A
 97%|█████████▋| 214/221 [00:58<00:02,  2.49it/s][A
 97%|█████████▋| 215/221 [00:58<00:01,  3.00it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.12it/s][A
 98%|█████████▊| 217/221 [00:59<00:01,  3.17it/s][A
 99%|█████████▊| 218/221 [00:59<00:00,  3.23it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.23it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.72it/s][A
100%|██████████| 221/221 [01:00<00:00,  4.01it/s][A100%|██████████| 221/221 [01:00<00:00,  3.66it/s]
09/09/2024 22:30:55 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 999--===========

09/09/2024 22:30:55 - INFO - __main__ -   {'area_r1': 40.4, 'area_recall': '40.4/64.5/75.6', 'area_ravg': 60.1}
09/09/2024 22:30:55 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 999--===========

09/09/2024 22:30:55 - INFO - __main__ -   {'forward_r1': 38.3, 'forward_recall': '38.3/67.3/78.1', 'forward_ravg': 61.2}
09/09/2024 22:30:55 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 999--===========

09/09/2024 22:30:55 - INFO - __main__ -   {'area_video_r1': 39.6, 'area_video_recall': '39.6/67.3/77.8', 'area_video_ravg': 61.6}
09/09/2024 22:30:55 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/09/2024 22:30:55 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 22:30:55 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 999--===========

09/09/2024 22:30:55 - INFO - __main__ -   {'area_video_r1': 52.9, 'area_video_recall': '52.9/75.2/83.0', 'area_video_ravg': 70.4, 'area_video_back_r1': 48.3, 'area_video_back_recall': '48.3/74.9/81.9', 'area_video_back_ravg': 68.4}
09/09/2024 22:30:55 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/09/2024 22:30:55 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/09/2024 22:30:55 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 999--===========

09/09/2024 22:30:55 - INFO - __main__ -   {'video_r1': 44.0, 'video_recall': '44.0/72.3/82.4', 'video_ravg': 66.2}
09/09/2024 22:30:55 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 22:30:55 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 22:30:55 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 999--===========

09/09/2024 22:30:55 - INFO - __main__ -   {'video_r1': 52.6, 'video_recall': '52.6/75.7/82.8', 'video_ravg': 70.4}
09/09/2024 22:30:55 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/09/2024 22:30:55 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/09/2024 22:31:18 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.008041215129196644, 'loss_ret%tv%ta--finetune_area/loss_area': 1.1225721836090088, 'loss_ret%tv%ta--finetune_area/total_loss': 1.1306134462356567}
[h264 @ 0x559c071d2bc0] mmco: unref short failure
[h264 @ 0x559c071d2bc0] mmco: unref short failure
[h264 @ 0x55a034241f40] mmco: unref short failure
[h264 @ 0x55a034241f40] mmco: unref short failure
 51%|█████▏    | 1000/1945 [5:25:59<33:48:28, 128.79s/it] 51%|█████▏    | 1001/1945 [5:26:03<23:57:52, 91.39s/it]  52%|█████▏    | 1002/1945 [5:26:07<17:06:20, 65.30s/it][h264 @ 0x559bee838640] mmco: unref short failure
[h264 @ 0x559bee838640] mmco: unref short failure
[h264 @ 0x559beadcfbc0] mmco: unref short failure
[h264 @ 0x559beadcfbc0] mmco: unref short failure
 52%|█████▏    | 1003/1945 [5:26:13<12:23:15, 47.34s/it] 52%|█████▏    | 1004/1945 [5:26:19<9:09:07, 35.01s/it] [h264 @ 0x55a042eac140] mmco: unref short failure
[h264 @ 0x55a042eac140] mmco: unref short failure
[h264 @ 0x55a04a01bb80] mmco: unref short failure
[h264 @ 0x55a04a01bb80] mmco: unref short failure
[h264 @ 0x559bef6e7580] mmco: unref short failure
[h264 @ 0x5624379ef240] mmco: unref short failure
[h264 @ 0x5624379ef240] mmco: unref short failure
 52%|█████▏    | 1005/1945 [5:26:25<6:53:22, 26.39s/it][h264 @ 0x559beaa31500] mmco: unref short failure
[h264 @ 0x559beaa31500] mmco: unref short failure
[h264 @ 0x556b3103f440] mmco: unref short failure
[h264 @ 0x556b3103f440] mmco: unref short failure
 52%|█████▏    | 1006/1945 [5:26:31<5:16:42, 20.24s/it][h264 @ 0x556b2e311000] mmco: unref short failure
[h264 @ 0x556b2e311000] mmco: unref short failure
 52%|█████▏    | 1007/1945 [5:26:38<4:13:01, 16.18s/it][h264 @ 0x55a03f1498c0] mmco: unref short failure
[h264 @ 0x55a03f1498c0] mmco: unref short failure
 52%|█████▏    | 1008/1945 [5:26:45<3:29:27, 13.41s/it] 52%|█████▏    | 1009/1945 [5:26:52<3:01:02, 11.61s/it][h264 @ 0x55a0466044c0] mmco: unref short failure
[h264 @ 0x55a0466044c0] mmco: unref short failure
[h264 @ 0x559bea357ec0] mmco: unref short failure
 52%|█████▏    | 1010/1945 [5:27:00<2:43:34, 10.50s/it][h264 @ 0x55a03272cdc0] mmco: unref short failure
[h264 @ 0x55a03272cdc0] mmco: unref short failure
[h264 @ 0x55a04332f840] mmco: unref short failure
 52%|█████▏    | 1011/1945 [5:27:07<2:29:11,  9.58s/it][h264 @ 0x55a03272c700] mmco: unref short failure
[h264 @ 0x55a03272c700] mmco: unref short failure
[h264 @ 0x56241c202e40] mmco: unref short failure
[h264 @ 0x556b2df4d8c0] mmco: unref short failure
[h264 @ 0x55a043d2fe80] mmco: unref short failure
[h264 @ 0x55a043d2fe80] mmco: unref short failure
 52%|█████▏    | 1012/1945 [5:27:16<2:25:50,  9.38s/it][h264 @ 0x556b363b07c0] mmco: unref short failure
 52%|█████▏    | 1013/1945 [5:27:24<2:16:16,  8.77s/it] 52%|█████▏    | 1014/1945 [5:27:32<2:13:49,  8.62s/it][h264 @ 0x559bef6a4340] mmco: unref short failure
[h264 @ 0x559bef6a4340] mmco: unref short failure
 52%|█████▏    | 1015/1945 [5:27:41<2:15:03,  8.71s/it][h264 @ 0x559bffe658c0] mmco: unref short failure
[h264 @ 0x559bffe658c0] mmco: unref short failure
[h264 @ 0x559bffe658c0] mmco: unref short failure
[h264 @ 0x559bffe658c0] mmco: unref short failure
 52%|█████▏    | 1016/1945 [5:27:49<2:10:38,  8.44s/it][h264 @ 0x556b2d9f0480] mmco: unref short failure
[h264 @ 0x55a042767ac0] mmco: unref short failure
[h264 @ 0x55a042767ac0] mmco: unref short failure
 52%|█████▏    | 1017/1945 [5:27:56<2:07:15,  8.23s/it][h264 @ 0x55a04b54ac00] mmco: unref short failure
 52%|█████▏    | 1018/1945 [5:28:03<1:59:53,  7.76s/it][h264 @ 0x559be95f2300] mmco: unref short failure
[h264 @ 0x559be95f2300] mmco: unref short failure
 52%|█████▏    | 1019/1945 [5:28:11<2:01:00,  7.84s/it][h264 @ 0x5624310bb340] mmco: unref short failure
[h264 @ 0x5624310bb340] mmco: unref short failure
[h264 @ 0x556b32e094c0] mmco: unref short failure
[h264 @ 0x556b3cee1d80] mmco: unref short failure
[h264 @ 0x556b3cee1d80] mmco: unref short failure
[h264 @ 0x559c02f4a300] mmco: unref short failure
[h264 @ 0x559bffe65640] mmco: unref short failure
[h264 @ 0x556b4f927680] mmco: unref short failure
[h264 @ 0x556b4f927680] mmco: unref short failure
[h264 @ 0x556b4f927680] mmco: unref short failure
[h264 @ 0x556b4f927680] mmco: unref short failure
 52%|█████▏    | 1020/1945 [5:28:27<2:39:47, 10.37s/it][h264 @ 0x55a03a69c680] mmco: unref short failure
[h264 @ 0x55a03a69c680] mmco: unref short failure
[h264 @ 0x55a03a69c680] mmco: unref short failure
[h264 @ 0x55a03a69c680] mmco: unref short failure
 52%|█████▏    | 1021/1945 [5:28:34<2:22:31,  9.26s/it][h264 @ 0x556b2e23f540] mmco: unref short failure
[h264 @ 0x556b2e23f540] mmco: unref short failure
[h264 @ 0x562424697780] mmco: unref short failure
[h264 @ 0x562424697780] mmco: unref short failure
[h264 @ 0x562424697780] mmco: unref short failure
[h264 @ 0x562424697780] mmco: unref short failure
 53%|█████▎    | 1022/1945 [5:28:47<2:39:30, 10.37s/it][h264 @ 0x556b41a86700] mmco: unref short failure
 53%|█████▎    | 1023/1945 [5:28:54<2:24:39,  9.41s/it][h264 @ 0x556b312eb8c0] mmco: unref short failure
[h264 @ 0x556b312eb8c0] mmco: unref short failure
[h264 @ 0x556b4d2eb080] mmco: unref short failure
[h264 @ 0x556b4d2eb080] mmco: unref short failure
[h264 @ 0x559beec3a5c0] mmco: unref short failure
 53%|█████▎    | 1024/1945 [5:29:27<4:11:38, 16.39s/it][h264 @ 0x55a0405538c0] mmco: unref short failure
[h264 @ 0x55a044c7dfc0] mmco: unref short failure
[h264 @ 0x55a044c7dfc0] mmco: unref short failure
[h264 @ 0x562437b9f340] mmco: unref short failure
[h264 @ 0x55a036424dc0] mmco: unref short failure
[h264 @ 0x55a036424dc0] mmco: unref short failure
[h264 @ 0x55a04332f3c0] mmco: unref short failure
[h264 @ 0x559c01401180] mmco: unref short failure
[h264 @ 0x559c0b62d500] mmco: unref short failure
 53%|█████▎    | 1025/1945 [5:29:55<5:03:34, 19.80s/it][h264 @ 0x55a042aae340] mmco: unref short failure
[h264 @ 0x55a042aae340] mmco: unref short failure
[h264 @ 0x56242d93b5c0] mmco: unref short failure
[h264 @ 0x56242d93b5c0] mmco: unref short failure
[h264 @ 0x559bf5209440] mmco: unref short failure
[h264 @ 0x56243989fc00] mmco: unref short failure
[h264 @ 0x55a043872c80] mmco: unref short failure
[h264 @ 0x562423c2ce80] mmco: unref short failure
[h264 @ 0x562423c2ce80] mmco: unref short failure
 53%|█████▎    | 1026/1945 [5:30:08<4:34:19, 17.91s/it][h264 @ 0x56241b870280] mmco: unref short failure
[h264 @ 0x56241b870280] mmco: unref short failure
[h264 @ 0x56241b870280] mmco: unref short failure
[h264 @ 0x56241b870280] mmco: unref short failure
[h264 @ 0x56241b870280] mmco: unref short failure
[h264 @ 0x56241b870280] mmco: unref short failure
[h264 @ 0x556b34744440] mmco: unref short failure
[h264 @ 0x556b34744440] mmco: unref short failure
[h264 @ 0x55a03e77a740] mmco: unref short failure
 53%|█████▎    | 1027/1945 [5:30:19<4:00:43, 15.73s/it][h264 @ 0x556b434616c0] mmco: unref short failure
[h264 @ 0x556b434616c0] mmco: unref short failure
[h264 @ 0x556b2f4b7340] mmco: unref short failure
 53%|█████▎    | 1028/1945 [5:30:36<4:06:52, 16.15s/it][h264 @ 0x559c0b5a1300] mmco: unref short failure
 53%|█████▎    | 1029/1945 [5:30:43<3:24:59, 13.43s/it][h264 @ 0x556b47390ac0] mmco: unref short failure
[h264 @ 0x556b47390ac0] mmco: unref short failure
[h264 @ 0x559bf42e01c0] mmco: unref short failure
[h264 @ 0x559bf42e01c0] mmco: unref short failure
[h264 @ 0x56241f8a0880] mmco: unref short failure
 53%|█████▎    | 1030/1945 [5:30:53<3:07:10, 12.27s/it][h264 @ 0x5624241c7bc0] mmco: unref short failure
[h264 @ 0x5624241c7bc0] mmco: unref short failure
 53%|█████▎    | 1031/1945 [5:31:00<2:46:12, 10.91s/it][h264 @ 0x55a04acd56c0] mmco: unref short failure
[h264 @ 0x55a04acd56c0] mmco: unref short failure
[h264 @ 0x55a04acd56c0] mmco: unref short failure
[h264 @ 0x559bf52ce600] mmco: unref short failure
[h264 @ 0x55a045a74f00] mmco: unref short failure
[h264 @ 0x55a0481b9600] mmco: unref short failure
[h264 @ 0x55a0481b9600] mmco: unref short failure
[h264 @ 0x56241946ad00] mmco: unref short failure
[h264 @ 0x56241946ad00] mmco: unref short failure
[h264 @ 0x56241946ad00] mmco: unref short failure
[h264 @ 0x56241946ad00] mmco: unref short failure
[h264 @ 0x5624310baec0] mmco: unref short failure
[h264 @ 0x5624310baec0] mmco: unref short failure
 53%|█████▎    | 1032/1945 [5:31:27<3:59:02, 15.71s/it][h264 @ 0x556b34744200] mmco: unref short failure
[h264 @ 0x556b34744200] mmco: unref short failure
[h264 @ 0x56242a989d40] mmco: unref short failure
[h264 @ 0x56242a989d40] mmco: unref short failure
[h264 @ 0x56242a989d40] mmco: unref short failure
[h264 @ 0x56242a989d40] mmco: unref short failure
[h264 @ 0x56242d4f4c40] mmco: unref short failure
[h264 @ 0x556b481fec00] mmco: unref short failure
[h264 @ 0x556b481fec00] mmco: unref short failure
[h264 @ 0x55a03502f440] mmco: unref short failure
[h264 @ 0x55a03502f440] mmco: unref short failure
[h264 @ 0x556b4ceefac0] mmco: unref short failure
[h264 @ 0x556b48216ec0] mmco: unref short failure
[h264 @ 0x556b48216ec0] mmco: unref short failure
[h264 @ 0x56242b8cf3c0] mmco: unref short failure
[h264 @ 0x56242b8cf3c0] mmco: unref short failure
[h264 @ 0x56242b8cf3c0] mmco: unref short failure
[h264 @ 0x56242b8cf3c0] mmco: unref short failure
[h264 @ 0x56242b8cf3c0] mmco: unref short failure
[h264 @ 0x56242b8cf3c0] mmco: unref short failure
[h264 @ 0x56242b8cf3c0] mmco: unref short failure
[h264 @ 0x56242b8cf3c0] mmco: unref short failure
[h264 @ 0x556b2de7eb80] mmco: unref short failure
[h264 @ 0x556b2de7eb80] mmco: unref short failure
[h264 @ 0x559bf58157c0] mmco: unref short failure
 53%|█████▎    | 1033/1945 [5:31:58<5:06:39, 20.18s/it][h264 @ 0x556b46e26640] mmco: unref short failure
[h264 @ 0x56242e0a3240] mmco: unref short failure
[h264 @ 0x55a032dd0980] mmco: unref short failure
[h264 @ 0x55a032dd0980] mmco: unref short failure
[h264 @ 0x55a032dd0980] mmco: unref short failure
[h264 @ 0x55a032dd0980] mmco: unref short failure
[h264 @ 0x55a032dd0980] mmco: unref short failure
[h264 @ 0x55a032dd0980] mmco: unref short failure
[h264 @ 0x55a032dd0980] mmco: unref short failure
[h264 @ 0x55a032dd0980] mmco: unref short failure
[h264 @ 0x55a032dd0980] mmco: unref short failure
[h264 @ 0x55a032dd0980] mmco: unref short failure
[h264 @ 0x55a032dd0980] mmco: unref short failure
[h264 @ 0x55a032dd0980] mmco: unref short failure
 53%|█████▎    | 1034/1945 [5:32:15<4:52:28, 19.26s/it][h264 @ 0x559bf99c4e80] mmco: unref short failure
[h264 @ 0x559bf99c4e80] mmco: unref short failure
 53%|█████▎    | 1035/1945 [5:32:21<3:52:42, 15.34s/it][h264 @ 0x559c0b62d300] mmco: unref short failure
[h264 @ 0x559beb2db840] mmco: unref short failure
[h264 @ 0x559c064a3240] mmco: unref short failure
[h264 @ 0x559c064a3240] mmco: unref short failure
[h264 @ 0x562434864300] mmco: unref short failure
[h264 @ 0x55a033792940] mmco: unref short failure
[h264 @ 0x55a033792940] mmco: unref short failure
[h264 @ 0x55a037a915c0] mmco: unref short failure
[h264 @ 0x55a037a915c0] mmco: unref short failure
[h264 @ 0x559bf0a4c600] mmco: unref short failure
[h264 @ 0x559bf0a4c600] mmco: unref short failure
[h264 @ 0x55a04e941840] mmco: unref short failure
[h264 @ 0x55a04e941840] mmco: unref short failure
[h264 @ 0x55a04e941840] mmco: unref short failure
 53%|█████▎    | 1036/1945 [5:32:40<4:10:01, 16.50s/it][h264 @ 0x562439f46740] mmco: unref short failure
 53%|█████▎    | 1037/1945 [5:32:47<3:26:01, 13.61s/it] 53%|█████▎    | 1038/1945 [5:32:57<3:08:26, 12.47s/it] 53%|█████▎    | 1039/1945 [5:33:03<2:40:56, 10.66s/it][h264 @ 0x559c05100240] mmco: unref short failure
[h264 @ 0x559c05100240] mmco: unref short failure
[h264 @ 0x559c0aae87c0] mmco: unref short failure
[h264 @ 0x559becb45b00] mmco: unref short failure
[h264 @ 0x55a034384900] mmco: unref short failure
[h264 @ 0x55a034384900] mmco: unref short failure
[h264 @ 0x55a036d80a00] mmco: unref short failure
[h264 @ 0x55a036d80a00] mmco: unref short failure
[h264 @ 0x562418bf0180] mmco: unref short failure
 53%|█████▎    | 1040/1945 [5:33:30<3:51:31, 15.35s/it][h264 @ 0x556b3d72a440] mmco: unref short failure
[h264 @ 0x556b3d72a440] mmco: unref short failure
[h264 @ 0x55a03523aec0] mmco: unref short failure
[h264 @ 0x559bef6e6ec0] mmco: unref short failure
[h264 @ 0x559beadcfbc0] mmco: unref short failure
[h264 @ 0x556b3edc2800] mmco: unref short failure
[h264 @ 0x56241bf8fb00] mmco: unref short failure
 54%|█████▎    | 1041/1945 [5:34:04<5:16:12, 20.99s/it][h264 @ 0x55a03d4b4140] mmco: unref short failure
[h264 @ 0x55a03d4b4140] mmco: unref short failure
[h264 @ 0x556b2d76fe00] mmco: unref short failure
[h264 @ 0x556b2d76fe00] mmco: unref short failure
[h264 @ 0x556b2d76fe00] mmco: unref short failure
[h264 @ 0x55a04cec1840] mmco: unref short failure
[h264 @ 0x55a04cec1840] mmco: unref short failure
[h264 @ 0x559c04555c80] mmco: unref short failure
[h264 @ 0x559c04555c80] mmco: unref short failure
 54%|█████▎    | 1042/1945 [5:34:22<5:01:36, 20.04s/it][h264 @ 0x556b3f4248c0] mmco: unref short failure
 54%|█████▎    | 1043/1945 [5:34:31<4:14:31, 16.93s/it] 54%|█████▎    | 1044/1945 [5:34:43<3:50:22, 15.34s/it][h264 @ 0x562439798200] mmco: unref short failure
[h264 @ 0x556b3668d900] mmco: unref short failure
[h264 @ 0x556b3668d900] mmco: unref short failure
[h264 @ 0x556b3668d900] mmco: unref short failure
[h264 @ 0x556b3668d900] mmco: unref short failure
[h264 @ 0x556b3668d900] mmco: unref short failure
[h264 @ 0x556b3668d900] mmco: unref short failure
[h264 @ 0x559c09b431c0] mmco: unref short failure
[h264 @ 0x559c09b431c0] mmco: unref short failure
 54%|█████▎    | 1045/1945 [5:34:50<3:13:54, 12.93s/it][h264 @ 0x56242d08a780] mmco: unref short failure
[h264 @ 0x56242d08a780] mmco: unref short failure
[h264 @ 0x556b33a7c4c0] mmco: unref short failure
[h264 @ 0x556b33a7c4c0] mmco: unref short failure
[h264 @ 0x556b47781700] mmco: unref short failure
[h264 @ 0x556b36ad2bc0] mmco: unref short failure
[h264 @ 0x5624293fa240] mmco: unref short failure
[h264 @ 0x55a035706d80] mmco: unref short failure
[h264 @ 0x55a035706d80] mmco: unref short failure
[h264 @ 0x55a035706d80] mmco: unref short failure
[h264 @ 0x55a035706d80] mmco: unref short failure
[h264 @ 0x55a035706d80] mmco: unref short failure
[h264 @ 0x55a035706d80] mmco: unref short failure
[h264 @ 0x559bffc11140] mmco: unref short failure
 54%|█████▍    | 1046/1945 [5:35:08<3:33:49, 14.27s/it][h264 @ 0x556b2efb5a00] mmco: unref short failure
[h264 @ 0x556b2efb5a00] mmco: unref short failure
[h264 @ 0x562434ec6dc0] mmco: unref short failure
 54%|█████▍    | 1047/1945 [5:35:15<3:03:04, 12.23s/it][h264 @ 0x55a049aeae40] mmco: unref short failure
[h264 @ 0x55a049aeae40] mmco: unref short failure
 54%|█████▍    | 1048/1945 [5:35:31<3:19:01, 13.31s/it][h264 @ 0x556b4a994540] mmco: unref short failure
[h264 @ 0x55a036046cc0] mmco: unref short failure
[h264 @ 0x55a036f73a00] mmco: unref short failure
[h264 @ 0x55a036f73a00] mmco: unref short failure
[h264 @ 0x559bfa80c900] mmco: unref short failure
[h264 @ 0x559bfa80c900] mmco: unref short failure
[h264 @ 0x556b3477d640] mmco: unref short failure
[h264 @ 0x556b3477d640] mmco: unref short failure
 54%|█████▍    | 1049/1945 [5:36:13<5:28:23, 21.99s/it]09/09/2024 22:41:35 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 22:41:35 - INFO - __main__ -   start running ret%tv validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x56242a254ac0] mmco: unref short failure
[h264 @ 0x56242a254ac0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556b51077bc0] mmco: unref short failure
[h264 @ 0x556b51077bc0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556b4fc23800] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559c06c500c0] mmco: unref short failure
[h264 @ 0x559c06c500c0] mmco: unref short failure
[h264 @ 0x556b4a7f9200] mmco: unref short failure
[h264 @ 0x556b4a7f9200] mmco: unref short failure
[h264 @ 0x559c0844bd40] mmco: unref short failure
[h264 @ 0x556b31282a00] mmco: unref short failure
[h264 @ 0x55a055ced7c0] mmco: unref short failure
[h264 @ 0x556b39c34fc0] mmco: unref short failure
[h264 @ 0x556b39c34fc0] mmco: unref short failure
[h264 @ 0x56242345ce40] mmco: unref short failure
[h264 @ 0x562419018fc0] mmco: unref short failure
[h264 @ 0x562419018fc0] mmco: unref short failure
[h264 @ 0x559bfd224080] mmco: unref short failure
[h264 @ 0x559bfd224080] mmco: unref short failure
[h264 @ 0x556b46ccf3c0] mmco: unref short failure
[h264 @ 0x556b46ccf3c0] mmco: unref short failure
[h264 @ 0x56242e3d8200] mmco: unref short failure
[h264 @ 0x56242e3d8200] mmco: unref short failure
[h264 @ 0x56242e3d8200] mmco: unref short failure
[h264 @ 0x56242e3d8200] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:29,  1.47it/s][A
  1%|          | 2/221 [00:01<02:11,  1.66it/s][A
  1%|▏         | 3/221 [00:01<01:35,  2.29it/s][A
  2%|▏         | 4/221 [00:01<01:14,  2.92it/s][A
  2%|▏         | 5/221 [00:01<01:07,  3.18it/s][A
  3%|▎         | 6/221 [00:02<00:54,  3.95it/s][A
  3%|▎         | 7/221 [00:02<00:53,  4.03it/s][A[h264 @ 0x559c05b78480] mmco: unref short failure
[h264 @ 0x559c05b78480] mmco: unref short failure

  4%|▎         | 8/221 [00:02<01:18,  2.73it/s][A
  4%|▍         | 9/221 [00:03<01:16,  2.78it/s][A
  5%|▍         | 10/221 [00:03<01:17,  2.74it/s][A
  5%|▌         | 12/221 [00:04<01:16,  2.73it/s][A
  6%|▌         | 13/221 [00:04<01:07,  3.09it/s][A
  6%|▋         | 14/221 [00:06<02:47,  1.24it/s][A
  7%|▋         | 15/221 [00:06<02:12,  1.55it/s][A
  7%|▋         | 16/221 [00:07<01:57,  1.74it/s][A
  8%|▊         | 17/221 [00:07<01:37,  2.10it/s][A[h264 @ 0x562428647040] mmco: unref short failure

  8%|▊         | 18/221 [00:07<01:24,  2.40it/s][A
  9%|▊         | 19/221 [00:07<01:08,  2.97it/s][A
 10%|▉         | 21/221 [00:08<00:51,  3.92it/s][A
 10%|▉         | 22/221 [00:08<00:52,  3.77it/s][A
 10%|█         | 23/221 [00:08<00:44,  4.48it/s][A
 11%|█         | 24/221 [00:08<00:38,  5.09it/s][A
 11%|█▏        | 25/221 [00:09<00:37,  5.25it/s][A
 12%|█▏        | 26/221 [00:09<00:42,  4.58it/s][A
 13%|█▎        | 28/221 [00:09<00:41,  4.62it/s][A
 13%|█▎        | 29/221 [00:09<00:41,  4.68it/s][A
 14%|█▎        | 30/221 [00:10<00:49,  3.88it/s][A
 14%|█▍        | 31/221 [00:10<00:48,  3.90it/s][A
 14%|█▍        | 32/221 [00:10<00:45,  4.18it/s][A
 15%|█▍        | 33/221 [00:11<00:51,  3.63it/s][A
 15%|█▌        | 34/221 [00:11<00:43,  4.28it/s][A
 16%|█▌        | 35/221 [00:11<00:38,  4.85it/s][A
 16%|█▋        | 36/221 [00:11<00:40,  4.60it/s][A
 17%|█▋        | 37/221 [00:12<01:02,  2.97it/s][A
 17%|█▋        | 38/221 [00:12<00:59,  3.09it/s][A
 18%|█▊        | 40/221 [00:12<00:49,  3.63it/s][A
 19%|█▊        | 41/221 [00:13<00:43,  4.10it/s][A
 19%|█▉        | 42/221 [00:13<00:47,  3.74it/s][A
 20%|█▉        | 44/221 [00:13<00:34,  5.10it/s][A
 20%|██        | 45/221 [00:14<01:03,  2.77it/s][A
 21%|██        | 46/221 [00:14<01:04,  2.71it/s][A[h264 @ 0x562434864780] mmco: unref short failure

 21%|██▏       | 47/221 [00:15<01:24,  2.07it/s][A
 22%|██▏       | 48/221 [00:15<01:06,  2.62it/s][A
 22%|██▏       | 49/221 [00:16<00:53,  3.24it/s][A
 23%|██▎       | 51/221 [00:16<00:41,  4.14it/s][A
 24%|██▎       | 52/221 [00:16<00:36,  4.65it/s][A
 24%|██▍       | 53/221 [00:16<00:33,  4.96it/s][A
 24%|██▍       | 54/221 [00:17<00:57,  2.91it/s][A
 25%|██▍       | 55/221 [00:17<00:59,  2.79it/s][A
 25%|██▌       | 56/221 [00:18<00:55,  2.96it/s][A
 26%|██▌       | 57/221 [00:18<00:48,  3.40it/s][A
 26%|██▌       | 58/221 [00:18<00:39,  4.15it/s][A
 27%|██▋       | 59/221 [00:18<00:34,  4.73it/s][A
 27%|██▋       | 60/221 [00:18<00:38,  4.18it/s][A
 28%|██▊       | 61/221 [00:19<00:38,  4.11it/s][A
 28%|██▊       | 62/221 [00:19<00:36,  4.39it/s][A
 29%|██▊       | 63/221 [00:19<00:33,  4.67it/s][A
 29%|██▉       | 64/221 [00:19<00:30,  5.09it/s][A[h264 @ 0x559bf2307bc0] mmco: unref short failure
[h264 @ 0x559bf2307bc0] mmco: unref short failure

 29%|██▉       | 65/221 [00:19<00:28,  5.53it/s][A
 30%|██▉       | 66/221 [00:20<00:36,  4.28it/s][A
 30%|███       | 67/221 [00:20<00:37,  4.13it/s][A
 31%|███       | 68/221 [00:20<00:31,  4.79it/s][A
 31%|███       | 69/221 [00:20<00:46,  3.27it/s][A
 32%|███▏      | 70/221 [00:21<00:38,  3.89it/s][A
 32%|███▏      | 71/221 [00:22<01:07,  2.23it/s][A
 33%|███▎      | 72/221 [00:22<00:56,  2.64it/s][A
 33%|███▎      | 73/221 [00:22<00:57,  2.58it/s][A
 33%|███▎      | 74/221 [00:22<00:46,  3.17it/s][A
 34%|███▍      | 75/221 [00:23<00:45,  3.20it/s][A
 34%|███▍      | 76/221 [00:23<00:38,  3.81it/s][A
 35%|███▍      | 77/221 [00:23<00:33,  4.36it/s][A
 35%|███▌      | 78/221 [00:23<00:34,  4.14it/s][A
 36%|███▌      | 79/221 [00:24<00:52,  2.70it/s][A
 36%|███▌      | 80/221 [00:24<00:46,  3.05it/s][A
 37%|███▋      | 81/221 [00:24<00:44,  3.14it/s][A
 37%|███▋      | 82/221 [00:25<00:41,  3.31it/s][A
 38%|███▊      | 83/221 [00:25<00:42,  3.28it/s][A
 38%|███▊      | 84/221 [00:25<00:42,  3.23it/s][A
 38%|███▊      | 85/221 [00:26<00:41,  3.28it/s][A
 39%|███▉      | 86/221 [00:26<00:35,  3.76it/s][A
 39%|███▉      | 87/221 [00:26<00:45,  2.97it/s][A
 40%|███▉      | 88/221 [00:27<00:43,  3.09it/s][A
 40%|████      | 89/221 [00:29<01:50,  1.20it/s][A
 41%|████      | 90/221 [00:29<01:24,  1.55it/s][A
 41%|████      | 91/221 [00:29<01:03,  2.04it/s][A
 42%|████▏     | 92/221 [00:29<00:52,  2.47it/s][A
 42%|████▏     | 93/221 [00:30<00:54,  2.35it/s][A
 43%|████▎     | 94/221 [00:30<00:48,  2.61it/s][A
 43%|████▎     | 95/221 [00:30<00:42,  2.98it/s][A
 43%|████▎     | 96/221 [00:30<00:36,  3.43it/s][A
 44%|████▍     | 98/221 [00:31<00:27,  4.50it/s][A
 45%|████▍     | 99/221 [00:31<00:23,  5.15it/s][A
 45%|████▌     | 100/221 [00:31<00:23,  5.15it/s][A
 46%|████▌     | 101/221 [00:31<00:21,  5.68it/s][A
 46%|████▌     | 102/221 [00:31<00:26,  4.53it/s][A
 47%|████▋     | 103/221 [00:31<00:22,  5.31it/s][A
 48%|████▊     | 105/221 [00:32<00:18,  6.12it/s][A
 48%|████▊     | 106/221 [00:33<00:39,  2.95it/s][A
 48%|████▊     | 107/221 [00:33<00:35,  3.23it/s][A
 49%|████▉     | 108/221 [00:33<00:32,  3.43it/s][A
 49%|████▉     | 109/221 [00:33<00:30,  3.71it/s][A
 50%|████▉     | 110/221 [00:33<00:27,  4.01it/s][A
 50%|█████     | 111/221 [00:34<00:31,  3.52it/s][A
 51%|█████     | 112/221 [00:34<00:30,  3.55it/s][A
 51%|█████     | 113/221 [00:34<00:33,  3.22it/s][A
 52%|█████▏    | 115/221 [00:35<00:22,  4.72it/s][A
 52%|█████▏    | 116/221 [00:38<01:46,  1.01s/it][A
 53%|█████▎    | 117/221 [00:38<01:25,  1.22it/s][A
 53%|█████▎    | 118/221 [00:39<01:11,  1.45it/s][A
 54%|█████▍    | 119/221 [00:39<00:53,  1.90it/s][A
 54%|█████▍    | 120/221 [00:39<00:47,  2.14it/s][A
 55%|█████▌    | 122/221 [00:39<00:31,  3.19it/s][A
 56%|█████▌    | 123/221 [00:40<00:27,  3.58it/s][A
 56%|█████▌    | 124/221 [00:40<00:25,  3.76it/s][A
 57%|█████▋    | 125/221 [00:40<00:25,  3.83it/s][A
 57%|█████▋    | 126/221 [00:40<00:25,  3.71it/s][A
 57%|█████▋    | 127/221 [00:41<00:28,  3.26it/s][A
 58%|█████▊    | 128/221 [00:41<00:28,  3.23it/s][A
 58%|█████▊    | 129/221 [00:41<00:24,  3.80it/s][A
 59%|█████▉    | 130/221 [00:41<00:21,  4.19it/s][A
 60%|█████▉    | 132/221 [00:42<00:16,  5.43it/s][A
 60%|██████    | 133/221 [00:42<00:21,  4.11it/s][A
 61%|██████    | 134/221 [00:42<00:20,  4.25it/s][A
 61%|██████    | 135/221 [00:43<00:24,  3.55it/s][A
 62%|██████▏   | 136/221 [00:43<00:25,  3.29it/s][A
 62%|██████▏   | 137/221 [00:43<00:21,  3.89it/s][A
 62%|██████▏   | 138/221 [00:44<00:23,  3.58it/s][A
 63%|██████▎   | 139/221 [00:44<00:24,  3.30it/s][A
 63%|██████▎   | 140/221 [00:44<00:24,  3.36it/s][A
 64%|██████▍   | 141/221 [00:44<00:22,  3.62it/s][A
 64%|██████▍   | 142/221 [00:45<00:28,  2.74it/s][A
 65%|██████▍   | 143/221 [00:45<00:28,  2.73it/s][A
 66%|██████▌   | 145/221 [00:45<00:17,  4.35it/s][A
 67%|██████▋   | 147/221 [00:46<00:14,  5.26it/s][A
 67%|██████▋   | 148/221 [00:46<00:14,  5.15it/s][A
 68%|██████▊   | 150/221 [00:46<00:10,  6.86it/s][A
 68%|██████▊   | 151/221 [00:47<00:17,  3.94it/s][A[h264 @ 0x559bf5829200] mmco: unref short failure
[h264 @ 0x559bf5829200] mmco: unref short failure

 69%|██████▉   | 152/221 [00:47<00:16,  4.12it/s][A
 69%|██████▉   | 153/221 [00:47<00:18,  3.76it/s][A
 70%|██████▉   | 154/221 [00:48<00:20,  3.24it/s][A
 71%|███████   | 156/221 [00:48<00:15,  4.33it/s][A[h264 @ 0x55a04e9f9400] mmco: unref short failure
[h264 @ 0x556b2f260b80] mmco: unref short failure

 71%|███████   | 157/221 [00:51<01:02,  1.03it/s][A
 71%|███████▏  | 158/221 [00:51<00:47,  1.32it/s][A
 72%|███████▏  | 159/221 [00:52<00:38,  1.63it/s][A
 72%|███████▏  | 160/221 [00:52<00:29,  2.07it/s][A
 73%|███████▎  | 162/221 [00:52<00:19,  3.02it/s][A
 74%|███████▍  | 163/221 [00:52<00:17,  3.29it/s][A
 74%|███████▍  | 164/221 [00:52<00:14,  3.84it/s][A
 75%|███████▌  | 166/221 [00:53<00:14,  3.90it/s][A
 76%|███████▌  | 167/221 [00:53<00:12,  4.44it/s][A[h264 @ 0x5624246e6180] mmco: unref short failure

 76%|███████▌  | 168/221 [00:57<01:00,  1.15s/it][A
 76%|███████▋  | 169/221 [00:57<00:46,  1.12it/s][A
 77%|███████▋  | 170/221 [00:57<00:36,  1.40it/s][A
 77%|███████▋  | 171/221 [00:58<00:27,  1.81it/s][A
 78%|███████▊  | 172/221 [00:58<00:22,  2.19it/s][A
 79%|███████▊  | 174/221 [00:58<00:13,  3.53it/s][A
 79%|███████▉  | 175/221 [00:58<00:12,  3.59it/s][A
 80%|███████▉  | 176/221 [00:58<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:59<00:10,  4.10it/s][A
 81%|████████  | 179/221 [00:59<00:13,  3.10it/s][A
 82%|████████▏ | 181/221 [01:00<00:09,  4.10it/s][A
 82%|████████▏ | 182/221 [01:00<00:08,  4.48it/s][A
 83%|████████▎ | 183/221 [01:00<00:07,  4.76it/s][A
 83%|████████▎ | 184/221 [01:00<00:08,  4.31it/s][A
 84%|████████▎ | 185/221 [01:00<00:07,  4.65it/s][A
 84%|████████▍ | 186/221 [01:01<00:09,  3.83it/s][A
 85%|████████▍ | 187/221 [01:01<00:07,  4.45it/s][A
 85%|████████▌ | 188/221 [01:01<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [01:02<00:08,  3.98it/s][A
 86%|████████▌ | 190/221 [01:02<00:07,  4.09it/s][A
 87%|████████▋ | 192/221 [01:02<00:05,  5.03it/s][A
 88%|████████▊ | 194/221 [01:03<00:06,  4.16it/s][A
 88%|████████▊ | 195/221 [01:03<00:05,  4.62it/s][A
 89%|████████▉ | 197/221 [01:03<00:03,  6.15it/s][A
 90%|████████▉ | 198/221 [01:03<00:04,  5.28it/s][A
 90%|█████████ | 199/221 [01:03<00:03,  5.89it/s][A
 90%|█████████ | 200/221 [01:04<00:04,  4.65it/s][A
 91%|█████████ | 201/221 [01:04<00:04,  4.69it/s][A
 91%|█████████▏| 202/221 [01:04<00:03,  4.98it/s][A
 92%|█████████▏| 204/221 [01:04<00:02,  6.70it/s][A
 93%|█████████▎| 206/221 [01:05<00:03,  4.45it/s][A
 94%|█████████▍| 208/221 [01:05<00:02,  5.66it/s][A
 95%|█████████▌| 210/221 [01:05<00:01,  7.39it/s][A
 96%|█████████▌| 212/221 [01:06<00:01,  6.34it/s][A
 97%|█████████▋| 214/221 [01:06<00:01,  5.51it/s][A
 97%|█████████▋| 215/221 [01:06<00:01,  5.64it/s][A
 98%|█████████▊| 216/221 [01:06<00:00,  5.48it/s][A
 98%|█████████▊| 217/221 [01:07<00:01,  3.39it/s][A
 99%|█████████▊| 218/221 [01:07<00:00,  3.84it/s][A
 99%|█████████▉| 219/221 [01:07<00:00,  4.05it/s][A
100%|█████████▉| 220/221 [01:11<00:01,  1.23s/it][A
100%|██████████| 221/221 [01:12<00:00,  1.07it/s][A100%|██████████| 221/221 [01:12<00:00,  3.07it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:57,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:51,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:38,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:22<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:19,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:51<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:57<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:28,  7.67it/s][A
  1%|          | 2/221 [00:00<00:49,  4.44it/s][A
  1%|▏         | 3/221 [00:00<00:56,  3.89it/s][A
  2%|▏         | 4/221 [00:00<00:48,  4.51it/s][A
  2%|▏         | 5/221 [00:01<00:47,  4.56it/s][A
  3%|▎         | 7/221 [00:01<00:42,  5.01it/s][A
  4%|▎         | 8/221 [00:01<00:52,  4.04it/s][A
  4%|▍         | 9/221 [00:02<00:50,  4.19it/s][A
  5%|▍         | 10/221 [00:02<01:08,  3.08it/s][A
  5%|▍         | 11/221 [00:02<01:00,  3.47it/s][A
  5%|▌         | 12/221 [00:02<00:51,  4.04it/s][A
  6%|▌         | 13/221 [00:03<01:31,  2.28it/s][A
  6%|▋         | 14/221 [00:03<01:11,  2.89it/s][A
  7%|▋         | 15/221 [00:04<01:03,  3.24it/s][A
  7%|▋         | 16/221 [00:04<01:08,  3.00it/s][A
  8%|▊         | 17/221 [00:05<01:25,  2.39it/s][A
  8%|▊         | 18/221 [00:05<01:12,  2.80it/s][A
  9%|▊         | 19/221 [00:05<01:00,  3.32it/s][A
 10%|▉         | 21/221 [00:05<00:44,  4.53it/s][A
 10%|▉         | 22/221 [00:06<00:41,  4.75it/s][A
 11%|█         | 24/221 [00:06<00:34,  5.66it/s][A
 11%|█▏        | 25/221 [00:06<00:35,  5.59it/s][A
 12%|█▏        | 26/221 [00:06<00:37,  5.17it/s][A
 12%|█▏        | 27/221 [00:06<00:33,  5.71it/s][A
 13%|█▎        | 28/221 [00:07<00:41,  4.62it/s][A
 13%|█▎        | 29/221 [00:07<00:42,  4.54it/s][A
 14%|█▎        | 30/221 [00:07<00:48,  3.97it/s][A
 14%|█▍        | 31/221 [00:07<00:46,  4.07it/s][A
 15%|█▍        | 33/221 [00:08<00:36,  5.13it/s][A
 15%|█▌        | 34/221 [00:08<00:38,  4.82it/s][A
 16%|█▌        | 35/221 [00:08<00:43,  4.28it/s][A
 16%|█▋        | 36/221 [00:09<00:46,  3.96it/s][A
 17%|█▋        | 37/221 [00:09<00:40,  4.55it/s][A
 17%|█▋        | 38/221 [00:09<00:43,  4.20it/s][A
 18%|█▊        | 39/221 [00:09<00:40,  4.55it/s][A
 18%|█▊        | 40/221 [00:10<00:48,  3.74it/s][A
 19%|█▊        | 41/221 [00:10<00:40,  4.40it/s][A
 19%|█▉        | 42/221 [00:10<00:35,  5.07it/s][A
 19%|█▉        | 43/221 [00:10<00:41,  4.24it/s][A
 20%|█▉        | 44/221 [00:10<00:41,  4.23it/s][A
 20%|██        | 45/221 [00:11<00:45,  3.90it/s][A
 21%|██        | 46/221 [00:11<00:40,  4.32it/s][A
 21%|██▏       | 47/221 [00:11<00:39,  4.39it/s][A
 22%|██▏       | 48/221 [00:11<00:34,  5.00it/s][A
 22%|██▏       | 49/221 [00:11<00:35,  4.81it/s][A
 23%|██▎       | 50/221 [00:12<00:47,  3.58it/s][A
 23%|██▎       | 51/221 [00:12<00:41,  4.11it/s][A
 24%|██▎       | 52/221 [00:12<00:43,  3.86it/s][A
 24%|██▍       | 53/221 [00:12<00:39,  4.30it/s][A
 24%|██▍       | 54/221 [00:13<00:52,  3.16it/s][A
 25%|██▍       | 55/221 [00:13<00:48,  3.45it/s][A
 25%|██▌       | 56/221 [00:13<00:41,  3.93it/s][A
 26%|██▌       | 57/221 [00:14<00:42,  3.89it/s][A
 26%|██▌       | 58/221 [00:14<00:48,  3.36it/s][A
 27%|██▋       | 59/221 [00:14<00:42,  3.78it/s][A
 27%|██▋       | 60/221 [00:14<00:36,  4.36it/s][A
 28%|██▊       | 61/221 [00:15<00:34,  4.66it/s][A
 28%|██▊       | 62/221 [00:15<00:35,  4.51it/s][A
 29%|██▊       | 63/221 [00:15<00:34,  4.62it/s][A
 29%|██▉       | 64/221 [00:15<00:43,  3.64it/s][A
 29%|██▉       | 65/221 [00:16<00:38,  4.02it/s][A
 30%|██▉       | 66/221 [00:16<00:50,  3.10it/s][A
 30%|███       | 67/221 [00:16<00:52,  2.93it/s][A
 31%|███       | 68/221 [00:17<00:44,  3.43it/s][A
 31%|███       | 69/221 [00:17<01:05,  2.31it/s][A
 32%|███▏      | 70/221 [00:18<00:50,  2.98it/s][A
 32%|███▏      | 71/221 [00:18<00:44,  3.38it/s][A
 33%|███▎      | 72/221 [00:18<00:48,  3.09it/s][A
 33%|███▎      | 73/221 [00:18<00:47,  3.11it/s][A
 33%|███▎      | 74/221 [00:19<00:40,  3.59it/s][A
 34%|███▍      | 75/221 [00:19<00:39,  3.66it/s][A
 34%|███▍      | 76/221 [00:19<00:37,  3.91it/s][A
 35%|███▍      | 77/221 [00:19<00:38,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:34,  4.09it/s][A
 36%|███▌      | 79/221 [00:20<00:43,  3.25it/s][A
 36%|███▌      | 80/221 [00:20<00:40,  3.51it/s][A
 37%|███▋      | 81/221 [00:21<00:37,  3.69it/s][A
 37%|███▋      | 82/221 [00:21<00:42,  3.28it/s][A
 38%|███▊      | 83/221 [00:21<00:44,  3.11it/s][A
 38%|███▊      | 84/221 [00:21<00:40,  3.38it/s][A
 38%|███▊      | 85/221 [00:22<00:33,  4.09it/s][A
 39%|███▉      | 86/221 [00:22<00:36,  3.68it/s][A
 39%|███▉      | 87/221 [00:22<00:46,  2.91it/s][A
 40%|███▉      | 88/221 [00:23<00:50,  2.63it/s][A
 40%|████      | 89/221 [00:23<00:44,  2.98it/s][A
 41%|████      | 90/221 [00:24<00:47,  2.74it/s][A
 41%|████      | 91/221 [00:24<00:38,  3.34it/s][A
 42%|████▏     | 92/221 [00:24<00:41,  3.10it/s][A
 42%|████▏     | 93/221 [00:25<00:54,  2.34it/s][A
 43%|████▎     | 94/221 [00:25<00:48,  2.60it/s][A
 43%|████▎     | 95/221 [00:25<00:43,  2.90it/s][A
 43%|████▎     | 96/221 [00:26<00:37,  3.36it/s][A
 44%|████▍     | 97/221 [00:26<00:32,  3.87it/s][A
 44%|████▍     | 98/221 [00:26<00:32,  3.84it/s][A
 45%|████▍     | 99/221 [00:26<00:28,  4.28it/s][A
 45%|████▌     | 100/221 [00:26<00:29,  4.05it/s][A
 46%|████▌     | 101/221 [00:27<00:28,  4.21it/s][A
 46%|████▌     | 102/221 [00:27<00:44,  2.66it/s][A
 47%|████▋     | 103/221 [00:27<00:35,  3.34it/s][A
 47%|████▋     | 104/221 [00:28<00:31,  3.76it/s][A
 48%|████▊     | 105/221 [00:28<00:29,  3.92it/s][A
 48%|████▊     | 106/221 [00:28<00:37,  3.09it/s][A
 48%|████▊     | 107/221 [00:29<00:32,  3.53it/s][A
 49%|████▉     | 108/221 [00:29<00:32,  3.52it/s][A
 50%|████▉     | 110/221 [00:29<00:25,  4.33it/s][A
 50%|█████     | 111/221 [00:29<00:26,  4.09it/s][A
 51%|█████     | 112/221 [00:30<00:26,  4.14it/s][A
 51%|█████     | 113/221 [00:30<00:23,  4.62it/s][A
 52%|█████▏    | 115/221 [00:30<00:19,  5.41it/s][A
 52%|█████▏    | 116/221 [00:30<00:21,  4.98it/s][A
 53%|█████▎    | 117/221 [00:31<00:21,  4.75it/s][A
 53%|█████▎    | 118/221 [00:31<00:21,  4.70it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.81it/s][A
 54%|█████▍    | 120/221 [00:31<00:24,  4.09it/s][A
 55%|█████▍    | 121/221 [00:32<00:20,  4.77it/s][A
 55%|█████▌    | 122/221 [00:32<00:22,  4.44it/s][A
 56%|█████▌    | 123/221 [00:32<00:23,  4.11it/s][A
 56%|█████▌    | 124/221 [00:32<00:23,  4.16it/s][A
 57%|█████▋    | 125/221 [00:33<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:33<00:24,  3.83it/s][A
 57%|█████▋    | 127/221 [00:33<00:30,  3.04it/s][A
 58%|█████▊    | 128/221 [00:34<00:27,  3.39it/s][A
 58%|█████▊    | 129/221 [00:34<00:22,  4.11it/s][A
 59%|█████▉    | 130/221 [00:34<00:23,  3.84it/s][A
 59%|█████▉    | 131/221 [00:34<00:19,  4.65it/s][A
 60%|█████▉    | 132/221 [00:35<00:22,  3.87it/s][A
 60%|██████    | 133/221 [00:35<00:24,  3.54it/s][A
 61%|██████    | 134/221 [00:35<00:30,  2.86it/s][A
 61%|██████    | 135/221 [00:36<00:31,  2.70it/s][A
 62%|██████▏   | 136/221 [00:36<00:27,  3.07it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.75it/s][A
 62%|██████▏   | 138/221 [00:36<00:22,  3.70it/s][A
 63%|██████▎   | 139/221 [00:37<00:27,  2.94it/s][A
 63%|██████▎   | 140/221 [00:37<00:26,  3.06it/s][A
 64%|██████▍   | 141/221 [00:37<00:23,  3.41it/s][A
 64%|██████▍   | 142/221 [00:38<00:20,  3.77it/s][A
 65%|██████▍   | 143/221 [00:38<00:30,  2.59it/s][A
 65%|██████▌   | 144/221 [00:39<00:30,  2.55it/s][A
 66%|██████▌   | 146/221 [00:39<00:18,  4.01it/s][A
 67%|██████▋   | 147/221 [00:39<00:18,  3.97it/s][A
 67%|██████▋   | 148/221 [00:40<00:22,  3.31it/s][A
 67%|██████▋   | 149/221 [00:40<00:20,  3.47it/s][A
 68%|██████▊   | 150/221 [00:40<00:19,  3.61it/s][A
 68%|██████▊   | 151/221 [00:41<00:22,  3.08it/s][A
 69%|██████▉   | 152/221 [00:41<00:33,  2.08it/s][A
 69%|██████▉   | 153/221 [00:41<00:25,  2.67it/s][A
 70%|██████▉   | 154/221 [00:42<00:21,  3.12it/s][A
 70%|███████   | 155/221 [00:42<00:18,  3.57it/s][A
 71%|███████   | 156/221 [00:42<00:21,  3.01it/s][A
 71%|███████   | 157/221 [00:43<00:20,  3.09it/s][A
 71%|███████▏  | 158/221 [00:43<00:19,  3.30it/s][A
 72%|███████▏  | 159/221 [00:43<00:15,  4.00it/s][A
 72%|███████▏  | 160/221 [00:43<00:13,  4.36it/s][A
 73%|███████▎  | 161/221 [00:44<00:17,  3.51it/s][A
 73%|███████▎  | 162/221 [00:44<00:15,  3.86it/s][A
 74%|███████▍  | 163/221 [00:44<00:14,  3.98it/s][A
 74%|███████▍  | 164/221 [00:44<00:12,  4.62it/s][A
 75%|███████▍  | 165/221 [00:44<00:11,  4.71it/s][A
 75%|███████▌  | 166/221 [00:45<00:11,  4.61it/s][A
 76%|███████▌  | 167/221 [00:45<00:09,  5.42it/s][A
 76%|███████▌  | 168/221 [00:45<00:10,  5.07it/s][A
 76%|███████▋  | 169/221 [00:45<00:09,  5.72it/s][A
 77%|███████▋  | 170/221 [00:46<00:13,  3.71it/s][A
 77%|███████▋  | 171/221 [00:46<00:12,  3.98it/s][A
 78%|███████▊  | 172/221 [00:46<00:11,  4.19it/s][A
 78%|███████▊  | 173/221 [00:46<00:13,  3.68it/s][A
 79%|███████▊  | 174/221 [00:47<00:15,  3.02it/s][A
 79%|███████▉  | 175/221 [00:47<00:15,  3.06it/s][A
 80%|███████▉  | 176/221 [00:47<00:13,  3.30it/s][A
 80%|████████  | 177/221 [00:48<00:12,  3.55it/s][A
 81%|████████  | 178/221 [00:48<00:12,  3.48it/s][A
 81%|████████  | 179/221 [00:48<00:11,  3.66it/s][A
 81%|████████▏ | 180/221 [00:48<00:09,  4.32it/s][A
 82%|████████▏ | 181/221 [00:48<00:09,  4.28it/s][A
 82%|████████▏ | 182/221 [00:49<00:11,  3.39it/s][A
 83%|████████▎ | 183/221 [00:49<00:12,  3.11it/s][A
 83%|████████▎ | 184/221 [00:50<00:10,  3.39it/s][A
 84%|████████▎ | 185/221 [00:50<00:09,  3.94it/s][A
 84%|████████▍ | 186/221 [00:50<00:11,  2.99it/s][A
 85%|████████▍ | 187/221 [00:50<00:10,  3.38it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.36it/s][A
 86%|████████▌ | 189/221 [00:51<00:08,  3.60it/s][A
 86%|████████▌ | 190/221 [00:51<00:09,  3.14it/s][A
 86%|████████▋ | 191/221 [00:52<00:08,  3.68it/s][A
 87%|████████▋ | 192/221 [00:52<00:08,  3.55it/s][A
 87%|████████▋ | 193/221 [00:52<00:06,  4.24it/s][A
 88%|████████▊ | 194/221 [00:52<00:07,  3.70it/s][A
 88%|████████▊ | 195/221 [00:53<00:06,  4.02it/s][A
 89%|████████▊ | 196/221 [00:53<00:06,  3.61it/s][A
 89%|████████▉ | 197/221 [00:53<00:06,  3.85it/s][A
 90%|████████▉ | 198/221 [00:54<00:07,  3.07it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.46it/s][A
 90%|█████████ | 200/221 [00:54<00:07,  2.98it/s][A
 91%|█████████ | 201/221 [00:54<00:05,  3.47it/s][A
 91%|█████████▏| 202/221 [00:55<00:05,  3.21it/s][A
 92%|█████████▏| 203/221 [00:55<00:05,  3.60it/s][A
 92%|█████████▏| 204/221 [00:55<00:05,  3.38it/s][A
 93%|█████████▎| 205/221 [00:55<00:03,  4.19it/s][A
 93%|█████████▎| 206/221 [00:56<00:04,  3.54it/s][A
 94%|█████████▎| 207/221 [00:56<00:03,  3.87it/s][A
 94%|█████████▍| 208/221 [00:56<00:03,  3.87it/s][A
 95%|█████████▍| 209/221 [00:57<00:03,  3.86it/s][A
 95%|█████████▌| 210/221 [00:57<00:02,  4.38it/s][A
 95%|█████████▌| 211/221 [00:57<00:02,  3.92it/s][A
 96%|█████████▌| 212/221 [00:57<00:02,  3.55it/s][A
 96%|█████████▋| 213/221 [00:58<00:02,  3.89it/s][A
 97%|█████████▋| 214/221 [00:58<00:02,  2.53it/s][A
 97%|█████████▋| 215/221 [00:58<00:01,  3.00it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.23it/s][A
 98%|█████████▊| 217/221 [00:59<00:01,  3.23it/s][A
 99%|█████████▊| 218/221 [00:59<00:00,  3.32it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.22it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.68it/s][A
100%|██████████| 221/221 [01:00<00:00,  4.01it/s][A100%|██████████| 221/221 [01:00<00:00,  3.65it/s]
09/09/2024 22:47:25 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 1049--===========

09/09/2024 22:47:25 - INFO - __main__ -   {'area_r1': 39.6, 'area_recall': '39.6/63.1/74.3', 'area_ravg': 59.0}
09/09/2024 22:47:25 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 1049--===========

09/09/2024 22:47:25 - INFO - __main__ -   {'forward_r1': 38.0, 'forward_recall': '38.0/66.9/77.4', 'forward_ravg': 60.7}
09/09/2024 22:47:25 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 1049--===========

09/09/2024 22:47:25 - INFO - __main__ -   {'area_video_r1': 38.7, 'area_video_recall': '38.7/67.3/77.5', 'area_video_ravg': 61.2}
09/09/2024 22:47:25 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/09/2024 22:47:25 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 22:47:25 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 1049--===========

09/09/2024 22:47:25 - INFO - __main__ -   {'area_video_r1': 52.8, 'area_video_recall': '52.8/75.0/82.5', 'area_video_ravg': 70.1, 'area_video_back_r1': 48.0, 'area_video_back_recall': '48.0/74.4/82.2', 'area_video_back_ravg': 68.2}
09/09/2024 22:47:25 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/09/2024 22:47:25 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/09/2024 22:47:25 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 1049--===========

09/09/2024 22:47:25 - INFO - __main__ -   {'video_r1': 43.6, 'video_recall': '43.6/71.8/82.7', 'video_ravg': 66.0}
09/09/2024 22:47:25 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 22:47:25 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 22:47:25 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 1049--===========

09/09/2024 22:47:25 - INFO - __main__ -   {'video_r1': 52.5, 'video_recall': '52.5/75.3/82.7', 'video_ravg': 70.2}
09/09/2024 22:47:25 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/09/2024 22:47:25 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/09/2024 22:47:46 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.006907482631504536, 'loss_ret%tv%ta--finetune_area/loss_area': 1.061356782913208, 'loss_ret%tv%ta--finetune_area/total_loss': 1.0682642459869385}
 54%|█████▍    | 1050/1945 [5:42:27<31:42:43, 127.56s/it][h264 @ 0x55a0513f3980] mmco: unref short failure
[h264 @ 0x55a0481b9180] mmco: unref short failure
[h264 @ 0x55a0481b9180] mmco: unref short failure
 54%|█████▍    | 1051/1945 [5:42:31<22:29:07, 90.55s/it] [h264 @ 0x559bffbfa880] mmco: unref short failure
[h264 @ 0x559bffbfa880] mmco: unref short failure
[h264 @ 0x562419bb7600] mmco: unref short failure
[h264 @ 0x562419bb7600] mmco: unref short failure
 54%|█████▍    | 1052/1945 [5:42:36<16:03:49, 64.76s/it][h264 @ 0x559bfc0b8e80] mmco: unref short failure
[h264 @ 0x559bfc0b8e80] mmco: unref short failure
 54%|█████▍    | 1053/1945 [5:42:42<11:39:24, 47.04s/it][h264 @ 0x56241c268000] mmco: unref short failure
[h264 @ 0x56241c268000] mmco: unref short failure
 54%|█████▍    | 1054/1945 [5:42:48<8:37:21, 34.84s/it] [h264 @ 0x559c03efd680] mmco: unref short failure
[h264 @ 0x559c03efd680] mmco: unref short failure
[h264 @ 0x559c04a08540] mmco: unref short failure
[h264 @ 0x559c04a08540] mmco: unref short failure
[h264 @ 0x559bed41bb80] mmco: unref short failure
[h264 @ 0x559bed41bb80] mmco: unref short failure
[h264 @ 0x562428b53c00] mmco: unref short failure
[h264 @ 0x562428b53c00] mmco: unref short failure
[h264 @ 0x55a032e4b0c0] mmco: unref short failure
 54%|█████▍    | 1055/1945 [5:42:54<6:30:03, 26.30s/it][h264 @ 0x56241f8eed00] mmco: unref short failure
[h264 @ 0x56241f8eed00] mmco: unref short failure
 54%|█████▍    | 1056/1945 [5:43:02<5:06:09, 20.66s/it] 54%|█████▍    | 1057/1945 [5:43:10<4:08:56, 16.82s/it][h264 @ 0x55a045a448c0] mmco: unref short failure
[h264 @ 0x55a045a448c0] mmco: unref short failure
[h264 @ 0x55a0419a81c0] mmco: unref short failure
[h264 @ 0x55a0419a81c0] mmco: unref short failure
[h264 @ 0x55a0419a81c0] mmco: unref short failure
 54%|█████▍    | 1058/1945 [5:43:17<3:28:08, 14.08s/it][h264 @ 0x559bee784680] mmco: unref short failure
 54%|█████▍    | 1059/1945 [5:43:25<2:58:30, 12.09s/it][h264 @ 0x559bed669200] mmco: unref short failure
 54%|█████▍    | 1060/1945 [5:43:33<2:39:47, 10.83s/it] 55%|█████▍    | 1061/1945 [5:43:39<2:20:52,  9.56s/it][h264 @ 0x556b441c4840] mmco: unref short failure
[h264 @ 0x556b2d848b80] mmco: unref short failure
[h264 @ 0x556b2d848b80] mmco: unref short failure
[h264 @ 0x556b2d848b80] mmco: unref short failure
[h264 @ 0x556b2d848b80] mmco: unref short failure
[h264 @ 0x562438838380] mmco: unref short failure
 55%|█████▍    | 1062/1945 [5:43:47<2:10:20,  8.86s/it][h264 @ 0x55a04b9e1240] mmco: unref short failure
[h264 @ 0x55a04b9e1240] mmco: unref short failure
 55%|█████▍    | 1063/1945 [5:43:55<2:09:20,  8.80s/it] 55%|█████▍    | 1064/1945 [5:44:04<2:08:36,  8.76s/it][h264 @ 0x556b350e6dc0] mmco: unref short failure
[h264 @ 0x556b350e6dc0] mmco: unref short failure
[h264 @ 0x559bf2ffc640] mmco: unref short failure
[h264 @ 0x559bf2ffc640] mmco: unref short failure
[h264 @ 0x559bf2ffc640] mmco: unref short failure
[h264 @ 0x559bf2ffc640] mmco: unref short failure
 55%|█████▍    | 1065/1945 [5:44:12<2:04:35,  8.49s/it] 55%|█████▍    | 1066/1945 [5:44:19<1:58:27,  8.09s/it][h264 @ 0x56242a820d40] mmco: unref short failure
[h264 @ 0x56242a820d40] mmco: unref short failure
[h264 @ 0x55a03622c500] mmco: unref short failure
 55%|█████▍    | 1067/1945 [5:44:27<1:57:31,  8.03s/it][h264 @ 0x55a039078600] mmco: unref short failure
[h264 @ 0x55a039078600] mmco: unref short failure
[h264 @ 0x55a039078600] mmco: unref short failure
[h264 @ 0x55a039078600] mmco: unref short failure
[h264 @ 0x559bf99c5300] mmco: unref short failure
[h264 @ 0x559bf99c5300] mmco: unref short failure
[h264 @ 0x559bf99c5300] mmco: unref short failure
[h264 @ 0x559bf99c5300] mmco: unref short failure
[h264 @ 0x556b37d71880] mmco: unref short failure
 55%|█████▍    | 1068/1945 [5:44:35<1:56:32,  7.97s/it][h264 @ 0x556b4f95d700] mmco: unref short failure
[h264 @ 0x556b4f95d700] mmco: unref short failure
[h264 @ 0x556b4f95d700] mmco: unref short failure
 55%|█████▍    | 1069/1945 [5:44:41<1:50:03,  7.54s/it][h264 @ 0x56242d02e640] mmco: unref short failure
[h264 @ 0x56242d02e640] mmco: unref short failure
 55%|█████▌    | 1070/1945 [5:44:48<1:48:10,  7.42s/it] 55%|█████▌    | 1071/1945 [5:44:59<2:02:10,  8.39s/it][h264 @ 0x559c071dc600] mmco: unref short failure
[h264 @ 0x559bed41c200] mmco: unref short failure
 55%|█████▌    | 1072/1945 [5:45:07<2:00:18,  8.27s/it][h264 @ 0x556b37c3ad80] mmco: unref short failure
[h264 @ 0x556b37c3ad80] mmco: unref short failure
 55%|█████▌    | 1073/1945 [5:45:23<2:34:25, 10.63s/it][h264 @ 0x559bf310e240] mmco: unref short failure
[h264 @ 0x556b34f53b40] mmco: unref short failure
[h264 @ 0x556b34f53b40] mmco: unref short failure
[h264 @ 0x556b34f53b40] mmco: unref short failure
[h264 @ 0x556b34f53b40] mmco: unref short failure
[h264 @ 0x56241a22fd40] mmco: unref short failure
[h264 @ 0x55a034fa1300] mmco: unref short failure
[h264 @ 0x562434819880] mmco: unref short failure
[h264 @ 0x562434819880] mmco: unref short failure
[h264 @ 0x56242f70a180] mmco: unref short failure
[h264 @ 0x55a033478600] mmco: unref short failure
[h264 @ 0x55a033478600] mmco: unref short failure
[h264 @ 0x559bfc91ec80] mmco: unref short failure
[h264 @ 0x559bfe0b9780] mmco: unref short failure
[h264 @ 0x559bfe0b9780] mmco: unref short failure
[h264 @ 0x55a0337212c0] mmco: unref short failure
[h264 @ 0x55a0337212c0] mmco: unref short failure
 55%|█████▌    | 1074/1945 [5:46:05<4:49:58, 19.98s/it][h264 @ 0x55a032fd23c0] mmco: unref short failure
[h264 @ 0x562427017dc0] mmco: unref short failure
[h264 @ 0x556b472628c0] mmco: unref short failure
[h264 @ 0x559bf7cc62c0] mmco: unref short failure
 55%|█████▌    | 1075/1945 [5:46:22<4:37:12, 19.12s/it][h264 @ 0x55a03bde8540] mmco: unref short failure
 55%|█████▌    | 1076/1945 [5:46:30<3:47:15, 15.69s/it][h264 @ 0x562424304640] mmco: unref short failure
[h264 @ 0x556b33621040] mmco: unref short failure
[h264 @ 0x556b323841c0] mmco: unref short failure
[h264 @ 0x559bffad11c0] mmco: unref short failure
[h264 @ 0x55a053e58700] mmco: unref short failure
 55%|█████▌    | 1077/1945 [5:46:48<3:56:27, 16.34s/it][h264 @ 0x556b3f5dd900] mmco: unref short failure
 55%|█████▌    | 1078/1945 [5:46:55<3:16:15, 13.58s/it][h264 @ 0x556b44c52080] mmco: unref short failure
 55%|█████▌    | 1079/1945 [5:47:07<3:12:04, 13.31s/it][h264 @ 0x559c06039140] mmco: unref short failure
[h264 @ 0x559c06039140] mmco: unref short failure
[h264 @ 0x562421540c00] mmco: unref short failure
[h264 @ 0x55a038aa6680] mmco: unref short failure
[h264 @ 0x55a038aa6680] mmco: unref short failure
 56%|█████▌    | 1080/1945 [5:47:15<2:49:18, 11.74s/it][h264 @ 0x556b4b031b40] mmco: unref short failure
[h264 @ 0x556b4b031b40] mmco: unref short failure
[h264 @ 0x556b2d252a80] mmco: unref short failure
[h264 @ 0x556b2d252a80] mmco: unref short failure
 56%|█████▌    | 1081/1945 [5:47:39<3:39:29, 15.24s/it][h264 @ 0x55a034d671c0] mmco: unref short failure
[h264 @ 0x559bf620bdc0] mmco: unref short failure
[h264 @ 0x559be98ab2c0] mmco: unref short failure
[h264 @ 0x56241f198a00] mmco: unref short failure
[h264 @ 0x56241f198a00] mmco: unref short failure
[h264 @ 0x559bed4d5bc0] mmco: unref short failure
 56%|█████▌    | 1082/1945 [5:48:11<4:52:21, 20.33s/it][h264 @ 0x556b47262ac0] mmco: unref short failure
[h264 @ 0x5624300a9100] mmco: unref short failure
[h264 @ 0x556b45138400] mmco: unref short failure
 56%|█████▌    | 1083/1945 [5:48:26<4:31:10, 18.87s/it] 56%|█████▌    | 1084/1945 [5:48:34<3:43:26, 15.57s/it][h264 @ 0x559bfc2ac000] mmco: unref short failure
[h264 @ 0x55a03d775300] mmco: unref short failure
[h264 @ 0x55a03d775300] mmco: unref short failure
[h264 @ 0x556b504213c0] mmco: unref short failure
[h264 @ 0x556b504213c0] mmco: unref short failure
[h264 @ 0x559bfdac5100] mmco: unref short failure
[h264 @ 0x559bfdac5100] mmco: unref short failure
[h264 @ 0x55a036157800] mmco: unref short failure
 56%|█████▌    | 1085/1945 [5:49:00<4:25:56, 18.55s/it][h264 @ 0x56241b1b5f40] mmco: unref short failure
[h264 @ 0x55a03822e3c0] mmco: unref short failure
[h264 @ 0x556b2e4fcc00] mmco: unref short failure
 56%|█████▌    | 1086/1945 [5:49:07<3:37:46, 15.21s/it][h264 @ 0x559bffbcd240] mmco: unref short failure
[h264 @ 0x55a050337040] mmco: unref short failure
[h264 @ 0x55a050337040] mmco: unref short failure
[h264 @ 0x5624398ddb80] mmco: unref short failure
 56%|█████▌    | 1087/1945 [5:49:15<3:04:11, 12.88s/it][h264 @ 0x556b334af900] mmco: unref short failure
[h264 @ 0x556b334af900] mmco: unref short failure
[h264 @ 0x559bfdce6a40] mmco: unref short failure
[h264 @ 0x559bfdce6a40] mmco: unref short failure
 56%|█████▌    | 1088/1945 [5:49:22<2:39:46, 11.19s/it][h264 @ 0x55a0365b1d80] mmco: unref short failure
[h264 @ 0x55a0365b1d80] mmco: unref short failure
 56%|█████▌    | 1089/1945 [5:49:43<3:22:11, 14.17s/it][h264 @ 0x55a034e07140] mmco: unref short failure
[h264 @ 0x55a034e07140] mmco: unref short failure
[h264 @ 0x56242f801640] mmco: unref short failure
[h264 @ 0x559c0791dac0] mmco: unref short failure
[h264 @ 0x556b34966f00] mmco: unref short failure
[h264 @ 0x556b34966f00] mmco: unref short failure
[h264 @ 0x55a03c071e00] mmco: unref short failure
 56%|█████▌    | 1090/1945 [5:50:08<4:07:05, 17.34s/it][h264 @ 0x559bfdad5f80] mmco: unref short failure
 56%|█████▌    | 1091/1945 [5:50:28<4:20:32, 18.30s/it][h264 @ 0x55a0364249c0] mmco: unref short failure
[h264 @ 0x55a0364249c0] mmco: unref short failure
 56%|█████▌    | 1092/1945 [5:50:36<3:36:22, 15.22s/it][h264 @ 0x559be9de1640] mmco: unref short failure
[h264 @ 0x559be9de1640] mmco: unref short failure
[h264 @ 0x55a05610b9c0] mmco: unref short failure
[h264 @ 0x55a05610b9c0] mmco: unref short failure
[h264 @ 0x559c0a32edc0] mmco: unref short failure
[h264 @ 0x5624300a2240] mmco: unref short failure
 56%|█████▌    | 1093/1945 [5:50:58<4:02:17, 17.06s/it][h264 @ 0x556b335ee000] mmco: unref short failure
[h264 @ 0x556b335ee000] mmco: unref short failure
[h264 @ 0x559c06038f40] mmco: unref short failure
[h264 @ 0x559c06038f40] mmco: unref short failure
[h264 @ 0x56241a1f1100] mmco: unref short failure
[h264 @ 0x56241a1f1100] mmco: unref short failure
[h264 @ 0x56241a1f1100] mmco: unref short failure
[h264 @ 0x56241a1f1100] mmco: unref short failure
 56%|█████▌    | 1094/1945 [5:51:05<3:19:41, 14.08s/it][h264 @ 0x562416d2e800] mmco: unref short failure
 56%|█████▋    | 1095/1945 [5:51:15<3:02:13, 12.86s/it] 56%|█████▋    | 1096/1945 [5:51:23<2:41:55, 11.44s/it][h264 @ 0x556b30684340] mmco: unref short failure
[h264 @ 0x55a0380ad8c0] mmco: unref short failure
[h264 @ 0x55a031cfb5c0] mmco: unref short failure
[h264 @ 0x55a031cfb5c0] mmco: unref short failure
[h264 @ 0x562427df1700] mmco: unref short failure
[h264 @ 0x556b36510d40] mmco: unref short failure
[h264 @ 0x556b36510d40] mmco: unref short failure
[h264 @ 0x556b36510d40] mmco: unref short failure
[h264 @ 0x556b36510d40] mmco: unref short failure
[h264 @ 0x559bea198900] mmco: unref short failure
 56%|█████▋    | 1097/1945 [5:51:54<4:02:58, 17.19s/it][h264 @ 0x556b4832afc0] mmco: unref short failure
[h264 @ 0x556b4832afc0] mmco: unref short failure
[h264 @ 0x556b3bc08600] mmco: unref short failure
[h264 @ 0x556b3bc08600] mmco: unref short failure
[h264 @ 0x55a043a76e40] mmco: unref short failure
[h264 @ 0x556b330c9500] mmco: unref short failure
[h264 @ 0x556b330c9500] mmco: unref short failure
[h264 @ 0x56241752e140] mmco: unref short failure
[h264 @ 0x56241752e140] mmco: unref short failure
[h264 @ 0x556b45e2aa40] mmco: unref short failure
 56%|█████▋    | 1098/1945 [5:52:23<4:54:53, 20.89s/it][h264 @ 0x556b2e22b500] mmco: unref short failure
 57%|█████▋    | 1099/1945 [5:52:32<4:02:16, 17.18s/it]09/09/2024 22:57:54 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 22:57:54 - INFO - __main__ -   start running ret%tv validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a036154440] mmco: unref short failure
[h264 @ 0x55a036154440] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x56241ebe2a80] Missing reference picture, default is 65562
[h264 @ 0x56243042cd40] mmco: unref short failure
[h264 @ 0x56243042cd40] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559c084c8040] mmco: unref short failure
[h264 @ 0x559c084c8040] mmco: unref short failure
[h264 @ 0x559c084c8040] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559bf47fbb80] mmco: unref short failure
[h264 @ 0x562435c1f8c0] mmco: unref short failure
[h264 @ 0x556b3d76b700] mmco: unref short failure
[h264 @ 0x556b34f68100] mmco: unref short failure
[h264 @ 0x556b34f68100] mmco: unref short failure
[h264 @ 0x562423bc8c40] mmco: unref short failure
[h264 @ 0x562423bc8c40] mmco: unref short failure
[h264 @ 0x556b34ac4280] mmco: unref short failure
[h264 @ 0x5624253214c0] mmco: unref short failure
[h264 @ 0x56242e55e700] mmco: unref short failure
[h264 @ 0x556b3ed8b440] mmco: unref short failure
[h264 @ 0x562418a31880] mmco: unref short failure
[h264 @ 0x562418a31880] mmco: unref short failure
[h264 @ 0x55a03e8bbb80] mmco: unref short failure
[h264 @ 0x55a03e8bbb80] mmco: unref short failure
[h264 @ 0x556b36510d40] mmco: unref short failure
[h264 @ 0x562417180bc0] mmco: unref short failure
[h264 @ 0x562417180bc0] mmco: unref short failure
[h264 @ 0x55a03a1f1e80] mmco: unref short failure
[h264 @ 0x562417ba0440] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:11,  1.68it/s][A
  1%|          | 2/221 [00:01<02:04,  1.76it/s][A
  1%|▏         | 3/221 [00:01<01:26,  2.52it/s][A
  2%|▏         | 4/221 [00:01<01:00,  3.57it/s][A
  2%|▏         | 5/221 [00:01<00:47,  4.56it/s][A
  3%|▎         | 6/221 [00:01<00:40,  5.37it/s][A
  3%|▎         | 7/221 [00:01<00:41,  5.10it/s][A
  4%|▎         | 8/221 [00:02<01:12,  2.94it/s][A
  4%|▍         | 9/221 [00:02<01:06,  3.19it/s][A
  5%|▍         | 10/221 [00:03<01:09,  3.05it/s][A
  5%|▍         | 11/221 [00:03<00:58,  3.61it/s][A
  5%|▌         | 12/221 [00:03<01:18,  2.65it/s][A
  6%|▌         | 13/221 [00:04<01:04,  3.25it/s][A
  6%|▋         | 14/221 [00:05<02:10,  1.59it/s][A
  7%|▋         | 15/221 [00:05<01:45,  1.95it/s][A
  7%|▋         | 16/221 [00:06<01:37,  2.10it/s][A
  8%|▊         | 17/221 [00:06<01:24,  2.41it/s][A
  8%|▊         | 18/221 [00:06<01:14,  2.73it/s][A
  9%|▊         | 19/221 [00:06<00:59,  3.40it/s][A
  9%|▉         | 20/221 [00:06<00:48,  4.12it/s][A
 10%|▉         | 21/221 [00:07<00:43,  4.62it/s][A
 10%|▉         | 22/221 [00:07<00:45,  4.36it/s][A
 10%|█         | 23/221 [00:07<00:41,  4.82it/s][A
 11%|█         | 24/221 [00:07<00:46,  4.20it/s][A
 11%|█▏        | 25/221 [00:07<00:45,  4.28it/s][A
 12%|█▏        | 26/221 [00:08<00:47,  4.07it/s][A
 12%|█▏        | 27/221 [00:08<00:41,  4.68it/s][A
 13%|█▎        | 28/221 [00:08<00:48,  3.96it/s][A
 13%|█▎        | 29/221 [00:08<00:41,  4.67it/s][A
 14%|█▎        | 30/221 [00:09<00:39,  4.89it/s][A
 14%|█▍        | 31/221 [00:09<00:38,  4.91it/s][A
 14%|█▍        | 32/221 [00:09<00:42,  4.45it/s][A
 15%|█▍        | 33/221 [00:10<01:04,  2.90it/s][A
 15%|█▌        | 34/221 [00:10<00:53,  3.48it/s][A
 16%|█▌        | 35/221 [00:10<00:45,  4.05it/s][A
 16%|█▋        | 36/221 [00:10<00:43,  4.22it/s][A
 17%|█▋        | 37/221 [00:11<00:59,  3.12it/s][A
 17%|█▋        | 38/221 [00:11<01:06,  2.74it/s][A
 18%|█▊        | 39/221 [00:11<00:53,  3.43it/s][A
 18%|█▊        | 40/221 [00:11<00:50,  3.58it/s][A
 19%|█▊        | 41/221 [00:12<00:40,  4.42it/s][A
 19%|█▉        | 42/221 [00:12<00:46,  3.82it/s][A
 19%|█▉        | 43/221 [00:12<00:38,  4.67it/s][A
 20%|█▉        | 44/221 [00:12<00:35,  5.03it/s][A
 20%|██        | 45/221 [00:13<01:27,  2.01it/s][A
 21%|██        | 46/221 [00:14<01:21,  2.14it/s][A[h264 @ 0x562416db6c80] mmco: unref short failure

 21%|██▏       | 47/221 [00:15<01:48,  1.60it/s][A
 22%|██▏       | 48/221 [00:15<01:21,  2.12it/s][A
 22%|██▏       | 49/221 [00:15<01:04,  2.67it/s][A
 23%|██▎       | 50/221 [00:15<00:50,  3.39it/s][A
 24%|██▎       | 52/221 [00:15<00:34,  4.85it/s][A
 24%|██▍       | 53/221 [00:16<00:33,  4.94it/s][A
 24%|██▍       | 54/221 [00:16<00:59,  2.79it/s][A
 25%|██▍       | 55/221 [00:17<01:04,  2.58it/s][A
 25%|██▌       | 56/221 [00:17<00:56,  2.93it/s][A
 26%|██▌       | 57/221 [00:17<00:48,  3.42it/s][A
 26%|██▌       | 58/221 [00:17<00:39,  4.18it/s][A
 27%|██▋       | 59/221 [00:17<00:34,  4.69it/s][A
 27%|██▋       | 60/221 [00:18<00:44,  3.62it/s][A
 28%|██▊       | 61/221 [00:18<00:42,  3.73it/s][A
 28%|██▊       | 62/221 [00:18<00:37,  4.22it/s][A
 29%|██▊       | 63/221 [00:18<00:32,  4.93it/s][A
 29%|██▉       | 64/221 [00:19<00:28,  5.54it/s][A[h264 @ 0x559bf2d4a500] mmco: unref short failure
[h264 @ 0x559bf2d4a500] mmco: unref short failure

 29%|██▉       | 65/221 [00:19<00:24,  6.24it/s][A[h264 @ 0x55a04d237640] mmco: unref short failure

 30%|██▉       | 66/221 [00:19<00:34,  4.50it/s][A[h264 @ 0x55a052fc5b40] mmco: unref short failure
[h264 @ 0x55a052fc5b40] mmco: unref short failure

 30%|███       | 67/221 [00:19<00:38,  3.99it/s][A
 31%|███       | 68/221 [00:20<00:34,  4.47it/s][A
 31%|███       | 69/221 [00:20<00:46,  3.28it/s][A
 32%|███▏      | 70/221 [00:20<00:38,  3.95it/s][A
 32%|███▏      | 71/221 [00:21<01:06,  2.25it/s][A
 33%|███▎      | 72/221 [00:21<01:05,  2.26it/s][A
 33%|███▎      | 73/221 [00:22<00:59,  2.50it/s][A[h264 @ 0x559be993bb00] mmco: unref short failure

 33%|███▎      | 74/221 [00:22<00:47,  3.07it/s][A
 34%|███▍      | 75/221 [00:22<00:47,  3.10it/s][A
 34%|███▍      | 76/221 [00:22<00:38,  3.74it/s][A
 35%|███▍      | 77/221 [00:23<00:32,  4.42it/s][A
 35%|███▌      | 78/221 [00:23<00:36,  3.93it/s][A
 36%|███▌      | 79/221 [00:23<00:51,  2.77it/s][A
 36%|███▌      | 80/221 [00:24<00:41,  3.42it/s][A
 37%|███▋      | 81/221 [00:24<00:36,  3.80it/s][A
 37%|███▋      | 82/221 [00:24<00:34,  4.06it/s][A
 38%|███▊      | 83/221 [00:24<00:33,  4.18it/s][A
 38%|███▊      | 84/221 [00:24<00:29,  4.67it/s][A
 38%|███▊      | 85/221 [00:24<00:25,  5.32it/s][A
 39%|███▉      | 86/221 [00:25<00:23,  5.75it/s][A
 39%|███▉      | 87/221 [00:25<00:39,  3.41it/s][A[h264 @ 0x556b32b90f80] mmco: unref short failure

 40%|███▉      | 88/221 [00:26<00:41,  3.21it/s][A
 40%|████      | 89/221 [00:27<01:44,  1.26it/s][A[h264 @ 0x559c0a3c8040] mmco: unref short failure

 41%|████      | 90/221 [00:28<01:29,  1.47it/s][A
 41%|████      | 91/221 [00:28<01:08,  1.90it/s][A
 42%|████▏     | 92/221 [00:28<00:56,  2.30it/s][A
 42%|████▏     | 93/221 [00:29<00:56,  2.28it/s][A
 43%|████▎     | 94/221 [00:29<00:48,  2.62it/s][A
 43%|████▎     | 95/221 [00:29<00:39,  3.22it/s][A
 43%|████▎     | 96/221 [00:29<00:34,  3.66it/s][A
 44%|████▍     | 98/221 [00:30<00:27,  4.52it/s][A
 45%|████▍     | 99/221 [00:30<00:25,  4.70it/s][A
 45%|████▌     | 100/221 [00:30<00:25,  4.66it/s][A
 46%|████▌     | 102/221 [00:30<00:25,  4.75it/s][A
 47%|████▋     | 103/221 [00:31<00:22,  5.17it/s][A
 47%|████▋     | 104/221 [00:31<00:20,  5.81it/s][A
 48%|████▊     | 105/221 [00:31<00:20,  5.56it/s][A[h264 @ 0x56242fe1f3c0] mmco: unref short failure

 48%|████▊     | 106/221 [00:32<00:41,  2.80it/s][A
 48%|████▊     | 107/221 [00:32<00:38,  2.95it/s][A
 49%|████▉     | 108/221 [00:32<00:38,  2.96it/s][A
 49%|████▉     | 109/221 [00:33<00:33,  3.32it/s][A
 50%|████▉     | 110/221 [00:33<00:30,  3.60it/s][A
 50%|█████     | 111/221 [00:33<00:33,  3.25it/s][A
 51%|█████     | 112/221 [00:33<00:30,  3.62it/s][A
 51%|█████     | 113/221 [00:34<00:34,  3.10it/s][A
 52%|█████▏    | 114/221 [00:34<00:31,  3.43it/s][A
 52%|█████▏    | 115/221 [00:34<00:29,  3.62it/s][A
 52%|█████▏    | 116/221 [00:38<02:20,  1.34s/it][A
 53%|█████▎    | 117/221 [00:38<01:46,  1.02s/it][A
 53%|█████▎    | 118/221 [00:39<01:25,  1.20it/s][A
 54%|█████▍    | 119/221 [00:39<01:07,  1.51it/s][A
 54%|█████▍    | 120/221 [00:39<00:57,  1.76it/s][A
 55%|█████▍    | 121/221 [00:40<00:45,  2.22it/s][A
 55%|█████▌    | 122/221 [00:40<00:37,  2.64it/s][A
 56%|█████▌    | 123/221 [00:40<00:30,  3.17it/s][A
 56%|█████▌    | 124/221 [00:40<00:27,  3.54it/s][A
 57%|█████▋    | 125/221 [00:40<00:26,  3.56it/s][A
 57%|█████▋    | 126/221 [00:41<00:28,  3.36it/s][A
 57%|█████▋    | 127/221 [00:41<00:31,  2.95it/s][A[h264 @ 0x559bf5dd3200] mmco: unref short failure
[h264 @ 0x559bf5dd3200] mmco: unref short failure

 58%|█████▊    | 128/221 [00:42<00:32,  2.87it/s][A
 58%|█████▊    | 129/221 [00:42<00:28,  3.25it/s][A
 59%|█████▉    | 130/221 [00:42<00:25,  3.51it/s][A
 59%|█████▉    | 131/221 [00:42<00:21,  4.21it/s][A
 60%|█████▉    | 132/221 [00:42<00:19,  4.55it/s][A
 60%|██████    | 133/221 [00:43<00:25,  3.46it/s][A
 61%|██████    | 134/221 [00:43<00:25,  3.38it/s][A
 61%|██████    | 135/221 [00:43<00:26,  3.22it/s][A
 62%|██████▏   | 136/221 [00:44<00:28,  2.96it/s][A
 62%|██████▏   | 137/221 [00:44<00:25,  3.30it/s][A[h264 @ 0x562419c22e40] mmco: unref short failure
[h264 @ 0x562419c22e40] mmco: unref short failure

 62%|██████▏   | 138/221 [00:44<00:28,  2.92it/s][A
 63%|██████▎   | 139/221 [00:45<00:27,  2.97it/s][A
 63%|██████▎   | 140/221 [00:45<00:28,  2.87it/s][A
 64%|██████▍   | 141/221 [00:45<00:27,  2.90it/s][A
 64%|██████▍   | 142/221 [00:46<00:29,  2.71it/s][A
 65%|██████▍   | 143/221 [00:46<00:28,  2.78it/s][A
 65%|██████▌   | 144/221 [00:46<00:22,  3.36it/s][A
 66%|██████▌   | 145/221 [00:47<00:18,  4.12it/s][A
 66%|██████▌   | 146/221 [00:47<00:15,  4.91it/s][A
 67%|██████▋   | 147/221 [00:47<00:12,  5.74it/s][A
 67%|██████▋   | 148/221 [00:47<00:14,  4.98it/s][A
 67%|██████▋   | 149/221 [00:47<00:14,  4.91it/s][A
 68%|██████▊   | 150/221 [00:47<00:12,  5.60it/s][A
 68%|██████▊   | 151/221 [00:48<00:27,  2.58it/s][A
 69%|██████▉   | 152/221 [00:48<00:23,  2.90it/s][A
 69%|██████▉   | 153/221 [00:49<00:23,  2.92it/s][A
 70%|██████▉   | 154/221 [00:49<00:25,  2.68it/s][A
 70%|███████   | 155/221 [00:49<00:21,  3.04it/s][A
 71%|███████   | 156/221 [00:50<00:18,  3.46it/s][A[h264 @ 0x562433d773c0] mmco: unref short failure

 71%|███████   | 157/221 [00:53<01:23,  1.31s/it][A
 71%|███████▏  | 158/221 [00:54<01:00,  1.04it/s][A
 72%|███████▏  | 159/221 [00:54<00:45,  1.37it/s][A
 72%|███████▏  | 160/221 [00:54<00:38,  1.60it/s][A
 73%|███████▎  | 162/221 [00:54<00:24,  2.46it/s][A
 74%|███████▍  | 163/221 [00:55<00:20,  2.81it/s][A
 74%|███████▍  | 164/221 [00:55<00:16,  3.36it/s][A
 75%|███████▍  | 165/221 [00:55<00:13,  4.03it/s][A
 75%|███████▌  | 166/221 [00:55<00:15,  3.62it/s][A
 76%|███████▌  | 167/221 [00:55<00:12,  4.27it/s][A
 76%|███████▌  | 168/221 [00:59<01:12,  1.36s/it][A
 76%|███████▋  | 169/221 [01:00<00:52,  1.02s/it][A
 77%|███████▋  | 170/221 [01:00<00:40,  1.26it/s][A
 77%|███████▋  | 171/221 [01:00<00:30,  1.66it/s][A[h264 @ 0x559bfb591500] mmco: unref short failure

 78%|███████▊  | 172/221 [01:00<00:23,  2.05it/s][A
 78%|███████▊  | 173/221 [01:00<00:17,  2.67it/s][A
 79%|███████▊  | 174/221 [01:00<00:13,  3.37it/s][A
 79%|███████▉  | 175/221 [01:01<00:13,  3.40it/s][A
 80%|███████▉  | 176/221 [01:01<00:12,  3.54it/s][A[h264 @ 0x559bf6802b00] mmco: unref short failure

 81%|████████  | 178/221 [01:01<00:10,  4.07it/s][A
 81%|████████  | 179/221 [01:02<00:14,  2.91it/s][A
 82%|████████▏ | 181/221 [01:02<00:10,  3.88it/s][A
 82%|████████▏ | 182/221 [01:02<00:09,  4.19it/s][A
 83%|████████▎ | 183/221 [01:03<00:08,  4.53it/s][A
 83%|████████▎ | 184/221 [01:03<00:08,  4.14it/s][A
 84%|████████▎ | 185/221 [01:03<00:07,  4.71it/s][A
 84%|████████▍ | 186/221 [01:03<00:09,  3.86it/s][A
 85%|████████▍ | 187/221 [01:04<00:07,  4.53it/s][A
 85%|████████▌ | 188/221 [01:04<00:09,  3.65it/s][A
 86%|████████▌ | 189/221 [01:04<00:08,  3.87it/s][A
 86%|████████▌ | 190/221 [01:04<00:07,  3.91it/s][A
 87%|████████▋ | 192/221 [01:05<00:06,  4.72it/s][A
 87%|████████▋ | 193/221 [01:05<00:05,  5.25it/s][A
 88%|████████▊ | 194/221 [01:05<00:07,  3.44it/s][A
 88%|████████▊ | 195/221 [01:06<00:06,  4.02it/s][A
 89%|████████▊ | 196/221 [01:06<00:05,  4.80it/s][A
 89%|████████▉ | 197/221 [01:06<00:04,  4.93it/s][A
 90%|████████▉ | 198/221 [01:06<00:05,  4.53it/s][A
 90%|█████████ | 199/221 [01:06<00:04,  5.34it/s][A
 90%|█████████ | 200/221 [01:07<00:04,  4.43it/s][A
 91%|█████████ | 201/221 [01:07<00:04,  4.47it/s][A
 91%|█████████▏| 202/221 [01:07<00:03,  4.77it/s][A
 92%|█████████▏| 203/221 [01:07<00:03,  5.59it/s][A
 92%|█████████▏| 204/221 [01:08<00:04,  3.72it/s][A
 93%|█████████▎| 205/221 [01:08<00:03,  4.49it/s][A
 93%|█████████▎| 206/221 [01:08<00:04,  3.02it/s][A
 94%|█████████▍| 208/221 [01:09<00:02,  4.39it/s][A
 95%|█████████▌| 210/221 [01:09<00:01,  6.26it/s][A
 95%|█████████▌| 211/221 [01:09<00:01,  5.02it/s][A
 96%|█████████▌| 212/221 [01:09<00:01,  5.67it/s][A
 96%|█████████▋| 213/221 [01:09<00:01,  6.22it/s][A
 97%|█████████▋| 214/221 [01:10<00:01,  3.87it/s][A
 97%|█████████▋| 215/221 [01:10<00:01,  4.27it/s][A
 98%|█████████▊| 216/221 [01:10<00:01,  4.29it/s][A[h264 @ 0x559c0957dac0] mmco: unref short failure
[h264 @ 0x559c0957dac0] mmco: unref short failure

 98%|█████████▊| 217/221 [01:11<00:01,  2.84it/s][A
 99%|█████████▊| 218/221 [01:11<00:00,  3.28it/s][A[h264 @ 0x559bf6802d00] mmco: unref short failure

 99%|█████████▉| 219/221 [01:11<00:00,  3.39it/s][A
100%|█████████▉| 220/221 [01:15<00:01,  1.44s/it][A
100%|██████████| 221/221 [01:16<00:00,  1.06s/it][A100%|██████████| 221/221 [01:16<00:00,  2.91it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.78it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.78it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.78it/s][A
  2%|▏         | 5/221 [00:01<00:57,  3.78it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.78it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.78it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.78it/s][A
  4%|▍         | 9/221 [00:02<00:56,  3.78it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.78it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.78it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:51,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:22<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:37<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.78it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.78it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.78it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.78it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.78it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.78it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.78it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.78it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.78it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.78it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:51<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.78it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.78it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:57<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:32,  6.74it/s][A
  1%|          | 2/221 [00:00<00:46,  4.68it/s][A
  1%|▏         | 3/221 [00:00<00:51,  4.27it/s][A
  2%|▏         | 4/221 [00:00<00:45,  4.77it/s][A
  2%|▏         | 5/221 [00:01<00:43,  4.95it/s][A
  3%|▎         | 7/221 [00:01<00:40,  5.29it/s][A
  4%|▎         | 8/221 [00:01<00:49,  4.32it/s][A
  4%|▍         | 9/221 [00:01<00:50,  4.16it/s][A
  5%|▍         | 10/221 [00:02<01:12,  2.92it/s][A
  5%|▍         | 11/221 [00:02<01:01,  3.41it/s][A
  5%|▌         | 12/221 [00:02<00:51,  4.05it/s][A
  6%|▌         | 13/221 [00:03<01:31,  2.27it/s][A
  6%|▋         | 14/221 [00:03<01:12,  2.86it/s][A
  7%|▋         | 15/221 [00:04<01:04,  3.18it/s][A
  7%|▋         | 16/221 [00:04<01:10,  2.91it/s][A
  8%|▊         | 17/221 [00:05<01:28,  2.30it/s][A
  8%|▊         | 18/221 [00:05<01:14,  2.72it/s][A
  9%|▊         | 19/221 [00:05<01:02,  3.21it/s][A
 10%|▉         | 21/221 [00:05<00:45,  4.41it/s][A
 10%|▉         | 22/221 [00:06<00:42,  4.67it/s][A
 11%|█         | 24/221 [00:06<00:35,  5.63it/s][A
 11%|█▏        | 25/221 [00:06<00:35,  5.55it/s][A
 12%|█▏        | 26/221 [00:06<00:37,  5.19it/s][A
 12%|█▏        | 27/221 [00:06<00:34,  5.63it/s][A
 13%|█▎        | 28/221 [00:07<00:43,  4.43it/s][A
 13%|█▎        | 29/221 [00:07<00:45,  4.25it/s][A
 14%|█▎        | 30/221 [00:07<00:47,  4.02it/s][A
 14%|█▍        | 31/221 [00:07<00:45,  4.18it/s][A
 15%|█▍        | 33/221 [00:08<00:36,  5.09it/s][A
 15%|█▌        | 34/221 [00:08<00:37,  5.01it/s][A
 16%|█▌        | 35/221 [00:08<00:43,  4.30it/s][A
 16%|█▋        | 36/221 [00:09<00:49,  3.76it/s][A
 17%|█▋        | 37/221 [00:09<00:42,  4.29it/s][A
 17%|█▋        | 38/221 [00:09<00:45,  4.04it/s][A
 18%|█▊        | 39/221 [00:09<00:40,  4.46it/s][A
 18%|█▊        | 40/221 [00:10<00:48,  3.71it/s][A
 19%|█▊        | 41/221 [00:10<00:43,  4.18it/s][A
 19%|█▉        | 42/221 [00:10<00:36,  4.86it/s][A
 19%|█▉        | 43/221 [00:10<00:43,  4.13it/s][A
 20%|█▉        | 44/221 [00:11<00:43,  4.03it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.78it/s][A
 21%|██        | 46/221 [00:11<00:40,  4.31it/s][A
 21%|██▏       | 47/221 [00:11<00:40,  4.34it/s][A
 22%|██▏       | 48/221 [00:11<00:34,  4.96it/s][A
 22%|██▏       | 49/221 [00:12<00:35,  4.78it/s][A
 23%|██▎       | 50/221 [00:12<00:52,  3.26it/s][A
 23%|██▎       | 51/221 [00:12<00:44,  3.80it/s][A
 24%|██▎       | 52/221 [00:13<00:45,  3.70it/s][A
 24%|██▍       | 53/221 [00:13<00:39,  4.20it/s][A
 24%|██▍       | 54/221 [00:13<00:50,  3.30it/s][A
 25%|██▍       | 55/221 [00:13<00:45,  3.64it/s][A
 25%|██▌       | 56/221 [00:14<00:39,  4.19it/s][A
 26%|██▌       | 57/221 [00:14<00:39,  4.15it/s][A
 26%|██▌       | 58/221 [00:14<00:50,  3.24it/s][A
 27%|██▋       | 59/221 [00:14<00:45,  3.59it/s][A
 27%|██▋       | 60/221 [00:15<00:37,  4.24it/s][A
 28%|██▊       | 61/221 [00:15<00:34,  4.65it/s][A
 28%|██▊       | 62/221 [00:15<00:35,  4.50it/s][A
 29%|██▊       | 63/221 [00:15<00:33,  4.65it/s][A
 29%|██▉       | 64/221 [00:16<00:44,  3.52it/s][A
 29%|██▉       | 65/221 [00:16<00:39,  3.95it/s][A
 30%|██▉       | 66/221 [00:16<00:48,  3.22it/s][A
 30%|███       | 67/221 [00:17<00:52,  2.93it/s][A
 31%|███       | 68/221 [00:17<00:43,  3.48it/s][A
 31%|███       | 69/221 [00:18<01:05,  2.32it/s][A
 32%|███▏      | 70/221 [00:18<00:50,  2.99it/s][A
 32%|███▏      | 71/221 [00:18<00:43,  3.45it/s][A
 33%|███▎      | 72/221 [00:18<00:49,  3.04it/s][A
 33%|███▎      | 73/221 [00:19<00:47,  3.10it/s][A
 33%|███▎      | 74/221 [00:19<00:42,  3.47it/s][A
 34%|███▍      | 75/221 [00:19<00:40,  3.60it/s][A
 34%|███▍      | 76/221 [00:19<00:38,  3.81it/s][A
 35%|███▍      | 77/221 [00:20<00:39,  3.64it/s][A
 35%|███▌      | 78/221 [00:20<00:36,  3.97it/s][A
 36%|███▌      | 79/221 [00:20<00:43,  3.28it/s][A
 36%|███▌      | 80/221 [00:20<00:39,  3.55it/s][A
 37%|███▋      | 81/221 [00:21<00:37,  3.74it/s][A
 37%|███▋      | 82/221 [00:21<00:42,  3.31it/s][A
 38%|███▊      | 83/221 [00:21<00:44,  3.07it/s][A
 38%|███▊      | 84/221 [00:22<00:41,  3.30it/s][A
 38%|███▊      | 85/221 [00:22<00:33,  4.01it/s][A
 39%|███▉      | 86/221 [00:22<00:37,  3.62it/s][A
 39%|███▉      | 87/221 [00:23<00:47,  2.81it/s][A
 40%|███▉      | 88/221 [00:23<00:51,  2.57it/s][A
 40%|████      | 89/221 [00:23<00:45,  2.91it/s][A
 41%|████      | 90/221 [00:24<00:48,  2.71it/s][A
 41%|████      | 91/221 [00:24<00:39,  3.27it/s][A
 42%|████▏     | 92/221 [00:24<00:43,  2.95it/s][A
 42%|████▏     | 93/221 [00:25<00:56,  2.26it/s][A
 43%|████▎     | 94/221 [00:25<00:50,  2.52it/s][A
 43%|████▎     | 95/221 [00:26<00:45,  2.77it/s][A
 43%|████▎     | 96/221 [00:26<00:39,  3.16it/s][A
 44%|████▍     | 97/221 [00:26<00:34,  3.63it/s][A
 44%|████▍     | 98/221 [00:26<00:34,  3.55it/s][A
 45%|████▍     | 99/221 [00:27<00:30,  3.95it/s][A
 45%|████▌     | 100/221 [00:27<00:30,  3.92it/s][A
 46%|████▌     | 101/221 [00:27<00:29,  4.09it/s][A
 46%|████▌     | 102/221 [00:28<00:45,  2.62it/s][A
 47%|████▋     | 103/221 [00:28<00:35,  3.33it/s][A
 47%|████▋     | 104/221 [00:28<00:31,  3.76it/s][A
 48%|████▊     | 105/221 [00:28<00:29,  3.91it/s][A
 48%|████▊     | 106/221 [00:29<00:35,  3.28it/s][A
 48%|████▊     | 107/221 [00:29<00:31,  3.66it/s][A
 49%|████▉     | 108/221 [00:29<00:31,  3.59it/s][A
 50%|████▉     | 110/221 [00:30<00:25,  4.34it/s][A
 50%|█████     | 111/221 [00:30<00:26,  4.10it/s][A
 51%|█████     | 112/221 [00:30<00:26,  4.13it/s][A
 51%|█████     | 113/221 [00:30<00:23,  4.61it/s][A
 52%|█████▏    | 115/221 [00:30<00:19,  5.32it/s][A
 52%|█████▏    | 116/221 [00:31<00:21,  4.93it/s][A
 53%|█████▎    | 117/221 [00:31<00:22,  4.63it/s][A
 53%|█████▎    | 118/221 [00:31<00:22,  4.66it/s][A
 54%|█████▍    | 119/221 [00:32<00:27,  3.64it/s][A
 54%|█████▍    | 120/221 [00:32<00:24,  4.12it/s][A
 55%|█████▍    | 121/221 [00:32<00:20,  4.83it/s][A
 55%|█████▌    | 122/221 [00:32<00:22,  4.36it/s][A
 56%|█████▌    | 123/221 [00:32<00:24,  4.04it/s][A
 56%|█████▌    | 124/221 [00:33<00:23,  4.11it/s][A
 57%|█████▋    | 125/221 [00:33<00:26,  3.66it/s][A
 57%|█████▋    | 126/221 [00:33<00:23,  3.96it/s][A
 57%|█████▋    | 127/221 [00:34<00:29,  3.18it/s][A
 58%|█████▊    | 128/221 [00:34<00:27,  3.37it/s][A
 58%|█████▊    | 129/221 [00:34<00:22,  4.11it/s][A
 59%|█████▉    | 130/221 [00:34<00:23,  3.87it/s][A
 59%|█████▉    | 131/221 [00:35<00:19,  4.70it/s][A
 60%|█████▉    | 132/221 [00:35<00:22,  3.95it/s][A
 60%|██████    | 133/221 [00:35<00:24,  3.59it/s][A
 61%|██████    | 134/221 [00:36<00:31,  2.73it/s][A
 61%|██████    | 135/221 [00:36<00:31,  2.71it/s][A
 62%|██████▏   | 136/221 [00:36<00:27,  3.06it/s][A
 62%|██████▏   | 137/221 [00:37<00:22,  3.72it/s][A
 62%|██████▏   | 138/221 [00:37<00:23,  3.56it/s][A
 63%|██████▎   | 139/221 [00:37<00:27,  3.03it/s][A
 63%|██████▎   | 140/221 [00:38<00:26,  3.11it/s][A
 64%|██████▍   | 141/221 [00:38<00:22,  3.55it/s][A
 64%|██████▍   | 142/221 [00:38<00:20,  3.84it/s][A
 65%|██████▍   | 143/221 [00:39<00:27,  2.88it/s][A
 65%|██████▌   | 144/221 [00:39<00:28,  2.69it/s][A
 66%|██████▌   | 146/221 [00:39<00:18,  4.15it/s][A
 67%|██████▋   | 147/221 [00:39<00:18,  3.98it/s][A
 67%|██████▋   | 148/221 [00:40<00:22,  3.27it/s][A
 67%|██████▋   | 149/221 [00:40<00:21,  3.33it/s][A
 68%|██████▊   | 150/221 [00:40<00:20,  3.54it/s][A
 68%|██████▊   | 151/221 [00:41<00:23,  2.94it/s][A
 69%|██████▉   | 152/221 [00:42<00:33,  2.03it/s][A
 69%|██████▉   | 153/221 [00:42<00:26,  2.60it/s][A
 70%|██████▉   | 154/221 [00:42<00:21,  3.06it/s][A
 70%|███████   | 155/221 [00:42<00:18,  3.51it/s][A
 71%|███████   | 156/221 [00:43<00:21,  3.06it/s][A
 71%|███████   | 157/221 [00:43<00:20,  3.06it/s][A
 71%|███████▏  | 158/221 [00:43<00:19,  3.25it/s][A
 72%|███████▏  | 159/221 [00:43<00:15,  3.92it/s][A
 72%|███████▏  | 160/221 [00:44<00:15,  4.06it/s][A
 73%|███████▎  | 161/221 [00:44<00:18,  3.27it/s][A
 73%|███████▎  | 162/221 [00:44<00:15,  3.80it/s][A
 74%|███████▍  | 163/221 [00:44<00:15,  3.85it/s][A
 74%|███████▍  | 164/221 [00:45<00:12,  4.50it/s][A
 75%|███████▍  | 165/221 [00:45<00:12,  4.59it/s][A
 75%|███████▌  | 166/221 [00:45<00:12,  4.51it/s][A
 76%|███████▌  | 167/221 [00:45<00:10,  5.32it/s][A
 76%|███████▌  | 168/221 [00:45<00:11,  4.75it/s][A
 76%|███████▋  | 169/221 [00:46<00:09,  5.47it/s][A
 77%|███████▋  | 170/221 [00:46<00:14,  3.61it/s][A
 77%|███████▋  | 171/221 [00:46<00:12,  3.93it/s][A
 78%|███████▊  | 172/221 [00:46<00:12,  4.04it/s][A
 78%|███████▊  | 173/221 [00:47<00:13,  3.62it/s][A
 79%|███████▊  | 174/221 [00:47<00:15,  3.00it/s][A
 79%|███████▉  | 175/221 [00:48<00:15,  3.01it/s][A
 80%|███████▉  | 176/221 [00:48<00:13,  3.25it/s][A
 80%|████████  | 177/221 [00:48<00:12,  3.51it/s][A
 81%|████████  | 178/221 [00:48<00:13,  3.23it/s][A
 81%|████████  | 179/221 [00:49<00:12,  3.47it/s][A
 81%|████████▏ | 180/221 [00:49<00:10,  4.06it/s][A
 82%|████████▏ | 181/221 [00:49<00:10,  3.87it/s][A
 82%|████████▏ | 182/221 [00:50<00:11,  3.35it/s][A
 83%|████████▎ | 183/221 [00:50<00:12,  3.15it/s][A
 83%|████████▎ | 184/221 [00:50<00:11,  3.35it/s][A
 84%|████████▎ | 185/221 [00:50<00:09,  3.88it/s][A
 84%|████████▍ | 186/221 [00:51<00:11,  3.01it/s][A
 85%|████████▍ | 187/221 [00:51<00:10,  3.40it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.38it/s][A
 86%|████████▌ | 189/221 [00:52<00:08,  3.59it/s][A
 86%|████████▌ | 190/221 [00:52<00:09,  3.29it/s][A
 86%|████████▋ | 191/221 [00:52<00:07,  3.81it/s][A
 87%|████████▋ | 192/221 [00:52<00:07,  3.88it/s][A
 87%|████████▋ | 193/221 [00:52<00:06,  4.55it/s][A
 88%|████████▊ | 194/221 [00:53<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:53<00:06,  4.07it/s][A
 89%|████████▊ | 196/221 [00:53<00:07,  3.54it/s][A
 89%|████████▉ | 197/221 [00:54<00:06,  3.75it/s][A
 90%|████████▉ | 198/221 [00:54<00:07,  3.01it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.43it/s][A
 90%|█████████ | 200/221 [00:55<00:07,  2.99it/s][A
 91%|█████████ | 201/221 [00:55<00:05,  3.45it/s][A
 91%|█████████▏| 202/221 [00:55<00:05,  3.20it/s][A
 92%|█████████▏| 203/221 [00:55<00:04,  3.64it/s][A
 92%|█████████▏| 204/221 [00:56<00:05,  3.38it/s][A
 93%|█████████▎| 205/221 [00:56<00:03,  4.20it/s][A
 93%|█████████▎| 206/221 [00:56<00:04,  3.51it/s][A
 94%|█████████▎| 207/221 [00:57<00:03,  3.73it/s][A
 94%|█████████▍| 208/221 [00:57<00:03,  3.86it/s][A
 95%|█████████▍| 209/221 [00:57<00:02,  4.12it/s][A
 95%|█████████▌| 210/221 [00:57<00:02,  4.67it/s][A
 95%|█████████▌| 211/221 [00:57<00:02,  4.03it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  3.63it/s][A
 96%|█████████▋| 213/221 [00:58<00:02,  3.82it/s][A
 97%|█████████▋| 214/221 [00:59<00:02,  2.53it/s][A
 97%|█████████▋| 215/221 [00:59<00:01,  3.00it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.16it/s][A
 98%|█████████▊| 217/221 [01:00<00:01,  3.19it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.27it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.17it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.69it/s][A
100%|██████████| 221/221 [01:01<00:00,  3.97it/s][A100%|██████████| 221/221 [01:01<00:00,  3.62it/s]
09/09/2024 23:03:39 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 1099--===========

09/09/2024 23:03:39 - INFO - __main__ -   {'area_r1': 38.5, 'area_recall': '38.5/63.5/73.5', 'area_ravg': 58.5}
09/09/2024 23:03:39 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 1099--===========

09/09/2024 23:03:39 - INFO - __main__ -   {'forward_r1': 37.8, 'forward_recall': '37.8/66.0/76.7', 'forward_ravg': 60.1}
09/09/2024 23:03:39 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 1099--===========

09/09/2024 23:03:39 - INFO - __main__ -   {'area_video_r1': 38.6, 'area_video_recall': '38.6/66.9/77.5', 'area_video_ravg': 61.0}
09/09/2024 23:03:39 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/09/2024 23:03:39 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 23:03:39 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 1099--===========

09/09/2024 23:03:39 - INFO - __main__ -   {'area_video_r1': 52.9, 'area_video_recall': '52.9/75.1/82.2', 'area_video_ravg': 70.1, 'area_video_back_r1': 47.7, 'area_video_back_recall': '47.7/74.7/82.0', 'area_video_back_ravg': 68.1}
09/09/2024 23:03:39 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/09/2024 23:03:39 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/09/2024 23:03:39 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 1099--===========

09/09/2024 23:03:39 - INFO - __main__ -   {'video_r1': 43.7, 'video_recall': '43.7/71.7/82.4', 'video_ravg': 65.9}
09/09/2024 23:03:39 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 23:03:39 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 23:03:39 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 1099--===========

09/09/2024 23:03:39 - INFO - __main__ -   {'video_r1': 52.7, 'video_recall': '52.7/75.6/83.3', 'video_ravg': 70.5}
09/09/2024 23:03:39 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/09/2024 23:03:39 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/09/2024 23:04:01 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.006174460984766483, 'loss_ret%tv%ta--finetune_area/loss_area': 1.011704921722412, 'loss_ret%tv%ta--finetune_area/total_loss': 1.0178793668746948}
 57%|█████▋    | 1100/1945 [5:58:41<28:50:49, 122.90s/it][h264 @ 0x559bfb3f47c0] mmco: unref short failure
[h264 @ 0x559bfb3f47c0] mmco: unref short failure
[h264 @ 0x559bfb3f47c0] mmco: unref short failure
[h264 @ 0x559bfb3f47c0] mmco: unref short failure
[h264 @ 0x556b3ba9ff40] mmco: unref short failure
[h264 @ 0x556b36794f00] mmco: unref short failure
[h264 @ 0x556b36794f00] mmco: unref short failure
 57%|█████▋    | 1101/1945 [5:58:45<20:27:30, 87.26s/it] [h264 @ 0x56241747f3c0] mmco: unref short failure
[h264 @ 0x56241747f3c0] mmco: unref short failure
 57%|█████▋    | 1102/1945 [5:58:50<14:38:08, 62.50s/it][h264 @ 0x55a03c122f40] mmco: unref short failure
 57%|█████▋    | 1103/1945 [5:58:56<10:40:05, 45.61s/it][h264 @ 0x562416925340] mmco: unref short failure
[h264 @ 0x562416925340] mmco: unref short failure
[h264 @ 0x56243668dfc0] mmco: unref short failure
 57%|█████▋    | 1104/1945 [5:59:03<7:54:34, 33.86s/it]  57%|█████▋    | 1105/1945 [5:59:09<5:57:04, 25.51s/it] 57%|█████▋    | 1106/1945 [5:59:16<4:39:23, 19.98s/it][h264 @ 0x56241a28e400] mmco: unref short failure
[h264 @ 0x56241a28e400] mmco: unref short failure
[h264 @ 0x55a04041b5c0] mmco: unref short failure
[h264 @ 0x55a04041b5c0] mmco: unref short failure
[h264 @ 0x55a047e66d00] mmco: unref short failure
[h264 @ 0x55a047e66d00] mmco: unref short failure
[h264 @ 0x55a047e66d00] mmco: unref short failure
[h264 @ 0x55a047e66d00] mmco: unref short failure
 57%|█████▋    | 1107/1945 [5:59:23<3:46:08, 16.19s/it] 57%|█████▋    | 1108/1945 [5:59:30<3:07:40, 13.45s/it][h264 @ 0x55a033f22c00] mmco: unref short failure
 57%|█████▋    | 1109/1945 [5:59:38<2:42:16, 11.65s/it][h264 @ 0x559c0bb5b600] mmco: unref short failure
[h264 @ 0x559c0bb5b600] mmco: unref short failure
[h264 @ 0x55a03e66a840] mmco: unref short failure
[h264 @ 0x55a03e66a840] mmco: unref short failure
[h264 @ 0x55a03e66a840] mmco: unref short failure
[h264 @ 0x55a03e66a840] mmco: unref short failure
[h264 @ 0x55a03e66a840] mmco: unref short failure
[h264 @ 0x55a03e66a840] mmco: unref short failure
 57%|█████▋    | 1110/1945 [5:59:45<2:24:32, 10.39s/it][h264 @ 0x562416db6c80] mmco: unref short failure
[h264 @ 0x562416db6c80] mmco: unref short failure
[h264 @ 0x562421e8e480] mmco: unref short failure
 57%|█████▋    | 1111/1945 [5:59:53<2:13:12,  9.58s/it][h264 @ 0x556b4d2eb3c0] mmco: unref short failure
[h264 @ 0x556b4d2eb3c0] mmco: unref short failure
 57%|█████▋    | 1112/1945 [6:00:00<2:04:53,  9.00s/it][h264 @ 0x56241deaac80] mmco: unref short failure
[h264 @ 0x559c074c0ac0] mmco: unref short failure
[h264 @ 0x559c074c0ac0] mmco: unref short failure
 57%|█████▋    | 1113/1945 [6:00:09<2:01:02,  8.73s/it][h264 @ 0x56241b5a6a80] mmco: unref short failure
[h264 @ 0x556b2d161d40] mmco: unref short failure
[h264 @ 0x556b2d161d40] mmco: unref short failure
[h264 @ 0x556b2d161d40] mmco: unref short failure
[h264 @ 0x55a05165ea40] mmco: unref short failure
 57%|█████▋    | 1114/1945 [6:00:16<1:54:04,  8.24s/it][h264 @ 0x556b484f9680] mmco: unref short failure
[h264 @ 0x5624253214c0] mmco: unref short failure
 57%|█████▋    | 1115/1945 [6:00:23<1:52:08,  8.11s/it][h264 @ 0x55a03d87b740] mmco: unref short failure
[h264 @ 0x55a03d87b740] mmco: unref short failure
[h264 @ 0x556b3139b300] mmco: unref short failure
[h264 @ 0x55a0400e4900] mmco: unref short failure
 57%|█████▋    | 1116/1945 [6:00:31<1:49:30,  7.93s/it] 57%|█████▋    | 1117/1945 [6:00:39<1:49:08,  7.91s/it][h264 @ 0x55a0333b77c0] mmco: unref short failure
[h264 @ 0x55a0333b77c0] mmco: unref short failure
[h264 @ 0x55a0333b77c0] mmco: unref short failure
[h264 @ 0x55a0333b77c0] mmco: unref short failure
[h264 @ 0x556b4eb37dc0] mmco: unref short failure
 57%|█████▋    | 1118/1945 [6:00:48<1:53:25,  8.23s/it][h264 @ 0x556b4b885a40] mmco: unref short failure
[h264 @ 0x556b4b885a40] mmco: unref short failure
 58%|█████▊    | 1119/1945 [6:01:00<2:08:29,  9.33s/it][h264 @ 0x559c06fd5b80] mmco: unref short failure
[h264 @ 0x559c06fd5b80] mmco: unref short failure
[h264 @ 0x5624253214c0] mmco: unref short failure
[h264 @ 0x559bef34bf80] mmco: unref short failure
 58%|█████▊    | 1120/1945 [6:01:07<1:58:26,  8.61s/it][h264 @ 0x556b2dc608c0] mmco: unref short failure
[h264 @ 0x556b2dc608c0] mmco: unref short failure
[h264 @ 0x559bf70d8280] mmco: unref short failure
[h264 @ 0x559bf70d8280] mmco: unref short failure
[h264 @ 0x55a0566b2b40] mmco: unref short failure
[h264 @ 0x55a036486900] mmco: unref short failure
[h264 @ 0x55a036486900] mmco: unref short failure
[h264 @ 0x55a036486900] mmco: unref short failure
[h264 @ 0x55a036486900] mmco: unref short failure
[h264 @ 0x556b4f9ee240] mmco: unref short failure
[h264 @ 0x556b4f9ee240] mmco: unref short failure
[h264 @ 0x556b4f9ee240] mmco: unref short failure
[h264 @ 0x556b4f9ee240] mmco: unref short failure
 58%|█████▊    | 1121/1945 [6:01:19<2:12:04,  9.62s/it][h264 @ 0x556b3a935640] mmco: unref short failure
[h264 @ 0x556b3a935640] mmco: unref short failure
[h264 @ 0x559bf2d5a300] mmco: unref short failure
[h264 @ 0x559bf2d5a300] mmco: unref short failure
 58%|█████▊    | 1122/1945 [6:01:26<2:02:08,  8.90s/it][h264 @ 0x559bea445500] mmco: unref short failure
[h264 @ 0x559bea445500] mmco: unref short failure
 58%|█████▊    | 1123/1945 [6:01:34<1:57:24,  8.57s/it][h264 @ 0x556b345071c0] mmco: unref short failure
[h264 @ 0x55a03995d640] mmco: unref short failure
[h264 @ 0x55a03995d640] mmco: unref short failure
[h264 @ 0x559c041e8440] mmco: unref short failure
[h264 @ 0x56242c36adc0] mmco: unref short failure
[h264 @ 0x55a037d1f1c0] mmco: unref short failure
[h264 @ 0x55a037d1f1c0] mmco: unref short failure
[h264 @ 0x55a040795880] mmco: unref short failure
[h264 @ 0x556b2dce2900] mmco: unref short failure
[h264 @ 0x556b2dce2900] mmco: unref short failure
[h264 @ 0x55a054c94940] mmco: unref short failure
[h264 @ 0x55a0463bb4c0] mmco: unref short failure
[h264 @ 0x55a0463bb4c0] mmco: unref short failure
[h264 @ 0x556b2dce6ac0] mmco: unref short failure
[h264 @ 0x556b2dce6ac0] mmco: unref short failure
[h264 @ 0x55a03825d800] mmco: unref short failure
[h264 @ 0x55a03825d800] mmco: unref short failure
[h264 @ 0x562426af4500] mmco: unref short failure
 58%|█████▊    | 1124/1945 [6:02:27<4:59:36, 21.90s/it] 58%|█████▊    | 1125/1945 [6:02:39<4:20:26, 19.06s/it] 58%|█████▊    | 1126/1945 [6:02:49<3:42:14, 16.28s/it][h264 @ 0x55a04a0ac300] mmco: unref short failure
[h264 @ 0x559c09c88180] mmco: unref short failure
[h264 @ 0x559c09c88180] mmco: unref short failure
[h264 @ 0x559c09c88180] mmco: unref short failure
[h264 @ 0x559c09c88180] mmco: unref short failure
[h264 @ 0x559c09fa7300] mmco: unref short failure
[h264 @ 0x559c09fa7300] mmco: unref short failure
[h264 @ 0x559bfdfa4b80] mmco: unref short failure
[h264 @ 0x559bfdfa4b80] mmco: unref short failure
[h264 @ 0x559bfdfa4b80] mmco: unref short failure
[h264 @ 0x559bfdfa4b80] mmco: unref short failure
[h264 @ 0x559bfdfa4b80] mmco: unref short failure
[h264 @ 0x559bfdfa4b80] mmco: unref short failure
[h264 @ 0x56242fe1f3c0] mmco: unref short failure
[h264 @ 0x56242fe1f3c0] mmco: unref short failure
[h264 @ 0x56241d3730c0] mmco: unref short failure
[h264 @ 0x562419d61a80] mmco: unref short failure
[h264 @ 0x562419d61a80] mmco: unref short failure
[h264 @ 0x562419d61a80] mmco: unref short failure
[h264 @ 0x562419d61a80] mmco: unref short failure
[h264 @ 0x562419d61a80] mmco: unref short failure
 58%|█████▊    | 1127/1945 [6:03:08<3:51:58, 17.02s/it] 58%|█████▊    | 1128/1945 [6:03:15<3:11:52, 14.09s/it][h264 @ 0x559beabb5180] mmco: unref short failure
[h264 @ 0x559beabb5180] mmco: unref short failure
[h264 @ 0x556b45deb7c0] mmco: unref short failure
[h264 @ 0x556b45deb7c0] mmco: unref short failure
 58%|█████▊    | 1129/1945 [6:03:23<2:46:24, 12.24s/it][h264 @ 0x556b4b9f4340] mmco: unref short failure
[h264 @ 0x556b4b9f4340] mmco: unref short failure
[h264 @ 0x556b4b9f4340] mmco: unref short failure
[h264 @ 0x556b4b9f4340] mmco: unref short failure
[h264 @ 0x559bebbeb400] mmco: unref short failure
[h264 @ 0x559bebbeb400] mmco: unref short failure
[h264 @ 0x56241e357800] mmco: unref short failure
[h264 @ 0x56241e357800] mmco: unref short failure
 58%|█████▊    | 1130/1945 [6:03:31<2:31:14, 11.13s/it][h264 @ 0x55a04e58f600] mmco: unref short failure
[h264 @ 0x55a04e58f600] mmco: unref short failure
[h264 @ 0x562424428b80] mmco: unref short failure
 58%|█████▊    | 1131/1945 [6:03:43<2:33:58, 11.35s/it][h264 @ 0x56241c043680] mmco: unref short failure
[h264 @ 0x55a032992000] mmco: unref short failure
[h264 @ 0x55a032992000] mmco: unref short failure
[h264 @ 0x556b41f72d80] mmco: unref short failure
[h264 @ 0x56242e1ff980] mmco: unref short failure
[h264 @ 0x556b388accc0] mmco: unref short failure
[h264 @ 0x556b388accc0] mmco: unref short failure
[h264 @ 0x55a0348a30c0] mmco: unref short failure
[h264 @ 0x55a03e0e2040] mmco: unref short failure
[h264 @ 0x55a03e0e2040] mmco: unref short failure
[h264 @ 0x559bead1c780] mmco: unref short failure
[h264 @ 0x559bead1c780] mmco: unref short failure
[h264 @ 0x56242d5c8980] mmco: unref short failure
[h264 @ 0x56242d5c8980] mmco: unref short failure
[h264 @ 0x559bfd4b4300] mmco: unref short failure
[h264 @ 0x56241960bc80] mmco: unref short failure
[h264 @ 0x559bf8e70bc0] mmco: unref short failure
[h264 @ 0x559bf8e70bc0] mmco: unref short failure
[h264 @ 0x562431624680] mmco: unref short failure
[h264 @ 0x562431624680] mmco: unref short failure
[h264 @ 0x556b3bd63f00] mmco: unref short failure
[h264 @ 0x556b3bd63f00] mmco: unref short failure
[h264 @ 0x55a03f77c280] mmco: unref short failure
 58%|█████▊    | 1132/1945 [6:04:28<4:51:39, 21.52s/it][h264 @ 0x562429117180] mmco: unref short failure
[h264 @ 0x562429117180] mmco: unref short failure
 58%|█████▊    | 1133/1945 [6:04:40<4:09:43, 18.45s/it][h264 @ 0x5624315a1ec0] mmco: unref short failure
[h264 @ 0x556b4e941080] mmco: unref short failure
[h264 @ 0x556b3453c500] mmco: unref short failure
[h264 @ 0x556b3453c500] mmco: unref short failure
 58%|█████▊    | 1134/1945 [6:04:59<4:12:00, 18.64s/it][h264 @ 0x56242a9adb40] mmco: unref short failure
[h264 @ 0x56242a9adb40] mmco: unref short failure
[h264 @ 0x56242a9adb40] mmco: unref short failure
[h264 @ 0x56242a9adb40] mmco: unref short failure
[h264 @ 0x559bf6f1df40] mmco: unref short failure
[h264 @ 0x559bf6f1df40] mmco: unref short failure
[h264 @ 0x55a04198cfc0] mmco: unref short failure
[h264 @ 0x55a04198cfc0] mmco: unref short failure
[h264 @ 0x55a04ff00080] mmco: unref short failure
[h264 @ 0x559bf192bec0] mmco: unref short failure
[h264 @ 0x559bf192bec0] mmco: unref short failure
 58%|█████▊    | 1135/1945 [6:05:12<3:50:25, 17.07s/it][h264 @ 0x556b5041bc00] mmco: unref short failure
[h264 @ 0x556b3ab693c0] mmco: unref short failure
 58%|█████▊    | 1136/1945 [6:05:20<3:14:31, 14.43s/it][h264 @ 0x556b4d0c11c0] mmco: unref short failure
[h264 @ 0x556b33cca1c0] mmco: unref short failure
[h264 @ 0x56241a07d740] mmco: unref short failure
 58%|█████▊    | 1137/1945 [6:05:28<2:46:15, 12.35s/it][h264 @ 0x5624174f3840] mmco: unref short failure
[h264 @ 0x55a037d1f1c0] mmco: unref short failure
[h264 @ 0x55a037d1f1c0] mmco: unref short failure
[h264 @ 0x559bfc23d040] mmco: unref short failure
[h264 @ 0x556b4502db80] mmco: unref short failure
[h264 @ 0x556b4502db80] mmco: unref short failure
[h264 @ 0x556b4502db80] mmco: unref short failure
[h264 @ 0x556b4502db80] mmco: unref short failure
[h264 @ 0x556b4502db80] mmco: unref short failure
[h264 @ 0x556b4502db80] mmco: unref short failure
 59%|█████▊    | 1138/1945 [6:05:35<2:24:57, 10.78s/it][h264 @ 0x55a0369c2840] mmco: unref short failure
 59%|█████▊    | 1139/1945 [6:05:44<2:16:35, 10.17s/it][h264 @ 0x55a0369c2840] mmco: unref short failure
[h264 @ 0x5624162236c0] mmco: unref short failure
[h264 @ 0x556b2db40280] mmco: unref short failure
[h264 @ 0x556b2db40280] mmco: unref short failure
[h264 @ 0x556b2e47ffc0] mmco: unref short failure
[h264 @ 0x556b33b22180] mmco: unref short failure
[h264 @ 0x556b33b22180] mmco: unref short failure
[h264 @ 0x556b33b22180] mmco: unref short failure
[h264 @ 0x556b33b22180] mmco: unref short failure
[h264 @ 0x559bf1e1c180] mmco: unref short failure
[h264 @ 0x559bf1e1c180] mmco: unref short failure
[h264 @ 0x559bfd2c1640] mmco: unref short failure
[h264 @ 0x559bfd2c1640] mmco: unref short failure
[h264 @ 0x556b4a9d7800] mmco: unref short failure
[h264 @ 0x556b4a9d7800] mmco: unref short failure
[h264 @ 0x56241cff1d40] mmco: unref short failure
[h264 @ 0x56241cff1d40] mmco: unref short failure
[h264 @ 0x55a04ffbf200] mmco: unref short failure
[h264 @ 0x56241cff1d40] mmco: unref short failure
[h264 @ 0x56241cff1d40] mmco: unref short failure
 59%|█████▊    | 1140/1945 [6:06:27<4:30:06, 20.13s/it][h264 @ 0x55a03dacaf80] mmco: unref short failure
[h264 @ 0x55a03dacaf80] mmco: unref short failure
 59%|█████▊    | 1141/1945 [6:06:40<4:01:57, 18.06s/it][h264 @ 0x559bf5894280] mmco: unref short failure
[h264 @ 0x559bf5894280] mmco: unref short failure
[h264 @ 0x556b49b1cb80] mmco: unref short failure
[h264 @ 0x556b49b1cb80] mmco: unref short failure
[h264 @ 0x556b4af0f8c0] mmco: unref short failure
 59%|█████▊    | 1142/1945 [6:06:57<3:53:50, 17.47s/it][h264 @ 0x559bf04192c0] mmco: unref short failure
[h264 @ 0x559bf04192c0] mmco: unref short failure
[h264 @ 0x559bf04192c0] mmco: unref short failure
[h264 @ 0x556b4ab35000] mmco: unref short failure
[h264 @ 0x556b4ab35000] mmco: unref short failure
[h264 @ 0x556b4ab35000] mmco: unref short failure
[h264 @ 0x556b4ab35000] mmco: unref short failure
 59%|█████▉    | 1143/1945 [6:07:16<4:02:14, 18.12s/it] 59%|█████▉    | 1144/1945 [6:07:24<3:21:14, 15.07s/it][h264 @ 0x55a032992000] mmco: unref short failure
[h264 @ 0x55a032992000] mmco: unref short failure
[h264 @ 0x55a052fa0fc0] mmco: unref short failure
[h264 @ 0x559c019fc7c0] mmco: unref short failure
[h264 @ 0x56241947c900] mmco: unref short failure
[h264 @ 0x56241947c900] mmco: unref short failure
 59%|█████▉    | 1145/1945 [6:07:32<2:50:37, 12.80s/it][h264 @ 0x556b2d887500] mmco: unref short failure
[h264 @ 0x55a04cdd7540] mmco: unref short failure
 59%|█████▉    | 1146/1945 [6:07:39<2:29:47, 11.25s/it] 59%|█████▉    | 1147/1945 [6:07:46<2:12:00,  9.92s/it][h264 @ 0x55a046179cc0] mmco: unref short failure
[h264 @ 0x55a03e739740] mmco: unref short failure
[h264 @ 0x556b4b9fafc0] mmco: unref short failure
[h264 @ 0x556b4b9fafc0] mmco: unref short failure
[h264 @ 0x556b4b9fafc0] mmco: unref short failure
[h264 @ 0x556b4b9fafc0] mmco: unref short failure
[h264 @ 0x556b452ca4c0] mmco: unref short failure
[h264 @ 0x556b452ca4c0] mmco: unref short failure
[h264 @ 0x559be8f553c0] mmco: unref short failure
[h264 @ 0x559c026cd100] mmco: unref short failure
[h264 @ 0x559c026cd100] mmco: unref short failure
[h264 @ 0x55a05172ec00] mmco: unref short failure
[h264 @ 0x556b34aa4440] mmco: unref short failure
[h264 @ 0x556b4905f180] mmco: unref short failure
[h264 @ 0x556b2e47ffc0] mmco: unref short failure
[h264 @ 0x556b4133da80] mmco: unref short failure
[h264 @ 0x556b4133da80] mmco: unref short failure
[h264 @ 0x55a03332d980] mmco: unref short failure
 59%|█████▉    | 1148/1945 [6:08:39<5:01:34, 22.70s/it][h264 @ 0x5624346712c0] mmco: unref short failure
 59%|█████▉    | 1149/1945 [6:08:50<4:15:01, 19.22s/it]09/09/2024 23:14:12 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 23:14:12 - INFO - __main__ -   start running ret%tv validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559bf5876340] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x56241c7d5b40] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a038dcdd40] mmco: unref short failure
[h264 @ 0x55a038dcdd40] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556b40b200c0] mmco: unref short failure
[h264 @ 0x556b48398100] mmco: unref short failure
[h264 @ 0x556b48398100] mmco: unref short failure
[h264 @ 0x562418dcd840] mmco: unref short failure
[h264 @ 0x562418dcd840] mmco: unref short failure
[h264 @ 0x556b3ffad880] mmco: unref short failure
[h264 @ 0x556b3ffad880] mmco: unref short failure
[h264 @ 0x559bf5876340] mmco: unref short failure
[h264 @ 0x559bf5876340] mmco: unref short failure
[h264 @ 0x55a0408dc500] mmco: unref short failure
[h264 @ 0x55a0408dc500] mmco: unref short failure
[h264 @ 0x55a0408dc500] mmco: unref short failure
[h264 @ 0x55a0408dc500] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x562425d6a840] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a0389c1480] mmco: unref short failure
[h264 @ 0x55a0389c1480] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a03ca4a480] mmco: unref short failure
[h264 @ 0x55a03ca4a480] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x556b32859300] mmco: unref short failure
[h264 @ 0x556b2e90ba00] mmco: unref short failure
[h264 @ 0x556b2e90ba00] mmco: unref short failure
[h264 @ 0x559bf5876340] mmco: unref short failure
[h264 @ 0x559bf5876340] mmco: unref short failure
[h264 @ 0x5624311c4500] mmco: unref short failure
[h264 @ 0x5624311c4500] mmco: unref short failure
[h264 @ 0x562425c1c3c0] mmco: unref short failure
[h264 @ 0x562425c1c3c0] mmco: unref short failure
[h264 @ 0x559c04ffcc00] mmco: unref short failure
[h264 @ 0x559c04ffcc00] mmco: unref short failure
[h264 @ 0x559c0bb5b600] mmco: unref short failure
[h264 @ 0x559c0bb5b600] mmco: unref short failure
[h264 @ 0x559c0bb5b600] mmco: unref short failure
[h264 @ 0x559c0bb5b600] mmco: unref short failure
[h264 @ 0x556b4e941080] mmco: unref short failure
[h264 @ 0x55a038dcdd40] mmco: unref short failure
[h264 @ 0x55a038dcdd40] mmco: unref short failure
[h264 @ 0x56241779bd40] mmco: unref short failure
[h264 @ 0x556b4e9132c0] mmco: unref short failure
[h264 @ 0x556b4e9132c0] mmco: unref short failure
[h264 @ 0x55a03fd09180] mmco: unref short failure
[h264 @ 0x55a03fd09180] mmco: unref short failure
[h264 @ 0x559bf2d4e500] mmco: unref short failure
[h264 @ 0x559bf2d4e500] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:51,  1.28it/s][A[h264 @ 0x55a034c4c040] mmco: unref short failure
[h264 @ 0x56241f253080] mmco: unref short failure
[h264 @ 0x56241f253080] mmco: unref short failure
[h264 @ 0x56241f253080] mmco: unref short failure
[h264 @ 0x56241f253080] mmco: unref short failure

  1%|          | 2/221 [00:01<02:38,  1.38it/s][A
  1%|▏         | 3/221 [00:01<02:01,  1.79it/s][A
  2%|▏         | 4/221 [00:01<01:25,  2.53it/s][A
  3%|▎         | 6/221 [00:02<00:54,  3.93it/s][A
  3%|▎         | 7/221 [00:02<00:55,  3.88it/s][A
  4%|▎         | 8/221 [00:03<01:18,  2.73it/s][A
  4%|▍         | 9/221 [00:03<01:06,  3.19it/s][A
  5%|▍         | 10/221 [00:03<01:22,  2.57it/s][A
  5%|▍         | 11/221 [00:04<01:06,  3.18it/s][A
  5%|▌         | 12/221 [00:04<01:23,  2.50it/s][A
  6%|▌         | 13/221 [00:04<01:09,  2.99it/s][A
  6%|▋         | 14/221 [00:06<02:27,  1.40it/s][A
  7%|▋         | 15/221 [00:06<01:59,  1.72it/s][A
  7%|▋         | 16/221 [00:07<01:50,  1.86it/s][A
  8%|▊         | 17/221 [00:07<01:33,  2.19it/s][A
  8%|▊         | 18/221 [00:07<01:19,  2.54it/s][A
  9%|▊         | 19/221 [00:07<01:08,  2.95it/s][A
  9%|▉         | 20/221 [00:08<01:00,  3.31it/s][A
 10%|▉         | 21/221 [00:08<00:50,  3.95it/s][A
 10%|▉         | 22/221 [00:08<00:48,  4.07it/s][A
 10%|█         | 23/221 [00:08<00:40,  4.93it/s][A
 11%|█         | 24/221 [00:08<00:35,  5.53it/s][A
 11%|█▏        | 25/221 [00:08<00:33,  5.91it/s][A
 12%|█▏        | 26/221 [00:09<00:38,  5.12it/s][A
 12%|█▏        | 27/221 [00:09<00:34,  5.69it/s][A
 13%|█▎        | 28/221 [00:09<00:44,  4.30it/s][A
 14%|█▎        | 30/221 [00:09<00:36,  5.20it/s][A
 14%|█▍        | 31/221 [00:10<00:37,  5.11it/s][A
 15%|█▍        | 33/221 [00:10<00:40,  4.67it/s][A
 16%|█▌        | 35/221 [00:10<00:34,  5.32it/s][A
 16%|█▋        | 36/221 [00:11<00:45,  4.07it/s][A
 17%|█▋        | 37/221 [00:11<00:59,  3.08it/s][A
 17%|█▋        | 38/221 [00:12<00:57,  3.17it/s][A
 18%|█▊        | 39/221 [00:12<00:49,  3.68it/s][A
 18%|█▊        | 40/221 [00:12<00:50,  3.56it/s][A
 19%|█▊        | 41/221 [00:12<00:46,  3.85it/s][A
 19%|█▉        | 42/221 [00:13<00:53,  3.32it/s][A
 19%|█▉        | 43/221 [00:13<00:46,  3.86it/s][A
 20%|█▉        | 44/221 [00:13<00:40,  4.34it/s][A
 20%|██        | 45/221 [00:14<01:31,  1.93it/s][A
 21%|██        | 46/221 [00:15<01:29,  1.95it/s][A
 21%|██▏       | 47/221 [00:16<01:47,  1.62it/s][A
 22%|██▏       | 48/221 [00:16<01:21,  2.13it/s][A
 22%|██▏       | 49/221 [00:16<01:03,  2.70it/s][A
 23%|██▎       | 50/221 [00:16<00:49,  3.44it/s][A
 24%|██▎       | 52/221 [00:16<00:34,  4.91it/s][A
 24%|██▍       | 53/221 [00:16<00:35,  4.68it/s][A
 24%|██▍       | 54/221 [00:17<01:00,  2.74it/s][A
 25%|██▍       | 55/221 [00:18<01:12,  2.28it/s][A
 25%|██▌       | 56/221 [00:18<01:01,  2.67it/s][A
 26%|██▌       | 57/221 [00:18<00:52,  3.11it/s][A
 26%|██▌       | 58/221 [00:18<00:42,  3.85it/s][A
 27%|██▋       | 59/221 [00:19<00:38,  4.26it/s][A
 27%|██▋       | 60/221 [00:19<00:42,  3.78it/s][A
 28%|██▊       | 61/221 [00:19<00:38,  4.11it/s][A
 28%|██▊       | 62/221 [00:19<00:37,  4.24it/s][A
 29%|██▊       | 63/221 [00:19<00:32,  4.88it/s][A
 29%|██▉       | 64/221 [00:20<00:28,  5.60it/s][A
 29%|██▉       | 65/221 [00:20<00:27,  5.76it/s][A
 30%|██▉       | 66/221 [00:20<00:38,  4.03it/s][A
 30%|███       | 67/221 [00:20<00:40,  3.82it/s][A
 31%|███       | 68/221 [00:21<00:35,  4.29it/s][A
 31%|███       | 69/221 [00:21<00:51,  2.93it/s][A
 32%|███▏      | 70/221 [00:21<00:41,  3.67it/s][A
 32%|███▏      | 71/221 [00:22<01:15,  1.98it/s][A
 33%|███▎      | 72/221 [00:23<01:07,  2.21it/s][A
 33%|███▎      | 73/221 [00:23<01:06,  2.22it/s][A
 33%|███▎      | 74/221 [00:23<00:58,  2.51it/s][A
 34%|███▍      | 75/221 [00:24<01:07,  2.18it/s][A
 34%|███▍      | 76/221 [00:24<00:56,  2.56it/s][A
 35%|███▍      | 77/221 [00:24<00:48,  2.95it/s][A
 35%|███▌      | 78/221 [00:25<00:46,  3.09it/s][A
 36%|███▌      | 79/221 [00:25<01:00,  2.33it/s][A
 36%|███▌      | 80/221 [00:26<00:50,  2.79it/s][A
 37%|███▋      | 81/221 [00:26<00:45,  3.07it/s][A
 37%|███▋      | 82/221 [00:26<00:40,  3.41it/s][A
 38%|███▊      | 83/221 [00:26<00:34,  3.96it/s][A
 38%|███▊      | 84/221 [00:26<00:29,  4.59it/s][A
 38%|███▊      | 85/221 [00:26<00:25,  5.34it/s][A
 39%|███▉      | 86/221 [00:27<00:23,  5.69it/s][A
 39%|███▉      | 87/221 [00:27<00:39,  3.36it/s][A
 40%|███▉      | 88/221 [00:28<00:45,  2.90it/s][A[h264 @ 0x55a052457900] mmco: unref short failure
[h264 @ 0x55a052457900] mmco: unref short failure

 40%|████      | 89/221 [00:30<01:52,  1.17it/s][A[h264 @ 0x55a03270a4c0] mmco: unref short failure
[h264 @ 0x55a03270a4c0] mmco: unref short failure
[h264 @ 0x55a03270a4c0] mmco: unref short failure
[h264 @ 0x55a03270a4c0] mmco: unref short failure

 41%|████      | 90/221 [00:30<01:29,  1.46it/s][A
 41%|████      | 91/221 [00:30<01:08,  1.89it/s][A[h264 @ 0x56242a7335c0] mmco: unref short failure
[h264 @ 0x56242a7335c0] mmco: unref short failure

 42%|████▏     | 92/221 [00:30<00:55,  2.32it/s][A
 42%|████▏     | 93/221 [00:31<00:55,  2.29it/s][A
 43%|████▎     | 94/221 [00:31<00:51,  2.45it/s][A
 43%|████▎     | 95/221 [00:31<00:43,  2.89it/s][A
 43%|████▎     | 96/221 [00:32<00:42,  2.95it/s][A
 44%|████▍     | 97/221 [00:32<00:35,  3.47it/s][A
 44%|████▍     | 98/221 [00:32<00:35,  3.47it/s][A
 45%|████▍     | 99/221 [00:32<00:28,  4.25it/s][A
 45%|████▌     | 100/221 [00:32<00:27,  4.39it/s][A
 46%|████▌     | 101/221 [00:33<00:24,  4.99it/s][A
 46%|████▌     | 102/221 [00:33<00:29,  4.00it/s][A
 47%|████▋     | 103/221 [00:33<00:24,  4.75it/s][A
 47%|████▋     | 104/221 [00:33<00:25,  4.51it/s][A
 48%|████▊     | 105/221 [00:34<00:29,  3.93it/s][A
 48%|████▊     | 106/221 [00:35<00:53,  2.15it/s][A[h264 @ 0x55a04470c540] mmco: unref short failure
[h264 @ 0x55a04470c540] mmco: unref short failure

 48%|████▊     | 107/221 [00:35<00:42,  2.67it/s][A
 49%|████▉     | 108/221 [00:35<00:36,  3.09it/s][A
 49%|████▉     | 109/221 [00:35<00:35,  3.20it/s][A
 50%|████▉     | 110/221 [00:35<00:29,  3.76it/s][A
 50%|█████     | 111/221 [00:36<00:33,  3.26it/s][A
 51%|█████     | 112/221 [00:36<00:30,  3.52it/s][A
 51%|█████     | 113/221 [00:36<00:33,  3.24it/s][A[h264 @ 0x5624313f8bc0] mmco: unref short failure

 52%|█████▏    | 115/221 [00:37<00:23,  4.42it/s][A[h264 @ 0x55a04470c540] mmco: unref short failure

 52%|█████▏    | 116/221 [00:41<02:01,  1.16s/it][A[h264 @ 0x556b2ff57480] mmco: unref short failure
[h264 @ 0x556b2ff57480] mmco: unref short failure

 53%|█████▎    | 117/221 [00:41<01:37,  1.07it/s][A
 53%|█████▎    | 118/221 [00:41<01:18,  1.31it/s][A
 54%|█████▍    | 119/221 [00:41<01:00,  1.67it/s][A
 54%|█████▍    | 120/221 [00:42<00:52,  1.92it/s][A
 55%|█████▍    | 121/221 [00:42<00:40,  2.45it/s][A
 55%|█████▌    | 122/221 [00:42<00:34,  2.85it/s][A
 56%|█████▌    | 123/221 [00:42<00:28,  3.40it/s][A
 56%|█████▌    | 124/221 [00:42<00:25,  3.77it/s][A
 57%|█████▋    | 125/221 [00:43<00:25,  3.77it/s][A
 57%|█████▋    | 126/221 [00:43<00:28,  3.35it/s][A
 57%|█████▋    | 127/221 [00:43<00:28,  3.28it/s][A
 58%|█████▊    | 128/221 [00:44<00:29,  3.19it/s][A
 58%|█████▊    | 129/221 [00:44<00:26,  3.46it/s][A
 59%|█████▉    | 130/221 [00:44<00:23,  3.94it/s][A
 60%|█████▉    | 132/221 [00:44<00:16,  5.33it/s][A
 60%|██████    | 133/221 [00:45<00:21,  4.05it/s][A
 61%|██████    | 134/221 [00:45<00:20,  4.17it/s][A
 61%|██████    | 135/221 [00:45<00:24,  3.58it/s][A
 62%|██████▏   | 136/221 [00:46<00:25,  3.30it/s][A
 62%|██████▏   | 137/221 [00:46<00:23,  3.62it/s][A[h264 @ 0x559bf05d2740] mmco: unref short failure
[h264 @ 0x559bf05d2740] mmco: unref short failure

 62%|██████▏   | 138/221 [00:46<00:25,  3.24it/s][A
 63%|██████▎   | 139/221 [00:47<00:24,  3.32it/s][A
 63%|██████▎   | 140/221 [00:47<00:24,  3.31it/s][A
 64%|██████▍   | 141/221 [00:47<00:20,  3.83it/s][A
 64%|██████▍   | 142/221 [00:48<00:25,  3.07it/s][A
 65%|██████▍   | 143/221 [00:48<00:25,  3.05it/s][A
 65%|██████▌   | 144/221 [00:48<00:20,  3.78it/s][A
 66%|██████▌   | 145/221 [00:48<00:16,  4.57it/s][A
 66%|██████▌   | 146/221 [00:48<00:16,  4.51it/s][A
 67%|██████▋   | 147/221 [00:49<00:15,  4.81it/s][A
 67%|██████▋   | 148/221 [00:49<00:15,  4.86it/s][A
 67%|██████▋   | 149/221 [00:49<00:12,  5.70it/s][A
 68%|██████▊   | 151/221 [00:50<00:18,  3.70it/s][A
 69%|██████▉   | 152/221 [00:50<00:18,  3.78it/s][A
 69%|██████▉   | 153/221 [00:50<00:18,  3.61it/s][A
 70%|██████▉   | 154/221 [00:51<00:21,  3.08it/s][A
 70%|███████   | 155/221 [00:51<00:17,  3.80it/s][A
 71%|███████   | 156/221 [00:51<00:15,  4.32it/s][A
 71%|███████   | 157/221 [00:54<01:11,  1.11s/it][A
 71%|███████▏  | 158/221 [00:54<00:52,  1.21it/s][A
 72%|███████▏  | 159/221 [00:54<00:39,  1.59it/s][A
 72%|███████▏  | 160/221 [00:55<00:29,  2.06it/s][A
 73%|███████▎  | 162/221 [00:55<00:17,  3.29it/s][A
 74%|███████▍  | 163/221 [00:55<00:16,  3.54it/s][A
 74%|███████▍  | 164/221 [00:55<00:13,  4.11it/s][A
 75%|███████▍  | 165/221 [00:55<00:11,  4.89it/s][A
 75%|███████▌  | 166/221 [00:56<00:13,  4.01it/s][A
 76%|███████▌  | 167/221 [00:56<00:11,  4.80it/s][A
 76%|███████▌  | 168/221 [01:00<01:09,  1.31s/it][A
 76%|███████▋  | 169/221 [01:00<00:50,  1.02it/s][A
 77%|███████▋  | 170/221 [01:00<00:38,  1.32it/s][A
 77%|███████▋  | 171/221 [01:00<00:28,  1.73it/s][A[h264 @ 0x556b49aed340] mmco: unref short failure
[h264 @ 0x556b49aed340] mmco: unref short failure

 78%|███████▊  | 172/221 [01:01<00:23,  2.08it/s][A
 79%|███████▊  | 174/221 [01:01<00:13,  3.36it/s][A
 79%|███████▉  | 175/221 [01:01<00:13,  3.41it/s][A
 80%|███████▉  | 176/221 [01:01<00:13,  3.34it/s][A[h264 @ 0x55a04b0b2dc0] mmco: unref short failure
[h264 @ 0x55a04b0b2dc0] mmco: unref short failure
[h264 @ 0x55a04b0b2dc0] mmco: unref short failure
[h264 @ 0x55a04b0b2dc0] mmco: unref short failure

 81%|████████  | 178/221 [01:02<00:11,  3.71it/s][A
 81%|████████  | 179/221 [01:02<00:15,  2.67it/s][A
 82%|████████▏ | 181/221 [01:03<00:11,  3.62it/s][A
 82%|████████▏ | 182/221 [01:03<00:09,  4.08it/s][A
 83%|████████▎ | 183/221 [01:03<00:08,  4.41it/s][A
 83%|████████▎ | 184/221 [01:03<00:09,  4.11it/s][A
 84%|████████▎ | 185/221 [01:04<00:08,  4.44it/s][A
 84%|████████▍ | 186/221 [01:04<00:09,  3.74it/s][A
 85%|████████▍ | 187/221 [01:04<00:08,  4.22it/s][A
 85%|████████▌ | 188/221 [01:04<00:09,  3.61it/s][A
 86%|████████▌ | 189/221 [01:05<00:08,  3.92it/s][A
 86%|████████▌ | 190/221 [01:05<00:07,  4.28it/s][A
 87%|████████▋ | 192/221 [01:05<00:05,  5.10it/s][A
 88%|████████▊ | 194/221 [01:06<00:06,  4.33it/s][A
 88%|████████▊ | 195/221 [01:06<00:05,  4.93it/s][A
 89%|████████▉ | 197/221 [01:06<00:03,  6.22it/s][A
 90%|████████▉ | 198/221 [01:06<00:04,  5.48it/s][A
 90%|█████████ | 199/221 [01:06<00:03,  5.76it/s][A
 90%|█████████ | 200/221 [01:07<00:04,  4.70it/s][A
 91%|█████████ | 201/221 [01:07<00:04,  4.65it/s][A
 91%|█████████▏| 202/221 [01:07<00:03,  4.98it/s][A
 92%|█████████▏| 203/221 [01:07<00:03,  5.72it/s][A
 93%|█████████▎| 205/221 [01:07<00:02,  7.34it/s][A
 93%|█████████▎| 206/221 [01:08<00:03,  4.21it/s][A
 94%|█████████▍| 208/221 [01:08<00:02,  5.43it/s][A
 95%|█████████▌| 210/221 [01:08<00:01,  7.06it/s][A
 95%|█████████▌| 211/221 [01:09<00:01,  5.60it/s][A
 96%|█████████▋| 213/221 [01:09<00:01,  6.93it/s][A
 97%|█████████▋| 214/221 [01:09<00:01,  4.55it/s][A
 97%|█████████▋| 215/221 [01:09<00:01,  4.91it/s][A
 98%|█████████▊| 216/221 [01:10<00:01,  4.80it/s][A
 98%|█████████▊| 217/221 [01:10<00:01,  3.03it/s][A
 99%|█████████▊| 218/221 [01:10<00:00,  3.51it/s][A
 99%|█████████▉| 219/221 [01:11<00:00,  3.72it/s][A[h264 @ 0x556b30185640] mmco: unref short failure
[h264 @ 0x556b30185640] mmco: unref short failure
[h264 @ 0x556b30185640] mmco: unref short failure
[h264 @ 0x556b30185640] mmco: unref short failure
[h264 @ 0x556b30185640] mmco: unref short failure
[h264 @ 0x556b30185640] mmco: unref short failure
[h264 @ 0x556b463adf40] mmco: unref short failure
[h264 @ 0x556b463adf40] mmco: unref short failure

100%|█████████▉| 220/221 [01:14<00:01,  1.25s/it][A
100%|██████████| 221/221 [01:15<00:00,  1.07it/s][A100%|██████████| 221/221 [01:15<00:00,  2.94it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:51,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:22<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:23,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:37<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:51<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:24,  9.11it/s][A
  1%|          | 2/221 [00:00<00:41,  5.25it/s][A
  1%|▏         | 3/221 [00:00<00:50,  4.35it/s][A
  2%|▏         | 4/221 [00:00<00:41,  5.20it/s][A
  2%|▏         | 5/221 [00:00<00:41,  5.26it/s][A
  3%|▎         | 7/221 [00:01<00:38,  5.51it/s][A
  4%|▎         | 8/221 [00:01<00:47,  4.48it/s][A
  4%|▍         | 9/221 [00:01<00:47,  4.46it/s][A
  5%|▍         | 10/221 [00:02<01:12,  2.93it/s][A
  5%|▍         | 11/221 [00:02<01:01,  3.43it/s][A
  5%|▌         | 12/221 [00:02<00:51,  4.09it/s][A
  6%|▌         | 13/221 [00:03<01:36,  2.14it/s][A
  6%|▋         | 14/221 [00:03<01:14,  2.78it/s][A
  7%|▋         | 15/221 [00:04<01:04,  3.18it/s][A
  7%|▋         | 16/221 [00:04<01:08,  2.97it/s][A
  8%|▊         | 17/221 [00:05<01:31,  2.23it/s][A
  8%|▊         | 18/221 [00:05<01:16,  2.64it/s][A
  9%|▊         | 19/221 [00:05<01:04,  3.15it/s][A
 10%|▉         | 21/221 [00:05<00:44,  4.48it/s][A
 10%|▉         | 22/221 [00:06<00:42,  4.71it/s][A
 11%|█         | 24/221 [00:06<00:34,  5.74it/s][A
 11%|█▏        | 25/221 [00:06<00:33,  5.80it/s][A
 12%|█▏        | 26/221 [00:06<00:35,  5.43it/s][A
 12%|█▏        | 27/221 [00:06<00:32,  5.92it/s][A
 13%|█▎        | 28/221 [00:07<00:44,  4.38it/s][A
 13%|█▎        | 29/221 [00:07<00:44,  4.28it/s][A
 14%|█▎        | 30/221 [00:07<00:48,  3.95it/s][A
 14%|█▍        | 31/221 [00:07<00:45,  4.15it/s][A
 15%|█▍        | 33/221 [00:08<00:36,  5.10it/s][A
 15%|█▌        | 34/221 [00:08<00:37,  5.01it/s][A
 16%|█▌        | 35/221 [00:08<00:41,  4.48it/s][A
 16%|█▋        | 36/221 [00:09<00:45,  4.03it/s][A
 17%|█▋        | 37/221 [00:09<00:39,  4.65it/s][A
 17%|█▋        | 38/221 [00:09<00:42,  4.26it/s][A
 18%|█▊        | 39/221 [00:09<00:39,  4.60it/s][A
 18%|█▊        | 40/221 [00:09<00:47,  3.85it/s][A
 19%|█▊        | 41/221 [00:10<00:39,  4.54it/s][A
 19%|█▉        | 42/221 [00:10<00:34,  5.17it/s][A
 19%|█▉        | 43/221 [00:10<00:40,  4.35it/s][A
 20%|█▉        | 44/221 [00:10<00:42,  4.19it/s][A
 20%|██        | 45/221 [00:11<00:48,  3.63it/s][A
 21%|██        | 46/221 [00:11<00:42,  4.09it/s][A
 21%|██▏       | 47/221 [00:11<00:40,  4.24it/s][A
 22%|██▏       | 48/221 [00:11<00:35,  4.90it/s][A
 22%|██▏       | 49/221 [00:11<00:36,  4.74it/s][A
 23%|██▎       | 50/221 [00:12<00:51,  3.31it/s][A
 23%|██▎       | 51/221 [00:12<00:44,  3.80it/s][A
 24%|██▎       | 52/221 [00:12<00:46,  3.65it/s][A
 24%|██▍       | 53/221 [00:13<00:38,  4.37it/s][A
 24%|██▍       | 54/221 [00:13<00:54,  3.07it/s][A
 25%|██▍       | 55/221 [00:13<00:52,  3.16it/s][A
 25%|██▌       | 56/221 [00:14<00:44,  3.68it/s][A
 26%|██▌       | 57/221 [00:14<00:45,  3.60it/s][A
 26%|██▌       | 58/221 [00:14<00:51,  3.14it/s][A
 27%|██▋       | 59/221 [00:14<00:46,  3.49it/s][A
 27%|██▋       | 60/221 [00:15<00:39,  4.04it/s][A
 28%|██▊       | 61/221 [00:15<00:36,  4.36it/s][A
 28%|██▊       | 62/221 [00:15<00:37,  4.22it/s][A
 29%|██▊       | 63/221 [00:15<00:35,  4.50it/s][A
 29%|██▉       | 64/221 [00:16<00:42,  3.66it/s][A
 29%|██▉       | 65/221 [00:16<00:38,  4.10it/s][A
 30%|██▉       | 66/221 [00:16<00:51,  3.02it/s][A
 30%|███       | 67/221 [00:17<00:54,  2.81it/s][A
 31%|███       | 68/221 [00:17<00:44,  3.46it/s][A
 31%|███       | 69/221 [00:18<01:13,  2.06it/s][A
 32%|███▏      | 70/221 [00:18<00:56,  2.69it/s][A
 32%|███▏      | 71/221 [00:18<00:47,  3.16it/s][A
 33%|███▎      | 72/221 [00:19<00:52,  2.86it/s][A
 33%|███▎      | 73/221 [00:19<00:50,  2.94it/s][A
 33%|███▎      | 74/221 [00:19<00:42,  3.46it/s][A
 34%|███▍      | 75/221 [00:19<00:40,  3.59it/s][A
 34%|███▍      | 76/221 [00:19<00:37,  3.85it/s][A
 35%|███▍      | 77/221 [00:20<00:38,  3.72it/s][A
 35%|███▌      | 78/221 [00:20<00:34,  4.13it/s][A
 36%|███▌      | 79/221 [00:20<00:45,  3.16it/s][A
 36%|███▌      | 80/221 [00:21<00:41,  3.38it/s][A
 37%|███▋      | 81/221 [00:21<00:39,  3.59it/s][A
 37%|███▋      | 82/221 [00:21<00:44,  3.16it/s][A
 38%|███▊      | 83/221 [00:22<00:45,  3.06it/s][A
 38%|███▊      | 84/221 [00:22<00:43,  3.18it/s][A
 38%|███▊      | 85/221 [00:22<00:34,  3.98it/s][A
 39%|███▉      | 86/221 [00:22<00:36,  3.69it/s][A
 39%|███▉      | 87/221 [00:23<00:47,  2.80it/s][A
 40%|███▉      | 88/221 [00:23<00:53,  2.47it/s][A
 40%|████      | 89/221 [00:24<00:47,  2.77it/s][A
 41%|████      | 90/221 [00:24<00:51,  2.54it/s][A
 41%|████      | 91/221 [00:24<00:41,  3.13it/s][A
 42%|████▏     | 92/221 [00:25<00:45,  2.83it/s][A
 42%|████▏     | 93/221 [00:26<00:59,  2.14it/s][A
 43%|████▎     | 94/221 [00:26<00:51,  2.47it/s][A
 43%|████▎     | 95/221 [00:26<00:45,  2.79it/s][A
 43%|████▎     | 96/221 [00:26<00:39,  3.13it/s][A
 44%|████▍     | 97/221 [00:26<00:34,  3.62it/s][A
 44%|████▍     | 98/221 [00:27<00:33,  3.69it/s][A
 45%|████▍     | 99/221 [00:27<00:28,  4.27it/s][A
 45%|████▌     | 100/221 [00:27<00:29,  4.11it/s][A
 46%|████▌     | 101/221 [00:27<00:27,  4.40it/s][A
 46%|████▌     | 102/221 [00:28<00:46,  2.58it/s][A
 47%|████▋     | 103/221 [00:28<00:35,  3.29it/s][A
 47%|████▋     | 104/221 [00:28<00:29,  3.99it/s][A
 48%|████▊     | 105/221 [00:29<00:30,  3.87it/s][A
 48%|████▊     | 106/221 [00:29<00:36,  3.15it/s][A
 48%|████▊     | 107/221 [00:29<00:31,  3.64it/s][A
 49%|████▉     | 108/221 [00:29<00:31,  3.63it/s][A
 50%|████▉     | 110/221 [00:30<00:24,  4.50it/s][A
 50%|█████     | 111/221 [00:30<00:26,  4.18it/s][A
 51%|█████     | 112/221 [00:30<00:25,  4.33it/s][A
 51%|█████     | 113/221 [00:30<00:22,  4.76it/s][A
 52%|█████▏    | 115/221 [00:31<00:19,  5.33it/s][A
 52%|█████▏    | 116/221 [00:31<00:21,  4.89it/s][A
 53%|█████▎    | 117/221 [00:31<00:22,  4.62it/s][A
 53%|█████▎    | 118/221 [00:31<00:22,  4.67it/s][A
 54%|█████▍    | 119/221 [00:32<00:27,  3.71it/s][A
 54%|█████▍    | 120/221 [00:32<00:24,  4.10it/s][A
 55%|█████▍    | 121/221 [00:32<00:20,  4.92it/s][A
 55%|█████▌    | 122/221 [00:32<00:22,  4.40it/s][A
 56%|█████▌    | 123/221 [00:33<00:25,  3.87it/s][A
 56%|█████▌    | 124/221 [00:33<00:24,  3.99it/s][A
 57%|█████▋    | 125/221 [00:33<00:27,  3.45it/s][A
 57%|█████▋    | 126/221 [00:34<00:24,  3.85it/s][A
 57%|█████▋    | 127/221 [00:34<00:30,  3.09it/s][A
 58%|█████▊    | 128/221 [00:34<00:27,  3.40it/s][A
 58%|█████▊    | 129/221 [00:34<00:22,  4.11it/s][A
 59%|█████▉    | 130/221 [00:35<00:23,  3.89it/s][A
 59%|█████▉    | 131/221 [00:35<00:19,  4.72it/s][A
 60%|█████▉    | 132/221 [00:35<00:22,  3.98it/s][A
 60%|██████    | 133/221 [00:36<00:24,  3.57it/s][A
 61%|██████    | 134/221 [00:36<00:33,  2.59it/s][A
 61%|██████    | 135/221 [00:37<00:34,  2.51it/s][A
 62%|██████▏   | 136/221 [00:37<00:29,  2.88it/s][A
 62%|██████▏   | 137/221 [00:37<00:23,  3.53it/s][A
 62%|██████▏   | 138/221 [00:37<00:23,  3.48it/s][A
 63%|██████▎   | 139/221 [00:38<00:29,  2.75it/s][A
 63%|██████▎   | 140/221 [00:38<00:27,  2.91it/s][A
 64%|██████▍   | 141/221 [00:38<00:23,  3.40it/s][A
 64%|██████▍   | 142/221 [00:38<00:21,  3.67it/s][A
 65%|██████▍   | 143/221 [00:39<00:27,  2.88it/s][A
 65%|██████▌   | 144/221 [00:39<00:27,  2.85it/s][A
 66%|██████▌   | 145/221 [00:39<00:21,  3.62it/s][A
 67%|██████▋   | 147/221 [00:40<00:17,  4.32it/s][A
 67%|██████▋   | 148/221 [00:40<00:19,  3.68it/s][A
 67%|██████▋   | 149/221 [00:41<00:20,  3.56it/s][A
 68%|██████▊   | 150/221 [00:41<00:18,  3.85it/s][A
 68%|██████▊   | 151/221 [00:41<00:22,  3.15it/s][A
 69%|██████▉   | 152/221 [00:42<00:33,  2.06it/s][A
 69%|██████▉   | 153/221 [00:42<00:25,  2.63it/s][A
 70%|██████▉   | 154/221 [00:42<00:21,  3.08it/s][A
 70%|███████   | 155/221 [00:43<00:18,  3.53it/s][A
 71%|███████   | 156/221 [00:43<00:21,  2.96it/s][A
 71%|███████   | 157/221 [00:43<00:21,  2.99it/s][A
 71%|███████▏  | 158/221 [00:44<00:19,  3.24it/s][A
 72%|███████▏  | 159/221 [00:44<00:15,  3.96it/s][A
 72%|███████▏  | 160/221 [00:44<00:14,  4.30it/s][A
 73%|███████▎  | 161/221 [00:44<00:17,  3.38it/s][A
 73%|███████▎  | 162/221 [00:45<00:14,  4.04it/s][A
 74%|███████▍  | 163/221 [00:45<00:14,  4.04it/s][A
 74%|███████▍  | 164/221 [00:45<00:12,  4.71it/s][A
 75%|███████▍  | 165/221 [00:45<00:11,  4.74it/s][A
 75%|███████▌  | 166/221 [00:45<00:11,  4.64it/s][A
 76%|███████▌  | 168/221 [00:46<00:10,  5.02it/s][A
 76%|███████▋  | 169/221 [00:46<00:09,  5.55it/s][A
 77%|███████▋  | 170/221 [00:46<00:13,  3.71it/s][A
 77%|███████▋  | 171/221 [00:47<00:12,  4.00it/s][A
 78%|███████▊  | 172/221 [00:47<00:11,  4.09it/s][A
 78%|███████▊  | 173/221 [00:47<00:12,  3.78it/s][A
 79%|███████▊  | 174/221 [00:48<00:15,  2.99it/s][A
 79%|███████▉  | 175/221 [00:48<00:15,  2.93it/s][A
 80%|███████▉  | 176/221 [00:48<00:13,  3.25it/s][A
 80%|████████  | 177/221 [00:48<00:12,  3.55it/s][A
 81%|████████  | 178/221 [00:49<00:13,  3.09it/s][A
 81%|████████  | 179/221 [00:49<00:12,  3.35it/s][A
 81%|████████▏ | 180/221 [00:49<00:10,  3.94it/s][A
 82%|████████▏ | 181/221 [00:49<00:10,  3.84it/s][A
 82%|████████▏ | 182/221 [00:50<00:11,  3.27it/s][A
 83%|████████▎ | 183/221 [00:50<00:12,  3.11it/s][A
 83%|████████▎ | 184/221 [00:51<00:11,  3.28it/s][A
 84%|████████▎ | 185/221 [00:51<00:09,  3.72it/s][A
 84%|████████▍ | 186/221 [00:51<00:11,  2.93it/s][A
 85%|████████▍ | 187/221 [00:51<00:10,  3.32it/s][A
 85%|████████▌ | 188/221 [00:52<00:09,  3.34it/s][A
 86%|████████▌ | 189/221 [00:52<00:08,  3.58it/s][A
 86%|████████▌ | 190/221 [00:52<00:09,  3.30it/s][A
 86%|████████▋ | 191/221 [00:52<00:07,  3.85it/s][A
 87%|████████▋ | 192/221 [00:53<00:07,  3.88it/s][A
 87%|████████▋ | 193/221 [00:53<00:06,  4.58it/s][A
 88%|████████▊ | 194/221 [00:53<00:06,  4.03it/s][A
 88%|████████▊ | 195/221 [00:53<00:05,  4.42it/s][A
 89%|████████▊ | 196/221 [00:54<00:07,  3.35it/s][A
 89%|████████▉ | 197/221 [00:54<00:06,  3.72it/s][A
 90%|████████▉ | 198/221 [00:54<00:07,  3.03it/s][A
 90%|█████████ | 199/221 [00:55<00:06,  3.49it/s][A
 90%|█████████ | 200/221 [00:55<00:06,  3.07it/s][A
 91%|█████████ | 201/221 [00:55<00:05,  3.53it/s][A
 91%|█████████▏| 202/221 [00:56<00:05,  3.30it/s][A
 92%|█████████▏| 203/221 [00:56<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:56<00:04,  3.59it/s][A
 93%|█████████▎| 205/221 [00:56<00:03,  4.41it/s][A
 93%|█████████▎| 206/221 [00:57<00:04,  3.57it/s][A
 94%|█████████▎| 207/221 [00:57<00:03,  3.97it/s][A
 94%|█████████▍| 208/221 [00:57<00:03,  3.85it/s][A
 95%|█████████▍| 209/221 [00:57<00:02,  4.09it/s][A
 95%|█████████▌| 210/221 [00:57<00:02,  4.57it/s][A
 95%|█████████▌| 211/221 [00:58<00:02,  3.96it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  3.81it/s][A
 96%|█████████▋| 213/221 [00:58<00:01,  4.06it/s][A
 97%|█████████▋| 214/221 [00:59<00:02,  2.55it/s][A
 97%|█████████▋| 215/221 [00:59<00:01,  3.06it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.20it/s][A
 98%|█████████▊| 217/221 [01:00<00:01,  3.16it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.24it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.10it/s][A
100%|█████████▉| 220/221 [01:01<00:00,  3.59it/s][A
100%|██████████| 221/221 [01:01<00:00,  3.91it/s][A100%|██████████| 221/221 [01:01<00:00,  3.61it/s]
09/09/2024 23:20:03 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 1149--===========

09/09/2024 23:20:03 - INFO - __main__ -   {'area_r1': 39.7, 'area_recall': '39.7/64.6/74.7', 'area_ravg': 59.7}
09/09/2024 23:20:03 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 1149--===========

09/09/2024 23:20:03 - INFO - __main__ -   {'forward_r1': 37.4, 'forward_recall': '37.4/66.4/77.3', 'forward_ravg': 60.4}
09/09/2024 23:20:03 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 1149--===========

09/09/2024 23:20:03 - INFO - __main__ -   {'area_video_r1': 38.8, 'area_video_recall': '38.8/67.6/77.6', 'area_video_ravg': 61.3}
09/09/2024 23:20:03 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/09/2024 23:20:03 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 23:20:03 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 1149--===========

09/09/2024 23:20:03 - INFO - __main__ -   {'area_video_r1': 53.1, 'area_video_recall': '53.1/75.2/82.9', 'area_video_ravg': 70.4, 'area_video_back_r1': 48.2, 'area_video_back_recall': '48.2/74.0/82.5', 'area_video_back_ravg': 68.2}
09/09/2024 23:20:03 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/09/2024 23:20:03 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/09/2024 23:20:03 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 1149--===========

09/09/2024 23:20:03 - INFO - __main__ -   {'video_r1': 43.9, 'video_recall': '43.9/71.4/82.6', 'video_ravg': 66.0}
09/09/2024 23:20:03 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 23:20:03 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 23:20:03 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 1149--===========

09/09/2024 23:20:03 - INFO - __main__ -   {'video_r1': 52.8, 'video_recall': '52.8/75.6/82.8', 'video_ravg': 70.4}
09/09/2024 23:20:03 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/09/2024 23:20:03 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/09/2024 23:20:24 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.00562139181420207, 'loss_ret%tv%ta--finetune_area/loss_area': 1.0304756164550781, 'loss_ret%tv%ta--finetune_area/total_loss': 1.0360970497131348}
 59%|█████▉    | 1150/1945 [6:15:05<27:48:06, 125.89s/it] 59%|█████▉    | 1151/1945 [6:15:08<19:41:54, 89.31s/it]  59%|█████▉    | 1152/1945 [6:15:12<14:01:11, 63.65s/it] 59%|█████▉    | 1153/1945 [6:15:16<10:03:05, 45.69s/it] 59%|█████▉    | 1154/1945 [6:15:20<7:16:49, 33.13s/it] [h264 @ 0x559be9f28fc0] mmco: unref short failure
[h264 @ 0x559be9f28fc0] mmco: unref short failure
[h264 @ 0x559be9f28fc0] mmco: unref short failure
[h264 @ 0x55a0427615c0] mmco: unref short failure
[h264 @ 0x55a0427615c0] mmco: unref short failure
[h264 @ 0x55a0427615c0] mmco: unref short failure
[h264 @ 0x55a0427615c0] mmco: unref short failure
 59%|█████▉    | 1155/1945 [6:15:24<5:20:21, 24.33s/it] 59%|█████▉    | 1156/1945 [6:15:27<3:59:02, 18.18s/it] 59%|█████▉    | 1157/1945 [6:15:31<3:02:05, 13.86s/it] 60%|█████▉    | 1158/1945 [6:15:35<2:22:14, 10.84s/it] 60%|█████▉    | 1159/1945 [6:15:39<1:54:16,  8.72s/it] 60%|█████▉    | 1160/1945 [6:15:43<1:34:43,  7.24s/it] 60%|█████▉    | 1161/1945 [6:15:46<1:21:01,  6.20s/it] 60%|█████▉    | 1162/1945 [6:15:50<1:11:30,  5.48s/it] 60%|█████▉    | 1163/1945 [6:15:54<1:04:51,  4.98s/it] 60%|█████▉    | 1164/1945 [6:15:58<1:00:05,  4.62s/it] 60%|█████▉    | 1165/1945 [6:16:02<56:49,  4.37s/it]   60%|█████▉    | 1166/1945 [6:16:05<54:25,  4.19s/it]/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a030c53700] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x562415042540] mmco: unref short failure
[h264 @ 0x562415042540] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559be902cf80] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a032cab980] mmco: unref short failure
[h264 @ 0x55a032cab980] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559be97ce040] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559be94f4940] mmco: unref short failure
[h264 @ 0x55a0328b3780] mmco: unref short failure
[h264 @ 0x55a0328b3780] mmco: unref short failure
[h264 @ 0x556b2d3a9b80] mmco: unref short failure
[h264 @ 0x556b2d3a9b80] mmco: unref short failure
[h264 @ 0x556b2d388840] mmco: unref short failure
[h264 @ 0x559be98e3200] mmco: unref short failure
[h264 @ 0x559be98e3200] mmco: unref short failure
[h264 @ 0x559be98e3200] mmco: unref short failure
[h264 @ 0x55a03466c0c0] mmco: unref short failure
[h264 @ 0x55a03466c0c0] mmco: unref short failure
[h264 @ 0x55a033288cc0] mmco: unref short failure
[h264 @ 0x55a033288cc0] mmco: unref short failure
[h264 @ 0x556b2f382080] mmco: unref short failure
[h264 @ 0x556b2f382080] mmco: unref short failure
[h264 @ 0x562417a51200] mmco: unref short failure
[h264 @ 0x559beda89bc0] mmco: unref short failure
[h264 @ 0x559beda89bc0] mmco: unref short failure
[h264 @ 0x559bebc92500] mmco: unref short failure
[h264 @ 0x55a0332ae980] mmco: unref short failure
[h264 @ 0x55a0327f0c00] mmco: unref short failure
[h264 @ 0x55a035655600] mmco: unref short failure
[h264 @ 0x55a035655600] mmco: unref short failure
[h264 @ 0x559beaf9dd40] mmco: unref short failure
[h264 @ 0x55a0331b1440] mmco: unref short failure
[h264 @ 0x559beb223a40] mmco: unref short failure
[h264 @ 0x5624177d1040] mmco: unref short failure
[h264 @ 0x5624175d8680] mmco: unref short failure
[h264 @ 0x5624175d8680] mmco: unref short failure
[h264 @ 0x556b2e53f8c0] mmco: unref short failure
[h264 @ 0x559bebd4a100] mmco: unref short failure
[h264 @ 0x556b33f45880] mmco: unref short failure
[h264 @ 0x556b33f45880] mmco: unref short failure
[h264 @ 0x55a035826d00] mmco: unref short failure
[h264 @ 0x556b30a99a00] mmco: unref short failure
[h264 @ 0x556b30a99a00] mmco: unref short failure
[h264 @ 0x559be91248c0] mmco: unref short failure
[h264 @ 0x559be8fb1700] mmco: unref short failure
[h264 @ 0x559be8fb1700] mmco: unref short failure
[h264 @ 0x556b3358ca80] mmco: unref short failure
[h264 @ 0x556b3358ca80] mmco: unref short failure
[h264 @ 0x559be9e7b080] mmco: unref short failure
[h264 @ 0x559be9e7b080] mmco: unref short failure
[h264 @ 0x5624183b0140] mmco: unref short failure
[h264 @ 0x5624183b0140] mmco: unref short failure
[h264 @ 0x55a033223680] mmco: unref short failure
[h264 @ 0x55a033223680] mmco: unref short failure
[h264 @ 0x56241df470c0] mmco: unref short failure
[h264 @ 0x56241df470c0] mmco: unref short failure
[h264 @ 0x559bea7add80] mmco: unref short failure
[h264 @ 0x56241d2f8900] mmco: unref short failure
[h264 @ 0x56241d2f8900] mmco: unref short failure
[h264 @ 0x5624178e6280] mmco: unref short failure
not have audios ua_Kowav7hg.20
 60%|██████    | 1167/1945 [6:18:31<10:04:54, 46.65s/it][h264 @ 0x559bf21aff00] mmco: unref short failure
 60%|██████    | 1168/1945 [6:18:39<7:32:28, 34.94s/it] [h264 @ 0x55a037a7d640] mmco: unref short failure
 60%|██████    | 1169/1945 [6:18:45<5:41:16, 26.39s/it][h264 @ 0x55a03b3d4640] mmco: unref short failure
[h264 @ 0x55a03b3d4640] mmco: unref short failure
[h264 @ 0x559bec4561c0] mmco: unref short failure
[h264 @ 0x559bec4561c0] mmco: unref short failure
[h264 @ 0x562417af2ec0] mmco: unref short failure
[h264 @ 0x559bedb44b40] mmco: unref short failure
[h264 @ 0x556b2e73aa40] mmco: unref short failure
 60%|██████    | 1170/1945 [6:18:53<4:28:39, 20.80s/it][h264 @ 0x559bed732b40] mmco: unref short failure
 60%|██████    | 1171/1945 [6:19:00<3:34:18, 16.61s/it][h264 @ 0x562417899000] mmco: unref short failure
[h264 @ 0x562417899000] mmco: unref short failure
 60%|██████    | 1172/1945 [6:19:07<2:58:57, 13.89s/it][h264 @ 0x556b30c15d80] mmco: unref short failure
[h264 @ 0x556b30c15d80] mmco: unref short failure
[h264 @ 0x56241b32b0c0] mmco: unref short failure
[h264 @ 0x56241b32b0c0] mmco: unref short failure
 60%|██████    | 1173/1945 [6:19:14<2:32:41, 11.87s/it][h264 @ 0x56241788f480] mmco: unref short failure
[h264 @ 0x56241788f480] mmco: unref short failure
 60%|██████    | 1174/1945 [6:19:21<2:13:26, 10.38s/it][h264 @ 0x559beb701040] mmco: unref short failure
[h264 @ 0x559beb701040] mmco: unref short failure
[h264 @ 0x559beb701040] mmco: unref short failure
[h264 @ 0x559beb701040] mmco: unref short failure
[h264 @ 0x556b2f55f200] mmco: unref short failure
[h264 @ 0x559bf0433100] mmco: unref short failure
[h264 @ 0x55a03bd532c0] mmco: unref short failure
[h264 @ 0x55a03bd532c0] mmco: unref short failure
[h264 @ 0x55a03bd532c0] mmco: unref short failure
[h264 @ 0x55a03bd532c0] mmco: unref short failure
[h264 @ 0x559bf22f51c0] mmco: unref short failure
[h264 @ 0x559bf22f51c0] mmco: unref short failure
[h264 @ 0x55a03321ea00] mmco: unref short failure
[h264 @ 0x556b2e9f9280] mmco: unref short failure
[h264 @ 0x556b2e9f9280] mmco: unref short failure
[h264 @ 0x55a03a7512c0] mmco: unref short failure
[h264 @ 0x55a036d81f40] mmco: unref short failure
[h264 @ 0x559bf137fac0] mmco: unref short failure
[h264 @ 0x559bf137fac0] mmco: unref short failure
[h264 @ 0x559bec08cb80] mmco: unref short failure
[h264 @ 0x56241a6f9ac0] mmco: unref short failure
[h264 @ 0x556b2d671280] mmco: unref short failure
[h264 @ 0x556b2d671280] mmco: unref short failure
[h264 @ 0x556b335461c0] mmco: unref short failure
[h264 @ 0x556b32975040] mmco: unref short failure
[h264 @ 0x55a03daac2c0] mmco: unref short failure
[h264 @ 0x55a03daac2c0] mmco: unref short failure
[h264 @ 0x55a033418a40] mmco: unref short failure
[h264 @ 0x55a0324f8a40] mmco: unref short failure
[h264 @ 0x55a0324f8a40] mmco: unref short failure
[h264 @ 0x5624174dc0c0] mmco: unref short failure
[h264 @ 0x5624174dc0c0] mmco: unref short failure
[h264 @ 0x55a042285440] mmco: unref short failure
[h264 @ 0x55a042285440] mmco: unref short failure
[h264 @ 0x55a033407080] mmco: unref short failure
[h264 @ 0x56241fce65c0] mmco: unref short failure
 60%|██████    | 1175/1945 [6:20:44<6:53:20, 32.21s/it][h264 @ 0x55a032627c00] mmco: unref short failure
 60%|██████    | 1176/1945 [6:20:51<5:15:25, 24.61s/it][h264 @ 0x562417d4f900] mmco: unref short failure
[h264 @ 0x562417d4f900] mmco: unref short failure
[h264 @ 0x55a038681d80] mmco: unref short failure
 61%|██████    | 1177/1945 [6:21:00<4:13:09, 19.78s/it][h264 @ 0x559bf5169c00] mmco: unref short failure
[h264 @ 0x559bf5169c00] mmco: unref short failure
[h264 @ 0x556b2d4f0000] mmco: unref short failure
[h264 @ 0x56241e3bb140] mmco: unref short failure
[h264 @ 0x56241e3bb140] mmco: unref short failure
 61%|██████    | 1178/1945 [6:21:07<3:23:09, 15.89s/it] 61%|██████    | 1179/1945 [6:21:14<2:51:07, 13.40s/it][h264 @ 0x559beb067380] mmco: unref short failure
[h264 @ 0x559beb067380] mmco: unref short failure
 61%|██████    | 1180/1945 [6:21:21<2:26:15, 11.47s/it][h264 @ 0x556b33be0980] mmco: unref short failure
[h264 @ 0x556b33be0980] mmco: unref short failure
[h264 @ 0x56241cad9580] mmco: unref short failure
[h264 @ 0x56241cad9580] mmco: unref short failure
 61%|██████    | 1181/1945 [6:21:28<2:08:47, 10.11s/it][h264 @ 0x556b2dcce640] mmco: unref short failure
[h264 @ 0x559bf124da40] mmco: unref short failure
[h264 @ 0x559bf124da40] mmco: unref short failure
 61%|██████    | 1182/1945 [6:21:36<2:00:49,  9.50s/it][h264 @ 0x562422087ac0] mmco: unref short failure
[h264 @ 0x5624177ba980] mmco: unref short failure
[h264 @ 0x5624177ba980] mmco: unref short failure
[h264 @ 0x556b3795e380] mmco: unref short failure
[h264 @ 0x556b3795e380] mmco: unref short failure
[h264 @ 0x56241e63a7c0] mmco: unref short failure
[h264 @ 0x556b2f0fb040] mmco: unref short failure
[h264 @ 0x556b2f0fb040] mmco: unref short failure
[h264 @ 0x56241a2a6080] mmco: unref short failure
[h264 @ 0x56241d649680] mmco: unref short failure
[h264 @ 0x559be9683580] mmco: unref short failure
[h264 @ 0x559be9683580] mmco: unref short failure
[h264 @ 0x559be9683580] mmco: unref short failure
[h264 @ 0x559be9683580] mmco: unref short failure
[h264 @ 0x556b2e442400] mmco: unref short failure
[h264 @ 0x556b2e442400] mmco: unref short failure
[h264 @ 0x55a042f166c0] mmco: unref short failure
[h264 @ 0x55a042f166c0] mmco: unref short failure
[h264 @ 0x56241f5b3300] mmco: unref short failure
[h264 @ 0x56241f704100] mmco: unref short failure
[h264 @ 0x56241f704100] mmco: unref short failure
[h264 @ 0x562427e53e00] mmco: unref short failure
[h264 @ 0x562427e53e00] mmco: unref short failure
[h264 @ 0x559bf31ef500] mmco: unref short failure
[h264 @ 0x556b31cd8380] mmco: unref short failure
[h264 @ 0x556b31cd8380] mmco: unref short failure
[h264 @ 0x56241b65ca40] mmco: unref short failure
[h264 @ 0x56241b65ca40] mmco: unref short failure
[h264 @ 0x559bea02b840] mmco: unref short failure
[h264 @ 0x559bea02b840] mmco: unref short failure
 61%|██████    | 1183/1945 [6:22:48<5:59:13, 28.29s/it][h264 @ 0x556b2e31a880] mmco: unref short failure
[h264 @ 0x56241c20aa40] mmco: unref short failure
[h264 @ 0x559bec6c1300] mmco: unref short failure
[h264 @ 0x559bec6c1300] mmco: unref short failure
[h264 @ 0x559bf656cd40] mmco: unref short failure
 61%|██████    | 1184/1945 [6:22:55<4:35:44, 21.74s/it][h264 @ 0x556b381853c0] mmco: unref short failure
[h264 @ 0x556b381853c0] mmco: unref short failure
 61%|██████    | 1185/1945 [6:23:02<3:38:44, 17.27s/it][h264 @ 0x55a03e8e1240] mmco: unref short failure
[h264 @ 0x55a03e8e1240] mmco: unref short failure
[h264 @ 0x559bf5202840] mmco: unref short failure
[h264 @ 0x559bf5202840] mmco: unref short failure
[h264 @ 0x55a040d29800] mmco: unref short failure
 61%|██████    | 1186/1945 [6:23:08<2:58:34, 14.12s/it][h264 @ 0x56241bdf4400] mmco: unref short failure
[h264 @ 0x56241bdf4400] mmco: unref short failure
[h264 @ 0x5624178c2700] mmco: unref short failure
[h264 @ 0x5624178c2700] mmco: unref short failure
[h264 @ 0x562421b00100] mmco: unref short failure
[h264 @ 0x562421b00100] mmco: unref short failure
 61%|██████    | 1187/1945 [6:23:15<2:31:08, 11.96s/it] 61%|██████    | 1188/1945 [6:23:22<2:11:58, 10.46s/it][h264 @ 0x562422db41c0] mmco: unref short failure
[h264 @ 0x562422db41c0] mmco: unref short failure
[h264 @ 0x562427e09040] mmco: unref short failure
 61%|██████    | 1189/1945 [6:23:31<2:05:13,  9.94s/it][h264 @ 0x55a0339d0b40] mmco: unref short failure
[h264 @ 0x556b41a16a00] mmco: unref short failure
[h264 @ 0x556b41a16a00] mmco: unref short failure
 61%|██████    | 1190/1945 [6:23:38<1:54:30,  9.10s/it][h264 @ 0x55a037925380] mmco: unref short failure
[h264 @ 0x55a037925380] mmco: unref short failure
[h264 @ 0x55a032f603c0] mmco: unref short failure
[h264 @ 0x55a032f603c0] mmco: unref short failure
[h264 @ 0x556b3de7b240] mmco: unref short failure
[h264 @ 0x556b3de7b240] mmco: unref short failure
[h264 @ 0x56241a95b5c0] mmco: unref short failure
[h264 @ 0x556b386e2640] mmco: unref short failure
[h264 @ 0x556b386e2640] mmco: unref short failure
[h264 @ 0x562422dc6dc0] mmco: unref short failure
[h264 @ 0x556b334c64c0] mmco: unref short failure
[h264 @ 0x556b334c64c0] mmco: unref short failure
[h264 @ 0x556b32fbb300] mmco: unref short failure
[h264 @ 0x56241ccee700] mmco: unref short failure
[h264 @ 0x559bed95fe40] mmco: unref short failure
[h264 @ 0x556b37c89dc0] mmco: unref short failure
[h264 @ 0x559bef553500] mmco: unref short failure
[h264 @ 0x559bef553500] mmco: unref short failure
[h264 @ 0x55a0330a3680] mmco: unref short failure
[h264 @ 0x55a03698e080] mmco: unref short failure
 61%|██████    | 1191/1945 [6:24:52<5:59:09, 28.58s/it][h264 @ 0x562427874640] mmco: unref short failure
[h264 @ 0x562427874640] mmco: unref short failure
 61%|██████▏   | 1192/1945 [6:24:59<4:35:16, 21.93s/it][h264 @ 0x559becb8a600] mmco: unref short failure
[h264 @ 0x559becb8a600] mmco: unref short failure
[h264 @ 0x56241f6da080] mmco: unref short failure
[h264 @ 0x56241f6da080] mmco: unref short failure
 61%|██████▏   | 1193/1945 [6:25:06<3:39:34, 17.52s/it][h264 @ 0x55a033cefe40] mmco: unref short failure
 61%|██████▏   | 1194/1945 [6:25:14<3:02:42, 14.60s/it] 61%|██████▏   | 1195/1945 [6:25:21<2:33:43, 12.30s/it][h264 @ 0x559bf586ed40] mmco: unref short failure
[h264 @ 0x559bf586ed40] mmco: unref short failure
 61%|██████▏   | 1196/1945 [6:25:27<2:11:17, 10.52s/it][h264 @ 0x55a044d26f80] mmco: unref short failure
 62%|██████▏   | 1197/1945 [6:25:34<1:58:01,  9.47s/it][h264 @ 0x559beef71ac0] mmco: unref short failure
[h264 @ 0x559beef71ac0] mmco: unref short failure
[h264 @ 0x556b39cb7100] mmco: unref short failure
[h264 @ 0x556b39cb7100] mmco: unref short failure
 62%|██████▏   | 1198/1945 [6:25:41<1:50:21,  8.86s/it][h264 @ 0x56241d017d00] mmco: unref short failure
[h264 @ 0x56241d017d00] mmco: unref short failure
[h264 @ 0x55a035e0a940] mmco: unref short failure
[h264 @ 0x55a035e0a940] mmco: unref short failure
[h264 @ 0x559bedd77fc0] mmco: unref short failure
[h264 @ 0x559bedd77fc0] mmco: unref short failure
[h264 @ 0x559beecd5600] mmco: unref short failure
[h264 @ 0x559beecd5600] mmco: unref short failure
[h264 @ 0x559beecd5600] mmco: unref short failure
[h264 @ 0x559beecd5600] mmco: unref short failure
[h264 @ 0x5624246d5900] mmco: unref short failure
[h264 @ 0x55a03b88cdc0] mmco: unref short failure
[h264 @ 0x55a03eb2c480] mmco: unref short failure
[h264 @ 0x55a03eb2c480] mmco: unref short failure
[h264 @ 0x556b2d54f040] mmco: unref short failure
[h264 @ 0x556b2d54f040] mmco: unref short failure
[h264 @ 0x559bea07c680] mmco: unref short failure
[h264 @ 0x56242243f340] mmco: unref short failure
[h264 @ 0x56242243f340] mmco: unref short failure
[h264 @ 0x556b34c237c0] mmco: unref short failure
[h264 @ 0x556b34c237c0] mmco: unref short failure
[h264 @ 0x559bea02c280] mmco: unref short failure
[h264 @ 0x55a0339cf680] mmco: unref short failure
[h264 @ 0x55a0339cf680] mmco: unref short failure
[h264 @ 0x556b36e68240] mmco: unref short failure
[h264 @ 0x55a03e937780] mmco: unref short failure
[h264 @ 0x556b40badbc0] mmco: unref short failure
[h264 @ 0x55a03562c640] mmco: unref short failure
[h264 @ 0x55a03562c640] mmco: unref short failure
[h264 @ 0x559bf863a4c0] mmco: unref short failure
 62%|██████▏   | 1199/1945 [6:27:04<6:23:46, 30.87s/it]09/09/2024 23:32:26 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 23:32:26 - INFO - __main__ -   start running ret%tv validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559bea19a340] mmco: unref short failure
[h264 @ 0x559bea19a340] mmco: unref short failure
[h264 @ 0x559becdaf200] mmco: unref short failure
[h264 @ 0x559becdaf200] mmco: unref short failure
[h264 @ 0x559bf53853c0] mmco: unref short failure
[h264 @ 0x559bf53853c0] mmco: unref short failure
[h264 @ 0x562422202b00] mmco: unref short failure
[h264 @ 0x562422202b00] mmco: unref short failure
[h264 @ 0x56242278ae00] mmco: unref short failure
[h264 @ 0x56242acc54c0] mmco: unref short failure
[h264 @ 0x55a044f64d40] mmco: unref short failure
[h264 @ 0x55a044f64d40] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x56242a0c4900] mmco: unref short failure
[h264 @ 0x56242a0c4900] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559bf44daf40] mmco: unref short failure
[h264 @ 0x556b2cc3c880] mmco: unref short failure
[h264 @ 0x556b2cc3c880] mmco: unref short failure
[h264 @ 0x556b396433c0] mmco: unref short failure
[h264 @ 0x556b396433c0] mmco: unref short failure
[h264 @ 0x562418ecd740] mmco: unref short failure
[h264 @ 0x562418ecd740] mmco: unref short failure
[h264 @ 0x55a03fb6fc80] mmco: unref short failure
[h264 @ 0x55a03fb6fc80] mmco: unref short failure
[h264 @ 0x55a03de6f380] mmco: unref short failure
[h264 @ 0x55a03c051000] mmco: unref short failure
[h264 @ 0x56241f91a240] mmco: unref short failure
[h264 @ 0x56241f91a240] mmco: unref short failure
[h264 @ 0x559bfae5cd80] mmco: unref short failure
[h264 @ 0x559bfae5cd80] mmco: unref short failure
[h264 @ 0x55a041b13800] mmco: unref short failure
[h264 @ 0x55a041b13800] mmco: unref short failure
[h264 @ 0x5624253201c0] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:48,  2.03it/s][A
  1%|          | 2/221 [00:01<01:55,  1.90it/s][A
  2%|▏         | 4/221 [00:01<00:50,  4.32it/s][A
  3%|▎         | 6/221 [00:01<00:32,  6.66it/s][A
  4%|▎         | 8/221 [00:01<00:50,  4.25it/s][A
  4%|▍         | 9/221 [00:02<00:44,  4.75it/s][A
  5%|▍         | 10/221 [00:02<00:52,  4.04it/s][A[h264 @ 0x55a033a89640] mmco: unref short failure
[h264 @ 0x55a033a89640] mmco: unref short failure
[h264 @ 0x55a033a89640] mmco: unref short failure
[h264 @ 0x55a033a89640] mmco: unref short failure

  5%|▌         | 12/221 [00:03<00:59,  3.50it/s][A
  6%|▋         | 14/221 [00:05<02:01,  1.71it/s][A
  7%|▋         | 15/221 [00:05<01:43,  1.99it/s][A
  7%|▋         | 16/221 [00:05<01:35,  2.14it/s][A
  8%|▊         | 17/221 [00:06<01:21,  2.50it/s][A
  8%|▊         | 18/221 [00:06<01:11,  2.85it/s][A
  9%|▉         | 20/221 [00:06<00:47,  4.22it/s][A
 10%|▉         | 22/221 [00:06<00:39,  4.98it/s][A[h264 @ 0x562421762f00] mmco: unref short failure
[h264 @ 0x562421762f00] mmco: unref short failure

 11%|█         | 24/221 [00:06<00:29,  6.67it/s][A
 12%|█▏        | 26/221 [00:07<00:30,  6.48it/s][A
 13%|█▎        | 28/221 [00:07<00:29,  6.44it/s][A
 14%|█▎        | 30/221 [00:07<00:25,  7.55it/s][A
 14%|█▍        | 31/221 [00:07<00:25,  7.31it/s][A
 15%|█▍        | 33/221 [00:08<00:28,  6.63it/s][A
 16%|█▌        | 35/221 [00:08<00:22,  8.17it/s][A
 16%|█▋        | 36/221 [00:08<00:24,  7.68it/s][A
 17%|█▋        | 37/221 [00:09<00:41,  4.47it/s][A
 17%|█▋        | 38/221 [00:09<00:42,  4.28it/s][A
 18%|█▊        | 40/221 [00:09<00:33,  5.34it/s][A
 19%|█▉        | 42/221 [00:09<00:32,  5.51it/s][A
 20%|█▉        | 44/221 [00:10<00:25,  7.07it/s][A
 20%|██        | 45/221 [00:11<00:57,  3.08it/s][A
 21%|██        | 46/221 [00:11<00:58,  3.00it/s][A
 21%|██▏       | 47/221 [00:12<01:29,  1.95it/s][A
 22%|██▏       | 49/221 [00:12<00:57,  2.97it/s][A
 23%|██▎       | 51/221 [00:12<00:39,  4.31it/s][A
 24%|██▍       | 53/221 [00:13<00:31,  5.39it/s][A
 25%|██▍       | 55/221 [00:13<00:45,  3.64it/s][A[h264 @ 0x562418096d40] mmco: unref short failure
[h264 @ 0x562418096d40] mmco: unref short failure

 25%|██▌       | 56/221 [00:14<00:42,  3.91it/s][A
 26%|██▌       | 57/221 [00:14<00:38,  4.26it/s][A
 27%|██▋       | 59/221 [00:14<00:28,  5.66it/s][A
 27%|██▋       | 60/221 [00:14<00:31,  5.14it/s][A
 28%|██▊       | 61/221 [00:14<00:30,  5.31it/s][A
 28%|██▊       | 62/221 [00:14<00:26,  5.92it/s][A
 29%|██▉       | 64/221 [00:15<00:20,  7.81it/s][A
 30%|██▉       | 66/221 [00:15<00:24,  6.45it/s][A
 30%|███       | 67/221 [00:15<00:23,  6.66it/s][A
 31%|███       | 69/221 [00:16<00:30,  5.03it/s][A
 32%|███▏      | 70/221 [00:16<00:27,  5.54it/s][A
 32%|███▏      | 71/221 [00:17<01:11,  2.10it/s][A
 33%|███▎      | 72/221 [00:17<00:59,  2.51it/s][A
 33%|███▎      | 73/221 [00:18<00:52,  2.84it/s][A
 34%|███▍      | 75/221 [00:18<00:41,  3.51it/s][A
 34%|███▍      | 76/221 [00:18<00:36,  4.02it/s][A
 35%|███▍      | 77/221 [00:18<00:30,  4.70it/s][A
 35%|███▌      | 78/221 [00:18<00:30,  4.65it/s][A
 36%|███▌      | 79/221 [00:19<00:43,  3.25it/s][A
 36%|███▌      | 80/221 [00:19<00:35,  3.98it/s][A
 37%|███▋      | 81/221 [00:19<00:32,  4.28it/s][A
 37%|███▋      | 82/221 [00:20<00:31,  4.42it/s][A
 38%|███▊      | 84/221 [00:20<00:22,  6.12it/s][A
 39%|███▉      | 86/221 [00:20<00:17,  7.55it/s][A
 39%|███▉      | 87/221 [00:20<00:26,  5.04it/s][A
 40%|███▉      | 88/221 [00:21<00:28,  4.71it/s][A
 40%|████      | 89/221 [00:23<01:39,  1.33it/s][A
 41%|████      | 90/221 [00:23<01:19,  1.65it/s][A
 42%|████▏     | 92/221 [00:23<00:51,  2.52it/s][A
 42%|████▏     | 93/221 [00:24<00:49,  2.61it/s][A
 43%|████▎     | 94/221 [00:24<00:43,  2.95it/s][A
 43%|████▎     | 96/221 [00:24<00:31,  3.98it/s][A
 44%|████▍     | 98/221 [00:24<00:24,  5.00it/s][A
 45%|████▌     | 100/221 [00:25<00:21,  5.75it/s][A
 46%|████▌     | 102/221 [00:25<00:19,  6.02it/s][A
 47%|████▋     | 104/221 [00:25<00:15,  7.50it/s][A
 48%|████▊     | 105/221 [00:25<00:16,  7.20it/s][A
 48%|████▊     | 106/221 [00:26<00:34,  3.36it/s][A
 49%|████▉     | 108/221 [00:26<00:25,  4.51it/s][A
 49%|████▉     | 109/221 [00:26<00:23,  4.75it/s][A
 50%|█████     | 111/221 [00:27<00:23,  4.60it/s][A
 51%|█████     | 112/221 [00:27<00:22,  4.90it/s][A
 51%|█████     | 113/221 [00:27<00:26,  4.13it/s][A
 52%|█████▏    | 116/221 [00:32<01:25,  1.22it/s][A
 53%|█████▎    | 117/221 [00:32<01:13,  1.42it/s][A
 53%|█████▎    | 118/221 [00:32<01:03,  1.62it/s][A
 54%|█████▍    | 120/221 [00:33<00:44,  2.25it/s][A
 55%|█████▌    | 122/221 [00:33<00:32,  3.06it/s][A
 56%|█████▌    | 123/221 [00:33<00:28,  3.47it/s][A
 56%|█████▌    | 124/221 [00:33<00:25,  3.80it/s][A
 57%|█████▋    | 125/221 [00:33<00:23,  4.12it/s][A
 57%|█████▋    | 126/221 [00:34<00:25,  3.78it/s][A
 57%|█████▋    | 127/221 [00:34<00:25,  3.62it/s][A
 58%|█████▊    | 128/221 [00:34<00:27,  3.33it/s][A
 58%|█████▊    | 129/221 [00:34<00:23,  3.95it/s][A
 59%|█████▉    | 130/221 [00:35<00:20,  4.43it/s][A
 60%|█████▉    | 132/221 [00:35<00:15,  5.92it/s][A
 60%|██████    | 133/221 [00:35<00:18,  4.67it/s][A
 61%|██████    | 134/221 [00:35<00:17,  4.92it/s][A
 61%|██████    | 135/221 [00:36<00:19,  4.41it/s][A
 62%|██████▏   | 136/221 [00:36<00:22,  3.81it/s][A
 62%|██████▏   | 137/221 [00:36<00:20,  4.18it/s][A
 62%|██████▏   | 138/221 [00:36<00:23,  3.48it/s][A
 63%|██████▎   | 139/221 [00:37<00:22,  3.61it/s][A
 63%|██████▎   | 140/221 [00:37<00:22,  3.58it/s][A
 64%|██████▍   | 141/221 [00:37<00:19,  4.11it/s][A
 64%|██████▍   | 142/221 [00:38<00:25,  3.07it/s][A
 65%|██████▍   | 143/221 [00:38<00:24,  3.19it/s][A
 66%|██████▌   | 145/221 [00:38<00:14,  5.08it/s][A
 67%|██████▋   | 147/221 [00:38<00:10,  6.88it/s][A
 67%|██████▋   | 148/221 [00:38<00:10,  6.71it/s][A
 68%|██████▊   | 150/221 [00:39<00:08,  8.55it/s][A
 69%|██████▉   | 152/221 [00:39<00:13,  5.00it/s][A
 69%|██████▉   | 153/221 [00:40<00:15,  4.43it/s][A
 70%|██████▉   | 154/221 [00:40<00:18,  3.58it/s][A
 71%|███████   | 156/221 [00:40<00:13,  4.88it/s][A
 71%|███████   | 157/221 [00:44<01:02,  1.03it/s][A
 71%|███████▏  | 158/221 [00:44<00:48,  1.30it/s][A
 72%|███████▏  | 159/221 [00:44<00:38,  1.62it/s][A
 72%|███████▏  | 160/221 [00:44<00:29,  2.06it/s][A
 73%|███████▎  | 162/221 [00:44<00:18,  3.24it/s][A
 74%|███████▍  | 163/221 [00:45<00:16,  3.54it/s][A
 74%|███████▍  | 164/221 [00:45<00:14,  4.02it/s][A
 75%|███████▌  | 166/221 [00:45<00:13,  4.12it/s][A
 76%|███████▌  | 167/221 [00:45<00:11,  4.74it/s][A
 76%|███████▌  | 168/221 [00:49<01:02,  1.17s/it][A
 76%|███████▋  | 169/221 [00:50<00:47,  1.10it/s][A
 77%|███████▋  | 170/221 [00:50<00:37,  1.38it/s][A
 77%|███████▋  | 171/221 [00:50<00:28,  1.78it/s][A
 78%|███████▊  | 172/221 [00:50<00:22,  2.15it/s][A
 79%|███████▊  | 174/221 [00:50<00:13,  3.49it/s][A
 79%|███████▉  | 175/221 [00:51<00:12,  3.59it/s][A
 80%|███████▉  | 176/221 [00:51<00:11,  3.86it/s][A
 81%|████████  | 178/221 [00:51<00:09,  4.38it/s][A
 81%|████████  | 179/221 [00:52<00:18,  2.33it/s][A
 82%|████████▏ | 181/221 [00:53<00:12,  3.19it/s][A
 82%|████████▏ | 182/221 [00:53<00:10,  3.62it/s][A
 83%|████████▎ | 183/221 [00:53<00:09,  4.03it/s][A
 83%|████████▎ | 184/221 [00:53<00:09,  4.09it/s][A
 84%|████████▎ | 185/221 [00:53<00:07,  4.75it/s][A
 84%|████████▍ | 186/221 [00:54<00:08,  3.91it/s][A
 85%|████████▍ | 187/221 [00:54<00:07,  4.66it/s][A
 85%|████████▌ | 188/221 [00:54<00:08,  3.92it/s][A
 86%|████████▌ | 189/221 [00:54<00:07,  4.02it/s][A
 86%|████████▌ | 190/221 [00:54<00:07,  4.38it/s][A
 87%|████████▋ | 192/221 [00:55<00:05,  5.14it/s][A
 88%|████████▊ | 194/221 [00:55<00:06,  4.35it/s][A
 88%|████████▊ | 195/221 [00:55<00:05,  4.96it/s][A
 89%|████████▉ | 197/221 [00:56<00:03,  6.56it/s][A
 90%|████████▉ | 198/221 [00:56<00:03,  5.88it/s][A
 90%|█████████ | 199/221 [00:56<00:03,  6.27it/s][A
 90%|█████████ | 200/221 [00:56<00:03,  5.48it/s][A
 91%|█████████ | 201/221 [00:56<00:03,  5.50it/s][A
 91%|█████████▏| 202/221 [00:57<00:03,  5.73it/s][A
 92%|█████████▏| 204/221 [00:57<00:02,  7.63it/s][A
 93%|█████████▎| 206/221 [00:57<00:03,  4.86it/s][A
 94%|█████████▍| 208/221 [00:58<00:02,  6.29it/s][A
 95%|█████████▌| 210/221 [00:58<00:01,  8.09it/s][A
 96%|█████████▌| 212/221 [00:58<00:01,  6.56it/s][A
 97%|█████████▋| 214/221 [00:59<00:01,  5.41it/s][A
 97%|█████████▋| 215/221 [00:59<00:01,  5.58it/s][A
 98%|█████████▊| 216/221 [00:59<00:00,  5.43it/s][A
 98%|█████████▊| 217/221 [01:00<00:01,  3.16it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.59it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.80it/s][A
100%|█████████▉| 220/221 [01:04<00:01,  1.28s/it][A
100%|██████████| 221/221 [01:04<00:00,  1.05it/s][A100%|██████████| 221/221 [01:04<00:00,  3.42it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:55,  3.59it/s][A
 10%|█         | 23/221 [00:06<00:54,  3.65it/s][A
 11%|█         | 24/221 [00:06<00:53,  3.69it/s][A
 11%|█▏        | 25/221 [00:06<00:52,  3.72it/s][A
 12%|█▏        | 26/221 [00:06<00:52,  3.74it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.75it/s][A
 13%|█▎        | 28/221 [00:07<00:51,  3.76it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.77it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.78it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.78it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.78it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:09<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:14<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:23<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:28<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:47<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:52<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:57<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:27,  7.95it/s][A
  1%|          | 2/221 [00:00<00:44,  4.89it/s][A
  1%|▏         | 3/221 [00:00<00:49,  4.43it/s][A
  2%|▏         | 4/221 [00:00<00:43,  4.98it/s][A
  2%|▏         | 5/221 [00:01<00:43,  4.92it/s][A
  3%|▎         | 7/221 [00:01<00:40,  5.22it/s][A
  4%|▎         | 8/221 [00:01<00:50,  4.25it/s][A
  4%|▍         | 9/221 [00:01<00:50,  4.17it/s][A
  5%|▍         | 10/221 [00:02<01:12,  2.90it/s][A
  5%|▍         | 11/221 [00:02<01:01,  3.42it/s][A
  5%|▌         | 12/221 [00:02<00:52,  3.95it/s][A
  6%|▌         | 13/221 [00:03<01:34,  2.19it/s][A
  6%|▋         | 14/221 [00:03<01:14,  2.80it/s][A
  7%|▋         | 15/221 [00:04<01:04,  3.19it/s][A
  7%|▋         | 16/221 [00:04<01:11,  2.88it/s][A
  8%|▊         | 17/221 [00:05<01:31,  2.23it/s][A
  8%|▊         | 18/221 [00:05<01:16,  2.65it/s][A
  9%|▊         | 19/221 [00:05<01:03,  3.16it/s][A
  9%|▉         | 20/221 [00:05<00:50,  3.96it/s][A
 10%|▉         | 21/221 [00:05<00:45,  4.41it/s][A
 10%|▉         | 22/221 [00:06<00:42,  4.70it/s][A
 10%|█         | 23/221 [00:06<00:35,  5.58it/s][A
 11%|█         | 24/221 [00:06<00:34,  5.70it/s][A
 11%|█▏        | 25/221 [00:06<00:35,  5.60it/s][A
 12%|█▏        | 26/221 [00:06<00:37,  5.23it/s][A
 12%|█▏        | 27/221 [00:06<00:33,  5.79it/s][A
 13%|█▎        | 28/221 [00:07<00:45,  4.24it/s][A
 13%|█▎        | 29/221 [00:07<00:45,  4.25it/s][A
 14%|█▎        | 30/221 [00:07<00:47,  3.99it/s][A
 14%|█▍        | 31/221 [00:08<00:45,  4.19it/s][A
 14%|█▍        | 32/221 [00:08<00:37,  5.04it/s][A
 15%|█▍        | 33/221 [00:08<00:36,  5.11it/s][A
 15%|█▌        | 34/221 [00:08<00:36,  5.09it/s][A
 16%|█▌        | 35/221 [00:08<00:42,  4.42it/s][A
 16%|█▋        | 36/221 [00:09<00:47,  3.88it/s][A
 17%|█▋        | 37/221 [00:09<00:41,  4.41it/s][A
 17%|█▋        | 38/221 [00:09<00:44,  4.09it/s][A
 18%|█▊        | 39/221 [00:09<00:40,  4.49it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.81it/s][A
 19%|█▊        | 41/221 [00:10<00:41,  4.34it/s][A
 19%|█▉        | 42/221 [00:10<00:35,  5.03it/s][A
 19%|█▉        | 43/221 [00:10<00:40,  4.36it/s][A
 20%|█▉        | 44/221 [00:10<00:41,  4.24it/s][A
 20%|██        | 45/221 [00:11<00:45,  3.85it/s][A
 21%|██        | 46/221 [00:11<00:41,  4.24it/s][A
 21%|██▏       | 47/221 [00:11<00:41,  4.23it/s][A
 22%|██▏       | 48/221 [00:11<00:35,  4.89it/s][A
 22%|██▏       | 49/221 [00:12<00:36,  4.66it/s][A
 23%|██▎       | 50/221 [00:12<00:51,  3.34it/s][A
 23%|██▎       | 51/221 [00:12<00:43,  3.94it/s][A
 24%|██▎       | 52/221 [00:13<00:46,  3.62it/s][A
 24%|██▍       | 53/221 [00:13<00:39,  4.30it/s][A
 24%|██▍       | 54/221 [00:13<00:49,  3.37it/s][A
 25%|██▍       | 55/221 [00:13<00:46,  3.53it/s][A
 25%|██▌       | 56/221 [00:14<00:40,  4.03it/s][A
 26%|██▌       | 57/221 [00:14<00:42,  3.86it/s][A
 26%|██▌       | 58/221 [00:14<00:51,  3.17it/s][A
 27%|██▋       | 59/221 [00:14<00:44,  3.62it/s][A
 27%|██▋       | 60/221 [00:15<00:37,  4.33it/s][A
 28%|██▊       | 61/221 [00:15<00:34,  4.67it/s][A
 28%|██▊       | 62/221 [00:15<00:34,  4.55it/s][A
 29%|██▊       | 63/221 [00:15<00:33,  4.77it/s][A
 29%|██▉       | 64/221 [00:16<00:43,  3.62it/s][A
 29%|██▉       | 65/221 [00:16<00:38,  4.06it/s][A
 30%|██▉       | 66/221 [00:16<00:49,  3.14it/s][A
 30%|███       | 67/221 [00:17<00:50,  3.05it/s][A
 31%|███       | 68/221 [00:17<00:42,  3.58it/s][A
 31%|███       | 69/221 [00:18<01:07,  2.27it/s][A
 32%|███▏      | 70/221 [00:18<00:54,  2.78it/s][A
 32%|███▏      | 71/221 [00:18<00:45,  3.32it/s][A
 33%|███▎      | 72/221 [00:18<00:50,  2.97it/s][A
 33%|███▎      | 73/221 [00:19<00:48,  3.02it/s][A
 33%|███▎      | 74/221 [00:19<00:42,  3.48it/s][A
 34%|███▍      | 75/221 [00:19<00:40,  3.60it/s][A
 34%|███▍      | 76/221 [00:19<00:37,  3.86it/s][A
 35%|███▍      | 77/221 [00:20<00:39,  3.65it/s][A
 35%|███▌      | 78/221 [00:20<00:35,  4.07it/s][A
 36%|███▌      | 79/221 [00:20<00:42,  3.34it/s][A
 36%|███▌      | 80/221 [00:20<00:39,  3.59it/s][A
 37%|███▋      | 81/221 [00:21<00:37,  3.77it/s][A
 37%|███▋      | 82/221 [00:21<00:42,  3.25it/s][A
 38%|███▊      | 83/221 [00:21<00:44,  3.07it/s][A
 38%|███▊      | 84/221 [00:22<00:42,  3.22it/s][A
 38%|███▊      | 85/221 [00:22<00:33,  4.01it/s][A
 39%|███▉      | 86/221 [00:22<00:37,  3.56it/s][A
 39%|███▉      | 87/221 [00:23<00:45,  2.96it/s][A
 40%|███▉      | 88/221 [00:23<00:51,  2.60it/s][A
 40%|████      | 89/221 [00:23<00:45,  2.90it/s][A
 41%|████      | 90/221 [00:24<00:48,  2.67it/s][A
 41%|████      | 91/221 [00:24<00:39,  3.32it/s][A
 42%|████▏     | 92/221 [00:24<00:43,  2.98it/s][A
 42%|████▏     | 93/221 [00:25<00:56,  2.28it/s][A
 43%|████▎     | 94/221 [00:25<00:49,  2.56it/s][A
 43%|████▎     | 95/221 [00:26<00:43,  2.87it/s][A
 43%|████▎     | 96/221 [00:26<00:39,  3.17it/s][A
 44%|████▍     | 97/221 [00:26<00:35,  3.46it/s][A
 44%|████▍     | 98/221 [00:26<00:34,  3.59it/s][A
 45%|████▍     | 99/221 [00:27<00:31,  3.88it/s][A
 45%|████▌     | 100/221 [00:27<00:32,  3.76it/s][A
 46%|████▌     | 101/221 [00:27<00:30,  3.94it/s][A
 46%|████▌     | 102/221 [00:28<00:45,  2.60it/s][A
 47%|████▋     | 103/221 [00:28<00:35,  3.28it/s][A
 47%|████▋     | 104/221 [00:28<00:31,  3.70it/s][A
 48%|████▊     | 105/221 [00:28<00:31,  3.65it/s][A
 48%|████▊     | 106/221 [00:29<00:36,  3.11it/s][A
 48%|████▊     | 107/221 [00:29<00:33,  3.44it/s][A
 49%|████▉     | 108/221 [00:29<00:32,  3.49it/s][A
 50%|████▉     | 110/221 [00:30<00:24,  4.49it/s][A
 50%|█████     | 111/221 [00:30<00:26,  4.13it/s][A
 51%|█████     | 112/221 [00:30<00:26,  4.18it/s][A
 51%|█████     | 113/221 [00:30<00:23,  4.63it/s][A
 52%|█████▏    | 114/221 [00:30<00:19,  5.43it/s][A
 52%|█████▏    | 115/221 [00:31<00:20,  5.18it/s][A
 52%|█████▏    | 116/221 [00:31<00:22,  4.76it/s][A
 53%|█████▎    | 117/221 [00:31<00:22,  4.58it/s][A
 53%|█████▎    | 118/221 [00:31<00:21,  4.71it/s][A
 54%|█████▍    | 119/221 [00:32<00:27,  3.71it/s][A
 54%|█████▍    | 120/221 [00:32<00:24,  4.14it/s][A
 55%|█████▍    | 121/221 [00:32<00:19,  5.00it/s][A
 55%|█████▌    | 122/221 [00:32<00:21,  4.57it/s][A
 56%|█████▌    | 123/221 [00:33<00:26,  3.71it/s][A
 56%|█████▌    | 124/221 [00:33<00:24,  3.93it/s][A
 57%|█████▋    | 125/221 [00:33<00:26,  3.57it/s][A
 57%|█████▋    | 126/221 [00:33<00:23,  3.97it/s][A
 57%|█████▋    | 127/221 [00:34<00:28,  3.31it/s][A
 58%|█████▊    | 128/221 [00:34<00:26,  3.49it/s][A
 58%|█████▊    | 129/221 [00:34<00:21,  4.23it/s][A
 59%|█████▉    | 130/221 [00:34<00:22,  3.96it/s][A
 59%|█████▉    | 131/221 [00:35<00:19,  4.66it/s][A
 60%|█████▉    | 132/221 [00:35<00:22,  3.90it/s][A
 60%|██████    | 133/221 [00:35<00:25,  3.52it/s][A
 61%|██████    | 134/221 [00:36<00:30,  2.86it/s][A
 61%|██████    | 135/221 [00:36<00:30,  2.83it/s][A
 62%|██████▏   | 136/221 [00:36<00:26,  3.17it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.77it/s][A
 62%|██████▏   | 138/221 [00:37<00:23,  3.52it/s][A
 63%|██████▎   | 139/221 [00:37<00:26,  3.09it/s][A
 63%|██████▎   | 140/221 [00:38<00:25,  3.18it/s][A
 64%|██████▍   | 141/221 [00:38<00:22,  3.57it/s][A
 64%|██████▍   | 142/221 [00:38<00:20,  3.82it/s][A
 65%|██████▍   | 143/221 [00:38<00:27,  2.88it/s][A
 65%|██████▌   | 144/221 [00:39<00:27,  2.83it/s][A
 66%|██████▌   | 145/221 [00:39<00:21,  3.60it/s][A
 67%|██████▋   | 147/221 [00:39<00:17,  4.29it/s][A
 67%|██████▋   | 148/221 [00:40<00:19,  3.77it/s][A
 67%|██████▋   | 149/221 [00:40<00:19,  3.71it/s][A
 68%|██████▊   | 150/221 [00:40<00:18,  3.86it/s][A
 68%|██████▊   | 151/221 [00:41<00:20,  3.46it/s][A
 69%|██████▉   | 152/221 [00:41<00:28,  2.46it/s][A
 69%|██████▉   | 153/221 [00:41<00:22,  3.07it/s][A
 70%|██████▉   | 154/221 [00:42<00:19,  3.44it/s][A
 70%|███████   | 155/221 [00:42<00:17,  3.87it/s][A
 71%|███████   | 156/221 [00:42<00:20,  3.13it/s][A
 71%|███████   | 157/221 [00:43<00:20,  3.14it/s][A
 71%|███████▏  | 158/221 [00:43<00:18,  3.35it/s][A
 72%|███████▏  | 159/221 [00:43<00:15,  4.07it/s][A
 72%|███████▏  | 160/221 [00:43<00:13,  4.36it/s][A
 73%|███████▎  | 161/221 [00:44<00:17,  3.43it/s][A
 73%|███████▎  | 162/221 [00:44<00:14,  4.09it/s][A
 74%|███████▍  | 163/221 [00:44<00:13,  4.14it/s][A
 74%|███████▍  | 164/221 [00:44<00:12,  4.64it/s][A
 75%|███████▍  | 165/221 [00:44<00:11,  4.68it/s][A
 75%|███████▌  | 166/221 [00:45<00:12,  4.57it/s][A
 76%|███████▌  | 167/221 [00:45<00:09,  5.42it/s][A
 76%|███████▌  | 168/221 [00:45<00:11,  4.62it/s][A
 76%|███████▋  | 169/221 [00:45<00:09,  5.42it/s][A
 77%|███████▋  | 170/221 [00:46<00:14,  3.57it/s][A
 77%|███████▋  | 171/221 [00:46<00:12,  4.00it/s][A
 78%|███████▊  | 172/221 [00:46<00:12,  3.98it/s][A
 78%|███████▊  | 173/221 [00:46<00:12,  3.70it/s][A
 79%|███████▊  | 174/221 [00:47<00:15,  2.99it/s][A
 79%|███████▉  | 175/221 [00:47<00:15,  2.92it/s][A
 80%|███████▉  | 176/221 [00:47<00:13,  3.23it/s][A
 80%|████████  | 177/221 [00:48<00:12,  3.40it/s][A
 81%|████████  | 178/221 [00:48<00:12,  3.39it/s][A
 81%|████████  | 179/221 [00:48<00:11,  3.57it/s][A
 81%|████████▏ | 180/221 [00:48<00:09,  4.11it/s][A
 82%|████████▏ | 181/221 [00:49<00:09,  4.07it/s][A
 82%|████████▏ | 182/221 [00:49<00:11,  3.47it/s][A
 83%|████████▎ | 183/221 [00:49<00:11,  3.29it/s][A
 83%|████████▎ | 184/221 [00:50<00:11,  3.35it/s][A
 84%|████████▎ | 185/221 [00:50<00:09,  3.80it/s][A
 84%|████████▍ | 186/221 [00:50<00:12,  2.89it/s][A
 85%|████████▍ | 187/221 [00:51<00:10,  3.27it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.31it/s][A
 86%|████████▌ | 189/221 [00:51<00:09,  3.50it/s][A
 86%|████████▌ | 190/221 [00:51<00:09,  3.22it/s][A
 86%|████████▋ | 191/221 [00:52<00:08,  3.66it/s][A
 87%|████████▋ | 192/221 [00:52<00:07,  3.81it/s][A
 87%|████████▋ | 193/221 [00:52<00:06,  4.46it/s][A
 88%|████████▊ | 194/221 [00:52<00:07,  3.78it/s][A
 88%|████████▊ | 195/221 [00:53<00:06,  4.08it/s][A
 89%|████████▊ | 196/221 [00:53<00:07,  3.46it/s][A
 89%|████████▉ | 197/221 [00:53<00:06,  3.77it/s][A
 90%|████████▉ | 198/221 [00:54<00:07,  3.14it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.52it/s][A
 90%|█████████ | 200/221 [00:54<00:06,  3.08it/s][A
 91%|█████████ | 201/221 [00:54<00:05,  3.48it/s][A
 91%|█████████▏| 202/221 [00:55<00:05,  3.24it/s][A
 92%|█████████▏| 203/221 [00:55<00:04,  3.74it/s][A
 92%|█████████▏| 204/221 [00:55<00:04,  3.49it/s][A
 93%|█████████▎| 205/221 [00:55<00:03,  4.23it/s][A
 93%|█████████▎| 206/221 [00:56<00:04,  3.57it/s][A
 94%|█████████▎| 207/221 [00:56<00:03,  3.86it/s][A
 94%|█████████▍| 208/221 [00:56<00:03,  3.84it/s][A
 95%|█████████▍| 209/221 [00:56<00:02,  4.13it/s][A
 95%|█████████▌| 210/221 [00:57<00:02,  4.30it/s][A
 95%|█████████▌| 211/221 [00:57<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:57<00:02,  3.54it/s][A
 96%|█████████▋| 213/221 [00:58<00:02,  3.76it/s][A
 97%|█████████▋| 214/221 [00:58<00:02,  2.58it/s][A
 97%|█████████▋| 215/221 [00:58<00:02,  3.00it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.16it/s][A
 98%|█████████▊| 217/221 [00:59<00:01,  3.16it/s][A
 99%|█████████▊| 218/221 [00:59<00:00,  3.32it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.14it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.63it/s][A
100%|██████████| 221/221 [01:00<00:00,  4.05it/s][A100%|██████████| 221/221 [01:00<00:00,  3.65it/s]
09/09/2024 23:37:52 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 1199--===========

09/09/2024 23:37:52 - INFO - __main__ -   {'area_r1': 38.5, 'area_recall': '38.5/63.6/73.1', 'area_ravg': 58.4}
09/09/2024 23:37:52 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 1199--===========

09/09/2024 23:37:52 - INFO - __main__ -   {'forward_r1': 37.3, 'forward_recall': '37.3/65.7/77.3', 'forward_ravg': 60.1}
09/09/2024 23:37:52 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 1199--===========

09/09/2024 23:37:52 - INFO - __main__ -   {'area_video_r1': 38.9, 'area_video_recall': '38.9/67.0/77.3', 'area_video_ravg': 61.0}
09/09/2024 23:37:52 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/09/2024 23:37:52 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 23:37:52 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 1199--===========

09/09/2024 23:37:52 - INFO - __main__ -   {'area_video_r1': 52.7, 'area_video_recall': '52.7/74.9/82.2', 'area_video_ravg': 69.9, 'area_video_back_r1': 48.0, 'area_video_back_recall': '48.0/73.6/81.9', 'area_video_back_ravg': 67.8}
09/09/2024 23:37:52 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/09/2024 23:37:52 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/09/2024 23:37:52 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 1199--===========

09/09/2024 23:37:52 - INFO - __main__ -   {'video_r1': 44.0, 'video_recall': '44.0/71.4/82.4', 'video_ravg': 65.9}
09/09/2024 23:37:52 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 23:37:52 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 23:37:52 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 1199--===========

09/09/2024 23:37:52 - INFO - __main__ -   {'video_r1': 52.8, 'video_recall': '52.8/75.5/82.9', 'video_ravg': 70.4}
09/09/2024 23:37:52 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/09/2024 23:37:52 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
[h264 @ 0x559befb2ba80] mmco: unref short failure
09/09/2024 23:38:13 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.007529676891863346, 'loss_ret%tv%ta--finetune_area/loss_area': 1.0282833576202393, 'loss_ret%tv%ta--finetune_area/total_loss': 1.0358130931854248}
[h264 @ 0x55a03ed83880] mmco: unref short failure
[h264 @ 0x55a03ed83880] mmco: unref short failure
 62%|██████▏   | 1200/1945 [6:32:54<26:14:04, 126.77s/it][h264 @ 0x55a04624b700] mmco: unref short failure
 62%|██████▏   | 1201/1945 [6:32:58<18:35:34, 89.97s/it] [h264 @ 0x56241e84ab40] mmco: unref short failure
 62%|██████▏   | 1202/1945 [6:33:03<13:17:08, 64.37s/it][h264 @ 0x559bff33e0c0] mmco: unref short failure
[h264 @ 0x556b39c49740] mmco: unref short failure
[h264 @ 0x55a046e482c0] mmco: unref short failure
 62%|██████▏   | 1203/1945 [6:33:08<9:35:43, 46.55s/it] [h264 @ 0x56241a06f100] mmco: unref short failure
[h264 @ 0x56241a06f100] mmco: unref short failure
 62%|██████▏   | 1204/1945 [6:33:13<7:02:49, 34.24s/it][h264 @ 0x559beff31840] mmco: unref short failure
[h264 @ 0x559beff31840] mmco: unref short failure
 62%|██████▏   | 1205/1945 [6:33:20<5:19:41, 25.92s/it][h264 @ 0x55a0330b4640] mmco: unref short failure
[h264 @ 0x55a0330b4640] mmco: unref short failure
[h264 @ 0x556b410e4bc0] mmco: unref short failure
[h264 @ 0x556b410e4bc0] mmco: unref short failure
 62%|██████▏   | 1206/1945 [6:33:26<4:06:07, 19.98s/it][h264 @ 0x556b2db714c0] mmco: unref short failure
[h264 @ 0x556b2db714c0] mmco: unref short failure
[h264 @ 0x556b2db714c0] mmco: unref short failure
[h264 @ 0x556b2db714c0] mmco: unref short failure
 62%|██████▏   | 1207/1945 [6:33:33<3:17:47, 16.08s/it][h264 @ 0x556b4023da40] mmco: unref short failure
[h264 @ 0x559bfa358f40] mmco: unref short failure
[h264 @ 0x559bfa358f40] mmco: unref short failure
[h264 @ 0x559beaa56780] mmco: unref short failure
 62%|██████▏   | 1208/1945 [6:33:40<2:44:30, 13.39s/it][h264 @ 0x556b3ba76c00] mmco: unref short failure
[h264 @ 0x55a043642dc0] mmco: unref short failure
[h264 @ 0x55a043642dc0] mmco: unref short failure
[h264 @ 0x559bfa131c40] mmco: unref short failure
[h264 @ 0x559bf1f6e7c0] mmco: unref short failure
[h264 @ 0x559bf1f6e7c0] mmco: unref short failure
 62%|██████▏   | 1209/1945 [6:33:47<2:20:40, 11.47s/it][h264 @ 0x55a043ed40c0] mmco: unref short failure
[h264 @ 0x55a043ed40c0] mmco: unref short failure
[h264 @ 0x56241a7a4000] mmco: unref short failure
[h264 @ 0x56241a7a4000] mmco: unref short failure
 62%|██████▏   | 1210/1945 [6:33:55<2:06:04, 10.29s/it] 62%|██████▏   | 1211/1945 [6:34:02<1:54:37,  9.37s/it][h264 @ 0x56242979b6c0] mmco: unref short failure
[h264 @ 0x56242979b6c0] mmco: unref short failure
 62%|██████▏   | 1212/1945 [6:34:09<1:45:41,  8.65s/it][h264 @ 0x559bfd7f91c0] mmco: unref short failure
[h264 @ 0x559bfd7f91c0] mmco: unref short failure
 62%|██████▏   | 1213/1945 [6:34:17<1:42:53,  8.43s/it][h264 @ 0x559bec7b03c0] mmco: unref short failure
[h264 @ 0x559bec7b03c0] mmco: unref short failure
[h264 @ 0x556b2da2ebc0] mmco: unref short failure
 62%|██████▏   | 1214/1945 [6:34:23<1:35:25,  7.83s/it][h264 @ 0x559bf2090740] mmco: unref short failure
[h264 @ 0x562417062840] mmco: unref short failure
[h264 @ 0x562417062840] mmco: unref short failure
 62%|██████▏   | 1215/1945 [6:34:30<1:33:14,  7.66s/it][h264 @ 0x56242a93d0c0] mmco: unref short failure
[h264 @ 0x559bf147f340] mmco: unref short failure
 63%|██████▎   | 1216/1945 [6:34:38<1:32:07,  7.58s/it][h264 @ 0x556b2f33ac40] mmco: unref short failure
[h264 @ 0x556b2f33ac40] mmco: unref short failure
[h264 @ 0x55a033946200] mmco: unref short failure
[h264 @ 0x55a033946200] mmco: unref short failure
[h264 @ 0x559bf2fb8880] mmco: unref short failure
 63%|██████▎   | 1217/1945 [6:34:46<1:33:07,  7.67s/it][h264 @ 0x556b428d0980] mmco: unref short failure
[h264 @ 0x55a03a6f1780] mmco: unref short failure
[h264 @ 0x562427e12900] mmco: unref short failure
 63%|██████▎   | 1218/1945 [6:34:57<1:46:41,  8.80s/it][h264 @ 0x55a035a1f600] mmco: unref short failure
[h264 @ 0x55a041691b00] mmco: unref short failure
[h264 @ 0x55a041691b00] mmco: unref short failure
 63%|██████▎   | 1219/1945 [6:35:05<1:41:35,  8.40s/it][h264 @ 0x559bf7cea440] mmco: unref short failure
[h264 @ 0x556b2f929600] mmco: unref short failure
[h264 @ 0x556b2f929600] mmco: unref short failure
[h264 @ 0x55a033ef0840] mmco: unref short failure
[h264 @ 0x55a033ef0840] mmco: unref short failure
[h264 @ 0x559bff4329c0] mmco: unref short failure
[h264 @ 0x559bff4329c0] mmco: unref short failure
[h264 @ 0x55a046de4ac0] mmco: unref short failure
[h264 @ 0x5624221b18c0] mmco: unref short failure
[h264 @ 0x5624221b18c0] mmco: unref short failure
[h264 @ 0x556b3a1cc7c0] mmco: unref short failure
[h264 @ 0x56242586c940] mmco: unref short failure
[h264 @ 0x56242586c940] mmco: unref short failure
[h264 @ 0x56242586c940] mmco: unref short failure
[h264 @ 0x56242586c940] mmco: unref short failure
 63%|██████▎   | 1220/1945 [6:35:23<2:15:51, 11.24s/it][h264 @ 0x562422201fc0] mmco: unref short failure
[h264 @ 0x562422201fc0] mmco: unref short failure
[h264 @ 0x55a03d334480] mmco: unref short failure
[h264 @ 0x55a03d334480] mmco: unref short failure
[h264 @ 0x556b3cc9e200] mmco: unref short failure
 63%|██████▎   | 1221/1945 [6:35:30<2:01:04, 10.03s/it][h264 @ 0x556b3996e2c0] mmco: unref short failure
[h264 @ 0x556b3996e2c0] mmco: unref short failure
[h264 @ 0x556b3996e2c0] mmco: unref short failure
[h264 @ 0x5624262ab780] mmco: unref short failure
[h264 @ 0x5624262ab780] mmco: unref short failure
 63%|██████▎   | 1222/1945 [6:35:37<1:50:01,  9.13s/it][h264 @ 0x55a04286a140] mmco: unref short failure
[h264 @ 0x55a04286a140] mmco: unref short failure
 63%|██████▎   | 1223/1945 [6:35:52<2:10:52, 10.88s/it][h264 @ 0x556b38f2bc00] mmco: unref short failure
[h264 @ 0x55a03eb4fc40] mmco: unref short failure
[h264 @ 0x55a03eb4fc40] mmco: unref short failure
[h264 @ 0x55a03eb4fc40] mmco: unref short failure
[h264 @ 0x55a03eb4fc40] mmco: unref short failure
[h264 @ 0x55a03c78c380] mmco: unref short failure
[h264 @ 0x55a03c78c380] mmco: unref short failure
[h264 @ 0x55a0379f5740] mmco: unref short failure
[h264 @ 0x559bfd7f93c0] mmco: unref short failure
[h264 @ 0x559bfd7f93c0] mmco: unref short failure
[h264 @ 0x559bfd7f93c0] mmco: unref short failure
[h264 @ 0x559bfd7f93c0] mmco: unref short failure
[h264 @ 0x556b440a70c0] mmco: unref short failure
[h264 @ 0x556b440a70c0] mmco: unref short failure
[h264 @ 0x556b440a70c0] mmco: unref short failure
[h264 @ 0x556b440a70c0] mmco: unref short failure
[h264 @ 0x556b440a70c0] mmco: unref short failure
[h264 @ 0x556b440a70c0] mmco: unref short failure
[h264 @ 0x55a0459d3880] mmco: unref short failure
[h264 @ 0x55a0459d3880] mmco: unref short failure
[h264 @ 0x556b31792a00] mmco: unref short failure
[h264 @ 0x559bfb310500] mmco: unref short failure
[h264 @ 0x55a042a7b9c0] mmco: unref short failure
[h264 @ 0x55a0396f7840] mmco: unref short failure
[h264 @ 0x559bf8afd440] mmco: unref short failure
[h264 @ 0x559bf8afd440] mmco: unref short failure
[h264 @ 0x556b31792a00] mmco: unref short failure
[h264 @ 0x556b31792a00] mmco: unref short failure
 63%|██████▎   | 1224/1945 [6:36:40<4:24:26, 22.01s/it][h264 @ 0x559bea3bb7c0] mmco: unref short failure
[h264 @ 0x559bea3bb7c0] mmco: unref short failure
[h264 @ 0x56241fc72a00] mmco: unref short failure
[h264 @ 0x56241fc72a00] mmco: unref short failure
[h264 @ 0x55a04585ac00] mmco: unref short failure
[h264 @ 0x556b4499b680] mmco: unref short failure
[h264 @ 0x556b4499b680] mmco: unref short failure
 63%|██████▎   | 1225/1945 [6:36:57<4:05:25, 20.45s/it][h264 @ 0x556b45f55c40] mmco: unref short failure
[h264 @ 0x556b45f55c40] mmco: unref short failure
 63%|██████▎   | 1226/1945 [6:37:03<3:14:34, 16.24s/it][h264 @ 0x559bf0dc81c0] mmco: unref short failure
[h264 @ 0x559bf6af31c0] mmco: unref short failure
[h264 @ 0x559bf6af31c0] mmco: unref short failure
[h264 @ 0x55a03e314680] mmco: unref short failure
[h264 @ 0x55a03e314680] mmco: unref short failure
 63%|██████▎   | 1227/1945 [6:37:10<2:42:21, 13.57s/it][h264 @ 0x556b4223bb80] mmco: unref short failure
 63%|██████▎   | 1228/1945 [6:37:24<2:42:14, 13.58s/it] 63%|██████▎   | 1229/1945 [6:37:34<2:30:01, 12.57s/it][h264 @ 0x55a03c050b40] mmco: unref short failure
[h264 @ 0x55a03c050b40] mmco: unref short failure
 63%|██████▎   | 1230/1945 [6:37:42<2:12:01, 11.08s/it][h264 @ 0x56241fd4f080] mmco: unref short failure
[h264 @ 0x56241fd4f080] mmco: unref short failure
[h264 @ 0x56241c885c80] mmco: unref short failure
[h264 @ 0x562427665a80] mmco: unref short failure
[h264 @ 0x55a03303ac00] mmco: unref short failure
[h264 @ 0x55a03303ac00] mmco: unref short failure
 63%|██████▎   | 1231/1945 [6:37:49<1:58:27,  9.95s/it][h264 @ 0x562428973a80] mmco: unref short failure
[h264 @ 0x562428973a80] mmco: unref short failure
[h264 @ 0x562428973a80] mmco: unref short failure
[h264 @ 0x562428973a80] mmco: unref short failure
[h264 @ 0x559bff33e0c0] mmco: unref short failure
[h264 @ 0x556b2dc0d100] mmco: unref short failure
[h264 @ 0x56241df0a340] mmco: unref short failure
[h264 @ 0x56241df0a340] mmco: unref short failure
[h264 @ 0x562423674c00] mmco: unref short failure
[h264 @ 0x559bfb375dc0] mmco: unref short failure
[h264 @ 0x559bfb375dc0] mmco: unref short failure
[h264 @ 0x556b3732e240] mmco: unref short failure
[h264 @ 0x556b3732e240] mmco: unref short failure
[h264 @ 0x556b3732e240] mmco: unref short failure
[h264 @ 0x559bf0d17700] mmco: unref short failure
[h264 @ 0x55a043b70b00] mmco: unref short failure
[h264 @ 0x562421c27180] mmco: unref short failure
[h264 @ 0x556b3ffbc600] mmco: unref short failure
[h264 @ 0x55a03c42ae80] mmco: unref short failure
[h264 @ 0x55a03c42ae80] mmco: unref short failure
[h264 @ 0x5624265a0f80] mmco: unref short failure
[h264 @ 0x5624265a0f80] mmco: unref short failure
[h264 @ 0x562429436b80] mmco: unref short failure
[h264 @ 0x562429436b80] mmco: unref short failure
[h264 @ 0x56243369e000] mmco: unref short failure
[h264 @ 0x55a03673bf80] mmco: unref short failure
 63%|██████▎   | 1232/1945 [6:38:40<4:26:06, 22.39s/it][h264 @ 0x556b3e2b1200] mmco: unref short failure
[h264 @ 0x556b44d45600] mmco: unref short failure
[h264 @ 0x556b44d45600] mmco: unref short failure
[h264 @ 0x562424773c40] mmco: unref short failure
[h264 @ 0x556b3cb950c0] mmco: unref short failure
[h264 @ 0x556b43d6aa80] mmco: unref short failure
[h264 @ 0x556b43d6aa80] mmco: unref short failure
[h264 @ 0x559bf7577100] mmco: unref short failure
[h264 @ 0x56242760cd40] mmco: unref short failure
 63%|██████▎   | 1233/1945 [6:38:59<4:11:30, 21.20s/it][h264 @ 0x556b3b693600] mmco: unref short failure
[h264 @ 0x556b3b693600] mmco: unref short failure
[h264 @ 0x55a044b13f00] mmco: unref short failure
[h264 @ 0x55a044b13f00] mmco: unref short failure
 63%|██████▎   | 1234/1945 [6:39:07<3:26:06, 17.39s/it][h264 @ 0x55a035b5c9c0] mmco: unref short failure
[h264 @ 0x55a035b5c9c0] mmco: unref short failure
[h264 @ 0x556b2e92acc0] mmco: unref short failure
[h264 @ 0x556b2e92acc0] mmco: unref short failure
[h264 @ 0x556b36d62180] mmco: unref short failure
[h264 @ 0x556b36d62180] mmco: unref short failure
 63%|██████▎   | 1235/1945 [6:39:16<2:56:14, 14.89s/it][h264 @ 0x556b389dd080] mmco: unref short failure
[h264 @ 0x556b389dd080] mmco: unref short failure
[h264 @ 0x556b389dd080] mmco: unref short failure
[h264 @ 0x556b389dd080] mmco: unref short failure
[h264 @ 0x556b389dd080] mmco: unref short failure
[h264 @ 0x556b389dd080] mmco: unref short failure
[h264 @ 0x556b3469d640] mmco: unref short failure
[h264 @ 0x556b3469d640] mmco: unref short failure
[h264 @ 0x559bf7143640] mmco: unref short failure
[h264 @ 0x559bf7143640] mmco: unref short failure
[h264 @ 0x559bf7143640] mmco: unref short failure
[h264 @ 0x559bf7143640] mmco: unref short failure
[h264 @ 0x56242c35f8c0] mmco: unref short failure
[h264 @ 0x562423b34f40] mmco: unref short failure
[h264 @ 0x562423b34f40] mmco: unref short failure
[h264 @ 0x55a04bde8780] mmco: unref short failure
[h264 @ 0x556b32ee8bc0] mmco: unref short failure
[h264 @ 0x55a04bde8780] mmco: unref short failure
[h264 @ 0x55a04bde8780] mmco: unref short failure
[h264 @ 0x556b36d648c0] mmco: unref short failure
[h264 @ 0x556b36d648c0] mmco: unref short failure
[h264 @ 0x56241880f100] mmco: unref short failure
 64%|██████▎   | 1236/1945 [6:39:35<3:07:40, 15.88s/it][h264 @ 0x56241bce1680] mmco: unref short failure
 64%|██████▎   | 1237/1945 [6:39:42<2:36:47, 13.29s/it][h264 @ 0x562423ed6000] mmco: unref short failure
[h264 @ 0x562423ed6000] mmco: unref short failure
[h264 @ 0x559bed635540] mmco: unref short failure
[h264 @ 0x559bed635540] mmco: unref short failure
[h264 @ 0x559bed635540] mmco: unref short failure
 64%|██████▎   | 1238/1945 [6:39:48<2:12:20, 11.23s/it][h264 @ 0x559bf47cdcc0] mmco: unref short failure
 64%|██████▎   | 1239/1945 [6:39:58<2:07:44, 10.86s/it][h264 @ 0x556b36f785c0] mmco: unref short failure
[h264 @ 0x556b36f785c0] mmco: unref short failure
[h264 @ 0x55a0488b22c0] mmco: unref short failure
[h264 @ 0x55a0488b22c0] mmco: unref short failure
[h264 @ 0x559c00728240] mmco: unref short failure
[h264 @ 0x55a042704f40] mmco: unref short failure
[h264 @ 0x55a042704f40] mmco: unref short failure
[h264 @ 0x556b46baa440] mmco: unref short failure
[h264 @ 0x556b46baa440] mmco: unref short failure
[h264 @ 0x556b2d3b6400] mmco: unref short failure
[h264 @ 0x556b343098c0] mmco: unref short failure
[h264 @ 0x556b343098c0] mmco: unref short failure
[h264 @ 0x562417936540] mmco: unref short failure
[h264 @ 0x562417936540] mmco: unref short failure
[h264 @ 0x56241f23f7c0] mmco: unref short failure
[h264 @ 0x56241f23f7c0] mmco: unref short failure
[h264 @ 0x556b45b69240] mmco: unref short failure
[h264 @ 0x55a045b33880] mmco: unref short failure
[h264 @ 0x556b2e7efb40] mmco: unref short failure
[h264 @ 0x556b2e7efb40] mmco: unref short failure
[h264 @ 0x556b2e7efb40] mmco: unref short failure
[h264 @ 0x556b2e7efb40] mmco: unref short failure
[h264 @ 0x5624203bdb00] mmco: unref short failure
[h264 @ 0x5624203bdb00] mmco: unref short failure
 64%|██████▍   | 1240/1945 [6:40:48<4:25:12, 22.57s/it] 64%|██████▍   | 1241/1945 [6:40:56<3:32:10, 18.08s/it][h264 @ 0x556b39e3ddc0] mmco: unref short failure
 64%|██████▍   | 1242/1945 [6:41:08<3:11:03, 16.31s/it][h264 @ 0x56242a001140] mmco: unref short failure
[h264 @ 0x56242a001140] mmco: unref short failure
[h264 @ 0x556b42a0e7c0] mmco: unref short failure
[h264 @ 0x556b42a0e7c0] mmco: unref short failure
[h264 @ 0x556b42a0e7c0] mmco: unref short failure
[h264 @ 0x556b42a0e7c0] mmco: unref short failure
[h264 @ 0x559bf2733780] mmco: unref short failure
 64%|██████▍   | 1243/1945 [6:41:22<3:01:45, 15.54s/it][h264 @ 0x55a04053b180] mmco: unref short failure
[h264 @ 0x559c04e63c00] mmco: unref short failure
[h264 @ 0x559c04e63c00] mmco: unref short failure
[h264 @ 0x559bfa3b2600] mmco: unref short failure
[h264 @ 0x559bfa3b2600] mmco: unref short failure
[h264 @ 0x559bfa3b2600] mmco: unref short failure
[h264 @ 0x559bfa3b2600] mmco: unref short failure
[h264 @ 0x55a033162400] mmco: unref short failure
 64%|██████▍   | 1244/1945 [6:41:40<3:10:33, 16.31s/it][h264 @ 0x562429b0ef40] mmco: unref short failure
[h264 @ 0x562429b0ef40] mmco: unref short failure
 64%|██████▍   | 1245/1945 [6:41:48<2:42:57, 13.97s/it] 64%|██████▍   | 1246/1945 [6:41:55<2:18:27, 11.88s/it][h264 @ 0x559bf7091080] mmco: unref short failure
[h264 @ 0x559bf7091080] mmco: unref short failure
[h264 @ 0x56242d9feb00] mmco: unref short failure
[h264 @ 0x56242d9feb00] mmco: unref short failure
 64%|██████▍   | 1247/1945 [6:42:03<2:02:30, 10.53s/it][h264 @ 0x559bed48e500] mmco: unref short failure
[h264 @ 0x556b40fdae80] mmco: unref short failure
[h264 @ 0x559bfa27e240] mmco: unref short failure
[h264 @ 0x559bfa27e240] mmco: unref short failure
[h264 @ 0x559bfa27e240] mmco: unref short failure
[h264 @ 0x559bfa27e240] mmco: unref short failure
[h264 @ 0x556b44e0e780] mmco: unref short failure
[h264 @ 0x556b44e0e780] mmco: unref short failure
[h264 @ 0x55a03ce33e00] mmco: unref short failure
[h264 @ 0x55a03ce33e00] mmco: unref short failure
[h264 @ 0x559bf68271c0] mmco: unref short failure
[h264 @ 0x55a040e60100] mmco: unref short failure
[h264 @ 0x556b34e41140] mmco: unref short failure
[h264 @ 0x556b34e41140] mmco: unref short failure
 64%|██████▍   | 1248/1945 [6:42:49<4:06:21, 21.21s/it][h264 @ 0x56242c91f140] mmco: unref short failure
[h264 @ 0x562429be6380] mmco: unref short failure
[h264 @ 0x556b4071c980] mmco: unref short failure
[h264 @ 0x55a040949200] mmco: unref short failure
[h264 @ 0x55a040949200] mmco: unref short failure
[h264 @ 0x55a040949200] mmco: unref short failure
[h264 @ 0x55a040949200] mmco: unref short failure
[h264 @ 0x559bfbeb0140] mmco: unref short failure
[h264 @ 0x559bfbeb0140] mmco: unref short failure
 64%|██████▍   | 1249/1945 [6:43:00<3:29:30, 18.06s/it]09/09/2024 23:48:22 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/09/2024 23:48:22 - INFO - __main__ -   start running ret%tv validation...
[h264 @ 0x556b46df7f00] mmco: unref short failure
[h264 @ 0x556b46df7f00] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x56242b6ba8c0] mmco: unref short failure
[h264 @ 0x556b448d7f80] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x56241ca86a80] mmco: unref short failure
[h264 @ 0x56241ca86a80] mmco: unref short failure
[h264 @ 0x559bf6225b00] mmco: unref short failure
[h264 @ 0x559bf6225b00] mmco: unref short failure
[h264 @ 0x56242b547940] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x56241727b600] mmco: unref short failure
[h264 @ 0x56241727b600] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x562426768440] mmco: unref short failure
[h264 @ 0x562426768440] mmco: unref short failure
[h264 @ 0x559bff6f61c0] mmco: unref short failure
[h264 @ 0x556b36f4c7c0] mmco: unref short failure
[h264 @ 0x556b36f4c7c0] mmco: unref short failure
[h264 @ 0x562429be5ec0] mmco: unref short failure
[h264 @ 0x56242f208f40] mmco: unref short failure
[h264 @ 0x56242f208f40] mmco: unref short failure
[h264 @ 0x55a03563f580] mmco: unref short failure
[h264 @ 0x55a03563f580] mmco: unref short failure
[h264 @ 0x56241af0de40] mmco: unref short failure
[h264 @ 0x56241af0de40] mmco: unref short failure
[h264 @ 0x56241af21000] mmco: unref short failure
[h264 @ 0x56241af21000] mmco: unref short failure
[h264 @ 0x56241a04afc0] mmco: unref short failure
[h264 @ 0x55a045d2d140] mmco: unref short failure
[h264 @ 0x556b4303f840] mmco: unref short failure
[h264 @ 0x556b4303f840] mmco: unref short failure
[h264 @ 0x55a04de7df00] mmco: unref short failure
[h264 @ 0x55a04de7df00] mmco: unref short failure
[h264 @ 0x556b31c4b240] mmco: unref short failure
[h264 @ 0x556b31c4b240] mmco: unref short failure
[h264 @ 0x559bed5daac0] mmco: unref short failure
[h264 @ 0x562429d58640] mmco: unref short failure
[h264 @ 0x562429d58640] mmco: unref short failure
[h264 @ 0x559bf7f22800] mmco: unref short failure
[h264 @ 0x559bf7f22800] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:04,  1.77it/s][A[h264 @ 0x559bf3258600] mmco: unref short failure
[h264 @ 0x559bf3258600] mmco: unref short failure

  1%|          | 2/221 [00:01<02:04,  1.76it/s][A
  1%|▏         | 3/221 [00:01<01:19,  2.74it/s][A[h264 @ 0x556b37fb36c0] mmco: unref short failure
[h264 @ 0x556b37fb36c0] mmco: unref short failure

  2%|▏         | 4/221 [00:01<01:06,  3.25it/s][A
  2%|▏         | 5/221 [00:01<00:56,  3.84it/s][A
  3%|▎         | 6/221 [00:01<00:46,  4.61it/s][A
  3%|▎         | 7/221 [00:02<00:48,  4.42it/s][A
  4%|▎         | 8/221 [00:02<01:13,  2.91it/s][A
  4%|▍         | 9/221 [00:02<01:05,  3.24it/s][A
  5%|▍         | 10/221 [00:03<01:05,  3.21it/s][A
  5%|▍         | 11/221 [00:03<01:00,  3.48it/s][A
  5%|▌         | 12/221 [00:04<01:25,  2.46it/s][A
  6%|▌         | 13/221 [00:04<01:07,  3.10it/s][A[h264 @ 0x559bfe3a81c0] mmco: unref short failure
[h264 @ 0x559bfe3a81c0] mmco: unref short failure
[h264 @ 0x559c05b8f600] mmco: unref short failure
[h264 @ 0x559c05b8f600] mmco: unref short failure

  6%|▋         | 14/221 [00:06<03:38,  1.06s/it][A
  7%|▋         | 15/221 [00:07<02:51,  1.20it/s][A[h264 @ 0x56241c3ae900] mmco: unref short failure

  7%|▋         | 16/221 [00:07<02:22,  1.43it/s][A
  8%|▊         | 17/221 [00:07<01:53,  1.81it/s][A[h264 @ 0x559bf168f9c0] mmco: unref short failure
[h264 @ 0x559bf168f9c0] mmco: unref short failure

  8%|▊         | 18/221 [00:08<01:41,  2.00it/s][A
  9%|▊         | 19/221 [00:08<01:21,  2.47it/s][A
  9%|▉         | 20/221 [00:08<01:10,  2.87it/s][A
 10%|▉         | 21/221 [00:08<01:01,  3.24it/s][A
 10%|▉         | 22/221 [00:09<01:00,  3.28it/s][A
 10%|█         | 23/221 [00:09<00:55,  3.54it/s][A
 11%|█         | 24/221 [00:09<00:46,  4.25it/s][A
 11%|█▏        | 25/221 [00:09<00:41,  4.69it/s][A
 12%|█▏        | 26/221 [00:09<00:44,  4.34it/s][A
 12%|█▏        | 27/221 [00:10<00:41,  4.68it/s][A
 13%|█▎        | 28/221 [00:10<00:44,  4.36it/s][A
 13%|█▎        | 29/221 [00:10<00:38,  5.00it/s][A
 14%|█▎        | 30/221 [00:10<00:35,  5.40it/s][A
 14%|█▍        | 31/221 [00:10<00:40,  4.67it/s][A
 14%|█▍        | 32/221 [00:11<00:37,  5.01it/s][A
 15%|█▍        | 33/221 [00:11<00:52,  3.61it/s][A
 15%|█▌        | 34/221 [00:11<00:50,  3.68it/s][A
 16%|█▌        | 35/221 [00:12<00:58,  3.19it/s][A[h264 @ 0x559bf46a00c0] mmco: unref short failure
[h264 @ 0x559bf46a00c0] mmco: unref short failure

 16%|█▋        | 36/221 [00:12<01:01,  2.99it/s][A
 17%|█▋        | 37/221 [00:13<01:22,  2.23it/s][A
 17%|█▋        | 38/221 [00:13<01:15,  2.44it/s][A
 18%|█▊        | 39/221 [00:13<00:58,  3.12it/s][A
 18%|█▊        | 40/221 [00:14<00:58,  3.09it/s][A
 19%|█▊        | 41/221 [00:14<00:54,  3.27it/s][A
 19%|█▉        | 42/221 [00:14<00:59,  3.03it/s][A
 19%|█▉        | 43/221 [00:14<00:48,  3.65it/s][A
 20%|█▉        | 44/221 [00:15<00:40,  4.39it/s][A
 20%|██        | 45/221 [00:16<01:33,  1.89it/s][A
 21%|██        | 46/221 [00:16<01:29,  1.95it/s][A[h264 @ 0x559c01254e40] mmco: unref short failure
[h264 @ 0x559c01254e40] mmco: unref short failure

 21%|██▏       | 47/221 [00:17<02:02,  1.42it/s][A
 22%|██▏       | 49/221 [00:18<01:16,  2.23it/s][A
 23%|██▎       | 50/221 [00:18<01:06,  2.59it/s][A
 23%|██▎       | 51/221 [00:18<00:56,  3.00it/s][A
 24%|██▎       | 52/221 [00:18<00:49,  3.40it/s][A
 24%|██▍       | 53/221 [00:18<00:44,  3.81it/s][A
 24%|██▍       | 54/221 [00:19<01:09,  2.41it/s][A
 25%|██▍       | 55/221 [00:20<01:09,  2.40it/s][A
 25%|██▌       | 56/221 [00:20<00:59,  2.79it/s][A
 26%|██▌       | 57/221 [00:20<00:54,  2.99it/s][A
 26%|██▌       | 58/221 [00:20<00:52,  3.12it/s][A
 27%|██▋       | 59/221 [00:21<00:43,  3.70it/s][A[h264 @ 0x556b34d700c0] mmco: unref short failure
[h264 @ 0x556b34d700c0] mmco: unref short failure

 27%|██▋       | 60/221 [00:21<00:46,  3.45it/s][A
 28%|██▊       | 61/221 [00:21<00:41,  3.88it/s][A
 28%|██▊       | 62/221 [00:21<00:36,  4.32it/s][A
 29%|██▊       | 63/221 [00:21<00:31,  5.05it/s][A
 29%|██▉       | 64/221 [00:22<00:27,  5.64it/s][A
 29%|██▉       | 65/221 [00:22<00:27,  5.59it/s][A
 30%|██▉       | 66/221 [00:22<00:37,  4.15it/s][A
 30%|███       | 67/221 [00:22<00:34,  4.40it/s][A
 31%|███       | 68/221 [00:22<00:30,  5.07it/s][A
 31%|███       | 69/221 [00:23<00:42,  3.58it/s][A[h264 @ 0x55a0355b5080] mmco: unref short failure
[h264 @ 0x55a0355b5080] mmco: unref short failure

 32%|███▏      | 70/221 [00:23<00:38,  3.97it/s][A
 32%|███▏      | 71/221 [00:24<01:27,  1.72it/s][A
 33%|███▎      | 72/221 [00:25<01:11,  2.10it/s][A
 33%|███▎      | 73/221 [00:25<01:02,  2.35it/s][A
 33%|███▎      | 74/221 [00:25<00:53,  2.76it/s][A
 34%|███▍      | 75/221 [00:26<00:55,  2.63it/s][A
 34%|███▍      | 76/221 [00:26<00:45,  3.19it/s][A
 35%|███▍      | 77/221 [00:26<00:39,  3.62it/s][A
 35%|███▌      | 78/221 [00:26<00:42,  3.37it/s][A
 36%|███▌      | 79/221 [00:27<00:56,  2.53it/s][A
 36%|███▌      | 80/221 [00:27<00:45,  3.13it/s][A[h264 @ 0x556b3c356300] mmco: unref short failure

 37%|███▋      | 81/221 [00:27<00:39,  3.57it/s][A
 37%|███▋      | 82/221 [00:28<00:43,  3.21it/s][A
 38%|███▊      | 83/221 [00:28<00:40,  3.43it/s][A
 38%|███▊      | 84/221 [00:28<00:34,  3.94it/s][A
 38%|███▊      | 85/221 [00:28<00:28,  4.71it/s][A
 39%|███▉      | 86/221 [00:28<00:25,  5.25it/s][A
 39%|███▉      | 87/221 [00:29<00:35,  3.78it/s][A
 40%|███▉      | 88/221 [00:29<00:38,  3.49it/s][A
 40%|████      | 89/221 [00:31<01:46,  1.24it/s][A
 41%|████      | 90/221 [00:31<01:27,  1.49it/s][A
 41%|████      | 91/221 [00:32<01:05,  2.00it/s][A[h264 @ 0x556b40fdb300] mmco: unref short failure
[h264 @ 0x556b40fdb300] mmco: unref short failure

 42%|████▏     | 92/221 [00:32<00:52,  2.46it/s][A
 42%|████▏     | 93/221 [00:32<00:50,  2.53it/s][A[h264 @ 0x55a04de7d640] mmco: unref short failure
[h264 @ 0x562425134d00] mmco: unref short failure
[h264 @ 0x562425134d00] mmco: unref short failure

 43%|████▎     | 94/221 [00:32<00:43,  2.93it/s][A
 43%|████▎     | 95/221 [00:33<00:38,  3.26it/s][A
 43%|████▎     | 96/221 [00:33<00:37,  3.32it/s][A
 44%|████▍     | 97/221 [00:33<00:30,  4.07it/s][A
 44%|████▍     | 98/221 [00:33<00:27,  4.41it/s][A
 45%|████▍     | 99/221 [00:33<00:27,  4.47it/s][A
 45%|████▌     | 100/221 [00:34<00:26,  4.60it/s][A
 46%|████▌     | 101/221 [00:34<00:22,  5.45it/s][A
 46%|████▌     | 102/221 [00:34<00:24,  4.84it/s][A[h264 @ 0x556b2cc38a80] mmco: unref short failure
[h264 @ 0x556b2cc38a80] mmco: unref short failure
[h264 @ 0x556b2cc38a80] mmco: unref short failure
[h264 @ 0x556b2cc38a80] mmco: unref short failure

 47%|████▋     | 104/221 [00:34<00:17,  6.60it/s][A
 48%|████▊     | 105/221 [00:34<00:22,  5.11it/s][A[h264 @ 0x559bff85d380] mmco: unref short failure
[h264 @ 0x559bff85d380] mmco: unref short failure
[h264 @ 0x559bff85d380] mmco: unref short failure
[h264 @ 0x559bff85d380] mmco: unref short failure
[h264 @ 0x559bff85d380] mmco: unref short failure
[h264 @ 0x559bff85d380] mmco: unref short failure

 48%|████▊     | 106/221 [00:35<00:48,  2.38it/s][A
 48%|████▊     | 107/221 [00:36<00:38,  2.95it/s][A
 49%|████▉     | 108/221 [00:36<00:33,  3.37it/s][A
 49%|████▉     | 109/221 [00:36<00:32,  3.47it/s][A
 50%|████▉     | 110/221 [00:36<00:32,  3.45it/s][A
 50%|█████     | 111/221 [00:37<00:36,  3.01it/s][A
 51%|█████     | 112/221 [00:37<00:30,  3.56it/s][A[h264 @ 0x556b421f6340] mmco: unref short failure
[h264 @ 0x556b421f6340] mmco: unref short failure
[h264 @ 0x556b421f6340] mmco: unref short failure
[h264 @ 0x556b421f6340] mmco: unref short failure

 51%|█████     | 113/221 [00:37<00:35,  3.05it/s][A[h264 @ 0x556b343a96c0] mmco: unref short failure
[h264 @ 0x556b343a96c0] mmco: unref short failure

 52%|█████▏    | 115/221 [00:38<00:23,  4.59it/s][A[h264 @ 0x55a04e2b46c0] mmco: unref short failure
[h264 @ 0x55a04e2b46c0] mmco: unref short failure

 52%|█████▏    | 116/221 [00:42<02:06,  1.21s/it][A
 53%|█████▎    | 117/221 [00:42<01:39,  1.04it/s][A
 53%|█████▎    | 118/221 [00:42<01:22,  1.25it/s][A
 54%|█████▍    | 119/221 [00:43<01:04,  1.57it/s][A[h264 @ 0x556b3be65000] mmco: unref short failure

 54%|█████▍    | 120/221 [00:43<00:55,  1.81it/s][A
 55%|█████▌    | 122/221 [00:43<00:36,  2.75it/s][A
 56%|█████▌    | 123/221 [00:43<00:30,  3.16it/s][A
 56%|█████▌    | 124/221 [00:44<00:27,  3.54it/s][A
 57%|█████▋    | 125/221 [00:44<00:25,  3.83it/s][A
 57%|█████▋    | 126/221 [00:44<00:26,  3.60it/s][A
 57%|█████▋    | 127/221 [00:44<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:45<00:28,  3.24it/s][A
 58%|█████▊    | 129/221 [00:45<00:24,  3.73it/s][A
 59%|█████▉    | 130/221 [00:45<00:22,  4.08it/s][A[h264 @ 0x55a0478e1080] mmco: unref short failure
[h264 @ 0x55a0478e1080] mmco: unref short failure

 60%|█████▉    | 132/221 [00:45<00:16,  5.40it/s][A
 60%|██████    | 133/221 [00:46<00:20,  4.19it/s][A
 61%|██████    | 134/221 [00:46<00:19,  4.39it/s][A
 61%|██████    | 135/221 [00:46<00:21,  3.94it/s][A
 62%|██████▏   | 136/221 [00:47<00:25,  3.27it/s][A
 62%|██████▏   | 137/221 [00:47<00:24,  3.47it/s][A
 62%|██████▏   | 138/221 [00:47<00:26,  3.13it/s][A
 63%|██████▎   | 139/221 [00:48<00:25,  3.25it/s][A
 63%|██████▎   | 140/221 [00:48<00:25,  3.23it/s][A
 64%|██████▍   | 141/221 [00:48<00:21,  3.66it/s][A
 64%|██████▍   | 142/221 [00:49<00:32,  2.41it/s][A
 65%|██████▍   | 143/221 [00:49<00:29,  2.67it/s][A
 66%|██████▌   | 145/221 [00:49<00:17,  4.27it/s][A
 66%|██████▌   | 146/221 [00:49<00:15,  4.91it/s][A
 67%|██████▋   | 148/221 [00:50<00:13,  5.39it/s][A
 68%|██████▊   | 150/221 [00:50<00:11,  6.08it/s][A
 68%|██████▊   | 151/221 [00:51<00:17,  3.92it/s][A
 69%|██████▉   | 152/221 [00:51<00:15,  4.40it/s][A
 69%|██████▉   | 153/221 [00:51<00:19,  3.58it/s][A
 70%|██████▉   | 154/221 [00:52<00:23,  2.85it/s][A
 70%|███████   | 155/221 [00:52<00:18,  3.49it/s][A
 71%|███████   | 156/221 [00:52<00:16,  4.01it/s][A[h264 @ 0x556b44bf7ac0] mmco: unref short failure
[h264 @ 0x556b44bf7ac0] mmco: unref short failure
[h264 @ 0x55a049773d00] mmco: unref short failure
[h264 @ 0x55a049773d00] mmco: unref short failure

 71%|███████   | 157/221 [00:56<01:19,  1.25s/it][A
 71%|███████▏  | 158/221 [00:56<00:57,  1.09it/s][A
 72%|███████▏  | 159/221 [00:56<00:43,  1.42it/s][A
 72%|███████▏  | 160/221 [00:56<00:32,  1.86it/s][A
 73%|███████▎  | 162/221 [00:56<00:19,  3.07it/s][A
 74%|███████▍  | 163/221 [00:57<00:17,  3.26it/s][A
 74%|███████▍  | 164/221 [00:57<00:14,  3.85it/s][A
 75%|███████▍  | 165/221 [00:57<00:12,  4.62it/s][A
 75%|███████▌  | 166/221 [00:57<00:14,  3.82it/s][A
 76%|███████▌  | 167/221 [00:57<00:13,  4.04it/s][A
 76%|███████▌  | 168/221 [01:01<01:11,  1.34s/it][A
 76%|███████▋  | 169/221 [01:02<00:51,  1.00it/s][A
 77%|███████▋  | 170/221 [01:02<00:39,  1.29it/s][A
 77%|███████▋  | 171/221 [01:02<00:29,  1.71it/s][A[h264 @ 0x556b3b223d00] mmco: unref short failure
[h264 @ 0x556b3b223d00] mmco: unref short failure

 78%|███████▊  | 172/221 [01:02<00:23,  2.11it/s][A
 79%|███████▊  | 174/221 [01:02<00:13,  3.49it/s][A
 79%|███████▉  | 175/221 [01:03<00:13,  3.49it/s][A
 80%|███████▉  | 176/221 [01:03<00:12,  3.71it/s][A
 81%|████████  | 178/221 [01:03<00:10,  3.94it/s][A
 81%|████████  | 179/221 [01:04<00:19,  2.15it/s][A
 82%|████████▏ | 181/221 [01:05<00:13,  2.97it/s][A
 82%|████████▏ | 182/221 [01:05<00:11,  3.34it/s][A
 83%|████████▎ | 183/221 [01:05<00:10,  3.73it/s][A
 83%|████████▎ | 184/221 [01:05<00:10,  3.64it/s][A
 84%|████████▍ | 186/221 [01:06<00:08,  4.22it/s][A
 85%|████████▍ | 187/221 [01:06<00:07,  4.74it/s][A
 85%|████████▌ | 188/221 [01:06<00:08,  3.92it/s][A
 86%|████████▌ | 189/221 [01:07<00:08,  3.87it/s][A
 86%|████████▌ | 190/221 [01:07<00:07,  4.22it/s][A
 87%|████████▋ | 192/221 [01:07<00:05,  4.89it/s][A
 88%|████████▊ | 194/221 [01:08<00:06,  4.31it/s][A
 88%|████████▊ | 195/221 [01:08<00:05,  4.87it/s][A
 89%|████████▉ | 197/221 [01:08<00:03,  6.36it/s][A
 90%|████████▉ | 198/221 [01:08<00:03,  5.95it/s][A
 90%|█████████ | 199/221 [01:08<00:03,  6.53it/s][A
 90%|█████████ | 200/221 [01:08<00:03,  5.25it/s][A
 91%|█████████ | 201/221 [01:09<00:03,  5.08it/s][A
 91%|█████████▏| 202/221 [01:09<00:03,  5.28it/s][A
 92%|█████████▏| 204/221 [01:09<00:02,  7.10it/s][A
 93%|█████████▎| 206/221 [01:10<00:03,  4.79it/s][A
 94%|█████████▍| 208/221 [01:10<00:02,  6.21it/s][A
 95%|█████████▌| 211/221 [01:10<00:01,  6.66it/s][A
 96%|█████████▋| 213/221 [01:10<00:01,  7.53it/s][A
 97%|█████████▋| 214/221 [01:11<00:01,  5.48it/s][A
 97%|█████████▋| 215/221 [01:11<00:01,  5.62it/s][A
 98%|█████████▊| 216/221 [01:11<00:00,  5.69it/s][A[h264 @ 0x556b2e79be40] mmco: unref short failure
[h264 @ 0x556b2e79be40] mmco: unref short failure

 98%|█████████▊| 217/221 [01:12<00:01,  3.07it/s][A
 99%|█████████▊| 218/221 [01:12<00:00,  3.49it/s][A
 99%|█████████▉| 219/221 [01:12<00:00,  3.71it/s][A
100%|█████████▉| 220/221 [01:17<00:01,  1.36s/it][A
100%|██████████| 221/221 [01:17<00:00,  1.01s/it][A100%|██████████| 221/221 [01:17<00:00,  2.86it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:51,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:51,  3.52it/s][A
 19%|█▊        | 41/221 [00:10<00:50,  3.60it/s][A
 19%|█▉        | 42/221 [00:11<00:49,  3.65it/s][A
 19%|█▉        | 43/221 [00:11<00:48,  3.69it/s][A
 20%|█▉        | 44/221 [00:11<00:47,  3.72it/s][A
 20%|██        | 45/221 [00:11<00:47,  3.74it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.76it/s][A
 21%|██▏       | 47/221 [00:12<00:46,  3.77it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.77it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.78it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.78it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:14<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:18<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:23<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:28<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:23,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:42<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:47<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:52<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:57<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:32,  6.74it/s][A
  1%|          | 2/221 [00:00<00:46,  4.74it/s][A
  1%|▏         | 3/221 [00:00<00:49,  4.40it/s][A
  2%|▏         | 4/221 [00:00<00:43,  5.01it/s][A
  2%|▏         | 5/221 [00:01<00:44,  4.83it/s][A
  3%|▎         | 7/221 [00:01<00:40,  5.33it/s][A
  4%|▎         | 8/221 [00:01<00:46,  4.58it/s][A
  4%|▍         | 9/221 [00:01<00:48,  4.40it/s][A
  5%|▍         | 10/221 [00:02<01:10,  3.00it/s][A
  5%|▍         | 11/221 [00:02<01:00,  3.49it/s][A
  5%|▌         | 12/221 [00:02<00:50,  4.12it/s][A
  6%|▌         | 13/221 [00:03<01:28,  2.35it/s][A
  6%|▋         | 14/221 [00:03<01:09,  2.98it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.33it/s][A
  7%|▋         | 16/221 [00:04<01:07,  3.05it/s][A
  8%|▊         | 17/221 [00:05<01:26,  2.37it/s][A
  8%|▊         | 18/221 [00:05<01:13,  2.75it/s][A
  9%|▊         | 19/221 [00:05<01:02,  3.25it/s][A
 10%|▉         | 21/221 [00:05<00:45,  4.42it/s][A
 10%|▉         | 22/221 [00:05<00:42,  4.66it/s][A
 11%|█         | 24/221 [00:06<00:35,  5.57it/s][A
 11%|█▏        | 25/221 [00:06<00:36,  5.44it/s][A
 12%|█▏        | 26/221 [00:06<00:37,  5.19it/s][A
 12%|█▏        | 27/221 [00:06<00:33,  5.84it/s][A
 13%|█▎        | 28/221 [00:07<00:43,  4.42it/s][A
 13%|█▎        | 29/221 [00:07<00:43,  4.42it/s][A
 14%|█▎        | 30/221 [00:07<00:46,  4.12it/s][A
 14%|█▍        | 31/221 [00:07<00:44,  4.30it/s][A
 14%|█▍        | 32/221 [00:07<00:39,  4.77it/s][A
 15%|█▍        | 33/221 [00:08<00:39,  4.81it/s][A
 15%|█▌        | 34/221 [00:08<00:40,  4.66it/s][A
 16%|█▌        | 35/221 [00:08<00:44,  4.22it/s][A
 16%|█▋        | 36/221 [00:08<00:48,  3.84it/s][A
 17%|█▋        | 37/221 [00:09<00:42,  4.35it/s][A
 17%|█▋        | 38/221 [00:09<00:44,  4.07it/s][A
 18%|█▊        | 39/221 [00:09<00:41,  4.39it/s][A
 18%|█▊        | 40/221 [00:09<00:49,  3.66it/s][A
 19%|█▊        | 41/221 [00:10<00:43,  4.10it/s][A
 19%|█▉        | 42/221 [00:10<00:37,  4.80it/s][A
 19%|█▉        | 43/221 [00:10<00:42,  4.15it/s][A
 20%|█▉        | 44/221 [00:10<00:44,  3.97it/s][A
 20%|██        | 45/221 [00:11<00:47,  3.72it/s][A
 21%|██        | 46/221 [00:11<00:43,  3.99it/s][A
 21%|██▏       | 47/221 [00:11<00:42,  4.05it/s][A
 22%|██▏       | 48/221 [00:11<00:36,  4.69it/s][A
 22%|██▏       | 49/221 [00:12<00:38,  4.45it/s][A
 23%|██▎       | 50/221 [00:12<00:51,  3.29it/s][A
 23%|██▎       | 51/221 [00:12<00:44,  3.81it/s][A
 24%|██▎       | 52/221 [00:12<00:45,  3.69it/s][A
 24%|██▍       | 53/221 [00:13<00:39,  4.22it/s][A
 24%|██▍       | 54/221 [00:13<00:49,  3.37it/s][A
 25%|██▍       | 55/221 [00:13<00:46,  3.58it/s][A
 25%|██▌       | 56/221 [00:13<00:40,  4.03it/s][A
 26%|██▌       | 57/221 [00:14<00:42,  3.86it/s][A
 26%|██▌       | 58/221 [00:14<00:49,  3.30it/s][A
 27%|██▋       | 59/221 [00:14<00:44,  3.66it/s][A
 27%|██▋       | 60/221 [00:15<00:37,  4.35it/s][A
 28%|██▊       | 61/221 [00:15<00:35,  4.53it/s][A
 28%|██▊       | 62/221 [00:15<00:36,  4.33it/s][A
 29%|██▊       | 63/221 [00:15<00:34,  4.60it/s][A
 29%|██▉       | 64/221 [00:16<00:43,  3.61it/s][A
 29%|██▉       | 65/221 [00:16<00:38,  4.06it/s][A
 30%|██▉       | 66/221 [00:16<00:49,  3.11it/s][A
 30%|███       | 67/221 [00:17<00:51,  3.01it/s][A
 31%|███       | 68/221 [00:17<00:43,  3.54it/s][A
 31%|███       | 69/221 [00:17<01:03,  2.38it/s][A
 32%|███▏      | 70/221 [00:18<00:51,  2.93it/s][A
 32%|███▏      | 71/221 [00:18<00:43,  3.42it/s][A
 33%|███▎      | 72/221 [00:18<00:49,  3.01it/s][A
 33%|███▎      | 73/221 [00:19<00:48,  3.02it/s][A
 33%|███▎      | 74/221 [00:19<00:42,  3.42it/s][A
 34%|███▍      | 75/221 [00:19<00:41,  3.56it/s][A
 34%|███▍      | 76/221 [00:19<00:37,  3.83it/s][A
 35%|███▍      | 77/221 [00:20<00:39,  3.61it/s][A
 35%|███▌      | 78/221 [00:20<00:35,  3.99it/s][A
 36%|███▌      | 79/221 [00:20<00:42,  3.30it/s][A
 36%|███▌      | 80/221 [00:20<00:40,  3.48it/s][A
 37%|███▋      | 81/221 [00:21<00:37,  3.74it/s][A
 37%|███▋      | 82/221 [00:21<00:42,  3.30it/s][A
 38%|███▊      | 83/221 [00:21<00:43,  3.16it/s][A
 38%|███▊      | 84/221 [00:22<00:42,  3.24it/s][A
 38%|███▊      | 85/221 [00:22<00:33,  4.01it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.85it/s][A
 39%|███▉      | 87/221 [00:23<00:42,  3.13it/s][A
 40%|███▉      | 88/221 [00:23<00:49,  2.68it/s][A
 40%|████      | 89/221 [00:23<00:45,  2.88it/s][A
 41%|████      | 90/221 [00:24<00:48,  2.71it/s][A
 41%|████      | 91/221 [00:24<00:39,  3.28it/s][A
 42%|████▏     | 92/221 [00:24<00:43,  2.94it/s][A
 42%|████▏     | 93/221 [00:25<00:57,  2.24it/s][A
 43%|████▎     | 94/221 [00:25<00:50,  2.53it/s][A
 43%|████▎     | 95/221 [00:26<00:44,  2.84it/s][A
 43%|████▎     | 96/221 [00:26<00:39,  3.20it/s][A
 44%|████▍     | 97/221 [00:26<00:34,  3.55it/s][A
 44%|████▍     | 98/221 [00:26<00:33,  3.68it/s][A
 45%|████▍     | 99/221 [00:26<00:30,  3.97it/s][A
 45%|████▌     | 100/221 [00:27<00:32,  3.75it/s][A
 46%|████▌     | 101/221 [00:27<00:30,  3.93it/s][A
 46%|████▌     | 102/221 [00:28<00:43,  2.72it/s][A
 47%|████▋     | 103/221 [00:28<00:34,  3.41it/s][A
 47%|████▋     | 104/221 [00:28<00:30,  3.86it/s][A
 48%|████▊     | 105/221 [00:28<00:30,  3.75it/s][A
 48%|████▊     | 106/221 [00:29<00:36,  3.15it/s][A
 48%|████▊     | 107/221 [00:29<00:32,  3.49it/s][A
 49%|████▉     | 108/221 [00:29<00:32,  3.49it/s][A
 49%|████▉     | 109/221 [00:29<00:25,  4.32it/s][A
 50%|████▉     | 110/221 [00:29<00:25,  4.31it/s][A
 50%|█████     | 111/221 [00:30<00:28,  3.92it/s][A
 51%|█████     | 112/221 [00:30<00:26,  4.06it/s][A
 51%|█████     | 113/221 [00:30<00:25,  4.29it/s][A
 52%|█████▏    | 114/221 [00:30<00:20,  5.13it/s][A
 52%|█████▏    | 115/221 [00:31<00:21,  4.87it/s][A
 52%|█████▏    | 116/221 [00:31<00:23,  4.54it/s][A
 53%|█████▎    | 117/221 [00:31<00:23,  4.34it/s][A
 53%|█████▎    | 118/221 [00:31<00:22,  4.53it/s][A
 54%|█████▍    | 119/221 [00:32<00:28,  3.58it/s][A
 54%|█████▍    | 120/221 [00:32<00:25,  4.03it/s][A
 55%|█████▍    | 121/221 [00:32<00:20,  4.90it/s][A
 55%|█████▌    | 122/221 [00:32<00:22,  4.37it/s][A
 56%|█████▌    | 123/221 [00:33<00:24,  3.96it/s][A
 56%|█████▌    | 124/221 [00:33<00:23,  4.06it/s][A
 57%|█████▋    | 125/221 [00:33<00:26,  3.65it/s][A
 57%|█████▋    | 126/221 [00:33<00:24,  3.94it/s][A
 57%|█████▋    | 127/221 [00:34<00:29,  3.24it/s][A
 58%|█████▊    | 128/221 [00:34<00:27,  3.34it/s][A
 58%|█████▊    | 129/221 [00:34<00:22,  4.04it/s][A
 59%|█████▉    | 130/221 [00:34<00:23,  3.86it/s][A
 59%|█████▉    | 131/221 [00:35<00:19,  4.58it/s][A
 60%|█████▉    | 132/221 [00:35<00:22,  3.99it/s][A
 60%|██████    | 133/221 [00:35<00:24,  3.61it/s][A
 61%|██████    | 134/221 [00:36<00:29,  2.95it/s][A
 61%|██████    | 135/221 [00:36<00:29,  2.89it/s][A
 62%|██████▏   | 136/221 [00:36<00:26,  3.22it/s][A
 62%|██████▏   | 137/221 [00:36<00:21,  3.88it/s][A
 62%|██████▏   | 138/221 [00:37<00:22,  3.66it/s][A
 63%|██████▎   | 139/221 [00:37<00:26,  3.13it/s][A
 63%|██████▎   | 140/221 [00:37<00:25,  3.20it/s][A
 64%|██████▍   | 141/221 [00:38<00:22,  3.55it/s][A
 64%|██████▍   | 142/221 [00:38<00:20,  3.80it/s][A
 65%|██████▍   | 143/221 [00:38<00:26,  2.98it/s][A
 65%|██████▌   | 144/221 [00:39<00:26,  2.91it/s][A
 66%|██████▌   | 145/221 [00:39<00:20,  3.62it/s][A
 67%|██████▋   | 147/221 [00:39<00:17,  4.31it/s][A
 67%|██████▋   | 148/221 [00:40<00:21,  3.46it/s][A
 67%|██████▋   | 149/221 [00:40<00:20,  3.56it/s][A
 68%|██████▊   | 150/221 [00:40<00:18,  3.74it/s][A
 68%|██████▊   | 151/221 [00:41<00:21,  3.31it/s][A
 69%|██████▉   | 152/221 [00:41<00:28,  2.46it/s][A
 69%|██████▉   | 153/221 [00:41<00:22,  2.99it/s][A
 70%|██████▉   | 154/221 [00:42<00:19,  3.37it/s][A
 70%|███████   | 155/221 [00:42<00:17,  3.78it/s][A
 71%|███████   | 156/221 [00:42<00:20,  3.19it/s][A
 71%|███████   | 157/221 [00:43<00:20,  3.19it/s][A
 71%|███████▏  | 158/221 [00:43<00:18,  3.36it/s][A
 72%|███████▏  | 159/221 [00:43<00:15,  4.06it/s][A
 72%|███████▏  | 160/221 [00:43<00:14,  4.29it/s][A
 73%|███████▎  | 161/221 [00:44<00:17,  3.46it/s][A
 73%|███████▎  | 162/221 [00:44<00:15,  3.90it/s][A
 74%|███████▍  | 163/221 [00:44<00:14,  3.98it/s][A
 74%|███████▍  | 164/221 [00:44<00:12,  4.50it/s][A
 75%|███████▍  | 165/221 [00:44<00:12,  4.54it/s][A
 75%|███████▌  | 166/221 [00:45<00:12,  4.48it/s][A
 76%|███████▌  | 168/221 [00:45<00:11,  4.79it/s][A
 76%|███████▋  | 169/221 [00:45<00:09,  5.37it/s][A
 77%|███████▋  | 170/221 [00:46<00:13,  3.67it/s][A
 77%|███████▋  | 171/221 [00:46<00:12,  4.00it/s][A
 78%|███████▊  | 172/221 [00:46<00:11,  4.14it/s][A
 78%|███████▊  | 173/221 [00:46<00:12,  3.84it/s][A
 79%|███████▊  | 174/221 [00:47<00:15,  3.06it/s][A
 79%|███████▉  | 175/221 [00:47<00:15,  2.89it/s][A
 80%|███████▉  | 176/221 [00:47<00:14,  3.11it/s][A
 80%|████████  | 177/221 [00:48<00:13,  3.28it/s][A
 81%|████████  | 178/221 [00:48<00:13,  3.29it/s][A
 81%|████████  | 179/221 [00:48<00:12,  3.46it/s][A
 81%|████████▏ | 180/221 [00:48<00:10,  4.01it/s][A
 82%|████████▏ | 181/221 [00:49<00:10,  3.98it/s][A
 82%|████████▏ | 182/221 [00:49<00:11,  3.50it/s][A
 83%|████████▎ | 183/221 [00:49<00:11,  3.31it/s][A
 83%|████████▎ | 184/221 [00:50<00:10,  3.46it/s][A
 84%|████████▎ | 185/221 [00:50<00:09,  3.94it/s][A
 84%|████████▍ | 186/221 [00:50<00:12,  2.91it/s][A
 85%|████████▍ | 187/221 [00:51<00:10,  3.33it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.35it/s][A
 86%|████████▌ | 189/221 [00:51<00:08,  3.56it/s][A
 86%|████████▌ | 190/221 [00:51<00:09,  3.29it/s][A
 86%|████████▋ | 191/221 [00:52<00:07,  3.82it/s][A
 87%|████████▋ | 192/221 [00:52<00:07,  3.87it/s][A
 87%|████████▋ | 193/221 [00:52<00:06,  4.43it/s][A
 88%|████████▊ | 194/221 [00:52<00:06,  3.95it/s][A
 88%|████████▊ | 195/221 [00:53<00:06,  4.22it/s][A
 89%|████████▊ | 196/221 [00:53<00:07,  3.48it/s][A
 89%|████████▉ | 197/221 [00:53<00:06,  3.71it/s][A
 90%|████████▉ | 198/221 [00:54<00:07,  3.10it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.49it/s][A
 90%|█████████ | 200/221 [00:54<00:06,  3.08it/s][A
 91%|█████████ | 201/221 [00:54<00:05,  3.53it/s][A
 91%|█████████▏| 202/221 [00:55<00:05,  3.21it/s][A
 92%|█████████▏| 203/221 [00:55<00:04,  3.70it/s][A
 92%|█████████▏| 204/221 [00:55<00:04,  3.45it/s][A
 93%|█████████▎| 205/221 [00:55<00:03,  4.19it/s][A
 93%|█████████▎| 206/221 [00:56<00:04,  3.53it/s][A
 94%|█████████▎| 207/221 [00:56<00:03,  3.53it/s][A
 94%|█████████▍| 208/221 [00:56<00:03,  3.71it/s][A
 95%|█████████▍| 209/221 [00:57<00:02,  4.00it/s][A
 95%|█████████▌| 210/221 [00:57<00:02,  4.27it/s][A
 95%|█████████▌| 211/221 [00:57<00:02,  3.77it/s][A
 96%|█████████▌| 212/221 [00:57<00:02,  3.65it/s][A
 96%|█████████▋| 213/221 [00:58<00:02,  3.92it/s][A
 97%|█████████▋| 214/221 [00:58<00:02,  2.60it/s][A
 97%|█████████▋| 215/221 [00:58<00:02,  2.98it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.20it/s][A
 98%|█████████▊| 217/221 [00:59<00:01,  3.16it/s][A
 99%|█████████▊| 218/221 [00:59<00:00,  3.25it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.13it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.60it/s][A
100%|██████████| 221/221 [01:00<00:00,  3.94it/s][A100%|██████████| 221/221 [01:00<00:00,  3.65it/s]
09/09/2024 23:54:09 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 1249--===========

09/09/2024 23:54:09 - INFO - __main__ -   {'area_r1': 38.5, 'area_recall': '38.5/62.8/73.1', 'area_ravg': 58.1}
09/09/2024 23:54:09 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 1249--===========

09/09/2024 23:54:09 - INFO - __main__ -   {'forward_r1': 36.8, 'forward_recall': '36.8/65.8/77.0', 'forward_ravg': 59.9}
09/09/2024 23:54:09 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 1249--===========

09/09/2024 23:54:09 - INFO - __main__ -   {'area_video_r1': 38.8, 'area_video_recall': '38.8/66.4/77.5', 'area_video_ravg': 60.9}
09/09/2024 23:54:09 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/09/2024 23:54:09 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/09/2024 23:54:09 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 1249--===========

09/09/2024 23:54:09 - INFO - __main__ -   {'area_video_r1': 52.6, 'area_video_recall': '52.6/74.8/82.5', 'area_video_ravg': 69.9, 'area_video_back_r1': 48.2, 'area_video_back_recall': '48.2/73.9/81.9', 'area_video_back_ravg': 68.0}
09/09/2024 23:54:09 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/09/2024 23:54:09 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/09/2024 23:54:09 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 1249--===========

09/09/2024 23:54:09 - INFO - __main__ -   {'video_r1': 43.2, 'video_recall': '43.2/71.4/82.0', 'video_ravg': 65.5}
09/09/2024 23:54:09 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/09/2024 23:54:09 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/09/2024 23:54:09 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 1249--===========

09/09/2024 23:54:09 - INFO - __main__ -   {'video_r1': 52.1, 'video_recall': '52.1/75.5/82.6', 'video_ravg': 70.1}
09/09/2024 23:54:09 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/09/2024 23:54:09 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/09/2024 23:54:30 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.009198488667607307, 'loss_ret%tv%ta--finetune_area/loss_area': 1.0966496467590332, 'loss_ret%tv%ta--finetune_area/total_loss': 1.1058481931686401}
[h264 @ 0x56242f4c5780] mmco: unref short failure
[h264 @ 0x55a040d29380] mmco: unref short failure
[h264 @ 0x55a040d29380] mmco: unref short failure
 64%|██████▍   | 1250/1945 [6:49:10<23:55:31, 123.93s/it] 64%|██████▍   | 1251/1945 [6:49:15<16:57:28, 87.97s/it] [h264 @ 0x56242f4c5300] mmco: unref short failure
[h264 @ 0x562421b44280] mmco: unref short failure
[h264 @ 0x562421b44280] mmco: unref short failure
[h264 @ 0x55a035d9a500] mmco: unref short failure
 64%|██████▍   | 1252/1945 [6:49:20<12:08:39, 63.09s/it][h264 @ 0x559bfbf00a00] mmco: unref short failure
[h264 @ 0x559bfbf00a00] mmco: unref short failure
[h264 @ 0x562433c523c0] mmco: unref short failure
 64%|██████▍   | 1253/1945 [6:49:25<8:47:24, 45.73s/it]  64%|██████▍   | 1254/1945 [6:49:30<6:27:30, 33.65s/it][h264 @ 0x55a04f585a00] mmco: unref short failure
 65%|██████▍   | 1255/1945 [6:49:37<4:52:55, 25.47s/it][h264 @ 0x56241a04a940] mmco: unref short failure
 65%|██████▍   | 1256/1945 [6:49:44<3:49:02, 19.95s/it][h264 @ 0x55a04c3a51c0] mmco: unref short failure
[h264 @ 0x55a04c3a51c0] mmco: unref short failure
 65%|██████▍   | 1257/1945 [6:49:50<3:03:04, 15.97s/it][h264 @ 0x55a04e096bc0] mmco: unref short failure
[h264 @ 0x556b49d36d80] mmco: unref short failure
[h264 @ 0x55a040dc72c0] mmco: unref short failure
[h264 @ 0x55a040dc72c0] mmco: unref short failure
[h264 @ 0x55a040dc72c0] mmco: unref short failure
[h264 @ 0x55a040dc72c0] mmco: unref short failure
not have audios 8-qwaveiHMM.3
 65%|██████▍   | 1258/1945 [6:49:58<2:33:57, 13.45s/it] 65%|██████▍   | 1259/1945 [6:50:05<2:11:44, 11.52s/it][h264 @ 0x556b2cc41240] mmco: unref short failure
 65%|██████▍   | 1260/1945 [6:50:13<1:59:24, 10.46s/it] 65%|██████▍   | 1261/1945 [6:50:21<1:49:22,  9.59s/it][h264 @ 0x556b38445d80] mmco: unref short failure
[h264 @ 0x559c045ad300] mmco: unref short failure
[h264 @ 0x559c045ad300] mmco: unref short failure
[h264 @ 0x559c045ad300] mmco: unref short failure
[h264 @ 0x559c045ad300] mmco: unref short failure
[h264 @ 0x556b46ca3280] mmco: unref short failure
[h264 @ 0x556b46ca3280] mmco: unref short failure
[h264 @ 0x556b46ca3280] mmco: unref short failure
 65%|██████▍   | 1262/1945 [6:50:27<1:40:14,  8.81s/it][h264 @ 0x556b47167f80] mmco: unref short failure
[h264 @ 0x559c035d2040] mmco: unref short failure
[h264 @ 0x559c02fcf580] mmco: unref short failure
[h264 @ 0x559c02fcf580] mmco: unref short failure
[h264 @ 0x55a0518a09c0] mmco: unref short failure
[h264 @ 0x55a0518a09c0] mmco: unref short failure
 65%|██████▍   | 1263/1945 [6:50:36<1:37:27,  8.57s/it] 65%|██████▍   | 1264/1945 [6:50:43<1:32:21,  8.14s/it] 65%|██████▌   | 1265/1945 [6:50:50<1:28:39,  7.82s/it] 65%|██████▌   | 1266/1945 [6:50:57<1:27:14,  7.71s/it][h264 @ 0x55a0361eccc0] mmco: unref short failure
 65%|██████▌   | 1267/1945 [6:51:05<1:27:27,  7.74s/it][h264 @ 0x559bf1617580] mmco: unref short failure
[h264 @ 0x56241f515740] mmco: unref short failure
[h264 @ 0x56241f515740] mmco: unref short failure
 65%|██████▌   | 1268/1945 [6:51:12<1:24:25,  7.48s/it][h264 @ 0x559c042bbac0] mmco: unref short failure
[h264 @ 0x559bec232840] mmco: unref short failure
[h264 @ 0x55a053b885c0] mmco: unref short failure
[h264 @ 0x55a053b885c0] mmco: unref short failure
 65%|██████▌   | 1269/1945 [6:51:23<1:35:58,  8.52s/it][h264 @ 0x55a047a3f700] mmco: unref short failure
 65%|██████▌   | 1270/1945 [6:51:37<1:53:40, 10.10s/it][h264 @ 0x556b43478d80] mmco: unref short failure
[h264 @ 0x556b43478d80] mmco: unref short failure
[h264 @ 0x556b4807a700] mmco: unref short failure
[h264 @ 0x562424df9040] mmco: unref short failure
[h264 @ 0x562424df9040] mmco: unref short failure
 65%|██████▌   | 1271/1945 [6:51:47<1:52:57, 10.06s/it][h264 @ 0x559bfcc0d740] mmco: unref short failure
[h264 @ 0x559bfcc0d740] mmco: unref short failure
[h264 @ 0x562427665880] mmco: unref short failure
[h264 @ 0x562427665880] mmco: unref short failure
 65%|██████▌   | 1272/1945 [6:51:53<1:40:35,  8.97s/it][h264 @ 0x55a041601e40] mmco: unref short failure
[h264 @ 0x55a041601e40] mmco: unref short failure
[h264 @ 0x562430142800] mmco: unref short failure
[h264 @ 0x562430142800] mmco: unref short failure
[h264 @ 0x559bff4e7b80] mmco: unref short failure
[h264 @ 0x559bff4e7b80] mmco: unref short failure
 65%|██████▌   | 1273/1945 [6:52:07<1:57:07, 10.46s/it][h264 @ 0x559bfb741380] mmco: unref short failure
[h264 @ 0x56242c91fa40] mmco: unref short failure
[h264 @ 0x56242c91fa40] mmco: unref short failure
[h264 @ 0x56242645f640] mmco: unref short failure
[h264 @ 0x559c0443e3c0] mmco: unref short failure
[h264 @ 0x559c0443e3c0] mmco: unref short failure
[h264 @ 0x556b4359f1c0] mmco: unref short failure
 66%|██████▌   | 1274/1945 [6:52:53<3:55:53, 21.09s/it][h264 @ 0x5624196f6d00] mmco: unref short failure
[h264 @ 0x5624196f6d00] mmco: unref short failure
 66%|██████▌   | 1275/1945 [6:53:00<3:08:25, 16.87s/it] 66%|██████▌   | 1276/1945 [6:53:13<2:57:10, 15.89s/it][h264 @ 0x55a04a49c340] mmco: unref short failure
[h264 @ 0x55a04a49c340] mmco: unref short failure
[h264 @ 0x55a04c85de80] mmco: unref short failure
[h264 @ 0x56242f2adbc0] mmco: unref short failure
 66%|██████▌   | 1277/1945 [6:53:25<2:41:55, 14.54s/it][h264 @ 0x559bea836d80] mmco: unref short failure
[h264 @ 0x559becfff340] mmco: unref short failure
[h264 @ 0x559becfff340] mmco: unref short failure
[h264 @ 0x56241fdc0740] mmco: unref short failure
[h264 @ 0x56241fdc0740] mmco: unref short failure
 66%|██████▌   | 1278/1945 [6:53:42<2:51:43, 15.45s/it][h264 @ 0x55a03c140340] mmco: unref short failure
 66%|██████▌   | 1279/1945 [6:53:52<2:31:04, 13.61s/it][h264 @ 0x55a039909700] mmco: unref short failure
[h264 @ 0x559c05580680] mmco: unref short failure
[h264 @ 0x556b4eaab380] mmco: unref short failure
 66%|██████▌   | 1280/1945 [6:53:59<2:08:28, 11.59s/it][h264 @ 0x55a047ea49c0] mmco: unref short failure
[h264 @ 0x55a047ea49c0] mmco: unref short failure
 66%|██████▌   | 1281/1945 [6:54:07<1:58:51, 10.74s/it][h264 @ 0x55a04832c740] mmco: unref short failure
[h264 @ 0x556b483f2500] mmco: unref short failure
[h264 @ 0x55a04d388e40] mmco: unref short failure
[h264 @ 0x56242bd704c0] mmco: unref short failure
[h264 @ 0x56242bd704c0] mmco: unref short failure
[h264 @ 0x556b446c9dc0] mmco: unref short failure
[h264 @ 0x55a03c13fa80] mmco: unref short failure
[h264 @ 0x562421b75300] mmco: unref short failure
[h264 @ 0x559bf6580c80] mmco: unref short failure
 66%|██████▌   | 1282/1945 [6:54:57<4:08:23, 22.48s/it][h264 @ 0x556b34eb49c0] mmco: unref short failure
[h264 @ 0x556b34eb49c0] mmco: unref short failure
[h264 @ 0x559bf9aa98c0] mmco: unref short failure
 66%|██████▌   | 1283/1945 [6:55:04<3:16:29, 17.81s/it][h264 @ 0x562436cce080] mmco: unref short failure
 66%|██████▌   | 1284/1945 [6:55:16<2:57:21, 16.10s/it][h264 @ 0x559bee75a540] mmco: unref short failure
[h264 @ 0x559bee75a540] mmco: unref short failure
[h264 @ 0x559bfba3c380] mmco: unref short failure
[h264 @ 0x559bfba3c380] mmco: unref short failure
 66%|██████▌   | 1285/1945 [6:55:25<2:33:41, 13.97s/it][h264 @ 0x556b3c355c40] mmco: unref short failure
[h264 @ 0x556b3c355c40] mmco: unref short failure
[h264 @ 0x556b3dfd3780] mmco: unref short failure
[h264 @ 0x559c01945080] mmco: unref short failure
[h264 @ 0x559bfab2fc40] mmco: unref short failure
[h264 @ 0x559bfab2fc40] mmco: unref short failure
 66%|██████▌   | 1286/1945 [6:55:45<2:51:45, 15.64s/it][h264 @ 0x55a04d04c4c0] mmco: unref short failure
[h264 @ 0x556b42a37a80] mmco: unref short failure
[h264 @ 0x556b42a37a80] mmco: unref short failure
[h264 @ 0x562434ece2c0] mmco: unref short failure
 66%|██████▌   | 1287/1945 [6:56:02<2:57:27, 16.18s/it] 66%|██████▌   | 1288/1945 [6:56:09<2:27:23, 13.46s/it][h264 @ 0x559bfa248900] mmco: unref short failure
[h264 @ 0x559bfa248900] mmco: unref short failure
[h264 @ 0x559bff4be540] mmco: unref short failure
[h264 @ 0x559bff4be540] mmco: unref short failure
 66%|██████▋   | 1289/1945 [6:56:17<2:09:24, 11.84s/it][h264 @ 0x562425449c80] mmco: unref short failure
[h264 @ 0x559bf660f0c0] mmco: unref short failure
[h264 @ 0x559bf660f0c0] mmco: unref short failure
not have audios 7wavFXW3AFw.7
[h264 @ 0x559c0443e5c0] mmco: unref short failure
[h264 @ 0x55a04c04bf00] mmco: unref short failure
[h264 @ 0x55a0438ff640] mmco: unref short failure
[h264 @ 0x556b48580840] mmco: unref short failure
[h264 @ 0x556b48580840] mmco: unref short failure
[h264 @ 0x556b48580840] mmco: unref short failure
[h264 @ 0x556b4d581240] mmco: unref short failure
[h264 @ 0x556b33495740] mmco: unref short failure
[h264 @ 0x556b44c0c740] mmco: unref short failure
[h264 @ 0x556b44c0c740] mmco: unref short failure
 66%|██████▋   | 1290/1945 [6:56:57<3:41:28, 20.29s/it][h264 @ 0x556b479fc8c0] mmco: unref short failure
[h264 @ 0x556b479fc8c0] mmco: unref short failure
[h264 @ 0x556b479fc8c0] mmco: unref short failure
[h264 @ 0x556b479fc8c0] mmco: unref short failure
 66%|██████▋   | 1291/1945 [6:57:05<3:00:10, 16.53s/it][h264 @ 0x559bf9a29240] mmco: unref short failure
[h264 @ 0x559bf9a29240] mmco: unref short failure
 66%|██████▋   | 1292/1945 [6:57:18<2:48:35, 15.49s/it][h264 @ 0x55a0483e0c00] mmco: unref short failure
[h264 @ 0x56243483e340] mmco: unref short failure
[h264 @ 0x56243483e340] mmco: unref short failure
[h264 @ 0x55a04738db80] mmco: unref short failure
[h264 @ 0x55a0398f0900] mmco: unref short failure
 66%|██████▋   | 1293/1945 [6:57:30<2:34:47, 14.25s/it][h264 @ 0x559bf700a540] mmco: unref short failure
[h264 @ 0x559bf700a540] mmco: unref short failure
[h264 @ 0x556b3fde6380] mmco: unref short failure
[h264 @ 0x556b3fde6380] mmco: unref short failure
 67%|██████▋   | 1294/1945 [6:57:48<2:49:31, 15.62s/it][h264 @ 0x55a03786e600] mmco: unref short failure
[h264 @ 0x55a03786e600] mmco: unref short failure
[h264 @ 0x55a04d4156c0] mmco: unref short failure
[h264 @ 0x562432ebcc00] mmco: unref short failure
[h264 @ 0x562432ebcc00] mmco: unref short failure
[h264 @ 0x556b42fdbb00] mmco: unref short failure
[h264 @ 0x556b42fdbb00] mmco: unref short failure
[h264 @ 0x56242d0e4680] mmco: unref short failure
[h264 @ 0x56242d0e4680] mmco: unref short failure
 67%|██████▋   | 1295/1945 [6:57:57<2:26:30, 13.52s/it][h264 @ 0x559bed43a6c0] mmco: unref short failure
[h264 @ 0x559bed43a6c0] mmco: unref short failure
[h264 @ 0x559bed43a6c0] mmco: unref short failure
[h264 @ 0x559bed43a6c0] mmco: unref short failure
[h264 @ 0x556b364cd200] mmco: unref short failure
[h264 @ 0x556b364cd200] mmco: unref short failure
[h264 @ 0x56242749e000] mmco: unref short failure
[h264 @ 0x56242749e000] mmco: unref short failure
[h264 @ 0x56242ec76940] mmco: unref short failure
 67%|██████▋   | 1296/1945 [6:58:05<2:07:11, 11.76s/it][h264 @ 0x56242e30d300] mmco: unref short failure
[h264 @ 0x56242851fc40] mmco: unref short failure
[h264 @ 0x56242851fc40] mmco: unref short failure
[h264 @ 0x56242851fc40] mmco: unref short failure
 67%|██████▋   | 1297/1945 [6:58:13<1:54:46, 10.63s/it][h264 @ 0x56242eb64bc0] mmco: unref short failure
[h264 @ 0x56242eb64bc0] mmco: unref short failure
[h264 @ 0x56242eb64bc0] mmco: unref short failure
[h264 @ 0x56242eb64bc0] mmco: unref short failure
[h264 @ 0x559c068dcf00] mmco: unref short failure
[h264 @ 0x55a0512e56c0] mmco: unref short failure
[h264 @ 0x55a0512e56c0] mmco: unref short failure
[h264 @ 0x556b4bc3b500] mmco: unref short failure
[h264 @ 0x556b4a7c6440] mmco: unref short failure
[h264 @ 0x55a04e745e40] mmco: unref short failure
 67%|██████▋   | 1298/1945 [6:58:54<3:34:10, 19.86s/it][h264 @ 0x55a0482ba500] mmco: unref short failure
[h264 @ 0x55a0482ba500] mmco: unref short failure
[h264 @ 0x55a048cf5100] mmco: unref short failure
 67%|██████▋   | 1299/1945 [6:59:04<3:03:08, 17.01s/it]09/10/2024 00:04:27 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/10/2024 00:04:27 - INFO - __main__ -   start running ret%tv validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a0371cc180] mmco: unref short failure
[h264 @ 0x55a0371cc180] mmco: unref short failure
[h264 @ 0x55a0371cc180] mmco: unref short failure
[h264 @ 0x55a0371cc180] mmco: unref short failure
[h264 @ 0x559c0868f780] mmco: unref short failure
[h264 @ 0x559c0868f780] mmco: unref short failure
[h264 @ 0x559bfb718000] mmco: unref short failure
[h264 @ 0x559bfb718000] mmco: unref short failure
[h264 @ 0x559bfb718000] mmco: unref short failure
[h264 @ 0x559bfb718000] mmco: unref short failure
[h264 @ 0x556b444c8000] mmco: unref short failure
[h264 @ 0x556b444c8000] mmco: unref short failure
[h264 @ 0x556b50e102c0] mmco: unref short failure
[h264 @ 0x556b50e102c0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559be9b23f00] mmco: unref short failure
[h264 @ 0x559be9b23f00] mmco: unref short failure
[h264 @ 0x55a04e30a800] mmco: unref short failure
[h264 @ 0x55a04e30a800] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x562434066fc0] mmco: unref short failure
[h264 @ 0x562434066fc0] mmco: unref short failure
[h264 @ 0x556b390e9240] mmco: unref short failure
[h264 @ 0x55a04f3bfe80] mmco: unref short failure
[h264 @ 0x55a04f3bfe80] mmco: unref short failure
[h264 @ 0x5624339e6d80] mmco: unref short failure
[h264 @ 0x5624339e6d80] mmco: unref short failure
[h264 @ 0x559c00818440] mmco: unref short failure
[h264 @ 0x5624376a5680] mmco: unref short failure
[h264 @ 0x559c091325c0] mmco: unref short failure
[h264 @ 0x559c091325c0] mmco: unref short failure
[h264 @ 0x55a04e7459c0] mmco: unref short failure
[h264 @ 0x55a04e7459c0] mmco: unref short failure
[h264 @ 0x56242ed6fbc0] mmco: unref short failure
[h264 @ 0x559bea658380] mmco: unref short failure
[h264 @ 0x559bea658380] mmco: unref short failure
[h264 @ 0x55a04c26a6c0] mmco: unref short failure
[h264 @ 0x55a04c26a6c0] mmco: unref short failure
[h264 @ 0x55a04c26a6c0] mmco: unref short failure
[h264 @ 0x55a04c26a6c0] mmco: unref short failure
[h264 @ 0x559bfd65f240] mmco: unref short failure
[h264 @ 0x5624258f1b00] mmco: unref short failure
[h264 @ 0x5624258f1b00] mmco: unref short failure
[h264 @ 0x55a037b28f80] mmco: unref short failure
[h264 @ 0x556b3e36c540] mmco: unref short failure
[h264 @ 0x559bf13e23c0] mmco: unref short failure
[h264 @ 0x559bf13e23c0] mmco: unref short failure
[h264 @ 0x559c05856380] mmco: unref short failure
[h264 @ 0x559c05856380] mmco: unref short failure
[h264 @ 0x559beb800340] mmco: unref short failure
[h264 @ 0x559c087894c0] mmco: unref short failure
[h264 @ 0x559c087894c0] mmco: unref short failure
[h264 @ 0x559c087894c0] mmco: unref short failure
[h264 @ 0x559c087894c0] mmco: unref short failure
[h264 @ 0x5624342f2380] mmco: unref short failure
[h264 @ 0x5624342f2380] mmco: unref short failure
[h264 @ 0x55a04e4d1700] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:32,  1.44it/s][A
  1%|          | 2/221 [00:01<02:05,  1.74it/s][A
  1%|▏         | 3/221 [00:01<01:24,  2.59it/s][A
  2%|▏         | 4/221 [00:01<01:11,  3.02it/s][A
  2%|▏         | 5/221 [00:01<01:05,  3.29it/s][A[h264 @ 0x55a04fffbf80] mmco: unref short failure
[h264 @ 0x55a04fffbf80] mmco: unref short failure

  3%|▎         | 6/221 [00:02<00:56,  3.83it/s][A
  3%|▎         | 7/221 [00:02<01:02,  3.42it/s][A
  4%|▎         | 8/221 [00:02<01:21,  2.62it/s][A
  4%|▍         | 9/221 [00:03<01:06,  3.19it/s][A
  5%|▍         | 10/221 [00:03<01:09,  3.04it/s][A
  5%|▍         | 11/221 [00:03<00:54,  3.86it/s][A
  5%|▌         | 12/221 [00:04<01:38,  2.12it/s][A
  6%|▌         | 13/221 [00:04<01:18,  2.66it/s][A[h264 @ 0x559c035e4dc0] mmco: unref short failure
[h264 @ 0x559c05856800] mmco: unref short failure

  6%|▋         | 14/221 [00:06<03:03,  1.13it/s][A
  7%|▋         | 15/221 [00:06<02:21,  1.45it/s][A
  7%|▋         | 16/221 [00:07<01:59,  1.71it/s][A
  8%|▊         | 17/221 [00:07<01:41,  2.02it/s][A
  8%|▊         | 18/221 [00:07<01:25,  2.36it/s][A
  9%|▊         | 19/221 [00:08<01:08,  2.94it/s][A
  9%|▉         | 20/221 [00:08<00:59,  3.40it/s][A
 10%|▉         | 21/221 [00:08<00:54,  3.64it/s][A
 10%|▉         | 22/221 [00:08<00:48,  4.07it/s][A
 10%|█         | 23/221 [00:08<00:40,  4.94it/s][A
 11%|█         | 24/221 [00:08<00:35,  5.60it/s][A
 11%|█▏        | 25/221 [00:09<00:33,  5.81it/s][A
 12%|█▏        | 26/221 [00:09<00:38,  5.07it/s][A
 13%|█▎        | 28/221 [00:09<00:37,  5.14it/s][A
 13%|█▎        | 29/221 [00:09<00:33,  5.79it/s][A
 14%|█▎        | 30/221 [00:09<00:34,  5.54it/s][A
 14%|█▍        | 31/221 [00:10<00:34,  5.49it/s][A
 14%|█▍        | 32/221 [00:10<00:32,  5.78it/s][A
 15%|█▍        | 33/221 [00:10<00:39,  4.80it/s][A
 15%|█▌        | 34/221 [00:10<00:34,  5.50it/s][A
 16%|█▌        | 35/221 [00:10<00:31,  5.97it/s][A
 16%|█▋        | 36/221 [00:11<00:36,  5.08it/s][A
 17%|█▋        | 37/221 [00:11<01:08,  2.69it/s][A
 17%|█▋        | 38/221 [00:12<01:05,  2.81it/s][A
 18%|█▊        | 39/221 [00:12<00:51,  3.52it/s][A
 18%|█▊        | 40/221 [00:12<00:50,  3.56it/s][A
 19%|█▊        | 41/221 [00:12<00:42,  4.19it/s][A
 19%|█▉        | 42/221 [00:13<00:45,  3.92it/s][A
 19%|█▉        | 43/221 [00:13<00:41,  4.25it/s][A
 20%|█▉        | 44/221 [00:13<00:35,  4.95it/s][A
 20%|██        | 45/221 [00:14<01:15,  2.34it/s][A
 21%|██        | 46/221 [00:14<01:21,  2.15it/s][A
 21%|██▏       | 47/221 [00:16<02:03,  1.41it/s][A
 22%|██▏       | 48/221 [00:16<01:34,  1.83it/s][A
 22%|██▏       | 49/221 [00:16<01:14,  2.32it/s][A
 23%|██▎       | 50/221 [00:16<00:58,  2.92it/s][A
 23%|██▎       | 51/221 [00:16<00:49,  3.46it/s][A
 24%|██▎       | 52/221 [00:16<00:44,  3.82it/s][A
 24%|██▍       | 53/221 [00:17<00:38,  4.35it/s][A
 24%|██▍       | 54/221 [00:17<01:00,  2.74it/s][A
 25%|██▍       | 55/221 [00:18<01:03,  2.60it/s][A
 25%|██▌       | 56/221 [00:18<00:54,  3.04it/s][A
 26%|██▌       | 57/221 [00:18<00:48,  3.39it/s][A
 26%|██▌       | 58/221 [00:18<00:39,  4.14it/s][A
 27%|██▋       | 59/221 [00:18<00:35,  4.59it/s][A[h264 @ 0x556b4bb71f80] mmco: unref short failure

 27%|██▋       | 60/221 [00:19<00:38,  4.17it/s][A
 28%|██▊       | 61/221 [00:19<00:33,  4.71it/s][A
 28%|██▊       | 62/221 [00:19<00:35,  4.53it/s][A
 29%|██▊       | 63/221 [00:19<00:34,  4.59it/s][A
 29%|██▉       | 64/221 [00:19<00:30,  5.18it/s][A
 29%|██▉       | 65/221 [00:20<00:27,  5.76it/s][A
 30%|██▉       | 66/221 [00:20<00:35,  4.38it/s][A
 30%|███       | 67/221 [00:20<00:32,  4.77it/s][A
 31%|███       | 68/221 [00:20<00:27,  5.60it/s][A
 31%|███       | 69/221 [00:21<00:38,  3.99it/s][A
 32%|███▏      | 70/221 [00:21<00:32,  4.65it/s][A
 32%|███▏      | 71/221 [00:22<01:35,  1.57it/s][A
 33%|███▎      | 72/221 [00:23<01:13,  2.03it/s][A
 33%|███▎      | 73/221 [00:23<01:01,  2.39it/s][A
 33%|███▎      | 74/221 [00:23<00:50,  2.89it/s][A
 34%|███▍      | 75/221 [00:23<00:51,  2.86it/s][A
 34%|███▍      | 76/221 [00:24<00:44,  3.27it/s][A
 35%|███▍      | 77/221 [00:24<00:41,  3.48it/s][A
 35%|███▌      | 78/221 [00:24<00:46,  3.07it/s][A[h264 @ 0x559c041fbe00] mmco: unref short failure

 36%|███▌      | 79/221 [00:25<01:05,  2.17it/s][A
 36%|███▌      | 80/221 [00:25<00:51,  2.73it/s][A
 37%|███▋      | 81/221 [00:25<00:43,  3.21it/s][A
 37%|███▋      | 82/221 [00:26<00:40,  3.42it/s][A
 38%|███▊      | 83/221 [00:26<00:33,  4.07it/s][A
 38%|███▊      | 84/221 [00:26<00:28,  4.78it/s][A
 39%|███▉      | 86/221 [00:26<00:22,  6.10it/s][A
 39%|███▉      | 87/221 [00:26<00:29,  4.53it/s][A
 40%|███▉      | 88/221 [00:27<00:37,  3.58it/s][A
 40%|████      | 89/221 [00:29<01:48,  1.21it/s][A
 41%|████      | 90/221 [00:29<01:28,  1.48it/s][A[h264 @ 0x56242a7e70c0] mmco: unref short failure

 41%|████      | 91/221 [00:30<01:09,  1.87it/s][A
 42%|████▏     | 92/221 [00:30<00:55,  2.34it/s][A
 42%|████▏     | 93/221 [00:30<00:54,  2.36it/s][A[h264 @ 0x556b4f4875c0] mmco: unref short failure
[h264 @ 0x556b4f4875c0] mmco: unref short failure

 43%|████▎     | 94/221 [00:30<00:45,  2.77it/s][A
 43%|████▎     | 95/221 [00:31<00:37,  3.36it/s][A
 43%|████▎     | 96/221 [00:31<00:35,  3.50it/s][A
 44%|████▍     | 97/221 [00:31<00:33,  3.67it/s][A
 44%|████▍     | 98/221 [00:31<00:34,  3.61it/s][A
 45%|████▍     | 99/221 [00:31<00:27,  4.43it/s][A
 45%|████▌     | 100/221 [00:32<00:25,  4.69it/s][A
 46%|████▌     | 101/221 [00:32<00:22,  5.22it/s][A
 46%|████▌     | 102/221 [00:32<00:24,  4.79it/s][A
 47%|████▋     | 104/221 [00:32<00:17,  6.65it/s][A
 48%|████▊     | 105/221 [00:32<00:19,  5.81it/s][A
 48%|████▊     | 106/221 [00:33<00:45,  2.53it/s][A
 49%|████▉     | 108/221 [00:34<00:32,  3.48it/s][A
 49%|████▉     | 109/221 [00:34<00:30,  3.72it/s][A
 50%|████▉     | 110/221 [00:34<00:25,  4.36it/s][A
 50%|█████     | 111/221 [00:34<00:30,  3.57it/s][A
 51%|█████     | 112/221 [00:35<00:29,  3.68it/s][A
 51%|█████     | 113/221 [00:35<00:35,  3.07it/s][A
 52%|█████▏    | 115/221 [00:35<00:22,  4.75it/s][A[h264 @ 0x55a0339f2580] mmco: unref short failure
[h264 @ 0x55a0339f2580] mmco: unref short failure
[h264 @ 0x55a032d4bd00] mmco: unref short failure

 52%|█████▏    | 116/221 [00:40<02:05,  1.20s/it][A
 53%|█████▎    | 117/221 [00:40<01:40,  1.03it/s][A
 53%|█████▎    | 118/221 [00:40<01:25,  1.21it/s][A
 54%|█████▍    | 119/221 [00:40<01:04,  1.59it/s][A
 54%|█████▍    | 120/221 [00:41<00:52,  1.94it/s][A
 55%|█████▍    | 121/221 [00:41<00:42,  2.35it/s][A
 55%|█████▌    | 122/221 [00:41<00:38,  2.59it/s][A
 56%|█████▌    | 123/221 [00:41<00:31,  3.07it/s][A
 56%|█████▌    | 124/221 [00:42<00:29,  3.28it/s][A
 57%|█████▋    | 125/221 [00:42<00:26,  3.58it/s][A
 57%|█████▋    | 126/221 [00:42<00:28,  3.28it/s][A
 57%|█████▋    | 127/221 [00:43<00:29,  3.18it/s][A
 58%|█████▊    | 128/221 [00:43<00:30,  3.01it/s][A
 58%|█████▊    | 129/221 [00:43<00:25,  3.57it/s][A
 59%|█████▉    | 130/221 [00:43<00:21,  4.15it/s][A
 59%|█████▉    | 131/221 [00:43<00:20,  4.31it/s][A
 60%|█████▉    | 132/221 [00:44<00:22,  3.90it/s][A
 60%|██████    | 133/221 [00:44<00:27,  3.25it/s][A
 61%|██████    | 134/221 [00:44<00:23,  3.71it/s][A
 61%|██████    | 135/221 [00:45<00:23,  3.61it/s][A
 62%|██████▏   | 136/221 [00:45<00:25,  3.30it/s][A
 62%|██████▏   | 137/221 [00:45<00:22,  3.67it/s][A
 62%|██████▏   | 138/221 [00:46<00:25,  3.25it/s][A
 63%|██████▎   | 139/221 [00:46<00:24,  3.28it/s][A
 63%|██████▎   | 140/221 [00:46<00:24,  3.33it/s][A
 64%|██████▍   | 141/221 [00:46<00:20,  3.86it/s][A
 64%|██████▍   | 142/221 [00:47<00:38,  2.06it/s][A[h264 @ 0x559bf0430140] mmco: unref short failure
[h264 @ 0x559bf0430140] mmco: unref short failure

 65%|██████▍   | 143/221 [00:48<00:35,  2.19it/s][A
 65%|██████▌   | 144/221 [00:48<00:29,  2.65it/s][A
 66%|██████▌   | 145/221 [00:48<00:25,  2.99it/s][A
 67%|██████▋   | 147/221 [00:48<00:15,  4.66it/s][A
 67%|██████▋   | 148/221 [00:49<00:15,  4.66it/s][A
 68%|██████▊   | 150/221 [00:49<00:11,  6.23it/s][A
 68%|██████▊   | 151/221 [00:49<00:17,  4.03it/s][A
 69%|██████▉   | 152/221 [00:49<00:15,  4.35it/s][A
 69%|██████▉   | 153/221 [00:50<00:18,  3.72it/s][A
 70%|██████▉   | 154/221 [00:50<00:23,  2.80it/s][A
 71%|███████   | 156/221 [00:51<00:16,  4.00it/s][A
 71%|███████   | 157/221 [00:54<01:09,  1.08s/it][A
 71%|███████▏  | 158/221 [00:55<00:53,  1.19it/s][A
 72%|███████▏  | 159/221 [00:55<00:41,  1.48it/s][A
 72%|███████▏  | 160/221 [00:55<00:33,  1.84it/s][A
 73%|███████▎  | 161/221 [00:55<00:26,  2.30it/s][A
 73%|███████▎  | 162/221 [00:55<00:20,  2.94it/s][A
 74%|███████▍  | 163/221 [00:55<00:18,  3.21it/s][A
 74%|███████▍  | 164/221 [00:56<00:15,  3.72it/s][A
 75%|███████▍  | 165/221 [00:56<00:12,  4.42it/s][A
 75%|███████▌  | 166/221 [00:56<00:15,  3.61it/s][A[h264 @ 0x55a045e1c780] mmco: unref short failure
[h264 @ 0x55a045e1c780] mmco: unref short failure

 76%|███████▌  | 168/221 [01:00<00:59,  1.12s/it][A
 76%|███████▋  | 169/221 [01:01<00:46,  1.12it/s][A
 77%|███████▋  | 170/221 [01:01<00:37,  1.38it/s][A
 77%|███████▋  | 171/221 [01:01<00:28,  1.76it/s][A
 78%|███████▊  | 172/221 [01:01<00:23,  2.07it/s][A
 79%|███████▊  | 174/221 [01:01<00:14,  3.35it/s][A
 79%|███████▉  | 175/221 [01:02<00:13,  3.37it/s][A
 80%|███████▉  | 176/221 [01:02<00:12,  3.48it/s][A
 81%|████████  | 178/221 [01:02<00:10,  3.96it/s][A[h264 @ 0x562417af0700] mmco: unref short failure

 81%|████████  | 179/221 [01:04<00:22,  1.85it/s][A
 82%|████████▏ | 181/221 [01:04<00:15,  2.66it/s][A
 82%|████████▏ | 182/221 [01:04<00:12,  3.03it/s][A
 83%|████████▎ | 183/221 [01:04<00:10,  3.54it/s][A
 83%|████████▎ | 184/221 [01:05<00:10,  3.67it/s][A
 84%|████████▍ | 186/221 [01:05<00:08,  4.19it/s][A
 85%|████████▍ | 187/221 [01:05<00:07,  4.70it/s][A
 85%|████████▌ | 188/221 [01:06<00:08,  3.91it/s][A
 86%|████████▌ | 189/221 [01:06<00:08,  3.71it/s][A
 86%|████████▌ | 190/221 [01:06<00:07,  4.04it/s][A
 87%|████████▋ | 192/221 [01:06<00:05,  4.93it/s][A[h264 @ 0x556b47688c80] mmco: unref short failure

 88%|████████▊ | 194/221 [01:07<00:06,  4.30it/s][A
 88%|████████▊ | 195/221 [01:07<00:05,  4.85it/s][A
 89%|████████▉ | 197/221 [01:07<00:03,  6.40it/s][A
 90%|████████▉ | 198/221 [01:07<00:03,  5.79it/s][A
 90%|█████████ | 199/221 [01:07<00:03,  6.19it/s][A
 90%|█████████ | 200/221 [01:08<00:03,  5.28it/s][A
 91%|█████████ | 201/221 [01:08<00:03,  5.26it/s][A
 91%|█████████▏| 202/221 [01:08<00:03,  5.34it/s][A
 92%|█████████▏| 203/221 [01:08<00:02,  6.11it/s][A
 93%|█████████▎| 205/221 [01:08<00:02,  7.49it/s][A
 93%|█████████▎| 206/221 [01:09<00:03,  4.51it/s][A
 94%|█████████▍| 208/221 [01:09<00:02,  6.19it/s][A
 95%|█████████▌| 211/221 [01:09<00:01,  6.75it/s][A
 96%|█████████▋| 213/221 [01:10<00:01,  7.60it/s][A
 97%|█████████▋| 214/221 [01:10<00:01,  5.48it/s][A
 97%|█████████▋| 215/221 [01:10<00:01,  5.49it/s][A
 98%|█████████▊| 216/221 [01:10<00:00,  5.59it/s][A
 98%|█████████▊| 217/221 [01:11<00:01,  3.16it/s][A
 99%|█████████▊| 218/221 [01:11<00:00,  3.56it/s][A
 99%|█████████▉| 219/221 [01:12<00:00,  3.83it/s][A
100%|█████████▉| 220/221 [01:16<00:01,  1.39s/it][A
100%|██████████| 221/221 [01:16<00:00,  1.03s/it][A100%|██████████| 221/221 [01:16<00:00,  2.89it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:52,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:46,  3.50it/s][A
 27%|██▋       | 60/221 [00:15<00:44,  3.58it/s][A
 28%|██▊       | 61/221 [00:16<00:43,  3.64it/s][A
 28%|██▊       | 62/221 [00:16<00:43,  3.69it/s][A
 29%|██▊       | 63/221 [00:16<00:42,  3.72it/s][A
 29%|██▉       | 64/221 [00:16<00:42,  3.74it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.75it/s][A
 30%|██▉       | 66/221 [00:17<00:41,  3.76it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.77it/s][A
 31%|███       | 68/221 [00:18<00:40,  3.78it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.78it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.78it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:23<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:28<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:42<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:47<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:52<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:56<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:57<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:32,  6.74it/s][A
  1%|          | 2/221 [00:00<00:43,  5.04it/s][A
  1%|▏         | 3/221 [00:00<00:48,  4.53it/s][A
  2%|▏         | 4/221 [00:00<00:42,  5.06it/s][A
  2%|▏         | 5/221 [00:01<00:44,  4.81it/s][A
  3%|▎         | 7/221 [00:01<00:40,  5.27it/s][A
  4%|▎         | 8/221 [00:01<00:47,  4.52it/s][A
  4%|▍         | 9/221 [00:01<00:48,  4.38it/s][A
  5%|▍         | 10/221 [00:02<01:11,  2.97it/s][A
  5%|▍         | 11/221 [00:02<01:00,  3.47it/s][A
  5%|▌         | 12/221 [00:02<00:52,  4.00it/s][A
  6%|▌         | 13/221 [00:03<01:34,  2.21it/s][A
  6%|▋         | 14/221 [00:03<01:13,  2.83it/s][A
  7%|▋         | 15/221 [00:04<01:05,  3.14it/s][A
  7%|▋         | 16/221 [00:04<01:09,  2.95it/s][A
  8%|▊         | 17/221 [00:05<01:25,  2.40it/s][A
  8%|▊         | 18/221 [00:05<01:12,  2.80it/s][A
  9%|▊         | 19/221 [00:05<01:00,  3.33it/s][A
 10%|▉         | 21/221 [00:05<00:43,  4.58it/s][A
 10%|▉         | 22/221 [00:05<00:40,  4.94it/s][A
 10%|█         | 23/221 [00:06<00:34,  5.67it/s][A
 11%|█         | 24/221 [00:06<00:33,  5.80it/s][A
 11%|█▏        | 25/221 [00:06<00:34,  5.73it/s][A
 12%|█▏        | 26/221 [00:06<00:36,  5.28it/s][A
 12%|█▏        | 27/221 [00:06<00:34,  5.54it/s][A
 13%|█▎        | 28/221 [00:07<00:45,  4.28it/s][A
 13%|█▎        | 29/221 [00:07<00:46,  4.17it/s][A
 14%|█▎        | 30/221 [00:07<00:48,  3.96it/s][A
 14%|█▍        | 31/221 [00:07<00:44,  4.29it/s][A
 14%|█▍        | 32/221 [00:07<00:38,  4.91it/s][A
 15%|█▍        | 33/221 [00:08<00:38,  4.86it/s][A
 15%|█▌        | 34/221 [00:08<00:41,  4.56it/s][A
 16%|█▌        | 35/221 [00:08<00:45,  4.13it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:43,  4.26it/s][A
 17%|█▋        | 38/221 [00:09<00:44,  4.15it/s][A
 18%|█▊        | 39/221 [00:09<00:40,  4.53it/s][A
 18%|█▊        | 40/221 [00:09<00:47,  3.80it/s][A
 19%|█▊        | 41/221 [00:10<00:42,  4.26it/s][A
 19%|█▉        | 42/221 [00:10<00:36,  4.95it/s][A
 19%|█▉        | 43/221 [00:10<00:42,  4.23it/s][A
 20%|█▉        | 44/221 [00:10<00:44,  4.02it/s][A
 20%|██        | 45/221 [00:11<00:47,  3.72it/s][A
 21%|██        | 46/221 [00:11<00:43,  4.00it/s][A
 21%|██▏       | 47/221 [00:11<00:43,  3.99it/s][A
 22%|██▏       | 48/221 [00:11<00:38,  4.55it/s][A
 22%|██▏       | 49/221 [00:12<00:38,  4.46it/s][A
 23%|██▎       | 50/221 [00:12<00:51,  3.33it/s][A
 23%|██▎       | 51/221 [00:12<00:44,  3.82it/s][A
 24%|██▎       | 52/221 [00:12<00:44,  3.83it/s][A
 24%|██▍       | 53/221 [00:13<00:38,  4.35it/s][A
 24%|██▍       | 54/221 [00:13<00:48,  3.44it/s][A
 25%|██▍       | 55/221 [00:13<00:46,  3.56it/s][A
 25%|██▌       | 56/221 [00:13<00:40,  4.03it/s][A
 26%|██▌       | 57/221 [00:14<00:44,  3.71it/s][A
 26%|██▌       | 58/221 [00:14<00:50,  3.22it/s][A
 27%|██▋       | 59/221 [00:14<00:45,  3.60it/s][A
 27%|██▋       | 60/221 [00:15<00:37,  4.25it/s][A
 28%|██▊       | 61/221 [00:15<00:34,  4.57it/s][A
 28%|██▊       | 62/221 [00:15<00:36,  4.40it/s][A
 29%|██▊       | 63/221 [00:15<00:33,  4.73it/s][A
 29%|██▉       | 64/221 [00:15<00:40,  3.91it/s][A
 29%|██▉       | 65/221 [00:16<00:35,  4.34it/s][A
 30%|██▉       | 66/221 [00:16<00:49,  3.15it/s][A
 30%|███       | 67/221 [00:17<00:51,  2.97it/s][A
 31%|███       | 68/221 [00:17<00:43,  3.52it/s][A
 31%|███       | 69/221 [00:17<01:03,  2.38it/s][A
 32%|███▏      | 70/221 [00:18<00:51,  2.91it/s][A
 32%|███▏      | 71/221 [00:18<00:45,  3.33it/s][A
 33%|███▎      | 72/221 [00:18<00:48,  3.08it/s][A
 33%|███▎      | 73/221 [00:19<00:47,  3.13it/s][A
 33%|███▎      | 74/221 [00:19<00:41,  3.57it/s][A
 34%|███▍      | 75/221 [00:19<00:39,  3.67it/s][A
 34%|███▍      | 76/221 [00:19<00:37,  3.86it/s][A
 35%|███▍      | 77/221 [00:20<00:41,  3.50it/s][A
 35%|███▌      | 78/221 [00:20<00:36,  3.91it/s][A
 36%|███▌      | 79/221 [00:20<00:45,  3.12it/s][A
 36%|███▌      | 80/221 [00:20<00:40,  3.44it/s][A
 37%|███▋      | 81/221 [00:21<00:37,  3.73it/s][A
 37%|███▋      | 82/221 [00:21<00:43,  3.18it/s][A
 38%|███▊      | 83/221 [00:21<00:46,  2.97it/s][A
 38%|███▊      | 84/221 [00:22<00:44,  3.10it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:37,  3.64it/s][A
 39%|███▉      | 87/221 [00:23<00:43,  3.07it/s][A
 40%|███▉      | 88/221 [00:23<00:51,  2.56it/s][A
 40%|████      | 89/221 [00:23<00:47,  2.79it/s][A
 41%|████      | 90/221 [00:24<00:49,  2.65it/s][A
 41%|████      | 91/221 [00:24<00:40,  3.23it/s][A
 42%|████▏     | 92/221 [00:24<00:44,  2.91it/s][A
 42%|████▏     | 93/221 [00:25<00:58,  2.19it/s][A
 43%|████▎     | 94/221 [00:25<00:51,  2.47it/s][A
 43%|████▎     | 95/221 [00:26<00:46,  2.71it/s][A
 43%|████▎     | 96/221 [00:26<00:40,  3.11it/s][A
 44%|████▍     | 97/221 [00:26<00:35,  3.47it/s][A
 44%|████▍     | 98/221 [00:26<00:34,  3.61it/s][A
 45%|████▍     | 99/221 [00:27<00:31,  3.90it/s][A
 45%|████▌     | 100/221 [00:27<00:32,  3.73it/s][A
 46%|████▌     | 101/221 [00:27<00:30,  3.99it/s][A
 46%|████▌     | 102/221 [00:28<00:46,  2.59it/s][A
 47%|████▋     | 103/221 [00:28<00:36,  3.25it/s][A
 47%|████▋     | 104/221 [00:28<00:30,  3.82it/s][A
 48%|████▊     | 105/221 [00:28<00:31,  3.71it/s][A
 48%|████▊     | 106/221 [00:29<00:36,  3.14it/s][A
 48%|████▊     | 107/221 [00:29<00:31,  3.61it/s][A
 49%|████▉     | 108/221 [00:29<00:32,  3.49it/s][A
 49%|████▉     | 109/221 [00:29<00:25,  4.31it/s][A
 50%|████▉     | 110/221 [00:30<00:26,  4.19it/s][A
 50%|█████     | 111/221 [00:30<00:28,  3.85it/s][A
 51%|█████     | 112/221 [00:30<00:27,  3.91it/s][A
 51%|█████     | 113/221 [00:30<00:25,  4.32it/s][A
 52%|█████▏    | 114/221 [00:30<00:20,  5.19it/s][A
 52%|█████▏    | 115/221 [00:31<00:21,  4.88it/s][A
 52%|█████▏    | 116/221 [00:31<00:23,  4.55it/s][A
 53%|█████▎    | 117/221 [00:31<00:23,  4.34it/s][A
 53%|█████▎    | 118/221 [00:31<00:23,  4.40it/s][A
 54%|█████▍    | 119/221 [00:32<00:29,  3.46it/s][A
 54%|█████▍    | 120/221 [00:32<00:25,  3.93it/s][A
 55%|█████▍    | 121/221 [00:32<00:21,  4.68it/s][A
 55%|█████▌    | 122/221 [00:32<00:23,  4.25it/s][A
 56%|█████▌    | 123/221 [00:33<00:26,  3.73it/s][A
 56%|█████▌    | 124/221 [00:33<00:23,  4.11it/s][A
 57%|█████▋    | 125/221 [00:33<00:26,  3.61it/s][A
 57%|█████▋    | 126/221 [00:34<00:23,  3.99it/s][A
 57%|█████▋    | 127/221 [00:34<00:27,  3.41it/s][A
 58%|█████▊    | 128/221 [00:34<00:26,  3.56it/s][A
 58%|█████▊    | 129/221 [00:34<00:22,  4.15it/s][A
 59%|█████▉    | 130/221 [00:35<00:22,  4.10it/s][A
 59%|█████▉    | 131/221 [00:35<00:18,  4.82it/s][A
 60%|█████▉    | 132/221 [00:35<00:20,  4.27it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.67it/s][A
 61%|██████    | 134/221 [00:36<00:28,  3.04it/s][A
 61%|██████    | 135/221 [00:36<00:28,  3.04it/s][A
 62%|██████▏   | 136/221 [00:36<00:25,  3.36it/s][A
 62%|██████▏   | 137/221 [00:37<00:21,  3.95it/s][A
 62%|██████▏   | 138/221 [00:37<00:22,  3.68it/s][A
 63%|██████▎   | 139/221 [00:37<00:26,  3.13it/s][A
 63%|██████▎   | 140/221 [00:38<00:25,  3.21it/s][A
 64%|██████▍   | 141/221 [00:38<00:21,  3.64it/s][A
 64%|██████▍   | 142/221 [00:38<00:20,  3.87it/s][A
 65%|██████▍   | 143/221 [00:38<00:25,  3.07it/s][A
 65%|██████▌   | 144/221 [00:39<00:26,  2.86it/s][A
 66%|██████▌   | 145/221 [00:39<00:21,  3.55it/s][A
 67%|██████▋   | 147/221 [00:39<00:17,  4.24it/s][A
 67%|██████▋   | 148/221 [00:40<00:20,  3.50it/s][A
 67%|██████▋   | 149/221 [00:40<00:20,  3.45it/s][A
 68%|██████▊   | 150/221 [00:40<00:19,  3.64it/s][A
 68%|██████▊   | 151/221 [00:41<00:21,  3.29it/s][A
 69%|██████▉   | 152/221 [00:41<00:27,  2.50it/s][A
 69%|██████▉   | 153/221 [00:41<00:22,  3.04it/s][A
 70%|██████▉   | 154/221 [00:42<00:19,  3.38it/s][A
 70%|███████   | 155/221 [00:42<00:17,  3.74it/s][A
 71%|███████   | 156/221 [00:42<00:20,  3.15it/s][A
 71%|███████   | 157/221 [00:43<00:20,  3.18it/s][A
 71%|███████▏  | 158/221 [00:43<00:18,  3.34it/s][A
 72%|███████▏  | 159/221 [00:43<00:15,  4.04it/s][A
 72%|███████▏  | 160/221 [00:43<00:14,  4.29it/s][A
 73%|███████▎  | 161/221 [00:44<00:18,  3.23it/s][A
 73%|███████▎  | 162/221 [00:44<00:15,  3.70it/s][A
 74%|███████▍  | 163/221 [00:44<00:15,  3.78it/s][A
 74%|███████▍  | 164/221 [00:44<00:13,  4.31it/s][A
 75%|███████▍  | 165/221 [00:45<00:12,  4.41it/s][A
 75%|███████▌  | 166/221 [00:45<00:12,  4.39it/s][A
 76%|███████▌  | 167/221 [00:45<00:10,  5.24it/s][A
 76%|███████▌  | 168/221 [00:45<00:11,  4.50it/s][A
 76%|███████▋  | 169/221 [00:45<00:09,  5.23it/s][A
 77%|███████▋  | 170/221 [00:46<00:14,  3.40it/s][A
 77%|███████▋  | 171/221 [00:46<00:13,  3.75it/s][A
 78%|███████▊  | 172/221 [00:46<00:13,  3.71it/s][A
 78%|███████▊  | 173/221 [00:47<00:13,  3.60it/s][A
 79%|███████▊  | 174/221 [00:47<00:15,  2.96it/s][A
 79%|███████▉  | 175/221 [00:47<00:16,  2.84it/s][A
 80%|███████▉  | 176/221 [00:48<00:14,  3.12it/s][A
 80%|████████  | 177/221 [00:48<00:13,  3.29it/s][A
 81%|████████  | 178/221 [00:48<00:13,  3.30it/s][A
 81%|████████  | 179/221 [00:49<00:12,  3.49it/s][A
 81%|████████▏ | 180/221 [00:49<00:10,  3.99it/s][A
 82%|████████▏ | 181/221 [00:49<00:10,  3.75it/s][A
 82%|████████▏ | 182/221 [00:49<00:12,  3.21it/s][A
 83%|████████▎ | 183/221 [00:50<00:11,  3.29it/s][A
 83%|████████▎ | 184/221 [00:50<00:10,  3.46it/s][A
 84%|████████▎ | 185/221 [00:50<00:09,  3.80it/s][A
 84%|████████▍ | 186/221 [00:51<00:11,  2.96it/s][A
 85%|████████▍ | 187/221 [00:51<00:09,  3.41it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:51<00:08,  3.64it/s][A
 86%|████████▌ | 190/221 [00:52<00:09,  3.28it/s][A
 86%|████████▋ | 191/221 [00:52<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:52<00:07,  3.96it/s][A
 87%|████████▋ | 193/221 [00:52<00:06,  4.60it/s][A
 88%|████████▊ | 194/221 [00:53<00:06,  3.94it/s][A
 88%|████████▊ | 195/221 [00:53<00:06,  4.19it/s][A
 89%|████████▊ | 196/221 [00:53<00:07,  3.53it/s][A
 89%|████████▉ | 197/221 [00:53<00:06,  3.67it/s][A
 90%|████████▉ | 198/221 [00:54<00:07,  3.02it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.39it/s][A
 90%|█████████ | 200/221 [00:55<00:06,  3.05it/s][A
 91%|█████████ | 201/221 [00:55<00:05,  3.49it/s][A
 91%|█████████▏| 202/221 [00:55<00:05,  3.22it/s][A
 92%|█████████▏| 203/221 [00:55<00:04,  3.72it/s][A
 92%|█████████▏| 204/221 [00:56<00:04,  3.47it/s][A
 93%|█████████▎| 205/221 [00:56<00:03,  4.31it/s][A
 93%|█████████▎| 206/221 [00:56<00:04,  3.57it/s][A
 94%|█████████▎| 207/221 [00:56<00:03,  3.65it/s][A
 94%|█████████▍| 208/221 [00:57<00:03,  3.85it/s][A
 95%|█████████▍| 209/221 [00:57<00:02,  4.24it/s][A
 95%|█████████▌| 210/221 [00:57<00:02,  4.53it/s][A
 95%|█████████▌| 211/221 [00:57<00:02,  3.94it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  3.73it/s][A
 96%|█████████▋| 213/221 [00:58<00:02,  3.94it/s][A
 97%|█████████▋| 214/221 [00:58<00:02,  2.63it/s][A
 97%|█████████▋| 215/221 [00:59<00:01,  3.01it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.22it/s][A
 98%|█████████▊| 217/221 [00:59<00:01,  3.24it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.26it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.09it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.57it/s][A
100%|██████████| 221/221 [01:00<00:00,  3.91it/s][A100%|██████████| 221/221 [01:00<00:00,  3.64it/s]
09/10/2024 00:10:15 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 1299--===========

09/10/2024 00:10:15 - INFO - __main__ -   {'area_r1': 38.2, 'area_recall': '38.2/62.6/72.6', 'area_ravg': 57.8}
09/10/2024 00:10:15 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 1299--===========

09/10/2024 00:10:15 - INFO - __main__ -   {'forward_r1': 36.4, 'forward_recall': '36.4/66.1/76.9', 'forward_ravg': 59.8}
09/10/2024 00:10:15 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 1299--===========

09/10/2024 00:10:15 - INFO - __main__ -   {'area_video_r1': 37.4, 'area_video_recall': '37.4/66.0/77.0', 'area_video_ravg': 60.1}
09/10/2024 00:10:15 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/10/2024 00:10:15 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/10/2024 00:10:15 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 1299--===========

09/10/2024 00:10:15 - INFO - __main__ -   {'area_video_r1': 52.0, 'area_video_recall': '52.0/74.2/82.2', 'area_video_ravg': 69.5, 'area_video_back_r1': 48.3, 'area_video_back_recall': '48.3/73.9/82.1', 'area_video_back_ravg': 68.1}
09/10/2024 00:10:15 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/10/2024 00:10:15 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/10/2024 00:10:15 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 1299--===========

09/10/2024 00:10:15 - INFO - __main__ -   {'video_r1': 43.0, 'video_recall': '43.0/71.4/82.2', 'video_ravg': 65.5}
09/10/2024 00:10:15 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/10/2024 00:10:15 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/10/2024 00:10:15 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 1299--===========

09/10/2024 00:10:15 - INFO - __main__ -   {'video_r1': 51.8, 'video_recall': '51.8/75.5/82.6', 'video_ravg': 69.9}
09/10/2024 00:10:15 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/10/2024 00:10:15 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/10/2024 00:10:35 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.007462674751877785, 'loss_ret%tv%ta--finetune_area/loss_area': 1.0674338340759277, 'loss_ret%tv%ta--finetune_area/total_loss': 1.0748964548110962}
 67%|██████▋   | 1300/1945 [7:05:16<22:05:01, 123.26s/it][h264 @ 0x559c0688d840] mmco: unref short failure
[h264 @ 0x559c0688d840] mmco: unref short failure
 67%|██████▋   | 1301/1945 [7:05:20<15:39:34, 87.54s/it]  67%|██████▋   | 1302/1945 [7:05:25<11:13:26, 62.84s/it][h264 @ 0x556b484e48c0] mmco: unref short failure
[h264 @ 0x562433e08740] mmco: unref short failure
[h264 @ 0x562433e08740] mmco: unref short failure
 67%|██████▋   | 1303/1945 [7:05:30<8:06:49, 45.50s/it] [h264 @ 0x556b499fbec0] mmco: unref short failure
[h264 @ 0x556b499fbec0] mmco: unref short failure
 67%|██████▋   | 1304/1945 [7:05:36<5:58:54, 33.60s/it][h264 @ 0x556b47e54780] mmco: unref short failure
[h264 @ 0x556b47e54780] mmco: unref short failure
[h264 @ 0x556b47e54780] mmco: unref short failure
[h264 @ 0x556b47e54780] mmco: unref short failure
 67%|██████▋   | 1305/1945 [7:05:43<4:32:17, 25.53s/it][h264 @ 0x562422425d40] mmco: unref short failure
[h264 @ 0x556b408d90c0] mmco: unref short failure
[h264 @ 0x556b408d90c0] mmco: unref short failure
[h264 @ 0x55a053cb8ec0] mmco: unref short failure
 67%|██████▋   | 1306/1945 [7:05:49<3:32:22, 19.94s/it] 67%|██████▋   | 1307/1945 [7:05:57<2:52:33, 16.23s/it][h264 @ 0x559c07a74c80] mmco: unref short failure
[h264 @ 0x556b365dac80] mmco: unref short failure
[h264 @ 0x556b365dac80] mmco: unref short failure
[h264 @ 0x559c057cdd00] mmco: unref short failure
 67%|██████▋   | 1308/1945 [7:06:06<2:28:53, 14.02s/it] 67%|██████▋   | 1309/1945 [7:06:12<2:04:26, 11.74s/it][h264 @ 0x559bf3f8c1c0] mmco: unref short failure
 67%|██████▋   | 1310/1945 [7:06:19<1:48:45, 10.28s/it][h264 @ 0x556b3b313e00] mmco: unref short failure
[h264 @ 0x556b3b313e00] mmco: unref short failure
 67%|██████▋   | 1311/1945 [7:06:26<1:36:44,  9.16s/it][h264 @ 0x5624302a9700] mmco: unref short failure
 67%|██████▋   | 1312/1945 [7:06:33<1:30:49,  8.61s/it][h264 @ 0x562429d64e00] mmco: unref short failure
[h264 @ 0x562429d64e00] mmco: unref short failure
 68%|██████▊   | 1313/1945 [7:06:41<1:29:38,  8.51s/it][h264 @ 0x556b2d7a4400] mmco: unref short failure
[h264 @ 0x556b2d7a4400] mmco: unref short failure
[h264 @ 0x559c00c77cc0] mmco: unref short failure
 68%|██████▊   | 1314/1945 [7:06:49<1:27:53,  8.36s/it][h264 @ 0x556b41691000] mmco: unref short failure
 68%|██████▊   | 1315/1945 [7:06:57<1:25:43,  8.16s/it][h264 @ 0x559bf04d6bc0] mmco: unref short failure
[h264 @ 0x559bf04d6bc0] mmco: unref short failure
[h264 @ 0x559be90ab340] mmco: unref short failure
[h264 @ 0x559be90ab340] mmco: unref short failure
[h264 @ 0x559be90ab340] mmco: unref short failure
 68%|██████▊   | 1316/1945 [7:07:05<1:23:51,  8.00s/it][h264 @ 0x55a03281a500] mmco: unref short failure
 68%|██████▊   | 1317/1945 [7:07:12<1:21:37,  7.80s/it][h264 @ 0x556b3e782940] mmco: unref short failure
[h264 @ 0x556b3e782940] mmco: unref short failure
[h264 @ 0x562433bd1fc0] mmco: unref short failure
[h264 @ 0x56243331dbc0] mmco: unref short failure
 68%|██████▊   | 1318/1945 [7:07:24<1:33:54,  8.99s/it][h264 @ 0x559c00c77ec0] mmco: unref short failure
[h264 @ 0x559c00c77ec0] mmco: unref short failure
 68%|██████▊   | 1319/1945 [7:07:31<1:26:50,  8.32s/it][h264 @ 0x562425db7c40] mmco: unref short failure
[h264 @ 0x559be984f5c0] mmco: unref short failure
[h264 @ 0x556b4c138d80] mmco: unref short failure
[h264 @ 0x562430f61f40] mmco: unref short failure
 68%|██████▊   | 1320/1945 [7:07:42<1:36:20,  9.25s/it][h264 @ 0x55a044fb0600] mmco: unref short failure
[h264 @ 0x55a044fb0600] mmco: unref short failure
[h264 @ 0x556b3068b100] mmco: unref short failure
[h264 @ 0x556b3068b100] mmco: unref short failure
 68%|██████▊   | 1321/1945 [7:07:57<1:53:38, 10.93s/it][h264 @ 0x559bfb82b380] mmco: unref short failure
[h264 @ 0x559bfb82b380] mmco: unref short failure
[h264 @ 0x56241b4cc800] mmco: unref short failure
[h264 @ 0x55a037ce5700] mmco: unref short failure
[h264 @ 0x55a037ce5700] mmco: unref short failure
[h264 @ 0x55a034585540] mmco: unref short failure
[h264 @ 0x55a034585540] mmco: unref short failure
 68%|██████▊   | 1322/1945 [7:08:04<1:41:25,  9.77s/it][h264 @ 0x559bea408f00] mmco: unref short failure
 68%|██████▊   | 1323/1945 [7:08:10<1:31:22,  8.81s/it][h264 @ 0x559bf110b040] mmco: unref short failure
[h264 @ 0x559be9622540] mmco: unref short failure
[h264 @ 0x556b2d3dc580] mmco: unref short failure
[h264 @ 0x556b2d3dc580] mmco: unref short failure
[h264 @ 0x55a032dd57c0] mmco: unref short failure
[h264 @ 0x559be901f400] mmco: unref short failure
[h264 @ 0x55a047ae1780] mmco: unref short failure
[h264 @ 0x55a047ae1780] mmco: unref short failure
[h264 @ 0x55a03f655740] mmco: unref short failure
[h264 @ 0x556b50549580] mmco: unref short failure
[h264 @ 0x556b50549580] mmco: unref short failure
[h264 @ 0x559bec5139c0] mmco: unref short failure
[h264 @ 0x559bec5139c0] mmco: unref short failure
[h264 @ 0x562433c62180] mmco: unref short failure
[h264 @ 0x562433c62180] mmco: unref short failure
[h264 @ 0x562427474480] mmco: unref short failure
[h264 @ 0x55a0516c1900] mmco: unref short failure
[h264 @ 0x55a0516c1900] mmco: unref short failure
[h264 @ 0x556b49b1ae80] mmco: unref short failure
[h264 @ 0x556b49b1ae80] mmco: unref short failure
[h264 @ 0x55a0395ad540] mmco: unref short failure
[h264 @ 0x55a0395ad540] mmco: unref short failure
[h264 @ 0x559beb8af140] mmco: unref short failure
[h264 @ 0x556b482b92c0] mmco: unref short failure
[h264 @ 0x55a040d86600] mmco: unref short failure
 68%|██████▊   | 1324/1945 [7:09:01<3:42:16, 21.48s/it] 68%|██████▊   | 1325/1945 [7:09:10<3:03:09, 17.73s/it][h264 @ 0x559be9ad6a40] mmco: unref short failure
[h264 @ 0x562425db8100] mmco: unref short failure
 68%|██████▊   | 1326/1945 [7:09:26<2:57:31, 17.21s/it][h264 @ 0x55a032633680] mmco: unref short failure
[h264 @ 0x559be9c36600] mmco: unref short failure
[h264 @ 0x55a036238b00] mmco: unref short failure
[h264 @ 0x562419360f00] mmco: unref short failure
[h264 @ 0x55a03351e4c0] mmco: unref short failure
[h264 @ 0x55a03351e4c0] mmco: unref short failure
[h264 @ 0x559c0583f1c0] mmco: unref short failure
[h264 @ 0x559c0583f1c0] mmco: unref short failure
 68%|██████▊   | 1327/1945 [7:09:40<2:44:36, 15.98s/it][h264 @ 0x55a0358f2cc0] mmco: unref short failure
[h264 @ 0x55a0358f2cc0] mmco: unref short failure
 68%|██████▊   | 1328/1945 [7:09:46<2:15:54, 13.22s/it][h264 @ 0x562432448200] mmco: unref short failure
[h264 @ 0x556b4973c040] mmco: unref short failure
 68%|██████▊   | 1329/1945 [7:10:03<2:26:37, 14.28s/it][h264 @ 0x559bf40b7a40] mmco: unref short failure
[h264 @ 0x55a033674c00] mmco: unref short failure
[h264 @ 0x55a033674c00] mmco: unref short failure
[h264 @ 0x55a033674c00] mmco: unref short failure
 68%|██████▊   | 1330/1945 [7:10:10<2:04:27, 12.14s/it] 68%|██████▊   | 1331/1945 [7:10:18<1:51:15, 10.87s/it][h264 @ 0x559c0b00ea00] mmco: unref short failure
[h264 @ 0x55a0487c2480] mmco: unref short failure
[h264 @ 0x556b2f0f9840] mmco: unref short failure
[h264 @ 0x556b2f0f9840] mmco: unref short failure
[h264 @ 0x556b38179c00] mmco: unref short failure
[h264 @ 0x556b38179c00] mmco: unref short failure
[h264 @ 0x556b38179c00] mmco: unref short failure
[h264 @ 0x556b38179c00] mmco: unref short failure
[h264 @ 0x556b2d32af00] mmco: unref short failure
[h264 @ 0x559beaf98140] mmco: unref short failure
[h264 @ 0x559beaf98140] mmco: unref short failure
[h264 @ 0x55a037698640] mmco: unref short failure
[h264 @ 0x55a037698640] mmco: unref short failure
[h264 @ 0x562422bc2b40] mmco: unref short failure
[h264 @ 0x562422bc2b40] mmco: unref short failure
[h264 @ 0x556b50a77d40] mmco: unref short failure
 68%|██████▊   | 1332/1945 [7:11:06<3:45:37, 22.08s/it][h264 @ 0x556b31adf980] mmco: unref short failure
[h264 @ 0x556b4062f940] mmco: unref short failure
[h264 @ 0x556b4062f940] mmco: unref short failure
[h264 @ 0x556b476887c0] mmco: unref short failure
[h264 @ 0x556b476887c0] mmco: unref short failure
[h264 @ 0x556b4062f940] mmco: unref short failure
[h264 @ 0x556b4062f940] mmco: unref short failure
[h264 @ 0x56243399c180] mmco: unref short failure
[h264 @ 0x56243399c180] mmco: unref short failure
 69%|██████▊   | 1333/1945 [7:11:13<2:58:54, 17.54s/it][h264 @ 0x556b3735bac0] mmco: unref short failure
[h264 @ 0x556b3735bac0] mmco: unref short failure
[h264 @ 0x562434066b40] mmco: unref short failure
[h264 @ 0x556b3026a380] mmco: unref short failure
[h264 @ 0x556b3026a380] mmco: unref short failure
[h264 @ 0x559be964cc80] mmco: unref short failure
[h264 @ 0x559be964cc80] mmco: unref short failure
 69%|██████▊   | 1334/1945 [7:11:33<3:06:13, 18.29s/it][h264 @ 0x55a04f29e8c0] mmco: unref short failure
[h264 @ 0x5624190b3740] mmco: unref short failure
 69%|██████▊   | 1335/1945 [7:11:47<2:51:50, 16.90s/it][h264 @ 0x556b2dce1680] mmco: unref short failure
[h264 @ 0x556b2dce1680] mmco: unref short failure
[h264 @ 0x556b3c9004c0] mmco: unref short failure
[h264 @ 0x559be8f06080] mmco: unref short failure
[h264 @ 0x559be8f06080] mmco: unref short failure
[h264 @ 0x559beaa13440] mmco: unref short failure
 69%|██████▊   | 1336/1945 [7:11:55<2:25:04, 14.29s/it] 69%|██████▊   | 1337/1945 [7:12:09<2:23:05, 14.12s/it] 69%|██████▉   | 1338/1945 [7:12:16<2:00:26, 11.91s/it][h264 @ 0x559bf38c4f40] mmco: unref short failure
 69%|██████▉   | 1339/1945 [7:12:23<1:47:06, 10.61s/it][h264 @ 0x556b35c6bbc0] mmco: unref short failure
[h264 @ 0x556b35c6bbc0] mmco: unref short failure
[h264 @ 0x55a044fb0600] mmco: unref short failure
[h264 @ 0x55a044fb0600] mmco: unref short failure
[h264 @ 0x559bf12b6c40] mmco: unref short failure
[h264 @ 0x559be99ed900] mmco: unref short failure
[h264 @ 0x559be99ed900] mmco: unref short failure
[h264 @ 0x56241aa3fcc0] mmco: unref short failure
[h264 @ 0x56241aa3fcc0] mmco: unref short failure
[h264 @ 0x56241aa3fcc0] mmco: unref short failure
[h264 @ 0x56241aa3fcc0] mmco: unref short failure
[h264 @ 0x556b43d66d40] mmco: unref short failure
[h264 @ 0x556b43d66d40] mmco: unref short failure
[h264 @ 0x55a03d8e5640] mmco: unref short failure
[h264 @ 0x55a03d8e5640] mmco: unref short failure
[h264 @ 0x559c06d350c0] mmco: unref short failure
[h264 @ 0x559c06d350c0] mmco: unref short failure
 69%|██████▉   | 1340/1945 [7:13:11<3:40:06, 21.83s/it][h264 @ 0x562433234280] mmco: unref short failure
[h264 @ 0x556b30e3bcc0] mmco: unref short failure
 69%|██████▉   | 1341/1945 [7:13:18<2:54:29, 17.33s/it][h264 @ 0x5624293e73c0] mmco: unref short failure
[h264 @ 0x5624293e73c0] mmco: unref short failure
[h264 @ 0x56241b03ca00] mmco: unref short failure
 69%|██████▉   | 1342/1945 [7:13:33<2:48:20, 16.75s/it][h264 @ 0x556b334b5c80] mmco: unref short failure
[h264 @ 0x556b39549200] mmco: unref short failure
[h264 @ 0x556b39549200] mmco: unref short failure
[h264 @ 0x55a0484ee980] mmco: unref short failure
[h264 @ 0x55a0484ee980] mmco: unref short failure
[h264 @ 0x55a034845ac0] mmco: unref short failure
[h264 @ 0x55a034845ac0] mmco: unref short failure
[h264 @ 0x55a053145540] mmco: unref short failure
[h264 @ 0x55a053145540] mmco: unref short failure
[h264 @ 0x5624293e7180] mmco: unref short failure
[h264 @ 0x5624293e7180] mmco: unref short failure
 69%|██████▉   | 1343/1945 [7:14:01<3:20:39, 20.00s/it][h264 @ 0x55a03a2faa40] mmco: unref short failure
[h264 @ 0x559bec907e40] mmco: unref short failure
[h264 @ 0x559bec907e40] mmco: unref short failure
 69%|██████▉   | 1344/1945 [7:14:08<2:41:30, 16.12s/it][h264 @ 0x559beffa6d80] mmco: unref short failure
[h264 @ 0x559beffa6d80] mmco: unref short failure
 69%|██████▉   | 1345/1945 [7:14:16<2:16:17, 13.63s/it][h264 @ 0x562432192e00] mmco: unref short failure
[h264 @ 0x562432192e00] mmco: unref short failure
[h264 @ 0x556b4973c040] mmco: unref short failure
[h264 @ 0x556b4973c040] mmco: unref short failure
[h264 @ 0x55a04c824cc0] mmco: unref short failure
[h264 @ 0x55a04c824cc0] mmco: unref short failure
[h264 @ 0x56241dd89c00] mmco: unref short failure
[h264 @ 0x562433741980] mmco: unref short failure
[h264 @ 0x562433741980] mmco: unref short failure
[h264 @ 0x562433741980] mmco: unref short failure
[h264 @ 0x562433741980] mmco: unref short failure
 69%|██████▉   | 1346/1945 [7:14:24<1:57:53, 11.81s/it] 69%|██████▉   | 1347/1945 [7:14:30<1:41:53, 10.22s/it][h264 @ 0x556b2ef595c0] mmco: unref short failure
[h264 @ 0x556b2ef595c0] mmco: unref short failure
[h264 @ 0x5624176c9280] mmco: unref short failure
[h264 @ 0x556b2ef595c0] mmco: unref short failure
[h264 @ 0x556b2ef595c0] mmco: unref short failure
[h264 @ 0x5624176c9280] mmco: unref short failure
[h264 @ 0x556b430fc480] mmco: unref short failure
[h264 @ 0x556b430fc480] mmco: unref short failure
[h264 @ 0x55a036281ac0] mmco: unref short failure
[h264 @ 0x55a036281ac0] mmco: unref short failure
[h264 @ 0x5624356e24c0] mmco: unref short failure
[h264 @ 0x5624356e24c0] mmco: unref short failure
[h264 @ 0x559beb823540] mmco: unref short failure
[h264 @ 0x5624178a8dc0] mmco: unref short failure
[h264 @ 0x5624178a8dc0] mmco: unref short failure
[h264 @ 0x5624178a8dc0] mmco: unref short failure
[h264 @ 0x5624178a8dc0] mmco: unref short failure
[h264 @ 0x559befe8e800] mmco: unref short failure
[h264 @ 0x559befe8e800] mmco: unref short failure
[h264 @ 0x559befe8e800] mmco: unref short failure
[h264 @ 0x559befe8e800] mmco: unref short failure
[h264 @ 0x559befe8e800] mmco: unref short failure
[h264 @ 0x55a034434f00] mmco: unref short failure
[h264 @ 0x55a034434f00] mmco: unref short failure
[h264 @ 0x556b2df990c0] mmco: unref short failure
[h264 @ 0x559beaa13900] mmco: unref short failure
[h264 @ 0x56241836cbc0] mmco: unref short failure
[h264 @ 0x56241836cbc0] mmco: unref short failure
 69%|██████▉   | 1348/1945 [7:15:15<3:25:58, 20.70s/it][h264 @ 0x562431cd7a80] mmco: unref short failure
[h264 @ 0x55a051a11640] mmco: unref short failure
[h264 @ 0x562416abae40] mmco: unref short failure
 69%|██████▉   | 1349/1945 [7:15:23<2:47:38, 16.88s/it]09/10/2024 00:20:45 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/10/2024 00:20:45 - INFO - __main__ -   start running ret%tv validation...
[h264 @ 0x559bebdd1e40] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a03b083000] mmco: unref short failure
[h264 @ 0x55a03b083000] mmco: unref short failure
[h264 @ 0x559bea15fa00] mmco: unref short failure
[h264 @ 0x556b5052cec0] mmco: unref short failure
[h264 @ 0x556b5052cec0] mmco: unref short failure
[h264 @ 0x562432447d80] mmco: unref short failure
[h264 @ 0x562432447d80] mmco: unref short failure
[h264 @ 0x55a049021d00] mmco: unref short failure
[h264 @ 0x55a049021d00] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559beae69480] mmco: unref short failure
[h264 @ 0x559beae69480] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a052995140] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a035387f00] mmco: unref short failure
[h264 @ 0x55a035387f00] mmco: unref short failure
[h264 @ 0x559be97dff80] mmco: unref short failure
[h264 @ 0x55a032d5d500] mmco: unref short failure
[h264 @ 0x55a041e55280] mmco: unref short failure
[h264 @ 0x55a041e55280] mmco: unref short failure
[h264 @ 0x562430742640] mmco: unref short failure
[h264 @ 0x562430742640] mmco: unref short failure
[h264 @ 0x562430742640] mmco: unref short failure
[h264 @ 0x562430742640] mmco: unref short failure
[h264 @ 0x562436907240] mmco: unref short failure
[h264 @ 0x562436907240] mmco: unref short failure
[h264 @ 0x556b2caea780] mmco: unref short failure
[h264 @ 0x556b2caea780] mmco: unref short failure
[h264 @ 0x559be9950e80] mmco: unref short failure
[h264 @ 0x55a0389821c0] mmco: unref short failure
[h264 @ 0x55a0389821c0] mmco: unref short failure
[h264 @ 0x55a05431b540] mmco: unref short failure
[h264 @ 0x55a04e1e9b40] mmco: unref short failure
[h264 @ 0x562419735480] mmco: unref short failure
[h264 @ 0x556b3d270780] mmco: unref short failure
[h264 @ 0x556b3d270780] mmco: unref short failure
[h264 @ 0x556b3d270780] mmco: unref short failure
[h264 @ 0x556b35c6c2c0] mmco: unref short failure
[h264 @ 0x556b4b1dd5c0] mmco: unref short failure
[h264 @ 0x556b4b1dd5c0] mmco: unref short failure
[h264 @ 0x55a0330e3e00] mmco: unref short failure
[h264 @ 0x55a0330e3e00] mmco: unref short failure
[h264 @ 0x556b5052d780] mmco: unref short failure
[h264 @ 0x556b5052d780] mmco: unref short failure
[h264 @ 0x559beaa13900] mmco: unref short failure
[h264 @ 0x56241d92acc0] mmco: unref short failure
[h264 @ 0x559bff3fda40] mmco: unref short failure
[h264 @ 0x556b2f85f080] mmco: unref short failure
[h264 @ 0x556b2f85f080] mmco: unref short failure
[h264 @ 0x556b2f85f080] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A[h264 @ 0x56241e273840] mmco: unref short failure
[h264 @ 0x56241e273840] mmco: unref short failure

  0%|          | 1/221 [00:00<02:55,  1.26it/s][A
  1%|          | 2/221 [00:01<02:23,  1.53it/s][A
  1%|▏         | 3/221 [00:01<01:33,  2.33it/s][A
  2%|▏         | 4/221 [00:01<01:05,  3.33it/s][A
  2%|▏         | 5/221 [00:01<00:52,  4.12it/s][A
  3%|▎         | 6/221 [00:01<00:43,  4.89it/s][A
  3%|▎         | 7/221 [00:02<00:45,  4.70it/s][A
  4%|▎         | 8/221 [00:02<01:08,  3.10it/s][A
  4%|▍         | 9/221 [00:02<00:57,  3.72it/s][A
  5%|▍         | 10/221 [00:03<01:02,  3.40it/s][A
  5%|▍         | 11/221 [00:03<00:51,  4.11it/s][A[h264 @ 0x55a038d3d000] mmco: unref short failure

  5%|▌         | 12/221 [00:04<01:29,  2.35it/s][A
  6%|▌         | 13/221 [00:04<01:09,  3.01it/s][A
  6%|▋         | 14/221 [00:05<02:23,  1.44it/s][A
  7%|▋         | 15/221 [00:06<01:54,  1.80it/s][A[h264 @ 0x556b47999700] mmco: unref short failure

  7%|▋         | 16/221 [00:06<01:40,  2.04it/s][A
  8%|▊         | 17/221 [00:06<01:21,  2.51it/s][A
  8%|▊         | 18/221 [00:06<01:11,  2.85it/s][A
  9%|▊         | 19/221 [00:06<00:59,  3.38it/s][A
  9%|▉         | 20/221 [00:07<00:53,  3.75it/s][A
 10%|▉         | 21/221 [00:07<00:45,  4.42it/s][A
 10%|▉         | 22/221 [00:07<00:48,  4.14it/s][A
 10%|█         | 23/221 [00:07<00:42,  4.64it/s][A
 11%|█         | 24/221 [00:08<00:47,  4.16it/s][A
 11%|█▏        | 25/221 [00:08<00:49,  3.95it/s][A
 12%|█▏        | 26/221 [00:08<00:52,  3.72it/s][A
 12%|█▏        | 27/221 [00:08<00:53,  3.61it/s][A
 13%|█▎        | 28/221 [00:09<00:57,  3.36it/s][A
 13%|█▎        | 29/221 [00:09<00:47,  4.06it/s][A
 14%|█▎        | 30/221 [00:09<00:42,  4.53it/s][A
 14%|█▍        | 31/221 [00:09<00:39,  4.86it/s][A
 14%|█▍        | 32/221 [00:09<00:33,  5.58it/s][A
 15%|█▍        | 33/221 [00:10<00:40,  4.61it/s][A
 16%|█▌        | 35/221 [00:10<00:32,  5.80it/s][A
 16%|█▋        | 36/221 [00:10<00:33,  5.49it/s][A
 17%|█▋        | 37/221 [00:11<01:03,  2.90it/s][A
 17%|█▋        | 38/221 [00:11<01:05,  2.77it/s][A
 18%|█▊        | 39/221 [00:11<00:54,  3.36it/s][A
 18%|█▊        | 40/221 [00:12<00:49,  3.64it/s][A
 19%|█▊        | 41/221 [00:12<00:43,  4.18it/s][A
 19%|█▉        | 42/221 [00:12<00:49,  3.60it/s][A
 19%|█▉        | 43/221 [00:12<00:43,  4.14it/s][A
 20%|█▉        | 44/221 [00:12<00:35,  4.96it/s][A
 20%|██        | 45/221 [00:13<01:16,  2.29it/s][A
 21%|██        | 46/221 [00:14<01:18,  2.24it/s][A
 21%|██▏       | 47/221 [00:15<02:13,  1.30it/s][A
 22%|██▏       | 48/221 [00:16<01:44,  1.66it/s][A
 22%|██▏       | 49/221 [00:16<01:19,  2.17it/s][A
 23%|██▎       | 50/221 [00:16<01:00,  2.82it/s][A
 23%|██▎       | 51/221 [00:16<00:47,  3.57it/s][A
 24%|██▎       | 52/221 [00:16<00:39,  4.32it/s][A
 24%|██▍       | 53/221 [00:16<00:33,  5.03it/s][A
 24%|██▍       | 54/221 [00:17<01:00,  2.75it/s][A
 25%|██▍       | 55/221 [00:17<01:06,  2.50it/s][A
 25%|██▌       | 56/221 [00:18<01:05,  2.53it/s][A[h264 @ 0x556b3a36a940] mmco: unref short failure
[h264 @ 0x556b3a36a940] mmco: unref short failure

 26%|██▌       | 57/221 [00:18<00:57,  2.87it/s][A
 26%|██▌       | 58/221 [00:18<00:44,  3.63it/s][A
 27%|██▋       | 59/221 [00:18<00:38,  4.20it/s][A
 27%|██▋       | 60/221 [00:19<00:44,  3.58it/s][A
 28%|██▊       | 61/221 [00:19<00:41,  3.84it/s][A
 28%|██▊       | 62/221 [00:19<00:37,  4.23it/s][A
 29%|██▊       | 63/221 [00:19<00:37,  4.21it/s][A
 29%|██▉       | 64/221 [00:20<00:40,  3.86it/s][A
 29%|██▉       | 65/221 [00:20<00:38,  4.01it/s][A
 30%|██▉       | 66/221 [00:20<00:43,  3.55it/s][A
 30%|███       | 67/221 [00:20<00:37,  4.12it/s][A
 31%|███       | 69/221 [00:21<00:39,  3.88it/s][A
 32%|███▏      | 70/221 [00:21<00:37,  4.08it/s][A
 32%|███▏      | 71/221 [00:23<01:30,  1.66it/s][A
 33%|███▎      | 72/221 [00:23<01:11,  2.07it/s][A
 33%|███▎      | 73/221 [00:23<01:03,  2.34it/s][A
 33%|███▎      | 74/221 [00:23<00:52,  2.79it/s][A
 34%|███▍      | 75/221 [00:24<00:55,  2.64it/s][A
 34%|███▍      | 76/221 [00:24<00:46,  3.12it/s][A
 35%|███▍      | 77/221 [00:24<00:38,  3.77it/s][A[h264 @ 0x5624171d0640] mmco: unref short failure
[h264 @ 0x5624171d0640] mmco: unref short failure

 35%|███▌      | 78/221 [00:26<01:54,  1.25it/s][A
 36%|███▌      | 79/221 [00:27<01:47,  1.32it/s][A
 36%|███▌      | 80/221 [00:27<01:24,  1.68it/s][A[h264 @ 0x556b4815cd40] mmco: unref short failure
[h264 @ 0x556b4815cd40] mmco: unref short failure

 37%|███▋      | 81/221 [00:27<01:08,  2.04it/s][A
 37%|███▋      | 82/221 [00:28<00:57,  2.40it/s][A
 38%|███▊      | 83/221 [00:28<00:46,  2.98it/s][A
 38%|███▊      | 84/221 [00:28<00:38,  3.60it/s][A
 38%|███▊      | 85/221 [00:28<00:30,  4.40it/s][A
 39%|███▉      | 86/221 [00:28<00:27,  4.83it/s][A
 39%|███▉      | 87/221 [00:29<00:36,  3.65it/s][A
 40%|███▉      | 88/221 [00:29<00:41,  3.18it/s][A
 40%|████      | 89/221 [00:32<02:25,  1.10s/it][A
 41%|████      | 90/221 [00:32<01:50,  1.19it/s][A
 41%|████      | 91/221 [00:32<01:20,  1.61it/s][A
 42%|████▏     | 92/221 [00:32<01:03,  2.04it/s][A
 42%|████▏     | 93/221 [00:33<01:00,  2.12it/s][A
 43%|████▎     | 94/221 [00:33<00:52,  2.43it/s][A
 43%|████▎     | 95/221 [00:33<00:45,  2.78it/s][A[h264 @ 0x559be9a4d100] mmco: unref short failure

 43%|████▎     | 96/221 [00:34<00:41,  2.98it/s][A
 44%|████▍     | 98/221 [00:34<00:28,  4.34it/s][A
 45%|████▌     | 100/221 [00:34<00:23,  5.09it/s][A
 46%|████▌     | 102/221 [00:34<00:22,  5.36it/s][A
 47%|████▋     | 103/221 [00:35<00:20,  5.88it/s][A
 48%|████▊     | 105/221 [00:35<00:17,  6.58it/s][A
 48%|████▊     | 106/221 [00:36<00:38,  2.99it/s][A[h264 @ 0x556b3800f940] mmco: unref short failure

 48%|████▊     | 107/221 [00:36<00:34,  3.27it/s][A
 49%|████▉     | 108/221 [00:36<00:33,  3.34it/s][A
 49%|████▉     | 109/221 [00:37<00:30,  3.64it/s][A
 50%|████▉     | 110/221 [00:37<00:26,  4.17it/s][A
 50%|█████     | 111/221 [00:37<00:32,  3.36it/s][A
 51%|█████     | 112/221 [00:37<00:28,  3.78it/s][A
 51%|█████     | 113/221 [00:38<00:37,  2.90it/s][A
 52%|█████▏    | 114/221 [00:38<00:33,  3.23it/s][A[h264 @ 0x556b38c6a5c0] mmco: unref short failure
[h264 @ 0x56241c781700] mmco: unref short failure
[h264 @ 0x56241c781700] mmco: unref short failure

 52%|█████▏    | 116/221 [00:42<02:02,  1.17s/it][A
 53%|█████▎    | 117/221 [00:43<01:38,  1.06it/s][A
 53%|█████▎    | 118/221 [00:43<01:21,  1.27it/s][A
 54%|█████▍    | 120/221 [00:43<00:52,  1.92it/s][A
 55%|█████▌    | 122/221 [00:44<00:38,  2.59it/s][A
 56%|█████▌    | 123/221 [00:44<00:32,  3.01it/s][A
 56%|█████▌    | 124/221 [00:44<00:35,  2.77it/s][A
 57%|█████▋    | 125/221 [00:45<00:33,  2.84it/s][A
 57%|█████▋    | 126/221 [00:45<00:35,  2.65it/s][A
 57%|█████▋    | 127/221 [00:45<00:34,  2.69it/s][A
 58%|█████▊    | 128/221 [00:46<00:36,  2.57it/s][A
 58%|█████▊    | 129/221 [00:46<00:29,  3.14it/s][A
 59%|█████▉    | 130/221 [00:46<00:25,  3.64it/s][A
 60%|█████▉    | 132/221 [00:47<00:19,  4.48it/s][A
 60%|██████    | 133/221 [00:47<00:25,  3.48it/s][A
 61%|██████    | 134/221 [00:47<00:22,  3.90it/s][A
 61%|██████    | 135/221 [00:47<00:23,  3.65it/s][A
 62%|██████▏   | 136/221 [00:48<00:25,  3.28it/s][A
 62%|██████▏   | 137/221 [00:48<00:23,  3.54it/s][A
 62%|██████▏   | 138/221 [00:49<00:29,  2.81it/s][A
 63%|██████▎   | 139/221 [00:49<00:27,  2.94it/s][A
 63%|██████▎   | 140/221 [00:49<00:26,  3.01it/s][A
 64%|██████▍   | 141/221 [00:49<00:23,  3.45it/s][A
 64%|██████▍   | 142/221 [00:50<00:36,  2.17it/s][A
 65%|██████▍   | 143/221 [00:51<00:33,  2.31it/s][A
 65%|██████▌   | 144/221 [00:51<00:26,  2.95it/s][A
 66%|██████▌   | 146/221 [00:51<00:16,  4.53it/s][A
 67%|██████▋   | 147/221 [00:51<00:14,  5.06it/s][A[h264 @ 0x55a033edcac0] mmco: unref short failure
[h264 @ 0x55a033edcac0] mmco: unref short failure

 67%|██████▋   | 148/221 [00:51<00:14,  4.88it/s][A
 67%|██████▋   | 149/221 [00:51<00:12,  5.55it/s][A
 68%|██████▊   | 150/221 [00:52<00:11,  6.24it/s][A
 68%|██████▊   | 151/221 [00:52<00:18,  3.77it/s][A
 69%|██████▉   | 152/221 [00:52<00:16,  4.17it/s][A
 69%|██████▉   | 153/221 [00:53<00:19,  3.44it/s][A
 70%|██████▉   | 154/221 [00:53<00:26,  2.48it/s][A
 71%|███████   | 156/221 [00:54<00:18,  3.55it/s][A
 71%|███████   | 157/221 [00:58<01:15,  1.17s/it][A
 71%|███████▏  | 158/221 [00:58<00:56,  1.11it/s][A
 72%|███████▏  | 159/221 [00:58<00:43,  1.42it/s][A
 72%|███████▏  | 160/221 [00:58<00:33,  1.84it/s][A
 73%|███████▎  | 161/221 [00:58<00:26,  2.24it/s][A
 73%|███████▎  | 162/221 [00:58<00:21,  2.78it/s][A
 74%|███████▍  | 163/221 [00:59<00:18,  3.13it/s][A
 74%|███████▍  | 164/221 [00:59<00:15,  3.56it/s][A
 75%|███████▍  | 165/221 [00:59<00:12,  4.39it/s][A
 75%|███████▌  | 166/221 [00:59<00:15,  3.48it/s][A
 76%|███████▌  | 167/221 [00:59<00:12,  4.27it/s][A[h264 @ 0x559beda38880] mmco: unref short failure
[h264 @ 0x559beda38880] mmco: unref short failure
[h264 @ 0x559beda38880] mmco: unref short failure
[h264 @ 0x559beda38880] mmco: unref short failure
[h264 @ 0x559beda38880] mmco: unref short failure
[h264 @ 0x559beda38880] mmco: unref short failure

 76%|███████▌  | 168/221 [01:04<01:16,  1.44s/it][A
 76%|███████▋  | 169/221 [01:04<00:56,  1.08s/it][A
 77%|███████▋  | 170/221 [01:04<00:42,  1.20it/s][A
 77%|███████▋  | 171/221 [01:04<00:31,  1.60it/s][A
 78%|███████▊  | 172/221 [01:04<00:23,  2.04it/s][A
 79%|███████▊  | 174/221 [01:05<00:13,  3.39it/s][A
 79%|███████▉  | 175/221 [01:05<00:13,  3.46it/s][A
 80%|███████▉  | 176/221 [01:05<00:12,  3.73it/s][A
 81%|████████  | 178/221 [01:05<00:10,  4.22it/s][A
 81%|████████  | 179/221 [01:07<00:23,  1.78it/s][A
 82%|████████▏ | 181/221 [01:07<00:15,  2.55it/s][A
 82%|████████▏ | 182/221 [01:07<00:13,  2.93it/s][A
 83%|████████▎ | 183/221 [01:08<00:11,  3.45it/s][A
 83%|████████▎ | 184/221 [01:08<00:10,  3.55it/s][A
 84%|████████▍ | 186/221 [01:08<00:08,  4.23it/s][A
 85%|████████▍ | 187/221 [01:08<00:07,  4.82it/s][A
 85%|████████▌ | 188/221 [01:09<00:08,  4.06it/s][A
 86%|████████▌ | 189/221 [01:09<00:08,  3.98it/s][A
 86%|████████▌ | 190/221 [01:09<00:07,  4.26it/s][A
 87%|████████▋ | 192/221 [01:09<00:05,  5.11it/s][A
 88%|████████▊ | 194/221 [01:10<00:05,  4.67it/s][A
 89%|████████▊ | 196/221 [01:10<00:04,  6.03it/s][A
 90%|████████▉ | 198/221 [01:10<00:03,  6.48it/s][A
 90%|█████████ | 199/221 [01:10<00:03,  6.91it/s][A[h264 @ 0x559c08d84180] mmco: unref short failure
[h264 @ 0x559c08d84180] mmco: unref short failure

 90%|█████████ | 200/221 [01:11<00:03,  5.56it/s][A
 91%|█████████ | 201/221 [01:11<00:03,  5.30it/s][A
 91%|█████████▏| 202/221 [01:11<00:03,  5.51it/s][A
 92%|█████████▏| 203/221 [01:11<00:02,  6.22it/s][A[h264 @ 0x55a034714340] mmco: unref short failure

 93%|█████████▎| 205/221 [01:11<00:01,  8.04it/s][A[h264 @ 0x55a03d8e5640] mmco: unref short failure
[h264 @ 0x55a03d8e5640] mmco: unref short failure

 93%|█████████▎| 206/221 [01:12<00:03,  4.96it/s][A
 94%|█████████▍| 208/221 [01:12<00:01,  6.64it/s][A
 95%|█████████▌| 211/221 [01:12<00:01,  6.65it/s][A
 96%|█████████▋| 213/221 [01:13<00:01,  7.62it/s][A
 97%|█████████▋| 214/221 [01:13<00:01,  5.32it/s][A
 97%|█████████▋| 215/221 [01:13<00:01,  5.35it/s][A
 98%|█████████▊| 216/221 [01:13<00:00,  5.56it/s][A
 98%|█████████▊| 217/221 [01:15<00:01,  2.13it/s][A
 99%|█████████▊| 218/221 [01:15<00:01,  2.54it/s][A
 99%|█████████▉| 219/221 [01:15<00:00,  2.85it/s][A[h264 @ 0x56241a044580] mmco: unref short failure
[h264 @ 0x56241a044580] mmco: unref short failure
[h264 @ 0x56241a044580] mmco: unref short failure
[h264 @ 0x56241a044580] mmco: unref short failure

100%|█████████▉| 220/221 [01:19<00:01,  1.45s/it][A
100%|██████████| 221/221 [01:20<00:00,  1.07s/it][A100%|██████████| 221/221 [01:20<00:00,  2.76it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:52,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:40,  3.49it/s][A
 37%|███▋      | 81/221 [00:21<00:39,  3.58it/s][A
 37%|███▋      | 82/221 [00:21<00:38,  3.64it/s][A
 38%|███▊      | 83/221 [00:21<00:37,  3.68it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.71it/s][A
 38%|███▊      | 85/221 [00:22<00:36,  3.74it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.75it/s][A
 39%|███▉      | 87/221 [00:23<00:35,  3.76it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.77it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.78it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.78it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.78it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:28<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:32<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:19,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:42<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:47<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:52<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:56<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:57<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.78it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:29,  7.40it/s][A
  1%|          | 2/221 [00:00<00:43,  4.98it/s][A
  1%|▏         | 3/221 [00:00<00:48,  4.51it/s][A
  2%|▏         | 4/221 [00:00<00:43,  5.00it/s][A
  2%|▏         | 5/221 [00:01<00:43,  4.93it/s][A
  3%|▎         | 7/221 [00:01<00:41,  5.19it/s][A
  4%|▎         | 8/221 [00:01<00:50,  4.22it/s][A
  4%|▍         | 9/221 [00:01<00:50,  4.17it/s][A
  5%|▍         | 10/221 [00:02<01:11,  2.94it/s][A
  5%|▍         | 11/221 [00:02<01:01,  3.44it/s][A
  5%|▌         | 12/221 [00:02<00:52,  3.98it/s][A
  6%|▌         | 13/221 [00:03<01:31,  2.27it/s][A
  6%|▋         | 14/221 [00:03<01:11,  2.88it/s][A
  7%|▋         | 15/221 [00:04<01:03,  3.26it/s][A
  7%|▋         | 16/221 [00:04<01:09,  2.95it/s][A
  8%|▊         | 17/221 [00:05<01:23,  2.45it/s][A
  8%|▊         | 18/221 [00:05<01:10,  2.89it/s][A
  9%|▊         | 19/221 [00:05<00:59,  3.40it/s][A
 10%|▉         | 21/221 [00:05<00:43,  4.56it/s][A
 10%|▉         | 22/221 [00:05<00:41,  4.80it/s][A
 11%|█         | 24/221 [00:06<00:34,  5.69it/s][A
 11%|█▏        | 25/221 [00:06<00:34,  5.61it/s][A
 12%|█▏        | 26/221 [00:06<00:36,  5.30it/s][A
 12%|█▏        | 27/221 [00:06<00:33,  5.77it/s][A
 13%|█▎        | 28/221 [00:07<00:43,  4.45it/s][A
 13%|█▎        | 29/221 [00:07<00:42,  4.55it/s][A
 14%|█▎        | 30/221 [00:07<00:46,  4.10it/s][A
 14%|█▍        | 31/221 [00:07<00:43,  4.33it/s][A
 14%|█▍        | 32/221 [00:07<00:36,  5.12it/s][A
 15%|█▍        | 33/221 [00:08<00:37,  5.03it/s][A
 15%|█▌        | 34/221 [00:08<00:40,  4.66it/s][A
 16%|█▌        | 35/221 [00:08<00:46,  4.03it/s][A
 16%|█▋        | 36/221 [00:08<00:49,  3.76it/s][A
 17%|█▋        | 37/221 [00:09<00:42,  4.29it/s][A
 17%|█▋        | 38/221 [00:09<00:46,  3.95it/s][A
 18%|█▊        | 39/221 [00:09<00:43,  4.20it/s][A
 18%|█▊        | 40/221 [00:10<00:51,  3.52it/s][A
 19%|█▊        | 41/221 [00:10<00:44,  4.01it/s][A
 19%|█▉        | 42/221 [00:10<00:37,  4.73it/s][A
 19%|█▉        | 43/221 [00:10<00:44,  4.02it/s][A
 20%|█▉        | 44/221 [00:10<00:46,  3.83it/s][A
 20%|██        | 45/221 [00:11<00:48,  3.59it/s][A
 21%|██        | 46/221 [00:11<00:44,  3.93it/s][A
 21%|██▏       | 47/221 [00:11<00:44,  3.94it/s][A
 22%|██▏       | 48/221 [00:11<00:37,  4.59it/s][A
 22%|██▏       | 49/221 [00:12<00:38,  4.41it/s][A
 23%|██▎       | 50/221 [00:12<00:55,  3.09it/s][A
 23%|██▎       | 51/221 [00:12<00:46,  3.67it/s][A
 24%|██▎       | 52/221 [00:13<00:46,  3.62it/s][A
 24%|██▍       | 53/221 [00:13<00:39,  4.28it/s][A
 24%|██▍       | 54/221 [00:13<00:50,  3.33it/s][A
 25%|██▍       | 55/221 [00:13<00:49,  3.38it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.80it/s][A
 26%|██▌       | 57/221 [00:14<00:45,  3.61it/s][A
 26%|██▌       | 58/221 [00:14<00:51,  3.17it/s][A
 27%|██▋       | 59/221 [00:15<00:44,  3.60it/s][A
 27%|██▋       | 60/221 [00:15<00:37,  4.26it/s][A
 28%|██▊       | 61/221 [00:15<00:35,  4.46it/s][A
 28%|██▊       | 62/221 [00:15<00:36,  4.31it/s][A
 29%|██▊       | 63/221 [00:15<00:35,  4.43it/s][A
 29%|██▉       | 64/221 [00:16<00:42,  3.68it/s][A
 29%|██▉       | 65/221 [00:16<00:37,  4.12it/s][A
 30%|██▉       | 66/221 [00:16<00:50,  3.08it/s][A
 30%|███       | 67/221 [00:17<00:51,  2.97it/s][A
 31%|███       | 68/221 [00:17<00:43,  3.50it/s][A
 31%|███       | 69/221 [00:18<01:05,  2.32it/s][A
 32%|███▏      | 70/221 [00:18<00:53,  2.80it/s][A
 32%|███▏      | 71/221 [00:18<00:46,  3.22it/s][A
 33%|███▎      | 72/221 [00:19<00:51,  2.89it/s][A
 33%|███▎      | 73/221 [00:19<00:50,  2.93it/s][A
 33%|███▎      | 74/221 [00:19<00:43,  3.40it/s][A
 34%|███▍      | 75/221 [00:19<00:41,  3.51it/s][A
 34%|███▍      | 76/221 [00:20<00:39,  3.71it/s][A
 35%|███▍      | 77/221 [00:20<00:41,  3.48it/s][A
 35%|███▌      | 78/221 [00:20<00:36,  3.92it/s][A
 36%|███▌      | 79/221 [00:21<00:46,  3.06it/s][A
 36%|███▌      | 80/221 [00:21<00:41,  3.42it/s][A
 37%|███▋      | 81/221 [00:21<00:37,  3.72it/s][A
 37%|███▋      | 82/221 [00:21<00:42,  3.27it/s][A
 38%|███▊      | 83/221 [00:22<00:43,  3.15it/s][A
 38%|███▊      | 84/221 [00:22<00:42,  3.20it/s][A
 38%|███▊      | 85/221 [00:22<00:34,  3.97it/s][A
 39%|███▉      | 86/221 [00:22<00:36,  3.74it/s][A
 39%|███▉      | 87/221 [00:23<00:43,  3.05it/s][A
 40%|███▉      | 88/221 [00:23<00:49,  2.68it/s][A
 40%|████      | 89/221 [00:24<00:44,  2.94it/s][A
 41%|████      | 90/221 [00:24<00:47,  2.75it/s][A
 41%|████      | 91/221 [00:24<00:39,  3.32it/s][A
 42%|████▏     | 92/221 [00:25<00:43,  2.98it/s][A
 42%|████▏     | 93/221 [00:25<00:58,  2.19it/s][A
 43%|████▎     | 94/221 [00:26<00:51,  2.45it/s][A
 43%|████▎     | 95/221 [00:26<00:45,  2.77it/s][A
 43%|████▎     | 96/221 [00:26<00:39,  3.17it/s][A
 44%|████▍     | 97/221 [00:26<00:35,  3.50it/s][A
 44%|████▍     | 98/221 [00:27<00:33,  3.62it/s][A
 45%|████▍     | 99/221 [00:27<00:30,  3.95it/s][A
 45%|████▌     | 100/221 [00:27<00:32,  3.74it/s][A
 46%|████▌     | 101/221 [00:27<00:29,  4.01it/s][A
 46%|████▌     | 102/221 [00:28<00:43,  2.72it/s][A
 47%|████▋     | 103/221 [00:28<00:34,  3.40it/s][A
 47%|████▋     | 104/221 [00:28<00:29,  3.96it/s][A
 48%|████▊     | 105/221 [00:29<00:30,  3.82it/s][A
 48%|████▊     | 106/221 [00:29<00:35,  3.28it/s][A
 48%|████▊     | 107/221 [00:29<00:30,  3.70it/s][A
 49%|████▉     | 108/221 [00:29<00:31,  3.62it/s][A
 50%|████▉     | 110/221 [00:30<00:24,  4.50it/s][A
 50%|█████     | 111/221 [00:30<00:26,  4.16it/s][A
 51%|█████     | 112/221 [00:30<00:26,  4.17it/s][A
 51%|█████     | 113/221 [00:30<00:24,  4.47it/s][A
 52%|█████▏    | 115/221 [00:31<00:20,  5.06it/s][A
 52%|█████▏    | 116/221 [00:31<00:22,  4.74it/s][A
 53%|█████▎    | 117/221 [00:31<00:22,  4.59it/s][A
 53%|█████▎    | 118/221 [00:31<00:22,  4.67it/s][A
 54%|█████▍    | 119/221 [00:32<00:27,  3.72it/s][A
 54%|█████▍    | 120/221 [00:32<00:24,  4.10it/s][A
 55%|█████▍    | 121/221 [00:32<00:20,  4.91it/s][A
 55%|█████▌    | 122/221 [00:32<00:22,  4.44it/s][A
 56%|█████▌    | 123/221 [00:33<00:25,  3.88it/s][A
 56%|█████▌    | 124/221 [00:33<00:23,  4.06it/s][A
 57%|█████▋    | 125/221 [00:33<00:26,  3.59it/s][A
 57%|█████▋    | 126/221 [00:34<00:23,  4.03it/s][A
 57%|█████▋    | 127/221 [00:34<00:28,  3.30it/s][A
 58%|█████▊    | 128/221 [00:34<00:27,  3.43it/s][A
 58%|█████▊    | 129/221 [00:34<00:22,  4.15it/s][A
 59%|█████▉    | 130/221 [00:35<00:22,  4.12it/s][A
 59%|█████▉    | 131/221 [00:35<00:18,  4.82it/s][A
 60%|█████▉    | 132/221 [00:35<00:21,  4.16it/s][A
 60%|██████    | 133/221 [00:35<00:24,  3.64it/s][A
 61%|██████    | 134/221 [00:36<00:31,  2.79it/s][A
 61%|██████    | 135/221 [00:36<00:30,  2.80it/s][A
 62%|██████▏   | 136/221 [00:37<00:27,  3.13it/s][A
 62%|██████▏   | 137/221 [00:37<00:22,  3.73it/s][A
 62%|██████▏   | 138/221 [00:37<00:23,  3.50it/s][A
 63%|██████▎   | 139/221 [00:37<00:26,  3.11it/s][A
 63%|██████▎   | 140/221 [00:38<00:25,  3.18it/s][A
 64%|██████▍   | 141/221 [00:38<00:22,  3.53it/s][A
 64%|██████▍   | 142/221 [00:38<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:39<00:26,  2.93it/s][A
 65%|██████▌   | 144/221 [00:39<00:27,  2.84it/s][A
 66%|██████▌   | 145/221 [00:39<00:21,  3.55it/s][A
 67%|██████▋   | 147/221 [00:40<00:17,  4.25it/s][A
 67%|██████▋   | 148/221 [00:40<00:20,  3.57it/s][A
 67%|██████▋   | 149/221 [00:40<00:19,  3.67it/s][A
 68%|██████▊   | 150/221 [00:40<00:18,  3.77it/s][A
 68%|██████▊   | 151/221 [00:41<00:21,  3.24it/s][A
 69%|██████▉   | 152/221 [00:42<00:28,  2.39it/s][A
 69%|██████▉   | 153/221 [00:42<00:22,  2.97it/s][A
 70%|██████▉   | 154/221 [00:42<00:20,  3.32it/s][A
 70%|███████   | 155/221 [00:42<00:17,  3.67it/s][A
 71%|███████   | 156/221 [00:42<00:19,  3.26it/s][A
 71%|███████   | 157/221 [00:43<00:19,  3.26it/s][A
 71%|███████▏  | 158/221 [00:43<00:18,  3.46it/s][A
 72%|███████▏  | 159/221 [00:43<00:14,  4.16it/s][A
 72%|███████▏  | 160/221 [00:43<00:14,  4.27it/s][A
 73%|███████▎  | 161/221 [00:44<00:18,  3.20it/s][A
 73%|███████▎  | 162/221 [00:44<00:16,  3.57it/s][A
 74%|███████▍  | 163/221 [00:44<00:15,  3.70it/s][A
 74%|███████▍  | 164/221 [00:44<00:13,  4.36it/s][A
 75%|███████▍  | 165/221 [00:45<00:12,  4.44it/s][A
 75%|███████▌  | 166/221 [00:45<00:12,  4.43it/s][A
 76%|███████▌  | 167/221 [00:45<00:10,  5.28it/s][A
 76%|███████▌  | 168/221 [00:45<00:12,  4.39it/s][A
 76%|███████▋  | 169/221 [00:45<00:10,  5.13it/s][A
 77%|███████▋  | 170/221 [00:46<00:15,  3.35it/s][A
 77%|███████▋  | 171/221 [00:46<00:13,  3.76it/s][A
 78%|███████▊  | 172/221 [00:46<00:12,  3.92it/s][A
 78%|███████▊  | 173/221 [00:47<00:13,  3.61it/s][A
 79%|███████▊  | 174/221 [00:47<00:15,  2.94it/s][A
 79%|███████▉  | 175/221 [00:48<00:16,  2.82it/s][A
 80%|███████▉  | 176/221 [00:48<00:14,  3.08it/s][A
 80%|████████  | 177/221 [00:48<00:13,  3.28it/s][A
 81%|████████  | 178/221 [00:48<00:14,  3.07it/s][A
 81%|████████  | 179/221 [00:49<00:12,  3.29it/s][A
 81%|████████▏ | 180/221 [00:49<00:10,  3.83it/s][A
 82%|████████▏ | 181/221 [00:49<00:10,  3.86it/s][A
 82%|████████▏ | 182/221 [00:50<00:12,  3.21it/s][A
 83%|████████▎ | 183/221 [00:50<00:11,  3.24it/s][A
 83%|████████▎ | 184/221 [00:50<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:50<00:09,  3.84it/s][A
 84%|████████▍ | 186/221 [00:51<00:11,  2.98it/s][A
 85%|████████▍ | 187/221 [00:51<00:09,  3.43it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.43it/s][A
 86%|████████▌ | 189/221 [00:52<00:08,  3.68it/s][A
 86%|████████▌ | 190/221 [00:52<00:09,  3.30it/s][A
 86%|████████▋ | 191/221 [00:52<00:07,  3.90it/s][A
 87%|████████▋ | 192/221 [00:52<00:07,  4.04it/s][A
 87%|████████▋ | 193/221 [00:52<00:06,  4.59it/s][A
 88%|████████▊ | 194/221 [00:53<00:06,  4.08it/s][A
 88%|████████▊ | 195/221 [00:53<00:06,  4.30it/s][A
 89%|████████▊ | 196/221 [00:53<00:07,  3.37it/s][A
 89%|████████▉ | 197/221 [00:54<00:06,  3.67it/s][A
 90%|████████▉ | 198/221 [00:54<00:07,  3.01it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.38it/s][A
 90%|█████████ | 200/221 [00:55<00:07,  2.97it/s][A
 91%|█████████ | 201/221 [00:55<00:05,  3.43it/s][A
 91%|█████████▏| 202/221 [00:55<00:06,  3.16it/s][A
 92%|█████████▏| 203/221 [00:55<00:04,  3.65it/s][A
 92%|█████████▏| 204/221 [00:56<00:05,  3.37it/s][A
 93%|█████████▎| 205/221 [00:56<00:03,  4.09it/s][A
 93%|█████████▎| 206/221 [00:56<00:04,  3.35it/s][A
 94%|█████████▎| 207/221 [00:57<00:03,  3.52it/s][A
 94%|█████████▍| 208/221 [00:57<00:03,  3.70it/s][A
 95%|█████████▍| 209/221 [00:57<00:02,  4.06it/s][A
 95%|█████████▌| 210/221 [00:57<00:02,  4.53it/s][A
 95%|█████████▌| 211/221 [00:58<00:02,  3.91it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  3.68it/s][A
 96%|█████████▋| 213/221 [00:58<00:02,  3.88it/s][A
 97%|█████████▋| 214/221 [00:59<00:02,  2.53it/s][A
 97%|█████████▋| 215/221 [00:59<00:02,  2.92it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.10it/s][A
 98%|█████████▊| 217/221 [01:00<00:01,  3.09it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.15it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  2.95it/s][A
100%|█████████▉| 220/221 [01:01<00:00,  3.43it/s][A
100%|██████████| 221/221 [01:01<00:00,  3.79it/s][A100%|██████████| 221/221 [01:01<00:00,  3.61it/s]
09/10/2024 00:26:31 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 1349--===========

09/10/2024 00:26:31 - INFO - __main__ -   {'area_r1': 38.1, 'area_recall': '38.1/61.7/71.2', 'area_ravg': 57.0}
09/10/2024 00:26:31 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 1349--===========

09/10/2024 00:26:31 - INFO - __main__ -   {'forward_r1': 36.8, 'forward_recall': '36.8/65.4/76.6', 'forward_ravg': 59.6}
09/10/2024 00:26:31 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 1349--===========

09/10/2024 00:26:31 - INFO - __main__ -   {'area_video_r1': 37.7, 'area_video_recall': '37.7/66.3/77.3', 'area_video_ravg': 60.4}
09/10/2024 00:26:31 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/10/2024 00:26:31 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/10/2024 00:26:31 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 1349--===========

09/10/2024 00:26:31 - INFO - __main__ -   {'area_video_r1': 52.7, 'area_video_recall': '52.7/73.8/81.2', 'area_video_ravg': 69.2, 'area_video_back_r1': 47.6, 'area_video_back_recall': '47.6/73.9/82.2', 'area_video_back_ravg': 67.9}
09/10/2024 00:26:31 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/10/2024 00:26:31 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/10/2024 00:26:31 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 1349--===========

09/10/2024 00:26:31 - INFO - __main__ -   {'video_r1': 42.6, 'video_recall': '42.6/71.6/81.6', 'video_ravg': 65.3}
09/10/2024 00:26:31 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/10/2024 00:26:31 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/10/2024 00:26:31 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 1349--===========

09/10/2024 00:26:31 - INFO - __main__ -   {'video_r1': 52.1, 'video_recall': '52.1/75.2/83.0', 'video_ravg': 70.1}
09/10/2024 00:26:31 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/10/2024 00:26:31 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/10/2024 00:26:52 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.00913955457508564, 'loss_ret%tv%ta--finetune_area/loss_area': 1.07180917263031, 'loss_ret%tv%ta--finetune_area/total_loss': 1.0809487104415894}
 69%|██████▉   | 1350/1945 [7:21:33<20:16:41, 122.69s/it][h264 @ 0x556b2df93040] mmco: unref short failure
 69%|██████▉   | 1351/1945 [7:21:37<14:23:04, 87.18s/it]  70%|██████▉   | 1352/1945 [7:21:42<10:16:52, 62.42s/it][h264 @ 0x559bf9609280] mmco: unref short failure
[h264 @ 0x559bf9609280] mmco: unref short failure
 70%|██████▉   | 1353/1945 [7:21:47<7:25:52, 45.19s/it]  70%|██████▉   | 1354/1945 [7:21:52<5:27:07, 33.21s/it][h264 @ 0x55a032f37b80] mmco: unref short failure
[h264 @ 0x55a032f37b80] mmco: unref short failure
 70%|██████▉   | 1355/1945 [7:21:58<4:06:36, 25.08s/it][h264 @ 0x559bf07ab680] mmco: unref short failure
[h264 @ 0x55a033229240] mmco: unref short failure
 70%|██████▉   | 1356/1945 [7:22:06<3:16:24, 20.01s/it][h264 @ 0x559bf06f9f80] mmco: unref short failure
[h264 @ 0x562423e17540] mmco: unref short failure
[h264 @ 0x562423e17540] mmco: unref short failure
 70%|██████▉   | 1357/1945 [7:22:14<2:38:57, 16.22s/it][h264 @ 0x562423e17540] mmco: unref short failure
[h264 @ 0x5624355c0f40] mmco: unref short failure
[h264 @ 0x5624355c0f40] mmco: unref short failure
[h264 @ 0x55a0374cb580] mmco: unref short failure
 70%|██████▉   | 1358/1945 [7:22:21<2:12:51, 13.58s/it][h264 @ 0x55a0373de100] mmco: unref short failure
[h264 @ 0x55a0373de100] mmco: unref short failure
[h264 @ 0x556b2e668880] mmco: unref short failure
[h264 @ 0x559bf3f77640] mmco: unref short failure
[h264 @ 0x559bf3f77640] mmco: unref short failure
[h264 @ 0x562417101e80] mmco: unref short failure
[h264 @ 0x562417101e80] mmco: unref short failure
 70%|██████▉   | 1359/1945 [7:22:29<1:56:26, 11.92s/it][h264 @ 0x55a032bf8780] mmco: unref short failure
[h264 @ 0x55a032bf8780] mmco: unref short failure
 70%|██████▉   | 1360/1945 [7:22:36<1:42:30, 10.51s/it][h264 @ 0x55a034713a80] mmco: unref short failure
[h264 @ 0x55a034713a80] mmco: unref short failure
 70%|██████▉   | 1361/1945 [7:22:44<1:33:55,  9.65s/it][h264 @ 0x556b3b5e0a40] mmco: unref short failure
[h264 @ 0x556b3b5e0a40] mmco: unref short failure
[h264 @ 0x556b37a33280] mmco: unref short failure
 70%|███████   | 1362/1945 [7:22:53<1:30:56,  9.36s/it][h264 @ 0x56241a044380] mmco: unref short failure
[h264 @ 0x56241a044380] mmco: unref short failure
[h264 @ 0x56241a044380] mmco: unref short failure
[h264 @ 0x56241a044380] mmco: unref short failure
[h264 @ 0x56241a044380] mmco: unref short failure
[h264 @ 0x56241a044380] mmco: unref short failure
 70%|███████   | 1363/1945 [7:23:00<1:24:29,  8.71s/it][h264 @ 0x55a0366b42c0] mmco: unref short failure
[h264 @ 0x55a0366b42c0] mmco: unref short failure
 70%|███████   | 1364/1945 [7:23:07<1:19:02,  8.16s/it][h264 @ 0x556b2d56ba40] mmco: unref short failure
 70%|███████   | 1365/1945 [7:23:14<1:17:03,  7.97s/it][h264 @ 0x55a036281ac0] mmco: unref short failure
 70%|███████   | 1366/1945 [7:23:21<1:14:19,  7.70s/it][h264 @ 0x562419734fc0] mmco: unref short failure
[h264 @ 0x562419734fc0] mmco: unref short failure
[h264 @ 0x562419734fc0] mmco: unref short failure
[h264 @ 0x562419734fc0] mmco: unref short failure
 70%|███████   | 1367/1945 [7:23:28<1:11:25,  7.41s/it][h264 @ 0x55a03999f840] mmco: unref short failure
[h264 @ 0x556b4f4290c0] mmco: unref short failure
[h264 @ 0x556b4f4290c0] mmco: unref short failure
[h264 @ 0x562426443880] mmco: unref short failure
[h264 @ 0x562426443880] mmco: unref short failure
 70%|███████   | 1368/1945 [7:23:37<1:15:22,  7.84s/it][h264 @ 0x559be94024c0] mmco: unref short failure
[h264 @ 0x559be94024c0] mmco: unref short failure
[h264 @ 0x56241c09e640] mmco: unref short failure
[h264 @ 0x56241c09e640] mmco: unref short failure
 70%|███████   | 1369/1945 [7:23:49<1:28:48,  9.25s/it][h264 @ 0x562419290080] mmco: unref short failure
[h264 @ 0x562419290080] mmco: unref short failure
 70%|███████   | 1370/1945 [7:23:59<1:28:24,  9.22s/it] 70%|███████   | 1371/1945 [7:24:06<1:22:28,  8.62s/it] 71%|███████   | 1372/1945 [7:24:17<1:28:47,  9.30s/it][h264 @ 0x556b37a33000] mmco: unref short failure
[h264 @ 0x559bf4b6c4c0] mmco: unref short failure
[h264 @ 0x559bf4b6c4c0] mmco: unref short failure
[h264 @ 0x559bf4b6c4c0] mmco: unref short failure
[h264 @ 0x559bf4b6c4c0] mmco: unref short failure
 71%|███████   | 1373/1945 [7:24:24<1:22:54,  8.70s/it][h264 @ 0x562419c561c0] mmco: unref short failure
[h264 @ 0x55a055857e40] mmco: unref short failure
[h264 @ 0x56241a04ab40] mmco: unref short failure
[h264 @ 0x56241a04ab40] mmco: unref short failure
[h264 @ 0x559bf1543a80] mmco: unref short failure
[h264 @ 0x55a0336c6400] mmco: unref short failure
[h264 @ 0x55a0336c6400] mmco: unref short failure
[h264 @ 0x559be9aa94c0] mmco: unref short failure
[h264 @ 0x559be9aa94c0] mmco: unref short failure
[h264 @ 0x559be9aa94c0] mmco: unref short failure
[h264 @ 0x559be9aa94c0] mmco: unref short failure
[h264 @ 0x556b37342a80] mmco: unref short failure
 71%|███████   | 1374/1945 [7:25:09<3:06:25, 19.59s/it][h264 @ 0x559bfcf58140] mmco: unref short failure
[h264 @ 0x559bfcf58140] mmco: unref short failure
[h264 @ 0x56242b9f4c00] mmco: unref short failure
[h264 @ 0x56242b9f4c00] mmco: unref short failure
[h264 @ 0x556b32197d40] mmco: unref short failure
 71%|███████   | 1375/1945 [7:25:24<2:54:29, 18.37s/it][h264 @ 0x559be9aa9240] mmco: unref short failure
[h264 @ 0x556b4d2bc2c0] mmco: unref short failure
[h264 @ 0x556b4d2bc2c0] mmco: unref short failure
[h264 @ 0x559be9950a00] mmco: unref short failure
[h264 @ 0x559be9950a00] mmco: unref short failure
[h264 @ 0x559be9950a00] mmco: unref short failure
[h264 @ 0x559be9950a00] mmco: unref short failure
[h264 @ 0x556b32f96d00] mmco: unref short failure
 71%|███████   | 1376/1945 [7:25:38<2:40:43, 16.95s/it][h264 @ 0x56241f25a700] mmco: unref short failure
[h264 @ 0x559c0688f200] mmco: unref short failure
[h264 @ 0x562429547000] mmco: unref short failure
[h264 @ 0x56241fd73080] mmco: unref short failure
 71%|███████   | 1377/1945 [7:25:50<2:25:16, 15.35s/it][h264 @ 0x5624200d1200] mmco: unref short failure
[h264 @ 0x562417bcfc40] mmco: unref short failure
[h264 @ 0x562429cb9300] mmco: unref short failure
 71%|███████   | 1378/1945 [7:26:14<2:51:17, 18.13s/it][h264 @ 0x556b3b313c00] mmco: unref short failure
[h264 @ 0x556b3b313c00] mmco: unref short failure
[h264 @ 0x5624178936c0] mmco: unref short failure
[h264 @ 0x5624178936c0] mmco: unref short failure
 71%|███████   | 1379/1945 [7:26:22<2:21:10, 14.97s/it][h264 @ 0x5624178936c0] mmco: unref short failure
[h264 @ 0x5624178936c0] mmco: unref short failure
[h264 @ 0x56241a9732c0] mmco: unref short failure
 71%|███████   | 1380/1945 [7:26:29<1:59:02, 12.64s/it][h264 @ 0x559beb1b7180] mmco: unref short failure
[h264 @ 0x55a033766100] mmco: unref short failure
[h264 @ 0x5624178a9480] mmco: unref short failure
 71%|███████   | 1381/1945 [7:26:36<1:43:40, 11.03s/it][h264 @ 0x559c05d6cb40] mmco: unref short failure
[h264 @ 0x556b3e653400] mmco: unref short failure
[h264 @ 0x556b30e09880] mmco: unref short failure
[h264 @ 0x556b30e09880] mmco: unref short failure
[h264 @ 0x55a056f65940] mmco: unref short failure
[h264 @ 0x55a056f65940] mmco: unref short failure
[h264 @ 0x55a056f65940] mmco: unref short failure
[h264 @ 0x55a056f65940] mmco: unref short failure
[h264 @ 0x55a035244600] mmco: unref short failure
[h264 @ 0x55a035244600] mmco: unref short failure
 71%|███████   | 1382/1945 [7:27:19<3:11:41, 20.43s/it][h264 @ 0x556b32a8b540] mmco: unref short failure
[h264 @ 0x556b32a8b540] mmco: unref short failure
 71%|███████   | 1383/1945 [7:27:29<2:43:14, 17.43s/it][h264 @ 0x556b329c5640] mmco: unref short failure
[h264 @ 0x556b329c5640] mmco: unref short failure
[h264 @ 0x5624198ed380] mmco: unref short failure
 71%|███████   | 1384/1945 [7:27:46<2:41:03, 17.23s/it][h264 @ 0x562438606fc0] mmco: unref short failure
 71%|███████   | 1385/1945 [7:27:58<2:26:37, 15.71s/it][h264 @ 0x55a03814a7c0] mmco: unref short failure
[h264 @ 0x55a03814a7c0] mmco: unref short failure
[h264 @ 0x556b45a01440] mmco: unref short failure
 71%|███████▏  | 1386/1945 [7:28:22<2:48:15, 18.06s/it][h264 @ 0x56241a04ad40] mmco: unref short failure
[h264 @ 0x56241a04ad40] mmco: unref short failure
 71%|███████▏  | 1387/1945 [7:28:29<2:17:28, 14.78s/it][h264 @ 0x5624382f2bc0] mmco: unref short failure
[h264 @ 0x5624382f2bc0] mmco: unref short failure
[h264 @ 0x55a03ee9d780] mmco: unref short failure
 71%|███████▏  | 1388/1945 [7:28:37<1:58:18, 12.74s/it][h264 @ 0x5624304bcf00] mmco: unref short failure
[h264 @ 0x5624304bcf00] mmco: unref short failure
[h264 @ 0x5624304bcf00] mmco: unref short failure
[h264 @ 0x5624304bcf00] mmco: unref short failure
 71%|███████▏  | 1389/1945 [7:28:43<1:40:38, 10.86s/it][h264 @ 0x56242b9f5540] mmco: unref short failure
[h264 @ 0x56242b9f5540] mmco: unref short failure
[h264 @ 0x559bf29fae80] mmco: unref short failure
[h264 @ 0x559bf29fae80] mmco: unref short failure
[h264 @ 0x56241f450300] mmco: unref short failure
[h264 @ 0x56241f450300] mmco: unref short failure
[h264 @ 0x56241f450300] mmco: unref short failure
[h264 @ 0x56241f450300] mmco: unref short failure
[h264 @ 0x5624381c2cc0] mmco: unref short failure
[h264 @ 0x556b3daab140] mmco: unref short failure
[h264 @ 0x556b3daab140] mmco: unref short failure
[h264 @ 0x559bebc425c0] mmco: unref short failure
[h264 @ 0x55a044266b80] mmco: unref short failure
[h264 @ 0x55a044266b80] mmco: unref short failure
 71%|███████▏  | 1390/1945 [7:29:22<2:56:56, 19.13s/it][h264 @ 0x55a04c90f9c0] mmco: unref short failure
[h264 @ 0x556b2fa83780] mmco: unref short failure
[h264 @ 0x556b2fa83780] mmco: unref short failure
[h264 @ 0x562438307540] mmco: unref short failure
[h264 @ 0x562438307540] mmco: unref short failure
 72%|███████▏  | 1391/1945 [7:29:33<2:36:06, 16.91s/it][h264 @ 0x556b37828000] mmco: unref short failure
[h264 @ 0x556b37828000] mmco: unref short failure
[h264 @ 0x556b30575340] mmco: unref short failure
 72%|███████▏  | 1392/1945 [7:29:56<2:50:22, 18.49s/it][h264 @ 0x562436a7e640] mmco: unref short failure
[h264 @ 0x562436a7e640] mmco: unref short failure
[h264 @ 0x559bea3c0a80] mmco: unref short failure
[h264 @ 0x559bea3c0a80] mmco: unref short failure
[h264 @ 0x559bea3c0a80] mmco: unref short failure
[h264 @ 0x559bea3c0a80] mmco: unref short failure
[h264 @ 0x559bea3c0a80] mmco: unref short failure
[h264 @ 0x559bea3c0a80] mmco: unref short failure
 72%|███████▏  | 1393/1945 [7:30:10<2:39:18, 17.32s/it][h264 @ 0x559c092b9f40] mmco: unref short failure
[h264 @ 0x559c092b9f40] mmco: unref short failure
[h264 @ 0x56242f0b05c0] mmco: unref short failure
[h264 @ 0x56242f0b05c0] mmco: unref short failure
[h264 @ 0x56241e852f00] mmco: unref short failure
[h264 @ 0x56241e852f00] mmco: unref short failure
 72%|███████▏  | 1394/1945 [7:30:22<2:23:15, 15.60s/it][h264 @ 0x55a0408c4000] mmco: unref short failure
[h264 @ 0x55a03753b980] mmco: unref short failure
 72%|███████▏  | 1395/1945 [7:30:29<1:59:54, 13.08s/it] 72%|███████▏  | 1396/1945 [7:30:37<1:46:59, 11.69s/it][h264 @ 0x559bf5bd3a80] mmco: unref short failure
 72%|███████▏  | 1397/1945 [7:30:50<1:48:01, 11.83s/it][h264 @ 0x556b2dcdd380] mmco: unref short failure
[h264 @ 0x562416c2df40] mmco: unref short failure
[h264 @ 0x562416c2df40] mmco: unref short failure
[h264 @ 0x55a03f734cc0] mmco: unref short failure
[h264 @ 0x559c0924a6c0] mmco: unref short failure
[h264 @ 0x559c0924a6c0] mmco: unref short failure
[h264 @ 0x559c0924a6c0] mmco: unref short failure
 72%|███████▏  | 1398/1945 [7:31:20<2:37:20, 17.26s/it][h264 @ 0x55a035654600] mmco: unref short failure
[h264 @ 0x55a035654600] mmco: unref short failure
[h264 @ 0x556b33f72a00] mmco: unref short failure
 72%|███████▏  | 1399/1945 [7:31:41<2:47:43, 18.43s/it]09/10/2024 00:37:03 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/10/2024 00:37:03 - INFO - __main__ -   start running ret%tv validation...
[h264 @ 0x559bf2058f00] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x562424a0f940] mmco: unref short failure
[h264 @ 0x55a032f24380] mmco: unref short failure
[h264 @ 0x55a035ad0a00] mmco: unref short failure
[h264 @ 0x559beda661c0] mmco: unref short failure
[h264 @ 0x559beda661c0] mmco: unref short failure
[h264 @ 0x556b49a47840] mmco: unref short failure
[h264 @ 0x556b49a47840] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x5624294364c0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559bfd14b640] mmco: unref short failure
[h264 @ 0x559bfd14b640] mmco: unref short failure
[h264 @ 0x559bfd14b640] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x562433f36040] mmco: unref short failure
[h264 @ 0x556b3f710240] mmco: unref short failure
[h264 @ 0x556b33ae6900] mmco: unref short failure
[h264 @ 0x556b33ae6900] mmco: unref short failure
[h264 @ 0x556b33ae6900] mmco: unref short failure
[h264 @ 0x556b33ae6900] mmco: unref short failure
[h264 @ 0x559bea101240] mmco: unref short failure
[h264 @ 0x559bea101240] mmco: unref short failure
[h264 @ 0x556b30c99500] mmco: unref short failure
[h264 @ 0x56242dc70dc0] mmco: unref short failure
[h264 @ 0x56242dc70dc0] mmco: unref short failure
[h264 @ 0x55a0394c9940] mmco: unref short failure
[h264 @ 0x55a0394c9940] mmco: unref short failure
[h264 @ 0x556b3f710440] mmco: unref short failure
[h264 @ 0x556b3f710440] mmco: unref short failure
[h264 @ 0x55a04fa74a00] mmco: unref short failure
[h264 @ 0x55a03e041dc0] mmco: unref short failure
[h264 @ 0x55a03e041dc0] mmco: unref short failure
[h264 @ 0x556b33ce7280] mmco: unref short failure
[h264 @ 0x55a047d6be40] mmco: unref short failure
[h264 @ 0x55a047d6be40] mmco: unref short failure
[h264 @ 0x55a047d6be40] mmco: unref short failure
[h264 @ 0x55a047d6be40] mmco: unref short failure
[h264 @ 0x559be90609c0] mmco: unref short failure
[h264 @ 0x559be90609c0] mmco: unref short failure
[h264 @ 0x559be90609c0] mmco: unref short failure
[h264 @ 0x559be90609c0] mmco: unref short failure
[h264 @ 0x556b33f72ec0] mmco: unref short failure
[h264 @ 0x556b33f72ec0] mmco: unref short failure
[h264 @ 0x556b33f72ec0] mmco: unref short failure
[h264 @ 0x556b33f72ec0] mmco: unref short failure
[h264 @ 0x556b3109fc00] mmco: unref short failure
[h264 @ 0x556b3109fc00] mmco: unref short failure
[h264 @ 0x55a032a41a00] mmco: unref short failure
[h264 @ 0x556b3c143c80] mmco: unref short failure
[h264 @ 0x556b3c143c80] mmco: unref short failure
[h264 @ 0x559bf06f9d00] mmco: unref short failure
[h264 @ 0x559bf06f9d00] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<03:20,  1.10it/s][A
  1%|          | 2/221 [00:01<02:46,  1.31it/s][A
  1%|▏         | 3/221 [00:01<01:55,  1.89it/s][A
  2%|▏         | 4/221 [00:01<01:18,  2.76it/s][A
  2%|▏         | 5/221 [00:02<00:58,  3.69it/s][A
  3%|▎         | 6/221 [00:02<00:47,  4.55it/s][A
  3%|▎         | 7/221 [00:02<00:46,  4.58it/s][A
  4%|▎         | 8/221 [00:02<01:03,  3.36it/s][A
  4%|▍         | 9/221 [00:03<00:53,  3.93it/s][A
  5%|▍         | 10/221 [00:03<01:06,  3.16it/s][A
  5%|▍         | 11/221 [00:03<01:01,  3.43it/s][A
  5%|▌         | 12/221 [00:04<01:22,  2.55it/s][A
  6%|▌         | 13/221 [00:04<01:07,  3.06it/s][A
  6%|▋         | 14/221 [00:05<02:07,  1.63it/s][A
  7%|▋         | 15/221 [00:06<01:44,  1.97it/s][A
  7%|▋         | 16/221 [00:06<01:39,  2.06it/s][A
  8%|▊         | 17/221 [00:06<01:21,  2.51it/s][A
  8%|▊         | 18/221 [00:06<01:13,  2.78it/s][A
  9%|▊         | 19/221 [00:07<00:59,  3.39it/s][A
  9%|▉         | 20/221 [00:07<00:52,  3.83it/s][A
 10%|▉         | 21/221 [00:07<00:46,  4.32it/s][A
 10%|▉         | 22/221 [00:07<00:44,  4.51it/s][A
 10%|█         | 23/221 [00:07<00:37,  5.35it/s][A
 11%|█         | 24/221 [00:07<00:33,  5.94it/s][A
 11%|█▏        | 25/221 [00:07<00:30,  6.35it/s][A
 12%|█▏        | 26/221 [00:08<00:39,  4.97it/s][A
 12%|█▏        | 27/221 [00:08<00:33,  5.72it/s][A
 13%|█▎        | 28/221 [00:08<00:45,  4.26it/s][A
 13%|█▎        | 29/221 [00:09<00:45,  4.23it/s][A
 14%|█▎        | 30/221 [00:09<00:46,  4.08it/s][A
 14%|█▍        | 31/221 [00:09<00:41,  4.56it/s][A
 14%|█▍        | 32/221 [00:09<00:34,  5.42it/s][A
 15%|█▍        | 33/221 [00:09<00:41,  4.54it/s][A
 15%|█▌        | 34/221 [00:10<00:37,  4.96it/s][A
 16%|█▌        | 35/221 [00:10<00:41,  4.44it/s][A
 16%|█▋        | 36/221 [00:10<00:54,  3.39it/s][A
 17%|█▋        | 37/221 [00:11<01:20,  2.30it/s][A[h264 @ 0x559bf4a27ec0] mmco: unref short failure
[h264 @ 0x559bf4a27ec0] mmco: unref short failure

 17%|█▋        | 38/221 [00:11<01:17,  2.37it/s][A
 18%|█▊        | 39/221 [00:12<00:59,  3.06it/s][A[h264 @ 0x55a032f25a80] mmco: unref short failure

 18%|█▊        | 40/221 [00:12<00:52,  3.42it/s][A
 19%|█▊        | 41/221 [00:12<00:46,  3.89it/s][A
 19%|█▉        | 42/221 [00:12<00:53,  3.34it/s][A
 19%|█▉        | 43/221 [00:12<00:43,  4.06it/s][A[h264 @ 0x556b2d859240] mmco: unref short failure
[h264 @ 0x556b2d859240] mmco: unref short failure

 20%|██        | 45/221 [00:13<01:02,  2.81it/s][A
 21%|██        | 46/221 [00:14<01:07,  2.59it/s][A
 21%|██▏       | 47/221 [00:15<01:57,  1.48it/s][A
 22%|██▏       | 49/221 [00:16<01:19,  2.17it/s][A[h264 @ 0x55a03cc27480] mmco: unref short failure

 23%|██▎       | 50/221 [00:16<01:08,  2.49it/s][A
 23%|██▎       | 51/221 [00:16<00:55,  3.07it/s][A
 24%|██▎       | 52/221 [00:16<00:45,  3.68it/s][A
 24%|██▍       | 53/221 [00:16<00:41,  4.04it/s][A
 24%|██▍       | 54/221 [00:17<01:01,  2.73it/s][A
 25%|██▍       | 55/221 [00:18<01:18,  2.13it/s][A
 25%|██▌       | 56/221 [00:18<01:06,  2.47it/s][A[h264 @ 0x559bfa8c5800] mmco: unref short failure

 26%|██▌       | 57/221 [00:18<00:55,  2.98it/s][A
 26%|██▌       | 58/221 [00:18<00:44,  3.69it/s][A
 27%|██▋       | 59/221 [00:18<00:37,  4.34it/s][A
 27%|██▋       | 60/221 [00:19<00:40,  3.97it/s][A
 28%|██▊       | 61/221 [00:19<00:39,  4.05it/s][A
 28%|██▊       | 62/221 [00:19<00:41,  3.85it/s][A
 29%|██▊       | 63/221 [00:19<00:40,  3.94it/s][A
 29%|██▉       | 64/221 [00:20<00:34,  4.61it/s][A
 29%|██▉       | 65/221 [00:20<00:29,  5.37it/s][A
 30%|██▉       | 66/221 [00:20<00:34,  4.48it/s][A
 30%|███       | 67/221 [00:20<00:31,  4.88it/s][A
 31%|███       | 68/221 [00:20<00:27,  5.54it/s][A
 31%|███       | 69/221 [00:21<00:42,  3.55it/s][A
 32%|███▏      | 70/221 [00:21<00:41,  3.66it/s][A[h264 @ 0x559bf4169dc0] mmco: unref short failure
[h264 @ 0x559bf4169dc0] mmco: unref short failure
[h264 @ 0x559bf4169dc0] mmco: unref short failure
[h264 @ 0x559bf4169dc0] mmco: unref short failure

 32%|███▏      | 71/221 [00:23<01:37,  1.54it/s][A
 33%|███▎      | 72/221 [00:23<01:18,  1.91it/s][A
 33%|███▎      | 73/221 [00:23<01:06,  2.22it/s][A
 33%|███▎      | 74/221 [00:23<00:53,  2.75it/s][A
 34%|███▍      | 75/221 [00:24<00:52,  2.80it/s][A
 34%|███▍      | 76/221 [00:24<00:44,  3.25it/s][A
 35%|███▍      | 77/221 [00:24<00:36,  3.93it/s][A
 35%|███▌      | 78/221 [00:24<00:40,  3.50it/s][A
 36%|███▌      | 79/221 [00:25<00:52,  2.69it/s][A
 36%|███▌      | 80/221 [00:25<00:42,  3.33it/s][A
 37%|███▋      | 81/221 [00:25<00:38,  3.68it/s][A
 37%|███▋      | 82/221 [00:25<00:37,  3.69it/s][A
 38%|███▊      | 83/221 [00:26<00:30,  4.53it/s][A
 38%|███▊      | 84/221 [00:26<00:25,  5.32it/s][A
 38%|███▊      | 85/221 [00:26<00:22,  5.93it/s][A
 39%|███▉      | 86/221 [00:26<00:20,  6.59it/s][A
 39%|███▉      | 87/221 [00:26<00:30,  4.33it/s][A
 40%|███▉      | 88/221 [00:27<00:35,  3.75it/s][A[h264 @ 0x5624270b3040] mmco: unref short failure
[h264 @ 0x5624270b3040] mmco: unref short failure

 40%|████      | 89/221 [00:30<02:22,  1.08s/it][A
 41%|████      | 90/221 [00:30<01:46,  1.23it/s][A
 41%|████      | 91/221 [00:30<01:19,  1.64it/s][A
 42%|████▏     | 92/221 [00:30<01:02,  2.07it/s][A
 42%|████▏     | 93/221 [00:31<01:02,  2.06it/s][A
 43%|████▎     | 94/221 [00:31<00:51,  2.46it/s][A
 43%|████▎     | 95/221 [00:31<00:39,  3.16it/s][A
 43%|████▎     | 96/221 [00:31<00:36,  3.43it/s][A
 44%|████▍     | 97/221 [00:31<00:29,  4.23it/s][A
 44%|████▍     | 98/221 [00:31<00:25,  4.84it/s][A
 45%|████▍     | 99/221 [00:32<00:22,  5.36it/s][A
 45%|████▌     | 100/221 [00:32<00:24,  5.02it/s][A
 46%|████▌     | 101/221 [00:32<00:23,  5.19it/s][A
 46%|████▌     | 102/221 [00:32<00:24,  4.76it/s][A
 47%|████▋     | 104/221 [00:32<00:17,  6.55it/s][A
 48%|████▊     | 105/221 [00:33<00:18,  6.30it/s][A
 48%|████▊     | 106/221 [00:33<00:37,  3.10it/s][A
 48%|████▊     | 107/221 [00:34<00:33,  3.40it/s][A
 49%|████▉     | 108/221 [00:34<00:30,  3.68it/s][A
 49%|████▉     | 109/221 [00:34<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:34<00:24,  4.60it/s][A
 50%|█████     | 111/221 [00:35<00:29,  3.78it/s][A
 51%|█████     | 112/221 [00:35<00:25,  4.24it/s][A
 51%|█████     | 113/221 [00:35<00:35,  3.05it/s][A
 52%|█████▏    | 115/221 [00:35<00:22,  4.62it/s][A[h264 @ 0x559bea556a00] mmco: unref short failure

 52%|█████▏    | 116/221 [00:40<02:09,  1.23s/it][A
 53%|█████▎    | 117/221 [00:40<01:44,  1.01s/it][A
 53%|█████▎    | 118/221 [00:41<01:27,  1.18it/s][A
 54%|█████▍    | 119/221 [00:41<01:05,  1.55it/s][A
 54%|█████▍    | 120/221 [00:41<00:52,  1.91it/s][A
 55%|█████▌    | 122/221 [00:41<00:34,  2.88it/s][A[h264 @ 0x55a0357b2440] mmco: unref short failure
[h264 @ 0x55a0357b2440] mmco: unref short failure

 56%|█████▌    | 123/221 [00:41<00:32,  3.01it/s][A
 56%|█████▌    | 124/221 [00:42<00:29,  3.29it/s][A
 57%|█████▋    | 125/221 [00:42<00:26,  3.69it/s][A[h264 @ 0x55a034061a80] mmco: unref short failure
[h264 @ 0x55a034061a80] mmco: unref short failure

 57%|█████▋    | 126/221 [00:42<00:28,  3.36it/s][A
 57%|█████▋    | 127/221 [00:43<00:28,  3.25it/s][A
 58%|█████▊    | 128/221 [00:43<00:30,  3.01it/s][A
 58%|█████▊    | 129/221 [00:43<00:25,  3.56it/s][A
 59%|█████▉    | 130/221 [00:43<00:23,  3.90it/s][A
 59%|█████▉    | 131/221 [00:43<00:20,  4.30it/s][A
 60%|█████▉    | 132/221 [00:44<00:19,  4.49it/s][A[h264 @ 0x562416cde400] mmco: unref short failure

 60%|██████    | 133/221 [00:44<00:26,  3.30it/s][A
 61%|██████    | 134/221 [00:44<00:23,  3.71it/s][A
 61%|██████    | 135/221 [00:45<00:24,  3.50it/s][A
 62%|██████▏   | 136/221 [00:45<00:26,  3.17it/s][A
 62%|██████▏   | 137/221 [00:45<00:23,  3.56it/s][A
 62%|██████▏   | 138/221 [00:46<00:29,  2.78it/s][A
 63%|██████▎   | 139/221 [00:46<00:27,  3.02it/s][A
 63%|██████▎   | 140/221 [00:46<00:26,  3.06it/s][A
 64%|██████▍   | 141/221 [00:47<00:21,  3.65it/s][A
 64%|██████▍   | 142/221 [00:47<00:32,  2.42it/s][A
 65%|██████▍   | 143/221 [00:48<00:28,  2.70it/s][A
 65%|██████▌   | 144/221 [00:48<00:22,  3.44it/s][A
 66%|██████▌   | 146/221 [00:48<00:14,  5.11it/s][A
 67%|██████▋   | 148/221 [00:48<00:12,  5.66it/s][A
 68%|██████▊   | 150/221 [00:48<00:10,  6.72it/s][A
 68%|██████▊   | 151/221 [00:49<00:16,  4.27it/s][A
 69%|██████▉   | 152/221 [00:49<00:14,  4.85it/s][A
 69%|██████▉   | 153/221 [00:49<00:17,  3.98it/s][A
 70%|██████▉   | 154/221 [00:50<00:23,  2.82it/s][A[h264 @ 0x556b2dd8ba00] mmco: unref short failure
[h264 @ 0x556b2dd8ba00] mmco: unref short failure

 71%|███████   | 156/221 [00:50<00:15,  4.09it/s][A
 71%|███████   | 157/221 [00:54<01:10,  1.10s/it][A
 71%|███████▏  | 158/221 [00:54<00:54,  1.15it/s][A
 72%|███████▏  | 159/221 [00:54<00:42,  1.46it/s][A
 72%|███████▏  | 160/221 [00:55<00:32,  1.89it/s][A
 73%|███████▎  | 162/221 [00:55<00:19,  2.95it/s][A
 74%|███████▍  | 163/221 [00:55<00:18,  3.17it/s][A
 74%|███████▍  | 164/221 [00:55<00:16,  3.39it/s][A
 75%|███████▍  | 165/221 [00:55<00:14,  3.83it/s][A
 75%|███████▌  | 166/221 [00:56<00:17,  3.17it/s][A
 76%|███████▌  | 167/221 [00:56<00:13,  3.90it/s][A[h264 @ 0x556b3eebf3c0] mmco: unref short failure
[h264 @ 0x556b3eebf3c0] mmco: unref short failure

 76%|███████▌  | 168/221 [01:00<01:11,  1.35s/it][A
 76%|███████▋  | 169/221 [01:00<00:53,  1.02s/it][A
 77%|███████▋  | 170/221 [01:01<00:40,  1.25it/s][A
 77%|███████▋  | 171/221 [01:01<00:30,  1.66it/s][A
 78%|███████▊  | 172/221 [01:01<00:23,  2.07it/s][A
 78%|███████▊  | 173/221 [01:01<00:17,  2.70it/s][A
 79%|███████▉  | 175/221 [01:01<00:12,  3.59it/s][A
 80%|███████▉  | 176/221 [01:02<00:12,  3.75it/s][A
 80%|████████  | 177/221 [01:02<00:09,  4.42it/s][A
 81%|████████  | 178/221 [01:02<00:10,  3.93it/s][A
 81%|████████  | 179/221 [01:04<00:27,  1.51it/s][A
 82%|████████▏ | 181/221 [01:04<00:17,  2.31it/s][A
 82%|████████▏ | 182/221 [01:04<00:14,  2.71it/s][A
 83%|████████▎ | 183/221 [01:04<00:11,  3.24it/s][A
 83%|████████▎ | 184/221 [01:05<00:11,  3.36it/s][A
 84%|████████▍ | 186/221 [01:05<00:08,  3.95it/s][A
 85%|████████▍ | 187/221 [01:05<00:07,  4.57it/s][A
 85%|████████▌ | 188/221 [01:05<00:08,  4.11it/s][A
 86%|████████▌ | 189/221 [01:06<00:08,  3.92it/s][A
 86%|████████▌ | 190/221 [01:06<00:07,  4.32it/s][A
 87%|████████▋ | 192/221 [01:06<00:05,  5.03it/s][A
 88%|████████▊ | 194/221 [01:07<00:06,  4.49it/s][A
 89%|████████▊ | 196/221 [01:07<00:04,  5.90it/s][A
 90%|████████▉ | 198/221 [01:07<00:03,  6.55it/s][A
 90%|█████████ | 199/221 [01:07<00:03,  6.96it/s][A
 90%|█████████ | 200/221 [01:07<00:03,  5.88it/s][A
 91%|█████████ | 201/221 [01:08<00:03,  5.44it/s][A
 91%|█████████▏| 202/221 [01:08<00:03,  5.90it/s][A
 92%|█████████▏| 203/221 [01:08<00:02,  6.57it/s][A
 93%|█████████▎| 205/221 [01:08<00:01,  8.50it/s][A
 93%|█████████▎| 206/221 [01:09<00:03,  4.96it/s][A
 94%|█████████▍| 208/221 [01:09<00:01,  6.61it/s][A
 95%|█████████▌| 211/221 [01:09<00:01,  6.66it/s][A
 96%|█████████▋| 213/221 [01:09<00:01,  7.78it/s][A[h264 @ 0x559c063383c0] mmco: unref short failure
[h264 @ 0x559c063383c0] mmco: unref short failure

 97%|█████████▋| 214/221 [01:10<00:01,  5.57it/s][A
 97%|█████████▋| 215/221 [01:10<00:01,  5.64it/s][A
 98%|█████████▊| 216/221 [01:10<00:00,  5.68it/s][A
 98%|█████████▊| 217/221 [01:11<00:01,  2.06it/s][A
 99%|█████████▊| 218/221 [01:12<00:01,  2.47it/s][A
 99%|█████████▉| 219/221 [01:12<00:00,  2.88it/s][A
100%|█████████▉| 220/221 [01:16<00:01,  1.47s/it][A
100%|██████████| 221/221 [01:16<00:00,  1.08s/it][A100%|██████████| 221/221 [01:16<00:00,  2.88it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:57,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:51,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:22<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:34,  3.49it/s][A
 46%|████▌     | 102/221 [00:26<00:33,  3.57it/s][A
 47%|████▋     | 103/221 [00:27<00:32,  3.64it/s][A
 47%|████▋     | 104/221 [00:27<00:31,  3.68it/s][A
 48%|████▊     | 105/221 [00:27<00:31,  3.71it/s][A
 48%|████▊     | 106/221 [00:28<00:30,  3.74it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.75it/s][A
 49%|████▉     | 108/221 [00:28<00:30,  3.76it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.77it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.78it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.78it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.78it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:32<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:42<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:47<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:52<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:56<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:57<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:29,  7.40it/s][A
  1%|          | 2/221 [00:00<00:41,  5.23it/s][A
  1%|▏         | 3/221 [00:00<00:47,  4.54it/s][A
  2%|▏         | 4/221 [00:00<00:44,  4.90it/s][A
  2%|▏         | 5/221 [00:01<00:44,  4.80it/s][A
  3%|▎         | 7/221 [00:01<00:41,  5.22it/s][A
  4%|▎         | 8/221 [00:01<00:47,  4.49it/s][A
  4%|▍         | 9/221 [00:01<00:50,  4.21it/s][A
  5%|▍         | 10/221 [00:02<01:13,  2.88it/s][A
  5%|▍         | 11/221 [00:02<01:01,  3.40it/s][A
  5%|▌         | 12/221 [00:02<00:51,  4.03it/s][A
  6%|▌         | 13/221 [00:03<01:29,  2.32it/s][A
  6%|▋         | 14/221 [00:03<01:10,  2.95it/s][A
  7%|▋         | 15/221 [00:04<01:02,  3.31it/s][A
  7%|▋         | 16/221 [00:04<01:06,  3.08it/s][A
  8%|▊         | 17/221 [00:05<01:23,  2.44it/s][A
  8%|▊         | 18/221 [00:05<01:11,  2.84it/s][A
  9%|▊         | 19/221 [00:05<00:59,  3.37it/s][A
 10%|▉         | 21/221 [00:05<00:43,  4.58it/s][A
 10%|▉         | 22/221 [00:05<00:41,  4.82it/s][A
 10%|█         | 23/221 [00:06<00:36,  5.43it/s][A
 11%|█         | 24/221 [00:06<00:35,  5.57it/s][A
 11%|█▏        | 25/221 [00:06<00:34,  5.68it/s][A
 12%|█▏        | 26/221 [00:06<00:36,  5.30it/s][A
 12%|█▏        | 27/221 [00:06<00:33,  5.83it/s][A
 13%|█▎        | 28/221 [00:07<00:44,  4.37it/s][A
 13%|█▎        | 29/221 [00:07<00:44,  4.27it/s][A
 14%|█▎        | 30/221 [00:07<00:47,  3.98it/s][A
 14%|█▍        | 31/221 [00:07<00:44,  4.22it/s][A
 14%|█▍        | 32/221 [00:07<00:39,  4.84it/s][A
 15%|█▍        | 33/221 [00:08<00:39,  4.78it/s][A
 15%|█▌        | 34/221 [00:08<00:40,  4.62it/s][A
 16%|█▌        | 35/221 [00:08<00:47,  3.95it/s][A
 16%|█▋        | 36/221 [00:09<00:52,  3.55it/s][A
 17%|█▋        | 37/221 [00:09<00:44,  4.13it/s][A
 17%|█▋        | 38/221 [00:09<00:46,  3.96it/s][A
 18%|█▊        | 39/221 [00:09<00:43,  4.23it/s][A
 18%|█▊        | 40/221 [00:10<00:49,  3.66it/s][A
 19%|█▊        | 41/221 [00:10<00:43,  4.14it/s][A
 19%|█▉        | 42/221 [00:10<00:37,  4.81it/s][A
 19%|█▉        | 43/221 [00:10<00:45,  3.93it/s][A
 20%|█▉        | 44/221 [00:11<00:47,  3.75it/s][A
 20%|██        | 45/221 [00:11<00:49,  3.58it/s][A
 21%|██        | 46/221 [00:11<00:43,  3.98it/s][A
 21%|██▏       | 47/221 [00:11<00:43,  3.98it/s][A
 22%|██▏       | 48/221 [00:11<00:37,  4.62it/s][A
 22%|██▏       | 49/221 [00:12<00:38,  4.43it/s][A
 23%|██▎       | 50/221 [00:12<00:50,  3.38it/s][A
 23%|██▎       | 51/221 [00:12<00:43,  3.91it/s][A
 24%|██▎       | 52/221 [00:13<00:45,  3.68it/s][A
 24%|██▍       | 53/221 [00:13<00:38,  4.33it/s][A
 24%|██▍       | 54/221 [00:13<00:48,  3.46it/s][A
 25%|██▍       | 55/221 [00:13<00:48,  3.45it/s][A
 25%|██▌       | 56/221 [00:14<00:42,  3.90it/s][A
 26%|██▌       | 57/221 [00:14<00:45,  3.60it/s][A
 26%|██▌       | 58/221 [00:14<00:52,  3.12it/s][A
 27%|██▋       | 59/221 [00:15<00:46,  3.48it/s][A
 27%|██▋       | 60/221 [00:15<00:38,  4.14it/s][A
 28%|██▊       | 61/221 [00:15<00:36,  4.44it/s][A
 28%|██▊       | 62/221 [00:15<00:37,  4.22it/s][A
 29%|██▊       | 63/221 [00:15<00:35,  4.44it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.81it/s][A
 29%|██▉       | 65/221 [00:16<00:36,  4.25it/s][A
 30%|██▉       | 66/221 [00:16<00:47,  3.25it/s][A
 30%|███       | 67/221 [00:17<00:48,  3.19it/s][A
 31%|███       | 68/221 [00:17<00:41,  3.71it/s][A
 31%|███       | 69/221 [00:18<01:05,  2.33it/s][A
 32%|███▏      | 70/221 [00:18<00:52,  2.86it/s][A
 32%|███▏      | 71/221 [00:18<00:44,  3.36it/s][A
 33%|███▎      | 72/221 [00:18<00:49,  2.99it/s][A
 33%|███▎      | 73/221 [00:19<00:48,  3.04it/s][A
 33%|███▎      | 74/221 [00:19<00:42,  3.49it/s][A
 34%|███▍      | 75/221 [00:19<00:40,  3.59it/s][A
 34%|███▍      | 76/221 [00:19<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:39,  3.60it/s][A
 35%|███▌      | 78/221 [00:20<00:35,  4.03it/s][A
 36%|███▌      | 79/221 [00:20<00:41,  3.43it/s][A
 36%|███▌      | 80/221 [00:21<00:38,  3.63it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.88it/s][A
 37%|███▋      | 82/221 [00:21<00:44,  3.14it/s][A
 38%|███▊      | 83/221 [00:22<00:45,  3.05it/s][A
 38%|███▊      | 84/221 [00:22<00:43,  3.18it/s][A
 38%|███▊      | 85/221 [00:22<00:34,  3.95it/s][A
 39%|███▉      | 86/221 [00:22<00:36,  3.67it/s][A
 39%|███▉      | 87/221 [00:23<00:44,  3.01it/s][A
 40%|███▉      | 88/221 [00:23<00:49,  2.67it/s][A
 40%|████      | 89/221 [00:23<00:44,  2.96it/s][A
 41%|████      | 90/221 [00:24<00:47,  2.78it/s][A
 41%|████      | 91/221 [00:24<00:38,  3.34it/s][A
 42%|████▏     | 92/221 [00:24<00:43,  2.98it/s][A
 42%|████▏     | 93/221 [00:25<00:58,  2.19it/s][A
 43%|████▎     | 94/221 [00:25<00:51,  2.47it/s][A
 43%|████▎     | 95/221 [00:26<00:45,  2.77it/s][A
 43%|████▎     | 96/221 [00:26<00:39,  3.17it/s][A
 44%|████▍     | 97/221 [00:26<00:35,  3.52it/s][A
 44%|████▍     | 98/221 [00:26<00:33,  3.65it/s][A
 45%|████▍     | 99/221 [00:27<00:30,  3.98it/s][A
 45%|████▌     | 100/221 [00:27<00:31,  3.80it/s][A
 46%|████▌     | 101/221 [00:27<00:31,  3.87it/s][A
 46%|████▌     | 102/221 [00:28<00:46,  2.53it/s][A
 47%|████▋     | 103/221 [00:28<00:36,  3.19it/s][A
 47%|████▋     | 104/221 [00:28<00:31,  3.76it/s][A
 48%|████▊     | 105/221 [00:28<00:31,  3.69it/s][A
 48%|████▊     | 106/221 [00:29<00:34,  3.35it/s][A
 48%|████▊     | 107/221 [00:29<00:30,  3.78it/s][A
 49%|████▉     | 108/221 [00:29<00:30,  3.67it/s][A
 49%|████▉     | 109/221 [00:29<00:24,  4.52it/s][A
 50%|████▉     | 110/221 [00:30<00:25,  4.41it/s][A
 50%|█████     | 111/221 [00:30<00:26,  4.14it/s][A
 51%|█████     | 112/221 [00:30<00:26,  4.18it/s][A
 51%|█████     | 113/221 [00:30<00:24,  4.38it/s][A
 52%|█████▏    | 115/221 [00:31<00:21,  5.03it/s][A
 52%|█████▏    | 116/221 [00:31<00:22,  4.71it/s][A
 53%|█████▎    | 117/221 [00:31<00:23,  4.48it/s][A
 53%|█████▎    | 118/221 [00:31<00:22,  4.59it/s][A
 54%|█████▍    | 119/221 [00:32<00:28,  3.58it/s][A
 54%|█████▍    | 120/221 [00:32<00:25,  3.99it/s][A
 55%|█████▍    | 121/221 [00:32<00:21,  4.68it/s][A
 55%|█████▌    | 122/221 [00:32<00:23,  4.30it/s][A
 56%|█████▌    | 123/221 [00:33<00:26,  3.75it/s][A
 56%|█████▌    | 124/221 [00:33<00:24,  4.00it/s][A
 57%|█████▋    | 125/221 [00:33<00:26,  3.60it/s][A
 57%|█████▋    | 126/221 [00:33<00:23,  3.98it/s][A
 57%|█████▋    | 127/221 [00:34<00:28,  3.34it/s][A
 58%|█████▊    | 128/221 [00:34<00:26,  3.51it/s][A
 58%|█████▊    | 129/221 [00:34<00:21,  4.34it/s][A
 59%|█████▉    | 130/221 [00:34<00:20,  4.34it/s][A
 59%|█████▉    | 131/221 [00:35<00:18,  4.99it/s][A
 60%|█████▉    | 132/221 [00:35<00:20,  4.40it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.71it/s][A
 61%|██████    | 134/221 [00:36<00:30,  2.85it/s][A
 61%|██████    | 135/221 [00:36<00:30,  2.81it/s][A
 62%|██████▏   | 136/221 [00:36<00:26,  3.15it/s][A
 62%|██████▏   | 137/221 [00:37<00:22,  3.75it/s][A
 62%|██████▏   | 138/221 [00:37<00:22,  3.61it/s][A
 63%|██████▎   | 139/221 [00:37<00:25,  3.24it/s][A
 63%|██████▎   | 140/221 [00:37<00:24,  3.28it/s][A
 64%|██████▍   | 141/221 [00:38<00:22,  3.62it/s][A
 64%|██████▍   | 142/221 [00:38<00:20,  3.85it/s][A
 65%|██████▍   | 143/221 [00:38<00:24,  3.13it/s][A
 65%|██████▌   | 144/221 [00:39<00:26,  2.93it/s][A
 66%|██████▌   | 145/221 [00:39<00:20,  3.67it/s][A
 67%|██████▋   | 147/221 [00:39<00:17,  4.31it/s][A
 67%|██████▋   | 148/221 [00:40<00:19,  3.70it/s][A
 67%|██████▋   | 149/221 [00:40<00:19,  3.65it/s][A
 68%|██████▊   | 150/221 [00:40<00:18,  3.83it/s][A
 68%|██████▊   | 151/221 [00:41<00:20,  3.36it/s][A
 69%|██████▉   | 152/221 [00:41<00:27,  2.47it/s][A
 69%|██████▉   | 153/221 [00:41<00:22,  3.01it/s][A
 70%|██████▉   | 154/221 [00:42<00:20,  3.32it/s][A
 70%|███████   | 155/221 [00:42<00:17,  3.67it/s][A
 71%|███████   | 156/221 [00:42<00:20,  3.25it/s][A
 71%|███████   | 157/221 [00:42<00:19,  3.26it/s][A
 71%|███████▏  | 158/221 [00:43<00:18,  3.44it/s][A
 72%|███████▏  | 159/221 [00:43<00:14,  4.15it/s][A
 72%|███████▏  | 160/221 [00:43<00:14,  4.31it/s][A
 73%|███████▎  | 161/221 [00:44<00:18,  3.19it/s][A
 73%|███████▎  | 162/221 [00:44<00:16,  3.66it/s][A
 74%|███████▍  | 163/221 [00:44<00:15,  3.70it/s][A
 74%|███████▍  | 164/221 [00:44<00:13,  4.18it/s][A
 75%|███████▍  | 165/221 [00:44<00:13,  4.21it/s][A
 75%|███████▌  | 166/221 [00:45<00:13,  4.23it/s][A
 76%|███████▌  | 167/221 [00:45<00:10,  5.10it/s][A
 76%|███████▌  | 168/221 [00:45<00:12,  4.20it/s][A
 76%|███████▋  | 169/221 [00:45<00:10,  5.01it/s][A
 77%|███████▋  | 170/221 [00:46<00:14,  3.50it/s][A
 77%|███████▋  | 171/221 [00:46<00:12,  3.85it/s][A
 78%|███████▊  | 172/221 [00:46<00:12,  4.03it/s][A
 78%|███████▊  | 173/221 [00:46<00:12,  3.73it/s][A
 79%|███████▊  | 174/221 [00:47<00:15,  3.12it/s][A
 79%|███████▉  | 175/221 [00:47<00:15,  2.97it/s][A
 80%|███████▉  | 176/221 [00:47<00:14,  3.20it/s][A
 80%|████████  | 177/221 [00:48<00:12,  3.46it/s][A
 81%|████████  | 178/221 [00:48<00:12,  3.33it/s][A
 81%|████████  | 179/221 [00:48<00:12,  3.49it/s][A
 81%|████████▏ | 180/221 [00:48<00:10,  3.97it/s][A
 82%|████████▏ | 181/221 [00:49<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:49<00:11,  3.31it/s][A
 83%|████████▎ | 183/221 [00:49<00:11,  3.44it/s][A
 83%|████████▎ | 184/221 [00:50<00:10,  3.56it/s][A
 84%|████████▎ | 185/221 [00:50<00:09,  3.94it/s][A
 84%|████████▍ | 186/221 [00:50<00:12,  2.91it/s][A
 85%|████████▍ | 187/221 [00:51<00:10,  3.30it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.36it/s][A
 86%|████████▌ | 189/221 [00:51<00:08,  3.59it/s][A
 86%|████████▌ | 190/221 [00:52<00:09,  3.24it/s][A
 86%|████████▋ | 191/221 [00:52<00:08,  3.70it/s][A
 87%|████████▋ | 192/221 [00:52<00:07,  3.80it/s][A
 87%|████████▋ | 193/221 [00:52<00:06,  4.37it/s][A
 88%|████████▊ | 194/221 [00:52<00:07,  3.85it/s][A
 88%|████████▊ | 195/221 [00:53<00:06,  4.08it/s][A
 89%|████████▊ | 196/221 [00:53<00:07,  3.28it/s][A
 89%|████████▉ | 197/221 [00:53<00:06,  3.65it/s][A
 90%|████████▉ | 198/221 [00:54<00:07,  3.11it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.48it/s][A
 90%|█████████ | 200/221 [00:54<00:06,  3.23it/s][A
 91%|█████████ | 201/221 [00:54<00:05,  3.67it/s][A
 91%|█████████▏| 202/221 [00:55<00:05,  3.29it/s][A
 92%|█████████▏| 203/221 [00:55<00:04,  3.77it/s][A
 92%|█████████▏| 204/221 [00:55<00:04,  3.45it/s][A
 93%|█████████▎| 205/221 [00:56<00:03,  4.19it/s][A
 93%|█████████▎| 206/221 [00:56<00:04,  3.51it/s][A
 94%|█████████▎| 207/221 [00:56<00:03,  3.63it/s][A
 94%|█████████▍| 208/221 [00:56<00:03,  3.62it/s][A
 95%|█████████▍| 209/221 [00:57<00:03,  3.91it/s][A
 95%|█████████▌| 210/221 [00:57<00:02,  4.03it/s][A
 95%|█████████▌| 211/221 [00:57<00:02,  3.64it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  3.43it/s][A
 96%|█████████▋| 213/221 [00:58<00:02,  3.66it/s][A
 97%|█████████▋| 214/221 [00:58<00:02,  2.64it/s][A
 97%|█████████▋| 215/221 [00:59<00:01,  3.02it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.23it/s][A
 98%|█████████▊| 217/221 [00:59<00:01,  3.21it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.19it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  2.99it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.47it/s][A
100%|██████████| 221/221 [01:00<00:00,  3.95it/s][A100%|██████████| 221/221 [01:00<00:00,  3.64it/s]
09/10/2024 00:42:52 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 1399--===========

09/10/2024 00:42:52 - INFO - __main__ -   {'area_r1': 38.5, 'area_recall': '38.5/61.8/72.1', 'area_ravg': 57.4}
09/10/2024 00:42:52 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 1399--===========

09/10/2024 00:42:52 - INFO - __main__ -   {'forward_r1': 37.1, 'forward_recall': '37.1/65.3/76.5', 'forward_ravg': 59.6}
09/10/2024 00:42:52 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 1399--===========

09/10/2024 00:42:52 - INFO - __main__ -   {'area_video_r1': 37.6, 'area_video_recall': '37.6/67.1/76.8', 'area_video_ravg': 60.5}
09/10/2024 00:42:52 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/10/2024 00:42:52 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/10/2024 00:42:52 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 1399--===========

09/10/2024 00:42:52 - INFO - __main__ -   {'area_video_r1': 51.8, 'area_video_recall': '51.8/74.7/82.1', 'area_video_ravg': 69.5, 'area_video_back_r1': 47.9, 'area_video_back_recall': '47.9/73.6/82.4', 'area_video_back_ravg': 67.9}
09/10/2024 00:42:52 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/10/2024 00:42:52 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/10/2024 00:42:52 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 1399--===========

09/10/2024 00:42:52 - INFO - __main__ -   {'video_r1': 43.9, 'video_recall': '43.9/71.6/81.7', 'video_ravg': 65.7}
09/10/2024 00:42:52 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/10/2024 00:42:52 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/10/2024 00:42:52 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 1399--===========

09/10/2024 00:42:52 - INFO - __main__ -   {'video_r1': 52.0, 'video_recall': '52.0/75.5/83.4', 'video_ravg': 70.3}
09/10/2024 00:42:52 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/10/2024 00:42:52 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/10/2024 00:43:13 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.007343671750277281, 'loss_ret%tv%ta--finetune_area/loss_area': 0.9883677959442139, 'loss_ret%tv%ta--finetune_area/total_loss': 0.9957114458084106}
 72%|███████▏  | 1400/1945 [7:37:54<18:54:09, 124.86s/it][h264 @ 0x556b39212100] mmco: unref short failure
[h264 @ 0x556b39212100] mmco: unref short failure
[h264 @ 0x556b39212100] mmco: unref short failure
[h264 @ 0x556b39212100] mmco: unref short failure
 72%|███████▏  | 1401/1945 [7:37:58<13:23:50, 88.66s/it]  72%|███████▏  | 1402/1945 [7:38:03<9:33:57, 63.42s/it] [h264 @ 0x55a043f4cf80] mmco: unref short failure
[h264 @ 0x55a043f4cf80] mmco: unref short failure
[h264 @ 0x55a043f4cf80] mmco: unref short failure
[h264 @ 0x55a043f4cf80] mmco: unref short failure
[h264 @ 0x56241cf98c40] mmco: unref short failure
[h264 @ 0x56241cf98c40] mmco: unref short failure
 72%|███████▏  | 1403/1945 [7:38:09<6:57:06, 46.18s/it] 72%|███████▏  | 1404/1945 [7:38:14<5:07:11, 34.07s/it][h264 @ 0x556b3990cb80] mmco: unref short failure
[h264 @ 0x556b4c7a4b80] mmco: unref short failure
[h264 @ 0x556b4c7a4b80] mmco: unref short failure
 72%|███████▏  | 1405/1945 [7:38:21<3:53:41, 25.96s/it] 72%|███████▏  | 1406/1945 [7:38:29<3:03:33, 20.43s/it] 72%|███████▏  | 1407/1945 [7:38:37<2:29:00, 16.62s/it][h264 @ 0x556b2dd8b800] mmco: unref short failure
 72%|███████▏  | 1408/1945 [7:38:44<2:04:20, 13.89s/it] 72%|███████▏  | 1409/1945 [7:38:52<1:48:58, 12.20s/it][h264 @ 0x55a046283400] mmco: unref short failure
[h264 @ 0x55a046283400] mmco: unref short failure
[h264 @ 0x55a052e7fec0] mmco: unref short failure
[h264 @ 0x56241a0acb40] mmco: unref short failure
[h264 @ 0x56241a0acb40] mmco: unref short failure
[h264 @ 0x56241a0acb40] mmco: unref short failure
[h264 @ 0x56241a0acb40] mmco: unref short failure
[h264 @ 0x56242cababc0] mmco: unref short failure
[h264 @ 0x56242cababc0] mmco: unref short failure
[h264 @ 0x56242cababc0] mmco: unref short failure
[h264 @ 0x56242cababc0] mmco: unref short failure
 72%|███████▏  | 1410/1945 [7:38:59<1:34:36, 10.61s/it][h264 @ 0x559c0022a340] mmco: unref short failure
[h264 @ 0x559c0022a340] mmco: unref short failure
 73%|███████▎  | 1411/1945 [7:39:07<1:26:23,  9.71s/it] 73%|███████▎  | 1412/1945 [7:39:15<1:21:42,  9.20s/it][h264 @ 0x56241abd5e40] mmco: unref short failure
[h264 @ 0x56241abd5e40] mmco: unref short failure
 73%|███████▎  | 1413/1945 [7:39:23<1:18:32,  8.86s/it][h264 @ 0x559c07a75100] mmco: unref short failure
[h264 @ 0x559c07a75100] mmco: unref short failure
[h264 @ 0x56241ded18c0] mmco: unref short failure
 73%|███████▎  | 1414/1945 [7:39:33<1:22:30,  9.32s/it] 73%|███████▎  | 1415/1945 [7:39:40<1:15:18,  8.53s/it][h264 @ 0x56242409c080] mmco: unref short failure
[h264 @ 0x56242409c080] mmco: unref short failure
[h264 @ 0x5624172fbec0] mmco: unref short failure
[h264 @ 0x5624172fbec0] mmco: unref short failure
[h264 @ 0x5624172fbec0] mmco: unref short failure
[h264 @ 0x5624172fbec0] mmco: unref short failure
 73%|███████▎  | 1416/1945 [7:39:48<1:12:38,  8.24s/it][h264 @ 0x559bf06f9d00] mmco: unref short failure
[h264 @ 0x559bf06f9d00] mmco: unref short failure
[h264 @ 0x562429590e40] mmco: unref short failure
 73%|███████▎  | 1417/1945 [7:39:56<1:13:55,  8.40s/it][h264 @ 0x56241660f100] mmco: unref short failure
[h264 @ 0x56242c815f00] mmco: unref short failure
[h264 @ 0x56242c815f00] mmco: unref short failure
 73%|███████▎  | 1418/1945 [7:40:08<1:21:37,  9.29s/it][h264 @ 0x56241e1d26c0] mmco: unref short failure
[h264 @ 0x56241e1d26c0] mmco: unref short failure
 73%|███████▎  | 1419/1945 [7:40:15<1:16:51,  8.77s/it][h264 @ 0x5624195d1280] mmco: unref short failure
[h264 @ 0x559bebc427c0] mmco: unref short failure
[h264 @ 0x559bebc427c0] mmco: unref short failure
 73%|███████▎  | 1420/1945 [7:40:23<1:13:54,  8.45s/it] 73%|███████▎  | 1421/1945 [7:40:30<1:10:06,  8.03s/it][h264 @ 0x556b3d4a2840] mmco: unref short failure
[h264 @ 0x556b3d4a2840] mmco: unref short failure
[h264 @ 0x556b3d4a2840] mmco: unref short failure
[h264 @ 0x556b3d4a2840] mmco: unref short failure
[h264 @ 0x559bf708c540] mmco: unref short failure
[h264 @ 0x559bf708c540] mmco: unref short failure
[h264 @ 0x5624283ad500] mmco: unref short failure
 73%|███████▎  | 1422/1945 [7:40:45<1:28:18, 10.13s/it][h264 @ 0x55a034de7000] mmco: unref short failure
[h264 @ 0x55a034de7000] mmco: unref short failure
 73%|███████▎  | 1423/1945 [7:40:51<1:18:00,  8.97s/it][h264 @ 0x55a0357b2240] mmco: unref short failure
[h264 @ 0x55a0357b2240] mmco: unref short failure
[h264 @ 0x55a0357b2240] mmco: unref short failure
[h264 @ 0x55a0357b2240] mmco: unref short failure
[h264 @ 0x559c07633680] mmco: unref short failure
[h264 @ 0x55a03df30680] mmco: unref short failure
[h264 @ 0x55a03df30680] mmco: unref short failure
[h264 @ 0x55a03df30680] mmco: unref short failure
[h264 @ 0x56242e8121c0] mmco: unref short failure
[h264 @ 0x56242e8121c0] mmco: unref short failure
[h264 @ 0x559be912c680] mmco: unref short failure
[h264 @ 0x559be912c680] mmco: unref short failure
[h264 @ 0x55a043bbb380] mmco: unref short failure
[h264 @ 0x55a043bbb380] mmco: unref short failure
[h264 @ 0x559beb5a6100] mmco: unref short failure
[h264 @ 0x556b2cd36080] mmco: unref short failure
[h264 @ 0x556b2cd36080] mmco: unref short failure
[h264 @ 0x55a05145b740] mmco: unref short failure
[h264 @ 0x56242d6acc00] mmco: unref short failure
[h264 @ 0x56242d6acc00] mmco: unref short failure
 73%|███████▎  | 1424/1945 [7:41:41<3:03:42, 21.16s/it][h264 @ 0x556b2c344100] mmco: unref short failure
[h264 @ 0x556b2c344100] mmco: unref short failure
[h264 @ 0x556b2c344100] mmco: unref short failure
[h264 @ 0x556b2c344100] mmco: unref short failure
[h264 @ 0x559bec75a9c0] mmco: unref short failure
[h264 @ 0x559bec75a9c0] mmco: unref short failure
[h264 @ 0x56241c33fb80] mmco: unref short failure
 73%|███████▎  | 1425/1945 [7:42:01<3:01:08, 20.90s/it][h264 @ 0x559be912c880] mmco: unref short failure
[h264 @ 0x556b2fc1b240] mmco: unref short failure
[h264 @ 0x556b2fc1b240] mmco: unref short failure
[h264 @ 0x559bf120f380] mmco: unref short failure
[h264 @ 0x559bf120f380] mmco: unref short failure
 73%|███████▎  | 1426/1945 [7:42:09<2:26:33, 16.94s/it][h264 @ 0x559c03f42cc0] mmco: unref short failure
 73%|███████▎  | 1427/1945 [7:42:16<2:01:07, 14.03s/it] 73%|███████▎  | 1428/1945 [7:42:24<1:45:40, 12.26s/it][h264 @ 0x5624175fc380] mmco: unref short failure
[h264 @ 0x5624175fc380] mmco: unref short failure
[h264 @ 0x559bec7cdf00] mmco: unref short failure
[h264 @ 0x55a04867fb00] mmco: unref short failure
 73%|███████▎  | 1429/1945 [7:42:32<1:33:38, 10.89s/it][h264 @ 0x556b33ae6f80] mmco: unref short failure
[h264 @ 0x556b33ae6f80] mmco: unref short failure
[h264 @ 0x556b33550f00] mmco: unref short failure
 74%|███████▎  | 1430/1945 [7:42:41<1:28:24, 10.30s/it] 74%|███████▎  | 1431/1945 [7:42:47<1:18:00,  9.11s/it][h264 @ 0x5624379cba80] mmco: unref short failure
[h264 @ 0x556b2d991740] mmco: unref short failure
[h264 @ 0x55a034488ac0] mmco: unref short failure
[h264 @ 0x55a034488ac0] mmco: unref short failure
[h264 @ 0x55a034488ac0] mmco: unref short failure
[h264 @ 0x55a034488ac0] mmco: unref short failure
[h264 @ 0x559c07633240] mmco: unref short failure
[h264 @ 0x559bec991280] mmco: unref short failure
[h264 @ 0x556b3c900240] mmco: unref short failure
[h264 @ 0x556b3df75900] mmco: unref short failure
[h264 @ 0x556b3df75900] mmco: unref short failure
[h264 @ 0x55a03faad400] mmco: unref short failure
[h264 @ 0x55a03faad400] mmco: unref short failure
[h264 @ 0x559bf75d9080] mmco: unref short failure
[h264 @ 0x556b3f6a6d80] mmco: unref short failure
[h264 @ 0x55a05033fac0] mmco: unref short failure
[h264 @ 0x55a05033fac0] mmco: unref short failure
[h264 @ 0x55a05033fac0] mmco: unref short failure
[h264 @ 0x55a05033fac0] mmco: unref short failure
[h264 @ 0x562427841f40] mmco: unref short failure
[h264 @ 0x562427841f40] mmco: unref short failure
[h264 @ 0x55a035811d00] mmco: unref short failure
[h264 @ 0x55a035811d00] mmco: unref short failure
[h264 @ 0x559bffd46500] mmco: unref short failure
[h264 @ 0x556b3860de80] mmco: unref short failure
[h264 @ 0x559bec991500] mmco: unref short failure
[h264 @ 0x559bec991500] mmco: unref short failure
[h264 @ 0x559c041dcf00] mmco: unref short failure
[h264 @ 0x559c041dcf00] mmco: unref short failure
[h264 @ 0x55a04fa74c00] mmco: unref short failure
[h264 @ 0x55a0556cbc00] mmco: unref short failure
[h264 @ 0x55a0556cbc00] mmco: unref short failure
 74%|███████▎  | 1432/1945 [7:43:44<3:19:19, 23.31s/it][h264 @ 0x556b2ed61880] mmco: unref short failure
[h264 @ 0x556b496f9e00] mmco: unref short failure
[h264 @ 0x556b496f9e00] mmco: unref short failure
[h264 @ 0x55a0345d2240] mmco: unref short failure
[h264 @ 0x55a0345d2240] mmco: unref short failure
[h264 @ 0x562422be1c00] mmco: unref short failure
[h264 @ 0x562422be1c00] mmco: unref short failure
 74%|███████▎  | 1433/1945 [7:43:59<2:58:21, 20.90s/it][h264 @ 0x56241726c5c0] mmco: unref short failure
[h264 @ 0x56241726c5c0] mmco: unref short failure
[h264 @ 0x55a039537a40] mmco: unref short failure
[h264 @ 0x55a039537a40] mmco: unref short failure
 74%|███████▎  | 1434/1945 [7:44:11<2:34:36, 18.15s/it][h264 @ 0x556b37504400] mmco: unref short failure
[h264 @ 0x556b37504400] mmco: unref short failure
[h264 @ 0x559bf03a8b00] mmco: unref short failure
[h264 @ 0x559bf03a8b00] mmco: unref short failure
[h264 @ 0x56242a0dbb00] mmco: unref short failure
[h264 @ 0x56242a0dbb00] mmco: unref short failure
 74%|███████▍  | 1435/1945 [7:44:17<2:04:30, 14.65s/it][h264 @ 0x556b41d37100] mmco: unref short failure
[h264 @ 0x556b41d37100] mmco: unref short failure
[h264 @ 0x556b3cadf780] mmco: unref short failure
 74%|███████▍  | 1436/1945 [7:44:26<1:48:06, 12.74s/it] 74%|███████▍  | 1437/1945 [7:44:33<1:35:17, 11.25s/it][h264 @ 0x55a0379fb0c0] mmco: unref short failure
[h264 @ 0x559bf47cf700] mmco: unref short failure
[h264 @ 0x559bf47cf700] mmco: unref short failure
[h264 @ 0x55a04057ec00] mmco: unref short failure
[h264 @ 0x55a04057ec00] mmco: unref short failure
[h264 @ 0x55a04057ec00] mmco: unref short failure
[h264 @ 0x55a04057ec00] mmco: unref short failure
 74%|███████▍  | 1438/1945 [7:44:52<1:54:13, 13.52s/it] 74%|███████▍  | 1439/1945 [7:44:59<1:36:22, 11.43s/it][h264 @ 0x559bf2c61d00] mmco: unref short failure
[h264 @ 0x559c0027bd00] mmco: unref short failure
[h264 @ 0x559c0027bd00] mmco: unref short failure
[h264 @ 0x559bf42eab40] mmco: unref short failure
[h264 @ 0x55a04e16d1c0] mmco: unref short failure
[h264 @ 0x55a04e16d1c0] mmco: unref short failure
[h264 @ 0x56241ebe4540] mmco: unref short failure
[h264 @ 0x56241ebe4540] mmco: unref short failure
[h264 @ 0x559bff7cca80] mmco: unref short failure
[h264 @ 0x559be9c37580] mmco: unref short failure
[h264 @ 0x559bf1505340] mmco: unref short failure
[h264 @ 0x559bf1505340] mmco: unref short failure
[h264 @ 0x559bec12d880] mmco: unref short failure
[h264 @ 0x559c0027b880] mmco: unref short failure
 74%|███████▍  | 1440/1945 [7:45:45<3:04:34, 21.93s/it][h264 @ 0x559bfe802900] mmco: unref short failure
[h264 @ 0x559bfe802900] mmco: unref short failure
[h264 @ 0x559bfe802900] mmco: unref short failure
[h264 @ 0x559bfe802900] mmco: unref short failure
[h264 @ 0x556b3e02e380] mmco: unref short failure
[h264 @ 0x556b3e02e380] mmco: unref short failure
[h264 @ 0x55a04982d800] mmco: unref short failure
[h264 @ 0x55a04982d800] mmco: unref short failure
[h264 @ 0x5624177174c0] mmco: unref short failure
[h264 @ 0x5624177174c0] mmco: unref short failure
[h264 @ 0x559bfd5e17c0] mmco: unref short failure
[h264 @ 0x559bfd5e17c0] mmco: unref short failure
 74%|███████▍  | 1441/1945 [7:46:10<3:11:44, 22.83s/it][h264 @ 0x55a0449283c0] mmco: unref short failure
[h264 @ 0x55a0449283c0] mmco: unref short failure
[h264 @ 0x56242cc5d800] mmco: unref short failure
[h264 @ 0x56242cc5d800] mmco: unref short failure
[h264 @ 0x56242cc5d800] mmco: unref short failure
[h264 @ 0x56242cc5d800] mmco: unref short failure
 74%|███████▍  | 1442/1945 [7:46:19<2:35:44, 18.58s/it][h264 @ 0x56241f7430c0] mmco: unref short failure
 74%|███████▍  | 1443/1945 [7:46:25<2:05:05, 14.95s/it][h264 @ 0x559bfc026080] mmco: unref short failure
[h264 @ 0x559bfc026080] mmco: unref short failure
 74%|███████▍  | 1444/1945 [7:46:33<1:46:23, 12.74s/it][h264 @ 0x556b460252c0] mmco: unref short failure
[h264 @ 0x556b3860dc80] mmco: unref short failure
[h264 @ 0x556b3860dc80] mmco: unref short failure
 74%|███████▍  | 1445/1945 [7:46:40<1:32:37, 11.11s/it][h264 @ 0x556b40f056c0] mmco: unref short failure
[h264 @ 0x562421b10500] mmco: unref short failure
[h264 @ 0x562421b10500] mmco: unref short failure
[h264 @ 0x562419429b80] mmco: unref short failure
[h264 @ 0x556b4778d280] mmco: unref short failure
[h264 @ 0x556b4778d280] mmco: unref short failure
[h264 @ 0x559bece37cc0] mmco: unref short failure
 74%|███████▍  | 1446/1945 [7:46:58<1:48:13, 13.01s/it][h264 @ 0x559bf7001100] mmco: unref short failure
[h264 @ 0x556b37504180] mmco: unref short failure
[h264 @ 0x556b37504180] mmco: unref short failure
[h264 @ 0x559bf1661900] mmco: unref short failure
[h264 @ 0x559bf1661900] mmco: unref short failure
 74%|███████▍  | 1447/1945 [7:47:06<1:35:32, 11.51s/it][h264 @ 0x559be9305880] mmco: unref short failure
[h264 @ 0x5624326a2800] mmco: unref short failure
[h264 @ 0x556b3a1af100] mmco: unref short failure
[h264 @ 0x5624220d2b80] mmco: unref short failure
[h264 @ 0x556b3c02cd80] mmco: unref short failure
[h264 @ 0x556b43c963c0] mmco: unref short failure
 74%|███████▍  | 1448/1945 [7:47:45<2:44:49, 19.90s/it][h264 @ 0x55a052d7ea80] mmco: unref short failure
[h264 @ 0x55a052d7ea80] mmco: unref short failure
[h264 @ 0x556b32f24000] mmco: unref short failure
[h264 @ 0x556b32f24000] mmco: unref short failure
 74%|███████▍  | 1449/1945 [7:48:08<2:53:21, 20.97s/it]09/10/2024 00:53:31 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/10/2024 00:53:31 - INFO - __main__ -   start running ret%tv validation...
[h264 @ 0x56241e6ee6c0] mmco: unref short failure
[h264 @ 0x56241e6ee6c0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a03d739480] mmco: unref short failure
[h264 @ 0x5624191fa5c0] mmco: unref short failure
[h264 @ 0x56241c6a9d00] mmco: unref short failure
[h264 @ 0x56241c6a9d00] mmco: unref short failure
[h264 @ 0x556b382928c0] mmco: unref short failure
[h264 @ 0x556b382928c0] mmco: unref short failure
[h264 @ 0x556b382928c0] mmco: unref short failure
[h264 @ 0x556b382928c0] mmco: unref short failure
[h264 @ 0x556b47a71580] mmco: unref short failure
[h264 @ 0x556b47a71580] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a0325a4a40] mmco: unref short failure
[h264 @ 0x55a0325a4a40] mmco: unref short failure
[h264 @ 0x562417d88d00] mmco: unref short failure
[h264 @ 0x559bf1fb5f40] mmco: unref short failure
[h264 @ 0x559bf1fb5f40] mmco: unref short failure
[h264 @ 0x55a03f407840] mmco: unref short failure
[h264 @ 0x562422be1e00] mmco: unref short failure
[h264 @ 0x562422be1e00] mmco: unref short failure
[h264 @ 0x56241c6a9d00] mmco: unref short failure
[h264 @ 0x56241c6a9d00] mmco: unref short failure
[h264 @ 0x559bf0218940] mmco: unref short failure
[h264 @ 0x55a04a34fd80] mmco: unref short failure
[h264 @ 0x55a052e91880] mmco: unref short failure
[h264 @ 0x556b2d670240] mmco: unref short failure
[h264 @ 0x55a0391c36c0] mmco: unref short failure
[h264 @ 0x562425c36700] mmco: unref short failure
[h264 @ 0x562425c36700] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:37,  1.39it/s][A[h264 @ 0x559c09339480] mmco: unref short failure
[h264 @ 0x559c09339480] mmco: unref short failure

  1%|          | 2/221 [00:01<02:35,  1.41it/s][A
  1%|▏         | 3/221 [00:01<01:44,  2.09it/s][A
  2%|▏         | 4/221 [00:01<01:17,  2.79it/s][A
  2%|▏         | 5/221 [00:02<01:06,  3.25it/s][A
  3%|▎         | 6/221 [00:02<00:52,  4.12it/s][A
  3%|▎         | 7/221 [00:02<00:53,  4.03it/s][A
  4%|▎         | 8/221 [00:02<01:15,  2.84it/s][A
  4%|▍         | 9/221 [00:03<01:03,  3.34it/s][A
  5%|▍         | 10/221 [00:03<01:05,  3.20it/s][A
  5%|▍         | 11/221 [00:03<01:01,  3.41it/s][A
  5%|▌         | 12/221 [00:04<01:34,  2.20it/s][A
  6%|▌         | 13/221 [00:04<01:15,  2.75it/s][A
  6%|▋         | 14/221 [00:06<02:32,  1.36it/s][A
  7%|▋         | 15/221 [00:06<02:01,  1.70it/s][A
  7%|▋         | 16/221 [00:06<01:43,  1.99it/s][A
  8%|▊         | 17/221 [00:07<01:23,  2.45it/s][A
  8%|▊         | 18/221 [00:07<01:17,  2.63it/s][A
  9%|▊         | 19/221 [00:07<01:07,  3.01it/s][A
  9%|▉         | 20/221 [00:07<00:57,  3.51it/s][A
 10%|▉         | 21/221 [00:08<00:55,  3.63it/s][A[h264 @ 0x556b476b3e00] mmco: unref short failure
[h264 @ 0x556b476b3e00] mmco: unref short failure
[h264 @ 0x556b476b3e00] mmco: unref short failure
[h264 @ 0x556b476b3e00] mmco: unref short failure

 10%|▉         | 22/221 [00:08<01:04,  3.07it/s][A
 10%|█         | 23/221 [00:08<00:55,  3.55it/s][A
 11%|█         | 24/221 [00:08<00:49,  4.00it/s][A
 11%|█▏        | 25/221 [00:09<00:45,  4.32it/s][A
 12%|█▏        | 26/221 [00:09<00:46,  4.17it/s][A
 12%|█▏        | 27/221 [00:09<00:47,  4.08it/s][A
 13%|█▎        | 28/221 [00:09<00:52,  3.69it/s][A
 13%|█▎        | 29/221 [00:10<00:51,  3.75it/s][A
 14%|█▎        | 30/221 [00:10<00:49,  3.84it/s][A
 14%|█▍        | 31/221 [00:10<00:43,  4.38it/s][A
 14%|█▍        | 32/221 [00:10<00:36,  5.24it/s][A
 15%|█▍        | 33/221 [00:10<00:42,  4.44it/s][A
 16%|█▌        | 35/221 [00:11<00:34,  5.37it/s][A
 16%|█▋        | 36/221 [00:11<00:36,  5.05it/s][A
 17%|█▋        | 37/221 [00:12<00:59,  3.09it/s][A
 17%|█▋        | 38/221 [00:12<00:57,  3.19it/s][A
 18%|█▊        | 39/221 [00:12<00:46,  3.88it/s][A
 18%|█▊        | 40/221 [00:12<00:47,  3.77it/s][A
 19%|█▊        | 41/221 [00:12<00:41,  4.35it/s][A
 19%|█▉        | 42/221 [00:13<00:53,  3.35it/s][A
 19%|█▉        | 43/221 [00:13<00:50,  3.52it/s][A
 20%|█▉        | 44/221 [00:13<00:48,  3.63it/s][A
 20%|██        | 45/221 [00:15<01:31,  1.93it/s][A
 21%|██        | 46/221 [00:15<01:26,  2.03it/s][A
 21%|██▏       | 47/221 [00:17<02:23,  1.21it/s][A
 22%|██▏       | 48/221 [00:17<01:50,  1.57it/s][A
 22%|██▏       | 49/221 [00:17<01:30,  1.90it/s][A
 23%|██▎       | 50/221 [00:17<01:11,  2.40it/s][A
 23%|██▎       | 51/221 [00:17<00:55,  3.09it/s][A
 24%|██▍       | 53/221 [00:17<00:36,  4.60it/s][A
 24%|██▍       | 54/221 [00:18<00:57,  2.88it/s][A
 25%|██▍       | 55/221 [00:19<01:11,  2.31it/s][A
 25%|██▌       | 56/221 [00:19<01:02,  2.65it/s][A
 26%|██▌       | 57/221 [00:19<00:53,  3.05it/s][A
 27%|██▋       | 59/221 [00:19<00:35,  4.55it/s][A
 27%|██▋       | 60/221 [00:20<00:40,  3.96it/s][A
 28%|██▊       | 61/221 [00:20<00:38,  4.21it/s][A
 28%|██▊       | 62/221 [00:20<00:34,  4.58it/s][A
 29%|██▊       | 63/221 [00:20<00:34,  4.60it/s][A
 29%|██▉       | 64/221 [00:21<00:29,  5.33it/s][A
 29%|██▉       | 65/221 [00:21<00:29,  5.38it/s][A
 30%|██▉       | 66/221 [00:21<00:37,  4.11it/s][A
 30%|███       | 67/221 [00:21<00:33,  4.66it/s][A
 31%|███       | 68/221 [00:21<00:28,  5.40it/s][A
 31%|███       | 69/221 [00:22<00:44,  3.45it/s][A
 32%|███▏      | 70/221 [00:22<00:38,  3.90it/s][A
 32%|███▏      | 71/221 [00:24<01:39,  1.50it/s][A
 33%|███▎      | 72/221 [00:24<01:18,  1.90it/s][A
 33%|███▎      | 73/221 [00:24<01:07,  2.19it/s][A
 33%|███▎      | 74/221 [00:24<00:53,  2.72it/s][A[h264 @ 0x559bf880d4c0] mmco: unref short failure

 34%|███▍      | 75/221 [00:25<00:52,  2.81it/s][A[h264 @ 0x559bf880d4c0] mmco: unref short failure

 34%|███▍      | 76/221 [00:25<00:41,  3.47it/s][A[h264 @ 0x559bf880d4c0] mmco: unref short failure

 35%|███▍      | 77/221 [00:25<00:35,  4.11it/s][A
 35%|███▌      | 78/221 [00:25<00:40,  3.49it/s][A
 36%|███▌      | 79/221 [00:26<01:00,  2.34it/s][A
 36%|███▌      | 80/221 [00:26<00:46,  3.02it/s][A
 37%|███▋      | 81/221 [00:26<00:39,  3.50it/s][A
 37%|███▋      | 82/221 [00:27<00:37,  3.66it/s][A
 38%|███▊      | 83/221 [00:27<00:33,  4.15it/s][A
 38%|███▊      | 84/221 [00:27<00:27,  4.94it/s][A
 39%|███▉      | 86/221 [00:27<00:19,  7.00it/s][A
 39%|███▉      | 87/221 [00:27<00:28,  4.75it/s][A
 40%|███▉      | 88/221 [00:28<00:32,  4.14it/s][A[h264 @ 0x559bfcb79800] mmco: unref short failure
[h264 @ 0x559bfcb79800] mmco: unref short failure

 40%|████      | 89/221 [00:31<02:03,  1.07it/s][A
 41%|████      | 90/221 [00:31<01:39,  1.31it/s][A
 41%|████      | 91/221 [00:31<01:14,  1.75it/s][A
 42%|████▏     | 92/221 [00:31<00:57,  2.26it/s][A
 42%|████▏     | 93/221 [00:32<00:55,  2.31it/s][A
 43%|████▎     | 94/221 [00:32<00:50,  2.51it/s][A
 43%|████▎     | 96/221 [00:32<00:36,  3.39it/s][A
 44%|████▍     | 98/221 [00:32<00:27,  4.48it/s][A
 45%|████▍     | 99/221 [00:33<00:24,  5.02it/s][A
 45%|████▌     | 100/221 [00:33<00:28,  4.31it/s][A
 46%|████▌     | 101/221 [00:33<00:23,  5.03it/s][A
 46%|████▌     | 102/221 [00:33<00:25,  4.70it/s][A
 47%|████▋     | 103/221 [00:33<00:25,  4.71it/s][A
 47%|████▋     | 104/221 [00:34<00:23,  5.06it/s][A
 48%|████▊     | 105/221 [00:34<00:22,  5.09it/s][A
 48%|████▊     | 106/221 [00:35<00:40,  2.81it/s][A
 48%|████▊     | 107/221 [00:35<00:34,  3.30it/s][A
 49%|████▉     | 108/221 [00:35<00:34,  3.30it/s][A
 49%|████▉     | 109/221 [00:35<00:31,  3.55it/s][A
 50%|█████     | 111/221 [00:36<00:28,  3.80it/s][A
 51%|█████     | 112/221 [00:36<00:26,  4.17it/s][A
 51%|█████     | 113/221 [00:36<00:34,  3.14it/s][A
 52%|█████▏    | 115/221 [00:37<00:23,  4.61it/s][A
 52%|█████▏    | 116/221 [00:41<02:05,  1.19s/it][A[h264 @ 0x55a04771fc80] mmco: unref short failure

 53%|█████▎    | 117/221 [00:41<01:40,  1.03it/s][A
 53%|█████▎    | 118/221 [00:42<01:23,  1.23it/s][A
 54%|█████▍    | 120/221 [00:42<00:54,  1.86it/s][A
 55%|█████▍    | 121/221 [00:42<00:46,  2.16it/s][A
 55%|█████▌    | 122/221 [00:42<00:40,  2.43it/s][A
 56%|█████▌    | 123/221 [00:43<00:35,  2.75it/s][A
 56%|█████▌    | 124/221 [00:43<00:34,  2.78it/s][A
 57%|█████▋    | 125/221 [00:43<00:30,  3.17it/s][A
 57%|█████▋    | 126/221 [00:44<00:31,  3.05it/s][A
 57%|█████▋    | 127/221 [00:44<00:30,  3.11it/s][A
 58%|█████▊    | 128/221 [00:44<00:31,  2.92it/s][A
 58%|█████▊    | 129/221 [00:44<00:26,  3.53it/s][A
 59%|█████▉    | 130/221 [00:45<00:21,  4.20it/s][A
 60%|█████▉    | 132/221 [00:45<00:15,  5.84it/s][A
 60%|██████    | 133/221 [00:45<00:20,  4.19it/s][A
 61%|██████    | 134/221 [00:45<00:19,  4.42it/s][A
 61%|██████    | 135/221 [00:46<00:23,  3.70it/s][A
 62%|██████▏   | 136/221 [00:46<00:24,  3.49it/s][A
 62%|██████▏   | 137/221 [00:46<00:21,  3.84it/s][A[h264 @ 0x56242c91f100] mmco: unref short failure

 62%|██████▏   | 138/221 [00:47<00:26,  3.15it/s][A
 63%|██████▎   | 139/221 [00:47<00:24,  3.32it/s][A
 63%|██████▎   | 140/221 [00:47<00:25,  3.16it/s][A
 64%|██████▍   | 141/221 [00:48<00:20,  3.82it/s][A[h264 @ 0x56241ccdb940] mmco: unref short failure
[h264 @ 0x56241ccdb940] mmco: unref short failure
[h264 @ 0x56241ccdb940] mmco: unref short failure
[h264 @ 0x56241ccdb940] mmco: unref short failure

 64%|██████▍   | 142/221 [00:48<00:30,  2.57it/s][A
 65%|██████▍   | 143/221 [00:49<00:28,  2.77it/s][A
 65%|██████▌   | 144/221 [00:49<00:22,  3.47it/s][A
 66%|██████▌   | 146/221 [00:49<00:13,  5.45it/s][A
 67%|██████▋   | 148/221 [00:49<00:12,  5.94it/s][A
 68%|██████▊   | 150/221 [00:49<00:09,  7.45it/s][A
 68%|██████▊   | 151/221 [00:50<00:14,  4.85it/s][A
 69%|██████▉   | 152/221 [00:50<00:12,  5.36it/s][A
 69%|██████▉   | 153/221 [00:50<00:16,  4.23it/s][A
 70%|██████▉   | 154/221 [00:51<00:23,  2.86it/s][A
 71%|███████   | 156/221 [00:51<00:15,  4.12it/s][A
 71%|███████   | 157/221 [00:55<01:04,  1.01s/it][A
 71%|███████▏  | 158/221 [00:55<00:50,  1.24it/s][A
 72%|███████▏  | 159/221 [00:55<00:39,  1.56it/s][A
 72%|███████▏  | 160/221 [00:55<00:30,  2.01it/s][A
 73%|███████▎  | 161/221 [00:55<00:23,  2.58it/s][A
 74%|███████▍  | 163/221 [00:55<00:16,  3.55it/s][A
 74%|███████▍  | 164/221 [00:56<00:14,  3.89it/s][A
 75%|███████▍  | 165/221 [00:56<00:12,  4.41it/s][A
 75%|███████▌  | 166/221 [00:56<00:15,  3.61it/s][A
 76%|███████▌  | 167/221 [00:56<00:12,  4.22it/s][A
 76%|███████▌  | 168/221 [01:00<01:09,  1.31s/it][A
 76%|███████▋  | 169/221 [01:01<00:51,  1.00it/s][A
 77%|███████▋  | 170/221 [01:01<00:39,  1.29it/s][A
 77%|███████▋  | 171/221 [01:01<00:29,  1.69it/s][A
 78%|███████▊  | 172/221 [01:01<00:24,  2.01it/s][A
 79%|███████▊  | 174/221 [01:01<00:14,  3.33it/s][A
 79%|███████▉  | 175/221 [01:02<00:13,  3.45it/s][A
 80%|███████▉  | 176/221 [01:02<00:12,  3.67it/s][A
 81%|████████  | 178/221 [01:02<00:10,  4.22it/s][A
 81%|████████  | 179/221 [01:04<00:20,  2.03it/s][A
 82%|████████▏ | 181/221 [01:04<00:13,  2.88it/s][A
 82%|████████▏ | 182/221 [01:04<00:12,  3.24it/s][A
 83%|████████▎ | 183/221 [01:04<00:10,  3.75it/s][A
 83%|████████▎ | 184/221 [01:05<00:10,  3.38it/s][A
 84%|████████▍ | 186/221 [01:05<00:08,  4.18it/s][A
 85%|████████▍ | 187/221 [01:05<00:07,  4.73it/s][A[h264 @ 0x55a0325fdd40] mmco: unref short failure

 85%|████████▌ | 188/221 [01:05<00:07,  4.33it/s][A
 86%|████████▌ | 189/221 [01:06<00:07,  4.17it/s][A
 86%|████████▌ | 190/221 [01:06<00:06,  4.51it/s][A
 87%|████████▋ | 192/221 [01:06<00:05,  5.15it/s][A[h264 @ 0x5624306bca80] mmco: unref short failure
[h264 @ 0x5624306bca80] mmco: unref short failure

 88%|████████▊ | 194/221 [01:06<00:05,  4.73it/s][A
 88%|████████▊ | 195/221 [01:07<00:04,  5.30it/s][A
 89%|████████▉ | 197/221 [01:07<00:03,  7.08it/s][A
 90%|████████▉ | 198/221 [01:07<00:03,  6.54it/s][A[h264 @ 0x55a03c7c8640] mmco: unref short failure
[h264 @ 0x55a03c7c8640] mmco: unref short failure

 90%|█████████ | 199/221 [01:07<00:03,  6.40it/s][A[h264 @ 0x556b2dc255c0] mmco: unref short failure
[h264 @ 0x556b2dc255c0] mmco: unref short failure

 90%|█████████ | 200/221 [01:07<00:04,  5.07it/s][A
 91%|█████████ | 201/221 [01:08<00:04,  4.70it/s][A
 91%|█████████▏| 202/221 [01:08<00:03,  5.28it/s][A
 92%|█████████▏| 203/221 [01:08<00:03,  5.88it/s][A
 93%|█████████▎| 205/221 [01:08<00:02,  7.97it/s][A
 93%|█████████▎| 206/221 [01:09<00:03,  4.84it/s][A
 94%|█████████▍| 208/221 [01:09<00:02,  6.45it/s][A
 95%|█████████▌| 211/221 [01:09<00:01,  6.82it/s][A
 96%|█████████▋| 213/221 [01:09<00:01,  7.93it/s][A
 97%|█████████▋| 214/221 [01:10<00:01,  5.62it/s][A
 97%|█████████▋| 215/221 [01:10<00:01,  5.71it/s][A
 98%|█████████▊| 216/221 [01:10<00:00,  5.77it/s][A
 98%|█████████▊| 217/221 [01:11<00:01,  2.71it/s][A
 99%|█████████▊| 218/221 [01:11<00:00,  3.15it/s][A
 99%|█████████▉| 219/221 [01:11<00:00,  3.41it/s][A
100%|█████████▉| 220/221 [01:16<00:01,  1.45s/it][A
100%|██████████| 221/221 [01:16<00:00,  1.06s/it][A100%|██████████| 221/221 [01:16<00:00,  2.89it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:51,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:22<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:32<00:25,  3.78it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.78it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:37<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:51<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:27,  7.96it/s][A
  1%|          | 2/221 [00:00<00:41,  5.34it/s][A
  1%|▏         | 3/221 [00:00<00:46,  4.66it/s][A
  2%|▏         | 4/221 [00:00<00:42,  5.16it/s][A
  2%|▏         | 5/221 [00:00<00:42,  5.03it/s][A
  3%|▎         | 7/221 [00:01<00:38,  5.55it/s][A
  4%|▎         | 8/221 [00:01<00:45,  4.63it/s][A
  4%|▍         | 9/221 [00:01<00:46,  4.55it/s][A
  5%|▍         | 10/221 [00:02<01:07,  3.12it/s][A
  5%|▍         | 11/221 [00:02<00:57,  3.64it/s][A
  5%|▌         | 12/221 [00:02<00:48,  4.32it/s][A
  6%|▌         | 13/221 [00:03<01:27,  2.39it/s][A
  6%|▋         | 14/221 [00:03<01:08,  3.03it/s][A
  7%|▋         | 15/221 [00:03<01:00,  3.38it/s][A
  7%|▋         | 16/221 [00:04<01:05,  3.13it/s][A
  8%|▊         | 17/221 [00:04<01:23,  2.43it/s][A
  8%|▊         | 18/221 [00:05<01:09,  2.90it/s][A
  9%|▊         | 19/221 [00:05<00:58,  3.43it/s][A
 10%|▉         | 21/221 [00:05<00:42,  4.68it/s][A
 10%|▉         | 22/221 [00:05<00:41,  4.84it/s][A
 10%|█         | 23/221 [00:05<00:35,  5.51it/s][A
 11%|█         | 24/221 [00:05<00:34,  5.71it/s][A
 11%|█▏        | 25/221 [00:06<00:33,  5.79it/s][A
 12%|█▏        | 26/221 [00:06<00:36,  5.41it/s][A
 12%|█▏        | 27/221 [00:06<00:32,  5.92it/s][A
 13%|█▎        | 28/221 [00:06<00:42,  4.51it/s][A
 13%|█▎        | 29/221 [00:07<00:44,  4.30it/s][A
 14%|█▎        | 30/221 [00:07<00:47,  4.00it/s][A
 14%|█▍        | 31/221 [00:07<00:43,  4.33it/s][A
 14%|█▍        | 32/221 [00:07<00:37,  4.98it/s][A
 15%|█▍        | 33/221 [00:07<00:38,  4.91it/s][A
 15%|█▌        | 34/221 [00:08<00:40,  4.62it/s][A
 16%|█▌        | 35/221 [00:08<00:47,  3.90it/s][A
 16%|█▋        | 36/221 [00:08<00:51,  3.60it/s][A
 17%|█▋        | 37/221 [00:08<00:42,  4.28it/s][A
 17%|█▋        | 38/221 [00:09<00:44,  4.12it/s][A
 18%|█▊        | 39/221 [00:09<00:42,  4.27it/s][A
 18%|█▊        | 40/221 [00:09<00:49,  3.65it/s][A
 19%|█▊        | 41/221 [00:09<00:43,  4.09it/s][A
 19%|█▉        | 42/221 [00:10<00:37,  4.81it/s][A
 19%|█▉        | 43/221 [00:10<00:44,  4.05it/s][A
 20%|█▉        | 44/221 [00:10<00:46,  3.82it/s][A
 20%|██        | 45/221 [00:11<00:49,  3.54it/s][A
 21%|██        | 46/221 [00:11<00:45,  3.85it/s][A
 21%|██▏       | 47/221 [00:11<00:44,  3.87it/s][A
 22%|██▏       | 48/221 [00:11<00:38,  4.44it/s][A
 22%|██▏       | 49/221 [00:11<00:40,  4.29it/s][A
 23%|██▎       | 50/221 [00:12<00:55,  3.07it/s][A
 23%|██▎       | 51/221 [00:12<00:47,  3.60it/s][A
 24%|██▎       | 52/221 [00:12<00:48,  3.50it/s][A
 24%|██▍       | 53/221 [00:13<00:39,  4.29it/s][A
 24%|██▍       | 54/221 [00:13<00:48,  3.42it/s][A
 25%|██▍       | 55/221 [00:13<00:48,  3.39it/s][A
 25%|██▌       | 56/221 [00:13<00:43,  3.80it/s][A
 26%|██▌       | 57/221 [00:14<00:46,  3.54it/s][A
 26%|██▌       | 58/221 [00:14<00:51,  3.18it/s][A
 27%|██▋       | 59/221 [00:14<00:45,  3.53it/s][A
 27%|██▋       | 60/221 [00:15<00:39,  4.09it/s][A
 28%|██▊       | 61/221 [00:15<00:36,  4.39it/s][A
 28%|██▊       | 62/221 [00:15<00:37,  4.28it/s][A
 29%|██▊       | 63/221 [00:15<00:35,  4.43it/s][A
 29%|██▉       | 64/221 [00:16<00:40,  3.90it/s][A
 29%|██▉       | 65/221 [00:16<00:36,  4.29it/s][A
 30%|██▉       | 66/221 [00:16<00:48,  3.18it/s][A
 30%|███       | 67/221 [00:17<00:49,  3.09it/s][A
 31%|███       | 68/221 [00:17<00:42,  3.63it/s][A
 31%|███       | 69/221 [00:18<01:06,  2.29it/s][A
 32%|███▏      | 70/221 [00:18<00:52,  2.86it/s][A
 32%|███▏      | 71/221 [00:18<00:45,  3.29it/s][A
 33%|███▎      | 72/221 [00:18<00:49,  3.02it/s][A
 33%|███▎      | 73/221 [00:19<00:48,  3.07it/s][A
 33%|███▎      | 74/221 [00:19<00:41,  3.51it/s][A
 34%|███▍      | 75/221 [00:19<00:40,  3.61it/s][A
 34%|███▍      | 76/221 [00:19<00:37,  3.82it/s][A
 35%|███▍      | 77/221 [00:20<00:40,  3.59it/s][A
 35%|███▌      | 78/221 [00:20<00:35,  3.97it/s][A
 36%|███▌      | 79/221 [00:20<00:42,  3.33it/s][A
 36%|███▌      | 80/221 [00:20<00:39,  3.58it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.85it/s][A
 37%|███▋      | 82/221 [00:21<00:44,  3.12it/s][A
 38%|███▊      | 83/221 [00:21<00:45,  3.02it/s][A
 38%|███▊      | 84/221 [00:22<00:43,  3.14it/s][A
 38%|███▊      | 85/221 [00:22<00:34,  3.93it/s][A
 39%|███▉      | 86/221 [00:22<00:36,  3.67it/s][A
 39%|███▉      | 87/221 [00:23<00:45,  2.94it/s][A
 40%|███▉      | 88/221 [00:23<00:50,  2.65it/s][A
 40%|████      | 89/221 [00:23<00:45,  2.93it/s][A
 41%|████      | 90/221 [00:24<00:49,  2.65it/s][A
 41%|████      | 91/221 [00:24<00:39,  3.28it/s][A
 42%|████▏     | 92/221 [00:24<00:42,  3.05it/s][A
 42%|████▏     | 93/221 [00:25<00:57,  2.24it/s][A
 43%|████▎     | 94/221 [00:25<00:50,  2.50it/s][A
 43%|████▎     | 95/221 [00:26<00:45,  2.76it/s][A
 43%|████▎     | 96/221 [00:26<00:40,  3.05it/s][A
 44%|████▍     | 97/221 [00:26<00:35,  3.53it/s][A
 44%|████▍     | 98/221 [00:26<00:34,  3.53it/s][A
 45%|████▍     | 99/221 [00:27<00:31,  3.93it/s][A
 45%|████▌     | 100/221 [00:27<00:32,  3.75it/s][A
 46%|████▌     | 101/221 [00:27<00:30,  3.96it/s][A
 46%|████▌     | 102/221 [00:28<00:46,  2.55it/s][A
 47%|████▋     | 103/221 [00:28<00:36,  3.20it/s][A
 47%|████▋     | 104/221 [00:28<00:30,  3.88it/s][A
 48%|████▊     | 105/221 [00:28<00:31,  3.66it/s][A
 48%|████▊     | 106/221 [00:29<00:34,  3.38it/s][A
 48%|████▊     | 107/221 [00:29<00:29,  3.91it/s][A
 49%|████▉     | 108/221 [00:29<00:29,  3.90it/s][A
 50%|████▉     | 110/221 [00:29<00:23,  4.67it/s][A
 50%|█████     | 111/221 [00:30<00:25,  4.35it/s][A
 51%|█████     | 112/221 [00:30<00:25,  4.35it/s][A
 51%|█████     | 113/221 [00:30<00:23,  4.52it/s][A
 52%|█████▏    | 114/221 [00:30<00:20,  5.26it/s][A
 52%|█████▏    | 115/221 [00:30<00:21,  4.94it/s][A
 52%|█████▏    | 116/221 [00:31<00:22,  4.61it/s][A
 53%|█████▎    | 117/221 [00:31<00:23,  4.39it/s][A
 53%|█████▎    | 118/221 [00:31<00:22,  4.56it/s][A
 54%|█████▍    | 119/221 [00:32<00:28,  3.54it/s][A
 54%|█████▍    | 120/221 [00:32<00:25,  3.99it/s][A
 55%|█████▍    | 121/221 [00:32<00:20,  4.80it/s][A
 55%|█████▌    | 122/221 [00:32<00:22,  4.44it/s][A
 56%|█████▌    | 123/221 [00:33<00:25,  3.84it/s][A
 56%|█████▌    | 124/221 [00:33<00:24,  3.99it/s][A
 57%|█████▋    | 125/221 [00:33<00:26,  3.57it/s][A
 57%|█████▋    | 126/221 [00:33<00:23,  3.97it/s][A
 57%|█████▋    | 127/221 [00:34<00:28,  3.25it/s][A
 58%|█████▊    | 128/221 [00:34<00:26,  3.53it/s][A
 58%|█████▊    | 129/221 [00:34<00:21,  4.28it/s][A
 59%|█████▉    | 130/221 [00:34<00:21,  4.19it/s][A
 59%|█████▉    | 131/221 [00:34<00:18,  4.90it/s][A
 60%|█████▉    | 132/221 [00:35<00:21,  4.15it/s][A
 60%|██████    | 133/221 [00:35<00:24,  3.54it/s][A
 61%|██████    | 134/221 [00:36<00:32,  2.66it/s][A
 61%|██████    | 135/221 [00:36<00:34,  2.48it/s][A
 62%|██████▏   | 136/221 [00:36<00:29,  2.85it/s][A
 62%|██████▏   | 137/221 [00:37<00:24,  3.45it/s][A
 62%|██████▏   | 138/221 [00:37<00:24,  3.45it/s][A
 63%|██████▎   | 139/221 [00:37<00:26,  3.12it/s][A
 63%|██████▎   | 140/221 [00:38<00:25,  3.19it/s][A
 64%|██████▍   | 141/221 [00:38<00:22,  3.62it/s][A
 64%|██████▍   | 142/221 [00:38<00:20,  3.83it/s][A
 65%|██████▍   | 143/221 [00:38<00:25,  3.12it/s][A
 65%|██████▌   | 144/221 [00:39<00:26,  2.93it/s][A
 66%|██████▌   | 145/221 [00:39<00:20,  3.63it/s][A
 67%|██████▋   | 147/221 [00:39<00:16,  4.41it/s][A
 67%|██████▋   | 148/221 [00:40<00:20,  3.64it/s][A
 67%|██████▋   | 149/221 [00:40<00:20,  3.55it/s][A
 68%|██████▊   | 150/221 [00:40<00:18,  3.78it/s][A
 68%|██████▊   | 151/221 [00:41<00:22,  3.11it/s][A
 69%|██████▉   | 152/221 [00:41<00:29,  2.36it/s][A
 69%|██████▉   | 153/221 [00:41<00:23,  2.94it/s][A
 70%|██████▉   | 154/221 [00:42<00:20,  3.26it/s][A
 70%|███████   | 155/221 [00:42<00:18,  3.62it/s][A
 71%|███████   | 156/221 [00:42<00:20,  3.18it/s][A
 71%|███████   | 157/221 [00:43<00:20,  3.20it/s][A
 71%|███████▏  | 158/221 [00:43<00:18,  3.44it/s][A
 72%|███████▏  | 159/221 [00:43<00:15,  4.10it/s][A
 72%|███████▏  | 160/221 [00:43<00:14,  4.27it/s][A
 73%|███████▎  | 161/221 [00:44<00:19,  3.03it/s][A
 73%|███████▎  | 162/221 [00:44<00:16,  3.69it/s][A
 74%|███████▍  | 163/221 [00:44<00:15,  3.77it/s][A
 74%|███████▍  | 164/221 [00:44<00:13,  4.29it/s][A
 75%|███████▍  | 165/221 [00:45<00:13,  4.29it/s][A
 75%|███████▌  | 166/221 [00:45<00:12,  4.33it/s][A
 76%|███████▌  | 167/221 [00:45<00:10,  5.07it/s][A
 76%|███████▌  | 168/221 [00:45<00:12,  4.29it/s][A
 76%|███████▋  | 169/221 [00:45<00:10,  5.10it/s][A
 77%|███████▋  | 170/221 [00:46<00:14,  3.51it/s][A
 77%|███████▋  | 171/221 [00:46<00:13,  3.84it/s][A
 78%|███████▊  | 172/221 [00:46<00:12,  3.97it/s][A
 78%|███████▊  | 173/221 [00:47<00:13,  3.61it/s][A
 79%|███████▊  | 174/221 [00:47<00:15,  3.02it/s][A
 79%|███████▉  | 175/221 [00:47<00:15,  3.00it/s][A
 80%|███████▉  | 176/221 [00:48<00:13,  3.28it/s][A
 80%|████████  | 177/221 [00:48<00:12,  3.60it/s][A
 81%|████████  | 178/221 [00:48<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:48<00:11,  3.56it/s][A
 81%|████████▏ | 180/221 [00:49<00:10,  4.07it/s][A
 82%|████████▏ | 181/221 [00:49<00:10,  3.86it/s][A
 82%|████████▏ | 182/221 [00:49<00:11,  3.30it/s][A
 83%|████████▎ | 183/221 [00:50<00:11,  3.35it/s][A
 83%|████████▎ | 184/221 [00:50<00:10,  3.39it/s][A
 84%|████████▎ | 185/221 [00:50<00:09,  3.69it/s][A
 84%|████████▍ | 186/221 [00:51<00:12,  2.83it/s][A
 85%|████████▍ | 187/221 [00:51<00:10,  3.25it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.33it/s][A
 86%|████████▌ | 189/221 [00:51<00:08,  3.64it/s][A
 86%|████████▌ | 190/221 [00:52<00:09,  3.16it/s][A
 86%|████████▋ | 191/221 [00:52<00:08,  3.65it/s][A
 87%|████████▋ | 192/221 [00:52<00:07,  3.76it/s][A
 87%|████████▋ | 193/221 [00:52<00:06,  4.30it/s][A
 88%|████████▊ | 194/221 [00:53<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:53<00:06,  3.96it/s][A
 89%|████████▊ | 196/221 [00:53<00:07,  3.46it/s][A
 89%|████████▉ | 197/221 [00:53<00:06,  3.77it/s][A
 90%|████████▉ | 198/221 [00:54<00:07,  3.07it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.45it/s][A
 90%|█████████ | 200/221 [00:54<00:06,  3.17it/s][A
 91%|█████████ | 201/221 [00:55<00:05,  3.61it/s][A
 91%|█████████▏| 202/221 [00:55<00:05,  3.33it/s][A
 92%|█████████▏| 203/221 [00:55<00:04,  3.81it/s][A
 92%|█████████▏| 204/221 [00:56<00:04,  3.50it/s][A
 93%|█████████▎| 205/221 [00:56<00:03,  4.29it/s][A
 93%|█████████▎| 206/221 [00:56<00:03,  3.76it/s][A
 94%|█████████▎| 207/221 [00:56<00:03,  3.88it/s][A
 94%|█████████▍| 208/221 [00:57<00:03,  3.85it/s][A
 95%|█████████▍| 209/221 [00:57<00:02,  4.12it/s][A
 95%|█████████▌| 210/221 [00:57<00:02,  4.29it/s][A
 95%|█████████▌| 211/221 [00:57<00:02,  3.81it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  3.51it/s][A
 96%|█████████▋| 213/221 [00:58<00:02,  3.77it/s][A
 97%|█████████▋| 214/221 [00:58<00:02,  2.68it/s][A
 97%|█████████▋| 215/221 [00:59<00:01,  3.07it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.30it/s][A
 98%|█████████▊| 217/221 [00:59<00:01,  3.22it/s][A
 99%|█████████▊| 218/221 [00:59<00:00,  3.41it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.06it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.55it/s][A
100%|██████████| 221/221 [01:00<00:00,  3.88it/s][A100%|██████████| 221/221 [01:00<00:00,  3.64it/s]
09/10/2024 00:59:13 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 1449--===========

09/10/2024 00:59:13 - INFO - __main__ -   {'area_r1': 37.9, 'area_recall': '37.9/61.7/72.2', 'area_ravg': 57.2}
09/10/2024 00:59:13 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 1449--===========

09/10/2024 00:59:13 - INFO - __main__ -   {'forward_r1': 36.5, 'forward_recall': '36.5/65.4/76.2', 'forward_ravg': 59.4}
09/10/2024 00:59:13 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 1449--===========

09/10/2024 00:59:13 - INFO - __main__ -   {'area_video_r1': 38.6, 'area_video_recall': '38.6/66.7/76.8', 'area_video_ravg': 60.7}
09/10/2024 00:59:13 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/10/2024 00:59:13 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/10/2024 00:59:13 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 1449--===========

09/10/2024 00:59:13 - INFO - __main__ -   {'area_video_r1': 51.7, 'area_video_recall': '51.7/74.1/81.2', 'area_video_ravg': 69.0, 'area_video_back_r1': 47.9, 'area_video_back_recall': '47.9/73.8/81.8', 'area_video_back_ravg': 67.8}
09/10/2024 00:59:13 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/10/2024 00:59:13 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/10/2024 00:59:13 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 1449--===========

09/10/2024 00:59:13 - INFO - __main__ -   {'video_r1': 43.4, 'video_recall': '43.4/71.7/81.2', 'video_ravg': 65.5}
09/10/2024 00:59:13 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/10/2024 00:59:13 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/10/2024 00:59:13 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 1449--===========

09/10/2024 00:59:13 - INFO - __main__ -   {'video_r1': 51.6, 'video_recall': '51.6/75.2/83.0', 'video_ravg': 69.9}
09/10/2024 00:59:13 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/10/2024 00:59:13 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/10/2024 00:59:34 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.005815231706947088, 'loss_ret%tv%ta--finetune_area/loss_area': 0.996150553226471, 'loss_ret%tv%ta--finetune_area/total_loss': 1.0019657611846924}
 75%|███████▍  | 1450/1945 [7:54:14<17:06:33, 124.43s/it] 75%|███████▍  | 1451/1945 [7:54:19<12:08:16, 88.45s/it] [h264 @ 0x55a0448f5b80] mmco: unref short failure
[h264 @ 0x55a0448f5b80] mmco: unref short failure
 75%|███████▍  | 1452/1945 [7:54:23<8:40:09, 63.31s/it]  75%|███████▍  | 1453/1945 [7:54:29<6:17:12, 46.00s/it][h264 @ 0x55a032eed9c0] mmco: unref short failure
 75%|███████▍  | 1454/1945 [7:54:35<4:37:29, 33.91s/it][h264 @ 0x5624219f6580] mmco: unref short failure
[h264 @ 0x5624219f6580] mmco: unref short failure
 75%|███████▍  | 1455/1945 [7:54:41<3:28:27, 25.53s/it][h264 @ 0x556b2d9e1d80] mmco: unref short failure
[h264 @ 0x556b31fb4300] mmco: unref short failure
[h264 @ 0x556b31fb4300] mmco: unref short failure
[h264 @ 0x5624290fdf00] mmco: unref short failure
[h264 @ 0x559c0632e740] mmco: unref short failure
[h264 @ 0x559c0632e740] mmco: unref short failure
 75%|███████▍  | 1456/1945 [7:54:47<2:41:47, 19.85s/it][h264 @ 0x556b359b55c0] mmco: unref short failure
 75%|███████▍  | 1457/1945 [7:54:56<2:13:51, 16.46s/it][h264 @ 0x559bebfb2480] mmco: unref short failure
[h264 @ 0x559bebfb2480] mmco: unref short failure
 75%|███████▍  | 1458/1945 [7:55:03<1:49:49, 13.53s/it] 75%|███████▌  | 1459/1945 [7:55:10<1:34:14, 11.63s/it][h264 @ 0x556b43010a00] mmco: unref short failure
[h264 @ 0x559c0682b200] mmco: unref short failure
[h264 @ 0x559c0682b200] mmco: unref short failure
[h264 @ 0x556b3c424d80] mmco: unref short failure
[h264 @ 0x556b3c424d80] mmco: unref short failure
 75%|███████▌  | 1460/1945 [7:55:19<1:27:17, 10.80s/it][h264 @ 0x55a03be5bd40] mmco: unref short failure
[h264 @ 0x55a03be5bd40] mmco: unref short failure
 75%|███████▌  | 1461/1945 [7:55:25<1:15:56,  9.41s/it] 75%|███████▌  | 1462/1945 [7:55:31<1:08:35,  8.52s/it][h264 @ 0x559c036fa7c0] mmco: unref short failure
 75%|███████▌  | 1463/1945 [7:55:38<1:04:28,  8.03s/it][h264 @ 0x559c0632e540] mmco: unref short failure
[h264 @ 0x559c0632e540] mmco: unref short failure
[h264 @ 0x562438a1a840] mmco: unref short failure
[h264 @ 0x562438a1a840] mmco: unref short failure
[h264 @ 0x556b3f219600] mmco: unref short failure
[h264 @ 0x559bf144c680] mmco: unref short failure
[h264 @ 0x559bf144c680] mmco: unref short failure
[h264 @ 0x556b2cd7c300] mmco: unref short failure
[h264 @ 0x556b2cd7c300] mmco: unref short failure
[h264 @ 0x55a042165900] mmco: unref short failure
[h264 @ 0x55a042165900] mmco: unref short failure
 75%|███████▌  | 1464/1945 [7:55:46<1:04:07,  8.00s/it][h264 @ 0x55a04536a140] mmco: unref short failure
[h264 @ 0x55a04536a140] mmco: unref short failure
[h264 @ 0x55a04536a140] mmco: unref short failure
[h264 @ 0x55a04536a140] mmco: unref short failure
 75%|███████▌  | 1465/1945 [7:55:54<1:03:57,  8.00s/it][h264 @ 0x55a044fdf440] mmco: unref short failure
 75%|███████▌  | 1466/1945 [7:56:01<1:01:13,  7.67s/it] 75%|███████▌  | 1467/1945 [7:56:08<59:45,  7.50s/it]  [h264 @ 0x56243504fac0] mmco: unref short failure
[h264 @ 0x56243504fac0] mmco: unref short failure
[h264 @ 0x56242a895d80] mmco: unref short failure
[h264 @ 0x56242a895d80] mmco: unref short failure
[h264 @ 0x55a055e208c0] mmco: unref short failure
[h264 @ 0x55a055e208c0] mmco: unref short failure
[h264 @ 0x56241a886100] mmco: unref short failure
[h264 @ 0x56241a886100] mmco: unref short failure
 75%|███████▌  | 1468/1945 [7:56:18<1:04:58,  8.17s/it][h264 @ 0x556b2d708040] mmco: unref short failure
[h264 @ 0x556b2d708040] mmco: unref short failure
[h264 @ 0x556b2d708040] mmco: unref short failure
[h264 @ 0x556b2d708040] mmco: unref short failure
[h264 @ 0x55a03a4a1000] mmco: unref short failure
[h264 @ 0x55a03a4a1000] mmco: unref short failure
[h264 @ 0x56243504fcc0] mmco: unref short failure
[h264 @ 0x559bed532040] mmco: unref short failure
 76%|███████▌  | 1469/1945 [7:56:32<1:19:00,  9.96s/it][h264 @ 0x556b42c4ea40] mmco: unref short failure
[h264 @ 0x556b42c4ea40] mmco: unref short failure
[h264 @ 0x556b42c4ea40] mmco: unref short failure
 76%|███████▌  | 1470/1945 [7:56:39<1:12:24,  9.15s/it][h264 @ 0x556b46399d80] mmco: unref short failure
[h264 @ 0x556b46399d80] mmco: unref short failure
[h264 @ 0x556b46399d80] mmco: unref short failure
[h264 @ 0x556b46399d80] mmco: unref short failure
[h264 @ 0x556b46399d80] mmco: unref short failure
[h264 @ 0x556b46399d80] mmco: unref short failure
[h264 @ 0x55a04fa53000] mmco: unref short failure
[h264 @ 0x55a04fa53000] mmco: unref short failure
[h264 @ 0x559c0152aa00] mmco: unref short failure
[h264 @ 0x559c0152aa00] mmco: unref short failure
 76%|███████▌  | 1471/1945 [7:57:00<1:40:54, 12.77s/it] 76%|███████▌  | 1472/1945 [7:57:08<1:28:46, 11.26s/it][h264 @ 0x562415f2b940] mmco: unref short failure
[h264 @ 0x559bebecd180] mmco: unref short failure
[h264 @ 0x559bebecd180] mmco: unref short failure
[h264 @ 0x559c01d30280] mmco: unref short failure
[h264 @ 0x559bf8dbcf80] mmco: unref short failure
 76%|███████▌  | 1473/1945 [7:57:17<1:21:52, 10.41s/it][h264 @ 0x559bee620780] mmco: unref short failure
[h264 @ 0x55a04c8203c0] mmco: unref short failure
[h264 @ 0x55a04c8203c0] mmco: unref short failure
[h264 @ 0x556b2caea300] mmco: unref short failure
[h264 @ 0x556b2caea300] mmco: unref short failure
[h264 @ 0x556b3612e4c0] mmco: unref short failure
[h264 @ 0x556b3612e4c0] mmco: unref short failure
[h264 @ 0x5624216bf100] mmco: unref short failure
[h264 @ 0x5624216bf100] mmco: unref short failure
[h264 @ 0x55a03d3ad500] mmco: unref short failure
[h264 @ 0x55a03d3ad500] mmco: unref short failure
[h264 @ 0x55a03d3ad500] mmco: unref short failure
[h264 @ 0x556b2d723d40] mmco: unref short failure
[h264 @ 0x556b2d723d40] mmco: unref short failure
 76%|███████▌  | 1474/1945 [7:57:47<2:09:59, 16.56s/it][h264 @ 0x556b2d723d40] mmco: unref short failure
[h264 @ 0x556b2d723d40] mmco: unref short failure
[h264 @ 0x556b343334c0] mmco: unref short failure
[h264 @ 0x556b343334c0] mmco: unref short failure
[h264 @ 0x556b38f4e100] mmco: unref short failure
[h264 @ 0x55a043a42340] mmco: unref short failure
[h264 @ 0x55a037f52c80] mmco: unref short failure
[h264 @ 0x55a037f52c80] mmco: unref short failure
[h264 @ 0x56241ecbe080] mmco: unref short failure
[h264 @ 0x56242db6ae40] mmco: unref short failure
[h264 @ 0x56242db6ae40] mmco: unref short failure
 76%|███████▌  | 1475/1945 [7:58:14<2:34:00, 19.66s/it][h264 @ 0x559bfa0ccf00] mmco: unref short failure
[h264 @ 0x559bfa0ccf00] mmco: unref short failure
 76%|███████▌  | 1476/1945 [7:58:22<2:06:04, 16.13s/it][h264 @ 0x55a04087f0c0] mmco: unref short failure
[h264 @ 0x55a04087f0c0] mmco: unref short failure
[h264 @ 0x55a04746dc40] mmco: unref short failure
[h264 @ 0x55a04746dc40] mmco: unref short failure
[h264 @ 0x559c079159c0] mmco: unref short failure
[h264 @ 0x55a048142e80] mmco: unref short failure
[h264 @ 0x556b37a32e00] mmco: unref short failure
[h264 @ 0x556b37a32e00] mmco: unref short failure
 76%|███████▌  | 1477/1945 [7:58:30<1:46:26, 13.65s/it][h264 @ 0x556b4a295a40] mmco: unref short failure
[h264 @ 0x556b4a295a40] mmco: unref short failure
 76%|███████▌  | 1478/1945 [7:58:44<1:46:41, 13.71s/it][h264 @ 0x56241ce45cc0] mmco: unref short failure
[h264 @ 0x56242c7e3ac0] mmco: unref short failure
[h264 @ 0x56242c7e3ac0] mmco: unref short failure
[h264 @ 0x556b37e220c0] mmco: unref short failure
[h264 @ 0x556b37e220c0] mmco: unref short failure
[h264 @ 0x556b3a505ec0] mmco: unref short failure
[h264 @ 0x556b3a505ec0] mmco: unref short failure
[h264 @ 0x55a04792ab40] mmco: unref short failure
 76%|███████▌  | 1479/1945 [7:59:06<2:06:56, 16.34s/it] 76%|███████▌  | 1480/1945 [7:59:15<1:47:45, 13.91s/it] 76%|███████▌  | 1481/1945 [7:59:22<1:33:08, 12.04s/it][h264 @ 0x559bea7823c0] mmco: unref short failure
[h264 @ 0x559bea7823c0] mmco: unref short failure
[h264 @ 0x56241f0bee00] mmco: unref short failure
[h264 @ 0x55a033cd0b00] mmco: unref short failure
[h264 @ 0x559c079159c0] mmco: unref short failure
[h264 @ 0x559c079159c0] mmco: unref short failure
 76%|███████▌  | 1482/1945 [7:59:53<2:16:15, 17.66s/it][h264 @ 0x556b49a0a9c0] mmco: unref short failure
[h264 @ 0x55a052e963c0] mmco: unref short failure
[h264 @ 0x55a052e963c0] mmco: unref short failure
 76%|███████▌  | 1483/1945 [8:00:16<2:27:20, 19.14s/it][h264 @ 0x559c0165f200] mmco: unref short failure
[h264 @ 0x559c0165f200] mmco: unref short failure
 76%|███████▋  | 1484/1945 [8:00:25<2:03:27, 16.07s/it][h264 @ 0x559c0a480740] mmco: unref short failure
[h264 @ 0x559c03442080] mmco: unref short failure
 76%|███████▋  | 1485/1945 [8:00:41<2:02:59, 16.04s/it][h264 @ 0x56242d6910c0] mmco: unref short failure
[h264 @ 0x56242d6910c0] mmco: unref short failure
[h264 @ 0x562434c707c0] mmco: unref short failure
[h264 @ 0x562434c707c0] mmco: unref short failure
 76%|███████▋  | 1486/1945 [8:00:50<1:46:23, 13.91s/it][h264 @ 0x559c07915340] mmco: unref short failure
[h264 @ 0x556b4f73b5c0] mmco: unref short failure
[h264 @ 0x5624261dfd40] mmco: unref short failure
[h264 @ 0x5624261dfd40] mmco: unref short failure
[h264 @ 0x56242918b100] mmco: unref short failure
[h264 @ 0x56242918b100] mmco: unref short failure
[h264 @ 0x55a03d38b180] mmco: unref short failure
 76%|███████▋  | 1487/1945 [8:01:09<1:57:51, 15.44s/it][h264 @ 0x559bf13c90c0] mmco: unref short failure
[h264 @ 0x559bf13c90c0] mmco: unref short failure
[h264 @ 0x556b30376980] mmco: unref short failure
[h264 @ 0x556b30376980] mmco: unref short failure
 77%|███████▋  | 1488/1945 [8:01:15<1:36:53, 12.72s/it][h264 @ 0x562422d9b5c0] mmco: unref short failure
[h264 @ 0x562422d9b5c0] mmco: unref short failure
[h264 @ 0x55a04412cb80] mmco: unref short failure
[h264 @ 0x55a0543b1000] mmco: unref short failure
[h264 @ 0x55a0543b1000] mmco: unref short failure
[h264 @ 0x559beac50a80] mmco: unref short failure
[h264 @ 0x55a037969380] mmco: unref short failure
 77%|███████▋  | 1489/1945 [8:01:22<1:24:45, 11.15s/it][h264 @ 0x559bf519dd00] mmco: unref short failure
[h264 @ 0x559bf519dd00] mmco: unref short failure
[h264 @ 0x556b443ad5c0] mmco: unref short failure
[h264 @ 0x562431803700] mmco: unref short failure
[h264 @ 0x55a033cd0b00] mmco: unref short failure
[h264 @ 0x55a046409040] mmco: unref short failure
[h264 @ 0x55a046409040] mmco: unref short failure
[h264 @ 0x55a046409040] mmco: unref short failure
[h264 @ 0x55a05429a880] mmco: unref short failure
 77%|███████▋  | 1490/1945 [8:01:52<2:05:31, 16.55s/it][h264 @ 0x559bfab194c0] mmco: unref short failure
[h264 @ 0x55a04cbccf00] mmco: unref short failure
[h264 @ 0x562434411ec0] mmco: unref short failure
[h264 @ 0x562434411ec0] mmco: unref short failure
[h264 @ 0x562434411ec0] mmco: unref short failure
[h264 @ 0x562434411ec0] mmco: unref short failure
[h264 @ 0x556b48784c00] mmco: unref short failure
[h264 @ 0x56241c1acd00] mmco: unref short failure
[h264 @ 0x56242fb1edc0] mmco: unref short failure
 77%|███████▋  | 1491/1945 [8:02:18<2:28:39, 19.65s/it][h264 @ 0x56241f0bf000] mmco: unref short failure
[h264 @ 0x56241f0bf000] mmco: unref short failure
[h264 @ 0x559bf6470740] mmco: unref short failure
[h264 @ 0x559bf6470740] mmco: unref short failure
[h264 @ 0x55a03fa2af00] mmco: unref short failure
 77%|███████▋  | 1492/1945 [8:02:26<1:59:54, 15.88s/it][h264 @ 0x55a0455678c0] mmco: unref short failure
[h264 @ 0x55a0333f8200] mmco: unref short failure
[h264 @ 0x556b37fc1d80] mmco: unref short failure
[h264 @ 0x556b37fc1d80] mmco: unref short failure
[h264 @ 0x56243607b340] mmco: unref short failure
[h264 @ 0x56243607b340] mmco: unref short failure
[h264 @ 0x556b479d0a00] mmco: unref short failure
[h264 @ 0x55a0546fb4c0] mmco: unref short failure
[h264 @ 0x559c02c8acc0] mmco: unref short failure
[h264 @ 0x559c02c8acc0] mmco: unref short failure
 77%|███████▋  | 1493/1945 [8:02:38<1:51:08, 14.75s/it][h264 @ 0x556b3c1f52c0] mmco: unref short failure
[h264 @ 0x556b3c1f52c0] mmco: unref short failure
[h264 @ 0x559becf88b80] mmco: unref short failure
[h264 @ 0x56241d52ce40] mmco: unref short failure
[h264 @ 0x556b33150b80] mmco: unref short failure
[h264 @ 0x556b33150b80] mmco: unref short failure
 77%|███████▋  | 1494/1945 [8:02:53<1:52:30, 14.97s/it][h264 @ 0x559bfe5f5a40] mmco: unref short failure
[h264 @ 0x559bfe5f5a40] mmco: unref short failure
[h264 @ 0x559bfe5f5a40] mmco: unref short failure
[h264 @ 0x559bfe5f5a40] mmco: unref short failure
[h264 @ 0x556b31bef000] mmco: unref short failure
[h264 @ 0x556b31bef000] mmco: unref short failure
[h264 @ 0x55a052646140] mmco: unref short failure
[h264 @ 0x559c01466e40] mmco: unref short failure
[h264 @ 0x559c01466e40] mmco: unref short failure
[h264 @ 0x56242f451180] mmco: unref short failure
[h264 @ 0x56242f451180] mmco: unref short failure
[h264 @ 0x56242f451180] mmco: unref short failure
[h264 @ 0x56242f451180] mmco: unref short failure
[h264 @ 0x556b468a7780] mmco: unref short failure
[h264 @ 0x556b4c7a9d00] mmco: unref short failure
 77%|███████▋  | 1495/1945 [8:03:17<2:11:39, 17.55s/it][h264 @ 0x5624359aea00] mmco: unref short failure
[h264 @ 0x5624359aea00] mmco: unref short failure
[h264 @ 0x562435b1f380] mmco: unref short failure
 77%|███████▋  | 1496/1945 [8:03:27<1:54:35, 15.31s/it][h264 @ 0x5624261dfd40] mmco: unref short failure
 77%|███████▋  | 1497/1945 [8:03:34<1:35:14, 12.76s/it][h264 @ 0x55a05514fcc0] mmco: unref short failure
[h264 @ 0x556b450dccc0] mmco: unref short failure
[h264 @ 0x556b450dccc0] mmco: unref short failure
[h264 @ 0x556b450dccc0] mmco: unref short failure
[h264 @ 0x556b450dccc0] mmco: unref short failure
[h264 @ 0x556b37efcd40] mmco: unref short failure
[h264 @ 0x556b37efcd40] mmco: unref short failure
 77%|███████▋  | 1498/1945 [8:03:53<1:50:34, 14.84s/it][h264 @ 0x559bf30608c0] mmco: unref short failure
[h264 @ 0x559bf30608c0] mmco: unref short failure
[h264 @ 0x559bf30608c0] mmco: unref short failure
[h264 @ 0x559bf30608c0] mmco: unref short failure
[h264 @ 0x562415c21900] mmco: unref short failure
[h264 @ 0x562415c21900] mmco: unref short failure
[h264 @ 0x55a050e757c0] mmco: unref short failure
[h264 @ 0x559beb4b9fc0] mmco: unref short failure
[h264 @ 0x559beb4b9fc0] mmco: unref short failure
 77%|███████▋  | 1499/1945 [8:04:21<2:18:06, 18.58s/it]09/10/2024 01:09:43 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/10/2024 01:09:43 - INFO - __main__ -   start running ret%tv validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a04b96d880] mmco: unref short failure
[h264 @ 0x556b4dff7600] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x562419addb80] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559bef07d280] mmco: unref short failure
[h264 @ 0x559bef07d280] mmco: unref short failure
[h264 @ 0x559bf05fb6c0] mmco: unref short failure
[h264 @ 0x556b4dff7600] mmco: unref short failure
[h264 @ 0x556b4dff7600] mmco: unref short failure
[h264 @ 0x559bfa24b300] mmco: unref short failure
[h264 @ 0x562417c4fc40] mmco: unref short failure
[h264 @ 0x562417c4fc40] mmco: unref short failure
[h264 @ 0x562417c4fc40] mmco: unref short failure
[h264 @ 0x562417c4fc40] mmco: unref short failure
[h264 @ 0x556b4dff7600] mmco: unref short failure
[h264 @ 0x556b4dff7600] mmco: unref short failure
[h264 @ 0x559bfdeddd40] mmco: unref short failure
[h264 @ 0x559bfdeddd40] mmco: unref short failure
[h264 @ 0x56243434b900] mmco: unref short failure
[h264 @ 0x55a032f0ea80] mmco: unref short failure
[h264 @ 0x562435997840] mmco: unref short failure
[h264 @ 0x559be9cd8240] mmco: unref short failure
[h264 @ 0x559be9cd8240] mmco: unref short failure
[h264 @ 0x56242911a000] mmco: unref short failure
[h264 @ 0x562429123740] mmco: unref short failure
[h264 @ 0x562429123740] mmco: unref short failure
[h264 @ 0x556b34762200] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A[h264 @ 0x5624311fb840] mmco: unref short failure
[h264 @ 0x5624311fb840] mmco: unref short failure

  0%|          | 1/221 [00:00<03:13,  1.13it/s][A
  1%|          | 2/221 [00:01<02:56,  1.24it/s][A
  1%|▏         | 3/221 [00:01<01:52,  1.94it/s][A
  2%|▏         | 5/221 [00:02<01:04,  3.34it/s][A
  3%|▎         | 6/221 [00:02<01:05,  3.28it/s][A
  3%|▎         | 7/221 [00:02<01:04,  3.32it/s][A
  4%|▎         | 8/221 [00:03<01:13,  2.91it/s][A
  4%|▍         | 9/221 [00:03<01:02,  3.37it/s][A
  5%|▍         | 10/221 [00:03<01:05,  3.24it/s][A
  5%|▍         | 11/221 [00:03<00:56,  3.70it/s][A
  5%|▌         | 12/221 [00:04<01:37,  2.15it/s][A
  6%|▌         | 13/221 [00:04<01:14,  2.78it/s][A
  6%|▋         | 14/221 [00:06<02:03,  1.68it/s][A
  7%|▋         | 15/221 [00:06<01:40,  2.04it/s][A
  7%|▋         | 16/221 [00:06<01:28,  2.33it/s][A
  8%|▊         | 17/221 [00:06<01:14,  2.75it/s][A
  8%|▊         | 18/221 [00:07<01:06,  3.08it/s][A
  9%|▊         | 19/221 [00:07<00:54,  3.73it/s][A
  9%|▉         | 20/221 [00:07<00:45,  4.40it/s][A
 10%|▉         | 21/221 [00:07<00:46,  4.33it/s][A
 10%|▉         | 22/221 [00:07<00:46,  4.29it/s][A
 10%|█         | 23/221 [00:07<00:45,  4.33it/s][A
 11%|█         | 24/221 [00:08<00:47,  4.13it/s][A
 11%|█▏        | 25/221 [00:08<00:43,  4.47it/s][A
 12%|█▏        | 26/221 [00:08<00:47,  4.07it/s][A
 12%|█▏        | 27/221 [00:08<00:39,  4.92it/s][A
 13%|█▎        | 28/221 [00:09<00:46,  4.16it/s][A
 13%|█▎        | 29/221 [00:09<00:40,  4.69it/s][A
 14%|█▎        | 30/221 [00:09<00:37,  5.13it/s][A
 14%|█▍        | 31/221 [00:09<00:37,  5.10it/s][A
 14%|█▍        | 32/221 [00:09<00:35,  5.32it/s][A
 15%|█▍        | 33/221 [00:10<00:42,  4.39it/s][A
 15%|█▌        | 34/221 [00:10<00:36,  5.19it/s][A
 16%|█▌        | 35/221 [00:10<00:32,  5.70it/s][A[h264 @ 0x5624267e62c0] mmco: unref short failure

 16%|█▋        | 36/221 [00:10<00:34,  5.30it/s][A
 17%|█▋        | 37/221 [00:11<01:03,  2.90it/s][A
 17%|█▋        | 38/221 [00:11<01:02,  2.91it/s][A
 18%|█▊        | 39/221 [00:11<00:52,  3.44it/s][A
 18%|█▊        | 40/221 [00:12<00:48,  3.76it/s][A
 19%|█▉        | 42/221 [00:12<00:46,  3.85it/s][A
 19%|█▉        | 43/221 [00:12<00:44,  4.01it/s][A
 20%|█▉        | 44/221 [00:12<00:38,  4.62it/s][A
 20%|██        | 45/221 [00:13<01:15,  2.32it/s][A
 21%|██        | 46/221 [00:14<01:16,  2.30it/s][A[h264 @ 0x55a04086f280] mmco: unref short failure
[h264 @ 0x56242ea92680] mmco: unref short failure

 21%|██▏       | 47/221 [00:16<02:27,  1.18it/s][A
 22%|██▏       | 48/221 [00:16<01:51,  1.55it/s][A
 22%|██▏       | 49/221 [00:16<01:25,  2.01it/s][A
 23%|██▎       | 50/221 [00:16<01:10,  2.42it/s][A
 24%|██▎       | 52/221 [00:16<00:44,  3.82it/s][A
 24%|██▍       | 53/221 [00:17<00:38,  4.31it/s][A
 24%|██▍       | 54/221 [00:17<01:02,  2.69it/s][A
 25%|██▍       | 55/221 [00:18<01:15,  2.21it/s][A
 25%|██▌       | 56/221 [00:18<01:03,  2.58it/s][A
 26%|██▌       | 57/221 [00:18<00:58,  2.81it/s][A
 27%|██▋       | 59/221 [00:19<00:40,  4.00it/s][A
 27%|██▋       | 60/221 [00:19<00:45,  3.51it/s][A
 28%|██▊       | 61/221 [00:19<00:42,  3.75it/s][A
 28%|██▊       | 62/221 [00:20<00:39,  3.99it/s][A
 29%|██▊       | 63/221 [00:20<00:33,  4.76it/s][A
 29%|██▉       | 64/221 [00:20<00:28,  5.58it/s][A
 29%|██▉       | 65/221 [00:20<00:24,  6.33it/s][A
 30%|██▉       | 66/221 [00:20<00:32,  4.82it/s][A
 30%|███       | 67/221 [00:20<00:33,  4.60it/s][A
 31%|███       | 68/221 [00:21<00:33,  4.57it/s][A
 31%|███       | 69/221 [00:21<00:44,  3.43it/s][A[h264 @ 0x562422d9b5c0] mmco: unref short failure
[h264 @ 0x562422d9b5c0] mmco: unref short failure
[h264 @ 0x562422d9b5c0] mmco: unref short failure
[h264 @ 0x562422d9b5c0] mmco: unref short failure

 32%|███▏      | 70/221 [00:21<00:38,  3.91it/s][A
 32%|███▏      | 71/221 [00:23<01:44,  1.43it/s][A
 33%|███▎      | 72/221 [00:23<01:22,  1.81it/s][A[h264 @ 0x55a034cb1e80] mmco: unref short failure
[h264 @ 0x55a034cb1e80] mmco: unref short failure

 33%|███▎      | 73/221 [00:24<01:13,  2.02it/s][A
 33%|███▎      | 74/221 [00:24<00:57,  2.54it/s][A
 34%|███▍      | 75/221 [00:24<00:54,  2.70it/s][A
 34%|███▍      | 76/221 [00:24<00:44,  3.22it/s][A
 35%|███▍      | 77/221 [00:24<00:36,  3.91it/s][A
 35%|███▌      | 78/221 [00:25<00:38,  3.70it/s][A
 36%|███▌      | 79/221 [00:25<00:53,  2.63it/s][A
 36%|███▌      | 80/221 [00:25<00:43,  3.26it/s][A
 37%|███▋      | 81/221 [00:26<00:38,  3.66it/s][A
 37%|███▋      | 82/221 [00:26<00:37,  3.69it/s][A
 38%|███▊      | 83/221 [00:26<00:30,  4.45it/s][A
 38%|███▊      | 84/221 [00:26<00:29,  4.67it/s][A
 38%|███▊      | 85/221 [00:26<00:26,  5.07it/s][A
 39%|███▉      | 86/221 [00:26<00:25,  5.34it/s][A
 39%|███▉      | 87/221 [00:27<00:34,  3.94it/s][A
 40%|███▉      | 88/221 [00:27<00:33,  4.00it/s][A[h264 @ 0x556b30bb5f80] mmco: unref short failure

 40%|████      | 89/221 [00:30<02:07,  1.04it/s][A
 41%|████      | 90/221 [00:30<01:38,  1.34it/s][A
 41%|████      | 91/221 [00:30<01:13,  1.76it/s][A
 42%|████▏     | 92/221 [00:30<00:56,  2.27it/s][A
 42%|████▏     | 93/221 [00:31<00:55,  2.33it/s][A
 43%|████▎     | 94/221 [00:31<00:47,  2.68it/s][A
 43%|████▎     | 95/221 [00:31<00:38,  3.26it/s][A
 43%|████▎     | 96/221 [00:31<00:36,  3.42it/s][A
 44%|████▍     | 98/221 [00:32<00:26,  4.72it/s][A
 45%|████▍     | 99/221 [00:32<00:24,  4.93it/s][A
 45%|████▌     | 100/221 [00:32<00:25,  4.67it/s][A
 46%|████▌     | 101/221 [00:32<00:22,  5.22it/s][A
 46%|████▌     | 102/221 [00:32<00:24,  4.87it/s][A
 47%|████▋     | 103/221 [00:33<00:21,  5.46it/s][A
 48%|████▊     | 105/221 [00:33<00:18,  6.26it/s][A
 48%|████▊     | 106/221 [00:34<00:37,  3.03it/s][A
 48%|████▊     | 107/221 [00:34<00:30,  3.68it/s][A
 49%|████▉     | 108/221 [00:34<00:27,  4.16it/s][A
 49%|████▉     | 109/221 [00:34<00:27,  4.11it/s][A[h264 @ 0x562422d9b5c0] mmco: unref short failure

 50%|████▉     | 110/221 [00:34<00:23,  4.69it/s][A
 50%|█████     | 111/221 [00:35<00:28,  3.81it/s][A
 51%|█████     | 112/221 [00:35<00:27,  4.02it/s][A
 51%|█████     | 113/221 [00:35<00:37,  2.85it/s][A
 52%|█████▏    | 115/221 [00:36<00:24,  4.36it/s][A[h264 @ 0x559c04017080] mmco: unref short failure

 52%|█████▏    | 116/221 [00:40<02:11,  1.25s/it][A
 53%|█████▎    | 117/221 [00:40<01:46,  1.02s/it][A
 53%|█████▎    | 118/221 [00:41<01:26,  1.19it/s][A
 54%|█████▍    | 119/221 [00:41<01:07,  1.52it/s][A
 54%|█████▍    | 120/221 [00:41<00:58,  1.74it/s][A
 55%|█████▍    | 121/221 [00:41<00:44,  2.23it/s][A
 55%|█████▌    | 122/221 [00:42<00:37,  2.62it/s][A
 56%|█████▌    | 123/221 [00:42<00:30,  3.23it/s][A
 56%|█████▌    | 124/221 [00:42<00:26,  3.61it/s][A
 57%|█████▋    | 125/221 [00:42<00:23,  4.09it/s][A
 57%|█████▋    | 126/221 [00:43<00:26,  3.55it/s][A
 57%|█████▋    | 127/221 [00:43<00:26,  3.53it/s][A
 58%|█████▊    | 128/221 [00:43<00:28,  3.21it/s][A
 58%|█████▊    | 129/221 [00:43<00:26,  3.53it/s][A
 59%|█████▉    | 130/221 [00:44<00:21,  4.19it/s][A
 59%|█████▉    | 131/221 [00:44<00:17,  5.08it/s][A
 60%|█████▉    | 132/221 [00:44<00:15,  5.63it/s][A
 60%|██████    | 133/221 [00:44<00:21,  4.11it/s][A
 61%|██████    | 134/221 [00:44<00:19,  4.43it/s][A
 61%|██████    | 135/221 [00:45<00:22,  3.85it/s][A
 62%|██████▏   | 136/221 [00:45<00:26,  3.25it/s][A
 62%|██████▏   | 137/221 [00:45<00:24,  3.45it/s][A[h264 @ 0x56242c815d80] mmco: unref short failure
[h264 @ 0x56242c815d80] mmco: unref short failure

 62%|██████▏   | 138/221 [00:46<00:30,  2.75it/s][A
 63%|██████▎   | 139/221 [00:46<00:27,  3.02it/s][A
 63%|██████▎   | 140/221 [00:46<00:26,  3.02it/s][A
 64%|██████▍   | 141/221 [00:47<00:22,  3.53it/s][A
 64%|██████▍   | 142/221 [00:47<00:28,  2.76it/s][A
 65%|██████▍   | 143/221 [00:47<00:25,  3.02it/s][A
 66%|██████▌   | 145/221 [00:48<00:16,  4.72it/s][A
 67%|██████▋   | 147/221 [00:48<00:13,  5.59it/s][A
 67%|██████▋   | 148/221 [00:48<00:12,  5.67it/s][A
 68%|██████▊   | 150/221 [00:48<00:09,  7.29it/s][A
 68%|██████▊   | 151/221 [00:49<00:14,  4.86it/s][A
 69%|██████▉   | 152/221 [00:49<00:13,  5.27it/s][A
 69%|██████▉   | 153/221 [00:49<00:16,  4.14it/s][A
 70%|██████▉   | 154/221 [00:50<00:22,  2.93it/s][A
 71%|███████   | 156/221 [00:50<00:14,  4.35it/s][A
 71%|███████   | 157/221 [00:54<01:08,  1.07s/it][A
 71%|███████▏  | 158/221 [00:54<00:52,  1.19it/s][A
 72%|███████▏  | 159/221 [00:54<00:41,  1.50it/s][A
 72%|███████▏  | 160/221 [00:54<00:31,  1.94it/s][A
 73%|███████▎  | 162/221 [00:54<00:18,  3.13it/s][A
 74%|███████▍  | 163/221 [00:55<00:17,  3.27it/s][A
 74%|███████▍  | 164/221 [00:55<00:15,  3.71it/s][A
 75%|███████▍  | 165/221 [00:55<00:12,  4.36it/s][A
 75%|███████▌  | 166/221 [00:55<00:15,  3.50it/s][A
 76%|███████▌  | 167/221 [00:55<00:12,  4.23it/s][A
 76%|███████▌  | 168/221 [01:00<01:15,  1.42s/it][A
 76%|███████▋  | 169/221 [01:00<00:55,  1.07s/it][A
 77%|███████▋  | 170/221 [01:00<00:42,  1.21it/s][A
 77%|███████▋  | 171/221 [01:00<00:30,  1.62it/s][A
 78%|███████▊  | 172/221 [01:01<00:24,  2.02it/s][A
 79%|███████▊  | 174/221 [01:01<00:13,  3.38it/s][A
 79%|███████▉  | 175/221 [01:01<00:13,  3.49it/s][A
 80%|███████▉  | 176/221 [01:01<00:12,  3.74it/s][A
 81%|████████  | 178/221 [01:02<00:10,  4.29it/s][A
 81%|████████  | 179/221 [01:03<00:24,  1.71it/s][A
 82%|████████▏ | 181/221 [01:04<00:16,  2.50it/s][A
 82%|████████▏ | 182/221 [01:04<00:13,  2.92it/s][A
 83%|████████▎ | 183/221 [01:04<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [01:04<00:11,  3.14it/s][A
 84%|████████▍ | 186/221 [01:04<00:08,  4.08it/s][A
 85%|████████▍ | 187/221 [01:05<00:07,  4.69it/s][A
 85%|████████▌ | 188/221 [01:05<00:07,  4.41it/s][A
 86%|████████▌ | 189/221 [01:05<00:07,  4.28it/s][A
 86%|████████▌ | 190/221 [01:05<00:06,  4.61it/s][A
 87%|████████▋ | 192/221 [01:06<00:05,  5.20it/s][A
 88%|████████▊ | 194/221 [01:06<00:06,  4.39it/s][A
 88%|████████▊ | 195/221 [01:06<00:05,  4.96it/s][A
 89%|████████▉ | 197/221 [01:06<00:03,  6.60it/s][A
 90%|████████▉ | 198/221 [01:07<00:03,  6.34it/s][A
 90%|█████████ | 199/221 [01:07<00:03,  6.35it/s][A
 90%|█████████ | 200/221 [01:07<00:04,  5.19it/s][A
 91%|█████████ | 201/221 [01:07<00:04,  4.59it/s][A
 91%|█████████▏| 202/221 [01:07<00:03,  5.15it/s][A
 92%|█████████▏| 203/221 [01:08<00:03,  5.77it/s][A
 93%|█████████▎| 205/221 [01:08<00:02,  7.85it/s][A
 93%|█████████▎| 206/221 [01:08<00:03,  4.83it/s][A
 94%|█████████▍| 208/221 [01:08<00:01,  6.71it/s][A
 95%|█████████▌| 211/221 [01:09<00:01,  6.77it/s][A
 96%|█████████▋| 213/221 [01:09<00:01,  7.81it/s][A
 97%|█████████▋| 214/221 [01:09<00:01,  5.86it/s][A
 97%|█████████▋| 215/221 [01:09<00:01,  5.79it/s][A
 98%|█████████▊| 216/221 [01:10<00:00,  5.97it/s][A
 98%|█████████▊| 217/221 [01:11<00:01,  2.30it/s][A
 99%|█████████▊| 218/221 [01:11<00:01,  2.76it/s][A
 99%|█████████▉| 219/221 [01:11<00:00,  3.09it/s][A
100%|█████████▉| 220/221 [01:16<00:01,  1.47s/it][A100%|██████████| 221/221 [01:16<00:00,  2.90it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:57,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:51,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:38,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:22<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:37<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.78it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.78it/s][A
 67%|██████▋   | 149/221 [00:39<00:19,  3.78it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:51<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.79it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:57<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:32,  6.73it/s][A
  1%|          | 2/221 [00:00<00:43,  5.08it/s][A
  1%|▏         | 3/221 [00:00<00:47,  4.55it/s][A
  2%|▏         | 4/221 [00:00<00:42,  5.08it/s][A
  2%|▏         | 5/221 [00:00<00:43,  4.96it/s][A
  3%|▎         | 7/221 [00:01<00:40,  5.34it/s][A
  4%|▎         | 8/221 [00:01<00:46,  4.58it/s][A
  4%|▍         | 9/221 [00:01<00:48,  4.40it/s][A
  5%|▍         | 10/221 [00:02<01:08,  3.07it/s][A
  5%|▍         | 11/221 [00:02<00:58,  3.60it/s][A
  5%|▌         | 12/221 [00:02<00:49,  4.26it/s][A
  6%|▌         | 13/221 [00:03<01:27,  2.37it/s][A
  6%|▋         | 14/221 [00:03<01:08,  3.00it/s][A
  7%|▋         | 15/221 [00:03<01:01,  3.35it/s][A
  7%|▋         | 16/221 [00:04<01:05,  3.11it/s][A
  8%|▊         | 17/221 [00:04<01:23,  2.44it/s][A
  8%|▊         | 18/221 [00:05<01:11,  2.86it/s][A
  9%|▊         | 19/221 [00:05<00:59,  3.39it/s][A
 10%|▉         | 21/221 [00:05<00:44,  4.55it/s][A
 10%|▉         | 22/221 [00:05<00:41,  4.76it/s][A
 10%|█         | 23/221 [00:05<00:37,  5.34it/s][A
 11%|█         | 24/221 [00:06<00:35,  5.61it/s][A
 11%|█▏        | 25/221 [00:06<00:35,  5.59it/s][A
 12%|█▏        | 26/221 [00:06<00:36,  5.29it/s][A
 12%|█▏        | 27/221 [00:06<00:32,  5.88it/s][A
 13%|█▎        | 28/221 [00:06<00:44,  4.32it/s][A
 13%|█▎        | 29/221 [00:07<00:44,  4.28it/s][A
 14%|█▎        | 30/221 [00:07<00:45,  4.19it/s][A
 14%|█▍        | 31/221 [00:07<00:43,  4.41it/s][A
 14%|█▍        | 32/221 [00:07<00:38,  4.87it/s][A
 15%|█▍        | 33/221 [00:08<00:38,  4.83it/s][A
 15%|█▌        | 34/221 [00:08<00:39,  4.78it/s][A
 16%|█▌        | 35/221 [00:08<00:44,  4.15it/s][A
 16%|█▋        | 36/221 [00:08<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:08<00:41,  4.44it/s][A
 17%|█▋        | 38/221 [00:09<00:44,  4.15it/s][A
 18%|█▊        | 39/221 [00:09<00:41,  4.44it/s][A
 18%|█▊        | 40/221 [00:09<00:48,  3.77it/s][A
 19%|█▊        | 41/221 [00:10<00:43,  4.17it/s][A
 19%|█▉        | 42/221 [00:10<00:36,  4.89it/s][A
 19%|█▉        | 43/221 [00:10<00:43,  4.10it/s][A
 20%|█▉        | 44/221 [00:10<00:45,  3.89it/s][A
 20%|██        | 45/221 [00:11<00:48,  3.65it/s][A
 21%|██        | 46/221 [00:11<00:44,  3.93it/s][A
 21%|██▏       | 47/221 [00:11<00:44,  3.95it/s][A
 22%|██▏       | 48/221 [00:11<00:37,  4.59it/s][A
 22%|██▏       | 49/221 [00:11<00:38,  4.46it/s][A
 23%|██▎       | 50/221 [00:12<00:50,  3.37it/s][A
 23%|██▎       | 51/221 [00:12<00:43,  3.87it/s][A
 24%|██▎       | 52/221 [00:12<00:46,  3.66it/s][A
 24%|██▍       | 53/221 [00:12<00:37,  4.49it/s][A
 24%|██▍       | 54/221 [00:13<00:47,  3.50it/s][A
 25%|██▍       | 55/221 [00:13<00:47,  3.50it/s][A
 25%|██▌       | 56/221 [00:13<00:41,  3.93it/s][A
 26%|██▌       | 57/221 [00:14<00:44,  3.67it/s][A
 26%|██▌       | 58/221 [00:14<00:49,  3.27it/s][A
 27%|██▋       | 59/221 [00:14<00:44,  3.62it/s][A
 27%|██▋       | 60/221 [00:14<00:38,  4.20it/s][A
 28%|██▊       | 61/221 [00:15<00:35,  4.50it/s][A
 28%|██▊       | 62/221 [00:15<00:36,  4.35it/s][A
 29%|██▊       | 63/221 [00:15<00:34,  4.54it/s][A
 29%|██▉       | 64/221 [00:15<00:40,  3.83it/s][A
 29%|██▉       | 65/221 [00:16<00:37,  4.19it/s][A
 30%|██▉       | 66/221 [00:16<00:49,  3.12it/s][A
 30%|███       | 67/221 [00:16<00:51,  3.01it/s][A
 31%|███       | 68/221 [00:17<00:43,  3.56it/s][A
 31%|███       | 69/221 [00:17<01:05,  2.33it/s][A
 32%|███▏      | 70/221 [00:18<00:52,  2.88it/s][A
 32%|███▏      | 71/221 [00:18<00:45,  3.30it/s][A
 33%|███▎      | 72/221 [00:18<00:50,  2.93it/s][A
 33%|███▎      | 73/221 [00:18<00:48,  3.04it/s][A
 33%|███▎      | 74/221 [00:19<00:42,  3.45it/s][A
 34%|███▍      | 75/221 [00:19<00:40,  3.56it/s][A
 34%|███▍      | 76/221 [00:19<00:38,  3.77it/s][A
 35%|███▍      | 77/221 [00:19<00:40,  3.57it/s][A
 35%|███▌      | 78/221 [00:20<00:36,  3.91it/s][A
 36%|███▌      | 79/221 [00:20<00:43,  3.29it/s][A
 36%|███▌      | 80/221 [00:20<00:39,  3.55it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.80it/s][A
 37%|███▋      | 82/221 [00:21<00:43,  3.19it/s][A
 38%|███▊      | 83/221 [00:21<00:45,  3.06it/s][A
 38%|███▊      | 84/221 [00:22<00:42,  3.19it/s][A
 38%|███▊      | 85/221 [00:22<00:34,  4.00it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.77it/s][A
 39%|███▉      | 87/221 [00:22<00:43,  3.08it/s][A
 40%|███▉      | 88/221 [00:23<00:48,  2.72it/s][A
 40%|████      | 89/221 [00:23<00:45,  2.92it/s][A
 41%|████      | 90/221 [00:24<00:48,  2.68it/s][A
 41%|████      | 91/221 [00:24<00:40,  3.23it/s][A
 42%|████▏     | 92/221 [00:24<00:42,  3.04it/s][A
 42%|████▏     | 93/221 [00:25<00:57,  2.22it/s][A
 43%|████▎     | 94/221 [00:25<00:51,  2.47it/s][A
 43%|████▎     | 95/221 [00:25<00:45,  2.78it/s][A
 43%|████▎     | 96/221 [00:26<00:42,  2.97it/s][A
 44%|████▍     | 97/221 [00:26<00:36,  3.36it/s][A
 44%|████▍     | 98/221 [00:26<00:35,  3.49it/s][A
 45%|████▍     | 99/221 [00:26<00:31,  3.83it/s][A
 45%|████▌     | 100/221 [00:27<00:33,  3.66it/s][A
 46%|████▌     | 101/221 [00:27<00:30,  3.91it/s][A
 46%|████▌     | 102/221 [00:28<00:46,  2.58it/s][A
 47%|████▋     | 103/221 [00:28<00:36,  3.21it/s][A
 47%|████▋     | 104/221 [00:28<00:31,  3.71it/s][A
 48%|████▊     | 105/221 [00:28<00:32,  3.57it/s][A
 48%|████▊     | 106/221 [00:29<00:34,  3.29it/s][A
 48%|████▊     | 107/221 [00:29<00:38,  2.93it/s][A
 49%|████▉     | 108/221 [00:29<00:36,  3.09it/s][A
 49%|████▉     | 109/221 [00:29<00:28,  3.87it/s][A
 50%|████▉     | 110/221 [00:30<00:28,  3.90it/s][A
 50%|█████     | 111/221 [00:30<00:29,  3.75it/s][A
 51%|█████     | 112/221 [00:30<00:27,  3.93it/s][A
 51%|█████     | 113/221 [00:30<00:26,  4.12it/s][A
 52%|█████▏    | 114/221 [00:31<00:21,  4.99it/s][A
 52%|█████▏    | 115/221 [00:31<00:22,  4.62it/s][A
 52%|█████▏    | 116/221 [00:31<00:23,  4.39it/s][A
 53%|█████▎    | 117/221 [00:31<00:24,  4.24it/s][A
 53%|█████▎    | 118/221 [00:31<00:23,  4.45it/s][A
 54%|█████▍    | 119/221 [00:32<00:29,  3.44it/s][A
 54%|█████▍    | 120/221 [00:32<00:26,  3.86it/s][A
 55%|█████▌    | 122/221 [00:32<00:22,  4.43it/s][A
 56%|█████▌    | 123/221 [00:33<00:24,  3.97it/s][A
 56%|█████▌    | 124/221 [00:33<00:23,  4.07it/s][A
 57%|█████▋    | 125/221 [00:33<00:25,  3.77it/s][A
 57%|█████▋    | 126/221 [00:34<00:23,  4.04it/s][A
 57%|█████▋    | 127/221 [00:34<00:27,  3.39it/s][A
 58%|█████▊    | 128/221 [00:34<00:25,  3.59it/s][A
 58%|█████▊    | 129/221 [00:34<00:21,  4.25it/s][A
 59%|█████▉    | 130/221 [00:35<00:21,  4.26it/s][A
 59%|█████▉    | 131/221 [00:35<00:18,  4.94it/s][A
 60%|█████▉    | 132/221 [00:35<00:20,  4.24it/s][A
 60%|██████    | 133/221 [00:35<00:25,  3.47it/s][A
 61%|██████    | 134/221 [00:36<00:30,  2.82it/s][A
 61%|██████    | 135/221 [00:36<00:30,  2.80it/s][A
 62%|██████▏   | 136/221 [00:37<00:27,  3.14it/s][A
 62%|██████▏   | 137/221 [00:37<00:22,  3.74it/s][A
 62%|██████▏   | 138/221 [00:37<00:23,  3.57it/s][A
 63%|██████▎   | 139/221 [00:37<00:26,  3.13it/s][A
 63%|██████▎   | 140/221 [00:38<00:25,  3.21it/s][A
 64%|██████▍   | 141/221 [00:38<00:22,  3.59it/s][A
 64%|██████▍   | 142/221 [00:38<00:20,  3.80it/s][A
 65%|██████▍   | 143/221 [00:39<00:24,  3.20it/s][A
 65%|██████▌   | 144/221 [00:39<00:26,  2.91it/s][A
 66%|██████▌   | 145/221 [00:39<00:21,  3.61it/s][A
 67%|██████▋   | 147/221 [00:39<00:16,  4.41it/s][A
 67%|██████▋   | 148/221 [00:40<00:19,  3.76it/s][A
 67%|██████▋   | 149/221 [00:40<00:18,  3.81it/s][A
 68%|██████▊   | 150/221 [00:40<00:17,  3.98it/s][A
 68%|██████▊   | 151/221 [00:41<00:21,  3.22it/s][A
 69%|██████▉   | 152/221 [00:41<00:28,  2.41it/s][A
 69%|██████▉   | 153/221 [00:42<00:23,  2.95it/s][A
 70%|██████▉   | 154/221 [00:42<00:20,  3.29it/s][A
 70%|███████   | 155/221 [00:42<00:18,  3.60it/s][A
 71%|███████   | 156/221 [00:42<00:20,  3.24it/s][A
 71%|███████   | 157/221 [00:43<00:19,  3.22it/s][A
 71%|███████▏  | 158/221 [00:43<00:18,  3.37it/s][A
 72%|███████▏  | 159/221 [00:43<00:15,  4.02it/s][A
 72%|███████▏  | 160/221 [00:43<00:14,  4.22it/s][A
 73%|███████▎  | 161/221 [00:44<00:18,  3.25it/s][A
 73%|███████▎  | 162/221 [00:44<00:15,  3.93it/s][A
 74%|███████▍  | 163/221 [00:44<00:14,  3.89it/s][A
 74%|███████▍  | 164/221 [00:44<00:13,  4.27it/s][A
 75%|███████▍  | 165/221 [00:45<00:12,  4.35it/s][A
 75%|███████▌  | 166/221 [00:45<00:12,  4.33it/s][A
 76%|███████▌  | 167/221 [00:45<00:10,  5.18it/s][A
 76%|███████▌  | 168/221 [00:45<00:11,  4.42it/s][A
 76%|███████▋  | 169/221 [00:45<00:09,  5.23it/s][A
 77%|███████▋  | 170/221 [00:46<00:14,  3.49it/s][A
 77%|███████▋  | 171/221 [00:46<00:12,  3.89it/s][A
 78%|███████▊  | 172/221 [00:46<00:12,  3.91it/s][A
 78%|███████▊  | 173/221 [00:47<00:13,  3.61it/s][A
 79%|███████▊  | 174/221 [00:47<00:15,  3.01it/s][A
 79%|███████▉  | 175/221 [00:47<00:15,  2.94it/s][A
 80%|███████▉  | 176/221 [00:48<00:14,  3.18it/s][A
 80%|████████  | 177/221 [00:48<00:12,  3.46it/s][A
 81%|████████  | 178/221 [00:48<00:12,  3.50it/s][A
 81%|████████  | 179/221 [00:48<00:11,  3.63it/s][A
 81%|████████▏ | 180/221 [00:49<00:09,  4.12it/s][A
 82%|████████▏ | 181/221 [00:49<00:10,  3.92it/s][A
 82%|████████▏ | 182/221 [00:49<00:11,  3.53it/s][A
 83%|████████▎ | 183/221 [00:50<00:10,  3.53it/s][A
 83%|████████▎ | 184/221 [00:50<00:10,  3.48it/s][A
 84%|████████▎ | 185/221 [00:50<00:09,  3.88it/s][A
 84%|████████▍ | 186/221 [00:51<00:11,  2.92it/s][A
 85%|████████▍ | 187/221 [00:51<00:10,  3.34it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.38it/s][A
 86%|████████▌ | 189/221 [00:51<00:09,  3.54it/s][A
 86%|████████▌ | 190/221 [00:52<00:09,  3.22it/s][A
 86%|████████▋ | 191/221 [00:52<00:07,  3.78it/s][A
 87%|████████▋ | 192/221 [00:52<00:07,  3.89it/s][A
 87%|████████▋ | 193/221 [00:52<00:06,  4.38it/s][A
 88%|████████▊ | 194/221 [00:53<00:07,  3.75it/s][A
 88%|████████▊ | 195/221 [00:53<00:06,  3.84it/s][A
 89%|████████▊ | 196/221 [00:53<00:07,  3.24it/s][A
 89%|████████▉ | 197/221 [00:53<00:06,  3.61it/s][A
 90%|████████▉ | 198/221 [00:54<00:07,  3.06it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.41it/s][A
 90%|█████████ | 200/221 [00:54<00:06,  3.18it/s][A
 91%|█████████ | 201/221 [00:55<00:05,  3.63it/s][A
 91%|█████████▏| 202/221 [00:55<00:05,  3.27it/s][A
 92%|█████████▏| 203/221 [00:55<00:04,  3.75it/s][A
 92%|█████████▏| 204/221 [00:56<00:04,  3.43it/s][A
 93%|█████████▎| 205/221 [00:56<00:03,  4.22it/s][A
 93%|█████████▎| 206/221 [00:56<00:04,  3.48it/s][A
 94%|█████████▎| 207/221 [00:56<00:03,  3.57it/s][A
 94%|█████████▍| 208/221 [00:57<00:03,  3.78it/s][A
 95%|█████████▍| 209/221 [00:57<00:02,  4.19it/s][A
 95%|█████████▌| 210/221 [00:57<00:02,  4.21it/s][A
 95%|█████████▌| 211/221 [00:57<00:02,  3.78it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  3.50it/s][A
 96%|█████████▋| 213/221 [00:58<00:02,  3.76it/s][A
 97%|█████████▋| 214/221 [00:58<00:02,  2.70it/s][A
 97%|█████████▋| 215/221 [00:59<00:01,  3.05it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.29it/s][A
 98%|█████████▊| 217/221 [00:59<00:01,  3.22it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.40it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.17it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.60it/s][A
100%|██████████| 221/221 [01:00<00:00,  4.09it/s][A100%|██████████| 221/221 [01:00<00:00,  3.64it/s]
09/10/2024 01:15:28 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 1499--===========

09/10/2024 01:15:28 - INFO - __main__ -   {'area_r1': 37.2, 'area_recall': '37.2/62.2/71.5', 'area_ravg': 57.0}
09/10/2024 01:15:28 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 1499--===========

09/10/2024 01:15:28 - INFO - __main__ -   {'forward_r1': 36.9, 'forward_recall': '36.9/65.7/76.5', 'forward_ravg': 59.7}
09/10/2024 01:15:28 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 1499--===========

09/10/2024 01:15:28 - INFO - __main__ -   {'area_video_r1': 37.4, 'area_video_recall': '37.4/66.1/77.1', 'area_video_ravg': 60.2}
09/10/2024 01:15:28 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/10/2024 01:15:28 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/10/2024 01:15:28 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 1499--===========

09/10/2024 01:15:28 - INFO - __main__ -   {'area_video_r1': 52.1, 'area_video_recall': '52.1/74.0/81.7', 'area_video_ravg': 69.3, 'area_video_back_r1': 47.6, 'area_video_back_recall': '47.6/73.2/82.2', 'area_video_back_ravg': 67.7}
09/10/2024 01:15:28 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/10/2024 01:15:28 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/10/2024 01:15:28 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 1499--===========

09/10/2024 01:15:28 - INFO - __main__ -   {'video_r1': 44.1, 'video_recall': '44.1/71.0/81.6', 'video_ravg': 65.6}
09/10/2024 01:15:28 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/10/2024 01:15:28 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/10/2024 01:15:28 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 1499--===========

09/10/2024 01:15:28 - INFO - __main__ -   {'video_r1': 51.7, 'video_recall': '51.7/75.3/82.9', 'video_ravg': 70.0}
09/10/2024 01:15:28 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/10/2024 01:15:28 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/10/2024 01:15:51 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.006801703944802284, 'loss_ret%tv%ta--finetune_area/loss_area': 1.0427100658416748, 'loss_ret%tv%ta--finetune_area/total_loss': 1.0495117902755737}
 77%|███████▋  | 1500/1945 [8:10:32<15:21:56, 124.31s/it][h264 @ 0x562424d57d40] mmco: unref short failure
[h264 @ 0x559bf381ba40] mmco: unref short failure
[h264 @ 0x559bf381ba40] mmco: unref short failure
[h264 @ 0x55a0391d9a00] mmco: unref short failure
[h264 @ 0x55a0391d9a00] mmco: unref short failure
[h264 @ 0x55a0391d9a00] mmco: unref short failure
[h264 @ 0x55a0391d9a00] mmco: unref short failure
 77%|███████▋  | 1501/1945 [8:10:36<10:53:04, 88.25s/it] [h264 @ 0x559bf5111640] mmco: unref short failure
[h264 @ 0x559bf5111640] mmco: unref short failure
[h264 @ 0x559bf5111640] mmco: unref short failure
[h264 @ 0x559bf5111640] mmco: unref short failure
[h264 @ 0x559bf5111640] mmco: unref short failure
[h264 @ 0x559bf5111640] mmco: unref short failure
 77%|███████▋  | 1502/1945 [8:10:41<7:47:05, 63.26s/it] [h264 @ 0x55a0340d8f40] mmco: unref short failure
[h264 @ 0x559bfedaa2c0] mmco: unref short failure
 77%|███████▋  | 1503/1945 [8:10:47<5:40:21, 46.20s/it] 77%|███████▋  | 1504/1945 [8:10:52<4:09:32, 33.95s/it] 77%|███████▋  | 1505/1945 [8:10:59<3:09:44, 25.87s/it][h264 @ 0x55a043c0fc00] mmco: unref short failure
[h264 @ 0x55a043c0fc00] mmco: unref short failure
 77%|███████▋  | 1506/1945 [8:11:06<2:26:36, 20.04s/it][h264 @ 0x55a03b9dea40] mmco: unref short failure
 77%|███████▋  | 1507/1945 [8:11:13<1:58:23, 16.22s/it][h264 @ 0x55a03638b5c0] mmco: unref short failure
[h264 @ 0x55a052630000] mmco: unref short failure
[h264 @ 0x556b2d540000] mmco: unref short failure
 78%|███████▊  | 1508/1945 [8:11:20<1:37:08, 13.34s/it] 78%|███████▊  | 1509/1945 [8:11:27<1:23:05, 11.44s/it][h264 @ 0x5624184c5d00] mmco: unref short failure
[h264 @ 0x5624184c5d00] mmco: unref short failure
 78%|███████▊  | 1510/1945 [8:11:34<1:13:49, 10.18s/it][h264 @ 0x562425cbd5c0] mmco: unref short failure
[h264 @ 0x562425cbd5c0] mmco: unref short failure
[h264 @ 0x5624236ab240] mmco: unref short failure
[h264 @ 0x5624236ab240] mmco: unref short failure
[h264 @ 0x556b45836e40] mmco: unref short failure
[h264 @ 0x556b45836e40] mmco: unref short failure
[h264 @ 0x556b2d4f4a00] mmco: unref short failure
[h264 @ 0x556b2d4f4a00] mmco: unref short failure
[h264 @ 0x556b2d4f4a00] mmco: unref short failure
[h264 @ 0x556b2d4f4a00] mmco: unref short failure
[h264 @ 0x55a04e2770c0] mmco: unref short failure
[h264 @ 0x55a04e2770c0] mmco: unref short failure
 78%|███████▊  | 1511/1945 [8:11:42<1:07:55,  9.39s/it][h264 @ 0x559c049655c0] mmco: unref short failure
[h264 @ 0x559c049655c0] mmco: unref short failure
[h264 @ 0x559c049655c0] mmco: unref short failure
 78%|███████▊  | 1512/1945 [8:11:49<1:03:15,  8.77s/it][h264 @ 0x559c0656db40] mmco: unref short failure
[h264 @ 0x559c0656db40] mmco: unref short failure
[h264 @ 0x56243189ac80] mmco: unref short failure
[h264 @ 0x56243189ac80] mmco: unref short failure
 78%|███████▊  | 1513/1945 [8:11:56<1:00:01,  8.34s/it][h264 @ 0x55a0453b4580] mmco: unref short failure
[h264 @ 0x55a0453b4580] mmco: unref short failure
[h264 @ 0x55a04b9b50c0] mmco: unref short failure
 78%|███████▊  | 1514/1945 [8:12:03<56:44,  7.90s/it]  [h264 @ 0x556b44bf1640] mmco: unref short failure
[h264 @ 0x556b44bf1640] mmco: unref short failure
[h264 @ 0x559bf0651b80] mmco: unref short failure
 78%|███████▊  | 1515/1945 [8:12:11<56:41,  7.91s/it][h264 @ 0x556b2c265100] mmco: unref short failure
 78%|███████▊  | 1516/1945 [8:12:18<55:11,  7.72s/it][h264 @ 0x56241764de40] mmco: unref short failure
[h264 @ 0x56241764de40] mmco: unref short failure
[h264 @ 0x55a0364cd800] mmco: unref short failure
[h264 @ 0x55a0364cd800] mmco: unref short failure
[h264 @ 0x55a0364cd800] mmco: unref short failure
 78%|███████▊  | 1517/1945 [8:12:25<53:28,  7.50s/it][h264 @ 0x559bf64769c0] mmco: unref short failure
[h264 @ 0x559bf64769c0] mmco: unref short failure
[h264 @ 0x556b44bf1640] mmco: unref short failure
[h264 @ 0x556b44bf1640] mmco: unref short failure
 78%|███████▊  | 1518/1945 [8:12:33<52:53,  7.43s/it][h264 @ 0x556b3be86800] mmco: unref short failure
[h264 @ 0x556b3be86800] mmco: unref short failure
[h264 @ 0x55a0363ba540] mmco: unref short failure
[h264 @ 0x55a0363ba540] mmco: unref short failure
[h264 @ 0x559becf83240] mmco: unref short failure
[h264 @ 0x559becf83240] mmco: unref short failure
[h264 @ 0x559becf83240] mmco: unref short failure
[h264 @ 0x559becf83240] mmco: unref short failure
[h264 @ 0x5624217584c0] mmco: unref short failure
 78%|███████▊  | 1519/1945 [8:12:43<59:34,  8.39s/it][h264 @ 0x5624267e62c0] mmco: unref short failure
[h264 @ 0x55a04b47f080] mmco: unref short failure
[h264 @ 0x55a04b47f080] mmco: unref short failure
[h264 @ 0x55a0391d9a00] mmco: unref short failure
 78%|███████▊  | 1520/1945 [8:12:55<1:06:20,  9.37s/it][h264 @ 0x559bf7c47700] mmco: unref short failure
 78%|███████▊  | 1521/1945 [8:13:03<1:02:54,  8.90s/it][h264 @ 0x55a03b413fc0] mmco: unref short failure
[h264 @ 0x55a03b413fc0] mmco: unref short failure
[h264 @ 0x559bf4764380] mmco: unref short failure
 78%|███████▊  | 1522/1945 [8:13:13<1:05:01,  9.22s/it][h264 @ 0x559bee620780] mmco: unref short failure
[h264 @ 0x562419fc22c0] mmco: unref short failure
[h264 @ 0x559becf83240] mmco: unref short failure
[h264 @ 0x559becf83240] mmco: unref short failure
[h264 @ 0x556b300290c0] mmco: unref short failure
 78%|███████▊  | 1523/1945 [8:13:21<1:02:04,  8.83s/it][h264 @ 0x556b30bb5f80] mmco: unref short failure
[h264 @ 0x559be9889980] mmco: unref short failure
[h264 @ 0x559be9889980] mmco: unref short failure
[h264 @ 0x556b2d540000] mmco: unref short failure
[h264 @ 0x556b30bb5f80] mmco: unref short failure
[h264 @ 0x556b30bb5f80] mmco: unref short failure
[h264 @ 0x556b44bf1640] mmco: unref short failure
[h264 @ 0x556b44bf1640] mmco: unref short failure
[h264 @ 0x556b44bf1640] mmco: unref short failure
[h264 @ 0x562425ca7e40] mmco: unref short failure
[h264 @ 0x562425ca7e40] mmco: unref short failure
[h264 @ 0x55a03f637b00] mmco: unref short failure
[h264 @ 0x55a03f637b00] mmco: unref short failure
[h264 @ 0x556b44bf1640] mmco: unref short failure
[h264 @ 0x5624171f0fc0] mmco: unref short failure
[h264 @ 0x5624171f0fc0] mmco: unref short failure
[h264 @ 0x55a051b69600] mmco: unref short failure
[h264 @ 0x562417998c40] mmco: unref short failure
[h264 @ 0x562417998c40] mmco: unref short failure
[h264 @ 0x559bf45b8580] mmco: unref short failure
[h264 @ 0x559bf45b8580] mmco: unref short failure
[h264 @ 0x559bf3834c00] mmco: unref short failure
[h264 @ 0x56241e2009c0] mmco: unref short failure
[h264 @ 0x56241e2009c0] mmco: unref short failure
[h264 @ 0x559beaa94400] mmco: unref short failure
[h264 @ 0x562426aefd80] mmco: unref short failure
 78%|███████▊  | 1524/1945 [8:14:22<2:53:35, 24.74s/it][h264 @ 0x55a03d75f9c0] mmco: unref short failure
[h264 @ 0x55a03d75f9c0] mmco: unref short failure
 78%|███████▊  | 1525/1945 [8:14:30<2:17:27, 19.64s/it] 78%|███████▊  | 1526/1945 [8:14:38<1:51:25, 15.96s/it][h264 @ 0x559be99d0f80] mmco: unref short failure
 79%|███████▊  | 1527/1945 [8:14:48<1:38:47, 14.18s/it][h264 @ 0x55a043c0fc00] mmco: unref short failure
[h264 @ 0x55a043c0fc00] mmco: unref short failure
 79%|███████▊  | 1528/1945 [8:14:56<1:26:39, 12.47s/it][h264 @ 0x559befa54dc0] mmco: unref short failure
[h264 @ 0x559befa54dc0] mmco: unref short failure
 79%|███████▊  | 1529/1945 [8:15:05<1:19:59, 11.54s/it][h264 @ 0x562435c4ea80] mmco: unref short failure
 79%|███████▊  | 1530/1945 [8:15:19<1:24:15, 12.18s/it] 79%|███████▊  | 1531/1945 [8:15:26<1:12:55, 10.57s/it][h264 @ 0x559bfeb51400] mmco: unref short failure
[h264 @ 0x559c050bd540] mmco: unref short failure
[h264 @ 0x56242a25f540] mmco: unref short failure
[h264 @ 0x56242a25f540] mmco: unref short failure
[h264 @ 0x55a04cc65580] mmco: unref short failure
[h264 @ 0x55a04cc65580] mmco: unref short failure
[h264 @ 0x55a04cc65580] mmco: unref short failure
[h264 @ 0x55a04cc65580] mmco: unref short failure
[h264 @ 0x556b4dff7600] mmco: unref short failure
[h264 @ 0x556b4dff7600] mmco: unref short failure
[h264 @ 0x562429e599c0] mmco: unref short failure
[h264 @ 0x559c093267c0] mmco: unref short failure
[h264 @ 0x559c093267c0] mmco: unref short failure
[h264 @ 0x55a032d55b40] mmco: unref short failure
[h264 @ 0x55a032d55b40] mmco: unref short failure
[h264 @ 0x56242c2ddec0] mmco: unref short failure
[h264 @ 0x56242c2ddec0] mmco: unref short failure
[h264 @ 0x559c04c78c40] mmco: unref short failure
[h264 @ 0x559c04c78c40] mmco: unref short failure
[h264 @ 0x559c04c78c40] mmco: unref short failure
[h264 @ 0x559bf848eb40] mmco: unref short failure
[h264 @ 0x559bf848eb40] mmco: unref short failure
[h264 @ 0x559bfeae4200] mmco: unref short failure
[h264 @ 0x55a03a77e280] mmco: unref short failure
[h264 @ 0x55a034cb1e80] mmco: unref short failure
[h264 @ 0x556b4eb36040] mmco: unref short failure
[h264 @ 0x556b4eb36040] mmco: unref short failure
[h264 @ 0x559c005a2580] mmco: unref short failure
[h264 @ 0x559c005a2580] mmco: unref short failure
[h264 @ 0x559c005a2580] mmco: unref short failure
 79%|███████▉  | 1532/1945 [8:16:32<3:06:56, 27.16s/it] 79%|███████▉  | 1533/1945 [8:16:39<2:24:27, 21.04s/it][h264 @ 0x55a051f6b3c0] mmco: unref short failure
[h264 @ 0x55a051f6b3c0] mmco: unref short failure
[h264 @ 0x559bea771300] mmco: unref short failure
[h264 @ 0x559bea771300] mmco: unref short failure
[h264 @ 0x556b49fe5500] mmco: unref short failure
[h264 @ 0x5624182aaa80] mmco: unref short failure
 79%|███████▉  | 1534/1945 [8:16:46<1:55:34, 16.87s/it] 79%|███████▉  | 1535/1945 [8:16:53<1:35:07, 13.92s/it][h264 @ 0x559bf30da640] mmco: unref short failure
[h264 @ 0x559bf30da640] mmco: unref short failure
[h264 @ 0x559bf30da640] mmco: unref short failure
 79%|███████▉  | 1536/1945 [8:17:05<1:31:08, 13.37s/it][h264 @ 0x55a04bf14240] mmco: unref short failure
[h264 @ 0x55a04bf14240] mmco: unref short failure
[h264 @ 0x55a04e27dd40] mmco: unref short failure
[h264 @ 0x55a04e27dd40] mmco: unref short failure
[h264 @ 0x556b4998eac0] mmco: unref short failure
[h264 @ 0x56242986ac00] mmco: unref short failure
[h264 @ 0x56242986ac00] mmco: unref short failure
[h264 @ 0x56242986ac00] mmco: unref short failure
 79%|███████▉  | 1537/1945 [8:17:23<1:41:11, 14.88s/it][h264 @ 0x556b3af59dc0] mmco: unref short failure
[h264 @ 0x556b3af59dc0] mmco: unref short failure
 79%|███████▉  | 1538/1945 [8:17:30<1:24:12, 12.41s/it][h264 @ 0x556b3dcbc340] mmco: unref short failure
[h264 @ 0x556b3dcbc340] mmco: unref short failure
[h264 @ 0x55a045e72240] mmco: unref short failure
[h264 @ 0x55a045e72240] mmco: unref short failure
[h264 @ 0x55a045e72240] mmco: unref short failure
[h264 @ 0x55a045e72240] mmco: unref short failure
[h264 @ 0x56242c2ddec0] mmco: unref short failure
[h264 @ 0x56242c2ddec0] mmco: unref short failure
[h264 @ 0x559bfd38c900] mmco: unref short failure
 79%|███████▉  | 1539/1945 [8:17:37<1:13:09, 10.81s/it][h264 @ 0x556b4df5ad40] mmco: unref short failure
[h264 @ 0x55a0325bbb00] mmco: unref short failure
[h264 @ 0x55a0325bbb00] mmco: unref short failure
[h264 @ 0x556b48884280] mmco: unref short failure
[h264 @ 0x556b48884280] mmco: unref short failure
[h264 @ 0x55a04e701f00] mmco: unref short failure
[h264 @ 0x559c0a6592c0] mmco: unref short failure
[h264 @ 0x559c0a6592c0] mmco: unref short failure
[h264 @ 0x559bee389780] mmco: unref short failure
[h264 @ 0x559bee389780] mmco: unref short failure
[h264 @ 0x559c09e20b40] mmco: unref short failure
[h264 @ 0x559c09e20b40] mmco: unref short failure
[h264 @ 0x56243137d5c0] mmco: unref short failure
[h264 @ 0x56243137d5c0] mmco: unref short failure
[h264 @ 0x56243137d5c0] mmco: unref short failure
[h264 @ 0x56243137d5c0] mmco: unref short failure
[h264 @ 0x55a0374b7c00] mmco: unref short failure
[h264 @ 0x556b31c71e40] mmco: unref short failure
[h264 @ 0x556b31c71e40] mmco: unref short failure
[h264 @ 0x556b389b3980] mmco: unref short failure
[h264 @ 0x556b389b3980] mmco: unref short failure
[h264 @ 0x556b389b3980] mmco: unref short failure
[h264 @ 0x556b389b3980] mmco: unref short failure
[h264 @ 0x559bf93886c0] mmco: unref short failure
[h264 @ 0x55a0558ced80] mmco: unref short failure
[h264 @ 0x556b2f2549c0] mmco: unref short failure
 79%|███████▉  | 1540/1945 [8:18:29<2:37:31, 23.34s/it] 79%|███████▉  | 1541/1945 [8:18:37<2:04:21, 18.47s/it] 79%|███████▉  | 1542/1945 [8:18:49<1:50:58, 16.52s/it] 79%|███████▉  | 1543/1945 [8:18:56<1:33:22, 13.94s/it][h264 @ 0x556b36af5800] mmco: unref short failure
[h264 @ 0x556b36af5800] mmco: unref short failure
[h264 @ 0x55a04d1a0900] mmco: unref short failure
[h264 @ 0x55a04d1a0900] mmco: unref short failure
 79%|███████▉  | 1544/1945 [8:19:09<1:29:33, 13.40s/it][h264 @ 0x56241cd47e40] mmco: unref short failure
 79%|███████▉  | 1545/1945 [8:19:19<1:23:26, 12.52s/it] 79%|███████▉  | 1546/1945 [8:19:26<1:11:53, 10.81s/it] 80%|███████▉  | 1547/1945 [8:19:33<1:04:17,  9.69s/it][h264 @ 0x56241aba9b80] mmco: unref short failure
[h264 @ 0x56241aba9b80] mmco: unref short failure
[h264 @ 0x56241aba9b80] mmco: unref short failure
[h264 @ 0x56241aba9b80] mmco: unref short failure
[h264 @ 0x559beb41dd00] mmco: unref short failure
[h264 @ 0x559beb41dd00] mmco: unref short failure
[h264 @ 0x562417e184c0] mmco: unref short failure
[h264 @ 0x562419fc22c0] mmco: unref short failure
[h264 @ 0x562419fc22c0] mmco: unref short failure
[h264 @ 0x562419fc22c0] mmco: unref short failure
[h264 @ 0x562419fc22c0] mmco: unref short failure
[h264 @ 0x559beae41640] mmco: unref short failure
[h264 @ 0x559beae41640] mmco: unref short failure
[h264 @ 0x559c0a02b880] mmco: unref short failure
[h264 @ 0x559c0a02b880] mmco: unref short failure
 80%|███████▉  | 1548/1945 [8:20:28<2:33:27, 23.19s/it][h264 @ 0x559bfeb18840] mmco: unref short failure
 80%|███████▉  | 1549/1945 [8:20:33<1:57:54, 17.86s/it]09/10/2024 01:25:55 - INFO - __main__ -   evaluate on ret%tv--msrvtt_ret task
09/10/2024 01:25:55 - INFO - __main__ -   start running ret%tv validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559bf422b740] mmco: unref short failure
[h264 @ 0x559bf422b740] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:17,  1.60it/s][A
  1%|          | 2/221 [00:01<02:07,  1.72it/s][A
  2%|▏         | 5/221 [00:01<00:42,  5.06it/s][A
  3%|▎         | 7/221 [00:01<00:35,  6.05it/s][A
  4%|▎         | 8/221 [00:01<00:47,  4.51it/s][A
  4%|▍         | 9/221 [00:02<00:41,  5.06it/s][A
  5%|▍         | 10/221 [00:02<00:46,  4.55it/s][A
  5%|▌         | 12/221 [00:03<01:03,  3.29it/s][A
  6%|▋         | 14/221 [00:05<01:51,  1.86it/s][A
  7%|▋         | 15/221 [00:05<01:38,  2.09it/s][A
  7%|▋         | 16/221 [00:05<01:26,  2.38it/s][A
  8%|▊         | 17/221 [00:05<01:11,  2.87it/s][A
  8%|▊         | 18/221 [00:05<01:03,  3.21it/s][A
  9%|▉         | 20/221 [00:06<00:42,  4.69it/s][A
 10%|▉         | 22/221 [00:06<00:35,  5.57it/s][A
 11%|█▏        | 25/221 [00:06<00:25,  7.81it/s][A
 12%|█▏        | 26/221 [00:06<00:29,  6.72it/s][A
 13%|█▎        | 28/221 [00:06<00:26,  7.24it/s][A
 14%|█▎        | 30/221 [00:07<00:22,  8.63it/s][A
 14%|█▍        | 32/221 [00:07<00:20,  9.38it/s][A
 15%|█▌        | 34/221 [00:07<00:22,  8.27it/s][A
 16%|█▋        | 36/221 [00:07<00:21,  8.63it/s][A
 17%|█▋        | 37/221 [00:08<00:41,  4.44it/s][A
 17%|█▋        | 38/221 [00:08<00:42,  4.34it/s][A
 18%|█▊        | 40/221 [00:08<00:33,  5.34it/s][A
 19%|█▉        | 42/221 [00:09<00:36,  4.94it/s][A
 20%|█▉        | 44/221 [00:09<00:27,  6.49it/s][A
 20%|██        | 45/221 [00:10<00:51,  3.41it/s][A
 21%|██        | 46/221 [00:10<00:56,  3.09it/s][A
 21%|██▏       | 47/221 [00:12<01:55,  1.50it/s][A
 22%|██▏       | 49/221 [00:12<01:13,  2.34it/s][A
 24%|██▎       | 52/221 [00:12<00:42,  3.96it/s][A
 24%|██▍       | 54/221 [00:13<00:47,  3.52it/s][A
 25%|██▍       | 55/221 [00:14<00:52,  3.15it/s][A
 25%|██▌       | 56/221 [00:14<00:46,  3.51it/s][A
 26%|██▌       | 57/221 [00:14<00:41,  3.92it/s][A
 27%|██▋       | 59/221 [00:14<00:29,  5.56it/s][A
 27%|██▋       | 60/221 [00:14<00:33,  4.81it/s][A
 28%|██▊       | 61/221 [00:15<00:32,  4.97it/s][A
 28%|██▊       | 62/221 [00:15<00:27,  5.68it/s][A
 29%|██▉       | 64/221 [00:15<00:20,  7.66it/s][A
 30%|██▉       | 66/221 [00:15<00:24,  6.25it/s][A
 30%|███       | 67/221 [00:15<00:23,  6.61it/s][A
 31%|███       | 69/221 [00:16<00:27,  5.50it/s][A
 32%|███▏      | 71/221 [00:18<01:07,  2.21it/s][A
 33%|███▎      | 72/221 [00:18<00:57,  2.58it/s][A
 33%|███▎      | 73/221 [00:18<00:52,  2.82it/s][A
 34%|███▍      | 75/221 [00:18<00:42,  3.41it/s][A
 34%|███▍      | 76/221 [00:19<00:36,  3.92it/s][A
 35%|███▌      | 78/221 [00:19<00:33,  4.32it/s][A
 36%|███▌      | 79/221 [00:20<00:43,  3.28it/s][A
 37%|███▋      | 81/221 [00:20<00:33,  4.14it/s][A
 37%|███▋      | 82/221 [00:20<00:33,  4.15it/s][A
 38%|███▊      | 84/221 [00:20<00:24,  5.69it/s][A
 39%|███▉      | 86/221 [00:20<00:18,  7.40it/s][A
 40%|███▉      | 88/221 [00:21<00:23,  5.60it/s][A
 40%|████      | 89/221 [00:24<01:29,  1.47it/s][A
 41%|████      | 90/221 [00:24<01:14,  1.76it/s][A
 42%|████▏     | 92/221 [00:24<00:49,  2.61it/s][A
 42%|████▏     | 93/221 [00:24<00:50,  2.56it/s][A
 43%|████▎     | 94/221 [00:25<00:44,  2.83it/s][A
 43%|████▎     | 96/221 [00:25<00:33,  3.71it/s][A
 44%|████▍     | 98/221 [00:25<00:24,  4.92it/s][A
 45%|████▌     | 100/221 [00:25<00:20,  5.86it/s][A
 46%|████▌     | 102/221 [00:26<00:19,  6.22it/s][A
 47%|████▋     | 104/221 [00:26<00:14,  7.81it/s][A
 48%|████▊     | 106/221 [00:27<00:25,  4.48it/s][A
 49%|████▉     | 108/221 [00:27<00:20,  5.46it/s][A
 49%|████▉     | 109/221 [00:27<00:21,  5.22it/s][A
 50%|█████     | 111/221 [00:27<00:22,  4.98it/s][A
 51%|█████     | 112/221 [00:28<00:20,  5.25it/s][A
 51%|█████     | 113/221 [00:28<00:27,  3.89it/s][A
 52%|█████▏    | 116/221 [00:33<01:29,  1.17it/s][A
 53%|█████▎    | 117/221 [00:33<01:17,  1.35it/s][A
 53%|█████▎    | 118/221 [00:33<01:07,  1.53it/s][A
 54%|█████▍    | 120/221 [00:33<00:46,  2.17it/s][A
 55%|█████▌    | 122/221 [00:34<00:33,  2.98it/s][A
 56%|█████▌    | 123/221 [00:34<00:28,  3.46it/s][A
 56%|█████▌    | 124/221 [00:34<00:25,  3.83it/s][A
 57%|█████▋    | 125/221 [00:34<00:22,  4.33it/s][A
 57%|█████▋    | 126/221 [00:34<00:24,  3.88it/s][A
 57%|█████▋    | 127/221 [00:35<00:24,  3.77it/s][A
 58%|█████▊    | 128/221 [00:35<00:26,  3.44it/s][A
 58%|█████▊    | 129/221 [00:35<00:22,  4.08it/s][A
 59%|█████▉    | 130/221 [00:35<00:19,  4.75it/s][A
 60%|█████▉    | 132/221 [00:35<00:14,  6.35it/s][A
 60%|██████    | 133/221 [00:36<00:19,  4.55it/s][A
 61%|██████    | 134/221 [00:36<00:17,  4.88it/s][A
 61%|██████    | 135/221 [00:36<00:19,  4.42it/s][A
 62%|██████▏   | 136/221 [00:37<00:22,  3.82it/s][A
 62%|██████▏   | 137/221 [00:37<00:21,  3.94it/s][A
 62%|██████▏   | 138/221 [00:37<00:29,  2.81it/s][A
 63%|██████▎   | 139/221 [00:38<00:26,  3.09it/s][A
 63%|██████▎   | 140/221 [00:38<00:25,  3.17it/s][A
 64%|██████▍   | 141/221 [00:38<00:20,  3.81it/s][A
 64%|██████▍   | 142/221 [00:39<00:28,  2.77it/s][A
 65%|██████▍   | 143/221 [00:39<00:24,  3.15it/s][A
 66%|██████▌   | 145/221 [00:39<00:15,  4.97it/s][A
 67%|██████▋   | 147/221 [00:39<00:10,  6.82it/s][A
 67%|██████▋   | 148/221 [00:39<00:11,  6.57it/s][A
 68%|██████▊   | 150/221 [00:40<00:08,  8.52it/s][A
 69%|██████▉   | 152/221 [00:40<00:12,  5.58it/s][A
 69%|██████▉   | 153/221 [00:41<00:15,  4.37it/s][A
 70%|██████▉   | 154/221 [00:41<00:18,  3.55it/s][A
 71%|███████   | 156/221 [00:41<00:13,  4.92it/s][A
 71%|███████   | 157/221 [00:45<01:01,  1.04it/s][A
 71%|███████▏  | 158/221 [00:45<00:48,  1.30it/s][A
 72%|███████▏  | 159/221 [00:45<00:38,  1.60it/s][A
 72%|███████▏  | 160/221 [00:45<00:30,  2.03it/s][A
 73%|███████▎  | 162/221 [00:45<00:18,  3.28it/s][A
 74%|███████▍  | 163/221 [00:46<00:16,  3.46it/s][A
 74%|███████▍  | 164/221 [00:46<00:14,  3.91it/s][A
 75%|███████▍  | 165/221 [00:46<00:12,  4.37it/s][A
 75%|███████▌  | 166/221 [00:46<00:16,  3.41it/s][A
 76%|███████▌  | 168/221 [00:51<00:59,  1.12s/it][A
 76%|███████▋  | 169/221 [00:51<00:47,  1.10it/s][A
 77%|███████▋  | 170/221 [00:51<00:37,  1.36it/s][A
 77%|███████▋  | 171/221 [00:51<00:28,  1.74it/s][A
 78%|███████▊  | 172/221 [00:52<00:22,  2.15it/s][A
 79%|███████▊  | 174/221 [00:52<00:13,  3.50it/s][A
 79%|███████▉  | 175/221 [00:52<00:12,  3.70it/s][A
 80%|███████▉  | 176/221 [00:52<00:11,  3.88it/s][A
 81%|████████  | 178/221 [00:52<00:09,  4.60it/s][A
 81%|████████  | 179/221 [00:54<00:22,  1.87it/s][A
 82%|████████▏ | 181/221 [00:54<00:14,  2.71it/s][A
 82%|████████▏ | 182/221 [00:54<00:12,  3.23it/s][A
 83%|████████▎ | 183/221 [00:54<00:10,  3.77it/s][A
 83%|████████▎ | 184/221 [00:55<00:10,  3.46it/s][A
 84%|████████▍ | 186/221 [00:55<00:08,  4.30it/s][A
 85%|████████▌ | 188/221 [00:56<00:07,  4.61it/s][A
 86%|████████▌ | 189/221 [00:56<00:07,  4.57it/s][A
 86%|████████▌ | 190/221 [00:56<00:06,  4.81it/s][A
 87%|████████▋ | 192/221 [00:56<00:05,  5.22it/s][A
 88%|████████▊ | 194/221 [00:57<00:06,  4.16it/s][A
 89%|████████▊ | 196/221 [00:57<00:04,  5.45it/s][A
 90%|████████▉ | 198/221 [00:57<00:03,  5.91it/s][A
 90%|█████████ | 199/221 [00:57<00:03,  6.33it/s][A
 90%|█████████ | 200/221 [00:58<00:03,  5.41it/s][A
 91%|█████████ | 201/221 [00:58<00:03,  5.10it/s][A
 91%|█████████▏| 202/221 [00:58<00:03,  5.56it/s][A
 92%|█████████▏| 203/221 [00:58<00:02,  6.20it/s][A
 93%|█████████▎| 205/221 [00:58<00:01,  8.34it/s][A
 93%|█████████▎| 206/221 [00:59<00:02,  5.10it/s][A
 94%|█████████▍| 208/221 [00:59<00:01,  7.17it/s][A
 95%|█████████▌| 211/221 [00:59<00:01,  7.03it/s][A
 96%|█████████▋| 213/221 [01:00<00:00,  8.11it/s][A
 97%|█████████▋| 215/221 [01:00<00:01,  5.51it/s][A
 98%|█████████▊| 216/221 [01:00<00:00,  5.69it/s][A
 98%|█████████▊| 217/221 [01:02<00:01,  2.49it/s][A
 99%|█████████▊| 218/221 [01:02<00:01,  2.87it/s][A
 99%|█████████▉| 219/221 [01:02<00:00,  3.21it/s][A
100%|█████████▉| 220/221 [01:06<00:01,  1.38s/it][A
100%|██████████| 221/221 [01:07<00:00,  1.04s/it][A100%|██████████| 221/221 [01:07<00:00,  3.30it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:58,  3.79it/s][A
  1%|          | 2/221 [00:00<00:57,  3.79it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.79it/s][A
  2%|▏         | 4/221 [00:01<00:57,  3.79it/s][A
  2%|▏         | 5/221 [00:01<00:57,  3.79it/s][A
  3%|▎         | 6/221 [00:01<00:56,  3.79it/s][A
  3%|▎         | 7/221 [00:01<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:02<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 10/221 [00:02<00:55,  3.79it/s][A
  5%|▍         | 11/221 [00:02<00:55,  3.79it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.79it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.79it/s][A
  7%|▋         | 16/221 [00:04<00:54,  3.79it/s][A
  8%|▊         | 17/221 [00:04<00:53,  3.79it/s][A
  8%|▊         | 18/221 [00:04<00:53,  3.79it/s][A
  9%|▊         | 19/221 [00:05<00:53,  3.79it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.79it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 22/221 [00:05<00:52,  3.79it/s][A
 10%|█         | 23/221 [00:06<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:06<00:52,  3.79it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 26/221 [00:06<00:51,  3.79it/s][A
 12%|█▏        | 27/221 [00:07<00:51,  3.79it/s][A
 13%|█▎        | 28/221 [00:07<00:50,  3.79it/s][A
 13%|█▎        | 29/221 [00:07<00:50,  3.79it/s][A
 14%|█▎        | 30/221 [00:07<00:50,  3.79it/s][A
 14%|█▍        | 31/221 [00:08<00:50,  3.79it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.79it/s][A
 15%|█▍        | 33/221 [00:08<00:49,  3.79it/s][A
 15%|█▌        | 34/221 [00:08<00:49,  3.79it/s][A
 16%|█▌        | 35/221 [00:09<00:49,  3.79it/s][A
 16%|█▋        | 36/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 37/221 [00:09<00:48,  3.79it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.79it/s][A
 18%|█▊        | 40/221 [00:10<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:10<00:47,  3.79it/s][A
 19%|█▉        | 42/221 [00:11<00:47,  3.79it/s][A
 19%|█▉        | 43/221 [00:11<00:46,  3.79it/s][A
 20%|█▉        | 44/221 [00:11<00:46,  3.79it/s][A
 20%|██        | 45/221 [00:11<00:46,  3.79it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 21%|██▏       | 47/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:45,  3.79it/s][A
 22%|██▏       | 49/221 [00:12<00:45,  3.79it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.79it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.79it/s][A
 24%|██▎       | 52/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 53/221 [00:13<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:14<00:44,  3.79it/s][A
 25%|██▍       | 55/221 [00:14<00:43,  3.79it/s][A
 25%|██▌       | 56/221 [00:14<00:43,  3.79it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.79it/s][A
 26%|██▌       | 58/221 [00:15<00:43,  3.79it/s][A
 27%|██▋       | 59/221 [00:15<00:42,  3.79it/s][A
 27%|██▋       | 60/221 [00:15<00:42,  3.79it/s][A
 28%|██▊       | 61/221 [00:16<00:42,  3.79it/s][A
 28%|██▊       | 62/221 [00:16<00:41,  3.79it/s][A
 29%|██▊       | 63/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 64/221 [00:16<00:41,  3.79it/s][A
 29%|██▉       | 65/221 [00:17<00:41,  3.79it/s][A
 30%|██▉       | 66/221 [00:17<00:40,  3.79it/s][A
 30%|███       | 67/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 68/221 [00:17<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:18<00:40,  3.79it/s][A
 32%|███▏      | 70/221 [00:18<00:39,  3.79it/s][A
 32%|███▏      | 71/221 [00:18<00:39,  3.79it/s][A
 33%|███▎      | 72/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 73/221 [00:19<00:39,  3.79it/s][A
 33%|███▎      | 74/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 75/221 [00:19<00:38,  3.79it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.79it/s][A
 35%|███▍      | 77/221 [00:20<00:38,  3.79it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 79/221 [00:20<00:37,  3.79it/s][A
 36%|███▌      | 80/221 [00:21<00:37,  3.79it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.79it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 83/221 [00:21<00:36,  3.79it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.79it/s][A
 38%|███▊      | 85/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 86/221 [00:22<00:35,  3.79it/s][A
 39%|███▉      | 87/221 [00:22<00:35,  3.79it/s][A
 40%|███▉      | 88/221 [00:23<00:35,  3.79it/s][A
 40%|████      | 89/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 90/221 [00:23<00:34,  3.79it/s][A
 41%|████      | 91/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 92/221 [00:24<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 94/221 [00:24<00:33,  3.79it/s][A
 43%|████▎     | 95/221 [00:25<00:33,  3.79it/s][A
 43%|████▎     | 96/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 97/221 [00:25<00:32,  3.79it/s][A
 44%|████▍     | 98/221 [00:25<00:32,  3.79it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.79it/s][A
 45%|████▌     | 100/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:26<00:31,  3.79it/s][A
 46%|████▌     | 102/221 [00:26<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:27<00:31,  3.79it/s][A
 47%|████▋     | 104/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 105/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 106/221 [00:27<00:30,  3.79it/s][A
 48%|████▊     | 107/221 [00:28<00:30,  3.79it/s][A
 49%|████▉     | 108/221 [00:28<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:28<00:29,  3.79it/s][A
 50%|████▉     | 110/221 [00:29<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:29<00:29,  3.79it/s][A
 51%|█████     | 112/221 [00:29<00:28,  3.79it/s][A
 51%|█████     | 113/221 [00:29<00:28,  3.79it/s][A
 52%|█████▏    | 114/221 [00:30<00:28,  3.79it/s][A
 52%|█████▏    | 115/221 [00:30<00:27,  3.79it/s][A
 52%|█████▏    | 116/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 117/221 [00:30<00:27,  3.79it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.79it/s][A
 54%|█████▍    | 119/221 [00:31<00:26,  3.79it/s][A
 54%|█████▍    | 120/221 [00:31<00:26,  3.79it/s][A
 55%|█████▍    | 121/221 [00:31<00:26,  3.79it/s][A
 55%|█████▌    | 122/221 [00:32<00:26,  3.79it/s][A
 56%|█████▌    | 123/221 [00:32<00:25,  3.79it/s][A
 56%|█████▌    | 124/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 125/221 [00:32<00:25,  3.79it/s][A
 57%|█████▋    | 126/221 [00:33<00:25,  3.79it/s][A
 57%|█████▋    | 127/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 128/221 [00:33<00:24,  3.79it/s][A
 58%|█████▊    | 129/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 130/221 [00:34<00:24,  3.79it/s][A
 59%|█████▉    | 131/221 [00:34<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:34<00:23,  3.79it/s][A
 60%|██████    | 133/221 [00:35<00:23,  3.79it/s][A
 61%|██████    | 134/221 [00:35<00:22,  3.79it/s][A
 61%|██████    | 135/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 136/221 [00:35<00:22,  3.79it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.79it/s][A
 62%|██████▏   | 138/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 139/221 [00:36<00:21,  3.79it/s][A
 63%|██████▎   | 140/221 [00:36<00:21,  3.79it/s][A
 64%|██████▍   | 141/221 [00:37<00:21,  3.79it/s][A
 64%|██████▍   | 142/221 [00:37<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:37<00:20,  3.79it/s][A
 65%|██████▌   | 144/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:38<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:38<00:19,  3.79it/s][A
 67%|██████▋   | 148/221 [00:39<00:19,  3.79it/s][A
 67%|██████▋   | 149/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:39<00:18,  3.79it/s][A
 68%|██████▊   | 151/221 [00:39<00:18,  3.79it/s][A
 69%|██████▉   | 152/221 [00:40<00:18,  3.79it/s][A
 69%|██████▉   | 153/221 [00:40<00:17,  3.79it/s][A
 70%|██████▉   | 154/221 [00:40<00:17,  3.79it/s][A
 70%|███████   | 155/221 [00:40<00:17,  3.79it/s][A
 71%|███████   | 156/221 [00:41<00:17,  3.79it/s][A
 71%|███████   | 157/221 [00:41<00:16,  3.79it/s][A
 71%|███████▏  | 158/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 159/221 [00:41<00:16,  3.79it/s][A
 72%|███████▏  | 160/221 [00:42<00:16,  3.79it/s][A
 73%|███████▎  | 161/221 [00:42<00:15,  3.79it/s][A
 73%|███████▎  | 162/221 [00:42<00:15,  3.79it/s][A
 74%|███████▍  | 163/221 [00:43<00:15,  3.79it/s][A
 74%|███████▍  | 164/221 [00:43<00:15,  3.79it/s][A
 75%|███████▍  | 165/221 [00:43<00:14,  3.79it/s][A
 75%|███████▌  | 166/221 [00:43<00:14,  3.79it/s][A
 76%|███████▌  | 167/221 [00:44<00:14,  3.79it/s][A
 76%|███████▌  | 168/221 [00:44<00:13,  3.79it/s][A
 76%|███████▋  | 169/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 170/221 [00:44<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:45<00:13,  3.79it/s][A
 78%|███████▊  | 172/221 [00:45<00:12,  3.79it/s][A
 78%|███████▊  | 173/221 [00:45<00:12,  3.79it/s][A
 79%|███████▊  | 174/221 [00:45<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [00:46<00:12,  3.79it/s][A
 80%|███████▉  | 176/221 [00:46<00:11,  3.79it/s][A
 80%|████████  | 177/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:46<00:11,  3.79it/s][A
 81%|████████  | 179/221 [00:47<00:11,  3.79it/s][A
 81%|████████▏ | 180/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 181/221 [00:47<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 183/221 [00:48<00:10,  3.79it/s][A
 83%|████████▎ | 184/221 [00:48<00:09,  3.79it/s][A
 84%|████████▎ | 185/221 [00:48<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [00:49<00:09,  3.79it/s][A
 85%|████████▍ | 187/221 [00:49<00:08,  3.79it/s][A
 85%|████████▌ | 188/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 189/221 [00:49<00:08,  3.79it/s][A
 86%|████████▌ | 190/221 [00:50<00:08,  3.79it/s][A
 86%|████████▋ | 191/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:50<00:07,  3.79it/s][A
 87%|████████▋ | 193/221 [00:50<00:07,  3.79it/s][A
 88%|████████▊ | 194/221 [00:51<00:07,  3.79it/s][A
 88%|████████▊ | 195/221 [00:51<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:51<00:06,  3.79it/s][A
 89%|████████▉ | 197/221 [00:51<00:06,  3.79it/s][A
 90%|████████▉ | 198/221 [00:52<00:06,  3.79it/s][A
 90%|█████████ | 199/221 [00:52<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:52<00:05,  3.79it/s][A
 91%|█████████ | 201/221 [00:53<00:05,  3.79it/s][A
 91%|█████████▏| 202/221 [00:53<00:05,  3.79it/s][A
 92%|█████████▏| 203/221 [00:53<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [00:53<00:04,  3.79it/s][A
 93%|█████████▎| 205/221 [00:54<00:04,  3.79it/s][A
 93%|█████████▎| 206/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▎| 207/221 [00:54<00:03,  3.79it/s][A
 94%|█████████▍| 208/221 [00:54<00:03,  3.79it/s][A
 95%|█████████▍| 209/221 [00:55<00:03,  3.79it/s][A
 95%|█████████▌| 210/221 [00:55<00:02,  3.79it/s][A
 95%|█████████▌| 211/221 [00:55<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [00:55<00:02,  3.78it/s][A
 96%|█████████▋| 213/221 [00:56<00:02,  3.78it/s][A
 97%|█████████▋| 214/221 [00:56<00:01,  3.79it/s][A
 97%|█████████▋| 215/221 [00:56<00:01,  3.79it/s][A
 98%|█████████▊| 216/221 [00:57<00:01,  3.79it/s][A
 98%|█████████▊| 217/221 [00:57<00:01,  3.79it/s][A
 99%|█████████▊| 218/221 [00:57<00:00,  3.79it/s][A
 99%|█████████▉| 219/221 [00:57<00:00,  3.79it/s][A
100%|█████████▉| 220/221 [00:58<00:00,  3.79it/s][A
100%|██████████| 221/221 [00:58<00:00,  3.79it/s][A100%|██████████| 221/221 [00:58<00:00,  3.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:34,  6.46it/s][A
  1%|          | 2/221 [00:00<00:43,  5.01it/s][A
  1%|▏         | 3/221 [00:00<00:48,  4.52it/s][A
  2%|▏         | 4/221 [00:00<00:45,  4.80it/s][A
  2%|▏         | 5/221 [00:01<00:45,  4.74it/s][A
  3%|▎         | 7/221 [00:01<00:39,  5.48it/s][A
  4%|▎         | 8/221 [00:01<00:45,  4.70it/s][A
  4%|▍         | 9/221 [00:01<00:47,  4.44it/s][A
  5%|▍         | 10/221 [00:02<01:11,  2.94it/s][A
  5%|▍         | 11/221 [00:02<01:00,  3.46it/s][A
  5%|▌         | 12/221 [00:02<00:50,  4.14it/s][A
  6%|▌         | 13/221 [00:03<01:31,  2.27it/s][A
  6%|▋         | 14/221 [00:03<01:12,  2.87it/s][A
  7%|▋         | 15/221 [00:04<01:03,  3.23it/s][A
  7%|▋         | 16/221 [00:04<01:06,  3.07it/s][A
  8%|▊         | 17/221 [00:05<01:23,  2.43it/s][A
  8%|▊         | 18/221 [00:05<01:10,  2.88it/s][A
  9%|▊         | 19/221 [00:05<00:59,  3.41it/s][A
 10%|▉         | 21/221 [00:05<00:43,  4.57it/s][A
 10%|▉         | 22/221 [00:05<00:41,  4.81it/s][A
 10%|█         | 23/221 [00:05<00:37,  5.33it/s][A
 11%|█         | 24/221 [00:06<00:35,  5.57it/s][A
 11%|█▏        | 25/221 [00:06<00:36,  5.34it/s][A
 12%|█▏        | 26/221 [00:06<00:37,  5.16it/s][A
 12%|█▏        | 27/221 [00:06<00:32,  5.90it/s][A
 13%|█▎        | 28/221 [00:07<00:42,  4.58it/s][A
 13%|█▎        | 29/221 [00:07<00:43,  4.46it/s][A
 14%|█▎        | 30/221 [00:07<00:45,  4.17it/s][A
 14%|█▍        | 31/221 [00:07<00:42,  4.45it/s][A
 14%|█▍        | 32/221 [00:07<00:38,  4.95it/s][A
 15%|█▍        | 33/221 [00:08<00:39,  4.75it/s][A
 15%|█▌        | 34/221 [00:08<00:40,  4.64it/s][A
 16%|█▌        | 35/221 [00:08<00:44,  4.15it/s][A
 16%|█▋        | 36/221 [00:08<00:48,  3.80it/s][A
 17%|█▋        | 37/221 [00:09<00:41,  4.45it/s][A
 17%|█▋        | 38/221 [00:09<00:44,  4.16it/s][A
 18%|█▊        | 39/221 [00:09<00:40,  4.46it/s][A
 18%|█▊        | 40/221 [00:09<00:49,  3.68it/s][A
 19%|█▊        | 41/221 [00:10<00:45,  3.98it/s][A
 19%|█▉        | 42/221 [00:10<00:38,  4.70it/s][A
 19%|█▉        | 43/221 [00:10<00:43,  4.05it/s][A
 20%|█▉        | 44/221 [00:10<00:46,  3.82it/s][A
 20%|██        | 45/221 [00:11<00:47,  3.68it/s][A
 21%|██        | 46/221 [00:11<00:45,  3.82it/s][A
 21%|██▏       | 47/221 [00:11<00:45,  3.87it/s][A
 22%|██▏       | 48/221 [00:11<00:39,  4.43it/s][A
 22%|██▏       | 49/221 [00:12<00:39,  4.31it/s][A
 23%|██▎       | 50/221 [00:12<00:52,  3.24it/s][A
 23%|██▎       | 51/221 [00:12<00:45,  3.76it/s][A
 24%|██▎       | 52/221 [00:12<00:44,  3.77it/s][A
 24%|██▍       | 53/221 [00:13<00:36,  4.57it/s][A
 24%|██▍       | 54/221 [00:13<00:46,  3.58it/s][A
 25%|██▍       | 55/221 [00:13<00:45,  3.66it/s][A
 25%|██▌       | 56/221 [00:13<00:41,  3.97it/s][A
 26%|██▌       | 57/221 [00:14<00:44,  3.72it/s][A
 26%|██▌       | 58/221 [00:14<00:48,  3.35it/s][A
 27%|██▋       | 59/221 [00:14<00:43,  3.70it/s][A
 27%|██▋       | 60/221 [00:15<00:38,  4.21it/s][A
 28%|██▊       | 61/221 [00:15<00:36,  4.40it/s][A
 28%|██▊       | 62/221 [00:15<00:37,  4.22it/s][A
 29%|██▊       | 63/221 [00:15<00:34,  4.58it/s][A
 29%|██▉       | 64/221 [00:15<00:39,  3.93it/s][A
 29%|██▉       | 65/221 [00:16<00:35,  4.35it/s][A
 30%|██▉       | 66/221 [00:16<00:50,  3.07it/s][A
 30%|███       | 67/221 [00:17<00:52,  2.93it/s][A
 31%|███       | 68/221 [00:17<00:44,  3.46it/s][A
 31%|███       | 69/221 [00:17<01:03,  2.38it/s][A
 32%|███▏      | 70/221 [00:18<00:51,  2.90it/s][A
 32%|███▏      | 71/221 [00:18<00:44,  3.36it/s][A
 33%|███▎      | 72/221 [00:18<00:49,  3.01it/s][A
 33%|███▎      | 73/221 [00:19<00:48,  3.02it/s][A
 33%|███▎      | 74/221 [00:19<00:42,  3.43it/s][A
 34%|███▍      | 75/221 [00:19<00:40,  3.57it/s][A
 34%|███▍      | 76/221 [00:19<00:37,  3.83it/s][A
 35%|███▍      | 77/221 [00:20<00:41,  3.48it/s][A
 35%|███▌      | 78/221 [00:20<00:38,  3.74it/s][A
 36%|███▌      | 79/221 [00:20<00:42,  3.32it/s][A
 36%|███▌      | 80/221 [00:20<00:38,  3.63it/s][A
 37%|███▋      | 81/221 [00:21<00:36,  3.86it/s][A
 37%|███▋      | 82/221 [00:21<00:42,  3.26it/s][A
 38%|███▊      | 83/221 [00:21<00:44,  3.11it/s][A
 38%|███▊      | 84/221 [00:22<00:42,  3.20it/s][A
 38%|███▊      | 85/221 [00:22<00:34,  4.00it/s][A
 39%|███▉      | 86/221 [00:22<00:34,  3.93it/s][A
 39%|███▉      | 87/221 [00:23<00:41,  3.21it/s][A
 40%|███▉      | 88/221 [00:23<00:46,  2.85it/s][A
 40%|████      | 89/221 [00:23<00:42,  3.10it/s][A
 41%|████      | 90/221 [00:24<00:47,  2.78it/s][A
 41%|████      | 91/221 [00:24<00:38,  3.35it/s][A
 42%|████▏     | 92/221 [00:24<00:41,  3.14it/s][A
 42%|████▏     | 93/221 [00:25<00:57,  2.24it/s][A
 43%|████▎     | 94/221 [00:25<00:50,  2.50it/s][A
 43%|████▎     | 95/221 [00:25<00:45,  2.75it/s][A
 43%|████▎     | 96/221 [00:26<00:42,  2.95it/s][A
 44%|████▍     | 97/221 [00:26<00:37,  3.33it/s][A
 44%|████▍     | 98/221 [00:26<00:35,  3.45it/s][A
 45%|████▍     | 99/221 [00:26<00:32,  3.76it/s][A
 45%|████▌     | 100/221 [00:27<00:33,  3.62it/s][A
 46%|████▌     | 101/221 [00:27<00:30,  3.90it/s][A
 46%|████▌     | 102/221 [00:28<00:44,  2.68it/s][A
 47%|████▋     | 103/221 [00:28<00:35,  3.34it/s][A
 47%|████▋     | 104/221 [00:28<00:29,  3.94it/s][A
 48%|████▊     | 105/221 [00:28<00:30,  3.77it/s][A
 48%|████▊     | 106/221 [00:29<00:34,  3.35it/s][A
 48%|████▊     | 107/221 [00:29<00:31,  3.61it/s][A
 49%|████▉     | 108/221 [00:29<00:30,  3.67it/s][A
 49%|████▉     | 109/221 [00:29<00:25,  4.37it/s][A
 50%|████▉     | 110/221 [00:29<00:26,  4.18it/s][A
 50%|█████     | 111/221 [00:30<00:26,  4.08it/s][A
 51%|█████     | 112/221 [00:30<00:26,  4.11it/s][A
 51%|█████     | 113/221 [00:30<00:24,  4.33it/s][A
 52%|█████▏    | 114/221 [00:30<00:21,  5.03it/s][A
 52%|█████▏    | 115/221 [00:31<00:22,  4.75it/s][A
 52%|█████▏    | 116/221 [00:31<00:23,  4.47it/s][A
 53%|█████▎    | 117/221 [00:31<00:24,  4.29it/s][A
 53%|█████▎    | 118/221 [00:31<00:23,  4.46it/s][A
 54%|█████▍    | 119/221 [00:32<00:29,  3.47it/s][A
 54%|█████▍    | 120/221 [00:32<00:26,  3.81it/s][A
 55%|█████▍    | 121/221 [00:32<00:21,  4.56it/s][A
 55%|█████▌    | 122/221 [00:32<00:23,  4.30it/s][A
 56%|█████▌    | 123/221 [00:33<00:26,  3.66it/s][A
 56%|█████▌    | 124/221 [00:33<00:24,  3.93it/s][A
 57%|█████▋    | 125/221 [00:33<00:26,  3.62it/s][A
 57%|█████▋    | 126/221 [00:33<00:23,  4.04it/s][A
 57%|█████▋    | 127/221 [00:34<00:26,  3.50it/s][A
 58%|█████▊    | 128/221 [00:34<00:26,  3.53it/s][A
 58%|█████▊    | 129/221 [00:34<00:21,  4.19it/s][A
 59%|█████▉    | 130/221 [00:34<00:21,  4.32it/s][A
 59%|█████▉    | 131/221 [00:34<00:17,  5.02it/s][A
 60%|█████▉    | 132/221 [00:35<00:20,  4.34it/s][A
 60%|██████    | 133/221 [00:35<00:24,  3.58it/s][A
 61%|██████    | 134/221 [00:36<00:29,  2.92it/s][A
 61%|██████    | 135/221 [00:36<00:30,  2.83it/s][A
 62%|██████▏   | 136/221 [00:36<00:26,  3.17it/s][A
 62%|██████▏   | 137/221 [00:36<00:22,  3.77it/s][A
 62%|██████▏   | 138/221 [00:37<00:23,  3.57it/s][A
 63%|██████▎   | 139/221 [00:37<00:25,  3.20it/s][A
 63%|██████▎   | 140/221 [00:37<00:24,  3.27it/s][A
 64%|██████▍   | 141/221 [00:38<00:22,  3.60it/s][A
 64%|██████▍   | 142/221 [00:38<00:20,  3.86it/s][A
 65%|██████▍   | 143/221 [00:38<00:24,  3.17it/s][A
 65%|██████▌   | 144/221 [00:39<00:27,  2.83it/s][A
 66%|██████▌   | 145/221 [00:39<00:21,  3.52it/s][A
 67%|██████▋   | 147/221 [00:39<00:17,  4.24it/s][A
 67%|██████▋   | 148/221 [00:40<00:19,  3.70it/s][A
 67%|██████▋   | 149/221 [00:40<00:19,  3.77it/s][A
 68%|██████▊   | 150/221 [00:40<00:18,  3.91it/s][A
 68%|██████▊   | 151/221 [00:40<00:21,  3.21it/s][A
 69%|██████▉   | 152/221 [00:41<00:28,  2.40it/s][A
 69%|██████▉   | 153/221 [00:41<00:23,  2.93it/s][A
 70%|██████▉   | 154/221 [00:42<00:20,  3.30it/s][A
 70%|███████   | 155/221 [00:42<00:17,  3.67it/s][A
 71%|███████   | 156/221 [00:42<00:19,  3.26it/s][A
 71%|███████   | 157/221 [00:42<00:19,  3.25it/s][A
 71%|███████▏  | 158/221 [00:43<00:18,  3.40it/s][A
 72%|███████▏  | 159/221 [00:43<00:15,  3.96it/s][A
 72%|███████▏  | 160/221 [00:43<00:14,  4.21it/s][A
 73%|███████▎  | 161/221 [00:44<00:19,  3.13it/s][A
 73%|███████▎  | 162/221 [00:44<00:15,  3.72it/s][A
 74%|███████▍  | 163/221 [00:44<00:15,  3.74it/s][A
 74%|███████▍  | 164/221 [00:44<00:13,  4.19it/s][A
 75%|███████▍  | 165/221 [00:44<00:13,  4.06it/s][A
 75%|███████▌  | 166/221 [00:45<00:13,  4.10it/s][A
 76%|███████▌  | 167/221 [00:45<00:10,  4.95it/s][A
 76%|███████▌  | 168/221 [00:45<00:12,  4.13it/s][A
 76%|███████▋  | 169/221 [00:45<00:10,  4.88it/s][A
 77%|███████▋  | 170/221 [00:46<00:15,  3.29it/s][A
 77%|███████▋  | 171/221 [00:46<00:13,  3.67it/s][A
 78%|███████▊  | 172/221 [00:46<00:13,  3.76it/s][A
 78%|███████▊  | 173/221 [00:47<00:13,  3.45it/s][A
 79%|███████▊  | 174/221 [00:47<00:16,  2.90it/s][A
 79%|███████▉  | 175/221 [00:47<00:16,  2.82it/s][A
 80%|███████▉  | 176/221 [00:48<00:14,  3.06it/s][A
 80%|████████  | 177/221 [00:48<00:13,  3.35it/s][A
 81%|████████  | 178/221 [00:48<00:12,  3.47it/s][A
 81%|████████  | 179/221 [00:48<00:11,  3.58it/s][A
 81%|████████▏ | 180/221 [00:49<00:10,  4.05it/s][A
 82%|████████▏ | 181/221 [00:49<00:10,  3.82it/s][A
 82%|████████▏ | 182/221 [00:49<00:11,  3.52it/s][A
 83%|████████▎ | 183/221 [00:49<00:10,  3.62it/s][A
 83%|████████▎ | 184/221 [00:50<00:10,  3.59it/s][A
 84%|████████▎ | 185/221 [00:50<00:09,  3.97it/s][A
 84%|████████▍ | 186/221 [00:50<00:11,  3.02it/s][A
 85%|████████▍ | 187/221 [00:51<00:09,  3.47it/s][A
 85%|████████▌ | 188/221 [00:51<00:09,  3.49it/s][A
 86%|████████▌ | 189/221 [00:51<00:08,  3.69it/s][A
 86%|████████▌ | 190/221 [00:52<00:09,  3.36it/s][A
 86%|████████▋ | 191/221 [00:52<00:07,  3.82it/s][A
 87%|████████▋ | 192/221 [00:52<00:07,  3.85it/s][A
 87%|████████▋ | 193/221 [00:52<00:06,  4.34it/s][A
 88%|████████▊ | 194/221 [00:52<00:07,  3.70it/s][A
 88%|████████▊ | 195/221 [00:53<00:06,  3.80it/s][A
 89%|████████▊ | 196/221 [00:53<00:07,  3.24it/s][A
 89%|████████▉ | 197/221 [00:53<00:06,  3.54it/s][A
 90%|████████▉ | 198/221 [00:54<00:07,  3.02it/s][A
 90%|█████████ | 199/221 [00:54<00:06,  3.35it/s][A
 90%|█████████ | 200/221 [00:54<00:06,  3.14it/s][A
 91%|█████████ | 201/221 [00:55<00:05,  3.61it/s][A
 91%|█████████▏| 202/221 [00:55<00:05,  3.26it/s][A
 92%|█████████▏| 203/221 [00:55<00:04,  3.74it/s][A
 92%|█████████▏| 204/221 [00:56<00:05,  3.32it/s][A
 93%|█████████▎| 205/221 [00:56<00:03,  4.14it/s][A
 93%|█████████▎| 206/221 [00:56<00:04,  3.52it/s][A
 94%|█████████▎| 207/221 [00:56<00:04,  3.50it/s][A
 94%|█████████▍| 208/221 [00:56<00:03,  3.85it/s][A
 95%|█████████▍| 209/221 [00:57<00:02,  4.08it/s][A
 95%|█████████▌| 210/221 [00:57<00:02,  4.17it/s][A
 95%|█████████▌| 211/221 [00:57<00:02,  3.72it/s][A
 96%|█████████▌| 212/221 [00:58<00:02,  3.45it/s][A
 96%|█████████▋| 213/221 [00:58<00:02,  3.67it/s][A
 97%|█████████▋| 214/221 [00:58<00:02,  2.66it/s][A
 97%|█████████▋| 215/221 [00:59<00:01,  3.00it/s][A
 98%|█████████▊| 216/221 [00:59<00:01,  3.16it/s][A
 98%|█████████▊| 217/221 [00:59<00:01,  3.13it/s][A
 99%|█████████▊| 218/221 [01:00<00:00,  3.23it/s][A
 99%|█████████▉| 219/221 [01:00<00:00,  3.04it/s][A
100%|█████████▉| 220/221 [01:00<00:00,  3.51it/s][A
100%|██████████| 221/221 [01:00<00:00,  3.97it/s][A100%|██████████| 221/221 [01:00<00:00,  3.63it/s]
09/10/2024 01:30:46 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_forward=====step 1549--===========

09/10/2024 01:30:46 - INFO - __main__ -   {'area_r1': 37.0, 'area_recall': '37.0/60.9/70.7', 'area_ravg': 56.2}
09/10/2024 01:30:46 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_backard=====step 1549--===========

09/10/2024 01:30:46 - INFO - __main__ -   {'forward_r1': 35.6, 'forward_recall': '35.6/64.6/76.1', 'forward_ravg': 58.8}
09/10/2024 01:30:46 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video=====step 1549--===========

09/10/2024 01:30:46 - INFO - __main__ -   {'area_video_r1': 38.0, 'area_video_recall': '38.0/66.1/76.5', 'area_video_ravg': 60.2}
09/10/2024 01:30:46 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/10/2024 01:30:46 - INFO - __main__ -   {'area_video_r1': 41.1, 'area_video_recall': '41.1/66.2/78.1', 'area_video_ravg': 61.8}
09/10/2024 01:30:46 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_area=====step 1549--===========

09/10/2024 01:30:46 - INFO - __main__ -   {'area_video_r1': 52.4, 'area_video_recall': '52.4/73.8/81.4', 'area_video_ravg': 69.2, 'area_video_back_r1': 46.7, 'area_video_back_recall': '46.7/73.3/82.4', 'area_video_back_ravg': 67.5}
09/10/2024 01:30:46 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_area====history best step: 449=======

09/10/2024 01:30:46 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.2/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.4/81.2', 'area_video_back_ravg': 68.4}
09/10/2024 01:30:46 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itc_tv=====step 1549--===========

09/10/2024 01:30:46 - INFO - __main__ -   {'video_r1': 43.7, 'video_recall': '43.7/70.9/81.2', 'video_ravg': 65.3}
09/10/2024 01:30:46 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itc_tv====history best step: 49=======

09/10/2024 01:30:46 - INFO - __main__ -   {'video_r1': 44.6, 'video_recall': '44.6/72.4/82.5', 'video_ravg': 66.5}
09/10/2024 01:30:46 - INFO - __main__ -   ====-evaluation--ret%tv--msrvtt_ret_ret_itm_tv=====step 1549--===========

09/10/2024 01:30:46 - INFO - __main__ -   {'video_r1': 52.3, 'video_recall': '52.3/75.2/83.0', 'video_ravg': 70.2}
09/10/2024 01:30:46 - INFO - __main__ -   ======evaluation--ret%tv--msrvtt_ret_ret_itm_tv====history best step: 399=======

09/10/2024 01:30:46 - INFO - __main__ -   {'video_r1': 53.1, 'video_recall': '53.1/75.5/82.8', 'video_ravg': 70.4}
09/10/2024 01:31:07 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.006779317744076252, 'loss_ret%tv%ta--finetune_area/loss_area': 1.026012897491455, 'loss_ret%tv%ta--finetune_area/total_loss': 1.0327922105789185}
 80%|███████▉  | 1550/1945 [8:25:48<11:43:54, 106.92s/it] 80%|███████▉  | 1551/1945 [8:25:52<8:18:58, 75.99s/it]   80%|███████▉  | 1552/1945 [8:25:55<5:55:51, 54.33s/it] 80%|███████▉  | 1553/1945 [8:25:59<4:15:54, 39.17s/it] 80%|███████▉  | 1554/1945 [8:26:03<3:06:03, 28.55s/it] 80%|███████▉  | 1555/1945 [8:26:07<2:17:18, 21.13s/it]/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a032e54f80] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559be9844000] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x559be97b7ec0] mmco: unref short failure
[h264 @ 0x55a0339e7ec0] mmco: unref short failure
[h264 @ 0x55a0339e7ec0] mmco: unref short failure
[h264 @ 0x55a032d03a80] mmco: unref short failure
[h264 @ 0x55a032d03a80] mmco: unref short failure
[h264 @ 0x559beaf73d40] mmco: unref short failure
[h264 @ 0x559beaf73d40] mmco: unref short failure
[h264 @ 0x55a034802480] mmco: unref short failure
[h264 @ 0x55a0327ba440] mmco: unref short failure
[h264 @ 0x55a0327ba440] mmco: unref short failure
[h264 @ 0x55a0327ba440] mmco: unref short failure
[h264 @ 0x55a0327ba440] mmco: unref short failure
[h264 @ 0x55a032f80000] mmco: unref short failure
[h264 @ 0x55a032f80000] mmco: unref short failure
[h264 @ 0x556b2f9bf3c0] mmco: unref short failure
[h264 @ 0x556b2f9bf3c0] mmco: unref short failure
[h264 @ 0x556b2d1c7200] mmco: unref short failure
[h264 @ 0x55a034228440] mmco: unref short failure
[h264 @ 0x559beaf178c0] mmco: unref short failure
[h264 @ 0x559beaf178c0] mmco: unref short failure
[h264 @ 0x559becb17240] mmco: unref short failure
[h264 @ 0x559becb17240] mmco: unref short failure
[h264 @ 0x56241c387c40] mmco: unref short failure
[h264 @ 0x556b2d61ba00] mmco: unref short failure
[h264 @ 0x55a0327a58c0] mmco: unref short failure
[h264 @ 0x55a032627c80] mmco: unref short failure
[h264 @ 0x559be977f700] mmco: unref short failure
[h264 @ 0x55a039acc840] mmco: unref short failure
[h264 @ 0x55a039acc840] mmco: unref short failure
[h264 @ 0x559beb17a940] mmco: unref short failure
[h264 @ 0x556b3390c000] mmco: unref short failure
[h264 @ 0x556b3390c000] mmco: unref short failure
[h264 @ 0x55a03f268100] mmco: unref short failure
[h264 @ 0x55a03f268100] mmco: unref short failure
[h264 @ 0x562418747800] mmco: unref short failure
[h264 @ 0x556b35627100] mmco: unref short failure
[h264 @ 0x562417d4ef80] mmco: unref short failure
[h264 @ 0x562417d4ef80] mmco: unref short failure
[h264 @ 0x55a0334d2440] mmco: unref short failure
[h264 @ 0x55a0334d2440] mmco: unref short failure
 80%|████████  | 1556/1945 [8:28:29<6:12:02, 57.38s/it][h264 @ 0x559be97dc4c0] mmco: unref short failure
 80%|████████  | 1557/1945 [8:28:36<4:34:30, 42.45s/it][h264 @ 0x55a033100d40] mmco: unref short failure
[h264 @ 0x55a033100d40] mmco: unref short failure
 80%|████████  | 1558/1945 [8:28:44<3:25:24, 31.84s/it][h264 @ 0x55a03e159d00] mmco: unref short failure
[h264 @ 0x562416760b80] mmco: unref short failure
[h264 @ 0x562416760b80] mmco: unref short failure
 80%|████████  | 1559/1945 [8:28:50<2:36:34, 24.34s/it][h264 @ 0x55a0330aea40] mmco: unref short failure
[h264 @ 0x55a0330aea40] mmco: unref short failure
 80%|████████  | 1560/1945 [8:28:56<2:01:08, 18.88s/it][h264 @ 0x556b2ff138c0] mmco: unref short failure
[h264 @ 0x556b2ff138c0] mmco: unref short failure
 80%|████████  | 1561/1945 [8:29:04<1:39:08, 15.49s/it][h264 @ 0x559be8eb7340] mmco: unref short failure
[h264 @ 0x559be8eb7340] mmco: unref short failure
[h264 @ 0x556b2ec1f800] mmco: unref short failure
[h264 @ 0x556b2ec1f800] mmco: unref short failure
 80%|████████  | 1562/1945 [8:29:12<1:23:47, 13.13s/it] 80%|████████  | 1563/1945 [8:29:19<1:12:15, 11.35s/it][h264 @ 0x559bea6a0a40] mmco: unref short failure
[h264 @ 0x559bea6a0a40] mmco: unref short failure
[h264 @ 0x55a03331e280] mmco: unref short failure
[h264 @ 0x55a03331e280] mmco: unref short failure
[h264 @ 0x55a035ac3640] mmco: unref short failure
[h264 @ 0x55a035ac3640] mmco: unref short failure
[h264 @ 0x562417838f00] mmco: unref short failure
[h264 @ 0x562417838f00] mmco: unref short failure
[h264 @ 0x559becce7b80] mmco: unref short failure
[h264 @ 0x559becce7b80] mmco: unref short failure
[h264 @ 0x55a03dd9e140] mmco: unref short failure
[h264 @ 0x55a03dd9e140] mmco: unref short failure
[h264 @ 0x55a03dd9e140] mmco: unref short failure
[h264 @ 0x55a03dd9e140] mmco: unref short failure
[h264 @ 0x559beab86740] mmco: unref short failure
[h264 @ 0x556b35142d00] mmco: unref short failure
[h264 @ 0x556b35142d00] mmco: unref short failure
[h264 @ 0x556b2d3fc600] mmco: unref short failure
[h264 @ 0x559bf20f2ec0] mmco: unref short failure
[h264 @ 0x556b2ef63100] mmco: unref short failure
[h264 @ 0x556b2ef63100] mmco: unref short failure
[h264 @ 0x559beddef280] mmco: unref short failure
[h264 @ 0x559beaede7c0] mmco: unref short failure
[h264 @ 0x556b2f8bc800] mmco: unref short failure
[h264 @ 0x556b2f8bc800] mmco: unref short failure
[h264 @ 0x559be949e040] mmco: unref short failure
[h264 @ 0x559bedd82b00] mmco: unref short failure
[h264 @ 0x562423001880] mmco: unref short failure
 80%|████████  | 1564/1945 [8:30:38<3:20:55, 31.64s/it][h264 @ 0x562422f2ab40] mmco: unref short failure
 80%|████████  | 1565/1945 [8:30:46<2:35:37, 24.57s/it][h264 @ 0x559bef886140] mmco: unref short failure
[h264 @ 0x559bef886140] mmco: unref short failure
[h264 @ 0x55a03d188340] mmco: unref short failure
 81%|████████  | 1566/1945 [8:30:53<2:01:41, 19.27s/it][h264 @ 0x56241c3c74c0] mmco: unref short failure
[h264 @ 0x56241c3c74c0] mmco: unref short failure
[h264 @ 0x556b339adb00] mmco: unref short failure
[h264 @ 0x556b339adb00] mmco: unref short failure
[h264 @ 0x559bf44e4e00] mmco: unref short failure
[h264 @ 0x559bf44e4e00] mmco: unref short failure
 81%|████████  | 1567/1945 [8:30:59<1:37:28, 15.47s/it][h264 @ 0x55a03def04c0] mmco: unref short failure
[h264 @ 0x55a03def04c0] mmco: unref short failure
[h264 @ 0x559becf97ac0] mmco: unref short failure
 81%|████████  | 1568/1945 [8:31:07<1:21:24, 12.96s/it] 81%|████████  | 1569/1945 [8:31:14<1:10:32, 11.26s/it][h264 @ 0x556b30c0b040] mmco: unref short failure
[h264 @ 0x556b30c0b040] mmco: unref short failure
[h264 @ 0x556b30c0b040] mmco: unref short failure
[h264 @ 0x556b30c0b040] mmco: unref short failure
 81%|████████  | 1570/1945 [8:31:21<1:02:35, 10.01s/it][h264 @ 0x559bec344f00] mmco: unref short failure
[h264 @ 0x559bec344f00] mmco: unref short failure
 81%|████████  | 1571/1945 [8:31:28<56:35,  9.08s/it]  [h264 @ 0x562419700ac0] mmco: unref short failure
[h264 @ 0x562419700ac0] mmco: unref short failure
[h264 @ 0x559bed675540] mmco: unref short failure
[h264 @ 0x559bef9bcf40] mmco: unref short failure
[h264 @ 0x56241cef1f40] mmco: unref short failure
[h264 @ 0x556b377b04c0] mmco: unref short failure
[h264 @ 0x556b377b04c0] mmco: unref short failure
[h264 @ 0x556b377b04c0] mmco: unref short failure
[h264 @ 0x559bec312f40] mmco: unref short failure
[h264 @ 0x556b310fb900] mmco: unref short failure
[h264 @ 0x556b310fb900] mmco: unref short failure
[h264 @ 0x559bf2cd20c0] mmco: unref short failure
[h264 @ 0x55a038e3f5c0] mmco: unref short failure
[h264 @ 0x562417ffd500] mmco: unref short failure
[h264 @ 0x562417ffd500] mmco: unref short failure
[h264 @ 0x556b43e21100] mmco: unref short failure
[h264 @ 0x556b43e21100] mmco: unref short failure
[h264 @ 0x556b43e21100] mmco: unref short failure
[h264 @ 0x556b377ee580] mmco: unref short failure
[h264 @ 0x556b37732840] mmco: unref short failure
[h264 @ 0x556b37732840] mmco: unref short failure
[h264 @ 0x5624265d4400] mmco: unref short failure
[h264 @ 0x5624265d4400] mmco: unref short failure
[h264 @ 0x55a040722380] mmco: unref short failure
[h264 @ 0x55a040722380] mmco: unref short failure
[h264 @ 0x5624185a4780] mmco: unref short failure
[h264 @ 0x55a03d7c4580] mmco: unref short failure
[h264 @ 0x556b38a21c40] mmco: unref short failure
[h264 @ 0x556b38a21c40] mmco: unref short failure
[h264 @ 0x556b38a21c40] mmco: unref short failure
[h264 @ 0x556b2d84b500] mmco: unref short failure
[h264 @ 0x556b2d84b500] mmco: unref short failure
[h264 @ 0x559bf1329f80] mmco: unref short failure
[h264 @ 0x559bf1329f80] mmco: unref short failure
[h264 @ 0x56241ec52980] mmco: unref short failure
 81%|████████  | 1572/1945 [8:32:46<3:04:36, 29.70s/it][h264 @ 0x55a0330ea500] mmco: unref short failure
[h264 @ 0x55a0330ea500] mmco: unref short failure
[h264 @ 0x55a03b3ea580] mmco: unref short failure
[h264 @ 0x55a03b3ea580] mmco: unref short failure
[h264 @ 0x56241a1d0f80] mmco: unref short failure
[h264 @ 0x5624262ee4c0] mmco: unref short failure
[h264 @ 0x56241a1d0f80] mmco: unref short failure
[h264 @ 0x56241a1d0f80] mmco: unref short failure
[h264 @ 0x56241a1d0f80] mmco: unref short failure
[h264 @ 0x56241a1d0f80] mmco: unref short failure
 81%|████████  | 1573/1945 [8:32:53<2:21:55, 22.89s/it] 81%|████████  | 1574/1945 [8:32:59<1:51:41, 18.06s/it][h264 @ 0x55a040a57980] mmco: unref short failure
[h264 @ 0x55a040a57980] mmco: unref short failure
[h264 @ 0x55a040a57980] mmco: unref short failure
[h264 @ 0x55a040a57980] mmco: unref short failure
[h264 @ 0x55a040a57980] mmco: unref short failure
[h264 @ 0x55a040a57980] mmco: unref short failure
[h264 @ 0x56241cef31c0] mmco: unref short failure
[h264 @ 0x56241cef31c0] mmco: unref short failure
[h264 @ 0x55a039368800] mmco: unref short failure
[h264 @ 0x55a039368800] mmco: unref short failure
 81%|████████  | 1575/1945 [8:33:07<1:31:57, 14.91s/it] 81%|████████  | 1576/1945 [8:33:16<1:20:30, 13.09s/it][h264 @ 0x556b31a95840] mmco: unref short failure
[h264 @ 0x556b31a95840] mmco: unref short failure
 81%|████████  | 1577/1945 [8:33:25<1:13:16, 11.95s/it][h264 @ 0x559bec7f71c0] mmco: unref short failure
[h264 @ 0x55a03e8298c0] mmco: unref short failure
[h264 @ 0x55a03e8298c0] mmco: unref short failure
[h264 @ 0x56241eec1940] mmco: unref short failure
 81%|████████  | 1578/1945 [8:33:33<1:04:56, 10.62s/it][h264 @ 0x559bf9821a40] mmco: unref short failure
[h264 @ 0x559bf9821a40] mmco: unref short failure
 81%|████████  | 1579/1945 [8:33:39<57:26,  9.42s/it]  [h264 @ 0x55a0360e8c00] mmco: unref short failure
[h264 @ 0x55a0360e8c00] mmco: unref short failure
[h264 @ 0x55a0365854c0] mmco: unref short failure
[h264 @ 0x55a03edf1e80] mmco: unref short failure
[h264 @ 0x55a03edf1e80] mmco: unref short failure
[h264 @ 0x55a03edf1e80] mmco: unref short failure
[h264 @ 0x55a03edf1e80] mmco: unref short failure
[h264 @ 0x559bf97f6140] mmco: unref short failure
[h264 @ 0x559bf97f6140] mmco: unref short failure
[h264 @ 0x56241d465580] mmco: unref short failure
[h264 @ 0x56241d465580] mmco: unref short failure
[h264 @ 0x55a036277c00] mmco: unref short failure
[h264 @ 0x55a036277c00] mmco: unref short failure
[h264 @ 0x55a03d7c4380] mmco: unref short failure
[h264 @ 0x55a03d7c4380] mmco: unref short failure
[h264 @ 0x559bee9e3700] mmco: unref short failure
[h264 @ 0x56241d48d840] mmco: unref short failure
[h264 @ 0x55a040ed8640] mmco: unref short failure
[h264 @ 0x55a040ed8640] mmco: unref short failure
[h264 @ 0x562425265140] mmco: unref short failure
[h264 @ 0x562425265140] mmco: unref short failure
[h264 @ 0x562425265140] mmco: unref short failure
[h264 @ 0x562425265140] mmco: unref short failure
[h264 @ 0x55a043171ac0] mmco: unref short failure
[h264 @ 0x55a043171ac0] mmco: unref short failure
[h264 @ 0x556b41021500] mmco: unref short failure
[h264 @ 0x556b41021500] mmco: unref short failure
[h264 @ 0x562422314080] mmco: unref short failure
[h264 @ 0x56242749fbc0] mmco: unref short failure
srun: Job step aborted: Waiting up to 92 seconds for job step to finish.
slurmstepd: error: *** STEP 7459348.0 ON lrdn0028 CANCELLED AT 2024-09-10T01:39:53 ***
WARNING:torch.distributed.elastic.agent.server.api:Received 15 death signal, shutting down workers
slurmstepd: error: *** JOB 7459348 ON lrdn0028 CANCELLED AT 2024-09-10T01:39:53 ***
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 511244 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 511245 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 511246 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 511247 closing signal SIGTERM
