NODELIST=lrdn1006
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
31

02

DEVICE SET
DEVICE SET
DEVICE SET
DEVICE SET
09/16/2024 23:12:02 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 2
09/16/2024 23:12:02 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 1
09/16/2024 23:12:02 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 3
09/16/2024 23:12:02 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 0
09/16/2024 23:12:02 - INFO - torch.distributed.distributed_c10d -   Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
09/16/2024 23:12:02 - INFO - torch.distributed.distributed_c10d -   Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
09/16/2024 23:12:02 - INFO - torch.distributed.distributed_c10d -   Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
09/16/2024 23:12:02 - INFO - torch.distributed.distributed_c10d -   Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
09/16/2024 23:12:02 - INFO - __main__ -   ==================model_configs==================

09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_model_type : vast
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_itm_ratio : 0.1
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_frozen_vision : False
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_frozen_audio : False
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_checkpointing : True
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_max_caption_len : 40
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_max_omni_caption_len : 70
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_max_subtitle_len : 70
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_contra_dim : 512
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_inherit_keys : ['vision_encoder_type', 'audio_encoder_type', 'audio_melbins', 'audio_target_length']
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_frame_embedding_type : adaptive
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_vision_resolution : 224
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_vision_encoder_type : evaclip01_giant
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_audio_encoder_type : beats
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_audio_melbins : 64
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_audio_target_length : 1024
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_beam_size : 3
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_captioner_mode : False
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_generate_nums : 1
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_ret_bidirection_evaluation : False
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_itm_rerank_num : 50
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_evaluation_type : evaluation_mm
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_default : ./config/vast/default_model_cfg.json
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_max_vision_sample_num : 2
09/16/2024 23:12:02 - INFO - __main__ -   model_cfg_max_audio_sample_num : 1
09/16/2024 23:12:02 - INFO - __main__ -   ==================run_configs==================

09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_checkpoint : 
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_output_dir : ./output/vast/pretrain_vast/downstream/finetuneVolume256batchlossonlyvolume4Mod150k
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_gradient_accumulation_steps : 1
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_clip_lr : 5e-07
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_optim : adamw
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_learning_rate : 2e-05
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_betas : [0.9, 0.98]
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_weight_decay : 0.01
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_grad_norm : 2.0
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_warmup_ratio : 0.1
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_resume : False
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_seed : 50
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_fp16 : True
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_bf16 : False
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_zero_shot : False
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_scheduler : warmup_linear
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_new_lr : 0
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_new_params_name : []
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_valid_freq : 10
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_dataset_mix_type : random
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_remove_before_ckpt : True
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_first_eval : True
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_pretrain_dir : ./output/vast/pretrain_vast
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_num_train_steps : 0
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_save_best : True
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_pin_mem : True
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_vision_resolution : 224
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_use_ddp : False
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_mode : training
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_log_steps : 100
09/16/2024 23:12:02 - INFO - __main__ -   run_cfg_default : ./config/vast/default_run_cfg.json
09/16/2024 23:12:02 - INFO - __main__ -   ==================data_configs==================

09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_finetune_area_train_type : annoindexed
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_finetune_area_train_training : True
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_finetune_area_train_name : finetune_area
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_finetune_area_train_txt : ../vast27m/annotations150k.json
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_finetune_area_train_vision : ../vast27m/videos/
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_finetune_area_train_audio : ../vast27m/audios
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_finetune_area_train_vision_transforms : crop_flip
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_finetune_area_train_vision_format : video_rawvideo
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_finetune_area_train_vision_sample_num : 2
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_finetune_area_train_audio_sample_num : 1
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_finetune_area_train_task : ret%tv%ta
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_finetune_area_train_epoch : 5
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_finetune_area_train_n_workers : 8
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_finetune_area_train_batch_size : 256
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_type : annoindexed
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_training : False
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_name : msrvtt_ret
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_txt : datasets/annotations/msrvtt/descs_ret_test.json
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_vision : ../MSRVTT/video_test
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_vision_transforms : crop_flip
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_vision_format : video_rawvideo
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_audio : ../MSRVTT/audio_test
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_vision_sample_num : 8
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_audio_sample_num : 1
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_task : ret%tva
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_n_workers : 8
09/16/2024 23:12:02 - INFO - __main__ -   data_cfg_msrvtt_ret_val_batch_size : 64
wandb: Tracking run with wandb version 0.17.8
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
09/16/2024 23:12:06 - INFO - __main__ -   finetune_area Using clip mean and std.
09/16/2024 23:12:06 - INFO - __main__ -   finetune_area transforms crop_flip
ci sono 149153 labelsci sono 149153 labels

ci sono 149153 labelsci sono 149153 labels

09/16/2024 23:13:11 - INFO - __main__ -   Create Dataset finetune_area Success
09/16/2024 23:13:11 - INFO - __main__ -    loader ret%tv%ta--finetune_area , ratio 2910 , bs_pergpu 64, n_workers 8
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
09/16/2024 23:13:14 - INFO - __main__ -   current idx Y6ZqQLFmpGU.39 from finetune_area returns wrong image/video, use 76870 instead.
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
09/16/2024 23:13:15 - INFO - __main__ -   msrvtt_ret Using clip mean and std.
09/16/2024 23:13:15 - INFO - __main__ -   msrvtt_ret transforms crop_flip
ci sono 884 labelsci sono 884 labels
ci sono 884 labels
ci sono 884 labels

09/16/2024 23:13:15 - INFO - __main__ -   Create Dataset msrvtt_ret Success
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Please 'pip install xformers'
Please 'pip install xformers'Please 'pip install xformers'
Please 'pip install xformers'

Please 'pip install xformers'
Please 'pip install xformers'
Please 'pip install xformers'
Please 'pip install xformers'
Please 'pip install xformers'
Please 'pip install xformers'
Please 'pip install xformers'
Please 'pip install xformers'
09/16/2024 23:13:17 - INFO - root -   Loaded EVA01-CLIP-g-14 model config.
09/16/2024 23:13:17 - INFO - root -   Loaded EVA01-CLIP-g-14 model config.
09/16/2024 23:13:17 - INFO - root -   Loaded EVA01-CLIP-g-14 model config.
09/16/2024 23:13:17 - INFO - root -   Loaded EVA01-CLIP-g-14 model config.
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x56068c469380] mmco: unref short failure
[h264 @ 0x55b4f40a8c80] mmco: unref short failure
[h264 @ 0x55a25baec480] mmco: unref short failure
[h264 @ 0x55a25baec480] mmco: unref short failure
[h264 @ 0x55a25b803900] mmco: unref short failure
[h264 @ 0x55b4f4014200] mmco: unref short failure
[h264 @ 0x55b4f4014200] mmco: unref short failure
[h264 @ 0x55b4f4014200] mmco: unref short failure
[h264 @ 0x55b4f4014200] mmco: unref short failure
[h264 @ 0x55a25bd34fc0] mmco: unref short failure
[h264 @ 0x55e18313b600] mmco: unref short failure
[h264 @ 0x55a25bb65880] mmco: unref short failure
09/16/2024 23:14:10 - INFO - __main__ -   current idx d018IFLZh_8.4 from finetune_area returns wrong image/video, use 17473 instead.
[h264 @ 0x55e18367ea00] mmco: unref short failure
[h264 @ 0x56068c9164c0] mmco: unref short failure
[h264 @ 0x56068c9164c0] mmco: unref short failure
09/16/2024 23:14:13 - INFO - root -   Loading pretrained EVA01-CLIP-g-14 weights (./pretrained_weights/clip/EVA01_CLIP_g_14_psz14_s11B.pt).
09/16/2024 23:14:14 - INFO - root -   Loading pretrained EVA01-CLIP-g-14 weights (./pretrained_weights/clip/EVA01_CLIP_g_14_psz14_s11B.pt).
09/16/2024 23:14:17 - INFO - root -   Loading pretrained EVA01-CLIP-g-14 weights (./pretrained_weights/clip/EVA01_CLIP_g_14_psz14_s11B.pt).
[h264 @ 0x56068c061d00] mmco: unref short failure
[h264 @ 0x56068c061d00] mmco: unref short failure
[h264 @ 0x55a25c5be480] mmco: unref short failure
[h264 @ 0x55a25c5be480] mmco: unref short failure
09/16/2024 23:14:23 - INFO - __main__ -   current idx GH7kTACMcMI.49 from finetune_area returns wrong image/video, use 13682 instead.
09/16/2024 23:14:23 - INFO - root -   Loading pretrained EVA01-CLIP-g-14 weights (./pretrained_weights/clip/EVA01_CLIP_g_14_psz14_s11B.pt).
09/16/2024 23:14:28 - INFO - root -   incompatible_keys.missing_keys: []
09/16/2024 23:14:28 - INFO - root -   incompatible_keys.missing_keys: []
09/16/2024 23:14:28 - INFO - root -   incompatible_keys.missing_keys: []
09/16/2024 23:14:30 - INFO - model.audio_encoders.beats.beats -   BEATs Config: {'input_patch_size': 16, 'embed_dim': 512, 'conv_bias': False, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_wise_gradient_decay_ratio': 1.0, 'layer_norm_first': False, 'deep_norm': True, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True, 'finetuned_model': False, 'predictor_dropout': 0.1, 'predictor_class': 527}
09/16/2024 23:14:30 - INFO - model.audio_encoders.beats.beats -   BEATs Config: {'input_patch_size': 16, 'embed_dim': 512, 'conv_bias': False, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_wise_gradient_decay_ratio': 1.0, 'layer_norm_first': False, 'deep_norm': True, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True, 'finetuned_model': False, 'predictor_dropout': 0.1, 'predictor_class': 527}
09/16/2024 23:14:31 - INFO - model.audio_encoders.beats.beats -   BEATs Config: {'input_patch_size': 16, 'embed_dim': 512, 'conv_bias': False, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_wise_gradient_decay_ratio': 1.0, 'layer_norm_first': False, 'deep_norm': True, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True, 'finetuned_model': False, 'predictor_dropout': 0.1, 'predictor_class': 527}
09/16/2024 23:14:33 - INFO - root -   incompatible_keys.missing_keys: []
09/16/2024 23:14:34 - INFO - model.audio_encoders.beats.beats -   BEATs Config: {'input_patch_size': 16, 'embed_dim': 512, 'conv_bias': False, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_wise_gradient_decay_ratio': 1.0, 'layer_norm_first': False, 'deep_norm': True, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True, 'finetuned_model': False, 'predictor_dropout': 0.1, 'predictor_class': 527}
[h264 @ 0x55a25b62c380] mmco: unref short failure
09/16/2024 23:14:42 - WARNING - model.text_encoders.bert.bert -   If you want to use `BertForMaskedLM` make sure `config.is_decoder=False` for bi-directional self-attention.
09/16/2024 23:14:42 - WARNING - model.text_encoders.bert.bert -   If you want to use `BertForMaskedLM` make sure `config.is_decoder=False` for bi-directional self-attention.
[h264 @ 0x55b4f41fc080] mmco: unref short failure
[h264 @ 0x55b4f41fc080] mmco: unref short failure
[h264 @ 0x55b4f41fc080] mmco: unref short failure
09/16/2024 23:14:44 - WARNING - model.text_encoders.bert.bert -   If you want to use `BertForMaskedLM` make sure `config.is_decoder=False` for bi-directional self-attention.
[h264 @ 0x55e184fb60c0] mmco: unref short failure
[h264 @ 0x55e184fb60c0] mmco: unref short failure
[h264 @ 0x55e184fb60c0] mmco: unref short failure
[h264 @ 0x55e184fb60c0] mmco: unref short failure
09/16/2024 23:14:46 - WARNING - model.text_encoders.bert.bert -   If you want to use `BertForMaskedLM` make sure `config.is_decoder=False` for bi-directional self-attention.
[h264 @ 0x55e182da6e80] mmco: unref short failure
[h264 @ 0x55e186458d40] mmco: unref short failure
Some weights of BertForMaskedLM were not initialized from the model checkpoint at ./pretrained_weights/bert/bert-base-uncased and are newly initialized: ['encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'cls.predictions.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.self.value.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.key.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.query.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.key.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.6.crossattention.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertForMaskedLM were not initialized from the model checkpoint at ./pretrained_weights/bert/bert-base-uncased and are newly initialized: ['encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.query.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.key.weight', 'cls.predictions.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.8.crossattention.self.key.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.query.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertForMaskedLM were not initialized from the model checkpoint at ./pretrained_weights/bert/bert-base-uncased and are newly initialized: ['encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.value.weight', 'cls.predictions.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.query.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.7.crossattention.self.query.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.value.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.6.crossattention.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertForMaskedLM were not initialized from the model checkpoint at ./pretrained_weights/bert/bert-base-uncased and are newly initialized: ['encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.value.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.6.crossattention.output.dense.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.query.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.7.crossattention.self.query.bias', 'cls.predictions.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.9.crossattention.self.key.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[h264 @ 0x55a25caea8c0] mmco: unref short failure
[h264 @ 0x55a25c7b4640] mmco: unref short failure
[h264 @ 0x55a25c7b4640] mmco: unref short failure
09/16/2024 23:15:13 - INFO - __main__ -   load_from_pretrained: ./output/vast/pretrain_vast/ckpt/model_step_204994.pt
09/16/2024 23:15:13 - INFO - __main__ -   Load from pretrained dir ./output/vast/pretrain_vast
09/16/2024 23:15:18 - INFO - __main__ -   Unexpected keys ['vision_encoder.text.logit_scale']
09/16/2024 23:15:18 - INFO - __main__ -   missing_keys  ['vision_encoder.logit_scale']
[h264 @ 0x55a25dfe1200] mmco: unref short failure
[h264 @ 0x55e18a609300] mmco: unref short failure
[h264 @ 0x55e18a609300] mmco: unref short failure
09/16/2024 23:15:25 - INFO - __main__ -   ==================learning_rate_settings==================

09/16/2024 23:15:25 - INFO - __main__ -     basic_lr : 2e-05
09/16/2024 23:15:25 - INFO - __main__ -     clip_lr_visual : 5e-07
09/16/2024 23:15:25 - INFO - __main__ -     clip_lr_visual_len : 245
09/16/2024 23:15:25 - INFO - __main__ -     new_lr : 0
09/16/2024 23:15:25 - INFO - __main__ -     new_params_name: []
09/16/2024 23:15:25 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/16/2024 23:15:25 - INFO - __main__ -   start running ret%tva validation...
[h264 @ 0x55b4f4ed2e00] mmco: unref short failure
[h264 @ 0x55b4f4ed2e00] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a25c7b5400] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a25e50f5c0] mmco: unref short failure
[h264 @ 0x55a25e50f5c0] mmco: unref short failure
[h264 @ 0x55b4f8513480] mmco: unref short failure
[h264 @ 0x55b4f8513480] mmco: unref short failure
[h264 @ 0x55b4f3be9a40] mmco: unref short failure
[h264 @ 0x55a25c000480] mmco: unref short failure
[h264 @ 0x56068bfd7c00] mmco: unref short failure
[h264 @ 0x55a261cc9880] mmco: unref short failure
[h264 @ 0x55a261cc9880] mmco: unref short failure
[h264 @ 0x55e1837ade00] mmco: unref short failure
[h264 @ 0x56068d94f1c0] mmco: unref short failure
[h264 @ 0x56068d94f1c0] mmco: unref short failure
09/16/2024 23:15:54 - INFO - __main__ -   current idx b1Hz-jQ4IM0.8 from finetune_area returns wrong image/video, use 35266 instead.
[h264 @ 0x55a25ccb8640] mmco: unref short failure
09/16/2024 23:15:56 - INFO - __main__ -   current idx BYYoxWKlR3E.11 from finetune_area returns wrong image/video, use 54238 instead.
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e1873c9380] mmco: unref short failure
[h264 @ 0x55e1873c9380] mmco: unref short failure
[h264 @ 0x55b4f3bbc880] mmco: unref short failure
[h264 @ 0x55b4f3bbc880] mmco: unref short failure
[h264 @ 0x56068ca9f840] mmco: unref short failure
[h264 @ 0x55a2615ce940] mmco: unref short failure
[h264 @ 0x55e18565b280] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
[h264 @ 0x55e18bb2e700] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
[h264 @ 0x55e18bb2e700] mmco: unref short failure
[h264 @ 0x56068c93f680] mmco: unref short failure
[h264 @ 0x56068c93f680] mmco: unref short failure
[h264 @ 0x55b4f8d8d440] mmco: unref short failure
[h264 @ 0x55b4f8d8d440] mmco: unref short failure
[h264 @ 0x55b4f3be4780] mmco: unref short failure
[h264 @ 0x55b4f5b42ac0] mmco: unref short failure
[h264 @ 0x55b4f5b42ac0] mmco: unref short failure
[h264 @ 0x55b4f5b42ac0] mmco: unref short failure
[h264 @ 0x55e185d7f200] mmco: unref short failure
[h264 @ 0x55b4ff77d5c0] mmco: unref short failure
[h264 @ 0x55b4f4ec6fc0] mmco: unref short failure
09/16/2024 23:17:43 - INFO - __main__ -   current idx bVHcVa51-ds.15 from finetune_area returns wrong image/video, use 87000 instead.
[h264 @ 0x55e182e7fdc0] mmco: unref short failure
[h264 @ 0x55e182e7fdc0] mmco: unref short failure
[h264 @ 0x55b4f91cba00] mmco: unref short failure
[h264 @ 0x55b4f91cba00] mmco: unref short failure
[h264 @ 0x56069751cc40] mmco: unref short failure
[h264 @ 0x56068c9d3f00] mmco: unref short failure
[h264 @ 0x55a25e9a5a80] mmco: unref short failure
[h264 @ 0x55a25e9a5a80] mmco: unref short failure
[h264 @ 0x55a25e9a5a80] mmco: unref short failure
[h264 @ 0x55a25e9a5a80] mmco: unref short failure
[h264 @ 0x55a25e9a5a80] mmco: unref short failure
[h264 @ 0x55a25e9a5a80] mmco: unref short failure
09/16/2024 23:18:01 - INFO - __main__ -   current idx 1-hr71oylIM.38 from finetune_area returns wrong image/video, use 139748 instead.
[h264 @ 0x55a25c02a200] mmco: unref short failure
[h264 @ 0x55a25c02a200] mmco: unref short failure
[h264 @ 0x55a25c02a200] mmco: unref short failure
[h264 @ 0x55a25c02a200] mmco: unref short failure
[h264 @ 0x55a25c02a200] mmco: unref short failure
[h264 @ 0x55a25c02a200] mmco: unref short failure
[h264 @ 0x560695a08380] mmco: unref short failure
  0%|          | 0/221 [00:00<?, ?it/s]  0%|          | 1/221 [00:00<00:27,  8.09it/s]  1%|          | 2/221 [00:00<00:27,  8.03it/s]  1%|▏         | 3/221 [00:00<00:36,  5.95it/s]  2%|▏         | 4/221 [00:00<00:30,  7.06it/s]  3%|▎         | 6/221 [00:00<00:24,  8.76it/s]  3%|▎         | 7/221 [00:00<00:27,  7.67it/s]  4%|▎         | 8/221 [00:01<00:26,  7.93it/s]  4%|▍         | 9/221 [00:01<00:27,  7.73it/s]  5%|▍         | 10/221 [00:01<00:28,  7.39it/s]  5%|▍         | 11/221 [00:01<00:27,  7.75it/s]  5%|▌         | 12/221 [00:03<02:50,  1.23it/s]  6%|▌         | 13/221 [00:03<02:05,  1.66it/s]  6%|▋         | 14/221 [00:04<01:34,  2.18it/s]  7%|▋         | 16/221 [00:04<00:59,  3.42it/s]  8%|▊         | 17/221 [00:04<00:57,  3.55it/s]  8%|▊         | 18/221 [00:04<00:50,  4.05it/s]  9%|▊         | 19/221 [00:04<00:43,  4.69it/s]  9%|▉         | 20/221 [00:04<00:37,  5.34it/s] 10%|▉         | 21/221 [00:05<00:35,  5.59it/s][h264 @ 0x560697863300] mmco: unref short failure
[h264 @ 0x560697863300] mmco: unref short failure
[h264 @ 0x560697863300] mmco: unref short failure
[h264 @ 0x560697863300] mmco: unref short failure
 10%|▉         | 22/221 [00:09<04:51,  1.47s/it] 11%|█         | 24/221 [00:09<02:44,  1.20it/s] 12%|█▏        | 26/221 [00:10<01:47,  1.81it/s] 13%|█▎        | 28/221 [00:10<01:15,  2.55it/s] 13%|█▎        | 29/221 [00:10<01:05,  2.92it/s] 14%|█▎        | 30/221 [00:10<00:56,  3.39it/s] 14%|█▍        | 31/221 [00:10<00:48,  3.92it/s] 14%|█▍        | 32/221 [00:10<00:40,  4.63it/s][h264 @ 0x55b4f4579480] mmco: unref short failure
[h264 @ 0x55b4f4579480] mmco: unref short failure
[h264 @ 0x55b4f4579480] mmco: unref short failure
[h264 @ 0x55b4f4579480] mmco: unref short failure
 15%|█▍        | 33/221 [00:11<00:43,  4.29it/s][h264 @ 0x55b4f4579480] mmco: unref short failure
[h264 @ 0x55b4f4579480] mmco: unref short failure
[h264 @ 0x55b4f4579480] mmco: unref short failure
[h264 @ 0x55b4f4579480] mmco: unref short failure
[h264 @ 0x55b4f4579480] mmco: unref short failure
[h264 @ 0x55b4f4579480] mmco: unref short failure
 15%|█▌        | 34/221 [00:11<00:36,  5.08it/s] 16%|█▌        | 35/221 [00:11<00:33,  5.57it/s] 16%|█▋        | 36/221 [00:11<00:30,  5.99it/s] 17%|█▋        | 37/221 [00:11<00:30,  6.03it/s] 17%|█▋        | 38/221 [00:11<00:28,  6.52it/s] 18%|█▊        | 39/221 [00:11<00:25,  7.11it/s] 18%|█▊        | 40/221 [00:12<00:24,  7.52it/s] 19%|█▊        | 41/221 [00:12<00:22,  7.93it/s] 19%|█▉        | 42/221 [00:12<00:21,  8.19it/s] 19%|█▉        | 43/221 [00:12<00:21,  8.34it/s] 20%|█▉        | 44/221 [00:12<00:21,  8.39it/s] 20%|██        | 45/221 [00:12<00:41,  4.29it/s] 21%|██        | 46/221 [00:13<00:37,  4.66it/s][h264 @ 0x55a25b623840] mmco: unref short failure
[h264 @ 0x55a25b623840] mmco: unref short failure
 21%|██▏       | 47/221 [00:17<04:34,  1.58s/it] 22%|██▏       | 48/221 [00:18<03:16,  1.14s/it] 22%|██▏       | 49/221 [00:18<02:22,  1.21it/s] 23%|██▎       | 50/221 [00:18<01:44,  1.63it/s] 24%|██▎       | 52/221 [00:18<01:02,  2.71it/s] 24%|██▍       | 53/221 [00:18<00:52,  3.23it/s] 24%|██▍       | 54/221 [00:22<03:31,  1.27s/it] 25%|██▍       | 55/221 [00:24<03:42,  1.34s/it] 26%|██▌       | 57/221 [00:24<02:11,  1.25it/s] 27%|██▋       | 59/221 [00:24<01:25,  1.91it/s] 27%|██▋       | 60/221 [00:24<01:11,  2.24it/s] 28%|██▊       | 61/221 [00:24<01:01,  2.59it/s] 28%|██▊       | 62/221 [00:24<00:50,  3.15it/s] 29%|██▉       | 64/221 [00:25<00:35,  4.48it/s]09/16/2024 23:18:37 - INFO - __main__ -   current idx -c6ksbh044A.74 from finetune_area returns wrong image/video, use 106497 instead.
 30%|██▉       | 66/221 [00:30<02:46,  1.08s/it] 30%|███       | 67/221 [00:30<02:19,  1.11it/s] 31%|███       | 68/221 [00:30<01:50,  1.38it/s] 31%|███       | 69/221 [00:30<01:29,  1.70it/s] 32%|███▏      | 71/221 [00:30<01:02,  2.41it/s] 33%|███▎      | 72/221 [00:31<00:53,  2.78it/s] 33%|███▎      | 73/221 [00:31<00:48,  3.07it/s] 33%|███▎      | 74/221 [00:31<00:45,  3.23it/s] 34%|███▍      | 75/221 [00:31<00:38,  3.79it/s] 34%|███▍      | 76/221 [00:31<00:33,  4.38it/s] 35%|███▍      | 77/221 [00:32<00:28,  5.14it/s] 35%|███▌      | 78/221 [00:32<00:24,  5.77it/s] 36%|███▌      | 79/221 [00:32<00:30,  4.68it/s] 36%|███▌      | 80/221 [00:32<00:25,  5.51it/s] 37%|███▋      | 81/221 [00:32<00:22,  6.22it/s] 37%|███▋      | 82/221 [00:32<00:24,  5.62it/s] 38%|███▊      | 83/221 [00:32<00:22,  6.24it/s] 38%|███▊      | 85/221 [00:33<00:17,  7.86it/s] 39%|███▉      | 86/221 [00:33<00:16,  8.01it/s] 39%|███▉      | 87/221 [00:33<00:15,  8.45it/s] 40%|███▉      | 88/221 [00:33<00:19,  6.85it/s] 40%|████      | 89/221 [00:33<00:25,  5.19it/s] 41%|████      | 90/221 [00:34<00:23,  5.63it/s] 42%|████▏     | 92/221 [00:34<00:17,  7.43it/s] 42%|████▏     | 93/221 [00:34<00:25,  5.09it/s] 43%|████▎     | 95/221 [00:34<00:20,  6.28it/s] 43%|████▎     | 96/221 [00:35<00:21,  5.82it/s] 44%|████▍     | 98/221 [00:35<00:18,  6.48it/s] 45%|████▍     | 99/221 [00:35<00:20,  5.82it/s] 45%|████▌     | 100/221 [00:35<00:21,  5.66it/s] 46%|████▌     | 102/221 [00:35<00:17,  6.88it/s] 47%|████▋     | 104/221 [00:36<00:14,  7.99it/s] 48%|████▊     | 106/221 [00:36<00:20,  5.49it/s] 48%|████▊     | 107/221 [00:36<00:19,  5.93it/s] 49%|████▉     | 108/221 [00:36<00:17,  6.51it/s] 50%|████▉     | 110/221 [00:37<00:14,  7.57it/s] 50%|█████     | 111/221 [00:37<00:17,  6.21it/s] 51%|█████     | 112/221 [00:37<00:19,  5.70it/s] 52%|█████▏    | 114/221 [00:37<00:15,  7.08it/s] 52%|█████▏    | 115/221 [00:37<00:14,  7.50it/s][h264 @ 0x55a25b595d00] mmco: unref short failure
[h264 @ 0x55a25b595d00] mmco: unref short failure
[h264 @ 0x55b4f2d2a300] mmco: unref short failure
[h264 @ 0x55b4f2d2a300] mmco: unref short failure
 52%|█████▏    | 116/221 [00:42<02:20,  1.34s/it] 53%|█████▎    | 117/221 [00:43<01:52,  1.08s/it] 53%|█████▎    | 118/221 [00:43<01:24,  1.21it/s] 54%|█████▍    | 119/221 [00:43<01:04,  1.59it/s] 54%|█████▍    | 120/221 [00:43<00:48,  2.08it/s] 55%|█████▌    | 122/221 [00:43<00:30,  3.24it/s] 56%|█████▌    | 123/221 [00:44<00:27,  3.59it/s] 56%|█████▌    | 124/221 [00:44<00:24,  4.04it/s] 57%|█████▋    | 125/221 [00:44<00:26,  3.67it/s] 57%|█████▋    | 126/221 [00:45<00:31,  3.06it/s] 57%|█████▋    | 127/221 [00:45<00:30,  3.12it/s] 58%|█████▊    | 128/221 [00:45<00:32,  2.90it/s] 58%|█████▊    | 129/221 [00:45<00:25,  3.62it/s] 59%|█████▉    | 131/221 [00:46<00:17,  5.18it/s] 60%|█████▉    | 132/221 [00:46<00:15,  5.62it/s] 60%|██████    | 133/221 [00:46<00:17,  5.14it/s] 61%|██████    | 134/221 [00:46<00:18,  4.69it/s] 61%|██████    | 135/221 [00:48<00:48,  1.79it/s][h264 @ 0x55e18c5b3400] mmco: unref short failure
 62%|██████▏   | 136/221 [00:48<00:44,  1.89it/s] 62%|██████▏   | 137/221 [00:50<01:29,  1.07s/it] 62%|██████▏   | 138/221 [00:51<01:11,  1.16it/s] 63%|██████▎   | 139/221 [00:51<01:01,  1.33it/s] 63%|██████▎   | 140/221 [00:52<00:52,  1.55it/s] 64%|██████▍   | 141/221 [00:52<00:43,  1.83it/s] 64%|██████▍   | 142/221 [00:52<00:35,  2.22it/s] 65%|██████▍   | 143/221 [00:52<00:28,  2.77it/s] 65%|██████▌   | 144/221 [00:53<00:23,  3.29it/s] 66%|██████▌   | 146/221 [00:53<00:15,  4.77it/s] 67%|██████▋   | 147/221 [00:53<00:13,  5.39it/s] 67%|██████▋   | 148/221 [00:53<00:15,  4.81it/s] 67%|██████▋   | 149/221 [00:53<00:13,  5.33it/s] 68%|██████▊   | 150/221 [00:54<00:20,  3.45it/s] 68%|██████▊   | 151/221 [00:54<00:20,  3.40it/s] 69%|██████▉   | 152/221 [00:54<00:16,  4.09it/s] 69%|██████▉   | 153/221 [00:54<00:14,  4.82it/s] 70%|██████▉   | 154/221 [00:54<00:11,  5.59it/s] 70%|███████   | 155/221 [00:55<00:10,  6.04it/s][h264 @ 0x55e183e5cf40] mmco: unref short failure
[h264 @ 0x55b4f4645a40] mmco: unref short failure
 71%|███████   | 156/221 [01:00<01:45,  1.62s/it] 71%|███████   | 157/221 [01:00<01:16,  1.19s/it] 72%|███████▏  | 159/221 [01:00<00:44,  1.39it/s] 72%|███████▏  | 160/221 [01:00<00:34,  1.75it/s] 73%|███████▎  | 162/221 [01:01<00:23,  2.51it/s] 74%|███████▍  | 163/221 [01:01<00:20,  2.80it/s] 74%|███████▍  | 164/221 [01:01<00:16,  3.38it/s][h264 @ 0x56068ef90600] mmco: unref short failure
 75%|███████▍  | 165/221 [01:06<01:26,  1.55s/it] 75%|███████▌  | 166/221 [01:06<01:05,  1.19s/it][h264 @ 0x55b4f478dc00] mmco: unref short failure
[h264 @ 0x55b4f478dc00] mmco: unref short failure
[h264 @ 0x55e183183940] mmco: unref short failure
 76%|███████▌  | 167/221 [01:09<01:23,  1.55s/it] 76%|███████▌  | 168/221 [01:09<01:00,  1.14s/it] 76%|███████▋  | 169/221 [01:09<00:47,  1.09it/s][h264 @ 0x55b50073eac0] mmco: unref short failure
[h264 @ 0x55b50073eac0] mmco: unref short failure
 77%|███████▋  | 170/221 [01:09<00:35,  1.43it/s] 78%|███████▊  | 172/221 [01:09<00:19,  2.48it/s] 79%|███████▊  | 174/221 [01:10<00:13,  3.60it/s] 80%|███████▉  | 176/221 [01:10<00:10,  4.23it/s] 80%|████████  | 177/221 [01:10<00:09,  4.66it/s] 81%|████████  | 178/221 [01:11<00:17,  2.46it/s] 82%|████████▏ | 181/221 [01:11<00:09,  4.43it/s] 83%|████████▎ | 183/221 [01:11<00:06,  5.51it/s] 84%|████████▍ | 186/221 [01:12<00:04,  8.00it/s] 85%|████████▌ | 188/221 [01:12<00:03,  8.82it/s] 86%|████████▌ | 190/221 [01:12<00:03,  9.69it/s] 88%|████████▊ | 194/221 [01:12<00:01, 13.65it/s] 89%|████████▉ | 197/221 [01:12<00:01, 16.32it/s] 90%|█████████ | 200/221 [01:12<00:01, 16.36it/s] 91%|█████████▏| 202/221 [01:13<00:01, 15.65it/s] 93%|█████████▎| 205/221 [01:13<00:01, 14.33it/s] 94%|█████████▍| 208/221 [01:13<00:00, 15.85it/s] 95%|█████████▌| 210/221 [01:13<00:00, 16.19it/s] 96%|█████████▌| 212/221 [01:13<00:00, 14.77it/s] 97%|█████████▋| 214/221 [01:14<00:00,  9.15it/s] 98%|█████████▊| 216/221 [01:16<00:01,  2.89it/s] 99%|█████████▊| 218/221 [01:16<00:00,  3.78it/s]100%|█████████▉| 220/221 [01:21<00:00,  1.09it/s]100%|█████████▉| 220/221 [01:21<00:00,  2.71it/s]
  0%|          | 0/221 [00:00<?, ?it/s]  0%|          | 1/221 [00:00<01:04,  3.42it/s]  1%|          | 2/221 [00:00<01:03,  3.42it/s]  1%|▏         | 3/221 [00:00<01:03,  3.42it/s]  2%|▏         | 4/221 [00:01<01:03,  3.42it/s]  2%|▏         | 5/221 [00:01<01:03,  3.42it/s]  3%|▎         | 6/221 [00:01<01:02,  3.42it/s]  3%|▎         | 7/221 [00:02<01:02,  3.42it/s]  4%|▎         | 8/221 [00:02<01:02,  3.42it/s]  4%|▍         | 9/221 [00:02<01:01,  3.42it/s]  5%|▍         | 10/221 [00:02<01:01,  3.42it/s]  5%|▍         | 11/221 [00:03<01:01,  3.42it/s]  5%|▌         | 12/221 [00:03<01:01,  3.42it/s]  6%|▌         | 13/221 [00:03<01:00,  3.42it/s]  6%|▋         | 14/221 [00:04<01:00,  3.42it/s]  7%|▋         | 15/221 [00:04<01:00,  3.42it/s]  7%|▋         | 16/221 [00:04<00:59,  3.42it/s]  8%|▊         | 17/221 [00:04<00:59,  3.42it/s]  8%|▊         | 18/221 [00:05<00:59,  3.42it/s]  9%|▊         | 19/221 [00:05<00:59,  3.42it/s]  9%|▉         | 20/221 [00:05<00:58,  3.42it/s] 10%|▉         | 21/221 [00:06<00:58,  3.42it/s] 10%|▉         | 22/221 [00:06<00:58,  3.42it/s] 10%|█         | 23/221 [00:06<00:57,  3.42it/s] 11%|█         | 24/221 [00:07<00:57,  3.42it/s] 11%|█▏        | 25/221 [00:07<00:57,  3.42it/s] 12%|█▏        | 26/221 [00:07<00:56,  3.42it/s] 12%|█▏        | 27/221 [00:07<00:56,  3.42it/s] 13%|█▎        | 28/221 [00:08<00:56,  3.42it/s] 13%|█▎        | 29/221 [00:08<00:56,  3.42it/s] 14%|█▎        | 30/221 [00:08<00:55,  3.42it/s] 14%|█▍        | 31/221 [00:09<00:55,  3.42it/s] 14%|█▍        | 32/221 [00:09<00:55,  3.42it/s] 15%|█▍        | 33/221 [00:09<00:54,  3.42it/s] 15%|█▌        | 34/221 [00:09<00:54,  3.42it/s] 16%|█▌        | 35/221 [00:10<00:54,  3.42it/s] 16%|█▋        | 36/221 [00:10<00:54,  3.42it/s] 17%|█▋        | 37/221 [00:10<00:53,  3.42it/s] 17%|█▋        | 38/221 [00:11<00:53,  3.42it/s] 18%|█▊        | 39/221 [00:11<00:53,  3.42it/s] 18%|█▊        | 40/221 [00:11<00:52,  3.42it/s] 19%|█▊        | 41/221 [00:11<00:52,  3.42it/s] 19%|█▉        | 42/221 [00:12<00:52,  3.42it/s] 19%|█▉        | 43/221 [00:12<00:51,  3.42it/s] 20%|█▉        | 44/221 [00:12<00:51,  3.42it/s] 20%|██        | 45/221 [00:13<00:51,  3.42it/s] 21%|██        | 46/221 [00:13<00:51,  3.42it/s] 21%|██▏       | 47/221 [00:13<00:50,  3.42it/s] 22%|██▏       | 48/221 [00:14<00:50,  3.42it/s] 22%|██▏       | 49/221 [00:14<00:50,  3.42it/s] 23%|██▎       | 50/221 [00:14<00:49,  3.42it/s] 23%|██▎       | 51/221 [00:14<00:49,  3.42it/s] 24%|██▎       | 52/221 [00:15<00:49,  3.42it/s] 24%|██▍       | 53/221 [00:15<00:49,  3.42it/s] 24%|██▍       | 54/221 [00:15<00:48,  3.42it/s] 25%|██▍       | 55/221 [00:16<00:48,  3.42it/s] 25%|██▌       | 56/221 [00:16<00:48,  3.42it/s] 26%|██▌       | 57/221 [00:16<00:47,  3.42it/s] 26%|██▌       | 58/221 [00:16<00:47,  3.42it/s] 27%|██▋       | 59/221 [00:17<00:47,  3.42it/s] 27%|██▋       | 60/221 [00:17<00:47,  3.42it/s] 28%|██▊       | 61/221 [00:17<00:46,  3.42it/s] 28%|██▊       | 62/221 [00:18<00:46,  3.42it/s] 29%|██▊       | 63/221 [00:18<00:46,  3.42it/s] 29%|██▉       | 64/221 [00:18<00:45,  3.42it/s] 29%|██▉       | 65/221 [00:18<00:45,  3.42it/s] 30%|██▉       | 66/221 [00:19<00:45,  3.42it/s] 30%|███       | 67/221 [00:19<00:44,  3.42it/s] 31%|███       | 68/221 [00:19<00:44,  3.42it/s] 31%|███       | 69/221 [00:20<00:44,  3.42it/s] 32%|███▏      | 70/221 [00:20<00:44,  3.42it/s] 32%|███▏      | 71/221 [00:20<00:43,  3.42it/s] 33%|███▎      | 72/221 [00:21<00:43,  3.42it/s] 33%|███▎      | 73/221 [00:21<00:43,  3.42it/s] 33%|███▎      | 74/221 [00:21<00:42,  3.42it/s] 34%|███▍      | 75/221 [00:21<00:42,  3.42it/s] 34%|███▍      | 76/221 [00:22<00:42,  3.42it/s] 35%|███▍      | 77/221 [00:22<00:42,  3.42it/s] 35%|███▌      | 78/221 [00:22<00:41,  3.42it/s] 36%|███▌      | 79/221 [00:23<00:41,  3.42it/s] 36%|███▌      | 80/221 [00:23<00:41,  3.42it/s] 37%|███▋      | 81/221 [00:23<00:40,  3.42it/s] 37%|███▋      | 82/221 [00:23<00:40,  3.42it/s] 38%|███▊      | 83/221 [00:24<00:40,  3.42it/s] 38%|███▊      | 84/221 [00:24<00:40,  3.42it/s] 38%|███▊      | 85/221 [00:24<00:39,  3.42it/s] 39%|███▉      | 86/221 [00:25<00:39,  3.42it/s] 39%|███▉      | 87/221 [00:25<00:39,  3.42it/s] 40%|███▉      | 88/221 [00:25<00:38,  3.42it/s] 40%|████      | 89/221 [00:25<00:38,  3.42it/s] 41%|████      | 90/221 [00:26<00:38,  3.42it/s] 41%|████      | 91/221 [00:26<00:37,  3.42it/s] 42%|████▏     | 92/221 [00:26<00:37,  3.42it/s] 42%|████▏     | 93/221 [00:27<00:37,  3.42it/s] 43%|████▎     | 94/221 [00:27<00:37,  3.42it/s] 43%|████▎     | 95/221 [00:27<00:36,  3.42it/s] 43%|████▎     | 96/221 [00:28<00:36,  3.42it/s] 44%|████▍     | 97/221 [00:28<00:36,  3.42it/s] 44%|████▍     | 98/221 [00:28<00:35,  3.42it/s] 45%|████▍     | 99/221 [00:28<00:35,  3.42it/s] 45%|████▌     | 100/221 [00:29<00:35,  3.42it/s] 46%|████▌     | 101/221 [00:29<00:35,  3.42it/s] 46%|████▌     | 102/221 [00:29<00:34,  3.42it/s] 47%|████▋     | 103/221 [00:30<00:34,  3.42it/s] 47%|████▋     | 104/221 [00:30<00:34,  3.42it/s] 48%|████▊     | 105/221 [00:30<00:33,  3.42it/s] 48%|████▊     | 106/221 [00:30<00:33,  3.42it/s] 48%|████▊     | 107/221 [00:31<00:33,  3.42it/s] 49%|████▉     | 108/221 [00:31<00:33,  3.42it/s] 49%|████▉     | 109/221 [00:31<00:32,  3.42it/s] 50%|████▉     | 110/221 [00:32<00:32,  3.42it/s] 50%|█████     | 111/221 [00:32<00:32,  3.42it/s] 51%|█████     | 112/221 [00:32<00:31,  3.42it/s] 51%|█████     | 113/221 [00:33<00:31,  3.42it/s] 52%|█████▏    | 114/221 [00:33<00:31,  3.42it/s] 52%|█████▏    | 115/221 [00:33<00:30,  3.42it/s] 52%|█████▏    | 116/221 [00:33<00:30,  3.42it/s] 53%|█████▎    | 117/221 [00:34<00:30,  3.42it/s] 53%|█████▎    | 118/221 [00:34<00:30,  3.42it/s] 54%|█████▍    | 119/221 [00:34<00:29,  3.42it/s] 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s] 55%|█████▍    | 121/221 [00:35<00:29,  3.42it/s] 55%|█████▌    | 122/221 [00:35<00:28,  3.42it/s] 56%|█████▌    | 123/221 [00:35<00:28,  3.42it/s] 56%|█████▌    | 124/221 [00:36<00:28,  3.42it/s] 57%|█████▋    | 125/221 [00:36<00:28,  3.42it/s] 57%|█████▋    | 126/221 [00:36<00:27,  3.42it/s] 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s] 58%|█████▊    | 128/221 [00:37<00:27,  3.42it/s] 58%|█████▊    | 129/221 [00:37<00:26,  3.42it/s] 59%|█████▉    | 130/221 [00:37<00:26,  3.42it/s] 59%|█████▉    | 131/221 [00:38<00:26,  3.42it/s] 60%|█████▉    | 132/221 [00:38<00:25,  3.42it/s] 60%|██████    | 133/221 [00:38<00:25,  3.42it/s] 61%|██████    | 134/221 [00:39<00:25,  3.42it/s] 61%|██████    | 135/221 [00:39<00:25,  3.42it/s] 62%|██████▏   | 136/221 [00:39<00:24,  3.42it/s] 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s] 62%|██████▏   | 138/221 [00:40<00:24,  3.42it/s] 63%|██████▎   | 139/221 [00:40<00:23,  3.42it/s] 63%|██████▎   | 140/221 [00:40<00:23,  3.43it/s] 64%|██████▍   | 141/221 [00:41<00:23,  3.42it/s] 64%|██████▍   | 142/221 [00:41<00:23,  3.42it/s] 65%|██████▍   | 143/221 [00:41<00:22,  3.42it/s] 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s] 66%|██████▌   | 145/221 [00:42<00:22,  3.42it/s] 66%|██████▌   | 146/221 [00:42<00:21,  3.42it/s] 67%|██████▋   | 147/221 [00:42<00:21,  3.42it/s] 67%|██████▋   | 148/221 [00:43<00:21,  3.42it/s] 67%|██████▋   | 149/221 [00:43<00:21,  3.42it/s] 68%|██████▊   | 150/221 [00:43<00:20,  3.42it/s] 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s] 69%|██████▉   | 152/221 [00:44<00:20,  3.42it/s] 69%|██████▉   | 153/221 [00:44<00:19,  3.42it/s] 70%|██████▉   | 154/221 [00:44<00:19,  3.42it/s] 70%|███████   | 155/221 [00:45<00:19,  3.42it/s] 71%|███████   | 156/221 [00:45<00:18,  3.42it/s] 71%|███████   | 157/221 [00:45<00:18,  3.42it/s] 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s] 72%|███████▏  | 159/221 [00:46<00:18,  3.42it/s] 72%|███████▏  | 160/221 [00:46<00:17,  3.42it/s] 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s] 73%|███████▎  | 162/221 [00:47<00:17,  3.42it/s] 74%|███████▍  | 163/221 [00:47<00:16,  3.42it/s] 74%|███████▍  | 164/221 [00:47<00:16,  3.42it/s] 75%|███████▍  | 165/221 [00:48<00:16,  3.42it/s] 75%|███████▌  | 166/221 [00:48<00:16,  3.42it/s] 76%|███████▌  | 167/221 [00:48<00:15,  3.42it/s] 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s] 76%|███████▋  | 169/221 [00:49<00:15,  3.42it/s] 77%|███████▋  | 170/221 [00:49<00:14,  3.42it/s] 77%|███████▋  | 171/221 [00:49<00:14,  3.42it/s] 78%|███████▊  | 172/221 [00:50<00:14,  3.42it/s] 78%|███████▊  | 173/221 [00:50<00:14,  3.42it/s] 79%|███████▊  | 174/221 [00:50<00:13,  3.42it/s] 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s] 80%|███████▉  | 176/221 [00:51<00:13,  3.42it/s] 80%|████████  | 177/221 [00:51<00:12,  3.42it/s] 81%|████████  | 178/221 [00:51<00:12,  3.42it/s] 81%|████████  | 179/221 [00:52<00:12,  3.42it/s] 81%|████████▏ | 180/221 [00:52<00:11,  3.42it/s] 82%|████████▏ | 181/221 [00:52<00:11,  3.42it/s] 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s] 83%|████████▎ | 183/221 [00:53<00:11,  3.42it/s] 83%|████████▎ | 184/221 [00:53<00:10,  3.42it/s] 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s] 84%|████████▍ | 186/221 [00:54<00:10,  3.42it/s] 85%|████████▍ | 187/221 [00:54<00:09,  3.42it/s] 85%|████████▌ | 188/221 [00:54<00:09,  3.42it/s] 86%|████████▌ | 189/221 [00:55<00:09,  3.42it/s] 86%|████████▌ | 190/221 [00:55<00:09,  3.42it/s] 86%|████████▋ | 191/221 [00:55<00:08,  3.42it/s] 87%|████████▋ | 192/221 [00:56<00:08,  3.43it/s] 87%|████████▋ | 193/221 [00:56<00:08,  3.42it/s] 88%|████████▊ | 194/221 [00:56<00:07,  3.42it/s] 88%|████████▊ | 195/221 [00:56<00:07,  3.42it/s] 89%|████████▊ | 196/221 [00:57<00:07,  3.42it/s] 89%|████████▉ | 197/221 [00:57<00:07,  3.42it/s] 90%|████████▉ | 198/221 [00:57<00:06,  3.42it/s] 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s] 90%|█████████ | 200/221 [00:58<00:06,  3.42it/s] 91%|█████████ | 201/221 [00:58<00:05,  3.42it/s] 91%|█████████▏| 202/221 [00:58<00:05,  3.42it/s] 92%|█████████▏| 203/221 [00:59<00:05,  3.42it/s] 92%|█████████▏| 204/221 [00:59<00:04,  3.42it/s] 93%|█████████▎| 205/221 [00:59<00:04,  3.42it/s] 93%|█████████▎| 206/221 [01:00<00:04,  3.42it/s] 94%|█████████▎| 207/221 [01:00<00:04,  3.42it/s] 94%|█████████▍| 208/221 [01:00<00:03,  3.42it/s] 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s] 95%|█████████▌| 210/221 [01:01<00:03,  3.42it/s] 95%|█████████▌| 211/221 [01:01<00:02,  3.43it/s] 96%|█████████▌| 212/221 [01:01<00:02,  3.43it/s] 96%|█████████▋| 213/221 [01:02<00:02,  3.43it/s] 97%|█████████▋| 214/221 [01:02<00:02,  3.43it/s] 97%|█████████▋| 215/221 [01:02<00:01,  3.42it/s] 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s] 98%|█████████▊| 217/221 [01:03<00:01,  3.42it/s] 99%|█████████▊| 218/221 [01:03<00:00,  3.42it/s] 99%|█████████▉| 219/221 [01:03<00:00,  3.42it/s]100%|█████████▉| 220/221 [01:04<00:00,  3.42it/s]100%|██████████| 221/221 [01:04<00:00,  3.42it/s]100%|██████████| 221/221 [01:04<00:00,  3.42it/s]
  0%|          | 0/221 [00:00<?, ?it/s]  0%|          | 1/221 [00:00<00:42,  5.15it/s]  1%|          | 2/221 [00:00<01:05,  3.34it/s]  1%|▏         | 3/221 [00:01<01:18,  2.77it/s]  2%|▏         | 4/221 [00:01<01:14,  2.91it/s]  2%|▏         | 5/221 [00:01<01:02,  3.45it/s]  3%|▎         | 6/221 [00:01<00:51,  4.17it/s]  3%|▎         | 7/221 [00:01<00:47,  4.52it/s]  4%|▎         | 8/221 [00:02<00:48,  4.41it/s]  4%|▍         | 9/221 [00:02<01:20,  2.64it/s]  5%|▍         | 10/221 [00:03<01:18,  2.68it/s]  5%|▍         | 11/221 [00:03<01:30,  2.32it/s]  5%|▌         | 12/221 [00:04<01:23,  2.51it/s]  6%|▌         | 13/221 [00:04<01:39,  2.10it/s]  6%|▋         | 14/221 [00:04<01:23,  2.49it/s]  7%|▋         | 15/221 [00:05<01:15,  2.72it/s]  7%|▋         | 16/221 [00:05<01:06,  3.10it/s]  8%|▊         | 17/221 [00:05<01:18,  2.61it/s]  8%|▊         | 18/221 [00:06<01:20,  2.53it/s]  9%|▊         | 19/221 [00:06<01:06,  3.02it/s]  9%|▉         | 20/221 [00:06<00:58,  3.43it/s] 10%|▉         | 22/221 [00:07<00:48,  4.08it/s] 10%|█         | 23/221 [00:07<00:45,  4.37it/s] 11%|█         | 24/221 [00:07<00:47,  4.17it/s] 11%|█▏        | 25/221 [00:07<00:45,  4.27it/s] 12%|█▏        | 26/221 [00:07<00:42,  4.60it/s] 12%|█▏        | 27/221 [00:08<00:48,  4.00it/s] 13%|█▎        | 28/221 [00:08<00:52,  3.67it/s] 13%|█▎        | 29/221 [00:09<01:07,  2.84it/s] 14%|█▎        | 30/221 [00:09<00:56,  3.38it/s] 14%|█▍        | 31/221 [00:09<00:49,  3.80it/s] 14%|█▍        | 32/221 [00:09<00:55,  3.38it/s] 15%|█▍        | 33/221 [00:10<00:49,  3.79it/s] 15%|█▌        | 34/221 [00:10<00:50,  3.73it/s] 16%|█▌        | 35/221 [00:10<00:44,  4.17it/s] 16%|█▋        | 36/221 [00:10<00:49,  3.74it/s] 17%|█▋        | 37/221 [00:11<00:50,  3.68it/s] 17%|█▋        | 38/221 [00:11<00:46,  3.95it/s] 18%|█▊        | 39/221 [00:11<00:41,  4.34it/s] 18%|█▊        | 40/221 [00:11<00:38,  4.71it/s] 19%|█▊        | 41/221 [00:11<00:34,  5.25it/s] 19%|█▉        | 42/221 [00:11<00:31,  5.76it/s] 19%|█▉        | 43/221 [00:12<00:40,  4.43it/s] 20%|█▉        | 44/221 [00:12<00:41,  4.25it/s] 20%|██        | 45/221 [00:13<01:01,  2.87it/s] 21%|██        | 46/221 [00:13<01:00,  2.91it/s] 21%|██▏       | 47/221 [00:13<00:48,  3.56it/s] 22%|██▏       | 48/221 [00:13<00:41,  4.20it/s] 23%|██▎       | 50/221 [00:14<00:39,  4.36it/s] 23%|██▎       | 51/221 [00:14<00:37,  4.56it/s] 24%|██▎       | 52/221 [00:14<00:33,  5.11it/s] 24%|██▍       | 53/221 [00:15<00:47,  3.56it/s] 24%|██▍       | 54/221 [00:15<00:45,  3.68it/s] 25%|██▍       | 55/221 [00:15<00:43,  3.85it/s] 25%|██▌       | 56/221 [00:15<00:43,  3.79it/s] 26%|██▌       | 57/221 [00:16<00:45,  3.58it/s] 26%|██▌       | 58/221 [00:16<00:37,  4.36it/s] 27%|██▋       | 59/221 [00:16<00:37,  4.30it/s] 27%|██▋       | 60/221 [00:16<00:35,  4.58it/s] 28%|██▊       | 61/221 [00:17<00:42,  3.74it/s] 28%|██▊       | 62/221 [00:17<00:38,  4.10it/s] 29%|██▊       | 63/221 [00:17<00:38,  4.11it/s] 29%|██▉       | 64/221 [00:17<00:33,  4.70it/s] 29%|██▉       | 65/221 [00:17<00:32,  4.79it/s] 30%|██▉       | 66/221 [00:18<00:37,  4.15it/s] 30%|███       | 67/221 [00:18<00:41,  3.71it/s] 31%|███       | 68/221 [00:18<00:43,  3.53it/s] 31%|███       | 69/221 [00:19<01:07,  2.26it/s] 32%|███▏      | 70/221 [00:19<00:57,  2.64it/s] 32%|███▏      | 71/221 [00:20<01:00,  2.50it/s] 33%|███▎      | 72/221 [00:20<00:53,  2.76it/s] 33%|███▎      | 73/221 [00:20<00:47,  3.14it/s] 33%|███▎      | 74/221 [00:20<00:40,  3.67it/s] 34%|███▍      | 75/221 [00:21<00:42,  3.43it/s] 34%|███▍      | 76/221 [00:21<00:42,  3.38it/s] 35%|███▍      | 77/221 [00:21<00:35,  4.00it/s] 35%|███▌      | 78/221 [00:22<00:39,  3.59it/s] 36%|███▌      | 79/221 [00:22<00:33,  4.22it/s] 36%|███▌      | 80/221 [00:22<00:33,  4.26it/s] 37%|███▋      | 81/221 [00:22<00:30,  4.52it/s] 37%|███▋      | 82/221 [00:22<00:36,  3.84it/s] 38%|███▊      | 83/221 [00:23<00:35,  3.87it/s] 38%|███▊      | 84/221 [00:23<00:40,  3.39it/s] 38%|███▊      | 85/221 [00:24<00:44,  3.09it/s] 39%|███▉      | 86/221 [00:24<00:36,  3.68it/s] 39%|███▉      | 87/221 [00:24<00:41,  3.24it/s] 40%|███▉      | 88/221 [00:24<00:37,  3.59it/s] 40%|████      | 89/221 [00:25<00:46,  2.86it/s] 41%|████      | 90/221 [00:25<00:44,  2.93it/s] 41%|████      | 91/221 [00:25<00:35,  3.67it/s] 42%|████▏     | 92/221 [00:25<00:30,  4.25it/s] 42%|████▏     | 93/221 [00:26<00:38,  3.34it/s] 43%|████▎     | 94/221 [00:26<00:34,  3.63it/s] 43%|████▎     | 95/221 [00:27<00:57,  2.19it/s] 43%|████▎     | 96/221 [00:27<00:50,  2.49it/s] 44%|████▍     | 97/221 [00:28<00:52,  2.36it/s] 44%|████▍     | 98/221 [00:28<00:46,  2.63it/s] 45%|████▍     | 99/221 [00:28<00:42,  2.86it/s] 45%|████▌     | 100/221 [00:29<00:46,  2.62it/s] 46%|████▌     | 101/221 [00:29<00:40,  2.99it/s] 46%|████▌     | 102/221 [00:29<00:38,  3.11it/s] 47%|████▋     | 103/221 [00:29<00:33,  3.55it/s] 48%|████▊     | 105/221 [00:30<00:24,  4.64it/s] 48%|████▊     | 106/221 [00:30<00:29,  3.86it/s] 49%|████▉     | 108/221 [00:30<00:19,  5.72it/s] 49%|████▉     | 109/221 [00:30<00:20,  5.58it/s] 50%|████▉     | 110/221 [00:31<00:22,  4.89it/s] 50%|█████     | 111/221 [00:31<00:24,  4.48it/s] 51%|█████     | 112/221 [00:31<00:30,  3.63it/s] 51%|█████     | 113/221 [00:32<00:29,  3.61it/s] 52%|█████▏    | 114/221 [00:32<00:24,  4.31it/s] 52%|█████▏    | 116/221 [00:32<00:21,  4.85it/s] 53%|█████▎    | 117/221 [00:32<00:22,  4.59it/s] 53%|█████▎    | 118/221 [00:33<00:23,  4.31it/s] 54%|█████▍    | 119/221 [00:33<00:26,  3.87it/s] 54%|█████▍    | 120/221 [00:33<00:30,  3.34it/s] 55%|█████▍    | 121/221 [00:34<00:27,  3.58it/s] 55%|█████▌    | 122/221 [00:34<00:34,  2.85it/s] 56%|█████▌    | 123/221 [00:34<00:29,  3.29it/s] 56%|█████▌    | 124/221 [00:35<00:37,  2.55it/s] 57%|█████▋    | 125/221 [00:35<00:43,  2.22it/s] 57%|█████▋    | 126/221 [00:36<00:37,  2.55it/s] 57%|█████▋    | 127/221 [00:36<00:34,  2.71it/s] 58%|█████▊    | 128/221 [00:36<00:31,  2.99it/s] 58%|█████▊    | 129/221 [00:36<00:24,  3.72it/s] 59%|█████▉    | 130/221 [00:37<00:23,  3.85it/s] 59%|█████▉    | 131/221 [00:37<00:20,  4.45it/s] 60%|█████▉    | 132/221 [00:37<00:26,  3.40it/s] 60%|██████    | 133/221 [00:38<00:32,  2.75it/s] 61%|██████    | 134/221 [00:38<00:28,  3.00it/s] 61%|██████    | 135/221 [00:38<00:25,  3.40it/s] 62%|██████▏   | 136/221 [00:39<00:27,  3.08it/s] 62%|██████▏   | 137/221 [00:39<00:26,  3.19it/s] 62%|██████▏   | 138/221 [00:39<00:24,  3.36it/s] 63%|██████▎   | 139/221 [00:40<00:30,  2.71it/s] 63%|██████▎   | 140/221 [00:40<00:25,  3.22it/s] 64%|██████▍   | 141/221 [00:40<00:25,  3.17it/s] 64%|██████▍   | 142/221 [00:40<00:22,  3.53it/s] 65%|██████▍   | 143/221 [00:41<00:23,  3.36it/s] 65%|██████▌   | 144/221 [00:41<00:22,  3.40it/s] 66%|██████▌   | 145/221 [00:42<00:26,  2.86it/s] 66%|██████▌   | 146/221 [00:42<00:25,  2.92it/s] 67%|██████▋   | 147/221 [00:42<00:20,  3.55it/s] 67%|██████▋   | 148/221 [00:43<00:36,  2.01it/s] 67%|██████▋   | 149/221 [00:43<00:28,  2.51it/s] 68%|██████▊   | 150/221 [00:43<00:23,  3.03it/s] 68%|██████▊   | 151/221 [00:44<00:37,  1.89it/s] 69%|██████▉   | 152/221 [00:45<00:40,  1.68it/s] 69%|██████▉   | 153/221 [00:45<00:34,  1.95it/s] 70%|██████▉   | 154/221 [00:46<00:28,  2.39it/s] 70%|███████   | 155/221 [00:46<00:25,  2.57it/s] 71%|███████   | 156/221 [00:46<00:23,  2.75it/s] 71%|███████   | 157/221 [00:47<00:21,  2.97it/s] 71%|███████▏  | 158/221 [00:47<00:21,  2.87it/s] 72%|███████▏  | 159/221 [00:47<00:19,  3.22it/s] 72%|███████▏  | 160/221 [00:47<00:20,  3.03it/s] 73%|███████▎  | 161/221 [00:48<00:16,  3.71it/s] 74%|███████▍  | 163/221 [00:48<00:12,  4.72it/s] 74%|███████▍  | 164/221 [00:48<00:12,  4.46it/s] 75%|███████▍  | 165/221 [00:48<00:12,  4.41it/s] 75%|███████▌  | 166/221 [00:49<00:16,  3.35it/s] 76%|███████▌  | 167/221 [00:49<00:14,  3.66it/s] 76%|███████▌  | 168/221 [00:49<00:14,  3.63it/s] 77%|███████▋  | 170/221 [00:50<00:14,  3.52it/s] 77%|███████▋  | 171/221 [00:50<00:15,  3.19it/s] 78%|███████▊  | 172/221 [00:51<00:13,  3.51it/s] 78%|███████▊  | 173/221 [00:51<00:13,  3.69it/s] 79%|███████▊  | 174/221 [00:51<00:13,  3.49it/s] 79%|███████▉  | 175/221 [00:51<00:13,  3.39it/s] 80%|███████▉  | 176/221 [00:52<00:11,  4.02it/s] 80%|████████  | 177/221 [00:52<00:09,  4.62it/s] 81%|████████  | 178/221 [00:52<00:13,  3.18it/s] 81%|████████  | 179/221 [00:53<00:13,  3.15it/s] 81%|████████▏ | 180/221 [00:53<00:10,  3.78it/s] 82%|████████▏ | 181/221 [00:53<00:12,  3.33it/s] 82%|████████▏ | 182/221 [00:53<00:09,  4.01it/s] 83%|████████▎ | 183/221 [00:53<00:09,  3.97it/s] 83%|████████▎ | 184/221 [00:54<00:10,  3.49it/s] 84%|████████▎ | 185/221 [00:54<00:10,  3.54it/s] 84%|████████▍ | 186/221 [00:55<00:12,  2.81it/s] 85%|████████▌ | 188/221 [00:55<00:08,  3.76it/s] 86%|████████▌ | 189/221 [00:55<00:07,  4.03it/s] 86%|████████▌ | 190/221 [00:55<00:08,  3.80it/s] 87%|████████▋ | 192/221 [00:56<00:06,  4.46it/s] 87%|████████▋ | 193/221 [00:56<00:07,  3.99it/s] 88%|████████▊ | 194/221 [00:56<00:06,  3.87it/s] 88%|████████▊ | 195/221 [00:57<00:06,  3.99it/s] 89%|████████▊ | 196/221 [00:57<00:08,  3.09it/s] 89%|████████▉ | 197/221 [00:57<00:06,  3.50it/s] 90%|████████▉ | 198/221 [00:58<00:06,  3.64it/s] 90%|█████████ | 199/221 [00:58<00:05,  4.23it/s] 90%|█████████ | 200/221 [00:58<00:04,  4.52it/s] 91%|█████████ | 201/221 [00:58<00:03,  5.35it/s] 91%|█████████▏| 202/221 [00:58<00:03,  5.25it/s] 92%|█████████▏| 203/221 [00:58<00:03,  5.30it/s] 92%|█████████▏| 204/221 [00:59<00:03,  4.92it/s] 93%|█████████▎| 205/221 [00:59<00:03,  4.95it/s] 93%|█████████▎| 206/221 [00:59<00:03,  4.18it/s] 94%|█████████▎| 207/221 [01:00<00:04,  3.18it/s] 94%|█████████▍| 208/221 [01:00<00:03,  3.95it/s] 95%|█████████▍| 209/221 [01:00<00:03,  3.95it/s] 95%|█████████▌| 210/221 [01:00<00:03,  3.42it/s] 95%|█████████▌| 211/221 [01:01<00:02,  3.37it/s] 96%|█████████▌| 212/221 [01:01<00:02,  3.21it/s] 96%|█████████▋| 213/221 [01:01<00:02,  3.29it/s] 97%|█████████▋| 214/221 [01:02<00:02,  2.65it/s] 97%|█████████▋| 215/221 [01:02<00:02,  2.86it/s] 98%|█████████▊| 216/221 [01:03<00:01,  2.75it/s] 98%|█████████▊| 217/221 [01:03<00:01,  2.81it/s] 99%|█████████▊| 218/221 [01:04<00:01,  2.38it/s] 99%|█████████▉| 219/221 [01:04<00:00,  2.46it/s]100%|█████████▉| 220/221 [01:04<00:00,  2.79it/s]100%|██████████| 221/221 [01:05<00:00,  2.75it/s]100%|██████████| 221/221 [01:05<00:00,  3.40it/s]
09/16/2024 23:21:45 - INFO - __main__ -   ==== evaluation--ret%tva--msrvtt_ret_ret_area_forward========

09/16/2024 23:21:45 - INFO - __main__ -   {'area_r1': 24.1, 'area_recall': '24.1/43.1/50.6', 'area_ravg': 39.3}
09/16/2024 23:21:45 - INFO - __main__ -   ==== evaluation--ret%tva--msrvtt_ret_ret_area_backard========

09/16/2024 23:21:45 - INFO - __main__ -   {'forward_r1': 33.3, 'forward_recall': '33.3/64.7/75.1', 'forward_ravg': 57.7}
09/16/2024 23:21:45 - INFO - __main__ -   ==== evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video========

09/16/2024 23:21:45 - INFO - __main__ -   {'area_video_r1': 33.3, 'area_video_recall': '33.3/64.4/75.9', 'area_video_ravg': 57.8}
09/16/2024 23:21:45 - INFO - __main__ -   ==== evaluation--ret%tva--msrvtt_ret_ret_itm_area========

09/16/2024 23:21:45 - INFO - __main__ -   {'area_video_r1': 47.2, 'area_video_recall': '47.2/66.7/72.6', 'area_video_ravg': 62.2, 'area_video_back_r1': 43.9, 'area_video_back_recall': '43.9/68.9/78.2', 'area_video_back_ravg': 63.7}
09/16/2024 23:21:45 - INFO - __main__ -   ==== evaluation--ret%tva--msrvtt_ret_ret_itc_tva========

09/16/2024 23:21:45 - INFO - __main__ -   {'video_r1': 35.7, 'video_recall': '35.7/63.6/72.5', 'video_ravg': 57.3}
09/16/2024 23:21:45 - INFO - __main__ -   ==== evaluation--ret%tva--msrvtt_ret_ret_itm_tva========

09/16/2024 23:21:45 - INFO - __main__ -   {'video_r1': 49.3, 'video_recall': '49.3/70.8/80.0', 'video_ravg': 66.7}
  0%|          | 0/2910 [00:00<?, ?it/s][h264 @ 0x55e188cc85c0] mmco: unref short failure
[h264 @ 0x55e188cc85c0] mmco: unref short failure
[h264 @ 0x55e188cc85c0] mmco: unref short failure
[h264 @ 0x55e188cc85c0] mmco: unref short failure
[h264 @ 0x55a25db54e80] mmco: unref short failure
[h264 @ 0x55a25db54e80] mmco: unref short failure
/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_optimizer.py:171: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1485.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_optimizer.py:171: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1485.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_optimizer.py:171: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1485.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_optimizer.py:171: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1485.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
  0%|          | 1/2910 [00:09<7:29:02,  9.26s/it]  0%|          | 2/2910 [00:13<4:59:15,  6.17s/it]  0%|          | 3/2910 [00:17<4:22:14,  5.41s/it]  0%|          | 4/2910 [00:21<3:59:08,  4.94s/it][h264 @ 0x55e18fa19640] mmco: unref short failure
[h264 @ 0x55e18fa19640] mmco: unref short failure
[h264 @ 0x56068cfdab80] mmco: unref short failure
[h264 @ 0x56068cfdab80] mmco: unref short failure
[h264 @ 0x56068f8db880] mmco: unref short failure
  0%|          | 5/2910 [00:26<3:56:14,  4.88s/it][h264 @ 0x55b4f749a400] mmco: unref short failure
[h264 @ 0x55b4f749a400] mmco: unref short failure
[h264 @ 0x55e18421e9c0] mmco: unref short failure
  0%|          | 6/2910 [00:32<4:03:58,  5.04s/it]09/16/2024 23:22:22 - INFO - __main__ -   current idx KX0TpgJdepY.11 from finetune_area returns wrong image/video, use 56889 instead.
[h264 @ 0x55e18bb2e700] mmco: unref short failure
  0%|          | 7/2910 [00:37<4:13:30,  5.24s/it][h264 @ 0x55a25d87cd00] mmco: unref short failure
  0%|          | 8/2910 [00:42<4:12:43,  5.23s/it][h264 @ 0x55a267403740] mmco: unref short failure
[h264 @ 0x55a260b2b980] mmco: unref short failure
[h264 @ 0x55a260b2b980] mmco: unref short failure
  0%|          | 9/2910 [00:49<4:30:39,  5.60s/it]  0%|          | 10/2910 [00:55<4:31:05,  5.61s/it]  0%|          | 11/2910 [01:00<4:24:41,  5.48s/it]  0%|          | 12/2910 [01:06<4:31:42,  5.63s/it]09/16/2024 23:22:55 - INFO - __main__ -   current idx f2vz8YAFQms.52 from finetune_area returns wrong image/video, use 47000 instead.
  0%|          | 13/2910 [01:12<4:42:36,  5.85s/it]  0%|          | 14/2910 [01:18<4:50:51,  6.03s/it][h264 @ 0x55e18dcd4940] mmco: unref short failure
[h264 @ 0x55e18dcd4940] mmco: unref short failure
[h264 @ 0x55e18dcd4940] mmco: unref short failure
[h264 @ 0x55e18dcd4940] mmco: unref short failure
09/16/2024 23:23:06 - INFO - __main__ -   current idx QzpF1yDPHf0.29 from finetune_area returns wrong image/video, use 139919 instead.
[h264 @ 0x55b4fd5295c0] mmco: unref short failure
[h264 @ 0x55b4f92c3400] mmco: unref short failure
[h264 @ 0x55b4f92c3400] mmco: unref short failure
  1%|          | 15/2910 [01:24<4:36:36,  5.73s/it][h264 @ 0x560696f58240] mmco: unref short failure
[h264 @ 0x560696f58240] mmco: unref short failure
[h264 @ 0x56068c792a40] mmco: unref short failure
[h264 @ 0x56068c792a40] mmco: unref short failure
[h264 @ 0x55e188cc16c0] mmco: unref short failure
[h264 @ 0x55e190ef1f40] mmco: unref short failure
[h264 @ 0x55a2618a8000] mmco: unref short failure
[h264 @ 0x55a2618a8000] mmco: unref short failure
[h264 @ 0x55b4ffb9d8c0] mmco: unref short failure
[h264 @ 0x55b4ffb9d8c0] mmco: unref short failure
[h264 @ 0x55a25ca1c200] mmco: unref short failure
[h264 @ 0x55a25ca1c200] mmco: unref short failure
[h264 @ 0x55a26630e280] mmco: unref short failure
  1%|          | 16/2910 [02:07<13:49:51, 17.21s/it]  1%|          | 17/2910 [02:13<11:00:56, 13.71s/it][h264 @ 0x56068ed849c0] mmco: unref short failure
[h264 @ 0x56068e54fd40] mmco: unref short failure
[h264 @ 0x55b5026c2240] mmco: unref short failure
[h264 @ 0x55b4f2d2a000] mmco: unref short failure
[h264 @ 0x55b4f2d2a000] mmco: unref short failure
[h264 @ 0x55b4f2d2a000] mmco: unref short failure
[h264 @ 0x55b4f2d2a000] mmco: unref short failure
[h264 @ 0x55e183241900] mmco: unref short failure
[h264 @ 0x55e183241900] mmco: unref short failure
[h264 @ 0x55b4fb612f00] mmco: unref short failure
  1%|          | 18/2910 [02:39<13:53:51, 17.30s/it][h264 @ 0x55e1859dd500] mmco: unref short failure
[h264 @ 0x55e1859dd500] mmco: unref short failure
  1%|          | 19/2910 [02:46<11:27:28, 14.27s/it][h264 @ 0x55a25b5f6080] mmco: unref short failure
[h264 @ 0x55a25b5f6080] mmco: unref short failure
[h264 @ 0x56068c42acc0] mmco: unref short failure
[h264 @ 0x56068c42acc0] mmco: unref short failure
  1%|          | 20/2910 [02:58<10:54:51, 13.60s/it][h264 @ 0x55e18787b200] mmco: unref short failure
[h264 @ 0x55e18787b200] mmco: unref short failure
[h264 @ 0x55e18787b200] mmco: unref short failure
[h264 @ 0x55e18787b200] mmco: unref short failure
[h264 @ 0x55a25c023400] mmco: unref short failure
[h264 @ 0x55a25c023400] mmco: unref short failure
  1%|          | 21/2910 [03:03<8:58:42, 11.19s/it] [h264 @ 0x55e183a9f000] mmco: unref short failure
[h264 @ 0x55a261e70800] mmco: unref short failure
[h264 @ 0x55a261e70800] mmco: unref short failure
  1%|          | 22/2910 [03:09<7:35:23,  9.46s/it]  1%|          | 23/2910 [03:16<6:55:21,  8.63s/it][h264 @ 0x55e185d70f80] mmco: unref short failure
[h264 @ 0x55e185d70f80] mmco: unref short failure
[h264 @ 0x55b4fb9d4840] mmco: unref short failure
[h264 @ 0x55b4fb9d4840] mmco: unref short failure
[h264 @ 0x55b4fad7a340] mmco: unref short failure
[h264 @ 0x55e18411a680] mmco: unref short failure
[h264 @ 0x55a25c785f40] mmco: unref short failure
[h264 @ 0x55a25c785f40] mmco: unref short failure
[h264 @ 0x56069269b700] mmco: unref short failure
[h264 @ 0x55e18b9ae000] mmco: unref short failure
[h264 @ 0x55e188cc1440] mmco: unref short failure
[h264 @ 0x55e188cc1440] mmco: unref short failure
[h264 @ 0x55b5034184c0] mmco: unref short failure
[h264 @ 0x55a266950580] mmco: unref short failure
[h264 @ 0x55a266950580] mmco: unref short failure
09/16/2024 23:26:13 - INFO - __main__ -   current idx IcQG8e_UOeA.24 from finetune_area returns wrong image/video, use 119424 instead.
  1%|          | 24/2910 [04:35<23:52:04, 29.77s/it][h264 @ 0x55e1922801c0] mmco: unref short failure
[h264 @ 0x55b4fe43c3c0] mmco: unref short failure
  1%|          | 25/2910 [04:40<18:02:36, 22.52s/it][h264 @ 0x5606913e7f00] mmco: unref short failure
09/16/2024 23:26:39 - INFO - __main__ -   current idx XgAp7Dp862o.1 from finetune_area returns wrong image/video, use 80046 instead.
[h264 @ 0x55e185932540] mmco: unref short failure
[h264 @ 0x55e185932540] mmco: unref short failure
[h264 @ 0x55a25c646300] mmco: unref short failure
[h264 @ 0x55a25c646300] mmco: unref short failure
[h264 @ 0x55e18e38a4c0] mmco: unref short failure
[h264 @ 0x55e18e38a4c0] mmco: unref short failure
[h264 @ 0x55e18e38a4c0] mmco: unref short failure
[h264 @ 0x55e18e38a4c0] mmco: unref short failure
[h264 @ 0x55e187dd7600] mmco: unref short failure
[h264 @ 0x55e195265b80] mmco: unref short failure
[h264 @ 0x55e195265b80] mmco: unref short failure
[h264 @ 0x55e195265b80] mmco: unref short failure
[h264 @ 0x55e195265b80] mmco: unref short failure
[h264 @ 0x56068e8c9280] mmco: unref short failure
  1%|          | 26/2910 [05:14<20:43:19, 25.87s/it][h264 @ 0x55a26a4f97c0] mmco: unref short failure
[h264 @ 0x55a26a4f97c0] mmco: unref short failure
[h264 @ 0x55b4fe32abc0] mmco: unref short failure
[h264 @ 0x55b4fe32abc0] mmco: unref short failure
[h264 @ 0x55b4fe32abc0] mmco: unref short failure
[h264 @ 0x55e187be2ac0] mmco: unref short failure
  1%|          | 27/2910 [05:22<16:30:39, 20.62s/it]  1%|          | 28/2910 [05:28<12:52:17, 16.08s/it][h264 @ 0x55b4faa29c00] mmco: unref short failure
[h264 @ 0x55b4faa29c00] mmco: unref short failure
  1%|          | 29/2910 [05:34<10:25:37, 13.03s/it][h264 @ 0x55e195622ac0] mmco: unref short failure
[h264 @ 0x55e195622ac0] mmco: unref short failure
[h264 @ 0x55e195622ac0] mmco: unref short failure
[h264 @ 0x55e195622ac0] mmco: unref short failure
  1%|          | 30/2910 [05:39<8:32:09, 10.67s/it] 09/16/2024 23:27:26 - INFO - __main__ -   current idx zpVEmyBr_Hg.14 from finetune_area returns wrong image/video, use 62748 instead.
  1%|          | 31/2910 [05:44<7:12:25,  9.01s/it][h264 @ 0x560691d73800] mmco: unref short failure
[h264 @ 0x560691d73800] mmco: unref short failure
[h264 @ 0x55a26d8d6880] mmco: unref short failure
[h264 @ 0x55b5025f6ec0] mmco: unref short failure
[h264 @ 0x55b5025f6ec0] mmco: unref short failure
[h264 @ 0x55e183c38d40] mmco: unref short failure
[h264 @ 0x55e183c38d40] mmco: unref short failure
[h264 @ 0x55b503927100] mmco: unref short failure
[h264 @ 0x55b503927100] mmco: unref short failure
[h264 @ 0x55a25b788240] mmco: unref short failure
[h264 @ 0x55a25b788240] mmco: unref short failure
[h264 @ 0x560690a311c0] mmco: unref short failure
[h264 @ 0x55e18c234dc0] mmco: unref short failure
[h264 @ 0x55e18c234dc0] mmco: unref short failure
[h264 @ 0x55e18c234dc0] mmco: unref short failure
[h264 @ 0x55e18c234dc0] mmco: unref short failure
[h264 @ 0x55a26692d9c0] mmco: unref short failure
[h264 @ 0x55a26692d9c0] mmco: unref short failure
[h264 @ 0x55b4fbc15500] mmco: unref short failure
[h264 @ 0x55b4fbc15500] mmco: unref short failure
[h264 @ 0x5606967ebd40] mmco: unref short failure
09/16/2024 23:28:14 - INFO - __main__ -   current idx fQszS3V8sxI.1 from finetune_area returns wrong image/video, use 34076 instead.
[h264 @ 0x55a2680f85c0] mmco: unref short failure
[h264 @ 0x55a2680f85c0] mmco: unref short failure
[h264 @ 0x55a26bc6d800] mmco: unref short failure
[h264 @ 0x55a26bc6d800] mmco: unref short failure
[h264 @ 0x55a2680f83c0] mmco: unref short failure
[h264 @ 0x55a2680f83c0] mmco: unref short failure
[h264 @ 0x55b4f82d1c00] mmco: unref short failure
[h264 @ 0x55b4f82d1c00] mmco: unref short failure
09/16/2024 23:28:32 - INFO - __main__ -   current idx gy0BKAObQyw.14 from finetune_area returns wrong image/video, use 146105 instead.
[h264 @ 0x55a26358b680] mmco: unref short failure
[h264 @ 0x55a26358b680] mmco: unref short failure
[h264 @ 0x55e195265e00] mmco: unref short failure
[h264 @ 0x55e195265e00] mmco: unref short failure
[h264 @ 0x560695398300] mmco: unref short failure
  1%|          | 32/2910 [06:58<22:53:46, 28.64s/it]  1%|          | 33/2910 [07:13<19:24:31, 24.29s/it][h264 @ 0x55b50563ddc0] mmco: unref short failure
[h264 @ 0x55b50563ddc0] mmco: unref short failure
[h264 @ 0x55b50563ddc0] mmco: unref short failure
[h264 @ 0x55b50563ddc0] mmco: unref short failure
[h264 @ 0x55b4fb9e8e40] mmco: unref short failure
[h264 @ 0x55a26c18ce80] mmco: unref short failure
[h264 @ 0x55b4f9278a40] mmco: unref short failure
[h264 @ 0x55b4f9278a40] mmco: unref short failure
[h264 @ 0x560695398300] mmco: unref short failure
[h264 @ 0x560695398300] mmco: unref short failure
[h264 @ 0x5606910ef780] mmco: unref short failure
[h264 @ 0x5606910ef780] mmco: unref short failure
  1%|          | 34/2910 [07:37<19:31:33, 24.44s/it][h264 @ 0x56068e9c5900] mmco: unref short failure
[h264 @ 0x55b50306b0c0] mmco: unref short failure
[h264 @ 0x55b50306b0c0] mmco: unref short failure
  1%|          | 35/2910 [07:47<16:03:39, 20.11s/it]  1%|          | 36/2910 [07:53<12:42:29, 15.92s/it]  1%|▏         | 37/2910 [07:58<10:04:14, 12.62s/it][h264 @ 0x55b4fb817840] mmco: unref short failure
[h264 @ 0x55b4fb817840] mmco: unref short failure
  1%|▏         | 38/2910 [08:05<8:30:42, 10.67s/it]   1%|▏         | 39/2910 [08:10<7:13:02,  9.05s/it][h264 @ 0x55a25cd47900] mmco: unref short failure
[h264 @ 0x55a25cd47900] mmco: unref short failure
[h264 @ 0x560694ecd840] mmco: unref short failure
[h264 @ 0x560694ecd840] mmco: unref short failure
09/16/2024 23:30:00 - INFO - __main__ -   current idx HnCSd-QjKvs.136 from finetune_area returns wrong image/video, use 135996 instead.
[h264 @ 0x55e1832a23c0] mmco: unref short failure
[h264 @ 0x55e1832a23c0] mmco: unref short failure
[h264 @ 0x55e186c8de80] mmco: unref short failure
[h264 @ 0x55a26899a240] mmco: unref short failure
[h264 @ 0x55a26899a240] mmco: unref short failure
[h264 @ 0x560691ca24c0] mmco: unref short failure
[h264 @ 0x560691ca24c0] mmco: unref short failure
[h264 @ 0x560692f69b00] mmco: unref short failure
[h264 @ 0x55a25c7c72c0] mmco: unref short failure
[h264 @ 0x55e1885c1c40] mmco: unref short failure
[h264 @ 0x55e1885c1c40] mmco: unref short failure
[h264 @ 0x55b4fbe22f80] mmco: unref short failure
[h264 @ 0x55b4fbe22f80] mmco: unref short failure
[h264 @ 0x55b4fbe22f80] mmco: unref short failure
[h264 @ 0x55b5002bd8c0] mmco: unref short failure
[h264 @ 0x55e18b783640] mmco: unref short failure
[h264 @ 0x55e18b783640] mmco: unref short failure
[h264 @ 0x55a2682c5640] mmco: unref short failure
[h264 @ 0x560696709b00] mmco: unref short failure
[h264 @ 0x560696709b00] mmco: unref short failure
[h264 @ 0x55e1835b8b40] mmco: unref short failure
[h264 @ 0x5606964538c0] mmco: unref short failure
[h264 @ 0x5606964538c0] mmco: unref short failure
[h264 @ 0x55a25c1b9f80] mmco: unref short failure
[h264 @ 0x55a25c1b9f80] mmco: unref short failure
[h264 @ 0x55a25d278740] mmco: unref short failure
[h264 @ 0x55a25d278740] mmco: unref short failure
[h264 @ 0x55a25d278740] mmco: unref short failure
  1%|▏         | 40/2910 [09:24<22:40:39, 28.45s/it][h264 @ 0x5606902a0500] mmco: unref short failure
[h264 @ 0x5606902a0500] mmco: unref short failure
[h264 @ 0x56068bf22840] mmco: unref short failure
[h264 @ 0x56068bf22840] mmco: unref short failure
[h264 @ 0x55a26a210d80] mmco: unref short failure
[h264 @ 0x55e191001680] mmco: unref short failure
[h264 @ 0x55e191001680] mmco: unref short failure
  1%|▏         | 41/2910 [09:51<22:29:27, 28.22s/it][h264 @ 0x55a25c83d800] mmco: unref short failure
[h264 @ 0x55a25c83d800] mmco: unref short failure
  1%|▏         | 42/2910 [10:04<18:43:19, 23.50s/it]09/16/2024 23:31:54 - INFO - __main__ -   current idx bcmbKN1aIOU.40 from finetune_area returns wrong image/video, use 123173 instead.
[h264 @ 0x56068c3a1140] mmco: unref short failure
[h264 @ 0x55a265b1e840] mmco: unref short failure
  1%|▏         | 43/2910 [10:16<15:56:07, 20.01s/it]  2%|▏         | 44/2910 [10:21<12:32:10, 15.75s/it]  2%|▏         | 45/2910 [10:28<10:14:45, 12.87s/it][h264 @ 0x55e1881d81c0] mmco: unref short failure
[h264 @ 0x55e1971c0c80] mmco: unref short failure
  2%|▏         | 46/2910 [10:35<8:51:03, 11.13s/it]   2%|▏         | 47/2910 [10:40<7:30:42,  9.45s/it][h264 @ 0x55e1944bbcc0] mmco: unref short failure
[h264 @ 0x55a265b1e840] mmco: unref short failure
[h264 @ 0x55e1933e4980] mmco: unref short failure
[h264 @ 0x55e1933e4980] mmco: unref short failure
[h264 @ 0x55e18af32c80] mmco: unref short failure
[h264 @ 0x55e18af32c80] mmco: unref short failure
[h264 @ 0x56068e48f580] mmco: unref short failure
[h264 @ 0x55a26bc51480] mmco: unref short failure
[h264 @ 0x55a26bc51480] mmco: unref short failure
[h264 @ 0x56068bcb9300] mmco: unref short failure
[h264 @ 0x560692195280] mmco: unref short failure
[h264 @ 0x55e190fdf0c0] mmco: unref short failure
[h264 @ 0x55a26521e140] mmco: unref short failure
[h264 @ 0x55b5009aff40] mmco: unref short failure
[h264 @ 0x55e1908efb00] mmco: unref short failure
[h264 @ 0x55e18df8c600] mmco: unref short failure
[h264 @ 0x55e18df8c600] mmco: unref short failure
  2%|▏         | 48/2910 [11:52<22:27:13, 28.24s/it][h264 @ 0x56068fbdf280] mmco: unref short failure
[h264 @ 0x56068fbdf280] mmco: unref short failure
[h264 @ 0x56068fbdf280] mmco: unref short failure
[h264 @ 0x56068fbdf280] mmco: unref short failure
[h264 @ 0x55b4f9d676c0] mmco: unref short failure
[h264 @ 0x55b4f9d676c0] mmco: unref short failure
[h264 @ 0x55b4f9d676c0] mmco: unref short failure
[h264 @ 0x55b4f9d676c0] mmco: unref short failure
  2%|▏         | 49/2910 [12:13<20:37:01, 25.94s/it]09/16/2024 23:33:59 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/16/2024 23:33:59 - INFO - __main__ -   start running ret%tva validation...
[h264 @ 0x56068eb78900] mmco: unref short failure
[h264 @ 0x55b4fc3e7380] mmco: unref short failure
[h264 @ 0x55b4fc3e7380] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a25cb7ff80] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a26acc6bc0] mmco: unref short failure
[h264 @ 0x55a26acc6bc0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a26acc6bc0] mmco: unref short failure
[h264 @ 0x55a26acc6bc0] mmco: unref short failure
[h264 @ 0x55a26acc6bc0] mmco: unref short failure
[h264 @ 0x55a26acc6bc0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e18b9cbbc0] mmco: unref short failure
[h264 @ 0x5606951d7bc0] mmco: unref short failure
[h264 @ 0x5606951d7bc0] mmco: unref short failure
[h264 @ 0x560698396c40] mmco: unref short failure
[h264 @ 0x560698396c40] mmco: unref short failure
[h264 @ 0x560698396c40] mmco: unref short failure
[h264 @ 0x560698396c40] mmco: unref short failure
[h264 @ 0x560691ffea40] mmco: unref short failure
[h264 @ 0x560691ffea40] mmco: unref short failure
[h264 @ 0x560691ffea40] mmco: unref short failure
[h264 @ 0x560691ffea40] mmco: unref short failure
[h264 @ 0x55e193f3dd00] mmco: unref short failure
[h264 @ 0x56069cda0780] mmco: unref short failure
[h264 @ 0x55b507cec1c0] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:35,  6.27it/s][A
  1%|          | 2/221 [00:00<00:40,  5.46it/s][A
  1%|▏         | 3/221 [00:00<00:51,  4.20it/s][A
  2%|▏         | 4/221 [00:00<00:45,  4.75it/s][A
  2%|▏         | 5/221 [00:01<00:43,  4.99it/s][A
  3%|▎         | 6/221 [00:01<00:40,  5.25it/s][A
  3%|▎         | 7/221 [00:01<00:42,  5.07it/s][A
  4%|▎         | 8/221 [00:01<00:36,  5.85it/s][A
  4%|▍         | 9/221 [00:01<00:32,  6.60it/s][A
  5%|▍         | 10/221 [00:01<00:29,  7.11it/s][A
  5%|▍         | 11/221 [00:01<00:27,  7.69it/s][A
  5%|▌         | 12/221 [00:03<01:41,  2.07it/s][A
  6%|▋         | 14/221 [00:03<01:02,  3.33it/s][A
  7%|▋         | 15/221 [00:03<00:54,  3.76it/s][A
  7%|▋         | 16/221 [00:03<00:51,  3.98it/s][A
  8%|▊         | 17/221 [00:03<00:53,  3.78it/s][A
  8%|▊         | 18/221 [00:04<00:47,  4.27it/s][A
  9%|▊         | 19/221 [00:04<00:41,  4.90it/s][A
  9%|▉         | 20/221 [00:04<00:36,  5.58it/s][A
 10%|▉         | 21/221 [00:04<00:33,  5.94it/s][A[h264 @ 0x56069cdff000] mmco: unref short failure

 10%|▉         | 22/221 [00:07<03:16,  1.01it/s][A
 10%|█         | 23/221 [00:07<02:25,  1.36it/s][A
 11%|█         | 24/221 [00:07<01:48,  1.81it/s][A
 11%|█▏        | 25/221 [00:07<01:22,  2.36it/s][A
 12%|█▏        | 26/221 [00:08<01:07,  2.91it/s][A
 13%|█▎        | 28/221 [00:08<00:48,  3.98it/s][A
 13%|█▎        | 29/221 [00:08<00:42,  4.54it/s][A
 14%|█▎        | 30/221 [00:08<00:42,  4.54it/s][A
 14%|█▍        | 31/221 [00:08<00:43,  4.42it/s][A
 14%|█▍        | 32/221 [00:09<00:41,  4.53it/s][A
 15%|█▍        | 33/221 [00:09<00:37,  5.06it/s][A
 15%|█▌        | 34/221 [00:09<00:33,  5.63it/s][A[h264 @ 0x56069cda09c0] mmco: unref short failure

 16%|█▌        | 35/221 [00:09<00:28,  6.46it/s][A
 16%|█▋        | 36/221 [00:09<00:26,  6.92it/s][A
 17%|█▋        | 37/221 [00:09<00:28,  6.44it/s][A
 17%|█▋        | 38/221 [00:09<00:28,  6.38it/s][A
 18%|█▊        | 39/221 [00:10<00:29,  6.26it/s][A
 18%|█▊        | 40/221 [00:10<00:26,  6.81it/s][A
 19%|█▉        | 42/221 [00:10<00:26,  6.87it/s][A
 19%|█▉        | 43/221 [00:10<00:27,  6.57it/s][A
 20%|██        | 45/221 [00:11<00:34,  5.03it/s][A
 21%|██        | 46/221 [00:11<00:32,  5.37it/s][A
 21%|██▏       | 47/221 [00:16<03:56,  1.36s/it][A
 22%|██▏       | 49/221 [00:16<02:24,  1.19it/s][A
 23%|██▎       | 50/221 [00:16<01:57,  1.45it/s][A
 23%|██▎       | 51/221 [00:16<01:33,  1.82it/s][A
 24%|██▎       | 52/221 [00:17<01:18,  2.15it/s][A
 24%|██▍       | 53/221 [00:17<01:09,  2.43it/s][A
 24%|██▍       | 54/221 [00:21<04:24,  1.58s/it][A
 25%|██▍       | 55/221 [00:22<03:42,  1.34s/it][A
 25%|██▌       | 56/221 [00:22<02:43,  1.01it/s][A
 26%|██▌       | 57/221 [00:22<02:00,  1.36it/s][A
 26%|██▌       | 58/221 [00:23<01:30,  1.80it/s][A
 27%|██▋       | 59/221 [00:23<01:09,  2.34it/s][A
 27%|██▋       | 60/221 [00:23<00:59,  2.71it/s][A
 28%|██▊       | 61/221 [00:23<00:48,  3.30it/s][A
 28%|██▊       | 62/221 [00:23<00:39,  4.05it/s][A
 29%|██▊       | 63/221 [00:23<00:35,  4.47it/s][A
 29%|██▉       | 64/221 [00:24<00:37,  4.18it/s][A
 29%|██▉       | 65/221 [00:24<00:37,  4.18it/s][A
 30%|██▉       | 66/221 [00:28<03:47,  1.47s/it][A
 30%|███       | 67/221 [00:29<02:55,  1.14s/it][A
 31%|███       | 68/221 [00:29<02:14,  1.14it/s][A
 31%|███       | 69/221 [00:29<01:47,  1.42it/s][A
 32%|███▏      | 70/221 [00:29<01:23,  1.82it/s][A
 32%|███▏      | 71/221 [00:29<01:04,  2.33it/s][A
 33%|███▎      | 72/221 [00:30<00:51,  2.90it/s][A
 33%|███▎      | 73/221 [00:30<00:45,  3.24it/s][A
 33%|███▎      | 74/221 [00:30<00:37,  3.94it/s][A
 34%|███▍      | 75/221 [00:30<00:35,  4.16it/s][A
 34%|███▍      | 76/221 [00:30<00:29,  4.85it/s][A
 35%|███▍      | 77/221 [00:30<00:29,  4.92it/s][A
 35%|███▌      | 78/221 [00:31<00:27,  5.20it/s][A
 36%|███▌      | 79/221 [00:31<00:34,  4.10it/s][A
 37%|███▋      | 81/221 [00:31<00:30,  4.60it/s][A
 37%|███▋      | 82/221 [00:32<00:32,  4.34it/s][A
 38%|███▊      | 83/221 [00:32<00:30,  4.50it/s][A
 38%|███▊      | 84/221 [00:32<00:27,  5.02it/s][A
 38%|███▊      | 85/221 [00:32<00:23,  5.77it/s][A
 39%|███▉      | 86/221 [00:32<00:20,  6.54it/s][A
 39%|███▉      | 87/221 [00:32<00:18,  7.25it/s][A
 40%|███▉      | 88/221 [00:33<00:22,  5.81it/s][A
 40%|████      | 89/221 [00:33<00:25,  5.10it/s][A
 41%|████      | 90/221 [00:33<00:29,  4.51it/s][A
 42%|████▏     | 92/221 [00:33<00:21,  5.89it/s][A
 42%|████▏     | 93/221 [00:34<00:29,  4.41it/s][A
 43%|████▎     | 94/221 [00:34<00:25,  5.02it/s][A
 43%|████▎     | 95/221 [00:34<00:24,  5.24it/s][A
 43%|████▎     | 96/221 [00:34<00:23,  5.32it/s][A
 44%|████▍     | 97/221 [00:34<00:20,  6.12it/s][A
 44%|████▍     | 98/221 [00:34<00:19,  6.38it/s][A
 45%|████▍     | 99/221 [00:35<00:18,  6.77it/s][A
 45%|████▌     | 100/221 [00:35<00:16,  7.32it/s][A
 46%|████▌     | 101/221 [00:35<00:15,  7.93it/s][A
 46%|████▌     | 102/221 [00:35<00:15,  7.93it/s][A
 47%|████▋     | 103/221 [00:35<00:14,  8.15it/s][A
 47%|████▋     | 104/221 [00:35<00:14,  7.89it/s][A
 48%|████▊     | 105/221 [00:35<00:15,  7.62it/s][A
 48%|████▊     | 106/221 [00:36<00:28,  4.04it/s][A
 48%|████▊     | 107/221 [00:36<00:24,  4.71it/s][A
 49%|████▉     | 108/221 [00:36<00:22,  5.01it/s][A
 50%|████▉     | 110/221 [00:36<00:15,  6.97it/s][A
 50%|█████     | 111/221 [00:37<00:20,  5.44it/s][A
 51%|█████     | 112/221 [00:37<00:18,  5.79it/s][A
 51%|█████     | 113/221 [00:37<00:17,  6.05it/s][A
 52%|█████▏    | 114/221 [00:37<00:15,  6.70it/s][A
 52%|█████▏    | 116/221 [00:42<02:11,  1.25s/it][A
 53%|█████▎    | 117/221 [00:43<01:46,  1.03s/it][A
 53%|█████▎    | 118/221 [00:43<01:21,  1.26it/s][A
 54%|█████▍    | 120/221 [00:43<00:50,  2.00it/s][A
 55%|█████▍    | 121/221 [00:43<00:43,  2.29it/s][A
 55%|█████▌    | 122/221 [00:43<00:38,  2.57it/s][A
 56%|█████▌    | 123/221 [00:43<00:30,  3.17it/s][A
 56%|█████▌    | 124/221 [00:44<00:26,  3.67it/s][A
 57%|█████▋    | 125/221 [00:44<00:31,  3.09it/s][A
 57%|█████▋    | 126/221 [00:44<00:32,  2.97it/s][A
 57%|█████▋    | 127/221 [00:45<00:40,  2.32it/s][A[h264 @ 0x55a2639b2900] mmco: unref short failure
[h264 @ 0x55a2639b2900] mmco: unref short failure

 58%|█████▊    | 128/221 [00:46<00:54,  1.72it/s][A
 58%|█████▊    | 129/221 [00:46<00:44,  2.09it/s][A
 59%|█████▉    | 130/221 [00:46<00:33,  2.69it/s][A
 59%|█████▉    | 131/221 [00:47<00:28,  3.18it/s][A
 60%|█████▉    | 132/221 [00:47<00:27,  3.22it/s][A
 60%|██████    | 133/221 [00:47<00:25,  3.50it/s][A
 61%|██████    | 134/221 [00:47<00:24,  3.51it/s][A[h264 @ 0x55b508915240] mmco: unref short failure
[h264 @ 0x55b508915240] mmco: unref short failure

 61%|██████    | 135/221 [00:48<00:35,  2.42it/s][A
 62%|██████▏   | 136/221 [00:49<00:55,  1.53it/s][A
 62%|██████▏   | 137/221 [00:54<02:36,  1.86s/it][A
 62%|██████▏   | 138/221 [00:55<02:03,  1.48s/it][A
 63%|██████▎   | 139/221 [00:55<01:39,  1.21s/it][A
 63%|██████▎   | 140/221 [00:55<01:15,  1.07it/s][A
 64%|██████▍   | 141/221 [00:56<01:02,  1.28it/s][A
 64%|██████▍   | 142/221 [00:56<00:49,  1.60it/s][A
 65%|██████▍   | 143/221 [00:56<00:38,  2.00it/s][A
 65%|██████▌   | 144/221 [00:56<00:31,  2.48it/s][A
 66%|██████▌   | 146/221 [00:57<00:19,  3.88it/s][A
 67%|██████▋   | 147/221 [00:57<00:16,  4.39it/s][A
 67%|██████▋   | 148/221 [00:57<00:17,  4.19it/s][A
 67%|██████▋   | 149/221 [00:57<00:16,  4.49it/s][A
 68%|██████▊   | 150/221 [00:58<00:16,  4.25it/s][A
 68%|██████▊   | 151/221 [00:58<00:19,  3.59it/s][A
 69%|██████▉   | 153/221 [00:58<00:13,  5.15it/s][A
 70%|███████   | 155/221 [00:58<00:11,  5.66it/s][A[h264 @ 0x55e1918f3140] mmco: unref short failure
[h264 @ 0x55e1918f3140] mmco: unref short failure
[h264 @ 0x55e1918f3140] mmco: unref short failure
[h264 @ 0x55e1918f3140] mmco: unref short failure
[h264 @ 0x55a26a3be400] mmco: unref short failure
[h264 @ 0x55a26a3be400] mmco: unref short failure

 71%|███████   | 156/221 [01:03<01:21,  1.26s/it][A
 71%|███████   | 157/221 [01:04<01:04,  1.00s/it][A
 71%|███████▏  | 158/221 [01:04<00:48,  1.29it/s][A
 72%|███████▏  | 159/221 [01:04<00:36,  1.68it/s][A
 72%|███████▏  | 160/221 [01:04<00:28,  2.18it/s][A
 73%|███████▎  | 161/221 [01:04<00:21,  2.76it/s][A
 73%|███████▎  | 162/221 [01:04<00:19,  2.98it/s][A
 74%|███████▍  | 163/221 [01:05<00:18,  3.22it/s][A
 74%|███████▍  | 164/221 [01:05<00:14,  3.89it/s][A[h264 @ 0x560698297e00] mmco: unref short failure
[h264 @ 0x560698297e00] mmco: unref short failure
[h264 @ 0x55b507317780] mmco: unref short failure

 75%|███████▍  | 165/221 [01:10<01:34,  1.69s/it][A09/16/2024 23:37:29 - INFO - __main__ -   current idx 3_mqkjCXK8E.83 from finetune_area returns wrong image/video, use 111731 instead.

 76%|███████▌  | 167/221 [01:14<01:38,  1.83s/it][A
 76%|███████▌  | 168/221 [01:14<01:14,  1.40s/it][A
 76%|███████▋  | 169/221 [01:14<00:59,  1.14s/it][A
 77%|███████▋  | 170/221 [01:15<00:47,  1.08it/s][A
 77%|███████▋  | 171/221 [01:15<00:35,  1.40it/s][A
 78%|███████▊  | 173/221 [01:15<00:21,  2.28it/s][A
 79%|███████▊  | 174/221 [01:15<00:17,  2.70it/s][A
 79%|███████▉  | 175/221 [01:15<00:15,  3.06it/s][A
 80%|███████▉  | 176/221 [01:16<00:12,  3.65it/s][A
 80%|████████  | 177/221 [01:16<00:11,  3.96it/s][A[h264 @ 0x56068d1994c0] mmco: unref short failure

 81%|████████  | 178/221 [01:20<01:01,  1.43s/it][A
 81%|████████▏ | 180/221 [01:20<00:33,  1.21it/s][A
 82%|████████▏ | 181/221 [01:20<00:26,  1.53it/s][A
 82%|████████▏ | 182/221 [01:21<00:20,  1.90it/s][A
 83%|████████▎ | 183/221 [01:21<00:16,  2.33it/s][A
 83%|████████▎ | 184/221 [01:21<00:12,  2.86it/s][A
 84%|████████▎ | 185/221 [01:21<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [01:21<00:08,  3.98it/s][A
 85%|████████▌ | 188/221 [01:21<00:06,  5.01it/s][A
 86%|████████▌ | 189/221 [01:22<00:06,  5.01it/s][A
 86%|████████▋ | 191/221 [01:22<00:04,  6.79it/s][A
 87%|████████▋ | 193/221 [01:22<00:03,  8.71it/s][A
 88%|████████▊ | 195/221 [01:22<00:02, 10.40it/s][A
 89%|████████▉ | 197/221 [01:22<00:02, 10.68it/s][A
 90%|█████████ | 199/221 [01:22<00:02, 10.87it/s][A
 91%|█████████ | 201/221 [01:23<00:02,  9.97it/s][A
 92%|█████████▏| 203/221 [01:23<00:02,  8.52it/s][A
 92%|█████████▏| 204/221 [01:23<00:02,  8.29it/s][A
 93%|█████████▎| 205/221 [01:23<00:02,  6.78it/s][A
 94%|█████████▎| 207/221 [01:23<00:01,  8.43it/s][A
 95%|█████████▍| 209/221 [01:24<00:01,  9.72it/s][A
 95%|█████████▌| 211/221 [01:24<00:01,  6.72it/s][A
 96%|█████████▌| 212/221 [01:24<00:01,  6.69it/s][A
 96%|█████████▋| 213/221 [01:25<00:01,  5.45it/s][A
 97%|█████████▋| 215/221 [01:25<00:00,  6.76it/s][A
 98%|█████████▊| 216/221 [01:30<00:05,  1.18s/it][A
 99%|█████████▊| 218/221 [01:30<00:02,  1.31it/s][A09/16/2024 23:37:48 - INFO - __main__ -   current idx 6mjP2GVtPHA.82 from finetune_area returns wrong image/video, use 90531 instead.

 99%|█████████▉| 219/221 [01:35<00:03,  1.68s/it][A100%|█████████▉| 220/221 [01:35<00:00,  2.30it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:04,  3.41it/s][A
  1%|          | 2/221 [00:00<01:04,  3.38it/s][A
  1%|▏         | 3/221 [00:00<01:04,  3.39it/s][A
  2%|▏         | 4/221 [00:01<01:04,  3.37it/s][A
  2%|▏         | 5/221 [00:01<01:04,  3.34it/s][A
  3%|▎         | 6/221 [00:01<01:04,  3.34it/s][A
  3%|▎         | 7/221 [00:02<01:04,  3.31it/s][A
  4%|▎         | 8/221 [00:02<01:04,  3.28it/s][A
  4%|▍         | 9/221 [00:02<01:03,  3.32it/s][A
  5%|▍         | 10/221 [00:02<01:03,  3.33it/s][A
  5%|▍         | 11/221 [00:03<01:03,  3.30it/s][A09/16/2024 23:37:58 - INFO - __main__ -   current idx DnpQpBpq4-8.30 from finetune_area returns wrong image/video, use 60115 instead.

  5%|▌         | 12/221 [00:03<01:03,  3.31it/s][A
  6%|▌         | 13/221 [00:03<01:02,  3.34it/s][A
  6%|▋         | 14/221 [00:04<01:01,  3.36it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.35it/s][A
  7%|▋         | 16/221 [00:04<01:01,  3.33it/s][A
  8%|▊         | 17/221 [00:05<01:02,  3.25it/s][A
  8%|▊         | 18/221 [00:05<01:02,  3.26it/s][A
  9%|▊         | 19/221 [00:05<01:03,  3.16it/s][A
  9%|▉         | 20/221 [00:06<01:07,  2.97it/s][A
 10%|▉         | 21/221 [00:06<01:04,  3.09it/s][A[h264 @ 0x55a25cb7b140] mmco: unref short failure
[h264 @ 0x55a25cb7b140] mmco: unref short failure

 10%|▉         | 22/221 [00:06<01:03,  3.14it/s][A
 10%|█         | 23/221 [00:07<01:02,  3.18it/s][A
 11%|█         | 24/221 [00:07<01:00,  3.23it/s][A
 11%|█▏        | 25/221 [00:07<00:59,  3.28it/s][A
 12%|█▏        | 26/221 [00:07<00:59,  3.29it/s][A
 12%|█▏        | 27/221 [00:08<00:58,  3.32it/s][A
 13%|█▎        | 28/221 [00:08<00:58,  3.30it/s][A
 13%|█▎        | 29/221 [00:08<00:57,  3.33it/s][A
 14%|█▎        | 30/221 [00:09<00:57,  3.33it/s][A
 14%|█▍        | 31/221 [00:09<00:57,  3.30it/s][A
 14%|█▍        | 32/221 [00:09<00:56,  3.32it/s][A
 15%|█▍        | 33/221 [00:10<00:57,  3.29it/s][A
 15%|█▌        | 34/221 [00:10<00:56,  3.32it/s][A
 16%|█▌        | 35/221 [00:10<00:55,  3.35it/s][A
 16%|█▋        | 36/221 [00:10<00:55,  3.35it/s][A
 17%|█▋        | 37/221 [00:11<00:54,  3.36it/s][A
 17%|█▋        | 38/221 [00:11<00:54,  3.38it/s][A[h264 @ 0x55a26bd1d080] mmco: unref short failure
[h264 @ 0x55a26bd1d080] mmco: unref short failure

 18%|█▊        | 39/221 [00:11<00:53,  3.38it/s][A
 18%|█▊        | 40/221 [00:12<00:53,  3.35it/s][A
 19%|█▊        | 41/221 [00:12<00:53,  3.37it/s][A
 19%|█▉        | 42/221 [00:12<00:52,  3.38it/s][A
 19%|█▉        | 43/221 [00:13<00:53,  3.33it/s][A
 20%|█▉        | 44/221 [00:13<00:52,  3.35it/s][A
 20%|██        | 45/221 [00:13<00:52,  3.37it/s][A
 21%|██        | 46/221 [00:14<00:58,  3.01it/s][A
 21%|██▏       | 47/221 [00:14<00:56,  3.08it/s][A
 22%|██▏       | 48/221 [00:14<00:55,  3.14it/s][A
 22%|██▏       | 49/221 [00:14<00:53,  3.21it/s][A
 23%|██▎       | 50/221 [00:15<00:52,  3.24it/s][A
 23%|██▎       | 51/221 [00:15<00:51,  3.28it/s][A
 24%|██▎       | 52/221 [00:15<00:50,  3.32it/s][A
 24%|██▍       | 53/221 [00:16<00:50,  3.34it/s][A
 24%|██▍       | 54/221 [00:16<00:49,  3.36it/s][A
09/16/2024 23:38:11 - INFO - __main__ -   current idx Lzt-UMekcLY.51 from finetune_area returns wrong image/video, use 144801 instead.
 25%|██▍       | 55/221 [00:16<00:49,  3.37it/s][A
 25%|██▌       | 56/221 [00:17<00:49,  3.36it/s][A
 26%|██▌       | 57/221 [00:17<00:48,  3.36it/s][A
 26%|██▌       | 58/221 [00:17<00:48,  3.37it/s][A
 27%|██▋       | 59/221 [00:17<00:48,  3.37it/s][A
 27%|██▋       | 60/221 [00:18<00:48,  3.35it/s][A
 28%|██▊       | 61/221 [00:18<00:47,  3.36it/s][A
 28%|██▊       | 62/221 [00:18<00:47,  3.34it/s][A
 29%|██▊       | 63/221 [00:19<00:47,  3.36it/s][A
 29%|██▉       | 64/221 [00:19<00:47,  3.32it/s][A
 29%|██▉       | 65/221 [00:19<00:46,  3.34it/s][A
 30%|██▉       | 66/221 [00:19<00:46,  3.36it/s][A
 30%|███       | 67/221 [00:20<00:45,  3.35it/s][A
 31%|███       | 68/221 [00:20<00:45,  3.36it/s][A
 31%|███       | 69/221 [00:20<00:45,  3.37it/s][A
 32%|███▏      | 70/221 [00:21<00:44,  3.38it/s][A
 32%|███▏      | 71/221 [00:21<00:44,  3.39it/s][A
 33%|███▎      | 72/221 [00:21<00:43,  3.39it/s][A
 33%|███▎      | 73/221 [00:22<00:43,  3.40it/s][A
 33%|███▎      | 74/221 [00:22<00:43,  3.40it/s][A
 34%|███▍      | 75/221 [00:22<00:42,  3.40it/s][A
 34%|███▍      | 76/221 [00:22<00:42,  3.41it/s][A
 35%|███▍      | 77/221 [00:23<00:42,  3.41it/s][A
 35%|███▌      | 78/221 [00:23<00:41,  3.41it/s][A
 36%|███▌      | 79/221 [00:23<00:41,  3.41it/s][A
 36%|███▌      | 80/221 [00:24<00:42,  3.29it/s][A
 37%|███▋      | 81/221 [00:24<00:42,  3.33it/s][A
 37%|███▋      | 82/221 [00:24<00:41,  3.35it/s][A
 38%|███▊      | 83/221 [00:25<00:40,  3.37it/s][A
 38%|███▊      | 84/221 [00:25<00:40,  3.39it/s][A
 38%|███▊      | 85/221 [00:25<00:40,  3.40it/s][A
 39%|███▉      | 86/221 [00:25<00:39,  3.40it/s][A
 39%|███▉      | 87/221 [00:26<00:39,  3.41it/s][A
 40%|███▉      | 88/221 [00:26<00:38,  3.41it/s][A
 40%|████      | 89/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 90/221 [00:27<00:38,  3.42it/s][A
 41%|████      | 91/221 [00:27<00:38,  3.42it/s][A
 42%|████▏     | 92/221 [00:27<00:37,  3.42it/s][A
 42%|████▏     | 93/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 94/221 [00:28<00:37,  3.42it/s][A
 43%|████▎     | 95/221 [00:28<00:36,  3.42it/s][A
 43%|████▎     | 96/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 97/221 [00:29<00:36,  3.42it/s][A
 44%|████▍     | 98/221 [00:29<00:35,  3.42it/s][A
 45%|████▍     | 99/221 [00:29<00:35,  3.42it/s][A
 45%|████▌     | 100/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 101/221 [00:30<00:35,  3.42it/s][A
 46%|████▌     | 102/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 104/221 [00:31<00:34,  3.42it/s][A
 48%|████▊     | 105/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 107/221 [00:32<00:33,  3.42it/s][A
 49%|████▉     | 108/221 [00:32<00:33,  3.42it/s][A
 49%|████▉     | 109/221 [00:32<00:32,  3.42it/s][A
 50%|████▉     | 110/221 [00:32<00:32,  3.42it/s][A
 50%|█████     | 111/221 [00:33<00:32,  3.42it/s][A
 51%|█████     | 112/221 [00:33<00:31,  3.42it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 114/221 [00:34<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:34<00:30,  3.42it/s][A
 52%|█████▏    | 116/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:35<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:35<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:36<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:37<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:37<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:38<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:39<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:39<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:40<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:41<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:41<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:42<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:43<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:44<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:44<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:45<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:45<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:46<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:46<00:19,  3.42it/s][A
 71%|███████   | 157/221 [00:46<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:47<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:48<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:48<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:48<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:49<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:49<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:50<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:50<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:51<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:51<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:52<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:53<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:54<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:55<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:55<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:56<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:57<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:57<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:58<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:59<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [01:00<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:02<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:05<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.42it/s][A100%|██████████| 221/221 [01:05<00:00,  3.38it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:30,  7.16it/s][A
  1%|          | 2/221 [00:00<01:14,  2.94it/s][A
  1%|▏         | 3/221 [00:01<01:28,  2.46it/s][A
  2%|▏         | 4/221 [00:01<01:17,  2.79it/s][A
  2%|▏         | 5/221 [00:01<01:05,  3.28it/s][A
  3%|▎         | 6/221 [00:01<00:53,  4.01it/s][A
  3%|▎         | 7/221 [00:01<00:45,  4.74it/s][A
  4%|▎         | 8/221 [00:02<00:46,  4.54it/s][A
  4%|▍         | 9/221 [00:02<01:21,  2.60it/s][A
  5%|▍         | 10/221 [00:03<01:21,  2.57it/s][A
  5%|▍         | 11/221 [00:03<01:23,  2.51it/s][A
  5%|▌         | 12/221 [00:03<01:18,  2.68it/s][A
  6%|▌         | 13/221 [00:04<01:35,  2.17it/s][A
  6%|▋         | 14/221 [00:04<01:22,  2.52it/s][A
  7%|▋         | 15/221 [00:05<01:18,  2.61it/s][A
  7%|▋         | 16/221 [00:05<01:11,  2.88it/s][A
  8%|▊         | 17/221 [00:06<01:21,  2.49it/s][A
  8%|▊         | 18/221 [00:06<01:21,  2.49it/s][A
  9%|▊         | 19/221 [00:06<01:13,  2.76it/s][A
  9%|▉         | 20/221 [00:06<01:03,  3.19it/s][A
 10%|▉         | 22/221 [00:07<00:51,  3.89it/s][A
 10%|█         | 23/221 [00:07<00:48,  4.08it/s][A
 11%|█         | 24/221 [00:07<00:45,  4.34it/s][A
 11%|█▏        | 25/221 [00:07<00:43,  4.53it/s][A
 12%|█▏        | 26/221 [00:08<00:40,  4.82it/s][A
 12%|█▏        | 27/221 [00:08<00:46,  4.19it/s][A
 13%|█▎        | 28/221 [00:08<00:51,  3.76it/s][A
 13%|█▎        | 29/221 [00:09<01:06,  2.88it/s][A
 14%|█▎        | 30/221 [00:09<00:58,  3.26it/s][A
 14%|█▍        | 31/221 [00:09<00:52,  3.62it/s][A
 14%|█▍        | 32/221 [00:10<00:58,  3.22it/s][A
 15%|█▍        | 33/221 [00:10<00:51,  3.62it/s][A
 15%|█▌        | 34/221 [00:10<00:50,  3.71it/s][A
 16%|█▌        | 35/221 [00:10<00:42,  4.34it/s][A
 16%|█▋        | 36/221 [00:11<00:53,  3.45it/s][A
 17%|█▋        | 37/221 [00:11<00:52,  3.49it/s][A
 17%|█▋        | 38/221 [00:11<00:49,  3.67it/s][A
 18%|█▊        | 39/221 [00:11<00:47,  3.85it/s][A
 18%|█▊        | 40/221 [00:12<00:42,  4.22it/s][A
 19%|█▊        | 41/221 [00:12<00:39,  4.52it/s][A
 19%|█▉        | 42/221 [00:12<00:35,  5.01it/s][A
 19%|█▉        | 43/221 [00:12<00:44,  3.96it/s][A
 20%|█▉        | 44/221 [00:12<00:45,  3.91it/s][A
 20%|██        | 45/221 [00:13<01:03,  2.78it/s][A
 21%|██        | 46/221 [00:13<01:04,  2.73it/s][A
 21%|██▏       | 47/221 [00:14<00:51,  3.35it/s][A
 22%|██▏       | 48/221 [00:14<00:42,  4.10it/s][A
 23%|██▎       | 50/221 [00:14<00:42,  3.99it/s][A
 23%|██▎       | 51/221 [00:14<00:40,  4.20it/s][A
 24%|██▎       | 52/221 [00:15<00:35,  4.71it/s][A
 24%|██▍       | 53/221 [00:15<00:44,  3.74it/s][A
 24%|██▍       | 54/221 [00:15<00:47,  3.54it/s][A
 25%|██▍       | 55/221 [00:15<00:41,  3.99it/s][A
 25%|██▌       | 56/221 [00:16<00:44,  3.71it/s][A
 26%|██▌       | 57/221 [00:16<00:46,  3.51it/s][A
 26%|██▌       | 58/221 [00:16<00:40,  4.01it/s][A
 27%|██▋       | 59/221 [00:17<00:39,  4.07it/s][A
 27%|██▋       | 60/221 [00:17<00:36,  4.43it/s][A
 28%|██▊       | 61/221 [00:17<00:43,  3.71it/s][A
 28%|██▊       | 62/221 [00:17<00:41,  3.83it/s][A
 29%|██▊       | 63/221 [00:18<00:39,  3.96it/s][A
 29%|██▉       | 64/221 [00:18<00:34,  4.60it/s][A
 29%|██▉       | 65/221 [00:18<00:36,  4.33it/s][A
 30%|██▉       | 66/221 [00:18<00:44,  3.49it/s][A
 30%|███       | 67/221 [00:19<00:48,  3.20it/s][A
 31%|███       | 68/221 [00:19<00:51,  2.96it/s][A
 31%|███       | 69/221 [00:20<01:14,  2.04it/s][A
 32%|███▏      | 70/221 [00:20<01:03,  2.39it/s][A
 32%|███▏      | 71/221 [00:21<01:00,  2.49it/s][A
 33%|███▎      | 72/221 [00:21<00:54,  2.71it/s][A
 33%|███▎      | 73/221 [00:21<00:53,  2.77it/s][A
 33%|███▎      | 74/221 [00:21<00:44,  3.31it/s][A
 34%|███▍      | 75/221 [00:22<00:45,  3.19it/s][A
 34%|███▍      | 76/221 [00:22<00:46,  3.15it/s][A
 35%|███▍      | 77/221 [00:22<00:38,  3.77it/s][A
 35%|███▌      | 78/221 [00:23<00:42,  3.36it/s][A
 36%|███▌      | 79/221 [00:23<00:35,  3.98it/s][A
 36%|███▌      | 80/221 [00:23<00:34,  4.04it/s][A
 37%|███▋      | 81/221 [00:23<00:31,  4.44it/s][A
 37%|███▋      | 82/221 [00:23<00:34,  3.97it/s][A
 38%|███▊      | 83/221 [00:24<00:32,  4.21it/s][A
 38%|███▊      | 84/221 [00:24<00:42,  3.24it/s][A
 38%|███▊      | 85/221 [00:24<00:42,  3.20it/s][A
 39%|███▉      | 86/221 [00:25<00:34,  3.97it/s][A
 39%|███▉      | 87/221 [00:25<00:43,  3.08it/s][A
 40%|███▉      | 88/221 [00:25<00:39,  3.34it/s][A
 40%|████      | 89/221 [00:26<00:46,  2.83it/s][A
 41%|████      | 90/221 [00:26<00:48,  2.69it/s][A
 41%|████      | 91/221 [00:26<00:38,  3.34it/s][A
 42%|████▏     | 92/221 [00:27<00:36,  3.58it/s][A
 42%|████▏     | 93/221 [00:27<00:40,  3.19it/s][A
 43%|████▎     | 94/221 [00:27<00:41,  3.08it/s][A
 43%|████▎     | 95/221 [00:28<00:58,  2.17it/s][A
 43%|████▎     | 96/221 [00:28<00:51,  2.43it/s][A
 44%|████▍     | 97/221 [00:29<00:47,  2.59it/s][A
 44%|████▍     | 98/221 [00:29<00:48,  2.52it/s][A
 45%|████▍     | 99/221 [00:29<00:44,  2.75it/s][A
 45%|████▌     | 100/221 [00:30<00:45,  2.67it/s][A
 46%|████▌     | 101/221 [00:30<00:39,  3.05it/s][A
 46%|████▌     | 102/221 [00:30<00:39,  3.01it/s][A
 47%|████▋     | 103/221 [00:31<00:35,  3.35it/s][A
 48%|████▊     | 105/221 [00:31<00:26,  4.46it/s][A
 48%|████▊     | 106/221 [00:31<00:30,  3.82it/s][A
 49%|████▉     | 108/221 [00:31<00:21,  5.28it/s][A
 49%|████▉     | 109/221 [00:32<00:21,  5.22it/s][A
 50%|████▉     | 110/221 [00:32<00:22,  4.91it/s][A
 50%|█████     | 111/221 [00:32<00:25,  4.30it/s][A
 51%|█████     | 112/221 [00:33<00:29,  3.69it/s][A
 51%|█████     | 113/221 [00:33<00:29,  3.72it/s][A
 52%|█████▏    | 114/221 [00:33<00:23,  4.50it/s][A
 52%|█████▏    | 116/221 [00:33<00:20,  5.18it/s][A
 53%|█████▎    | 117/221 [00:33<00:20,  5.02it/s][A
 53%|█████▎    | 118/221 [00:34<00:23,  4.41it/s][A
 54%|█████▍    | 119/221 [00:34<00:28,  3.60it/s][A
 54%|█████▍    | 120/221 [00:35<00:30,  3.28it/s][A
 55%|█████▍    | 121/221 [00:35<00:30,  3.32it/s][A
 55%|█████▌    | 122/221 [00:35<00:30,  3.28it/s][A
 56%|█████▌    | 123/221 [00:35<00:26,  3.67it/s][A
 56%|█████▌    | 124/221 [00:36<00:34,  2.85it/s][A
 57%|█████▋    | 125/221 [00:36<00:37,  2.58it/s][A
 57%|█████▋    | 126/221 [00:37<00:33,  2.82it/s][A
 57%|█████▋    | 127/221 [00:37<00:33,  2.84it/s][A
 58%|█████▊    | 128/221 [00:37<00:29,  3.11it/s][A
 58%|█████▊    | 129/221 [00:37<00:24,  3.78it/s][A
 59%|█████▉    | 130/221 [00:38<00:22,  4.04it/s][A
 59%|█████▉    | 131/221 [00:38<00:20,  4.34it/s][A
 60%|█████▉    | 132/221 [00:38<00:27,  3.26it/s][A
 60%|██████    | 133/221 [00:39<00:30,  2.91it/s][A
 61%|██████    | 134/221 [00:39<00:31,  2.80it/s][A
 61%|██████    | 135/221 [00:39<00:28,  3.05it/s][A
 62%|██████▏   | 136/221 [00:40<00:27,  3.04it/s][A
 62%|██████▏   | 137/221 [00:40<00:26,  3.20it/s][A
 62%|██████▏   | 138/221 [00:40<00:23,  3.50it/s][A
 63%|██████▎   | 139/221 [00:41<00:28,  2.83it/s][A
 63%|██████▎   | 140/221 [00:41<00:25,  3.19it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.36it/s][A
 64%|██████▍   | 142/221 [00:41<00:20,  3.79it/s][A
 65%|██████▍   | 143/221 [00:42<00:23,  3.29it/s][A
 65%|██████▌   | 144/221 [00:42<00:21,  3.54it/s][A
 66%|██████▌   | 145/221 [00:43<00:27,  2.74it/s][A
 66%|██████▌   | 146/221 [00:43<00:25,  2.91it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.46it/s][A
 67%|██████▋   | 148/221 [00:44<00:30,  2.40it/s][A
 67%|██████▋   | 149/221 [00:44<00:24,  2.89it/s][A
 68%|██████▊   | 150/221 [00:44<00:22,  3.21it/s][A
 68%|██████▊   | 151/221 [00:45<00:34,  2.04it/s][A
 69%|██████▉   | 152/221 [00:46<00:36,  1.90it/s][A
 69%|██████▉   | 153/221 [00:46<00:31,  2.19it/s][A
 70%|██████▉   | 154/221 [00:46<00:25,  2.67it/s][A
 70%|███████   | 155/221 [00:46<00:22,  2.94it/s][A
 71%|███████   | 156/221 [00:47<00:20,  3.17it/s][A
 71%|███████   | 157/221 [00:47<00:19,  3.34it/s][A
 71%|███████▏  | 158/221 [00:47<00:18,  3.41it/s][A
 72%|███████▏  | 159/221 [00:47<00:16,  3.82it/s][A
 72%|███████▏  | 160/221 [00:48<00:18,  3.29it/s][A
 73%|███████▎  | 162/221 [00:48<00:12,  4.79it/s][A
 74%|███████▍  | 163/221 [00:48<00:11,  4.88it/s][A
 74%|███████▍  | 164/221 [00:48<00:12,  4.49it/s][A
 75%|███████▍  | 165/221 [00:49<00:13,  4.21it/s][A
 75%|███████▌  | 166/221 [00:49<00:15,  3.45it/s][A
 76%|███████▌  | 167/221 [00:49<00:14,  3.78it/s][A
 76%|███████▌  | 168/221 [00:50<00:13,  3.83it/s][A
 77%|███████▋  | 170/221 [00:50<00:13,  3.90it/s][A
 77%|███████▋  | 171/221 [00:51<00:15,  3.22it/s][A
 78%|███████▊  | 172/221 [00:51<00:14,  3.47it/s][A
 78%|███████▊  | 173/221 [00:51<00:14,  3.38it/s][A
 79%|███████▊  | 174/221 [00:51<00:14,  3.28it/s][A
 79%|███████▉  | 175/221 [00:52<00:14,  3.08it/s][A
 80%|███████▉  | 176/221 [00:52<00:11,  3.78it/s][A
 80%|████████  | 177/221 [00:52<00:10,  4.18it/s][A
 81%|████████  | 178/221 [00:53<00:15,  2.77it/s][A
 81%|████████  | 179/221 [00:53<00:14,  2.82it/s][A
 81%|████████▏ | 180/221 [00:53<00:11,  3.52it/s][A
 82%|████████▏ | 181/221 [00:54<00:12,  3.21it/s][A
 82%|████████▏ | 182/221 [00:54<00:10,  3.86it/s][A
 83%|████████▎ | 183/221 [00:54<00:10,  3.72it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:55<00:09,  3.64it/s][A
 84%|████████▍ | 186/221 [00:55<00:12,  2.87it/s][A
 85%|████████▌ | 188/221 [00:55<00:08,  3.83it/s][A
 86%|████████▌ | 189/221 [00:56<00:07,  4.09it/s][A
 86%|████████▌ | 190/221 [00:56<00:08,  3.81it/s][A
 86%|████████▋ | 191/221 [00:56<00:06,  4.55it/s][A
 87%|████████▋ | 192/221 [00:56<00:06,  4.52it/s][A
 87%|████████▋ | 193/221 [00:57<00:07,  3.78it/s][A
 88%|████████▊ | 194/221 [00:57<00:07,  3.52it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.63it/s][A
 89%|████████▊ | 196/221 [00:58<00:08,  3.02it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.36it/s][A
 90%|████████▉ | 198/221 [00:58<00:07,  3.09it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.53it/s][A
 90%|█████████ | 200/221 [00:59<00:05,  3.92it/s][A
 91%|█████████ | 201/221 [00:59<00:04,  4.39it/s][A
 91%|█████████▏| 202/221 [00:59<00:04,  4.69it/s][A
 92%|█████████▏| 203/221 [00:59<00:03,  4.52it/s][A
 92%|█████████▏| 204/221 [00:59<00:03,  4.53it/s][A
 93%|█████████▎| 205/221 [01:00<00:03,  4.70it/s][A
 93%|█████████▎| 206/221 [01:00<00:03,  3.83it/s][A
 94%|█████████▎| 207/221 [01:00<00:04,  3.15it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.53it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.50it/s][A
 95%|█████████▌| 210/221 [01:01<00:03,  3.40it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.59it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.57it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.52it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  2.62it/s][A
 97%|█████████▋| 215/221 [01:03<00:02,  2.84it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  2.81it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  2.83it/s][A
 99%|█████████▊| 218/221 [01:04<00:01,  2.72it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  2.71it/s][A
100%|█████████▉| 220/221 [01:05<00:00,  3.13it/s][A
100%|██████████| 221/221 [01:05<00:00,  2.82it/s][A100%|██████████| 221/221 [01:05<00:00,  3.37it/s]
09/16/2024 23:40:07 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 49--===========

09/16/2024 23:40:07 - INFO - __main__ -   {'area_r1': 33.6, 'area_recall': '33.6/54.1/60.4', 'area_ravg': 49.4}
09/16/2024 23:40:07 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 49--===========

09/16/2024 23:40:07 - INFO - __main__ -   {'forward_r1': 36.0, 'forward_recall': '36.0/67.0/77.5', 'forward_ravg': 60.1}
09/16/2024 23:40:07 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 49--===========

09/16/2024 23:40:07 - INFO - __main__ -   {'area_video_r1': 36.9, 'area_video_recall': '36.9/67.2/77.8', 'area_video_ravg': 60.6}
09/16/2024 23:40:07 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 49=======

09/16/2024 23:40:07 - INFO - __main__ -   {'area_video_r1': 36.9, 'area_video_recall': '36.9/67.2/77.8', 'area_video_ravg': 60.6}
09/16/2024 23:40:07 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 49--===========

09/16/2024 23:40:07 - INFO - __main__ -   {'area_video_r1': 49.2, 'area_video_recall': '49.2/69.5/76.6', 'area_video_ravg': 65.1, 'area_video_back_r1': 45.2, 'area_video_back_recall': '45.2/70.8/79.9', 'area_video_back_ravg': 65.3}
09/16/2024 23:40:07 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 49=======

09/16/2024 23:40:07 - INFO - __main__ -   {'area_video_r1': 49.2, 'area_video_recall': '49.2/69.5/76.6', 'area_video_ravg': 65.1, 'area_video_back_r1': 45.2, 'area_video_back_recall': '45.2/70.8/79.9', 'area_video_back_ravg': 65.3}
09/16/2024 23:40:07 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 49--===========

09/16/2024 23:40:07 - INFO - __main__ -   {'video_r1': 37.0, 'video_recall': '37.0/65.4/73.9', 'video_ravg': 58.7}
09/16/2024 23:40:07 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 49=======

09/16/2024 23:40:07 - INFO - __main__ -   {'video_r1': 37.0, 'video_recall': '37.0/65.4/73.9', 'video_ravg': 58.7}
09/16/2024 23:40:07 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 49--===========

09/16/2024 23:40:07 - INFO - __main__ -   {'video_r1': 50.8, 'video_recall': '50.8/71.8/79.8', 'video_ravg': 67.5}
09/16/2024 23:40:07 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 49=======

09/16/2024 23:40:07 - INFO - __main__ -   {'video_r1': 50.8, 'video_recall': '50.8/71.8/79.8', 'video_ravg': 67.5}
09/16/2024 23:40:45 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.0077205924317240715, 'loss_ret%tv%ta--finetune_area/loss_area': 4.376612186431885, 'loss_ret%tv%ta--finetune_area/total_loss': 4.384332656860352}
[h264 @ 0x55e1881d81c0] mmco: unref short failure
[h264 @ 0x55e1881d81c0] mmco: unref short failure
[h264 @ 0x55e1881d81c0] mmco: unref short failure
[h264 @ 0x55e1881d81c0] mmco: unref short failure
[h264 @ 0x55a262df7740] mmco: unref short failure
[h264 @ 0x55a262df7740] mmco: unref short failure
  2%|▏         | 50/2910 [19:02<111:52:13, 140.82s/it]  2%|▏         | 51/2910 [19:05<79:07:43, 99.64s/it]    2%|▏         | 52/2910 [19:09<56:21:42, 70.99s/it][h264 @ 0x55e18b9ad940] mmco: unref short failure
[h264 @ 0x55e18b9ad940] mmco: unref short failure
[h264 @ 0x55a2614b8780] mmco: unref short failure
  2%|▏         | 53/2910 [19:13<40:24:06, 50.91s/it]  2%|▏         | 54/2910 [19:18<29:26:30, 37.11s/it]  2%|▏         | 55/2910 [19:24<21:51:42, 27.57s/it][h264 @ 0x55b50c98db00] mmco: unref short failure
[h264 @ 0x55a2674e2dc0] mmco: unref short failure
  2%|▏         | 56/2910 [19:29<16:36:03, 20.94s/it]  2%|▏         | 57/2910 [19:34<12:47:39, 16.14s/it][h264 @ 0x55e195664740] mmco: unref short failure
[h264 @ 0x55a25cb7b3c0] mmco: unref short failure
  2%|▏         | 58/2910 [19:39<10:09:16, 12.82s/it][h264 @ 0x55a262a19740] mmco: unref short failure
[h264 @ 0x55a25bee4400] mmco: unref short failure
[h264 @ 0x55a25bee4400] mmco: unref short failure
[h264 @ 0x55b4f7b77f40] mmco: unref short failure
[h264 @ 0x55b4f7b77f40] mmco: unref short failure
  2%|▏         | 59/2910 [19:44<8:16:44, 10.45s/it] [h264 @ 0x55b4fb43c7c0] mmco: unref short failure
[h264 @ 0x55b4fb43c7c0] mmco: unref short failure
  2%|▏         | 60/2910 [19:49<6:54:19,  8.72s/it][h264 @ 0x560694de2980] mmco: unref short failure
[h264 @ 0x560694de2980] mmco: unref short failure
[h264 @ 0x55a2674e2fc0] mmco: unref short failure
[h264 @ 0x55a2674e2fc0] mmco: unref short failure
  2%|▏         | 61/2910 [19:54<6:06:13,  7.71s/it]  2%|▏         | 62/2910 [19:59<5:27:28,  6.90s/it][h264 @ 0x55b5009cf340] mmco: unref short failure
[h264 @ 0x55b5009cf340] mmco: unref short failure
  2%|▏         | 63/2910 [20:04<5:04:41,  6.42s/it][h264 @ 0x55b4f5cd0000] mmco: unref short failure
  2%|▏         | 64/2910 [20:09<4:42:43,  5.96s/it][h264 @ 0x55b4f8250b40] mmco: unref short failure
[h264 @ 0x55b4f8250b40] mmco: unref short failure
[h264 @ 0x55a26a3be8c0] mmco: unref short failure
  2%|▏         | 65/2910 [20:15<4:36:22,  5.83s/it][h264 @ 0x55a275aa4300] mmco: unref short failure
[h264 @ 0x55a275aa4300] mmco: unref short failure
[h264 @ 0x55a27004d7c0] mmco: unref short failure
[h264 @ 0x55a27004d7c0] mmco: unref short failure
[h264 @ 0x55b50570cd00] mmco: unref short failure
[h264 @ 0x55e18ebd9400] mmco: unref short failure
[h264 @ 0x55e18e709800] mmco: unref short failure
[h264 @ 0x5606973b7480] mmco: unref short failure
[h264 @ 0x5606973b7480] mmco: unref short failure
[h264 @ 0x5606a4ca7b80] mmco: unref short failure
[h264 @ 0x5606a4ca7b80] mmco: unref short failure
[h264 @ 0x55b506d88d40] mmco: unref short failure
09/16/2024 23:42:34 - INFO - __main__ -   current idx LGB6ZEjGm7Q.29 from finetune_area returns wrong image/video, use 134176 instead.
[h264 @ 0x55b4faf3d340] mmco: unref short failure
[h264 @ 0x55b4faf3d340] mmco: unref short failure
[h264 @ 0x55a27516cb40] mmco: unref short failure
[h264 @ 0x55a27516cb40] mmco: unref short failure
09/16/2024 23:42:47 - INFO - __main__ -   current idx AqyH6qo2WI0.9 from finetune_area returns wrong image/video, use 117540 instead.
[h264 @ 0x55a26ee73280] mmco: unref short failure
[h264 @ 0x55e18de71e00] mmco: unref short failure
[h264 @ 0x55e18de71e00] mmco: unref short failure
[h264 @ 0x55a27140dac0] mmco: unref short failure
[h264 @ 0x5606951fe7c0] mmco: unref short failure
[h264 @ 0x5606951fe7c0] mmco: unref short failure
[h264 @ 0x5606a4272840] mmco: unref short failure
  2%|▏         | 66/2910 [21:20<18:45:32, 23.75s/it][h264 @ 0x55a275667000] mmco: unref short failure
[h264 @ 0x55a275667000] mmco: unref short failure
[h264 @ 0x55a275667000] mmco: unref short failure
[h264 @ 0x55b5035e6740] mmco: unref short failure
  2%|▏         | 67/2910 [21:26<14:26:23, 18.28s/it][h264 @ 0x56069a7af880] mmco: unref short failure
[h264 @ 0x56069a7af880] mmco: unref short failure
  2%|▏         | 68/2910 [21:31<11:17:53, 14.31s/it][h264 @ 0x55e19cbeb540] mmco: unref short failure
[h264 @ 0x55e19cbeb540] mmco: unref short failure
  2%|▏         | 69/2910 [21:48<11:52:18, 15.04s/it][h264 @ 0x5606939ef740] mmco: unref short failure
[h264 @ 0x5606939ef740] mmco: unref short failure
[h264 @ 0x55a26fac7cc0] mmco: unref short failure
[h264 @ 0x55a26fac7cc0] mmco: unref short failure
[h264 @ 0x56069a5ceac0] mmco: unref short failure
  2%|▏         | 70/2910 [21:57<10:25:18, 13.21s/it][h264 @ 0x55b5089b9cc0] mmco: unref short failure
[h264 @ 0x55b5089b9cc0] mmco: unref short failure
  2%|▏         | 71/2910 [22:06<9:36:18, 12.18s/it] [h264 @ 0x5606951e7840] mmco: unref short failure
[h264 @ 0x5606951e7840] mmco: unref short failure
  2%|▏         | 72/2910 [22:11<7:52:57, 10.00s/it][h264 @ 0x56069e608bc0] mmco: unref short failure
[h264 @ 0x56069e608bc0] mmco: unref short failure
[h264 @ 0x55b5009afd40] mmco: unref short failure
[h264 @ 0x55b5009afd40] mmco: unref short failure
  3%|▎         | 73/2910 [22:17<6:55:47,  8.79s/it][h264 @ 0x55e19a46fe00] mmco: unref short failure
09/16/2024 23:44:19 - INFO - __main__ -   current idx UGjfq2kyBqs.34 from finetune_area returns wrong image/video, use 93098 instead.
[h264 @ 0x55e18e343ec0] mmco: unref short failure
[h264 @ 0x55e18e343ec0] mmco: unref short failure
[h264 @ 0x5606939d7000] mmco: unref short failure
[h264 @ 0x55e18de71c00] mmco: unref short failure
[h264 @ 0x55b4f8fdd880] mmco: unref short failure
[h264 @ 0x55b4f8fdd880] mmco: unref short failure
09/16/2024 23:44:54 - INFO - __main__ -   current idx 1cJZfRW1WbY.33 from finetune_area returns wrong image/video, use 109243 instead.
09/16/2024 23:44:58 - INFO - __main__ -   current idx Yn3caOZk6dk.38 from finetune_area returns wrong image/video, use 36582 instead.
[h264 @ 0x55e189d8c9c0] mmco: unref short failure
[h264 @ 0x55e189d8c9c0] mmco: unref short failure
[h264 @ 0x55e189d8c9c0] mmco: unref short failure
[h264 @ 0x55e189d8c9c0] mmco: unref short failure
[h264 @ 0x55e189d8c9c0] mmco: unref short failure
[h264 @ 0x55e189d8c9c0] mmco: unref short failure
[h264 @ 0x5606a07d2300] mmco: unref short failure
[h264 @ 0x56069eb79a80] mmco: unref short failure
[h264 @ 0x56069eb79a80] mmco: unref short failure
[h264 @ 0x56069eb79a80] mmco: unref short failure
[h264 @ 0x56069eb79a80] mmco: unref short failure
[h264 @ 0x560693e21100] mmco: unref short failure
[h264 @ 0x55b4ff502900] mmco: unref short failure
[h264 @ 0x55b4ff502900] mmco: unref short failure
  3%|▎         | 74/2910 [23:51<26:53:33, 34.14s/it][h264 @ 0x55b4f9d79d40] mmco: unref short failure
  3%|▎         | 75/2910 [23:56<20:01:29, 25.43s/it][h264 @ 0x55b4ffed3f40] mmco: unref short failure
[h264 @ 0x55b4ffed3f40] mmco: unref short failure
  3%|▎         | 76/2910 [24:01<15:17:42, 19.43s/it][h264 @ 0x55e18b9cb900] mmco: unref short failure
[h264 @ 0x55b4fee41580] mmco: unref short failure
  3%|▎         | 77/2910 [24:13<13:37:58, 17.32s/it][h264 @ 0x55b4f6201040] mmco: unref short failure
  3%|▎         | 78/2910 [24:19<10:55:41, 13.89s/it][h264 @ 0x55e19cbeae40] mmco: unref short failure
[h264 @ 0x55e19cbeae40] mmco: unref short failure
  3%|▎         | 79/2910 [24:27<9:32:03, 12.12s/it]   3%|▎         | 80/2910 [24:33<7:57:51, 10.13s/it][h264 @ 0x56069a3577c0] mmco: unref short failure
[h264 @ 0x56069a3577c0] mmco: unref short failure
  3%|▎         | 81/2910 [24:39<7:00:06,  8.91s/it][h264 @ 0x55e192bfd6c0] mmco: unref short failure
[h264 @ 0x55e192bfd6c0] mmco: unref short failure
[h264 @ 0x55e192bfd6c0] mmco: unref short failure
[h264 @ 0x55e192bfd6c0] mmco: unref short failure
[h264 @ 0x55b509a00e40] mmco: unref short failure
[h264 @ 0x55b509a00e40] mmco: unref short failure
[h264 @ 0x55e189607880] mmco: unref short failure
[h264 @ 0x55b5035e6500] mmco: unref short failure
[h264 @ 0x55b5035e6500] mmco: unref short failure
09/16/2024 23:47:25 - INFO - __main__ -   current idx cLYenAzoWwo.8 from finetune_area returns wrong image/video, use 12933 instead.
[h264 @ 0x55e1918f2ec0] mmco: unref short failure
[h264 @ 0x55e1918f2ec0] mmco: unref short failure
[h264 @ 0x55e1918f2ec0] mmco: unref short failure
[h264 @ 0x55a263740100] mmco: unref short failure
09/16/2024 23:47:34 - INFO - __main__ -   current idx bhKtsohT-Xg.14 from finetune_area returns wrong image/video, use 106581 instead.
[h264 @ 0x55a265221a00] mmco: unref short failure
[h264 @ 0x55a2705e6f80] mmco: unref short failure
  3%|▎         | 82/2910 [26:14<27:20:57, 34.82s/it][h264 @ 0x55a26c72d480] mmco: unref short failure
[h264 @ 0x55a26d9eee00] mmco: unref short failure
[h264 @ 0x55a26d9eee00] mmco: unref short failure
[h264 @ 0x55a26555e5c0] mmco: unref short failure
[h264 @ 0x55a26555e5c0] mmco: unref short failure
  3%|▎         | 83/2910 [26:20<20:30:58, 26.13s/it][h264 @ 0x55e19ee878c0] mmco: unref short failure
[h264 @ 0x55e19ee878c0] mmco: unref short failure
[h264 @ 0x55e1981cf900] mmco: unref short failure
[h264 @ 0x55e1981cf900] mmco: unref short failure
  3%|▎         | 84/2910 [26:25<15:34:26, 19.84s/it][h264 @ 0x55e18924c340] mmco: unref short failure
[h264 @ 0x55e18924c340] mmco: unref short failure
[h264 @ 0x5606a4d80900] mmco: unref short failure
  3%|▎         | 85/2910 [26:47<15:55:29, 20.29s/it][mov,mp4,m4a,3gp,3g2,mj2 @ 0x55a25ee5b840] moov atom not found
  3%|▎         | 86/2910 [26:52<12:28:39, 15.91s/it][h264 @ 0x55a270faa0c0] mmco: unref short failure
[h264 @ 0x55a270faa0c0] mmco: unref short failure
  3%|▎         | 87/2910 [26:57<9:57:47, 12.71s/it] [h264 @ 0x55e1888a0c80] mmco: unref short failure
[h264 @ 0x55e1888a0c80] mmco: unref short failure
  3%|▎         | 88/2910 [27:03<8:23:03, 10.70s/it]  3%|▎         | 89/2910 [27:09<7:09:31,  9.14s/it][h264 @ 0x560696b2aa80] mmco: unref short failure
[h264 @ 0x560696b2aa80] mmco: unref short failure
[h264 @ 0x560698e5e400] mmco: unref short failure
[h264 @ 0x560698e5e400] mmco: unref short failure
[h264 @ 0x560698e5e400] mmco: unref short failure
[h264 @ 0x560698e5e400] mmco: unref short failure
[h264 @ 0x55b4f447b2c0] mmco: unref short failure
[h264 @ 0x55b4f447b2c0] mmco: unref short failure
[h264 @ 0x55a276d53540] mmco: unref short failure
[h264 @ 0x55b509e3a980] mmco: unref short failure
[h264 @ 0x55b509e3a980] mmco: unref short failure
[h264 @ 0x56068ebf80c0] mmco: unref short failure
[h264 @ 0x56068ebf80c0] mmco: unref short failure
[h264 @ 0x56068ebf80c0] mmco: unref short failure
[h264 @ 0x56068ebf80c0] mmco: unref short failure
[h264 @ 0x55a25d1e7bc0] mmco: unref short failure
[h264 @ 0x55a25d1e7bc0] mmco: unref short failure
[h264 @ 0x55e189587ac0] mmco: unref short failure
[h264 @ 0x55e189587ac0] mmco: unref short failure
[h264 @ 0x55e189587ac0] mmco: unref short failure
[h264 @ 0x55e195d27600] mmco: unref short failure
[h264 @ 0x55a269f0ecc0] mmco: unref short failure
[h264 @ 0x55a269f0ecc0] mmco: unref short failure
[h264 @ 0x55e19cb72180] mmco: unref short failure
  3%|▎         | 90/2910 [28:45<27:40:07, 35.32s/it]  3%|▎         | 91/2910 [28:50<20:31:48, 26.22s/it][h264 @ 0x55a2638d6ec0] mmco: unref short failure
[h264 @ 0x55a2638d6ec0] mmco: unref short failure
  3%|▎         | 92/2910 [28:56<15:39:45, 20.01s/it][h264 @ 0x55a25bf85180] mmco: unref short failure
[h264 @ 0x55a25bf85180] mmco: unref short failure
[h264 @ 0x56068f9d29c0] mmco: unref short failure
  3%|▎         | 93/2910 [29:09<13:57:38, 17.84s/it]  3%|▎         | 94/2910 [29:19<12:09:06, 15.54s/it][h264 @ 0x56069a31be40] mmco: unref short failure
[h264 @ 0x56069a31be40] mmco: unref short failure
[h264 @ 0x55b50ca50140] mmco: unref short failure
[h264 @ 0x55b50ca50140] mmco: unref short failure
  3%|▎         | 95/2910 [29:32<11:32:05, 14.75s/it]  3%|▎         | 96/2910 [29:36<9:11:08, 11.75s/it] [h264 @ 0x55e185d12600] mmco: unref short failure
[h264 @ 0x55e1a1e00fc0] mmco: unref short failure
  3%|▎         | 97/2910 [29:42<7:48:48, 10.00s/it][h264 @ 0x55b4f2e2b140] mmco: unref short failure
[h264 @ 0x55b4f2e2b140] mmco: unref short failure
not have audios GAwav3sZcGw.4
[h264 @ 0x55e1888b2e40] mmco: unref short failure
[h264 @ 0x55e1888b2e40] mmco: unref short failure
[h264 @ 0x55b4f4473740] mmco: unref short failure
[h264 @ 0x55b4f4473740] mmco: unref short failure
[h264 @ 0x56068cb68380] mmco: unref short failure
[h264 @ 0x56068cb68380] mmco: unref short failure
[h264 @ 0x55b506412080] mmco: unref short failure
[h264 @ 0x55b506412080] mmco: unref short failure
[h264 @ 0x55b506412080] mmco: unref short failure
[h264 @ 0x55b506412080] mmco: unref short failure
[h264 @ 0x55a260ffcc80] mmco: unref short failure
[h264 @ 0x55a260ffcc80] mmco: unref short failure
[h264 @ 0x55a260ffcc80] mmco: unref short failure
[h264 @ 0x55a260ffcc80] mmco: unref short failure
09/16/2024 23:51:59 - INFO - __main__ -   current idx JRTVXn0PfXQ.11 from finetune_area returns wrong image/video, use 109641 instead.
[h264 @ 0x55a275afd1c0] mmco: unref short failure
[h264 @ 0x55b50daf7440] mmco: unref short failure
[h264 @ 0x55b50daf7440] mmco: unref short failure
[h264 @ 0x55b503a8d900] mmco: unref short failure
[h264 @ 0x55b503a8d900] mmco: unref short failure
[h264 @ 0x55b503a8d900] mmco: unref short failure
[h264 @ 0x55b503a8d900] mmco: unref short failure
[h264 @ 0x55a26d4a0ac0] mmco: unref short failure
[h264 @ 0x55a26d4a0ac0] mmco: unref short failure
[h264 @ 0x55b5060eb3c0] mmco: unref short failure
[h264 @ 0x55a263005240] mmco: unref short failure
[h264 @ 0x55a263005240] mmco: unref short failure
[h264 @ 0x5606a42a1240] mmco: unref short failure
[h264 @ 0x55b50d585700] mmco: unref short failure
[h264 @ 0x55b4f39be980] mmco: unref short failure
[h264 @ 0x55e19c73dd80] mmco: unref short failure
[h264 @ 0x55a275acf780] mmco: unref short failure
[h264 @ 0x55a275acf780] mmco: unref short failure
[h264 @ 0x55a25f6984c0] mmco: unref short failure
[h264 @ 0x55a272988780] mmco: unref short failure
[h264 @ 0x55e19943dd40] mmco: unref short failure
[h264 @ 0x55e19943dd40] mmco: unref short failure
[h264 @ 0x55e19943dd40] mmco: unref short failure
[h264 @ 0x55e19943dd40] mmco: unref short failure
[h264 @ 0x55e19a2b09c0] mmco: unref short failure
[h264 @ 0x55a264d12100] mmco: unref short failure
[h264 @ 0x55a264d12100] mmco: unref short failure
[h264 @ 0x5606a35c4880] mmco: unref short failure
[h264 @ 0x55b509686000] mmco: unref short failure
[h264 @ 0x55b509686000] mmco: unref short failure
[h264 @ 0x55b5076d78c0] mmco: unref short failure
[h264 @ 0x55b5076d78c0] mmco: unref short failure
  3%|▎         | 98/2910 [31:08<25:28:45, 32.62s/it][h264 @ 0x55b5048f7fc0] mmco: unref short failure
  3%|▎         | 99/2910 [31:14<19:11:04, 24.57s/it]09/16/2024 23:52:59 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/16/2024 23:52:59 - INFO - __main__ -   start running ret%tva validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55b50ca50140] mmco: unref short failure
[h264 @ 0x55b50ca50140] mmco: unref short failure
[h264 @ 0x55b50ca50140] mmco: unref short failure
[h264 @ 0x55b50ca50140] mmco: unref short failure
[h264 @ 0x55a279eb0040] mmco: unref short failure
[h264 @ 0x55a279eb0040] mmco: unref short failure
[h264 @ 0x55b508fa0140] mmco: unref short failure
[h264 @ 0x55b508fa0140] mmco: unref short failure
[h264 @ 0x55a260c00540] mmco: unref short failure
[h264 @ 0x55a260c00540] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
09/16/2024 23:53:42 - INFO - __main__ -   current idx AXNTPfihw4Y.36 from finetune_area returns wrong image/video, use 138393 instead.
[h264 @ 0x55e19843ba00] mmco: unref short failure
[h264 @ 0x5606a39bf200] mmco: unref short failure
[h264 @ 0x5606a39bf200] mmco: unref short failure
[h264 @ 0x55e18593bb00] mmco: unref short failure
[h264 @ 0x55e18593bb00] mmco: unref short failure
[h264 @ 0x55a25c0b0080] mmco: unref short failure
[h264 @ 0x55a25c0b0080] mmco: unref short failure
[h264 @ 0x55a25c0b0080] mmco: unref short failure
[h264 @ 0x55a25c0b0080] mmco: unref short failure
[h264 @ 0x55a25c0b0080] mmco: unref short failure
[h264 @ 0x55e19eb068c0] mmco: unref short failure
[h264 @ 0x55e19eb068c0] mmco: unref short failure
[h264 @ 0x55a265e29ec0] mmco: unref short failure
[h264 @ 0x55b50c505f40] mmco: unref short failure
[h264 @ 0x55b50c505f40] mmco: unref short failure
[h264 @ 0x55b4ff10bf40] mmco: unref short failure
[h264 @ 0x56069c772440] mmco: unref short failure
[h264 @ 0x5606953f0100] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:08,  3.20it/s][A
  1%|          | 2/221 [00:00<01:27,  2.49it/s][A
  1%|▏         | 3/221 [00:01<01:29,  2.45it/s][A
  2%|▏         | 4/221 [00:01<01:10,  3.06it/s][A
  2%|▏         | 5/221 [00:01<01:12,  3.00it/s][A
  3%|▎         | 6/221 [00:02<01:07,  3.18it/s][A
  3%|▎         | 7/221 [00:02<01:10,  3.04it/s][A
  4%|▎         | 8/221 [00:02<01:02,  3.41it/s][A
  4%|▍         | 9/221 [00:02<00:54,  3.87it/s][A
  5%|▍         | 10/221 [00:03<00:59,  3.54it/s][A
  5%|▍         | 11/221 [00:03<00:50,  4.20it/s][A
  5%|▌         | 12/221 [00:03<00:54,  3.87it/s][A
  6%|▌         | 13/221 [00:03<00:48,  4.28it/s][A
  6%|▋         | 14/221 [00:03<00:48,  4.25it/s][A
  7%|▋         | 15/221 [00:04<00:47,  4.38it/s][A
  7%|▋         | 16/221 [00:04<01:02,  3.29it/s][A
  8%|▊         | 17/221 [00:05<01:18,  2.59it/s][A
  8%|▊         | 18/221 [00:05<01:13,  2.78it/s][A
  9%|▊         | 19/221 [00:05<01:01,  3.30it/s][A
  9%|▉         | 20/221 [00:05<00:52,  3.86it/s][A
 10%|▉         | 21/221 [00:06<00:50,  3.93it/s][A[h264 @ 0x55b507c77540] mmco: unref short failure
[h264 @ 0x55b507c77540] mmco: unref short failure

 10%|▉         | 22/221 [00:06<01:08,  2.89it/s][A
 10%|█         | 23/221 [00:06<00:57,  3.43it/s][A09/16/2024 23:55:24 - INFO - __main__ -   current idx dYEsNlBENWc.3 from finetune_area returns wrong image/video, use 115903 instead.

 11%|█         | 24/221 [00:07<00:50,  3.92it/s][A
 11%|█▏        | 25/221 [00:07<00:46,  4.17it/s][A
 12%|█▏        | 26/221 [00:07<00:58,  3.35it/s][A
 12%|█▏        | 27/221 [00:07<00:46,  4.16it/s][A
 13%|█▎        | 28/221 [00:08<00:55,  3.47it/s][A
 13%|█▎        | 29/221 [00:08<00:54,  3.51it/s][A
 14%|█▎        | 30/221 [00:08<01:02,  3.05it/s][A
 14%|█▍        | 31/221 [00:09<01:03,  2.99it/s][A
 14%|█▍        | 32/221 [00:09<00:50,  3.76it/s][A
 15%|█▍        | 33/221 [00:09<00:45,  4.10it/s][A
 15%|█▌        | 34/221 [00:09<00:39,  4.79it/s][A
 16%|█▌        | 35/221 [00:09<00:36,  5.10it/s][A
 16%|█▋        | 36/221 [00:10<00:39,  4.71it/s][A
 17%|█▋        | 37/221 [00:10<00:48,  3.83it/s][A[h264 @ 0x55b50ca50140] mmco: unref short failure

 17%|█▋        | 38/221 [00:10<00:57,  3.18it/s][A[h264 @ 0x55b50d5b5400] mmco: unref short failure
[h264 @ 0x55b50d5b5400] mmco: unref short failure

 18%|█▊        | 39/221 [00:10<00:47,  3.85it/s][A
 18%|█▊        | 40/221 [00:11<00:47,  3.80it/s][A
 19%|█▊        | 41/221 [00:11<00:41,  4.36it/s][A[h264 @ 0x55e198d4ebc0] mmco: unref short failure
[h264 @ 0x55e198d4ebc0] mmco: unref short failure

 19%|█▉        | 42/221 [00:12<01:00,  2.97it/s][A
 19%|█▉        | 43/221 [00:12<00:49,  3.57it/s][A
 20%|█▉        | 44/221 [00:12<00:41,  4.23it/s][A
 20%|██        | 45/221 [00:12<00:58,  3.01it/s][A
 21%|██        | 46/221 [00:13<00:55,  3.13it/s][A
 21%|██▏       | 47/221 [00:15<02:32,  1.14it/s][A
 22%|██▏       | 48/221 [00:15<01:52,  1.54it/s][A
 22%|██▏       | 49/221 [00:15<01:30,  1.91it/s][A
 23%|██▎       | 50/221 [00:15<01:17,  2.21it/s][A
 23%|██▎       | 51/221 [00:16<01:02,  2.72it/s][A
 24%|██▎       | 52/221 [00:16<00:58,  2.90it/s][A
 24%|██▍       | 53/221 [00:16<00:47,  3.51it/s][A
 24%|██▍       | 54/221 [00:17<01:35,  1.74it/s][A
 25%|██▍       | 55/221 [00:18<01:27,  1.89it/s][A
 25%|██▌       | 56/221 [00:18<01:07,  2.45it/s][A
 26%|██▌       | 57/221 [00:18<01:00,  2.71it/s][A
 26%|██▌       | 58/221 [00:18<00:50,  3.23it/s][A
 27%|██▋       | 59/221 [00:18<00:41,  3.86it/s][A
 27%|██▋       | 60/221 [00:19<01:06,  2.42it/s][A
 28%|██▊       | 61/221 [00:20<01:01,  2.60it/s][A
 28%|██▊       | 62/221 [00:20<01:03,  2.50it/s][A
 29%|██▊       | 63/221 [00:20<00:55,  2.84it/s][A
 29%|██▉       | 64/221 [00:21<01:01,  2.57it/s][A
 29%|██▉       | 65/221 [00:21<00:52,  2.96it/s][A
 30%|██▉       | 66/221 [00:22<01:05,  2.38it/s][A
 30%|███       | 67/221 [00:22<00:54,  2.81it/s][A
 31%|███       | 68/221 [00:22<00:47,  3.19it/s][A
 31%|███       | 69/221 [00:23<01:08,  2.21it/s][A
 32%|███▏      | 70/221 [00:23<00:58,  2.57it/s][A
 32%|███▏      | 71/221 [00:23<00:52,  2.85it/s][A
 33%|███▎      | 72/221 [00:24<00:57,  2.57it/s][A
 33%|███▎      | 73/221 [00:24<01:04,  2.31it/s][A
 33%|███▎      | 74/221 [00:24<00:50,  2.92it/s][A
 34%|███▍      | 75/221 [00:25<00:49,  2.95it/s][A
 34%|███▍      | 76/221 [00:25<00:46,  3.14it/s][A
 35%|███▍      | 77/221 [00:25<00:47,  3.01it/s][A
 35%|███▌      | 78/221 [00:25<00:40,  3.56it/s][A
 36%|███▌      | 79/221 [00:26<00:46,  3.06it/s][A
 36%|███▌      | 80/221 [00:26<00:42,  3.31it/s][A
 37%|███▋      | 81/221 [00:27<00:47,  2.97it/s][A
 37%|███▋      | 82/221 [00:27<00:49,  2.80it/s][A[h264 @ 0x5606a0279040] mmco: unref short failure
[h264 @ 0x5606a0279040] mmco: unref short failure

 38%|███▊      | 83/221 [00:27<00:49,  2.80it/s][A
 38%|███▊      | 84/221 [00:28<00:44,  3.05it/s][A
 38%|███▊      | 85/221 [00:28<00:35,  3.85it/s][A
 39%|███▉      | 86/221 [00:28<00:32,  4.10it/s][A[h264 @ 0x5606a0279040] mmco: unref short failure
[h264 @ 0x5606a0279040] mmco: unref short failure

 39%|███▉      | 87/221 [00:29<01:03,  2.11it/s][A
 40%|███▉      | 88/221 [00:30<01:07,  1.96it/s][A
 40%|████      | 89/221 [00:30<00:55,  2.38it/s][A
 41%|████      | 90/221 [00:30<00:47,  2.78it/s][A
 41%|████      | 91/221 [00:30<00:39,  3.33it/s][A
 42%|████▏     | 92/221 [00:30<00:36,  3.58it/s][A
 42%|████▏     | 93/221 [00:31<00:39,  3.25it/s][A
 43%|████▎     | 94/221 [00:31<00:40,  3.15it/s][A
 43%|████▎     | 95/221 [00:31<00:39,  3.15it/s][A
 43%|████▎     | 96/221 [00:32<00:56,  2.22it/s][A09/16/2024 23:55:50 - INFO - __main__ -   current idx NK2f7abMxq4.56 from finetune_area returns wrong image/video, use 141039 instead.

 44%|████▍     | 97/221 [00:32<00:50,  2.45it/s][A
 44%|████▍     | 98/221 [00:33<01:05,  1.89it/s][A
 45%|████▍     | 99/221 [00:34<00:54,  2.23it/s][A
 45%|████▌     | 100/221 [00:34<00:48,  2.51it/s][A
 46%|████▌     | 101/221 [00:34<00:44,  2.71it/s][A[h264 @ 0x56068c0e6380] mmco: unref short failure
[h264 @ 0x56068c0e6380] mmco: unref short failure

 46%|████▌     | 102/221 [00:35<00:46,  2.57it/s][A
 47%|████▋     | 103/221 [00:35<00:35,  3.28it/s][A
 47%|████▋     | 104/221 [00:35<00:29,  3.93it/s][A
 48%|████▊     | 105/221 [00:35<00:33,  3.46it/s][A09/16/2024 23:55:53 - INFO - __main__ -   current idx c0na5aaBMBE.58 from finetune_area returns wrong image/video, use 26302 instead.

 48%|████▊     | 106/221 [00:36<00:51,  2.23it/s][A
 48%|████▊     | 107/221 [00:36<00:46,  2.46it/s][A
 49%|████▉     | 108/221 [00:37<00:40,  2.80it/s][A
 49%|████▉     | 109/221 [00:37<00:39,  2.84it/s][A
 50%|████▉     | 110/221 [00:37<00:31,  3.57it/s][A
 50%|█████     | 111/221 [00:37<00:32,  3.39it/s][A
 51%|█████     | 112/221 [00:38<00:29,  3.66it/s][A
 51%|█████     | 113/221 [00:38<00:28,  3.76it/s][A
 52%|█████▏    | 115/221 [00:38<00:20,  5.16it/s][A
 52%|█████▏    | 116/221 [00:39<00:38,  2.70it/s][A
 53%|█████▎    | 117/221 [00:39<00:39,  2.65it/s][A
 53%|█████▎    | 118/221 [00:39<00:33,  3.10it/s][A
 54%|█████▍    | 119/221 [00:40<00:32,  3.11it/s][A
 54%|█████▍    | 120/221 [00:40<00:28,  3.58it/s][A
 55%|█████▍    | 121/221 [00:40<00:23,  4.29it/s][A
 55%|█████▌    | 122/221 [00:40<00:26,  3.71it/s][A
 56%|█████▌    | 123/221 [00:41<00:25,  3.80it/s][A
 56%|█████▌    | 124/221 [00:41<00:28,  3.37it/s][A
 57%|█████▋    | 125/221 [00:42<00:37,  2.53it/s][A[h264 @ 0x56069f4a0680] mmco: unref short failure
[h264 @ 0x56069f4a0680] mmco: unref short failure
[h264 @ 0x56069f4a0680] mmco: unref short failure
[h264 @ 0x56069f4a0680] mmco: unref short failure
[h264 @ 0x56069f4a0680] mmco: unref short failure
[h264 @ 0x56069f4a0680] mmco: unref short failure

 57%|█████▋    | 126/221 [00:42<00:37,  2.54it/s][A
 57%|█████▋    | 127/221 [00:43<00:54,  1.74it/s][A
 58%|█████▊    | 128/221 [00:44<00:49,  1.88it/s][A
 58%|█████▊    | 129/221 [00:44<00:37,  2.44it/s][A09/16/2024 23:56:01 - INFO - __main__ -   current idx fGbJT-U6ymc.18 from finetune_area returns wrong image/video, use 96578 instead.

 59%|█████▉    | 130/221 [00:44<00:32,  2.76it/s][A
 59%|█████▉    | 131/221 [00:44<00:29,  3.05it/s][A
 60%|█████▉    | 132/221 [00:45<00:49,  1.80it/s][A
 60%|██████    | 133/221 [00:46<00:44,  1.96it/s][A
 61%|██████    | 134/221 [00:46<00:51,  1.69it/s][A[h264 @ 0x55b50e669d00] mmco: unref short failure
[h264 @ 0x55b50e669d00] mmco: unref short failure
[h264 @ 0x55e19d02f180] mmco: unref short failure
[h264 @ 0x55e19d02f180] mmco: unref short failure

 61%|██████    | 135/221 [00:47<00:53,  1.61it/s][A
 62%|██████▏   | 136/221 [00:48<00:49,  1.71it/s][A
 62%|██████▏   | 137/221 [00:48<00:46,  1.80it/s][A[h264 @ 0x5606a4714fc0] mmco: unref short failure

 62%|██████▏   | 138/221 [00:49<00:43,  1.91it/s][A
 63%|██████▎   | 139/221 [00:49<00:52,  1.56it/s][A
 63%|██████▎   | 140/221 [00:50<00:45,  1.76it/s][A
 64%|██████▍   | 141/221 [00:50<00:46,  1.71it/s][A[h264 @ 0x55b50ca7f580] mmco: unref short failure

 64%|██████▍   | 142/221 [00:51<00:43,  1.83it/s][A
 65%|██████▍   | 143/221 [00:51<00:38,  2.02it/s][A
 65%|██████▌   | 144/221 [00:52<00:32,  2.37it/s][A
 66%|██████▌   | 145/221 [00:52<00:27,  2.73it/s][A
 66%|██████▌   | 146/221 [00:52<00:24,  3.08it/s][A
 67%|██████▋   | 147/221 [00:52<00:24,  3.06it/s][A
 67%|██████▋   | 148/221 [00:53<00:33,  2.21it/s][A
 67%|██████▋   | 149/221 [00:53<00:31,  2.31it/s][A
 68%|██████▊   | 150/221 [00:54<00:27,  2.61it/s][A
 68%|██████▊   | 151/221 [00:54<00:25,  2.77it/s][A
 69%|██████▉   | 152/221 [00:55<00:33,  2.06it/s][A
 69%|██████▉   | 153/221 [00:55<00:27,  2.47it/s][A
 70%|██████▉   | 154/221 [00:55<00:25,  2.64it/s][A
 70%|███████   | 155/221 [00:56<00:22,  2.96it/s][A
 71%|███████   | 156/221 [00:56<00:22,  2.88it/s][A[h264 @ 0x55a2773321c0] mmco: unref short failure

 71%|███████   | 157/221 [00:57<00:43,  1.47it/s][A
 71%|███████▏  | 158/221 [00:58<00:36,  1.74it/s][A
 72%|███████▏  | 159/221 [00:58<00:28,  2.21it/s][A
 72%|███████▏  | 160/221 [00:58<00:22,  2.77it/s][A
 73%|███████▎  | 161/221 [00:58<00:17,  3.46it/s][A
 73%|███████▎  | 162/221 [00:58<00:14,  3.98it/s][A
 74%|███████▍  | 163/221 [00:59<00:16,  3.59it/s][A
 74%|███████▍  | 164/221 [00:59<00:16,  3.46it/s][A
 75%|███████▍  | 165/221 [00:59<00:16,  3.44it/s][A
 75%|███████▌  | 166/221 [01:01<00:32,  1.68it/s][A
 76%|███████▌  | 167/221 [01:01<00:24,  2.22it/s][A
 76%|███████▌  | 168/221 [01:02<00:36,  1.46it/s][A
 76%|███████▋  | 169/221 [01:02<00:27,  1.92it/s][A
 77%|███████▋  | 170/221 [01:02<00:22,  2.26it/s][A
 77%|███████▋  | 171/221 [01:03<00:24,  2.05it/s][A
 78%|███████▊  | 172/221 [01:03<00:21,  2.25it/s][A
 78%|███████▊  | 173/221 [01:04<00:21,  2.22it/s][A
 79%|███████▊  | 174/221 [01:04<00:16,  2.80it/s][A
 79%|███████▉  | 175/221 [01:04<00:15,  3.00it/s][A
 80%|███████▉  | 176/221 [01:04<00:13,  3.35it/s][A
 80%|████████  | 177/221 [01:05<00:14,  3.13it/s][A
 81%|████████  | 178/221 [01:06<00:23,  1.84it/s][A
 81%|████████  | 179/221 [01:06<00:22,  1.88it/s][A
 81%|████████▏ | 180/221 [01:06<00:17,  2.40it/s][A
 82%|████████▏ | 181/221 [01:07<00:13,  3.06it/s][A
 82%|████████▏ | 182/221 [01:07<00:11,  3.33it/s][A
 83%|████████▎ | 183/221 [01:07<00:12,  3.15it/s][A
 83%|████████▎ | 184/221 [01:08<00:12,  3.05it/s][A
 84%|████████▎ | 185/221 [01:08<00:10,  3.47it/s][A[h264 @ 0x55a277aed240] mmco: unref short failure
[h264 @ 0x55a277aed240] mmco: unref short failure

 84%|████████▍ | 186/221 [01:08<00:13,  2.57it/s][A
 85%|████████▍ | 187/221 [01:09<00:11,  2.85it/s][A
 85%|████████▌ | 188/221 [01:09<00:10,  3.24it/s][A
 86%|████████▌ | 189/221 [01:09<00:10,  3.01it/s][A
 86%|████████▌ | 190/221 [01:10<00:10,  2.89it/s][A
 87%|████████▋ | 192/221 [01:10<00:07,  3.91it/s][A
 87%|████████▋ | 193/221 [01:10<00:06,  4.59it/s][A
 88%|████████▊ | 194/221 [01:12<00:17,  1.56it/s][A
 88%|████████▊ | 195/221 [01:12<00:13,  1.91it/s][A
 89%|████████▊ | 196/221 [01:12<00:10,  2.41it/s][A
 89%|████████▉ | 197/221 [01:13<00:09,  2.58it/s][A
 90%|████████▉ | 198/221 [01:13<00:07,  3.06it/s][A
 90%|█████████ | 199/221 [01:13<00:07,  3.09it/s][A
 90%|█████████ | 200/221 [01:13<00:05,  3.62it/s][A
 91%|█████████ | 201/221 [01:13<00:05,  3.99it/s][A
 91%|█████████▏| 202/221 [01:14<00:05,  3.67it/s][A
 92%|█████████▏| 203/221 [01:14<00:05,  3.57it/s][A
 92%|█████████▏| 204/221 [01:14<00:04,  3.88it/s][A
 93%|█████████▎| 205/221 [01:14<00:04,  3.86it/s][A
 93%|█████████▎| 206/221 [01:15<00:04,  3.21it/s][A
 94%|█████████▎| 207/221 [01:15<00:03,  3.91it/s][A
 94%|█████████▍| 208/221 [01:15<00:03,  3.37it/s][A
 95%|█████████▍| 209/221 [01:16<00:03,  3.62it/s][A
 95%|█████████▌| 211/221 [01:16<00:02,  3.92it/s][A
 96%|█████████▌| 212/221 [01:16<00:02,  3.78it/s][A
 96%|█████████▋| 213/221 [01:17<00:02,  3.95it/s][A
 97%|█████████▋| 214/221 [01:17<00:02,  3.24it/s][A
 97%|█████████▋| 215/221 [01:17<00:01,  3.84it/s][A
 98%|█████████▊| 216/221 [01:17<00:01,  3.71it/s][A
 98%|█████████▊| 217/221 [01:18<00:01,  2.70it/s][A
 99%|█████████▊| 218/221 [01:18<00:00,  3.04it/s][A
 99%|█████████▉| 219/221 [01:19<00:00,  3.02it/s][A
100%|█████████▉| 220/221 [01:20<00:00,  1.88it/s][A
100%|██████████| 221/221 [01:20<00:00,  2.35it/s][A100%|██████████| 221/221 [01:20<00:00,  2.75it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:08,  3.22it/s][A
  1%|          | 2/221 [00:00<01:05,  3.32it/s][A
  1%|▏         | 3/221 [00:00<01:07,  3.24it/s][A
  2%|▏         | 4/221 [00:01<01:07,  3.19it/s][A
  2%|▏         | 5/221 [00:01<01:07,  3.22it/s][A
  3%|▎         | 6/221 [00:01<01:09,  3.11it/s][A
  3%|▎         | 7/221 [00:02<01:06,  3.20it/s][A
  4%|▎         | 8/221 [00:02<01:05,  3.26it/s][A[h264 @ 0x56068c83a840] mmco: unref short failure

  4%|▍         | 9/221 [00:02<01:04,  3.30it/s][A
  5%|▍         | 10/221 [00:03<01:03,  3.33it/s][A
  5%|▍         | 11/221 [00:03<01:02,  3.34it/s][A
  5%|▌         | 12/221 [00:03<01:02,  3.36it/s][A
  6%|▌         | 13/221 [00:03<01:01,  3.37it/s][A
  6%|▋         | 14/221 [00:04<01:02,  3.32it/s][A
  7%|▋         | 15/221 [00:04<01:02,  3.30it/s][A
  7%|▋         | 16/221 [00:04<01:02,  3.31it/s][A
  8%|▊         | 17/221 [00:05<01:01,  3.33it/s][A
  8%|▊         | 18/221 [00:05<01:00,  3.35it/s][A
  9%|▊         | 19/221 [00:05<00:59,  3.37it/s][A
  9%|▉         | 20/221 [00:06<00:59,  3.36it/s][A
 10%|▉         | 21/221 [00:06<00:59,  3.34it/s][A
 10%|▉         | 22/221 [00:06<01:00,  3.29it/s][A
 10%|█         | 23/221 [00:06<00:59,  3.33it/s][A[h264 @ 0x55b50e66a180] mmco: unref short failure

 11%|█         | 24/221 [00:07<00:59,  3.31it/s][A
 11%|█▏        | 25/221 [00:07<00:59,  3.32it/s][A[h264 @ 0x55a265283e00] mmco: unref short failure
[h264 @ 0x55a265283e00] mmco: unref short failure

 12%|█▏        | 26/221 [00:07<00:58,  3.32it/s][A
 12%|█▏        | 27/221 [00:08<00:57,  3.35it/s][A
 13%|█▎        | 28/221 [00:08<00:57,  3.36it/s][A
 13%|█▎        | 29/221 [00:08<00:57,  3.33it/s][A
 14%|█▎        | 30/221 [00:09<00:57,  3.35it/s][A
 14%|█▍        | 31/221 [00:09<00:57,  3.32it/s][A
 14%|█▍        | 32/221 [00:09<00:56,  3.35it/s][A
 15%|█▍        | 33/221 [00:09<00:55,  3.36it/s][A[h264 @ 0x55b50ccfc9c0] mmco: unref short failure
[h264 @ 0x55b50ccfc9c0] mmco: unref short failure

 15%|█▌        | 34/221 [00:10<00:55,  3.38it/s][A
 16%|█▌        | 35/221 [00:10<00:55,  3.38it/s][A[h264 @ 0x55a25cd18880] mmco: unref short failure

 16%|█▋        | 36/221 [00:10<00:55,  3.33it/s][A
 17%|█▋        | 37/221 [00:11<00:55,  3.33it/s][A
 17%|█▋        | 38/221 [00:11<00:54,  3.35it/s][A
 18%|█▊        | 39/221 [00:11<00:54,  3.36it/s][A[h264 @ 0x55b500c36600] mmco: unref short failure
[h264 @ 0x55b500c36600] mmco: unref short failure

 18%|█▊        | 40/221 [00:12<00:53,  3.37it/s][A
 19%|█▊        | 41/221 [00:12<00:53,  3.38it/s][A
 19%|█▉        | 42/221 [00:12<00:52,  3.38it/s][A
 19%|█▉        | 43/221 [00:12<00:53,  3.32it/s][A
 20%|█▉        | 44/221 [00:13<00:52,  3.35it/s][A09/16/2024 23:56:56 - INFO - __main__ -   current idx 1DPLzfs419g.3 from finetune_area returns wrong image/video, use 1432 instead.

 20%|██        | 45/221 [00:13<00:53,  3.26it/s][A
 21%|██        | 46/221 [00:13<00:52,  3.30it/s][A
 21%|██▏       | 47/221 [00:14<00:52,  3.29it/s][A
 22%|██▏       | 48/221 [00:14<00:52,  3.32it/s][A
 22%|██▏       | 49/221 [00:14<00:51,  3.33it/s][A
 23%|██▎       | 50/221 [00:15<00:51,  3.29it/s][A
 23%|██▎       | 51/221 [00:15<00:51,  3.33it/s][A
 24%|██▎       | 52/221 [00:15<00:50,  3.35it/s][A
 24%|██▍       | 53/221 [00:15<00:50,  3.33it/s][A
 24%|██▍       | 54/221 [00:16<00:49,  3.34it/s][A
 25%|██▍       | 55/221 [00:16<00:49,  3.34it/s][A
 25%|██▌       | 56/221 [00:16<00:49,  3.36it/s][A
 26%|██▌       | 57/221 [00:17<00:48,  3.35it/s][A
 26%|██▌       | 58/221 [00:17<00:48,  3.37it/s][A
 27%|██▋       | 59/221 [00:17<00:48,  3.34it/s][A
 27%|██▋       | 60/221 [00:18<00:47,  3.36it/s][A
 28%|██▊       | 61/221 [00:18<00:47,  3.37it/s][A
 28%|██▊       | 62/221 [00:18<00:47,  3.38it/s][A
 29%|██▊       | 63/221 [00:18<00:46,  3.39it/s][A
 29%|██▉       | 64/221 [00:19<00:46,  3.39it/s][A
 29%|██▉       | 65/221 [00:19<00:45,  3.40it/s][A
 30%|██▉       | 66/221 [00:19<00:45,  3.40it/s][A
 30%|███       | 67/221 [00:20<00:45,  3.40it/s][A
 31%|███       | 68/221 [00:20<00:44,  3.40it/s][A
 31%|███       | 69/221 [00:20<00:44,  3.40it/s][A
 32%|███▏      | 70/221 [00:20<00:44,  3.40it/s][A
 32%|███▏      | 71/221 [00:21<00:44,  3.40it/s][A
 33%|███▎      | 72/221 [00:21<00:43,  3.40it/s][A
 33%|███▎      | 73/221 [00:21<00:43,  3.40it/s][A
 33%|███▎      | 74/221 [00:22<00:43,  3.40it/s][A
 34%|███▍      | 75/221 [00:22<00:42,  3.40it/s][A
 34%|███▍      | 76/221 [00:22<00:42,  3.40it/s][A
 35%|███▍      | 77/221 [00:23<00:42,  3.40it/s][A
 35%|███▌      | 78/221 [00:23<00:42,  3.40it/s][A
 36%|███▌      | 79/221 [00:23<00:41,  3.40it/s][A
 36%|███▌      | 80/221 [00:23<00:41,  3.40it/s][A
 37%|███▋      | 81/221 [00:24<00:41,  3.40it/s][A
 37%|███▋      | 82/221 [00:24<00:40,  3.41it/s][A[h264 @ 0x55a271284380] mmco: unref short failure

 38%|███▊      | 83/221 [00:24<00:40,  3.41it/s][A
 38%|███▊      | 84/221 [00:25<00:40,  3.41it/s][A
 38%|███▊      | 85/221 [00:25<00:39,  3.41it/s][A
 39%|███▉      | 86/221 [00:25<00:39,  3.41it/s][A
 39%|███▉      | 87/221 [00:25<00:39,  3.41it/s][A
 40%|███▉      | 88/221 [00:26<00:39,  3.41it/s][A
 40%|████      | 89/221 [00:26<00:38,  3.41it/s][A
 41%|████      | 90/221 [00:26<00:38,  3.41it/s][A
 41%|████      | 91/221 [00:27<00:38,  3.41it/s][A
 42%|████▏     | 92/221 [00:27<00:37,  3.41it/s][A
 42%|████▏     | 93/221 [00:27<00:37,  3.41it/s][A
 43%|████▎     | 94/221 [00:28<00:37,  3.41it/s][A
 43%|████▎     | 95/221 [00:28<00:36,  3.41it/s][A
 43%|████▎     | 96/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 97/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 98/221 [00:29<00:35,  3.42it/s][A
 45%|████▍     | 99/221 [00:29<00:35,  3.42it/s][A
 45%|████▌     | 100/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 101/221 [00:30<00:35,  3.42it/s][A
 46%|████▌     | 102/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 104/221 [00:30<00:34,  3.42it/s][A
 48%|████▊     | 105/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 107/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 108/221 [00:32<00:33,  3.42it/s][A
 49%|████▉     | 109/221 [00:32<00:32,  3.42it/s][A
 50%|████▉     | 110/221 [00:32<00:32,  3.42it/s][A
 50%|█████     | 111/221 [00:32<00:32,  3.42it/s][A
 51%|█████     | 112/221 [00:33<00:31,  3.42it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 114/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:34<00:30,  3.42it/s][A
 52%|█████▏    | 116/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:35<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:35<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:35<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:37<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:38<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:39<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:40<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:40<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:41<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:42<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:44<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:45<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:45<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:46<00:18,  3.42it/s][A
 71%|███████   | 157/221 [00:46<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:47<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:47<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:48<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:48<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:49<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:49<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:49<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:50<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:51<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:51<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:52<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:54<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:54<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:55<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:56<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:57<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:57<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:59<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:03<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.42it/s][A100%|██████████| 221/221 [01:05<00:00,  3.39it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:24,  9.02it/s][A
  1%|          | 2/221 [00:00<01:00,  3.62it/s][A
  1%|▏         | 3/221 [00:01<01:29,  2.43it/s][A
  2%|▏         | 4/221 [00:01<01:03,  3.44it/s][A
  2%|▏         | 5/221 [00:01<00:58,  3.68it/s][A
  3%|▎         | 6/221 [00:01<00:53,  4.05it/s][A
  3%|▎         | 7/221 [00:01<00:51,  4.17it/s][A
  4%|▎         | 8/221 [00:02<01:01,  3.45it/s][A
  4%|▍         | 9/221 [00:02<01:04,  3.30it/s][A
  5%|▍         | 10/221 [00:03<01:19,  2.64it/s][A
  5%|▍         | 11/221 [00:03<01:18,  2.66it/s][A
  5%|▌         | 12/221 [00:03<01:09,  2.99it/s][A
  6%|▌         | 13/221 [00:04<01:17,  2.67it/s][A
  6%|▋         | 14/221 [00:04<01:16,  2.69it/s][A
  7%|▋         | 15/221 [00:05<01:22,  2.50it/s][A
  7%|▋         | 16/221 [00:05<01:17,  2.66it/s][A
  8%|▊         | 17/221 [00:05<01:21,  2.51it/s][A
  8%|▊         | 18/221 [00:06<01:14,  2.73it/s][A
  9%|▊         | 19/221 [00:06<01:11,  2.83it/s][A
  9%|▉         | 20/221 [00:06<00:56,  3.53it/s][A
 10%|▉         | 21/221 [00:06<00:50,  3.95it/s][A
 10%|▉         | 22/221 [00:06<00:45,  4.33it/s][A
 10%|█         | 23/221 [00:07<00:38,  5.13it/s][A
 11%|█         | 24/221 [00:07<00:34,  5.70it/s][A
 11%|█▏        | 25/221 [00:07<00:36,  5.30it/s][A
 12%|█▏        | 26/221 [00:07<00:42,  4.55it/s][A
 12%|█▏        | 27/221 [00:07<00:41,  4.68it/s][A
 13%|█▎        | 28/221 [00:08<00:48,  3.97it/s][A
 13%|█▎        | 29/221 [00:08<00:58,  3.28it/s][A
 14%|█▎        | 30/221 [00:09<01:04,  2.94it/s][A
 14%|█▍        | 31/221 [00:09<00:58,  3.23it/s][A
 14%|█▍        | 32/221 [00:09<01:00,  3.15it/s][A
 15%|█▍        | 33/221 [00:09<00:53,  3.54it/s][A
 15%|█▌        | 34/221 [00:09<00:43,  4.29it/s][A
 16%|█▋        | 36/221 [00:10<00:44,  4.11it/s][A
 17%|█▋        | 37/221 [00:10<00:46,  3.95it/s][A
 17%|█▋        | 38/221 [00:11<00:50,  3.60it/s][A
 18%|█▊        | 39/221 [00:11<00:46,  3.92it/s][A
 18%|█▊        | 40/221 [00:11<00:50,  3.62it/s][A
 19%|█▊        | 41/221 [00:11<00:49,  3.67it/s][A
 19%|█▉        | 42/221 [00:12<00:43,  4.15it/s][A
 19%|█▉        | 43/221 [00:12<00:45,  3.91it/s][A
 20%|█▉        | 44/221 [00:12<00:38,  4.57it/s][A
 20%|██        | 45/221 [00:12<00:49,  3.54it/s][A
 21%|██        | 46/221 [00:13<00:52,  3.31it/s][A
 21%|██▏       | 47/221 [00:13<00:45,  3.81it/s][A
 22%|██▏       | 49/221 [00:13<00:30,  5.69it/s][A
 23%|██▎       | 50/221 [00:14<00:48,  3.54it/s][A
 23%|██▎       | 51/221 [00:14<00:46,  3.64it/s][A
 24%|██▎       | 52/221 [00:14<00:41,  4.09it/s][A
 24%|██▍       | 53/221 [00:14<00:44,  3.77it/s][A
 24%|██▍       | 54/221 [00:15<00:40,  4.11it/s][A
 25%|██▍       | 55/221 [00:15<00:35,  4.72it/s][A
 25%|██▌       | 56/221 [00:15<00:36,  4.55it/s][A
 26%|██▌       | 57/221 [00:15<00:40,  4.00it/s][A
 27%|██▋       | 59/221 [00:16<00:34,  4.75it/s][A
 27%|██▋       | 60/221 [00:16<00:30,  5.34it/s][A
 28%|██▊       | 61/221 [00:16<00:30,  5.22it/s][A
 28%|██▊       | 62/221 [00:16<00:37,  4.25it/s][A
 29%|██▉       | 64/221 [00:17<00:37,  4.22it/s][A
 29%|██▉       | 65/221 [00:17<00:33,  4.70it/s][A
 30%|██▉       | 66/221 [00:17<00:39,  3.97it/s][A
 30%|███       | 67/221 [00:18<00:39,  3.87it/s][A
 31%|███       | 68/221 [00:18<00:44,  3.47it/s][A
 31%|███       | 69/221 [00:18<00:56,  2.71it/s][A
 32%|███▏      | 70/221 [00:19<00:48,  3.11it/s][A
 32%|███▏      | 71/221 [00:19<00:47,  3.13it/s][A
 33%|███▎      | 72/221 [00:19<00:52,  2.86it/s][A
 33%|███▎      | 73/221 [00:20<00:51,  2.86it/s][A
 33%|███▎      | 74/221 [00:20<00:42,  3.48it/s][A
 34%|███▍      | 75/221 [00:20<00:45,  3.21it/s][A
 34%|███▍      | 76/221 [00:21<00:46,  3.11it/s][A
 35%|███▍      | 77/221 [00:21<00:42,  3.38it/s][A
 35%|███▌      | 78/221 [00:21<00:39,  3.61it/s][A
 36%|███▌      | 79/221 [00:21<00:36,  3.92it/s][A
 36%|███▌      | 80/221 [00:22<00:39,  3.59it/s][A
 37%|███▋      | 81/221 [00:22<00:38,  3.66it/s][A
 37%|███▋      | 82/221 [00:22<00:34,  3.98it/s][A
 38%|███▊      | 84/221 [00:23<00:39,  3.51it/s][A
 38%|███▊      | 85/221 [00:23<00:32,  4.15it/s][A
 39%|███▉      | 86/221 [00:23<00:32,  4.16it/s][A
 39%|███▉      | 87/221 [00:24<00:40,  3.29it/s][A
 40%|███▉      | 88/221 [00:24<00:44,  2.96it/s][A
 40%|████      | 89/221 [00:24<00:47,  2.76it/s][A
 41%|████      | 90/221 [00:25<00:48,  2.72it/s][A
 41%|████      | 91/221 [00:25<00:40,  3.20it/s][A
 42%|████▏     | 92/221 [00:25<00:40,  3.18it/s][A
 42%|████▏     | 93/221 [00:25<00:36,  3.48it/s][A
 43%|████▎     | 94/221 [00:26<00:35,  3.53it/s][A
 43%|████▎     | 95/221 [00:27<00:52,  2.39it/s][A
 43%|████▎     | 96/221 [00:27<00:52,  2.39it/s][A
 44%|████▍     | 97/221 [00:27<00:50,  2.48it/s][A
 44%|████▍     | 98/221 [00:28<00:59,  2.07it/s][A
 45%|████▍     | 99/221 [00:28<00:53,  2.26it/s][A
 45%|████▌     | 100/221 [00:29<00:54,  2.21it/s][A
 46%|████▌     | 101/221 [00:29<00:52,  2.28it/s][A
 46%|████▌     | 102/221 [00:29<00:45,  2.62it/s][A
 47%|████▋     | 103/221 [00:30<00:36,  3.24it/s][A
 48%|████▊     | 105/221 [00:30<00:31,  3.73it/s][A
 48%|████▊     | 106/221 [00:30<00:34,  3.37it/s][A
 48%|████▊     | 107/221 [00:31<00:30,  3.74it/s][A
 49%|████▉     | 108/221 [00:31<00:28,  3.91it/s][A
 49%|████▉     | 109/221 [00:31<00:31,  3.59it/s][A
 50%|████▉     | 110/221 [00:31<00:29,  3.82it/s][A
 50%|█████     | 111/221 [00:32<00:31,  3.44it/s][A
 51%|█████     | 112/221 [00:32<00:31,  3.49it/s][A
 51%|█████     | 113/221 [00:32<00:28,  3.81it/s][A
 52%|█████▏    | 115/221 [00:32<00:22,  4.82it/s][A
 52%|█████▏    | 116/221 [00:33<00:21,  4.99it/s][A
 53%|█████▎    | 117/221 [00:33<00:22,  4.69it/s][A
 53%|█████▎    | 118/221 [00:33<00:25,  4.08it/s][A
 54%|█████▍    | 119/221 [00:34<00:30,  3.35it/s][A
 54%|█████▍    | 120/221 [00:34<00:29,  3.40it/s][A
 55%|█████▍    | 121/221 [00:34<00:32,  3.10it/s][A
 55%|█████▌    | 122/221 [00:35<00:34,  2.91it/s][A
 56%|█████▌    | 123/221 [00:35<00:28,  3.40it/s][A
 56%|█████▌    | 124/221 [00:35<00:31,  3.07it/s][A
 57%|█████▋    | 125/221 [00:36<00:33,  2.82it/s][A
 57%|█████▋    | 126/221 [00:36<00:29,  3.26it/s][A
 57%|█████▋    | 127/221 [00:36<00:30,  3.05it/s][A
 58%|█████▊    | 128/221 [00:37<00:27,  3.35it/s][A
 58%|█████▊    | 129/221 [00:37<00:22,  4.15it/s][A
 59%|█████▉    | 130/221 [00:37<00:27,  3.30it/s][A
 59%|█████▉    | 131/221 [00:37<00:24,  3.64it/s][A
 60%|█████▉    | 132/221 [00:38<00:32,  2.70it/s][A
 60%|██████    | 133/221 [00:38<00:28,  3.14it/s][A
 61%|██████    | 134/221 [00:39<00:31,  2.76it/s][A
 61%|██████    | 135/221 [00:39<00:26,  3.25it/s][A
 62%|██████▏   | 136/221 [00:39<00:26,  3.22it/s][A
 62%|██████▏   | 137/221 [00:39<00:25,  3.31it/s][A
 62%|██████▏   | 138/221 [00:40<00:23,  3.55it/s][A
 63%|██████▎   | 139/221 [00:40<00:25,  3.27it/s][A
 63%|██████▎   | 140/221 [00:40<00:23,  3.50it/s][A
 64%|██████▍   | 141/221 [00:41<00:26,  3.04it/s][A
 64%|██████▍   | 142/221 [00:41<00:23,  3.32it/s][A
 65%|██████▍   | 143/221 [00:41<00:22,  3.50it/s][A
 65%|██████▌   | 144/221 [00:41<00:19,  3.92it/s][A
 66%|██████▌   | 145/221 [00:42<00:22,  3.38it/s][A
 66%|██████▌   | 146/221 [00:42<00:20,  3.70it/s][A
 67%|██████▋   | 148/221 [00:43<00:28,  2.57it/s][A
 67%|██████▋   | 149/221 [00:43<00:27,  2.61it/s][A
 68%|██████▊   | 150/221 [00:44<00:27,  2.58it/s][A
 68%|██████▊   | 151/221 [00:45<00:36,  1.90it/s][A
 69%|██████▉   | 152/221 [00:45<00:33,  2.03it/s][A
 69%|██████▉   | 153/221 [00:45<00:28,  2.41it/s][A
 70%|██████▉   | 154/221 [00:46<00:25,  2.64it/s][A
 70%|███████   | 155/221 [00:46<00:20,  3.14it/s][A
 71%|███████   | 156/221 [00:46<00:20,  3.24it/s][A
 71%|███████   | 157/221 [00:46<00:19,  3.29it/s][A
 71%|███████▏  | 158/221 [00:47<00:19,  3.19it/s][A
 72%|███████▏  | 159/221 [00:47<00:17,  3.64it/s][A
 72%|███████▏  | 160/221 [00:47<00:15,  3.82it/s][A
 74%|███████▍  | 163/221 [00:47<00:10,  5.52it/s][A
 74%|███████▍  | 164/221 [00:48<00:10,  5.35it/s][A
 75%|███████▍  | 165/221 [00:48<00:12,  4.37it/s][A
 75%|███████▌  | 166/221 [00:48<00:13,  3.95it/s][A
 76%|███████▌  | 167/221 [00:48<00:12,  4.20it/s][A
 76%|███████▌  | 168/221 [00:49<00:12,  4.09it/s][A
 77%|███████▋  | 170/221 [00:49<00:10,  4.68it/s][A
 77%|███████▋  | 171/221 [00:50<00:16,  3.06it/s][A
 78%|███████▊  | 172/221 [00:50<00:16,  3.05it/s][A
 78%|███████▊  | 173/221 [00:51<00:16,  2.90it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.58it/s][A
 79%|███████▉  | 175/221 [00:51<00:11,  3.88it/s][A
 80%|███████▉  | 176/221 [00:51<00:09,  4.52it/s][A
 80%|████████  | 177/221 [00:51<00:10,  4.07it/s][A
 81%|████████  | 178/221 [00:52<00:17,  2.41it/s][A
 81%|████████  | 179/221 [00:52<00:16,  2.57it/s][A
 82%|████████▏ | 181/221 [00:53<00:10,  3.84it/s][A
 82%|████████▏ | 182/221 [00:53<00:10,  3.84it/s][A
 83%|████████▎ | 183/221 [00:53<00:10,  3.52it/s][A
 83%|████████▎ | 184/221 [00:54<00:11,  3.18it/s][A
 84%|████████▍ | 186/221 [00:54<00:09,  3.57it/s][A
 85%|████████▍ | 187/221 [00:54<00:08,  3.92it/s][A
 85%|████████▌ | 188/221 [00:54<00:07,  4.31it/s][A
 86%|████████▌ | 189/221 [00:55<00:07,  4.45it/s][A
 86%|████████▌ | 190/221 [00:55<00:08,  3.73it/s][A
 86%|████████▋ | 191/221 [00:55<00:06,  4.44it/s][A
 87%|████████▋ | 192/221 [00:55<00:06,  4.24it/s][A
 87%|████████▋ | 193/221 [00:56<00:08,  3.32it/s][A
 88%|████████▊ | 194/221 [00:56<00:09,  2.72it/s][A
 88%|████████▊ | 195/221 [00:57<00:09,  2.62it/s][A
 89%|████████▊ | 196/221 [00:57<00:08,  2.84it/s][A
 89%|████████▉ | 197/221 [00:58<00:09,  2.50it/s][A
 90%|████████▉ | 198/221 [00:58<00:08,  2.75it/s][A
 90%|█████████ | 199/221 [00:58<00:07,  3.06it/s][A
 90%|█████████ | 200/221 [00:58<00:05,  3.60it/s][A
 91%|█████████ | 201/221 [00:58<00:05,  3.89it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.65it/s][A
 92%|█████████▏| 203/221 [00:59<00:05,  3.49it/s][A
 92%|█████████▏| 204/221 [00:59<00:03,  4.30it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.86it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.41it/s][A
 94%|█████████▎| 207/221 [01:00<00:04,  3.46it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.25it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.60it/s][A
 95%|█████████▌| 210/221 [01:01<00:02,  3.93it/s][A
 95%|█████████▌| 211/221 [01:01<00:02,  3.79it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.46it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.78it/s][A
 97%|█████████▋| 214/221 [01:02<00:02,  3.40it/s][A
 97%|█████████▋| 215/221 [01:02<00:01,  3.41it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.53it/s][A
 98%|█████████▊| 217/221 [01:03<00:01,  3.20it/s][A
 99%|█████████▊| 218/221 [01:04<00:01,  2.77it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  2.70it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.31it/s][A
100%|██████████| 221/221 [01:04<00:00,  3.48it/s][A100%|██████████| 221/221 [01:04<00:00,  3.41it/s]
09/16/2024 23:58:56 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 99--===========

09/16/2024 23:58:56 - INFO - __main__ -   {'area_r1': 41.2, 'area_recall': '41.2/69.1/79.3', 'area_ravg': 63.2}
09/16/2024 23:58:56 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 99--===========

09/16/2024 23:58:56 - INFO - __main__ -   {'forward_r1': 35.9, 'forward_recall': '35.9/64.0/75.2', 'forward_ravg': 58.4}
09/16/2024 23:58:56 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 99--===========

09/16/2024 23:58:56 - INFO - __main__ -   {'area_video_r1': 35.4, 'area_video_recall': '35.4/64.8/75.9', 'area_video_ravg': 58.7}
09/16/2024 23:58:56 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 49=======

09/16/2024 23:58:56 - INFO - __main__ -   {'area_video_r1': 36.9, 'area_video_recall': '36.9/67.2/77.8', 'area_video_ravg': 60.6}
09/16/2024 23:58:56 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 99--===========

09/16/2024 23:58:56 - INFO - __main__ -   {'area_video_r1': 51.0, 'area_video_recall': '51.0/74.8/83.0', 'area_video_ravg': 69.6, 'area_video_back_r1': 49.9, 'area_video_back_recall': '49.9/73.4/80.7', 'area_video_back_ravg': 68.0}
09/16/2024 23:58:56 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 99=======

09/16/2024 23:58:56 - INFO - __main__ -   {'area_video_r1': 51.0, 'area_video_recall': '51.0/74.8/83.0', 'area_video_ravg': 69.6, 'area_video_back_r1': 49.9, 'area_video_back_recall': '49.9/73.4/80.7', 'area_video_back_ravg': 68.0}
09/16/2024 23:58:56 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 99--===========

09/16/2024 23:58:56 - INFO - __main__ -   {'video_r1': 35.5, 'video_recall': '35.5/65.3/74.7', 'video_ravg': 58.5}
09/16/2024 23:58:56 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 49=======

09/16/2024 23:58:56 - INFO - __main__ -   {'video_r1': 37.0, 'video_recall': '37.0/65.4/73.9', 'video_ravg': 58.7}
09/16/2024 23:58:56 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 99--===========

09/16/2024 23:58:56 - INFO - __main__ -   {'video_r1': 50.9, 'video_recall': '50.9/73.4/81.4', 'video_ravg': 68.6}
09/16/2024 23:58:56 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 99=======

09/16/2024 23:58:56 - INFO - __main__ -   {'video_r1': 50.9, 'video_recall': '50.9/73.4/81.4', 'video_ravg': 68.6}
09/16/2024 23:59:26 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.011976703070104122, 'loss_ret%tv%ta--finetune_area/loss_area': 2.7560853958129883, 'loss_ret%tv%ta--finetune_area/total_loss': 2.768062114715576}
  3%|▎         | 100/2910 [37:43<104:30:47, 133.90s/it]  3%|▎         | 101/2910 [37:46<73:57:53, 94.79s/it]  [h264 @ 0x55a26f2f2580] mmco: unref short failure
[h264 @ 0x55a26f2f2580] mmco: unref short failure
  4%|▎         | 102/2910 [37:50<52:39:27, 67.51s/it]  4%|▎         | 103/2910 [37:54<37:50:33, 48.53s/it]  4%|▎         | 104/2910 [37:59<27:34:20, 35.37s/it]  4%|▎         | 105/2910 [38:04<20:24:06, 26.18s/it]  4%|▎         | 106/2910 [38:09<15:29:50, 19.90s/it][h264 @ 0x5606a5eda900] mmco: unref short failure
[h264 @ 0x5606a5eda900] mmco: unref short failure
[h264 @ 0x55a25ed37780] mmco: unref short failure
[h264 @ 0x55a25ed37780] mmco: unref short failure
  4%|▎         | 107/2910 [38:15<12:13:36, 15.70s/it][h264 @ 0x55a27232c980] mmco: unref short failure
[h264 @ 0x55b4f4473740] mmco: unref short failure
[h264 @ 0x55b4f4473740] mmco: unref short failure
  4%|▎         | 108/2910 [38:20<9:44:07, 12.51s/it] [h264 @ 0x55b510beebc0] mmco: unref short failure
[h264 @ 0x5606a567f180] mmco: unref short failure
[h264 @ 0x5606a567f180] mmco: unref short failure
  4%|▎         | 109/2910 [38:26<8:08:46, 10.47s/it][h264 @ 0x55a269ddb180] mmco: unref short failure
[h264 @ 0x55a269ddb180] mmco: unref short failure
[h264 @ 0x55a276ef82c0] mmco: unref short failure
[h264 @ 0x55a276ef82c0] mmco: unref short failure
[h264 @ 0x55a276ef82c0] mmco: unref short failure
[h264 @ 0x55a276ef82c0] mmco: unref short failure
  4%|▍         | 110/2910 [38:32<7:07:37,  9.16s/it]  4%|▍         | 111/2910 [38:37<6:11:46,  7.97s/it]  4%|▍         | 112/2910 [38:42<5:29:08,  7.06s/it]  4%|▍         | 113/2910 [38:47<5:08:31,  6.62s/it]  4%|▍         | 114/2910 [38:53<4:55:02,  6.33s/it][h264 @ 0x55e19fef7380] mmco: unref short failure
[h264 @ 0x55e19fef7380] mmco: unref short failure
  4%|▍         | 115/2910 [38:58<4:41:01,  6.03s/it]09/17/2024 00:00:48 - INFO - __main__ -   current idx BYJeo2oa0SU.13 from finetune_area returns wrong image/video, use 23897 instead.
[h264 @ 0x55e1a21563c0] mmco: unref short failure
[h264 @ 0x55e1a21563c0] mmco: unref short failure
[h264 @ 0x55e18a3e3500] mmco: unref short failure
[h264 @ 0x55e18a3e3500] mmco: unref short failure
[h264 @ 0x55a25bc60440] mmco: unref short failure
[h264 @ 0x55a25e4623c0] mmco: unref short failure
[h264 @ 0x56069fdf38c0] mmco: unref short failure
[h264 @ 0x56069fdf38c0] mmco: unref short failure
[h264 @ 0x56068c4818c0] mmco: unref short failure
[h264 @ 0x55e1867b7300] mmco: unref short failure
[h264 @ 0x55b4f3a8a380] mmco: unref short failure
[h264 @ 0x55b4f3a8a380] mmco: unref short failure
[h264 @ 0x5606a7494140] mmco: unref short failure
[h264 @ 0x55a262e21800] mmco: unref short failure
[h264 @ 0x55a262e21800] mmco: unref short failure
  4%|▍         | 116/2910 [39:51<15:26:20, 19.89s/it][h264 @ 0x55b50b55b3c0] mmco: unref short failure
[h264 @ 0x55b50b55b3c0] mmco: unref short failure
  4%|▍         | 117/2910 [40:00<13:02:29, 16.81s/it][h264 @ 0x55b4ff57fa00] mmco: unref short failure
[h264 @ 0x55e19804e800] mmco: unref short failure
  4%|▍         | 118/2910 [40:10<11:25:48, 14.74s/it][h264 @ 0x55b5028a06c0] mmco: unref short failure
[h264 @ 0x55b5028a06c0] mmco: unref short failure
  4%|▍         | 119/2910 [40:29<12:28:38, 16.09s/it][h264 @ 0x55b4f8eb3e80] mmco: unref short failure
  4%|▍         | 120/2910 [40:35<10:00:09, 12.91s/it]  4%|▍         | 121/2910 [40:40<8:16:27, 10.68s/it]   4%|▍         | 122/2910 [40:46<6:59:57,  9.04s/it][h264 @ 0x5606a7574400] mmco: unref short failure
[h264 @ 0x5606a7574400] mmco: unref short failure
  4%|▍         | 123/2910 [40:54<6:51:49,  8.87s/it][h264 @ 0x5606a6520880] mmco: unref short failure
[h264 @ 0x55e18c131640] mmco: unref short failure
[h264 @ 0x55e18c131640] mmco: unref short failure
[h264 @ 0x55a279b52140] mmco: unref short failure
[h264 @ 0x55b50ca4f800] mmco: unref short failure
[h264 @ 0x55b50ca4f800] mmco: unref short failure
09/17/2024 00:03:09 - INFO - __main__ -   current idx UqfcB6M8FA4.49 from finetune_area returns wrong image/video, use 7219 instead.
[h264 @ 0x55b50d6fcbc0] mmco: unref short failure
[h264 @ 0x55b50d6fcbc0] mmco: unref short failure
[h264 @ 0x55e19b226d80] mmco: unref short failure
[h264 @ 0x5606ad6899c0] mmco: unref short failure
[h264 @ 0x560691dc7180] mmco: unref short failure
[h264 @ 0x560691dc7180] mmco: unref short failure
[h264 @ 0x55e184268dc0] mmco: unref short failure
[h264 @ 0x55e184268dc0] mmco: unref short failure
[h264 @ 0x55b50b575b40] mmco: unref short failure
[h264 @ 0x55e18b6e2900] mmco: unref short failure
[h264 @ 0x55e18b6e2900] mmco: unref short failure
[h264 @ 0x55a26347ec00] mmco: unref short failure
[h264 @ 0x55a26347ec00] mmco: unref short failure
[h264 @ 0x55b50003e380] mmco: unref short failure
09/17/2024 00:04:12 - INFO - __main__ -   current idx M28z2aVJm9M.7 from finetune_area returns wrong image/video, use 148289 instead.
[h264 @ 0x55b51084a800] mmco: unref short failure
[h264 @ 0x55b51084a800] mmco: unref short failure
  4%|▍         | 124/2910 [42:28<26:38:22, 34.42s/it][h264 @ 0x56068c9d6b00] mmco: unref short failure
[h264 @ 0x56068c9d6b00] mmco: unref short failure
  4%|▍         | 125/2910 [42:33<19:46:22, 25.56s/it][h264 @ 0x55a26e26dd40] mmco: unref short failure
[h264 @ 0x560692c74480] mmco: unref short failure
[h264 @ 0x560692c74480] mmco: unref short failure
  4%|▍         | 126/2910 [42:46<16:52:38, 21.82s/it][h264 @ 0x55e19cf0b340] mmco: unref short failure
[h264 @ 0x55a25db3a3c0] mmco: unref short failure
  4%|▍         | 127/2910 [42:59<14:48:47, 19.16s/it]  4%|▍         | 128/2910 [43:05<11:38:42, 15.07s/it]  4%|▍         | 129/2910 [43:10<9:22:49, 12.14s/it] [h264 @ 0x55a25d939640] mmco: unref short failure
[h264 @ 0x55b50699f0c0] mmco: unref short failure
  4%|▍         | 130/2910 [43:16<7:58:23, 10.33s/it]  5%|▍         | 131/2910 [43:22<6:52:38,  8.91s/it][h264 @ 0x5606a2f36b80] mmco: unref short failure
[h264 @ 0x5606a2f36b80] mmco: unref short failure
[h264 @ 0x55a27277ed80] mmco: unref short failure
[h264 @ 0x55a27a5fe740] mmco: unref short failure
[h264 @ 0x55a27a5fe740] mmco: unref short failure
[h264 @ 0x55a25cad76c0] mmco: unref short failure
[h264 @ 0x55e19dbae900] mmco: unref short failure
[h264 @ 0x55e19dbae900] mmco: unref short failure
[h264 @ 0x55b5131c9580] mmco: unref short failure
[h264 @ 0x55b5131c9580] mmco: unref short failure
[h264 @ 0x55e19a9cf580] mmco: unref short failure
[h264 @ 0x55e19a9cf580] mmco: unref short failure
[h264 @ 0x55e19a9cf580] mmco: unref short failure
[h264 @ 0x55e19a9cf580] mmco: unref short failure
[h264 @ 0x55b5141925c0] mmco: unref short failure
09/17/2024 00:05:52 - INFO - __main__ -   current idx 6_p3rXnYE3Y.137 from finetune_area returns wrong image/video, use 38831 instead.
[h264 @ 0x5606a2f36740] mmco: unref short failure
[h264 @ 0x5606a2f36740] mmco: unref short failure
[h264 @ 0x55e199aefd00] mmco: unref short failure
[h264 @ 0x55e199aefd00] mmco: unref short failure
[h264 @ 0x55e199aefd00] mmco: unref short failure
[h264 @ 0x55e186c7a4c0] mmco: unref short failure
[h264 @ 0x55e186c7a4c0] mmco: unref short failure
[h264 @ 0x55e18a70f900] mmco: unref short failure
[h264 @ 0x55e18a70f900] mmco: unref short failure
[h264 @ 0x55a25e461880] mmco: unref short failure
[h264 @ 0x560690ef0ec0] mmco: unref short failure
[h264 @ 0x560690ef0ec0] mmco: unref short failure
  5%|▍         | 132/2910 [44:57<26:55:13, 34.89s/it]  5%|▍         | 133/2910 [45:02<19:59:17, 25.91s/it][h264 @ 0x55b50dc10480] mmco: unref short failure
[h264 @ 0x55b50dc10480] mmco: unref short failure
[h264 @ 0x55b4f7dcd5c0] mmco: unref short failure
[h264 @ 0x55b4f7dcd5c0] mmco: unref short failure
[h264 @ 0x55a275ccb440] mmco: unref short failure
[h264 @ 0x55a275ccb440] mmco: unref short failure
[h264 @ 0x55e183d46300] mmco: unref short failure
[h264 @ 0x55e183d46300] mmco: unref short failure
  5%|▍         | 134/2910 [45:14<16:40:55, 21.63s/it]  5%|▍         | 135/2910 [45:22<13:33:04, 17.58s/it][h264 @ 0x55b502210b00] mmco: unref short failure
[h264 @ 0x560695679480] mmco: unref short failure
  5%|▍         | 136/2910 [45:27<10:41:51, 13.88s/it]  5%|▍         | 137/2910 [45:32<8:43:52, 11.34s/it] [h264 @ 0x55b5002c08c0] mmco: unref short failure
[h264 @ 0x55b5002c08c0] mmco: unref short failure
[h264 @ 0x55a27bc3f000] mmco: unref short failure
  5%|▍         | 138/2910 [45:43<8:37:43, 11.21s/it]  5%|▍         | 139/2910 [45:48<7:13:30,  9.39s/it][h264 @ 0x560699864800] mmco: unref short failure
[h264 @ 0x560699864800] mmco: unref short failure
[h264 @ 0x560699864800] mmco: unref short failure
[h264 @ 0x560699864800] mmco: unref short failure
[h264 @ 0x560699864800] mmco: unref short failure
[h264 @ 0x560699864800] mmco: unref short failure
[h264 @ 0x55e18e6aac80] mmco: unref short failure
[h264 @ 0x55e18e6aac80] mmco: unref short failure
[h264 @ 0x55e1a0102ac0] mmco: unref short failure
[h264 @ 0x55e1a0102ac0] mmco: unref short failure
[h264 @ 0x56069ca6e300] mmco: unref short failure
[h264 @ 0x55e186c7ab80] mmco: unref short failure
09/17/2024 00:08:00 - INFO - __main__ -   current idx fwdyHxHBek4.10 from finetune_area returns wrong image/video, use 51250 instead.
[h264 @ 0x55b4f75b2540] mmco: unref short failure
[h264 @ 0x55b4f75b2540] mmco: unref short failure
[h264 @ 0x55e183c6fec0] mmco: unref short failure
[h264 @ 0x55e183c6fec0] mmco: unref short failure
[h264 @ 0x55e183c6fec0] mmco: unref short failure
[h264 @ 0x55e183c6fec0] mmco: unref short failure
09/17/2024 00:08:26 - INFO - __main__ -   current idx Xlq5RVCHKWg.8 from finetune_area returns wrong image/video, use 58295 instead.
09/17/2024 00:08:30 - INFO - __main__ -   current idx hvInlSH5o8c.6 from finetune_area returns wrong image/video, use 16063 instead.
[h264 @ 0x55b500182ec0] mmco: unref short failure
[h264 @ 0x55a26bafad00] mmco: unref short failure
[h264 @ 0x55a26bafad00] mmco: unref short failure
[h264 @ 0x55b4f8375300] mmco: unref short failure
[h264 @ 0x55b4f8375300] mmco: unref short failure
[h264 @ 0x55b4fdbca080] mmco: unref short failure
[h264 @ 0x55b4fdbca080] mmco: unref short failure
[h264 @ 0x55b4fdbca080] mmco: unref short failure
[h264 @ 0x55b4fdbca080] mmco: unref short failure
[h264 @ 0x55a263570980] mmco: unref short failure
[h264 @ 0x55a263570980] mmco: unref short failure
[h264 @ 0x55b5061bc400] mmco: unref short failure
09/17/2024 00:08:53 - INFO - __main__ -   current idx MVC6nKCrOgI.12 from finetune_area returns wrong image/video, use 71575 instead.
[h264 @ 0x55a26e23e100] mmco: unref short failure
[h264 @ 0x55a26e23e100] mmco: unref short failure
  5%|▍         | 140/2910 [47:27<27:45:43, 36.08s/it]  5%|▍         | 141/2910 [47:32<20:37:03, 26.81s/it]  5%|▍         | 142/2910 [47:39<16:06:10, 20.94s/it][h264 @ 0x55b4f4170200] mmco: unref short failure
[h264 @ 0x55b4f4170200] mmco: unref short failure
[h264 @ 0x55b4f4170200] mmco: unref short failure
[h264 @ 0x55b4f4170200] mmco: unref short failure
[h264 @ 0x5606a58ffb80] mmco: unref short failure
[h264 @ 0x5606a58ffb80] mmco: unref short failure
[h264 @ 0x5606a58ffb80] mmco: unref short failure
[h264 @ 0x5606a58ffb80] mmco: unref short failure
[h264 @ 0x55b506ba5280] mmco: unref short failure
[h264 @ 0x55b506ba5280] mmco: unref short failure
[h264 @ 0x55a26e4cb600] mmco: unref short failure
  5%|▍         | 143/2910 [47:44<12:25:12, 16.16s/it][h264 @ 0x55e1a24bf700] mmco: unref short failure
[h264 @ 0x55e1a24bf700] mmco: unref short failure
[h264 @ 0x55e189607c80] mmco: unref short failure
[h264 @ 0x55e189607c80] mmco: unref short failure
[h264 @ 0x55e189607c80] mmco: unref short failure
[h264 @ 0x55b50a09a380] mmco: unref short failure
  5%|▍         | 144/2910 [47:51<10:09:51, 13.23s/it][h264 @ 0x55e18b08ca40] mmco: unref short failure
09/17/2024 00:09:40 - INFO - __main__ -   current idx dIAiCVZ5tEo.28 from finetune_area returns wrong image/video, use 21760 instead.
  5%|▍         | 145/2910 [47:56<8:17:58, 10.81s/it]   5%|▌         | 146/2910 [48:07<8:24:40, 10.96s/it]  5%|▌         | 147/2910 [48:13<7:08:52,  9.31s/it][h264 @ 0x55a26e9ca700] mmco: unref short failure
[h264 @ 0x55b50b13b880] mmco: unref short failure
[h264 @ 0x55b50b13b880] mmco: unref short failure
[h264 @ 0x55e19e149300] mmco: unref short failure
[h264 @ 0x55a263fe43c0] mmco: unref short failure
[h264 @ 0x55a263fe43c0] mmco: unref short failure
[h264 @ 0x55a266f390c0] mmco: unref short failure
[h264 @ 0x55e18319c600] mmco: unref short failure
[h264 @ 0x55e18319c600] mmco: unref short failure
[h264 @ 0x56068d714580] mmco: unref short failure
[h264 @ 0x56068d714580] mmco: unref short failure
[h264 @ 0x56068d714580] mmco: unref short failure
[h264 @ 0x56068d714580] mmco: unref short failure
[h264 @ 0x55b500a36d80] mmco: unref short failure
[h264 @ 0x55a278b63fc0] mmco: unref short failure
[h264 @ 0x55a278b63fc0] mmco: unref short failure
[h264 @ 0x55a278b63fc0] mmco: unref short failure
[h264 @ 0x55a278b63fc0] mmco: unref short failure
[h264 @ 0x5606982e9380] mmco: unref short failure
[h264 @ 0x5606982e9380] mmco: unref short failure
[h264 @ 0x5606982e9380] mmco: unref short failure
[h264 @ 0x5606982e9380] mmco: unref short failure
09/17/2024 00:10:47 - INFO - __main__ -   current idx gtp43VGk4b0.59 from finetune_area returns wrong image/video, use 42619 instead.
[h264 @ 0x55a2759f3d80] mmco: unref short failure
[h264 @ 0x55a2759f3d80] mmco: unref short failure
[h264 @ 0x55b514de7800] mmco: unref short failure
[h264 @ 0x55b4f6e43980] mmco: unref short failure
[h264 @ 0x55b4f6e43980] mmco: unref short failure
[h264 @ 0x55e18c131d00] mmco: unref short failure
[h264 @ 0x55e18c131d00] mmco: unref short failure
09/17/2024 00:10:59 - INFO - __main__ -   current idx 7rNZakrnk74.48 from finetune_area returns wrong image/video, use 146023 instead.
[h264 @ 0x55e197028500] mmco: unref short failure
[h264 @ 0x5606ac0dcf00] mmco: unref short failure
  5%|▌         | 148/2910 [49:54<28:23:32, 37.01s/it]  5%|▌         | 149/2910 [49:59<20:58:06, 27.34s/it]09/17/2024 00:11:45 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 00:11:45 - INFO - __main__ -   start running ret%tva validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a25bcc4740] mmco: unref short failure
[h264 @ 0x55a25bcc4740] mmco: unref short failure
[h264 @ 0x55b4f4070a40] mmco: unref short failure
[h264 @ 0x55b4f4070a40] mmco: unref short failure
[h264 @ 0x56068d34f280] mmco: unref short failure
[h264 @ 0x55e1980cbd40] mmco: unref short failure
[h264 @ 0x55e1980cbd40] mmco: unref short failure
[h264 @ 0x55e1980cbd40] mmco: unref short failure
[h264 @ 0x55a2663818c0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x56068c28fd80] mmco: unref short failure
[h264 @ 0x56068c28fd80] mmco: unref short failure
[h264 @ 0x5606ac3c8cc0] mmco: unref short failure
[h264 @ 0x55a264f7a540] mmco: unref short failure
[h264 @ 0x55a274c33840] mmco: unref short failure
[h264 @ 0x55a274c33840] mmco: unref short failure
[h264 @ 0x55e1a7813600] mmco: unref short failure
[h264 @ 0x55e1a7813600] mmco: unref short failure
[h264 @ 0x5606ac19a5c0] mmco: unref short failure
[h264 @ 0x5606ac19a5c0] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:38,  2.24it/s][A
  1%|          | 2/221 [00:00<01:45,  2.07it/s][A
  1%|▏         | 3/221 [00:01<01:40,  2.17it/s][A
  2%|▏         | 4/221 [00:01<01:15,  2.86it/s][A
  2%|▏         | 5/221 [00:01<01:05,  3.32it/s][A
  3%|▎         | 7/221 [00:02<00:48,  4.38it/s][A
  4%|▎         | 8/221 [00:02<00:43,  4.87it/s][A
  4%|▍         | 9/221 [00:02<00:51,  4.11it/s][A
  5%|▍         | 10/221 [00:03<01:08,  3.07it/s][A[h264 @ 0x560699a1db00] mmco: unref short failure
[h264 @ 0x560699a1db00] mmco: unref short failure

  5%|▌         | 12/221 [00:03<00:57,  3.66it/s][A
  6%|▌         | 13/221 [00:03<00:54,  3.83it/s][A
  6%|▋         | 14/221 [00:04<00:53,  3.89it/s][A
  7%|▋         | 15/221 [00:04<00:50,  4.11it/s][A
  7%|▋         | 16/221 [00:04<01:01,  3.32it/s][A[h264 @ 0x5606a5c56f40] mmco: unref short failure

  8%|▊         | 17/221 [00:05<01:19,  2.55it/s][A
  8%|▊         | 18/221 [00:05<01:13,  2.75it/s][A
  9%|▊         | 19/221 [00:05<01:04,  3.13it/s][A
  9%|▉         | 20/221 [00:05<00:55,  3.60it/s][A
 10%|▉         | 21/221 [00:06<00:54,  3.65it/s][A
 10%|▉         | 22/221 [00:06<01:05,  3.03it/s][A
 10%|█         | 23/221 [00:06<00:53,  3.70it/s][A
 11%|█         | 24/221 [00:07<00:49,  4.01it/s][A
 11%|█▏        | 25/221 [00:07<00:46,  4.21it/s][A
 12%|█▏        | 26/221 [00:07<00:56,  3.45it/s][A
 12%|█▏        | 27/221 [00:07<00:46,  4.13it/s][A
 13%|█▎        | 28/221 [00:08<01:13,  2.61it/s][A
 13%|█▎        | 29/221 [00:08<01:08,  2.81it/s][A
 14%|█▎        | 30/221 [00:09<01:11,  2.68it/s][A
 14%|█▍        | 31/221 [00:09<01:07,  2.80it/s][A
 14%|█▍        | 32/221 [00:09<01:04,  2.93it/s][A
 15%|█▍        | 33/221 [00:10<00:59,  3.15it/s][A
 15%|█▌        | 34/221 [00:10<00:48,  3.87it/s][A
 16%|█▌        | 35/221 [00:10<00:45,  4.07it/s][A
 16%|█▋        | 36/221 [00:10<00:56,  3.28it/s][A
 17%|█▋        | 37/221 [00:11<01:02,  2.93it/s][A
 17%|█▋        | 38/221 [00:11<01:06,  2.77it/s][A
 18%|█▊        | 39/221 [00:11<00:52,  3.48it/s][A
 18%|█▊        | 40/221 [00:12<00:51,  3.50it/s][A
 19%|█▊        | 41/221 [00:12<00:45,  3.96it/s][A
 19%|█▉        | 42/221 [00:12<00:56,  3.15it/s][A
 19%|█▉        | 43/221 [00:12<00:50,  3.56it/s][A
 20%|█▉        | 44/221 [00:13<00:47,  3.70it/s][A
 20%|██        | 45/221 [00:13<01:01,  2.87it/s][A
 21%|██        | 46/221 [00:13<00:56,  3.11it/s][A
 21%|██▏       | 47/221 [00:14<01:24,  2.07it/s][A
 22%|██▏       | 48/221 [00:15<01:07,  2.56it/s][A
 22%|██▏       | 49/221 [00:15<01:01,  2.80it/s][A
 23%|██▎       | 50/221 [00:15<00:57,  2.98it/s][A
 23%|██▎       | 51/221 [00:15<00:49,  3.43it/s][A
 24%|██▎       | 52/221 [00:16<00:53,  3.14it/s][A
 24%|██▍       | 53/221 [00:16<00:46,  3.58it/s][A[h264 @ 0x55b4f91ec4c0] mmco: unref short failure
[h264 @ 0x55b4f91ec4c0] mmco: unref short failure

 24%|██▍       | 54/221 [00:17<01:45,  1.59it/s][A
 25%|██▍       | 55/221 [00:18<01:32,  1.79it/s][A
 25%|██▌       | 56/221 [00:18<01:10,  2.33it/s][A
 26%|██▌       | 57/221 [00:18<01:01,  2.68it/s][A
 26%|██▌       | 58/221 [00:18<00:55,  2.96it/s][A
 27%|██▋       | 59/221 [00:19<00:50,  3.23it/s][A
 27%|██▋       | 60/221 [00:20<01:21,  1.97it/s][A
 28%|██▊       | 61/221 [00:20<01:07,  2.36it/s][A
 28%|██▊       | 62/221 [00:20<01:08,  2.33it/s][A
 29%|██▊       | 63/221 [00:21<01:08,  2.31it/s][A[h264 @ 0x55a268c14b00] mmco: unref short failure
[h264 @ 0x55a268c14b00] mmco: unref short failure
[h264 @ 0x55b4f415eec0] mmco: unref short failure
[h264 @ 0x55b4f415eec0] mmco: unref short failure
[h264 @ 0x55b4f415eec0] mmco: unref short failure
[h264 @ 0x55b4f415eec0] mmco: unref short failure

 29%|██▉       | 64/221 [00:21<01:26,  1.81it/s][A
 29%|██▉       | 65/221 [00:22<01:09,  2.24it/s][A
 30%|██▉       | 66/221 [00:22<01:09,  2.22it/s][A
 30%|███       | 67/221 [00:22<00:58,  2.61it/s][A
 31%|███       | 68/221 [00:22<00:47,  3.23it/s][A
 31%|███       | 69/221 [00:23<01:12,  2.10it/s][A
 32%|███▏      | 70/221 [00:24<01:03,  2.38it/s][A
 32%|███▏      | 71/221 [00:24<00:55,  2.70it/s][A[h264 @ 0x55a2759d8100] mmco: unref short failure
[h264 @ 0x55a2759d8100] mmco: unref short failure

 33%|███▎      | 72/221 [00:24<00:59,  2.49it/s][A
 33%|███▎      | 73/221 [00:25<01:03,  2.32it/s][A
 33%|███▎      | 74/221 [00:25<00:49,  2.99it/s][A
 34%|███▍      | 75/221 [00:25<00:52,  2.76it/s][A
 34%|███▍      | 76/221 [00:26<00:50,  2.90it/s][A
 35%|███▍      | 77/221 [00:26<00:52,  2.76it/s][A
 35%|███▌      | 78/221 [00:26<00:41,  3.43it/s][A
 36%|███▌      | 79/221 [00:27<00:45,  3.10it/s][A
 36%|███▌      | 80/221 [00:27<00:42,  3.30it/s][A
 37%|███▋      | 81/221 [00:27<00:47,  2.97it/s][A
 37%|███▋      | 82/221 [00:28<00:46,  2.96it/s][A
 38%|███▊      | 83/221 [00:28<00:50,  2.71it/s][A
 38%|███▊      | 84/221 [00:28<00:47,  2.89it/s][A
 38%|███▊      | 85/221 [00:28<00:37,  3.66it/s][A
 39%|███▉      | 86/221 [00:29<00:32,  4.14it/s][A
 39%|███▉      | 87/221 [00:30<01:05,  2.05it/s][A
 40%|███▉      | 88/221 [00:30<01:13,  1.80it/s][A
 40%|████      | 89/221 [00:31<01:02,  2.11it/s][A[h264 @ 0x5606aa3813c0] mmco: unref short failure

 41%|████      | 90/221 [00:31<00:54,  2.42it/s][A
 41%|████      | 91/221 [00:31<00:43,  2.96it/s][A
 42%|████▏     | 92/221 [00:31<00:40,  3.21it/s][A09/17/2024 00:14:42 - INFO - __main__ -   current idx dMEgMG6TS3c.6 from finetune_area returns wrong image/video, use 15518 instead.

 42%|████▏     | 93/221 [00:32<00:46,  2.77it/s][A
 43%|████▎     | 94/221 [00:32<00:42,  2.98it/s][A
 43%|████▎     | 95/221 [00:32<00:41,  3.04it/s][A
 43%|████▎     | 96/221 [00:33<00:50,  2.47it/s][A
 44%|████▍     | 97/221 [00:33<00:44,  2.80it/s][A
 44%|████▍     | 98/221 [00:34<00:58,  2.11it/s][A
 45%|████▍     | 99/221 [00:34<00:50,  2.40it/s][A
 45%|████▌     | 100/221 [00:35<00:46,  2.60it/s][A
 46%|████▌     | 101/221 [00:35<00:44,  2.72it/s][A
 46%|████▌     | 102/221 [00:35<00:50,  2.38it/s][A
 47%|████▋     | 103/221 [00:36<00:39,  2.99it/s][A
 47%|████▋     | 104/221 [00:36<00:33,  3.46it/s][A
 48%|████▊     | 105/221 [00:36<00:33,  3.45it/s][A[h264 @ 0x56069dd16200] mmco: unref short failure
[h264 @ 0x56069dd16200] mmco: unref short failure

 48%|████▊     | 106/221 [00:37<00:52,  2.21it/s][A
 48%|████▊     | 107/221 [00:37<00:51,  2.22it/s][A
 49%|████▉     | 108/221 [00:38<00:44,  2.55it/s][A
 49%|████▉     | 109/221 [00:38<00:40,  2.75it/s][A
 50%|████▉     | 110/221 [00:38<00:32,  3.43it/s][A
 50%|█████     | 111/221 [00:38<00:33,  3.25it/s][A
 51%|█████     | 112/221 [00:39<00:32,  3.36it/s][A
 51%|█████     | 113/221 [00:39<00:30,  3.49it/s][A
 52%|█████▏    | 115/221 [00:39<00:22,  4.72it/s][A
 52%|█████▏    | 116/221 [00:40<00:32,  3.19it/s][A09/17/2024 00:14:51 - INFO - __main__ -   current idx 3xMq89jLDYE.29 from finetune_area returns wrong image/video, use 48211 instead.

 53%|█████▎    | 117/221 [00:40<00:35,  2.91it/s][A
 53%|█████▎    | 118/221 [00:40<00:32,  3.13it/s][A
 54%|█████▍    | 119/221 [00:41<00:33,  3.05it/s][A
 54%|█████▍    | 120/221 [00:41<00:27,  3.61it/s][A
 55%|█████▍    | 121/221 [00:41<00:23,  4.27it/s][A
 55%|█████▌    | 122/221 [00:41<00:26,  3.77it/s][A
 56%|█████▌    | 123/221 [00:42<00:24,  3.94it/s][A
 56%|█████▌    | 124/221 [00:42<00:34,  2.78it/s][A
 57%|█████▋    | 125/221 [00:43<00:42,  2.24it/s][A[h264 @ 0x55b4f49e8a40] mmco: unref short failure

 57%|█████▋    | 126/221 [00:43<00:40,  2.37it/s][A
 57%|█████▋    | 127/221 [00:45<01:10,  1.33it/s][A
 58%|█████▊    | 128/221 [00:45<01:01,  1.52it/s][A
 58%|█████▊    | 129/221 [00:45<00:45,  2.00it/s][A
 59%|█████▉    | 130/221 [00:46<00:38,  2.39it/s][A
 59%|█████▉    | 131/221 [00:46<00:32,  2.77it/s][A[h264 @ 0x55a2615b9880] mmco: unref short failure

 60%|█████▉    | 132/221 [00:47<00:55,  1.61it/s][A
 60%|██████    | 133/221 [00:47<00:48,  1.82it/s][A
 61%|██████    | 134/221 [00:48<00:56,  1.53it/s][A
 61%|██████    | 135/221 [00:49<00:53,  1.60it/s][A
 62%|██████▏   | 136/221 [00:49<00:47,  1.79it/s][A
 62%|██████▏   | 137/221 [00:50<00:40,  2.07it/s][A
 62%|██████▏   | 138/221 [00:50<00:38,  2.16it/s][A
 63%|██████▎   | 139/221 [00:51<00:44,  1.83it/s][A
 63%|██████▎   | 140/221 [00:51<00:40,  1.98it/s][A
 64%|██████▍   | 141/221 [00:52<00:37,  2.11it/s][A
 64%|██████▍   | 142/221 [00:52<00:35,  2.26it/s][A
 65%|██████▍   | 143/221 [00:52<00:34,  2.28it/s][A
 65%|██████▌   | 144/221 [00:53<00:32,  2.35it/s][A
 66%|██████▌   | 145/221 [00:53<00:25,  2.94it/s][A
 66%|██████▌   | 146/221 [00:53<00:22,  3.36it/s][A
 67%|██████▋   | 147/221 [00:54<00:25,  2.94it/s][A
 67%|██████▋   | 148/221 [00:54<00:27,  2.69it/s][A[h264 @ 0x55a260128740] mmco: unref short failure
[h264 @ 0x55a260128740] mmco: unref short failure

 67%|██████▋   | 149/221 [00:55<00:30,  2.38it/s][A
 68%|██████▊   | 150/221 [00:55<00:28,  2.53it/s][A
 68%|██████▊   | 151/221 [00:55<00:30,  2.27it/s][A
 69%|██████▉   | 152/221 [00:56<00:43,  1.59it/s][A
 69%|██████▉   | 153/221 [00:57<00:32,  2.07it/s][A
 70%|██████▉   | 154/221 [00:57<00:27,  2.41it/s][A
 70%|███████   | 155/221 [00:57<00:24,  2.70it/s][A
 71%|███████   | 156/221 [00:58<00:26,  2.49it/s][A
 71%|███████   | 157/221 [00:58<00:28,  2.27it/s][A
 71%|███████▏  | 158/221 [00:58<00:25,  2.50it/s][A
 72%|███████▏  | 159/221 [00:59<00:21,  2.92it/s][A
 72%|███████▏  | 160/221 [00:59<00:18,  3.33it/s][A
 73%|███████▎  | 161/221 [00:59<00:15,  3.86it/s][A
 73%|███████▎  | 162/221 [00:59<00:13,  4.52it/s][A
 74%|███████▍  | 163/221 [00:59<00:14,  4.03it/s][A
 74%|███████▍  | 164/221 [01:00<00:13,  4.08it/s][A
 75%|███████▍  | 165/221 [01:00<00:13,  4.20it/s][A
 75%|███████▌  | 166/221 [01:01<00:19,  2.88it/s][A
 76%|███████▌  | 167/221 [01:01<00:15,  3.54it/s][A
 76%|███████▌  | 168/221 [01:01<00:21,  2.46it/s][A
 76%|███████▋  | 169/221 [01:01<00:16,  3.13it/s][A[h264 @ 0x55e1889842c0] mmco: unref short failure

 77%|███████▋  | 170/221 [01:02<00:16,  3.10it/s][A
 77%|███████▋  | 171/221 [01:02<00:18,  2.74it/s][A
 78%|███████▊  | 172/221 [01:02<00:15,  3.15it/s][A
 78%|███████▊  | 173/221 [01:03<00:17,  2.74it/s][A
 79%|███████▊  | 174/221 [01:03<00:14,  3.19it/s][A
 79%|███████▉  | 175/221 [01:04<00:15,  3.06it/s][A
 80%|███████▉  | 176/221 [01:04<00:12,  3.62it/s][A
 80%|████████  | 177/221 [01:04<00:11,  3.73it/s][A
 81%|████████  | 178/221 [01:05<00:19,  2.18it/s][A
 81%|████████  | 179/221 [01:05<00:18,  2.24it/s][A
 81%|████████▏ | 180/221 [01:05<00:14,  2.84it/s][A
 82%|████████▏ | 182/221 [01:06<00:10,  3.83it/s][A
 83%|████████▎ | 183/221 [01:06<00:11,  3.38it/s][A
 83%|████████▎ | 184/221 [01:06<00:11,  3.10it/s][A
 84%|████████▎ | 185/221 [01:07<00:10,  3.31it/s][A
 84%|████████▍ | 186/221 [01:07<00:13,  2.55it/s][A
 85%|████████▍ | 187/221 [01:08<00:11,  2.87it/s][A
 85%|████████▌ | 188/221 [01:08<00:10,  3.05it/s][A
 86%|████████▌ | 189/221 [01:08<00:10,  2.95it/s][A
 86%|████████▌ | 190/221 [01:09<00:11,  2.74it/s][A
 86%|████████▋ | 191/221 [01:09<00:09,  3.15it/s][A
 87%|████████▋ | 192/221 [01:09<00:08,  3.36it/s][A
 87%|████████▋ | 193/221 [01:09<00:06,  4.18it/s][A
 88%|████████▊ | 194/221 [01:11<00:18,  1.44it/s][A
 88%|████████▊ | 195/221 [01:11<00:14,  1.82it/s][A
 89%|████████▊ | 196/221 [01:11<00:11,  2.23it/s][A
 89%|████████▉ | 197/221 [01:12<00:09,  2.49it/s][A
 90%|████████▉ | 198/221 [01:12<00:07,  2.90it/s][A
 90%|█████████ | 199/221 [01:12<00:07,  3.02it/s][A
 90%|█████████ | 200/221 [01:12<00:06,  3.48it/s][A
 91%|█████████ | 201/221 [01:13<00:05,  3.99it/s][A
 91%|█████████▏| 202/221 [01:13<00:04,  3.82it/s][A
 92%|█████████▏| 203/221 [01:13<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [01:13<00:04,  4.00it/s][A[h264 @ 0x55e182b757c0] mmco: unref short failure
[h264 @ 0x55e182b757c0] mmco: unref short failure

 93%|█████████▎| 205/221 [01:14<00:03,  4.35it/s][A
 93%|█████████▎| 206/221 [01:14<00:04,  3.01it/s][A
 94%|█████████▍| 208/221 [01:15<00:03,  3.52it/s][A
 95%|█████████▍| 209/221 [01:15<00:03,  3.60it/s][A
 95%|█████████▌| 211/221 [01:15<00:02,  3.92it/s][A
 96%|█████████▌| 212/221 [01:16<00:02,  3.86it/s][A
 96%|█████████▋| 213/221 [01:16<00:01,  4.11it/s][A
 97%|█████████▋| 214/221 [01:16<00:02,  2.87it/s][A
 97%|█████████▋| 215/221 [01:17<00:01,  3.39it/s][A[h264 @ 0x55e1a2d21000] mmco: unref short failure

 98%|█████████▊| 216/221 [01:17<00:01,  3.44it/s][A
 98%|█████████▊| 217/221 [01:17<00:01,  2.99it/s][A
 99%|█████████▊| 218/221 [01:18<00:01,  2.96it/s][A
 99%|█████████▉| 219/221 [01:18<00:00,  3.01it/s][A
100%|█████████▉| 220/221 [01:19<00:00,  2.33it/s][A
100%|██████████| 221/221 [01:19<00:00,  2.99it/s][A100%|██████████| 221/221 [01:19<00:00,  2.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:09,  3.18it/s][A
  1%|          | 2/221 [00:00<01:08,  3.19it/s][A
  1%|▏         | 3/221 [00:00<01:06,  3.28it/s][A
  2%|▏         | 4/221 [00:01<01:05,  3.30it/s][A
  2%|▏         | 5/221 [00:01<01:04,  3.34it/s][A
  3%|▎         | 6/221 [00:01<01:05,  3.30it/s][A
  3%|▎         | 7/221 [00:02<01:06,  3.24it/s][A
  4%|▎         | 8/221 [00:02<01:05,  3.23it/s][A
  4%|▍         | 9/221 [00:02<01:05,  3.25it/s][A
  5%|▍         | 10/221 [00:03<01:04,  3.29it/s][A
  5%|▍         | 11/221 [00:03<01:03,  3.30it/s][A
  5%|▌         | 12/221 [00:03<01:02,  3.33it/s][A
  6%|▌         | 13/221 [00:03<01:02,  3.35it/s][A
  6%|▋         | 14/221 [00:04<01:01,  3.35it/s][A
  7%|▋         | 15/221 [00:04<01:02,  3.30it/s][A
  7%|▋         | 16/221 [00:04<01:01,  3.33it/s][A
  8%|▊         | 17/221 [00:05<01:00,  3.35it/s][A
  8%|▊         | 18/221 [00:05<01:01,  3.33it/s][A
  9%|▊         | 19/221 [00:05<01:00,  3.35it/s][A
  9%|▉         | 20/221 [00:06<00:59,  3.36it/s][A
 10%|▉         | 21/221 [00:06<00:59,  3.35it/s][A
 10%|▉         | 22/221 [00:06<00:59,  3.35it/s][A
 10%|█         | 23/221 [00:06<00:59,  3.33it/s][A
 11%|█         | 24/221 [00:07<00:58,  3.35it/s][A
 11%|█▏        | 25/221 [00:07<00:58,  3.33it/s][A
 12%|█▏        | 26/221 [00:07<00:58,  3.35it/s][A
 12%|█▏        | 27/221 [00:08<00:59,  3.27it/s][A
 13%|█▎        | 28/221 [00:08<00:58,  3.27it/s][A
 13%|█▎        | 29/221 [00:08<00:58,  3.30it/s][A
 14%|█▎        | 30/221 [00:09<00:59,  3.22it/s][A
 14%|█▍        | 31/221 [00:09<00:58,  3.26it/s][A
 14%|█▍        | 32/221 [00:09<00:57,  3.26it/s][A
 15%|█▍        | 33/221 [00:10<00:57,  3.26it/s][A
 15%|█▌        | 34/221 [00:10<00:58,  3.22it/s][A
 16%|█▌        | 35/221 [00:10<00:57,  3.22it/s][A
 16%|█▋        | 36/221 [00:10<00:57,  3.24it/s][A
 17%|█▋        | 37/221 [00:11<00:55,  3.29it/s][A
 17%|█▋        | 38/221 [00:11<00:55,  3.32it/s][A
 18%|█▊        | 39/221 [00:11<00:55,  3.29it/s][A[h264 @ 0x5606972f0c40] mmco: unref short failure

 18%|█▊        | 40/221 [00:12<00:54,  3.32it/s][A
 19%|█▊        | 41/221 [00:12<00:53,  3.33it/s][A
 19%|█▉        | 42/221 [00:12<00:53,  3.35it/s][A
 19%|█▉        | 43/221 [00:13<00:52,  3.37it/s][A
 20%|█▉        | 44/221 [00:13<00:52,  3.38it/s][A
 20%|██        | 45/221 [00:13<00:52,  3.34it/s][A
 21%|██        | 46/221 [00:13<00:53,  3.28it/s][A
 21%|██▏       | 47/221 [00:14<00:52,  3.29it/s][A
 22%|██▏       | 48/221 [00:14<00:52,  3.28it/s][A
 22%|██▏       | 49/221 [00:14<00:52,  3.28it/s][A
 23%|██▎       | 50/221 [00:15<00:52,  3.27it/s][A
 23%|██▎       | 51/221 [00:15<00:51,  3.31it/s][A
 24%|██▎       | 52/221 [00:15<00:50,  3.33it/s][A
 24%|██▍       | 53/221 [00:16<00:50,  3.34it/s][A
 24%|██▍       | 54/221 [00:16<00:49,  3.36it/s][A
 25%|██▍       | 55/221 [00:16<00:49,  3.33it/s][A
 25%|██▌       | 56/221 [00:16<00:49,  3.33it/s][A
 26%|██▌       | 57/221 [00:17<00:48,  3.35it/s][A
 26%|██▌       | 58/221 [00:17<00:48,  3.37it/s][A
 27%|██▋       | 59/221 [00:17<00:48,  3.37it/s][A
 27%|██▋       | 60/221 [00:18<00:47,  3.38it/s][A
 28%|██▊       | 61/221 [00:18<00:47,  3.37it/s][A
 28%|██▊       | 62/221 [00:18<00:47,  3.37it/s][A
 29%|██▊       | 63/221 [00:19<00:47,  3.34it/s][A
 29%|██▉       | 64/221 [00:19<00:46,  3.36it/s][A
 29%|██▉       | 65/221 [00:19<00:46,  3.36it/s][A
 30%|██▉       | 66/221 [00:19<00:45,  3.38it/s][A
 30%|███       | 67/221 [00:20<00:45,  3.38it/s][A
 31%|███       | 68/221 [00:20<00:46,  3.27it/s][A
 31%|███       | 69/221 [00:20<00:46,  3.27it/s][A
 32%|███▏      | 70/221 [00:21<00:45,  3.31it/s][A
 32%|███▏      | 71/221 [00:21<00:45,  3.28it/s][A09/17/2024 00:15:54 - INFO - __main__ -   current idx DYY8KovKO3M.52 from finetune_area returns wrong image/video, use 146096 instead.

 33%|███▎      | 72/221 [00:21<00:45,  3.30it/s][A
 33%|███▎      | 73/221 [00:22<00:44,  3.33it/s][A
 33%|███▎      | 74/221 [00:22<00:44,  3.30it/s][A
 34%|███▍      | 75/221 [00:22<00:43,  3.33it/s][A
 34%|███▍      | 76/221 [00:22<00:43,  3.35it/s][A
 35%|███▍      | 77/221 [00:23<00:42,  3.37it/s][A
 35%|███▌      | 78/221 [00:23<00:42,  3.35it/s][A
 36%|███▌      | 79/221 [00:23<00:42,  3.37it/s][A
 36%|███▌      | 80/221 [00:24<00:41,  3.37it/s][A
 37%|███▋      | 81/221 [00:24<00:41,  3.38it/s][A
 37%|███▋      | 82/221 [00:24<00:41,  3.39it/s][A
 38%|███▊      | 83/221 [00:24<00:40,  3.38it/s][A
 38%|███▊      | 84/221 [00:25<00:40,  3.38it/s][A
 38%|███▊      | 85/221 [00:25<00:40,  3.39it/s][A
 39%|███▉      | 86/221 [00:25<00:39,  3.39it/s][A
 39%|███▉      | 87/221 [00:26<00:39,  3.40it/s][A
 40%|███▉      | 88/221 [00:26<00:39,  3.40it/s][A
 40%|████      | 89/221 [00:26<00:38,  3.40it/s][A
 41%|████      | 90/221 [00:27<00:38,  3.40it/s][A
 41%|████      | 91/221 [00:27<00:38,  3.40it/s][A
 42%|████▏     | 92/221 [00:27<00:37,  3.40it/s][A
 42%|████▏     | 93/221 [00:27<00:37,  3.41it/s][A
 43%|████▎     | 94/221 [00:28<00:37,  3.41it/s][A
 43%|████▎     | 95/221 [00:28<00:36,  3.41it/s][A
 43%|████▎     | 96/221 [00:28<00:36,  3.41it/s][A
 44%|████▍     | 97/221 [00:29<00:36,  3.41it/s][A
 44%|████▍     | 98/221 [00:29<00:36,  3.41it/s][A
 45%|████▍     | 99/221 [00:29<00:35,  3.41it/s][A
 45%|████▌     | 100/221 [00:29<00:35,  3.41it/s][A
 46%|████▌     | 101/221 [00:30<00:35,  3.41it/s][A
 46%|████▌     | 102/221 [00:30<00:34,  3.41it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.41it/s][A
 47%|████▋     | 104/221 [00:31<00:34,  3.41it/s][A
 48%|████▊     | 105/221 [00:31<00:34,  3.41it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.41it/s][A
 48%|████▊     | 107/221 [00:32<00:33,  3.41it/s][A
 49%|████▉     | 108/221 [00:32<00:33,  3.41it/s][A
 49%|████▉     | 109/221 [00:32<00:32,  3.41it/s][A
 50%|████▉     | 110/221 [00:32<00:32,  3.41it/s][A
 50%|█████     | 111/221 [00:33<00:32,  3.41it/s][A
 51%|█████     | 112/221 [00:33<00:31,  3.41it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.41it/s][A
 52%|█████▏    | 114/221 [00:34<00:31,  3.41it/s][A
 52%|█████▏    | 115/221 [00:34<00:31,  3.41it/s][A
 52%|█████▏    | 116/221 [00:34<00:30,  3.41it/s][A
 53%|█████▎    | 117/221 [00:34<00:30,  3.41it/s][A
 53%|█████▎    | 118/221 [00:35<00:30,  3.41it/s][A
 54%|█████▍    | 119/221 [00:35<00:29,  3.41it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.41it/s][A
 55%|█████▍    | 121/221 [00:36<00:29,  3.41it/s][A
 55%|█████▌    | 122/221 [00:36<00:29,  3.41it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.41it/s][A
 56%|█████▌    | 124/221 [00:37<00:28,  3.41it/s][A
 57%|█████▋    | 125/221 [00:37<00:28,  3.41it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.41it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.41it/s][A
 58%|█████▊    | 128/221 [00:38<00:27,  3.41it/s][A
 58%|█████▊    | 129/221 [00:38<00:26,  3.41it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.41it/s][A
 59%|█████▉    | 131/221 [00:39<00:26,  3.41it/s][A
 60%|█████▉    | 132/221 [00:39<00:26,  3.41it/s][A
 60%|██████    | 133/221 [00:39<00:25,  3.41it/s][A
 61%|██████    | 134/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:40<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:41<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:41<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:42<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:42<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:43<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:44<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:44<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:45<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:45<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:46<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:46<00:19,  3.42it/s][A
 71%|███████   | 157/221 [00:46<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:47<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:48<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:48<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:49<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:49<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:49<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:50<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:50<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:51<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:51<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:52<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:53<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:54<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:55<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:55<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:56<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:57<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:57<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:58<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:59<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [01:00<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:01<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:02<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:05<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.42it/s][A100%|██████████| 221/221 [01:05<00:00,  3.38it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:26,  8.38it/s][A
  1%|          | 2/221 [00:00<00:54,  3.99it/s][A
  1%|▏         | 3/221 [00:01<01:35,  2.29it/s][A
  2%|▏         | 4/221 [00:01<01:06,  3.24it/s][A
  2%|▏         | 5/221 [00:01<00:57,  3.74it/s][A
  3%|▎         | 6/221 [00:01<00:50,  4.24it/s][A
  3%|▎         | 7/221 [00:01<00:46,  4.64it/s][A
  4%|▎         | 8/221 [00:02<00:48,  4.36it/s][A
  4%|▍         | 9/221 [00:02<00:58,  3.65it/s][A
  5%|▍         | 10/221 [00:03<01:24,  2.49it/s][A
  5%|▍         | 11/221 [00:03<01:22,  2.54it/s][A
  5%|▌         | 12/221 [00:03<01:11,  2.92it/s][A
  6%|▌         | 13/221 [00:04<01:21,  2.54it/s][A
  6%|▋         | 14/221 [00:04<01:14,  2.78it/s][A
  7%|▋         | 15/221 [00:04<01:22,  2.50it/s][A
  7%|▋         | 16/221 [00:05<01:14,  2.75it/s][A
  8%|▊         | 17/221 [00:05<01:22,  2.46it/s][A
  8%|▊         | 18/221 [00:06<01:16,  2.66it/s][A
  9%|▊         | 19/221 [00:06<01:08,  2.96it/s][A
  9%|▉         | 20/221 [00:06<00:55,  3.61it/s][A
 10%|▉         | 21/221 [00:06<00:48,  4.12it/s][A
 10%|▉         | 22/221 [00:06<00:44,  4.52it/s][A
 10%|█         | 23/221 [00:06<00:37,  5.35it/s][A
 11%|█         | 24/221 [00:07<00:33,  5.89it/s][A
 11%|█▏        | 25/221 [00:07<00:36,  5.32it/s][A
 12%|█▏        | 26/221 [00:07<00:46,  4.22it/s][A
 12%|█▏        | 27/221 [00:07<00:44,  4.37it/s][A
 13%|█▎        | 28/221 [00:08<00:58,  3.30it/s][A
 13%|█▎        | 29/221 [00:08<00:58,  3.29it/s][A
 14%|█▎        | 30/221 [00:08<00:58,  3.28it/s][A
 14%|█▍        | 31/221 [00:09<00:56,  3.36it/s][A
 14%|█▍        | 32/221 [00:09<00:53,  3.53it/s][A
 15%|█▍        | 33/221 [00:09<00:49,  3.83it/s][A
 15%|█▌        | 34/221 [00:09<00:43,  4.28it/s][A
 16%|█▌        | 35/221 [00:09<00:36,  5.08it/s][A
 16%|█▋        | 36/221 [00:10<00:55,  3.31it/s][A
 17%|█▋        | 37/221 [00:10<00:53,  3.44it/s][A
 17%|█▋        | 38/221 [00:11<00:54,  3.35it/s][A
 18%|█▊        | 39/221 [00:11<00:45,  3.97it/s][A
 18%|█▊        | 40/221 [00:11<00:47,  3.82it/s][A
 19%|█▊        | 41/221 [00:11<00:46,  3.88it/s][A
 19%|█▉        | 42/221 [00:11<00:41,  4.29it/s][A
 19%|█▉        | 43/221 [00:12<00:52,  3.41it/s][A
 20%|█▉        | 44/221 [00:12<00:45,  3.86it/s][A
 20%|██        | 45/221 [00:12<00:51,  3.43it/s][A
 21%|██        | 46/221 [00:13<00:53,  3.26it/s][A
 21%|██▏       | 47/221 [00:13<00:44,  3.90it/s][A
 22%|██▏       | 49/221 [00:13<00:30,  5.65it/s][A
 23%|██▎       | 50/221 [00:14<00:46,  3.65it/s][A
 23%|██▎       | 51/221 [00:14<00:45,  3.74it/s][A
 24%|██▎       | 52/221 [00:14<00:40,  4.18it/s][A
 24%|██▍       | 53/221 [00:14<00:48,  3.43it/s][A
 24%|██▍       | 54/221 [00:15<00:45,  3.65it/s][A
 25%|██▍       | 55/221 [00:15<00:39,  4.24it/s][A
 25%|██▌       | 56/221 [00:15<00:38,  4.27it/s][A
 26%|██▌       | 57/221 [00:15<00:40,  4.07it/s][A
 27%|██▋       | 59/221 [00:16<00:34,  4.65it/s][A
 27%|██▋       | 60/221 [00:16<00:31,  5.07it/s][A
 28%|██▊       | 61/221 [00:16<00:31,  5.06it/s][A
 28%|██▊       | 62/221 [00:16<00:37,  4.24it/s][A
 29%|██▉       | 64/221 [00:17<00:32,  4.86it/s][A
 29%|██▉       | 65/221 [00:17<00:29,  5.33it/s][A
 30%|██▉       | 66/221 [00:17<00:34,  4.54it/s][A
 30%|███       | 67/221 [00:17<00:38,  3.98it/s][A
 31%|███       | 68/221 [00:18<00:37,  4.10it/s][A
 31%|███       | 69/221 [00:18<00:52,  2.92it/s][A
 32%|███▏      | 70/221 [00:18<00:44,  3.37it/s][A
 32%|███▏      | 71/221 [00:19<00:43,  3.45it/s][A
 33%|███▎      | 72/221 [00:19<00:53,  2.81it/s][A
 33%|███▎      | 73/221 [00:20<00:51,  2.89it/s][A
 33%|███▎      | 74/221 [00:20<00:40,  3.59it/s][A
 34%|███▍      | 75/221 [00:20<00:46,  3.16it/s][A
 34%|███▍      | 76/221 [00:20<00:43,  3.33it/s][A
 35%|███▍      | 77/221 [00:21<00:42,  3.41it/s][A
 35%|███▌      | 78/221 [00:21<00:39,  3.61it/s][A
 36%|███▌      | 79/221 [00:21<00:36,  3.85it/s][A
 36%|███▌      | 80/221 [00:21<00:35,  3.99it/s][A
 37%|███▋      | 81/221 [00:22<00:36,  3.86it/s][A
 37%|███▋      | 82/221 [00:22<00:32,  4.23it/s][A
 38%|███▊      | 83/221 [00:22<00:28,  4.89it/s][A
 38%|███▊      | 84/221 [00:22<00:34,  4.02it/s][A
 39%|███▉      | 86/221 [00:23<00:26,  5.03it/s][A
 39%|███▉      | 87/221 [00:23<00:34,  3.92it/s][A
 40%|███▉      | 88/221 [00:23<00:40,  3.25it/s][A
 40%|████      | 89/221 [00:24<00:43,  3.01it/s][A
 41%|████      | 90/221 [00:24<00:45,  2.90it/s][A
 41%|████      | 91/221 [00:24<00:40,  3.24it/s][A
 42%|████▏     | 92/221 [00:25<00:37,  3.40it/s][A
 42%|████▏     | 93/221 [00:25<00:40,  3.14it/s][A
 43%|████▎     | 94/221 [00:25<00:34,  3.64it/s][A
 43%|████▎     | 95/221 [00:26<00:53,  2.36it/s][A
 43%|████▎     | 96/221 [00:26<00:49,  2.54it/s][A
 44%|████▍     | 97/221 [00:27<00:46,  2.66it/s][A
 44%|████▍     | 98/221 [00:27<00:50,  2.45it/s][A
 45%|████▍     | 99/221 [00:27<00:46,  2.63it/s][A
 45%|████▌     | 100/221 [00:28<00:46,  2.62it/s][A
 46%|████▌     | 101/221 [00:28<00:49,  2.42it/s][A
 46%|████▌     | 102/221 [00:29<00:41,  2.84it/s][A
 47%|████▋     | 103/221 [00:29<00:33,  3.51it/s][A
 48%|████▊     | 105/221 [00:29<00:26,  4.43it/s][A
 48%|████▊     | 106/221 [00:29<00:30,  3.81it/s][A
 48%|████▊     | 107/221 [00:30<00:27,  4.09it/s][A
 49%|████▉     | 108/221 [00:30<00:30,  3.65it/s][A
 49%|████▉     | 109/221 [00:30<00:32,  3.50it/s][A
 50%|████▉     | 110/221 [00:30<00:28,  3.87it/s][A
 50%|█████     | 111/221 [00:31<00:31,  3.47it/s][A
 51%|█████     | 112/221 [00:31<00:31,  3.48it/s][A
 51%|█████     | 113/221 [00:31<00:28,  3.82it/s][A
 52%|█████▏    | 115/221 [00:32<00:21,  4.94it/s][A
 52%|█████▏    | 116/221 [00:32<00:20,  5.12it/s][A
 53%|█████▎    | 117/221 [00:32<00:21,  4.84it/s][A
 53%|█████▎    | 118/221 [00:32<00:25,  3.97it/s][A
 54%|█████▍    | 119/221 [00:33<00:30,  3.35it/s][A
 54%|█████▍    | 120/221 [00:33<00:29,  3.40it/s][A
 55%|█████▍    | 121/221 [00:33<00:32,  3.10it/s][A
 55%|█████▌    | 122/221 [00:34<00:33,  2.99it/s][A
 56%|█████▌    | 123/221 [00:34<00:28,  3.50it/s][A
 56%|█████▌    | 124/221 [00:34<00:33,  2.91it/s][A
 57%|█████▋    | 125/221 [00:35<00:36,  2.62it/s][A
 57%|█████▋    | 126/221 [00:35<00:30,  3.13it/s][A
 57%|█████▋    | 127/221 [00:36<00:35,  2.66it/s][A
 58%|█████▊    | 128/221 [00:36<00:30,  3.04it/s][A
 58%|█████▊    | 129/221 [00:36<00:24,  3.81it/s][A
 59%|█████▉    | 130/221 [00:36<00:25,  3.63it/s][A
 59%|█████▉    | 131/221 [00:36<00:22,  4.00it/s][A
 60%|█████▉    | 132/221 [00:37<00:29,  2.98it/s][A
 60%|██████    | 133/221 [00:37<00:28,  3.04it/s][A
 61%|██████    | 134/221 [00:38<00:36,  2.40it/s][A
 61%|██████    | 135/221 [00:38<00:30,  2.82it/s][A
 62%|██████▏   | 136/221 [00:38<00:29,  2.90it/s][A
 62%|██████▏   | 137/221 [00:39<00:26,  3.19it/s][A
 62%|██████▏   | 138/221 [00:39<00:24,  3.43it/s][A
 63%|██████▎   | 139/221 [00:39<00:25,  3.20it/s][A
 63%|██████▎   | 140/221 [00:40<00:24,  3.33it/s][A
 64%|██████▍   | 141/221 [00:40<00:25,  3.13it/s][A
 64%|██████▍   | 142/221 [00:40<00:23,  3.36it/s][A
 65%|██████▍   | 143/221 [00:40<00:22,  3.53it/s][A
 65%|██████▌   | 144/221 [00:41<00:21,  3.64it/s][A
 66%|██████▌   | 145/221 [00:41<00:22,  3.39it/s][A
 66%|██████▌   | 146/221 [00:41<00:20,  3.63it/s][A
 67%|██████▋   | 147/221 [00:41<00:16,  4.42it/s][A
 67%|██████▋   | 148/221 [00:42<00:32,  2.26it/s][A
 67%|██████▋   | 149/221 [00:42<00:27,  2.66it/s][A
 68%|██████▊   | 150/221 [00:43<00:24,  2.87it/s][A
 68%|██████▊   | 151/221 [00:44<00:43,  1.59it/s][A
 69%|██████▉   | 152/221 [00:45<00:40,  1.69it/s][A
 69%|██████▉   | 153/221 [00:45<00:33,  2.06it/s][A
 70%|██████▉   | 154/221 [00:45<00:29,  2.29it/s][A
 70%|███████   | 155/221 [00:45<00:24,  2.75it/s][A
 71%|███████   | 156/221 [00:46<00:21,  2.96it/s][A
 71%|███████   | 157/221 [00:46<00:19,  3.21it/s][A
 71%|███████▏  | 158/221 [00:46<00:20,  3.02it/s][A
 72%|███████▏  | 159/221 [00:46<00:17,  3.47it/s][A
 72%|███████▏  | 160/221 [00:47<00:19,  3.20it/s][A
 73%|███████▎  | 162/221 [00:47<00:11,  5.13it/s][A
 74%|███████▍  | 163/221 [00:47<00:11,  4.89it/s][A
 74%|███████▍  | 164/221 [00:47<00:11,  4.92it/s][A
 75%|███████▍  | 165/221 [00:48<00:12,  4.64it/s][A
 75%|███████▌  | 166/221 [00:48<00:12,  4.25it/s][A
 76%|███████▌  | 168/221 [00:48<00:11,  4.76it/s][A
 77%|███████▋  | 170/221 [00:49<00:10,  4.98it/s][A
 77%|███████▋  | 171/221 [00:49<00:14,  3.34it/s][A
 78%|███████▊  | 172/221 [00:49<00:13,  3.57it/s][A
 78%|███████▊  | 173/221 [00:50<00:14,  3.27it/s][A
 79%|███████▉  | 175/221 [00:50<00:11,  4.02it/s][A
 80%|███████▉  | 176/221 [00:50<00:10,  4.26it/s][A
 80%|████████  | 177/221 [00:51<00:11,  3.92it/s][A
 81%|████████  | 178/221 [00:51<00:17,  2.51it/s][A
 81%|████████  | 179/221 [00:52<00:16,  2.60it/s][A
 82%|████████▏ | 181/221 [00:52<00:10,  3.75it/s][A
 82%|████████▏ | 182/221 [00:52<00:10,  3.84it/s][A
 83%|████████▎ | 183/221 [00:53<00:10,  3.65it/s][A
 83%|████████▎ | 184/221 [00:53<00:11,  3.30it/s][A
 84%|████████▍ | 186/221 [00:53<00:09,  3.62it/s][A
 85%|████████▍ | 187/221 [00:54<00:08,  4.14it/s][A
 85%|████████▌ | 188/221 [00:54<00:07,  4.33it/s][A
 86%|████████▌ | 189/221 [00:54<00:07,  4.44it/s][A
 86%|████████▌ | 190/221 [00:54<00:08,  3.56it/s][A
 86%|████████▋ | 191/221 [00:55<00:06,  4.32it/s][A
 87%|████████▋ | 192/221 [00:55<00:08,  3.52it/s][A
 87%|████████▋ | 193/221 [00:55<00:08,  3.40it/s][A
 88%|████████▊ | 194/221 [00:56<00:09,  2.72it/s][A
 88%|████████▊ | 195/221 [00:56<00:10,  2.52it/s][A
 89%|████████▊ | 196/221 [00:57<00:10,  2.48it/s][A
 89%|████████▉ | 197/221 [00:57<00:11,  2.07it/s][A
 90%|████████▉ | 198/221 [00:58<00:09,  2.37it/s][A
 90%|█████████ | 199/221 [00:58<00:07,  2.94it/s][A
 90%|█████████ | 200/221 [00:58<00:05,  3.57it/s][A
 91%|█████████ | 201/221 [00:58<00:04,  4.03it/s][A
 91%|█████████▏| 202/221 [00:58<00:05,  3.58it/s][A
 92%|█████████▏| 203/221 [00:59<00:04,  3.65it/s][A
 92%|█████████▏| 204/221 [00:59<00:04,  4.02it/s][A
 93%|█████████▎| 205/221 [00:59<00:04,  3.89it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.11it/s][A
 94%|█████████▎| 207/221 [01:00<00:04,  3.30it/s][A
 94%|█████████▍| 208/221 [01:00<00:03,  3.25it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.17it/s][A
 95%|█████████▌| 210/221 [01:01<00:02,  3.68it/s][A
 95%|█████████▌| 211/221 [01:01<00:02,  3.68it/s][A
 96%|█████████▌| 212/221 [01:01<00:02,  3.41it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.60it/s][A
 97%|█████████▋| 214/221 [01:02<00:02,  3.08it/s][A
 97%|█████████▋| 215/221 [01:02<00:01,  3.09it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.35it/s][A
 98%|█████████▊| 217/221 [01:03<00:01,  3.20it/s][A
 99%|█████████▊| 218/221 [01:04<00:01,  2.56it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  2.71it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.32it/s][A
100%|██████████| 221/221 [01:04<00:00,  3.56it/s][A100%|██████████| 221/221 [01:04<00:00,  3.41it/s]
09/17/2024 00:17:45 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 149--===========

09/17/2024 00:17:45 - INFO - __main__ -   {'area_r1': 42.3, 'area_recall': '42.3/69.3/79.5', 'area_ravg': 63.7}
09/17/2024 00:17:45 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 149--===========

09/17/2024 00:17:45 - INFO - __main__ -   {'forward_r1': 37.7, 'forward_recall': '37.7/65.4/76.0', 'forward_ravg': 59.7}
09/17/2024 00:17:45 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 149--===========

09/17/2024 00:17:45 - INFO - __main__ -   {'area_video_r1': 38.0, 'area_video_recall': '38.0/65.7/76.2', 'area_video_ravg': 60.0}
09/17/2024 00:17:45 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 149=======

09/17/2024 00:17:45 - INFO - __main__ -   {'area_video_r1': 38.0, 'area_video_recall': '38.0/65.7/76.2', 'area_video_ravg': 60.0}
09/17/2024 00:17:45 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 149--===========

09/17/2024 00:17:45 - INFO - __main__ -   {'area_video_r1': 51.2, 'area_video_recall': '51.2/75.9/84.0', 'area_video_ravg': 70.4, 'area_video_back_r1': 50.0, 'area_video_back_recall': '50.0/73.0/80.8', 'area_video_back_ravg': 67.9}
09/17/2024 00:17:45 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 149=======

09/17/2024 00:17:45 - INFO - __main__ -   {'area_video_r1': 51.2, 'area_video_recall': '51.2/75.9/84.0', 'area_video_ravg': 70.4, 'area_video_back_r1': 50.0, 'area_video_back_recall': '50.0/73.0/80.8', 'area_video_back_ravg': 67.9}
09/17/2024 00:17:45 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 149--===========

09/17/2024 00:17:45 - INFO - __main__ -   {'video_r1': 36.1, 'video_recall': '36.1/65.6/75.9', 'video_ravg': 59.2}
09/17/2024 00:17:45 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 49=======

09/17/2024 00:17:45 - INFO - __main__ -   {'video_r1': 37.0, 'video_recall': '37.0/65.4/73.9', 'video_ravg': 58.7}
09/17/2024 00:17:45 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 149--===========

09/17/2024 00:17:45 - INFO - __main__ -   {'video_r1': 50.8, 'video_recall': '50.8/74.4/82.2', 'video_ravg': 69.2}
09/17/2024 00:17:45 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 99=======

09/17/2024 00:17:45 - INFO - __main__ -   {'video_r1': 50.9, 'video_recall': '50.9/73.4/81.4', 'video_ravg': 68.6}
09/17/2024 00:18:17 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.012868018820881844, 'loss_ret%tv%ta--finetune_area/loss_area': 2.5867505073547363, 'loss_ret%tv%ta--finetune_area/total_loss': 2.599618434906006}
[h264 @ 0x55e187197580] mmco: unref short failure
[h264 @ 0x55e187197580] mmco: unref short failure
  5%|▌         | 150/2910 [56:34<105:27:40, 137.56s/it][h264 @ 0x55e183090f40] mmco: unref short failure
[h264 @ 0x55e183090f40] mmco: unref short failure
[h264 @ 0x55e183090f40] mmco: unref short failure
[h264 @ 0x55e183090f40] mmco: unref short failure
[h264 @ 0x55e183090f40] mmco: unref short failure
[h264 @ 0x55e1873c6b40] mmco: unref short failure
09/17/2024 00:18:22 - INFO - __main__ -   current idx rGthtRZl8B0.21 from finetune_area returns wrong image/video, use 30520 instead.
  5%|▌         | 151/2910 [56:37<74:37:45, 97.38s/it]  [h264 @ 0x5606a3c67e80] mmco: unref short failure
  5%|▌         | 152/2910 [56:41<53:09:57, 69.40s/it]  5%|▌         | 153/2910 [56:46<38:12:27, 49.89s/it]  5%|▌         | 154/2910 [56:51<27:49:02, 36.34s/it][h264 @ 0x56069e81f880] mmco: unref short failure
  5%|▌         | 155/2910 [56:56<20:41:42, 27.04s/it]  5%|▌         | 156/2910 [57:01<15:45:37, 20.60s/it][h264 @ 0x55b4f8312b40] mmco: unref short failure
[h264 @ 0x55b5034c3580] mmco: unref short failure
  5%|▌         | 157/2910 [57:07<12:21:41, 16.16s/it]  5%|▌         | 158/2910 [57:13<10:03:28, 13.16s/it][h264 @ 0x55e184768ac0] mmco: unref short failure
[h264 @ 0x55e184768ac0] mmco: unref short failure
[h264 @ 0x55e184768ac0] mmco: unref short failure
[h264 @ 0x55e184768ac0] mmco: unref short failure
[h264 @ 0x55a27277e900] mmco: unref short failure
[h264 @ 0x55a27277e900] mmco: unref short failure
  5%|▌         | 159/2910 [57:19<8:17:54, 10.86s/it]   5%|▌         | 160/2910 [57:24<7:01:31,  9.20s/it][h264 @ 0x55a25e072680] mmco: unref short failure
[h264 @ 0x55a25e072680] mmco: unref short failure
  6%|▌         | 161/2910 [57:29<6:05:12,  7.97s/it]  6%|▌         | 162/2910 [57:35<5:37:53,  7.38s/it]  6%|▌         | 163/2910 [57:41<5:20:04,  6.99s/it][h264 @ 0x55e19ac03b40] mmco: unref short failure
  6%|▌         | 164/2910 [57:48<5:14:10,  6.86s/it][h264 @ 0x55b4f4d62900] mmco: unref short failure
[h264 @ 0x55b4f4d62900] mmco: unref short failure
[h264 @ 0x5606a3c68300] mmco: unref short failure
[h264 @ 0x5606a3c68300] mmco: unref short failure
  6%|▌         | 165/2910 [57:54<5:00:51,  6.58s/it][h264 @ 0x55e18b6e2280] mmco: unref short failure
[h264 @ 0x55e18b6e2280] mmco: unref short failure
[h264 @ 0x55b5040fddc0] mmco: unref short failure
[h264 @ 0x55b5040fddc0] mmco: unref short failure
[h264 @ 0x5606a5078180] mmco: unref short failure
[h264 @ 0x5606a5078180] mmco: unref short failure
[h264 @ 0x55b4f9a2de80] mmco: unref short failure
[h264 @ 0x55b4f9a2de80] mmco: unref short failure
[h264 @ 0x55b4f7115300] mmco: unref short failure
[h264 @ 0x55b4f7115300] mmco: unref short failure
[h264 @ 0x56068c291400] mmco: unref short failure
[h264 @ 0x55b4f4e37500] mmco: unref short failure
[h264 @ 0x55b4f4e37500] mmco: unref short failure
[h264 @ 0x55b4f4e37500] mmco: unref short failure
[h264 @ 0x55b4f4e37500] mmco: unref short failure
[h264 @ 0x5606a5002280] mmco: unref short failure
[h264 @ 0x5606a5002280] mmco: unref short failure
[h264 @ 0x55a2708ffd00] mmco: unref short failure
[h264 @ 0x55a2708ffd00] mmco: unref short failure
[h264 @ 0x5606934b33c0] mmco: unref short failure
[h264 @ 0x55b4fc827280] mmco: unref short failure
[h264 @ 0x55b4fc827280] mmco: unref short failure
[h264 @ 0x55b4fc827280] mmco: unref short failure
[h264 @ 0x55b4fc827280] mmco: unref short failure
  6%|▌         | 166/2910 [58:42<14:25:44, 18.93s/it][h264 @ 0x55a26107cb40] mmco: unref short failure
[h264 @ 0x56069ed03240] mmco: unref short failure
  6%|▌         | 167/2910 [58:56<13:20:59, 17.52s/it]09/17/2024 00:20:49 - INFO - __main__ -   current idx 6wN4IYAiKIg.70 from finetune_area returns wrong image/video, use 15062 instead.
[h264 @ 0x55a261a49600] mmco: unref short failure
[h264 @ 0x55a261a49600] mmco: unref short failure
[h264 @ 0x55e187bd67c0] mmco: unref short failure
[h264 @ 0x55e187bd67c0] mmco: unref short failure
[h264 @ 0x55e1906f2880] mmco: unref short failure
[h264 @ 0x55a25f8b0cc0] mmco: unref short failure
[h264 @ 0x55e1830ce3c0] mmco: unref short failure
[h264 @ 0x55e1830ce3c0] mmco: unref short failure
  6%|▌         | 168/2910 [59:19<14:34:58, 19.15s/it][h264 @ 0x55a26039e4c0] mmco: unref short failure
[h264 @ 0x55a26039e4c0] mmco: unref short failure
  6%|▌         | 169/2910 [59:27<12:04:30, 15.86s/it]  6%|▌         | 170/2910 [59:33<9:52:15, 12.97s/it] [h264 @ 0x5606a862d6c0] mmco: unref short failure
[h264 @ 0x55a271424bc0] mmco: unref short failure
[h264 @ 0x55a271424bc0] mmco: unref short failure
  6%|▌         | 171/2910 [59:43<9:11:32, 12.08s/it]09/17/2024 00:21:31 - INFO - __main__ -   current idx nCOpzvA0wgE.12 from finetune_area returns wrong image/video, use 6319 instead.
  6%|▌         | 172/2910 [59:49<7:40:52, 10.10s/it][h264 @ 0x55e1830ce1c0] mmco: unref short failure
  6%|▌         | 173/2910 [59:55<6:42:47,  8.83s/it][h264 @ 0x55e18357b7c0] mmco: unref short failure
[h264 @ 0x55e18357b7c0] mmco: unref short failure
[h264 @ 0x55e198158700] mmco: unref short failure
[h264 @ 0x55a265c328c0] mmco: unref short failure
[h264 @ 0x55a265c328c0] mmco: unref short failure
[h264 @ 0x5606a90a4e80] mmco: unref short failure
[h264 @ 0x5606a90a4e80] mmco: unref short failure
[h264 @ 0x55e1830d4780] mmco: unref short failure
[h264 @ 0x55a27c578480] mmco: unref short failure
[h264 @ 0x55a27c578480] mmco: unref short failure
[h264 @ 0x55e19bde2ec0] mmco: unref short failure
[h264 @ 0x55a277b246c0] mmco: unref short failure
[h264 @ 0x55a277b246c0] mmco: unref short failure
09/17/2024 00:22:15 - INFO - __main__ -   current idx 7OpYRTupJJ0.44 from finetune_area returns wrong image/video, use 70154 instead.
[h264 @ 0x55b4fb418d40] mmco: unref short failure
[h264 @ 0x55b4fb418d40] mmco: unref short failure
[h264 @ 0x55b50374ca00] mmco: unref short failure
[h264 @ 0x55b50374ca00] mmco: unref short failure
[h264 @ 0x5606918d7580] mmco: unref short failure
[h264 @ 0x5606918d7580] mmco: unref short failure
[h264 @ 0x55e19dc46600] mmco: unref short failure
[h264 @ 0x55e19dc46600] mmco: unref short failure
[h264 @ 0x55e19dc46600] mmco: unref short failure
[h264 @ 0x55a25fbff300] mmco: unref short failure
[h264 @ 0x55a25fbff300] mmco: unref short failure
[h264 @ 0x55a25bb037c0] mmco: unref short failure
  6%|▌         | 174/2910 [1:01:10<21:50:34, 28.74s/it][h264 @ 0x55e1935cbe40] mmco: unref short failure
09/17/2024 00:23:00 - INFO - __main__ -   current idx Yy-gLEskjRc.46 from finetune_area returns wrong image/video, use 78565 instead.
[h264 @ 0x55e187197ec0] mmco: unref short failure
[h264 @ 0x55e187197ec0] mmco: unref short failure
[h264 @ 0x55b512a68980] mmco: unref short failure
[h264 @ 0x55b512a68980] mmco: unref short failure
[h264 @ 0x55e1a1b33680] mmco: unref short failure
  6%|▌         | 175/2910 [1:01:27<19:14:09, 25.32s/it][h264 @ 0x55b4fef28400] mmco: unref short failure
[h264 @ 0x55b4fef28400] mmco: unref short failure
[h264 @ 0x55a265c328c0] mmco: unref short failure
[h264 @ 0x55a265c328c0] mmco: unref short failure
[h264 @ 0x55a265c328c0] mmco: unref short failure
[h264 @ 0x55e1a1c42380] mmco: unref short failure
[h264 @ 0x55e1a1c42380] mmco: unref short failure
09/17/2024 00:23:28 - INFO - __main__ -   current idx cdG0MaKc36M.46 from finetune_area returns wrong image/video, use 148488 instead.
  6%|▌         | 176/2910 [1:01:51<18:51:19, 24.83s/it][h264 @ 0x55a25f8eae00] mmco: unref short failure
[h264 @ 0x55a25f8eae00] mmco: unref short failure
  6%|▌         | 177/2910 [1:01:57<14:36:49, 19.25s/it]  6%|▌         | 178/2910 [1:02:06<12:22:27, 16.31s/it][h264 @ 0x55b50da7c280] mmco: unref short failure
[h264 @ 0x55b50da7c280] mmco: unref short failure
[h264 @ 0x56068f6c8f80] mmco: unref short failure
  6%|▌         | 179/2910 [1:02:15<10:36:53, 13.99s/it][h264 @ 0x55a2708ffd00] mmco: unref short failure
[h264 @ 0x55a2708ffd00] mmco: unref short failure
[h264 @ 0x56069381e300] mmco: unref short failure
[h264 @ 0x55b4f66fb400] mmco: unref short failure
[h264 @ 0x55b4f66fb400] mmco: unref short failure
  6%|▌         | 180/2910 [1:02:20<8:36:22, 11.35s/it]   6%|▌         | 181/2910 [1:02:26<7:15:55,  9.58s/it][h264 @ 0x55e1844cb980] mmco: unref short failure
[h264 @ 0x55e1844cb980] mmco: unref short failure
[h264 @ 0x56068c2c37c0] mmco: unref short failure
[h264 @ 0x56068c2c37c0] mmco: unref short failure
[h264 @ 0x55b4fbcd37c0] mmco: unref short failure
[h264 @ 0x55a268c91900] mmco: unref short failure
[h264 @ 0x55b51386dcc0] mmco: unref short failure
[h264 @ 0x55b51386dcc0] mmco: unref short failure
[h264 @ 0x55b4f96d5e40] mmco: unref short failure
[h264 @ 0x55b4f96d5e40] mmco: unref short failure
[h264 @ 0x55b4fbf00fc0] mmco: unref short failure
[h264 @ 0x55b4fbf00fc0] mmco: unref short failure
[h264 @ 0x55b4f5b23900] mmco: unref short failure
[h264 @ 0x55b4fa2f20c0] mmco: unref short failure
[h264 @ 0x55b4f9a99380] mmco: unref short failure
[h264 @ 0x55b50bdf77c0] mmco: unref short failure
[h264 @ 0x55b50bdf77c0] mmco: unref short failure
[h264 @ 0x55e193578240] mmco: unref short failure
[h264 @ 0x55e193578240] mmco: unref short failure
[h264 @ 0x55a25b8630c0] mmco: unref short failure
[h264 @ 0x55e19a26a700] mmco: unref short failure
[h264 @ 0x55e19a26a700] mmco: unref short failure
[h264 @ 0x55e196f04b40] mmco: unref short failure
[h264 @ 0x55e196f04b40] mmco: unref short failure
  6%|▋         | 182/2910 [1:03:40<21:51:46, 28.85s/it][h264 @ 0x55e1935cba00] mmco: unref short failure
[h264 @ 0x55e1935cba00] mmco: unref short failure
not have audios 8-qwaveiHMM.3
[h264 @ 0x55a27c586e40] mmco: unref short failure
  6%|▋         | 183/2910 [1:03:57<19:20:27, 25.53s/it][h264 @ 0x55b4fe53bc00] mmco: unref short failure
  6%|▋         | 184/2910 [1:04:11<16:40:22, 22.02s/it][h264 @ 0x55a25da3d9c0] mmco: unref short failure
[h264 @ 0x55b50c721c00] mmco: unref short failure
[h264 @ 0x55b50c721c00] mmco: unref short failure
  6%|▋         | 185/2910 [1:04:16<12:49:22, 16.94s/it][h264 @ 0x55b4f8327a00] mmco: unref short failure
[h264 @ 0x55b4f8327a00] mmco: unref short failure
[h264 @ 0x5606972f0d80] mmco: unref short failure
[h264 @ 0x5606972f0d80] mmco: unref short failure
[h264 @ 0x55e193577dc0] mmco: unref short failure
[h264 @ 0x55e193577dc0] mmco: unref short failure
[h264 @ 0x55b4fef28180] mmco: unref short failure
[h264 @ 0x55b4fef28180] mmco: unref short failure
[h264 @ 0x55b4f4055e00] mmco: unref short failure
[h264 @ 0x55b4f4055e00] mmco: unref short failure
  6%|▋         | 186/2910 [1:04:28<11:38:40, 15.39s/it][h264 @ 0x55a262ee93c0] mmco: unref short failure
[h264 @ 0x55e18c401900] mmco: unref short failure
[h264 @ 0x55e18c401900] mmco: unref short failure
[h264 @ 0x55b50e780640] mmco: unref short failure
[h264 @ 0x56069aebab00] mmco: unref short failure
[h264 @ 0x56069aebab00] mmco: unref short failure
[h264 @ 0x55e184110700] mmco: unref short failure
[h264 @ 0x55e184110700] mmco: unref short failure
  6%|▋         | 187/2910 [1:04:42<11:17:48, 14.94s/it]  6%|▋         | 188/2910 [1:04:47<9:03:33, 11.98s/it]   6%|▋         | 189/2910 [1:04:53<7:39:30, 10.13s/it]09/17/2024 00:26:42 - INFO - __main__ -   current idx eYV2bd-oyoQ.13 from finetune_area returns wrong image/video, use 132972 instead.
[h264 @ 0x56068dc87f40] mmco: unref short failure
[h264 @ 0x55a25bbf9640] mmco: unref short failure
[h264 @ 0x55a25bbf9640] mmco: unref short failure
[h264 @ 0x55b4f9d6d2c0] mmco: unref short failure
[h264 @ 0x55b4f9d6d2c0] mmco: unref short failure
[h264 @ 0x55b4fd236700] mmco: unref short failure
[h264 @ 0x55b4fd236700] mmco: unref short failure
[h264 @ 0x55b4f5072740] mmco: unref short failure
[h264 @ 0x55b4f5072740] mmco: unref short failure
[h264 @ 0x56068c695bc0] mmco: unref short failure
[h264 @ 0x56068c695bc0] mmco: unref short failure
[h264 @ 0x56068c695bc0] mmco: unref short failure
[h264 @ 0x56068c695bc0] mmco: unref short failure
[h264 @ 0x55b4f7d8b180] mmco: unref short failure
[h264 @ 0x55b4f7d8b180] mmco: unref short failure
[h264 @ 0x560691e15940] mmco: unref short failure
[h264 @ 0x55e184110940] mmco: unref short failure
[h264 @ 0x55e184110940] mmco: unref short failure
[h264 @ 0x55a264f7a9c0] mmco: unref short failure
[h264 @ 0x55a264f7a9c0] mmco: unref short failure
[h264 @ 0x55a264f7a9c0] mmco: unref short failure
[h264 @ 0x55a264f7a9c0] mmco: unref short failure
[h264 @ 0x55a279713100] mmco: unref short failure
[h264 @ 0x55a279713100] mmco: unref short failure
  7%|▋         | 190/2910 [1:06:21<25:26:11, 33.67s/it][h264 @ 0x55a25b7a8b40] mmco: unref short failure
[h264 @ 0x55a25b7a8b40] mmco: unref short failure
[h264 @ 0x55e18e768980] mmco: unref short failure
[h264 @ 0x55e18e768980] mmco: unref short failure
[h264 @ 0x55e18e768980] mmco: unref short failure
[h264 @ 0x55e18e768980] mmco: unref short failure
[h264 @ 0x55e18e768980] mmco: unref short failure
[h264 @ 0x55e18e768980] mmco: unref short failure
  7%|▋         | 191/2910 [1:06:35<20:58:11, 27.76s/it][h264 @ 0x56068c6a7440] mmco: unref short failure
[h264 @ 0x56068c6a7440] mmco: unref short failure
[h264 @ 0x55a266f00a80] mmco: unref short failure
[h264 @ 0x55a266f00a80] mmco: unref short failure
  7%|▋         | 192/2910 [1:06:42<16:05:38, 21.32s/it]09/17/2024 00:28:29 - INFO - __main__ -   current idx 6oFC5O_u-SI.107 from finetune_area returns wrong image/video, use 102237 instead.
  7%|▋         | 193/2910 [1:06:47<12:27:43, 16.51s/it][h264 @ 0x55e1887f9bc0] mmco: unref short failure
[h264 @ 0x55e1887f9bc0] mmco: unref short failure
[h264 @ 0x55b4fedc4e00] mmco: unref short failure
  7%|▋         | 194/2910 [1:06:54<10:24:26, 13.79s/it][h264 @ 0x55e184dc76c0] mmco: unref short failure
[h264 @ 0x5606a5002900] mmco: unref short failure
[h264 @ 0x55a260302280] mmco: unref short failure
[h264 @ 0x55a269d8d440] mmco: unref short failure
[h264 @ 0x55a262a5d400] mmco: unref short failure
  7%|▋         | 195/2910 [1:07:06<9:57:23, 13.20s/it]   7%|▋         | 196/2910 [1:07:12<8:23:08, 11.12s/it]  7%|▋         | 197/2910 [1:07:17<6:58:35,  9.26s/it][h264 @ 0x55a27f7c1d00] mmco: unref short failure
[h264 @ 0x55b50c7220c0] mmco: unref short failure
[h264 @ 0x55e1a33748c0] mmco: unref short failure
[h264 @ 0x55b5040fe000] mmco: unref short failure
[h264 @ 0x55b5040fe000] mmco: unref short failure
[h264 @ 0x55a273785f40] mmco: unref short failure
[h264 @ 0x55a262d79f40] mmco: unref short failure
09/17/2024 00:29:18 - INFO - __main__ -   current idx 988Ksd7axRY.8 from finetune_area returns wrong image/video, use 141681 instead.
[h264 @ 0x55a25fc1b4c0] mmco: unref short failure
[h264 @ 0x55a25fc1b4c0] mmco: unref short failure
09/17/2024 00:29:26 - INFO - __main__ -   current idx 9W2zPcc4Kl8.5 from finetune_area returns wrong image/video, use 35737 instead.
[h264 @ 0x55e18f2d3dc0] mmco: unref short failure
[h264 @ 0x55e18f2d3dc0] mmco: unref short failure
[h264 @ 0x55e191c9bcc0] mmco: unref short failure
[h264 @ 0x55e184110940] mmco: unref short failure
[h264 @ 0x55e184110940] mmco: unref short failure
[h264 @ 0x56068c0a4340] mmco: unref short failure
[h264 @ 0x55b51084a380] mmco: unref short failure
[h264 @ 0x55b51084a380] mmco: unref short failure
[h264 @ 0x55e1a7a68800] mmco: unref short failure
[h264 @ 0x55e18ffacd80] mmco: unref short failure
[h264 @ 0x55e18ffacd80] mmco: unref short failure
[h264 @ 0x55a27c578200] mmco: unref short failure
[h264 @ 0x55a27c578200] mmco: unref short failure
[h264 @ 0x55a262d2b780] mmco: unref short failure
[h264 @ 0x55a262d2b780] mmco: unref short failure
[h264 @ 0x5606ad984640] mmco: unref short failure
[h264 @ 0x55b4fd236b00] mmco: unref short failure
[h264 @ 0x5606a119b3c0] mmco: unref short failure
[h264 @ 0x5606a119b3c0] mmco: unref short failure
[h264 @ 0x55a25f1a3680] mmco: unref short failure
[h264 @ 0x55a25f1a3680] mmco: unref short failure
[h264 @ 0x560689e17f80] mmco: unref short failure
[h264 @ 0x560689e17f80] mmco: unref short failure
  7%|▋         | 198/2910 [1:08:47<25:08:17, 33.37s/it][h264 @ 0x55b50549cf00] mmco: unref short failure
  7%|▋         | 199/2910 [1:08:57<19:55:33, 26.46s/it]09/17/2024 00:30:43 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 00:30:43 - INFO - __main__ -   start running ret%tva validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e196fe7140] mmco: unref short failure
[h264 @ 0x55e196fe7140] mmco: unref short failure
[h264 @ 0x55a2710af700] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55b507b20880] mmco: unref short failure
[h264 @ 0x55b507b20880] mmco: unref short failure
[h264 @ 0x55b4f5072080] mmco: unref short failure
[h264 @ 0x55b4f5072080] mmco: unref short failure
[h264 @ 0x55e18d4c5240] mmco: unref short failure
[h264 @ 0x55e18d4c5240] mmco: unref short failure
[h264 @ 0x55e18d4c5240] mmco: unref short failure
[h264 @ 0x55b4f4637ac0] mmco: unref short failure
[h264 @ 0x55b4f4637ac0] mmco: unref short failure
[h264 @ 0x55e183aebcc0] mmco: unref short failure
[h264 @ 0x55e1830c3fc0] mmco: unref short failure
[h264 @ 0x55e1830c3fc0] mmco: unref short failure
[h264 @ 0x55a27abb0fc0] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:47,  2.05it/s][A
  1%|          | 2/221 [00:00<01:39,  2.20it/s][A
  1%|▏         | 3/221 [00:01<01:39,  2.18it/s][A
  2%|▏         | 4/221 [00:01<01:16,  2.84it/s][A
  2%|▏         | 5/221 [00:01<01:18,  2.77it/s][A09/17/2024 00:33:04 - INFO - __main__ -   current idx bdHJRIWkgos.39 from finetune_area returns wrong image/video, use 8538 instead.

  3%|▎         | 6/221 [00:02<01:01,  3.48it/s][A
  3%|▎         | 7/221 [00:02<00:55,  3.84it/s][A
  4%|▎         | 8/221 [00:02<00:46,  4.56it/s][A
  4%|▍         | 9/221 [00:02<00:51,  4.14it/s][A
  5%|▍         | 10/221 [00:03<01:11,  2.95it/s][A
  5%|▍         | 11/221 [00:03<01:02,  3.38it/s][A[h264 @ 0x55e1a1bf7bc0] mmco: unref short failure
[h264 @ 0x55e1a1bf7bc0] mmco: unref short failure

  5%|▌         | 12/221 [00:03<01:02,  3.33it/s][A
  6%|▌         | 13/221 [00:04<01:09,  3.00it/s][A
  6%|▋         | 14/221 [00:04<01:04,  3.19it/s][A
  7%|▋         | 15/221 [00:04<00:58,  3.55it/s][A
  7%|▋         | 16/221 [00:05<01:08,  2.98it/s][A
  8%|▊         | 17/221 [00:05<01:25,  2.38it/s][A
  8%|▊         | 18/221 [00:06<01:24,  2.41it/s][A
  9%|▊         | 19/221 [00:06<01:13,  2.76it/s][A
  9%|▉         | 20/221 [00:06<01:00,  3.33it/s][A
 10%|▉         | 21/221 [00:06<00:54,  3.66it/s][A
 10%|▉         | 22/221 [00:07<01:02,  3.20it/s][A
 10%|█         | 23/221 [00:07<00:57,  3.46it/s][A
 11%|█         | 24/221 [00:07<00:53,  3.65it/s][A
 11%|█▏        | 25/221 [00:07<00:47,  4.15it/s][A
 12%|█▏        | 26/221 [00:08<00:59,  3.28it/s][A
 12%|█▏        | 27/221 [00:08<00:49,  3.94it/s][A
 13%|█▎        | 28/221 [00:09<01:23,  2.32it/s][A
 13%|█▎        | 29/221 [00:09<01:10,  2.73it/s][A
 14%|█▎        | 30/221 [00:09<01:03,  3.02it/s][A
 14%|█▍        | 31/221 [00:10<01:01,  3.08it/s][A
 15%|█▍        | 33/221 [00:10<00:43,  4.35it/s][A
 15%|█▌        | 34/221 [00:10<00:38,  4.81it/s][A
 16%|█▌        | 35/221 [00:10<00:45,  4.05it/s][A
 16%|█▋        | 36/221 [00:11<00:54,  3.37it/s][A
 17%|█▋        | 37/221 [00:11<01:09,  2.67it/s][A
 17%|█▋        | 38/221 [00:12<01:18,  2.34it/s][A
 18%|█▊        | 40/221 [00:12<00:58,  3.07it/s][A
 19%|█▊        | 41/221 [00:12<00:50,  3.57it/s][A
 19%|█▉        | 42/221 [00:13<00:58,  3.05it/s][A
 19%|█▉        | 43/221 [00:13<00:52,  3.40it/s][A
 20%|█▉        | 44/221 [00:13<00:48,  3.67it/s][A
 20%|██        | 45/221 [00:14<01:06,  2.66it/s][A
 21%|██        | 46/221 [00:14<01:01,  2.84it/s][A[h264 @ 0x55b4f4167ec0] mmco: unref short failure

 21%|██▏       | 47/221 [00:15<01:28,  1.96it/s][A
 22%|██▏       | 48/221 [00:15<01:10,  2.45it/s][A
 22%|██▏       | 49/221 [00:16<01:05,  2.62it/s][A
 23%|██▎       | 50/221 [00:16<00:57,  2.97it/s][A
 23%|██▎       | 51/221 [00:16<00:47,  3.61it/s][A
 24%|██▎       | 52/221 [00:16<00:44,  3.84it/s][A
 24%|██▍       | 53/221 [00:16<00:38,  4.41it/s][A
 24%|██▍       | 54/221 [00:18<02:03,  1.36it/s][A
 25%|██▍       | 55/221 [00:19<01:51,  1.49it/s][A
 25%|██▌       | 56/221 [00:19<01:24,  1.96it/s][A
 26%|██▌       | 57/221 [00:19<01:07,  2.42it/s][A
 26%|██▌       | 58/221 [00:19<00:56,  2.87it/s][A
 27%|██▋       | 59/221 [00:19<00:50,  3.19it/s][A
 27%|██▋       | 60/221 [00:20<01:20,  2.00it/s][A
 28%|██▊       | 61/221 [00:21<01:04,  2.46it/s][A
 28%|██▊       | 62/221 [00:21<00:59,  2.65it/s][A
 29%|██▊       | 63/221 [00:21<00:50,  3.15it/s][A
 29%|██▉       | 64/221 [00:21<00:51,  3.05it/s][A
 29%|██▉       | 65/221 [00:22<00:44,  3.51it/s][A[h264 @ 0x5606a6de0fc0] mmco: unref short failure
[h264 @ 0x5606a6de0fc0] mmco: unref short failure

 30%|██▉       | 66/221 [00:22<01:01,  2.52it/s][A
 30%|███       | 67/221 [00:23<00:53,  2.86it/s][A
 31%|███       | 68/221 [00:23<00:42,  3.62it/s][A
 31%|███       | 69/221 [00:24<01:11,  2.13it/s][A
 32%|███▏      | 70/221 [00:24<00:59,  2.55it/s][A
 32%|███▏      | 71/221 [00:24<00:50,  2.98it/s][A
 33%|███▎      | 72/221 [00:24<00:50,  2.93it/s][A
 33%|███▎      | 73/221 [00:25<00:55,  2.64it/s][A
 33%|███▎      | 74/221 [00:25<00:44,  3.31it/s][A
 34%|███▍      | 75/221 [00:25<00:51,  2.83it/s][A
 34%|███▍      | 76/221 [00:26<00:46,  3.14it/s][A
 35%|███▍      | 77/221 [00:26<00:51,  2.80it/s][A
 35%|███▌      | 78/221 [00:26<00:40,  3.57it/s][A
 36%|███▌      | 79/221 [00:27<00:44,  3.17it/s][A
 36%|███▌      | 80/221 [00:27<00:41,  3.42it/s][A
 37%|███▋      | 81/221 [00:27<00:41,  3.40it/s][A
 37%|███▋      | 82/221 [00:28<00:52,  2.65it/s][A
 38%|███▊      | 83/221 [00:28<00:54,  2.55it/s][A
 38%|███▊      | 84/221 [00:28<00:46,  2.92it/s][A
 38%|███▊      | 85/221 [00:28<00:36,  3.70it/s][A
 39%|███▉      | 86/221 [00:29<00:33,  4.02it/s][A
 39%|███▉      | 87/221 [00:30<01:03,  2.11it/s][A
 40%|███▉      | 88/221 [00:30<01:11,  1.85it/s][A
 40%|████      | 89/221 [00:31<00:58,  2.25it/s][A
 41%|████      | 90/221 [00:31<00:50,  2.59it/s][A
 41%|████      | 91/221 [00:31<00:40,  3.19it/s][A
 42%|████▏     | 92/221 [00:31<00:37,  3.48it/s][A
 42%|████▏     | 93/221 [00:32<00:46,  2.76it/s][A
 43%|████▎     | 94/221 [00:32<00:43,  2.93it/s][A
 43%|████▎     | 95/221 [00:32<00:40,  3.12it/s][A
 43%|████▎     | 96/221 [00:33<00:57,  2.17it/s][A
 44%|████▍     | 97/221 [00:33<00:49,  2.52it/s][A[h264 @ 0x56069b8d69c0] mmco: unref short failure
[h264 @ 0x56069b8d69c0] mmco: unref short failure

 44%|████▍     | 98/221 [00:34<01:01,  2.01it/s][A
 45%|████▍     | 99/221 [00:34<00:54,  2.25it/s][A
 45%|████▌     | 100/221 [00:35<00:46,  2.60it/s][A
 46%|████▌     | 101/221 [00:35<00:40,  2.97it/s][A
 46%|████▌     | 102/221 [00:35<00:47,  2.48it/s][A
 47%|████▋     | 103/221 [00:36<00:38,  3.04it/s][A
 47%|████▋     | 104/221 [00:36<00:34,  3.35it/s][A
 48%|████▊     | 105/221 [00:36<00:34,  3.39it/s][A
 48%|████▊     | 106/221 [00:37<00:51,  2.24it/s][A
 48%|████▊     | 107/221 [00:37<00:43,  2.62it/s][A
 49%|████▉     | 108/221 [00:37<00:38,  2.93it/s][A
 49%|████▉     | 109/221 [00:38<00:34,  3.28it/s][A
 50%|████▉     | 110/221 [00:38<00:29,  3.79it/s][A
 50%|█████     | 111/221 [00:38<00:36,  3.03it/s][A
 51%|█████     | 112/221 [00:38<00:34,  3.19it/s][A
 51%|█████     | 113/221 [00:39<00:34,  3.14it/s][A
 52%|█████▏    | 114/221 [00:39<00:28,  3.73it/s][A
 52%|█████▏    | 115/221 [00:39<00:23,  4.55it/s][A
 52%|█████▏    | 116/221 [00:40<00:43,  2.42it/s][A
 53%|█████▎    | 117/221 [00:40<00:40,  2.54it/s][A
 53%|█████▎    | 118/221 [00:41<00:35,  2.87it/s][A
 54%|█████▍    | 119/221 [00:41<00:39,  2.60it/s][A
 54%|█████▍    | 120/221 [00:41<00:33,  2.99it/s][A
 55%|█████▍    | 121/221 [00:41<00:29,  3.40it/s][A
 55%|█████▌    | 122/221 [00:42<00:29,  3.36it/s][A
 56%|█████▌    | 123/221 [00:42<00:25,  3.90it/s][A
not have audios 7wavFXW3AFw.7
 56%|█████▌    | 124/221 [00:42<00:28,  3.37it/s][A
 57%|█████▋    | 125/221 [00:43<00:37,  2.59it/s][A
 57%|█████▋    | 126/221 [00:43<00:36,  2.57it/s][A
 57%|█████▋    | 127/221 [00:45<01:17,  1.21it/s][A
 58%|█████▊    | 128/221 [00:46<01:05,  1.43it/s][A
 58%|█████▊    | 129/221 [00:46<00:50,  1.83it/s][A
 59%|█████▉    | 130/221 [00:46<00:41,  2.22it/s][A
 59%|█████▉    | 131/221 [00:46<00:33,  2.66it/s][A[h264 @ 0x56068d69d080] mmco: unref short failure
[h264 @ 0x56068d69d080] mmco: unref short failure

 60%|█████▉    | 132/221 [00:47<00:53,  1.65it/s][A
 60%|██████    | 133/221 [00:48<00:49,  1.78it/s][A
 61%|██████    | 134/221 [00:49<00:56,  1.55it/s][A
 61%|██████    | 135/221 [00:49<00:51,  1.67it/s][A
 62%|██████▏   | 136/221 [00:49<00:45,  1.88it/s][A
 62%|██████▏   | 137/221 [00:50<00:37,  2.23it/s][A
 62%|██████▏   | 138/221 [00:50<00:36,  2.30it/s][A
 63%|██████▎   | 139/221 [00:51<00:47,  1.73it/s][A
 63%|██████▎   | 140/221 [00:51<00:43,  1.88it/s][A
 64%|██████▍   | 141/221 [00:52<00:36,  2.18it/s][A
 64%|██████▍   | 142/221 [00:52<00:33,  2.33it/s][A[h264 @ 0x55e188d9f680] mmco: unref short failure
[h264 @ 0x55e188d9f680] mmco: unref short failure

 65%|██████▍   | 143/221 [00:53<00:35,  2.21it/s][A
 65%|██████▌   | 144/221 [00:53<00:31,  2.43it/s][A
 66%|██████▌   | 145/221 [00:53<00:24,  3.07it/s][A
 66%|██████▌   | 146/221 [00:53<00:19,  3.81it/s][A
 67%|██████▋   | 147/221 [00:53<00:20,  3.64it/s][A
 67%|██████▋   | 148/221 [00:54<00:21,  3.39it/s][A
 67%|██████▋   | 149/221 [00:54<00:23,  3.09it/s][A
 68%|██████▊   | 150/221 [00:54<00:20,  3.46it/s][A
 68%|██████▊   | 151/221 [00:55<00:27,  2.50it/s][A
 69%|██████▉   | 152/221 [00:57<00:51,  1.33it/s][A
 69%|██████▉   | 153/221 [00:57<00:39,  1.71it/s][A
 70%|██████▉   | 154/221 [00:57<00:32,  2.04it/s][A
 70%|███████   | 155/221 [00:57<00:28,  2.33it/s][A
 71%|███████   | 156/221 [00:58<00:30,  2.14it/s][A[h264 @ 0x55e1922f3980] mmco: unref short failure
[h264 @ 0x55e1922f3980] mmco: unref short failure

 71%|███████   | 157/221 [00:59<00:35,  1.81it/s][A
 71%|███████▏  | 158/221 [00:59<00:29,  2.12it/s][A
 72%|███████▏  | 159/221 [00:59<00:23,  2.63it/s][A
 72%|███████▏  | 160/221 [00:59<00:20,  3.00it/s][A
 73%|███████▎  | 161/221 [01:00<00:17,  3.45it/s][A
 73%|███████▎  | 162/221 [01:00<00:14,  4.07it/s][A
 74%|███████▍  | 163/221 [01:00<00:15,  3.67it/s][A
 74%|███████▍  | 164/221 [01:00<00:16,  3.44it/s][A
 75%|███████▍  | 165/221 [01:00<00:13,  4.02it/s][A
 75%|███████▌  | 166/221 [01:01<00:16,  3.36it/s][A
 76%|███████▌  | 167/221 [01:01<00:13,  3.90it/s][A[h264 @ 0x56069eff4e80] mmco: unref short failure
[h264 @ 0x56069eff4e80] mmco: unref short failure

 76%|███████▌  | 168/221 [01:02<00:22,  2.35it/s][A
 76%|███████▋  | 169/221 [01:02<00:19,  2.67it/s][A
 77%|███████▋  | 170/221 [01:02<00:17,  2.91it/s][A
 77%|███████▋  | 171/221 [01:03<00:18,  2.78it/s][A
 78%|███████▊  | 172/221 [01:03<00:15,  3.14it/s][A
 78%|███████▊  | 173/221 [01:03<00:17,  2.81it/s][A
 79%|███████▊  | 174/221 [01:04<00:15,  3.12it/s][A
 79%|███████▉  | 175/221 [01:04<00:14,  3.12it/s][A
 80%|███████▉  | 176/221 [01:04<00:11,  3.88it/s][A
 80%|████████  | 177/221 [01:04<00:09,  4.45it/s][A
 81%|████████  | 178/221 [01:05<00:16,  2.57it/s][A
 81%|████████  | 179/221 [01:06<00:17,  2.41it/s][A
 81%|████████▏ | 180/221 [01:06<00:13,  2.98it/s][A
 82%|████████▏ | 182/221 [01:06<00:10,  3.83it/s][A
 83%|████████▎ | 183/221 [01:06<00:10,  3.46it/s][A
 83%|████████▎ | 184/221 [01:07<00:12,  2.96it/s][A
 84%|████████▎ | 185/221 [01:07<00:10,  3.55it/s][A
 84%|████████▍ | 186/221 [01:07<00:11,  2.98it/s][A
 85%|████████▍ | 187/221 [01:08<00:10,  3.19it/s][A
 85%|████████▌ | 188/221 [01:08<00:09,  3.44it/s][A
 86%|████████▌ | 189/221 [01:08<00:09,  3.22it/s][A[h264 @ 0x55e1a2d03740] mmco: unref short failure
[h264 @ 0x55e1a2d03740] mmco: unref short failure

 86%|████████▌ | 190/221 [01:09<00:10,  2.86it/s][A
 86%|████████▋ | 191/221 [01:09<00:08,  3.57it/s][A
 87%|████████▋ | 192/221 [01:09<00:08,  3.57it/s][A
 88%|████████▊ | 194/221 [01:11<00:14,  1.90it/s][A
 88%|████████▊ | 195/221 [01:11<00:12,  2.16it/s][A
 89%|████████▊ | 196/221 [01:11<00:10,  2.41it/s][A
 89%|████████▉ | 197/221 [01:12<00:08,  2.72it/s][A
 90%|████████▉ | 198/221 [01:12<00:07,  3.03it/s][A
 90%|█████████ | 199/221 [01:12<00:06,  3.17it/s][A
 90%|█████████ | 200/221 [01:12<00:05,  3.73it/s][A
 91%|█████████ | 201/221 [01:13<00:05,  3.38it/s][A
 91%|█████████▏| 202/221 [01:13<00:06,  3.11it/s][A[h264 @ 0x55e193453580] mmco: unref short failure

 92%|█████████▏| 203/221 [01:13<00:05,  3.21it/s][A
 92%|█████████▏| 204/221 [01:14<00:04,  3.49it/s][A
 93%|█████████▎| 205/221 [01:14<00:04,  3.96it/s][A
 93%|█████████▎| 206/221 [01:14<00:05,  2.68it/s][A
 94%|█████████▍| 208/221 [01:15<00:04,  3.17it/s][A
 95%|█████████▍| 209/221 [01:15<00:03,  3.33it/s][A
 95%|█████████▌| 211/221 [01:16<00:02,  3.66it/s][A
 96%|█████████▌| 212/221 [01:16<00:02,  3.63it/s][A
 96%|█████████▋| 213/221 [01:16<00:02,  3.71it/s][A
 97%|█████████▋| 214/221 [01:17<00:02,  2.60it/s][A
 97%|█████████▋| 215/221 [01:17<00:02,  2.96it/s][A
 98%|█████████▊| 216/221 [01:17<00:01,  3.03it/s][A
 98%|█████████▊| 217/221 [01:18<00:01,  2.72it/s][A
 99%|█████████▊| 218/221 [01:18<00:01,  2.84it/s][A
 99%|█████████▉| 219/221 [01:18<00:00,  2.99it/s][A
100%|█████████▉| 220/221 [01:19<00:00,  2.03it/s][A
100%|██████████| 221/221 [01:19<00:00,  2.63it/s][A100%|██████████| 221/221 [01:19<00:00,  2.77it/s]
[h264 @ 0x55e182d9edc0] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A[h264 @ 0x55e1a6629e00] mmco: unref short failure

  0%|          | 1/221 [00:00<01:07,  3.26it/s][A
  1%|          | 2/221 [00:00<01:05,  3.34it/s][A
  1%|▏         | 3/221 [00:00<01:05,  3.33it/s][A
  2%|▏         | 4/221 [00:01<01:04,  3.36it/s][A
  2%|▏         | 5/221 [00:01<01:04,  3.36it/s][A
  3%|▎         | 6/221 [00:01<01:03,  3.37it/s][A
  3%|▎         | 7/221 [00:02<01:03,  3.35it/s][A
  4%|▎         | 8/221 [00:02<01:03,  3.37it/s][A
  4%|▍         | 9/221 [00:02<01:03,  3.33it/s][A
  5%|▍         | 10/221 [00:02<01:03,  3.31it/s][A
  5%|▍         | 11/221 [00:03<01:03,  3.32it/s][A
  5%|▌         | 12/221 [00:03<01:02,  3.34it/s][A
  6%|▌         | 13/221 [00:03<01:01,  3.36it/s][A
  6%|▋         | 14/221 [00:04<01:01,  3.37it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.38it/s][A
  7%|▋         | 16/221 [00:04<01:00,  3.38it/s][A
  8%|▊         | 17/221 [00:05<01:00,  3.35it/s][A
  8%|▊         | 18/221 [00:05<01:01,  3.28it/s][A
  9%|▊         | 19/221 [00:05<01:01,  3.29it/s][A
  9%|▉         | 20/221 [00:05<01:00,  3.32it/s][A
 10%|▉         | 21/221 [00:06<00:59,  3.34it/s][A
 10%|▉         | 22/221 [00:06<01:00,  3.32it/s][A
 10%|█         | 23/221 [00:06<00:59,  3.34it/s][A
 11%|█         | 24/221 [00:07<00:58,  3.36it/s][A
 11%|█▏        | 25/221 [00:07<00:59,  3.31it/s][A
 12%|█▏        | 26/221 [00:07<00:58,  3.33it/s][A
 12%|█▏        | 27/221 [00:08<00:58,  3.31it/s][A
 13%|█▎        | 28/221 [00:08<00:58,  3.33it/s][A
 13%|█▎        | 29/221 [00:08<00:59,  3.22it/s][A
 14%|█▎        | 30/221 [00:09<00:58,  3.25it/s][A
 14%|█▍        | 31/221 [00:09<00:57,  3.29it/s][A
 14%|█▍        | 32/221 [00:09<00:57,  3.31it/s][A
 15%|█▍        | 33/221 [00:09<00:56,  3.33it/s][A
 15%|█▌        | 34/221 [00:10<00:56,  3.29it/s][A
 16%|█▌        | 35/221 [00:10<00:56,  3.27it/s][A
 16%|█▋        | 36/221 [00:10<00:56,  3.27it/s][A
 17%|█▋        | 37/221 [00:11<00:56,  3.28it/s][A
 17%|█▋        | 38/221 [00:11<00:56,  3.26it/s][A
 18%|█▊        | 39/221 [00:11<00:56,  3.24it/s][A
 18%|█▊        | 40/221 [00:12<00:55,  3.24it/s][A
 19%|█▊        | 41/221 [00:12<00:54,  3.29it/s][A
 19%|█▉        | 42/221 [00:12<00:55,  3.24it/s][A09/17/2024 00:34:37 - INFO - __main__ -   current idx 0GZSfBuhf6Y.63 from finetune_area returns wrong image/video, use 98921 instead.

 19%|█▉        | 43/221 [00:12<00:54,  3.29it/s][A
 20%|█▉        | 44/221 [00:13<00:53,  3.31it/s][A
 20%|██        | 45/221 [00:13<00:53,  3.30it/s][A
 21%|██        | 46/221 [00:13<00:52,  3.33it/s][A[h264 @ 0x56069b611b00] mmco: unref short failure

 21%|██▏       | 47/221 [00:14<00:52,  3.32it/s][A
 22%|██▏       | 48/221 [00:14<00:51,  3.33it/s][A
 22%|██▏       | 49/221 [00:14<00:51,  3.35it/s][A
 23%|██▎       | 50/221 [00:15<00:50,  3.37it/s][A
 23%|██▎       | 51/221 [00:15<00:50,  3.38it/s][A
 24%|██▎       | 52/221 [00:15<00:50,  3.38it/s][A[h264 @ 0x55a261d27a00] mmco: unref short failure
[h264 @ 0x55a261d27a00] mmco: unref short failure

 24%|██▍       | 53/221 [00:15<00:49,  3.37it/s][A
 24%|██▍       | 54/221 [00:16<00:49,  3.38it/s][A
 25%|██▍       | 55/221 [00:16<00:49,  3.39it/s][A
 25%|██▌       | 56/221 [00:16<00:48,  3.39it/s][A
 26%|██▌       | 57/221 [00:17<00:48,  3.39it/s][A
 26%|██▌       | 58/221 [00:17<00:48,  3.39it/s][A
 27%|██▋       | 59/221 [00:17<00:47,  3.40it/s][A
 27%|██▋       | 60/221 [00:18<00:47,  3.40it/s][A
 28%|██▊       | 61/221 [00:18<00:47,  3.36it/s][A
 28%|██▊       | 62/221 [00:18<00:47,  3.36it/s][A
 29%|██▊       | 63/221 [00:18<00:46,  3.37it/s][A
 29%|██▉       | 64/221 [00:19<00:46,  3.38it/s][A
 29%|██▉       | 65/221 [00:19<00:46,  3.39it/s][A
 30%|██▉       | 66/221 [00:19<00:45,  3.38it/s][A
 30%|███       | 67/221 [00:20<00:45,  3.39it/s][A
 31%|███       | 68/221 [00:20<00:45,  3.38it/s][A
 31%|███       | 69/221 [00:20<00:44,  3.39it/s][A
 32%|███▏      | 70/221 [00:20<00:44,  3.37it/s][A
 32%|███▏      | 71/221 [00:21<00:44,  3.38it/s][A
 33%|███▎      | 72/221 [00:21<00:44,  3.34it/s][A
 33%|███▎      | 73/221 [00:21<00:44,  3.36it/s][A
 33%|███▎      | 74/221 [00:22<00:43,  3.37it/s][A
 34%|███▍      | 75/221 [00:22<00:43,  3.38it/s][A
 34%|███▍      | 76/221 [00:22<00:42,  3.39it/s][A
 35%|███▍      | 77/221 [00:23<00:42,  3.38it/s][A
 35%|███▌      | 78/221 [00:23<00:42,  3.38it/s][A
 36%|███▌      | 79/221 [00:23<00:42,  3.35it/s][A
 36%|███▌      | 80/221 [00:23<00:41,  3.36it/s][A
 37%|███▋      | 81/221 [00:24<00:41,  3.37it/s][A
 37%|███▋      | 82/221 [00:24<00:41,  3.37it/s][A
 38%|███▊      | 83/221 [00:24<00:41,  3.35it/s][A
 38%|███▊      | 84/221 [00:25<00:40,  3.37it/s][A
 38%|███▊      | 85/221 [00:25<00:40,  3.38it/s][A
 39%|███▉      | 86/221 [00:25<00:39,  3.38it/s][A
 39%|███▉      | 87/221 [00:26<00:39,  3.38it/s][A
 40%|███▉      | 88/221 [00:26<00:39,  3.36it/s][A
 40%|████      | 89/221 [00:26<00:39,  3.33it/s][A
 41%|████      | 90/221 [00:26<00:39,  3.29it/s][A
 41%|████      | 91/221 [00:27<00:39,  3.32it/s][A
 42%|████▏     | 92/221 [00:27<00:38,  3.31it/s][A
 42%|████▏     | 93/221 [00:27<00:38,  3.34it/s][A
 43%|████▎     | 94/221 [00:28<00:37,  3.36it/s][A
 43%|████▎     | 95/221 [00:28<00:37,  3.37it/s][A
 43%|████▎     | 96/221 [00:28<00:36,  3.38it/s][A
 44%|████▍     | 97/221 [00:29<00:36,  3.39it/s][A
 44%|████▍     | 98/221 [00:29<00:36,  3.39it/s][A[h264 @ 0x55b4f8327c40] mmco: unref short failure

 45%|████▍     | 99/221 [00:29<00:35,  3.39it/s][A
 45%|████▌     | 100/221 [00:29<00:35,  3.40it/s][A
 46%|████▌     | 101/221 [00:30<00:35,  3.40it/s][A
 46%|████▌     | 102/221 [00:30<00:34,  3.40it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.40it/s][A
 47%|████▋     | 104/221 [00:31<00:34,  3.40it/s][A
 48%|████▊     | 105/221 [00:31<00:34,  3.40it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.40it/s][A[h264 @ 0x55b4f9d6d2c0] mmco: unref short failure

 48%|████▊     | 107/221 [00:31<00:33,  3.40it/s][A
 49%|████▉     | 108/221 [00:32<00:33,  3.40it/s][A
 49%|████▉     | 109/221 [00:32<00:32,  3.40it/s][A
 50%|████▉     | 110/221 [00:32<00:32,  3.40it/s][A
 50%|█████     | 111/221 [00:33<00:32,  3.41it/s][A
 51%|█████     | 112/221 [00:33<00:31,  3.41it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.41it/s][A
 52%|█████▏    | 114/221 [00:34<00:31,  3.41it/s][A
 52%|█████▏    | 115/221 [00:34<00:31,  3.41it/s][A
 52%|█████▏    | 116/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:35<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:35<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:36<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:37<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:38<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:38<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:39<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:40<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:41<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:41<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:42<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:43<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:44<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:45<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:45<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:46<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:46<00:19,  3.42it/s][A
 71%|███████   | 157/221 [00:46<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:47<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:48<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:48<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:48<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:49<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:49<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:50<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:50<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:51<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:52<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:53<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:54<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:55<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:55<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:57<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:57<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:57<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:59<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [01:00<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:02<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:05<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.42it/s][A100%|██████████| 221/221 [01:05<00:00,  3.38it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:30,  7.17it/s][A
  1%|          | 2/221 [00:00<00:54,  4.00it/s][A
  1%|▏         | 3/221 [00:01<01:36,  2.27it/s][A
  2%|▏         | 4/221 [00:01<01:08,  3.19it/s][A
  2%|▏         | 5/221 [00:01<00:57,  3.77it/s][A
  3%|▎         | 6/221 [00:01<00:48,  4.43it/s][A
  3%|▎         | 7/221 [00:01<00:44,  4.79it/s][A
  4%|▎         | 8/221 [00:01<00:45,  4.64it/s][A
  4%|▍         | 9/221 [00:02<00:59,  3.58it/s][A
  5%|▍         | 10/221 [00:03<01:25,  2.46it/s][A
  5%|▍         | 11/221 [00:03<01:23,  2.50it/s][A
  5%|▌         | 12/221 [00:03<01:10,  2.96it/s][A
  6%|▌         | 13/221 [00:04<01:24,  2.47it/s][A
  6%|▋         | 14/221 [00:04<01:12,  2.84it/s][A
  7%|▋         | 15/221 [00:04<01:17,  2.67it/s][A
  7%|▋         | 16/221 [00:05<01:10,  2.89it/s][A
  8%|▊         | 17/221 [00:05<01:20,  2.53it/s][A
  8%|▊         | 18/221 [00:06<01:16,  2.67it/s][A
  9%|▊         | 19/221 [00:06<01:08,  2.94it/s][A
  9%|▉         | 20/221 [00:06<00:55,  3.59it/s][A
 10%|▉         | 21/221 [00:06<00:47,  4.17it/s][A
 10%|▉         | 22/221 [00:06<00:43,  4.61it/s][A
 11%|█         | 24/221 [00:06<00:32,  6.00it/s][A
 11%|█▏        | 25/221 [00:07<00:36,  5.34it/s][A
 12%|█▏        | 26/221 [00:07<00:44,  4.42it/s][A
 12%|█▏        | 27/221 [00:07<00:42,  4.57it/s][A
 13%|█▎        | 28/221 [00:08<00:58,  3.31it/s][A
 13%|█▎        | 29/221 [00:08<00:53,  3.59it/s][A
 14%|█▎        | 30/221 [00:08<00:55,  3.46it/s][A
 14%|█▍        | 31/221 [00:09<00:56,  3.38it/s][A
 14%|█▍        | 32/221 [00:09<00:51,  3.70it/s][A
 15%|█▍        | 33/221 [00:09<00:47,  3.99it/s][A
 15%|█▌        | 34/221 [00:09<00:42,  4.36it/s][A
 16%|█▌        | 35/221 [00:09<00:38,  4.86it/s][A
 16%|█▋        | 36/221 [00:10<01:04,  2.88it/s][A
 17%|█▋        | 37/221 [00:10<00:58,  3.12it/s][A
 17%|█▋        | 38/221 [00:11<00:56,  3.23it/s][A
 18%|█▊        | 39/221 [00:11<00:46,  3.89it/s][A
 18%|█▊        | 40/221 [00:11<00:49,  3.64it/s][A
 19%|█▊        | 41/221 [00:11<00:48,  3.74it/s][A
 19%|█▉        | 42/221 [00:11<00:42,  4.20it/s][A
 19%|█▉        | 43/221 [00:12<00:57,  3.11it/s][A
 20%|█▉        | 44/221 [00:12<00:50,  3.53it/s][A
 20%|██        | 45/221 [00:12<00:52,  3.35it/s][A
 21%|██        | 46/221 [00:13<00:51,  3.43it/s][A
 21%|██▏       | 47/221 [00:13<00:43,  4.05it/s][A
 22%|██▏       | 49/221 [00:13<00:30,  5.64it/s][A
 23%|██▎       | 50/221 [00:14<00:44,  3.85it/s][A
 23%|██▎       | 51/221 [00:14<00:42,  3.97it/s][A
 24%|██▎       | 52/221 [00:14<00:37,  4.54it/s][A
 24%|██▍       | 53/221 [00:14<00:46,  3.60it/s][A
 24%|██▍       | 54/221 [00:15<00:45,  3.69it/s][A
 25%|██▍       | 55/221 [00:15<00:38,  4.28it/s][A
 25%|██▌       | 56/221 [00:15<00:39,  4.15it/s][A
 26%|██▌       | 57/221 [00:15<00:43,  3.81it/s][A
 27%|██▋       | 59/221 [00:16<00:36,  4.46it/s][A
 27%|██▋       | 60/221 [00:16<00:33,  4.86it/s][A
 28%|██▊       | 61/221 [00:16<00:32,  4.87it/s][A
 28%|██▊       | 62/221 [00:16<00:35,  4.42it/s][A
 29%|██▉       | 64/221 [00:17<00:30,  5.19it/s][A
 29%|██▉       | 65/221 [00:17<00:28,  5.53it/s][A
 30%|██▉       | 66/221 [00:17<00:33,  4.62it/s][A
 30%|███       | 67/221 [00:18<00:42,  3.59it/s][A
 31%|███       | 68/221 [00:18<00:38,  3.94it/s][A
 31%|███       | 69/221 [00:18<00:53,  2.86it/s][A
 32%|███▏      | 70/221 [00:19<00:46,  3.28it/s][A
 32%|███▏      | 71/221 [00:19<00:44,  3.34it/s][A
 33%|███▎      | 72/221 [00:19<00:54,  2.71it/s][A
 33%|███▎      | 73/221 [00:20<00:50,  2.93it/s][A
 33%|███▎      | 74/221 [00:20<00:40,  3.59it/s][A
 34%|███▍      | 75/221 [00:20<00:48,  2.99it/s][A
 34%|███▍      | 76/221 [00:20<00:43,  3.30it/s][A
 35%|███▍      | 77/221 [00:21<00:47,  3.03it/s][A
 35%|███▌      | 78/221 [00:21<00:42,  3.35it/s][A
 36%|███▌      | 79/221 [00:21<00:40,  3.51it/s][A
 36%|███▌      | 80/221 [00:22<00:36,  3.86it/s][A
 37%|███▋      | 81/221 [00:22<00:36,  3.80it/s][A
 37%|███▋      | 82/221 [00:22<00:34,  4.05it/s][A
 38%|███▊      | 83/221 [00:22<00:29,  4.66it/s][A
 38%|███▊      | 84/221 [00:22<00:34,  3.98it/s][A
 39%|███▉      | 86/221 [00:23<00:24,  5.46it/s][A
 39%|███▉      | 87/221 [00:23<00:32,  4.13it/s][A
 40%|███▉      | 88/221 [00:23<00:36,  3.66it/s][A
 40%|████      | 89/221 [00:24<00:40,  3.26it/s][A
 41%|████      | 90/221 [00:24<00:47,  2.78it/s][A
 41%|████      | 91/221 [00:25<00:40,  3.17it/s][A
 42%|████▏     | 92/221 [00:25<00:37,  3.46it/s][A
 42%|████▏     | 93/221 [00:25<00:40,  3.13it/s][A
 43%|████▎     | 94/221 [00:25<00:35,  3.56it/s][A
 43%|████▎     | 95/221 [00:26<00:49,  2.55it/s][A
 43%|████▎     | 96/221 [00:26<00:45,  2.75it/s][A
 44%|████▍     | 97/221 [00:27<00:42,  2.89it/s][A
 44%|████▍     | 98/221 [00:27<00:47,  2.57it/s][A
 45%|████▍     | 99/221 [00:27<00:46,  2.65it/s][A
 45%|████▌     | 100/221 [00:28<00:42,  2.87it/s][A
 46%|████▌     | 101/221 [00:28<00:47,  2.53it/s][A
 46%|████▌     | 102/221 [00:29<00:42,  2.79it/s][A
 47%|████▋     | 103/221 [00:29<00:34,  3.40it/s][A
 48%|████▊     | 105/221 [00:29<00:28,  4.09it/s][A
 48%|████▊     | 106/221 [00:29<00:31,  3.62it/s][A
 48%|████▊     | 107/221 [00:30<00:28,  3.95it/s][A
 49%|████▉     | 108/221 [00:30<00:33,  3.40it/s][A
 49%|████▉     | 109/221 [00:30<00:32,  3.41it/s][A
 50%|████▉     | 110/221 [00:30<00:28,  3.86it/s][A
 50%|█████     | 111/221 [00:31<00:31,  3.46it/s][A
 51%|█████     | 112/221 [00:31<00:30,  3.52it/s][A
 51%|█████     | 113/221 [00:31<00:28,  3.77it/s][A
 52%|█████▏    | 115/221 [00:32<00:21,  4.89it/s][A
 52%|█████▏    | 116/221 [00:32<00:21,  4.95it/s][A
 53%|█████▎    | 117/221 [00:32<00:21,  4.84it/s][A
 53%|█████▎    | 118/221 [00:32<00:26,  3.90it/s][A
 54%|█████▍    | 119/221 [00:33<00:31,  3.20it/s][A
 54%|█████▍    | 120/221 [00:33<00:30,  3.26it/s][A
 55%|█████▍    | 121/221 [00:34<00:32,  3.08it/s][A
 55%|█████▌    | 122/221 [00:34<00:31,  3.13it/s][A
 56%|█████▌    | 123/221 [00:34<00:27,  3.62it/s][A
 56%|█████▌    | 124/221 [00:34<00:32,  3.02it/s][A
 57%|█████▋    | 125/221 [00:35<00:38,  2.50it/s][A
 57%|█████▋    | 126/221 [00:35<00:32,  2.89it/s][A
 57%|█████▋    | 127/221 [00:36<00:37,  2.48it/s][A
 58%|█████▊    | 128/221 [00:36<00:32,  2.83it/s][A
 58%|█████▊    | 129/221 [00:36<00:26,  3.49it/s][A
 59%|█████▉    | 130/221 [00:36<00:24,  3.68it/s][A
 59%|█████▉    | 131/221 [00:37<00:22,  3.97it/s][A
 60%|█████▉    | 132/221 [00:37<00:29,  3.01it/s][A
 60%|██████    | 133/221 [00:37<00:28,  3.04it/s][A
 61%|██████    | 134/221 [00:38<00:36,  2.39it/s][A
 61%|██████    | 135/221 [00:38<00:30,  2.86it/s][A
 62%|██████▏   | 136/221 [00:39<00:29,  2.93it/s][A
 62%|██████▏   | 137/221 [00:39<00:25,  3.25it/s][A
 62%|██████▏   | 138/221 [00:39<00:24,  3.44it/s][A
 63%|██████▎   | 139/221 [00:39<00:25,  3.25it/s][A
 63%|██████▎   | 140/221 [00:40<00:23,  3.40it/s][A
 64%|██████▍   | 141/221 [00:40<00:22,  3.55it/s][A
 64%|██████▍   | 142/221 [00:40<00:21,  3.66it/s][A
 65%|██████▍   | 143/221 [00:40<00:20,  3.74it/s][A
 65%|██████▌   | 144/221 [00:41<00:18,  4.12it/s][A
 66%|██████▌   | 145/221 [00:41<00:21,  3.59it/s][A
 66%|██████▌   | 146/221 [00:41<00:19,  3.81it/s][A
 67%|██████▋   | 147/221 [00:41<00:16,  4.50it/s][A
 67%|██████▋   | 148/221 [00:42<00:26,  2.76it/s][A
 67%|██████▋   | 149/221 [00:42<00:22,  3.19it/s][A
 68%|██████▊   | 150/221 [00:42<00:19,  3.60it/s][A
 68%|██████▊   | 151/221 [00:44<00:40,  1.75it/s][A
 69%|██████▉   | 152/221 [00:44<00:39,  1.76it/s][A
 69%|██████▉   | 153/221 [00:44<00:32,  2.07it/s][A
 70%|██████▉   | 154/221 [00:45<00:29,  2.26it/s][A
 70%|███████   | 155/221 [00:45<00:25,  2.60it/s][A
 71%|███████   | 156/221 [00:45<00:24,  2.66it/s][A
 71%|███████   | 157/221 [00:46<00:21,  3.01it/s][A
 71%|███████▏  | 158/221 [00:46<00:22,  2.86it/s][A
 72%|███████▏  | 159/221 [00:46<00:18,  3.40it/s][A
 72%|███████▏  | 160/221 [00:47<00:21,  2.82it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.47it/s][A
 74%|███████▍  | 163/221 [00:47<00:12,  4.48it/s][A
 74%|███████▍  | 164/221 [00:47<00:12,  4.66it/s][A
 75%|███████▍  | 165/221 [00:48<00:11,  4.97it/s][A
 75%|███████▌  | 166/221 [00:48<00:12,  4.42it/s][A
 76%|███████▌  | 168/221 [00:48<00:10,  5.01it/s][A
 77%|███████▋  | 170/221 [00:49<00:10,  4.95it/s][A
 77%|███████▋  | 171/221 [00:49<00:13,  3.70it/s][A
 78%|███████▊  | 172/221 [00:49<00:13,  3.77it/s][A
 78%|███████▊  | 173/221 [00:50<00:13,  3.51it/s][A
 79%|███████▉  | 175/221 [00:50<00:11,  4.01it/s][A
 80%|███████▉  | 176/221 [00:50<00:10,  4.42it/s][A
 80%|████████  | 177/221 [00:50<00:10,  4.12it/s][A
 81%|████████  | 178/221 [00:51<00:15,  2.81it/s][A
 81%|████████  | 179/221 [00:52<00:15,  2.79it/s][A
 82%|████████▏ | 181/221 [00:52<00:09,  4.01it/s][A
 82%|████████▏ | 182/221 [00:52<00:09,  4.05it/s][A
 83%|████████▎ | 183/221 [00:52<00:10,  3.71it/s][A
 83%|████████▎ | 184/221 [00:53<00:11,  3.31it/s][A
 84%|████████▍ | 186/221 [00:53<00:09,  3.86it/s][A
 85%|████████▍ | 187/221 [00:53<00:07,  4.36it/s][A
 85%|████████▌ | 188/221 [00:53<00:07,  4.53it/s][A
 86%|████████▌ | 189/221 [00:54<00:06,  4.60it/s][A
 86%|████████▌ | 190/221 [00:54<00:08,  3.73it/s][A
 86%|████████▋ | 191/221 [00:54<00:06,  4.36it/s][A
 87%|████████▋ | 192/221 [00:55<00:08,  3.58it/s][A
 87%|████████▋ | 193/221 [00:55<00:07,  3.64it/s][A
 88%|████████▊ | 194/221 [00:55<00:09,  2.88it/s][A
 88%|████████▊ | 195/221 [00:56<00:09,  2.76it/s][A
 89%|████████▊ | 196/221 [00:56<00:10,  2.45it/s][A
 89%|████████▉ | 197/221 [00:57<00:11,  2.09it/s][A
 90%|████████▉ | 198/221 [00:57<00:09,  2.32it/s][A
 90%|█████████ | 199/221 [00:57<00:07,  2.90it/s][A
 90%|█████████ | 200/221 [00:58<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:58<00:05,  3.80it/s][A
 91%|█████████▏| 202/221 [00:58<00:04,  3.80it/s][A
 92%|█████████▏| 203/221 [00:58<00:04,  3.90it/s][A
 92%|█████████▏| 204/221 [00:59<00:04,  4.03it/s][A
 93%|█████████▎| 205/221 [00:59<00:04,  3.98it/s][A
 93%|█████████▎| 206/221 [00:59<00:04,  3.14it/s][A
 94%|█████████▎| 207/221 [00:59<00:03,  3.52it/s][A
 94%|█████████▍| 208/221 [01:00<00:03,  3.33it/s][A
 95%|█████████▍| 209/221 [01:00<00:03,  3.20it/s][A
 95%|█████████▌| 210/221 [01:00<00:02,  3.82it/s][A
 95%|█████████▌| 211/221 [01:01<00:02,  3.85it/s][A
 96%|█████████▌| 212/221 [01:01<00:02,  3.52it/s][A
 96%|█████████▋| 213/221 [01:01<00:02,  3.63it/s][A
 97%|█████████▋| 214/221 [01:02<00:02,  2.78it/s][A
 97%|█████████▋| 215/221 [01:02<00:02,  2.74it/s][A
 98%|█████████▊| 216/221 [01:02<00:01,  2.96it/s][A
 98%|█████████▊| 217/221 [01:03<00:01,  2.98it/s][A
 99%|█████████▊| 218/221 [01:03<00:01,  2.56it/s][A
 99%|█████████▉| 219/221 [01:03<00:00,  2.80it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.41it/s][A
100%|██████████| 221/221 [01:04<00:00,  3.25it/s][A100%|██████████| 221/221 [01:04<00:00,  3.43it/s]
09/17/2024 00:36:37 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 199--===========

09/17/2024 00:36:37 - INFO - __main__ -   {'area_r1': 42.4, 'area_recall': '42.4/69.3/80.0', 'area_ravg': 63.9}
09/17/2024 00:36:37 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 199--===========

09/17/2024 00:36:37 - INFO - __main__ -   {'forward_r1': 38.7, 'forward_recall': '38.7/66.1/76.9', 'forward_ravg': 60.6}
09/17/2024 00:36:37 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 199--===========

09/17/2024 00:36:37 - INFO - __main__ -   {'area_video_r1': 38.9, 'area_video_recall': '38.9/66.1/77.4', 'area_video_ravg': 60.8}
09/17/2024 00:36:37 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 199=======

09/17/2024 00:36:37 - INFO - __main__ -   {'area_video_r1': 38.9, 'area_video_recall': '38.9/66.1/77.4', 'area_video_ravg': 60.8}
09/17/2024 00:36:37 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 199--===========

09/17/2024 00:36:37 - INFO - __main__ -   {'area_video_r1': 51.5, 'area_video_recall': '51.5/74.7/83.1', 'area_video_ravg': 69.8, 'area_video_back_r1': 49.3, 'area_video_back_recall': '49.3/72.4/80.0', 'area_video_back_ravg': 67.2}
09/17/2024 00:36:37 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 199=======

09/17/2024 00:36:37 - INFO - __main__ -   {'area_video_r1': 51.5, 'area_video_recall': '51.5/74.7/83.1', 'area_video_ravg': 69.8, 'area_video_back_r1': 49.3, 'area_video_back_recall': '49.3/72.4/80.0', 'area_video_back_ravg': 67.2}
09/17/2024 00:36:37 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 199--===========

09/17/2024 00:36:37 - INFO - __main__ -   {'video_r1': 36.5, 'video_recall': '36.5/66.1/75.9', 'video_ravg': 59.5}
09/17/2024 00:36:37 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 49=======

09/17/2024 00:36:37 - INFO - __main__ -   {'video_r1': 37.0, 'video_recall': '37.0/65.4/73.9', 'video_ravg': 58.7}
09/17/2024 00:36:37 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 199--===========

09/17/2024 00:36:37 - INFO - __main__ -   {'video_r1': 51.0, 'video_recall': '51.0/74.1/82.2', 'video_ravg': 69.1}
09/17/2024 00:36:37 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 199=======

09/17/2024 00:36:37 - INFO - __main__ -   {'video_r1': 51.0, 'video_recall': '51.0/74.1/82.2', 'video_ravg': 69.1}
09/17/2024 00:37:11 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.01161954179406166, 'loss_ret%tv%ta--finetune_area/loss_area': 2.181204319000244, 'loss_ret%tv%ta--finetune_area/total_loss': 2.192823886871338}
  7%|▋         | 200/2910 [1:15:28<102:06:39, 135.65s/it]  7%|▋         | 201/2910 [1:15:31<72:14:17, 96.00s/it]    7%|▋         | 202/2910 [1:15:35<51:28:36, 68.43s/it][h264 @ 0x5606aa2da040] mmco: unref short failure
[h264 @ 0x5606aa2da040] mmco: unref short failure
[h264 @ 0x55e199b30500] mmco: unref short failure
[h264 @ 0x55e199b30500] mmco: unref short failure
  7%|▋         | 203/2910 [1:15:40<36:59:43, 49.20s/it][h264 @ 0x55a26e450fc0] mmco: unref short failure
[h264 @ 0x55e196fe7140] mmco: unref short failure
  7%|▋         | 204/2910 [1:15:44<26:54:53, 35.81s/it]  7%|▋         | 205/2910 [1:15:49<19:58:11, 26.58s/it][h264 @ 0x55e1843263c0] mmco: unref short failure
[h264 @ 0x55a27b8fe640] mmco: unref short failure
  7%|▋         | 206/2910 [1:15:54<15:05:03, 20.08s/it]  7%|▋         | 207/2910 [1:15:59<11:42:43, 15.60s/it]  7%|▋         | 208/2910 [1:16:04<9:20:34, 12.45s/it] [h264 @ 0x560697861dc0] mmco: unref short failure
[h264 @ 0x560697861dc0] mmco: unref short failure
[h264 @ 0x56068edb2240] mmco: unref short failure
[h264 @ 0x56068edb2240] mmco: unref short failure
  7%|▋         | 209/2910 [1:16:10<7:43:00, 10.29s/it][h264 @ 0x55a277b24440] mmco: unref short failure
[h264 @ 0x55b4fc304d00] mmco: unref short failure
[h264 @ 0x55b4fc304d00] mmco: unref short failure
  7%|▋         | 210/2910 [1:16:15<6:33:51,  8.75s/it]  7%|▋         | 211/2910 [1:16:21<5:58:22,  7.97s/it][h264 @ 0x5606a1d94c40] mmco: unref short failure
[h264 @ 0x5606a1d94c40] mmco: unref short failure
  7%|▋         | 212/2910 [1:16:27<5:25:27,  7.24s/it]  7%|▋         | 213/2910 [1:16:32<4:58:42,  6.65s/it]  7%|▋         | 214/2910 [1:16:38<4:50:03,  6.46s/it]  7%|▋         | 215/2910 [1:16:43<4:33:43,  6.09s/it][h264 @ 0x55e189e7edc0] mmco: unref short failure
[h264 @ 0x55b506ba5bc0] mmco: unref short failure
[h264 @ 0x55b506ba5bc0] mmco: unref short failure
[h264 @ 0x55e18f583a00] mmco: unref short failure
[h264 @ 0x55e18f583a00] mmco: unref short failure
[h264 @ 0x56069f1dbf00] mmco: unref short failure
[h264 @ 0x55b4fa998e00] mmco: unref short failure
[h264 @ 0x55b4fa998e00] mmco: unref short failure
[h264 @ 0x55a275a2afc0] mmco: unref short failure
[h264 @ 0x55e195215380] mmco: unref short failure
  7%|▋         | 216/2910 [1:17:35<14:45:19, 19.72s/it][h264 @ 0x560696e5c340] mmco: unref short failure
[h264 @ 0x560696e5c340] mmco: unref short failure
[h264 @ 0x55e19cb71c40] mmco: unref short failure
09/17/2024 00:39:26 - INFO - __main__ -   current idx bYqphpDyeRQ.22 from finetune_area returns wrong image/video, use 122375 instead.
[h264 @ 0x55a25b9553c0] mmco: unref short failure
  7%|▋         | 217/2910 [1:17:47<13:03:59, 17.47s/it][h264 @ 0x55b4f8102f80] mmco: unref short failure
[h264 @ 0x55b4f9d6d980] mmco: unref short failure
[h264 @ 0x55b4f9d6d980] mmco: unref short failure
[h264 @ 0x55e18d2a0fc0] mmco: unref short failure
[h264 @ 0x55e18d2a0fc0] mmco: unref short failure
  7%|▋         | 218/2910 [1:17:54<10:44:17, 14.36s/it][h264 @ 0x56069ee81cc0] mmco: unref short failure
[h264 @ 0x56069ee81cc0] mmco: unref short failure
[h264 @ 0x55e19e6bf940] mmco: unref short failure
[h264 @ 0x55a25bd4d100] mmco: unref short failure
[h264 @ 0x55a25bd4d100] mmco: unref short failure
[h264 @ 0x55e19bbe8280] mmco: unref short failure
  8%|▊         | 219/2910 [1:18:16<12:32:03, 16.77s/it][h264 @ 0x55b50bb05f00] mmco: unref short failure
[h264 @ 0x55b50bb05f00] mmco: unref short failure
  8%|▊         | 220/2910 [1:18:22<10:01:18, 13.41s/it][h264 @ 0x55a278bd02c0] mmco: unref short failure
[h264 @ 0x55a278bd02c0] mmco: unref short failure
  8%|▊         | 221/2910 [1:18:28<8:19:40, 11.15s/it]   8%|▊         | 222/2910 [1:18:33<7:01:08,  9.40s/it][h264 @ 0x5606a4d7c740] mmco: unref short failure
[h264 @ 0x5606a4d7c740] mmco: unref short failure
[h264 @ 0x55e191c9b640] mmco: unref short failure
[h264 @ 0x55e191c9b640] mmco: unref short failure
[h264 @ 0x55a25bcc4080] mmco: unref short failure
[h264 @ 0x55a25bcc4080] mmco: unref short failure
  8%|▊         | 223/2910 [1:18:40<6:29:08,  8.69s/it][h264 @ 0x55b4f5de58c0] mmco: unref short failure
[h264 @ 0x55b4f5de58c0] mmco: unref short failure
09/17/2024 00:40:30 - INFO - __main__ -   current idx TXPcr1HyKkY.54 from finetune_area returns wrong image/video, use 68487 instead.
[h264 @ 0x55b5151af600] mmco: unref short failure
[h264 @ 0x55b5151af600] mmco: unref short failure
[h264 @ 0x55a279f522c0] mmco: unref short failure
[h264 @ 0x56068d5e9bc0] mmco: unref short failure
[h264 @ 0x55e1a4605340] mmco: unref short failure
[h264 @ 0x55e1a4605340] mmco: unref short failure
[h264 @ 0x55e1a4605340] mmco: unref short failure
[h264 @ 0x56069d0b8380] mmco: unref short failure
[h264 @ 0x55b4faa70700] mmco: unref short failure
[h264 @ 0x55a25c03f640] mmco: unref short failure
[h264 @ 0x55b4fe800d40] mmco: unref short failure
[h264 @ 0x55b4fe800d40] mmco: unref short failure
[h264 @ 0x55e197882080] mmco: unref short failure
[h264 @ 0x560691e04000] mmco: unref short failure
[h264 @ 0x55b50b13b440] mmco: unref short failure
09/17/2024 00:41:29 - INFO - __main__ -   current idx yYJt_XCcAsY.15 from finetune_area returns wrong image/video, use 10302 instead.
[h264 @ 0x55e182f2e440] mmco: unref short failure
[h264 @ 0x55e182f2e440] mmco: unref short failure
[h264 @ 0x55a25c7ead40] mmco: unref short failure
[h264 @ 0x55a25c7ead40] mmco: unref short failure
09/17/2024 00:41:38 - INFO - __main__ -   current idx 1wUrnDB1U9c.8 from finetune_area returns wrong image/video, use 27324 instead.
[h264 @ 0x5606ac08ef80] mmco: unref short failure
[h264 @ 0x5606ac08ef80] mmco: unref short failure
[h264 @ 0x55a27bbf9fc0] mmco: unref short failure
[h264 @ 0x55e18f2d3900] mmco: unref short failure
[h264 @ 0x55b5061bbf80] mmco: unref short failure
[h264 @ 0x55b5061bbf80] mmco: unref short failure
[h264 @ 0x56068c970ac0] mmco: unref short failure
[h264 @ 0x56068c970ac0] mmco: unref short failure
  8%|▊         | 224/2910 [1:20:13<25:14:06, 33.82s/it][h264 @ 0x56068ced3580] mmco: unref short failure
[h264 @ 0x56068ced3580] mmco: unref short failure
[h264 @ 0x55a26c77eb40] mmco: unref short failure
[h264 @ 0x55a26c77eb40] mmco: unref short failure
[h264 @ 0x56068be627c0] mmco: unref short failure
[h264 @ 0x56068be627c0] mmco: unref short failure
[h264 @ 0x55b4fef28400] mmco: unref short failure
  8%|▊         | 225/2910 [1:20:22<19:41:21, 26.40s/it][h264 @ 0x560696f17680] mmco: unref short failure
[h264 @ 0x560696f17680] mmco: unref short failure
  8%|▊         | 226/2910 [1:20:28<15:17:35, 20.51s/it][h264 @ 0x55a27779ce40] mmco: unref short failure
  8%|▊         | 227/2910 [1:20:44<14:14:58, 19.12s/it][h264 @ 0x55e183aebac0] mmco: unref short failure
[h264 @ 0x55a25c03f640] mmco: unref short failure
[h264 @ 0x55a25c03f640] mmco: unref short failure
  8%|▊         | 228/2910 [1:20:49<11:07:52, 14.94s/it][h264 @ 0x55e18ea4a280] mmco: unref short failure
  8%|▊         | 229/2910 [1:20:55<8:58:40, 12.06s/it] [h264 @ 0x55b4fe0868c0] mmco: unref short failure
[h264 @ 0x55e191af23c0] mmco: unref short failure
  8%|▊         | 230/2910 [1:21:00<7:29:27, 10.06s/it]09/17/2024 00:42:46 - INFO - __main__ -   current idx Zsx1-4aJ4ys.28 from finetune_area returns wrong image/video, use 101535 instead.
[h264 @ 0x55e18302d140] mmco: unref short failure
[h264 @ 0x55e18302d140] mmco: unref short failure
  8%|▊         | 231/2910 [1:21:10<7:31:50, 10.12s/it][h264 @ 0x56068f9aa280] mmco: unref short failure
[h264 @ 0x56068f9aa280] mmco: unref short failure
[h264 @ 0x55a275a2b640] mmco: unref short failure
[h264 @ 0x55a275a2b640] mmco: unref short failure
[h264 @ 0x55a275a2b640] mmco: unref short failure
[h264 @ 0x55a275a2b640] mmco: unref short failure
[h264 @ 0x55b4f6f21700] mmco: unref short failure
[h264 @ 0x55b4f6f21700] mmco: unref short failure
[h264 @ 0x55e194ac79c0] mmco: unref short failure
[h264 @ 0x55e194ac79c0] mmco: unref short failure
[h264 @ 0x55e18dc66ec0] mmco: unref short failure
[h264 @ 0x55e18dc66ec0] mmco: unref short failure
[h264 @ 0x55e19a40a200] mmco: unref short failure
[h264 @ 0x55e19a40a200] mmco: unref short failure
[h264 @ 0x55e19a40a200] mmco: unref short failure
[h264 @ 0x55e183406e40] mmco: unref short failure
[h264 @ 0x55a277e52840] mmco: unref short failure
[h264 @ 0x55a277e52840] mmco: unref short failure
[h264 @ 0x55b4f90a0b40] mmco: unref short failure
[h264 @ 0x55b4f90a0b40] mmco: unref short failure
[h264 @ 0x55e196f04940] mmco: unref short failure
[h264 @ 0x55e196f04940] mmco: unref short failure
[h264 @ 0x55e1a2302540] mmco: unref short failure
[h264 @ 0x55e1a2302540] mmco: unref short failure
[h264 @ 0x55a279f49640] mmco: unref short failure
[h264 @ 0x55a25f97d680] mmco: unref short failure
[h264 @ 0x55e19fcd3280] mmco: unref short failure
[h264 @ 0x55e19fcd3280] mmco: unref short failure
[h264 @ 0x55b4f7bbf080] mmco: unref short failure
[h264 @ 0x55b4f7bbf080] mmco: unref short failure
09/17/2024 00:44:02 - INFO - __main__ -   current idx gtt8O0yuAiA.7 from finetune_area returns wrong image/video, use 92865 instead.
[h264 @ 0x55b4f49fcbc0] mmco: unref short failure
[h264 @ 0x55b4f49fcbc0] mmco: unref short failure
[h264 @ 0x55b4f49fcbc0] mmco: unref short failure
[h264 @ 0x55b4f49fcbc0] mmco: unref short failure
[h264 @ 0x55b4fe481640] mmco: unref short failure
[h264 @ 0x55b4fe481640] mmco: unref short failure
[h264 @ 0x55e183b42e40] mmco: unref short failure
09/17/2024 00:44:24 - INFO - __main__ -   current idx Q_Kn3yzSJ5w.69 from finetune_area returns wrong image/video, use 43269 instead.
[h264 @ 0x55e1832dd780] mmco: unref short failure
  8%|▊         | 232/2910 [1:22:43<25:50:15, 34.73s/it]  8%|▊         | 233/2910 [1:22:49<19:27:31, 26.17s/it][h264 @ 0x55a27779d240] mmco: unref short failure
[h264 @ 0x55a27779d240] mmco: unref short failure
  8%|▊         | 234/2910 [1:22:56<15:08:13, 20.36s/it][h264 @ 0x55a25cb9bb40] mmco: unref short failure
[h264 @ 0x55a25cb9bb40] mmco: unref short failure
[h264 @ 0x55b4f2ca28c0] mmco: unref short failure
[h264 @ 0x55e182bad2c0] mmco: unref short failure
  8%|▊         | 235/2910 [1:23:13<14:23:12, 19.36s/it][h264 @ 0x55b500f89c00] mmco: unref short failure
  8%|▊         | 236/2910 [1:23:18<11:15:24, 15.16s/it][h264 @ 0x55b4fda982c0] mmco: unref short failure
[h264 @ 0x55b4fda982c0] mmco: unref short failure
[h264 @ 0x55b4fda982c0] mmco: unref short failure
[h264 @ 0x55b4fda982c0] mmco: unref short failure
  8%|▊         | 237/2910 [1:23:23<9:01:54, 12.16s/it] [h264 @ 0x55b500989fc0] mmco: unref short failure
  8%|▊         | 238/2910 [1:23:31<8:09:41, 11.00s/it]  8%|▊         | 239/2910 [1:23:37<6:57:08,  9.37s/it][h264 @ 0x56068bd915c0] mmco: unref short failure
[h264 @ 0x55a27bbfa400] mmco: unref short failure
[h264 @ 0x55a27bbfa400] mmco: unref short failure
[h264 @ 0x5606a426f4c0] mmco: unref short failure
[h264 @ 0x5606a426f4c0] mmco: unref short failure
[h264 @ 0x55e19e6e60c0] mmco: unref short failure
[h264 @ 0x55e19e6e60c0] mmco: unref short failure
[h264 @ 0x560696f17680] mmco: unref short failure
[h264 @ 0x560696f17680] mmco: unref short failure
09/17/2024 00:45:53 - INFO - __main__ -   current idx kZsPqzB36mk.13 from finetune_area returns wrong image/video, use 109316 instead.
[h264 @ 0x55a2680dcd80] mmco: unref short failure
[h264 @ 0x5606a4dedc00] mmco: unref short failure
[h264 @ 0x560699f50280] mmco: unref short failure
[h264 @ 0x55a25bff8480] mmco: unref short failure
[h264 @ 0x55a25bff8480] mmco: unref short failure
[h264 @ 0x55b508a16a80] mmco: unref short failure
[h264 @ 0x55b508a16a80] mmco: unref short failure
[h264 @ 0x55e184dc7940] mmco: unref short failure
[h264 @ 0x55e18a729680] mmco: unref short failure
[h264 @ 0x55e18a729680] mmco: unref short failure
[h264 @ 0x55b4f4053180] mmco: unref short failure
[h264 @ 0x55b4f4053180] mmco: unref short failure
[h264 @ 0x55b4f4053180] mmco: unref short failure
[h264 @ 0x55b4f4053180] mmco: unref short failure
[h264 @ 0x55b4f4202ac0] mmco: unref short failure
[h264 @ 0x55a261ab4040] mmco: unref short failure
[h264 @ 0x55a261ab4040] mmco: unref short failure
[h264 @ 0x55b4fa9f3d00] mmco: unref short failure
[h264 @ 0x55b4fa9f3d00] mmco: unref short failure
[h264 @ 0x55b4fa9f3d00] mmco: unref short failure
[h264 @ 0x55b4fa9f3d00] mmco: unref short failure
[h264 @ 0x55e18b8bf200] mmco: unref short failure
  8%|▊         | 240/2910 [1:25:06<24:35:47, 33.16s/it][h264 @ 0x560691c0abc0] mmco: unref short failure
[h264 @ 0x560691c0abc0] mmco: unref short failure
[h264 @ 0x55e18b0316c0] mmco: unref short failure
  8%|▊         | 241/2910 [1:25:17<19:37:56, 26.48s/it][h264 @ 0x55e1836afe40] mmco: unref short failure
[h264 @ 0x55e1836afe40] mmco: unref short failure
[h264 @ 0x55e1836afe40] mmco: unref short failure
[h264 @ 0x55e1836afe40] mmco: unref short failure
  8%|▊         | 242/2910 [1:25:26<15:50:16, 21.37s/it][h264 @ 0x55b4f4081800] mmco: unref short failure
[h264 @ 0x55e18e459a40] mmco: unref short failure
[h264 @ 0x55e18e459a40] mmco: unref short failure
  8%|▊         | 243/2910 [1:25:34<12:56:59, 17.48s/it][h264 @ 0x55a276287880] mmco: unref short failure
[h264 @ 0x5606a9426580] mmco: unref short failure
[h264 @ 0x5606a9426580] mmco: unref short failure
[h264 @ 0x5606aa79b0c0] mmco: unref short failure
[h264 @ 0x5606aa79b0c0] mmco: unref short failure
[h264 @ 0x5606aa79b0c0] mmco: unref short failure
[h264 @ 0x5606aa79b0c0] mmco: unref short failure
[h264 @ 0x55a275a7f6c0] mmco: unref short failure
[h264 @ 0x55a275a7f6c0] mmco: unref short failure
[h264 @ 0x55b4f930e700] mmco: unref short failure
[h264 @ 0x55b4f930e700] mmco: unref short failure
  8%|▊         | 244/2910 [1:26:02<15:11:22, 20.51s/it]09/17/2024 00:47:52 - INFO - __main__ -   current idx 4DqZp71UU3o.53 from finetune_area returns wrong image/video, use 33976 instead.
  8%|▊         | 245/2910 [1:26:08<11:52:17, 16.04s/it]  8%|▊         | 246/2910 [1:26:13<9:28:06, 12.80s/it]   8%|▊         | 247/2910 [1:26:18<7:47:57, 10.54s/it][h264 @ 0x560699fd3100] mmco: unref short failure
[h264 @ 0x560699fd3100] mmco: unref short failure
[h264 @ 0x55a2662b0280] mmco: unref short failure
[h264 @ 0x55a2662b0280] mmco: unref short failure
[h264 @ 0x55a2696982c0] mmco: unref short failure
[h264 @ 0x55a2696982c0] mmco: unref short failure
[h264 @ 0x55b4fbe48840] mmco: unref short failure
[h264 @ 0x560693299dc0] mmco: unref short failure
[h264 @ 0x55b507d1ed80] mmco: unref short failure
[h264 @ 0x5606a7f56000] mmco: unref short failure
[h264 @ 0x5606a7f56000] mmco: unref short failure
[h264 @ 0x55b50f303880] mmco: unref short failure
[h264 @ 0x5606a4d7c540] mmco: unref short failure
[h264 @ 0x5606a4d7c540] mmco: unref short failure
[h264 @ 0x55e192c83ec0] mmco: unref short failure
[h264 @ 0x5606a2064f40] mmco: unref short failure
[h264 @ 0x5606a2064f40] mmco: unref short failure
[h264 @ 0x55b4f90152c0] mmco: unref short failure
  9%|▊         | 248/2910 [1:27:34<22:19:36, 30.19s/it][h264 @ 0x56068c455840] mmco: unref short failure
[h264 @ 0x56068c455840] mmco: unref short failure
[h264 @ 0x55e187a126c0] mmco: unref short failure
  9%|▊         | 249/2910 [1:27:45<17:58:16, 24.31s/it]09/17/2024 00:49:31 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 00:49:31 - INFO - __main__ -   start running ret%tva validation...
[h264 @ 0x55b511eb0700] mmco: unref short failure
[h264 @ 0x55b511eb0700] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
09/17/2024 00:49:37 - INFO - __main__ -   current idx 66BbxK8sJjM.10 from finetune_area returns wrong image/video, use 130037 instead.
[h264 @ 0x55a27172f400] mmco: unref short failure
[h264 @ 0x55a27172f400] mmco: unref short failure
[h264 @ 0x56068c794a00] mmco: unref short failure
[h264 @ 0x56068c794a00] mmco: unref short failure
[h264 @ 0x55a27172f400] mmco: unref short failure
[h264 @ 0x55a27172f400] mmco: unref short failure
[h264 @ 0x55e19e3c9680] mmco: unref short failure
[h264 @ 0x55b4f5b8e5c0] mmco: unref short failure
[h264 @ 0x55a2683bbb40] mmco: unref short failure
[h264 @ 0x55a2683bbb40] mmco: unref short failure
[h264 @ 0x55a2683bbb40] mmco: unref short failure
[h264 @ 0x55a2683bbb40] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55b4f6364800] mmco: unref short failure
[h264 @ 0x55b4f6364800] mmco: unref short failure
[h264 @ 0x55b4f6364800] mmco: unref short failure
[h264 @ 0x55b4f6364800] mmco: unref short failure
[h264 @ 0x55a2696a31c0] mmco: unref short failure
[h264 @ 0x55b5118067c0] mmco: unref short failure
[h264 @ 0x5606a38bcdc0] mmco: unref short failure
[h264 @ 0x5606a38bcdc0] mmco: unref short failure
[h264 @ 0x55b506f30280] mmco: unref short failure
[h264 @ 0x55b506f30280] mmco: unref short failure
[h264 @ 0x55b509e2e6c0] mmco: unref short failure
[h264 @ 0x55e19d6bae80] mmco: unref short failure
[h264 @ 0x55e19d6bae80] mmco: unref short failure
[h264 @ 0x55e19d6bae80] mmco: unref short failure
[h264 @ 0x55e19d6bae80] mmco: unref short failure
09/17/2024 00:51:29 - INFO - __main__ -   current idx G_BESfJVLFg.1 from finetune_area returns wrong image/video, use 4065 instead.
[h264 @ 0x55b5141cae00] mmco: unref short failure
[h264 @ 0x55e19a42dd80] mmco: unref short failure
[h264 @ 0x55e19a42dd80] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:38,  2.23it/s][A[h264 @ 0x56068d69ff40] mmco: unref short failure
[h264 @ 0x56068d69ff40] mmco: unref short failure

  1%|          | 2/221 [00:00<01:39,  2.19it/s][A
  1%|▏         | 3/221 [00:01<01:44,  2.09it/s][A
  2%|▏         | 4/221 [00:01<01:16,  2.84it/s][A
  2%|▏         | 5/221 [00:01<01:01,  3.51it/s][A
  3%|▎         | 6/221 [00:01<00:58,  3.66it/s][A
  3%|▎         | 7/221 [00:02<00:58,  3.68it/s][A
  4%|▎         | 8/221 [00:02<00:55,  3.87it/s][A
  4%|▍         | 9/221 [00:02<00:59,  3.54it/s][A
  5%|▍         | 10/221 [00:03<01:15,  2.78it/s][A
  5%|▍         | 11/221 [00:03<01:00,  3.49it/s][A
  5%|▌         | 12/221 [00:03<01:08,  3.04it/s][A
  6%|▌         | 13/221 [00:04<01:03,  3.26it/s][A
  6%|▋         | 14/221 [00:04<01:03,  3.27it/s][A
  7%|▋         | 15/221 [00:04<01:04,  3.20it/s][A
  7%|▋         | 16/221 [00:05<01:10,  2.90it/s][A
  8%|▊         | 17/221 [00:05<01:26,  2.35it/s][A
  8%|▊         | 18/221 [00:06<01:19,  2.54it/s][A
  9%|▊         | 19/221 [00:06<01:10,  2.86it/s][A
  9%|▉         | 20/221 [00:06<00:58,  3.41it/s][A
 10%|▉         | 21/221 [00:06<00:56,  3.51it/s][A
 10%|▉         | 22/221 [00:07<00:57,  3.44it/s][A
 10%|█         | 23/221 [00:07<00:48,  4.11it/s][A
 11%|█         | 24/221 [00:07<00:45,  4.31it/s][A
 11%|█▏        | 25/221 [00:07<00:42,  4.63it/s][A
 12%|█▏        | 26/221 [00:08<00:51,  3.76it/s][A
 12%|█▏        | 27/221 [00:08<00:42,  4.56it/s][A
 13%|█▎        | 28/221 [00:09<01:21,  2.37it/s][A
 13%|█▎        | 29/221 [00:09<01:12,  2.66it/s][A
 14%|█▎        | 30/221 [00:09<01:03,  3.01it/s][A
 14%|█▍        | 31/221 [00:09<01:04,  2.96it/s][A
 14%|█▍        | 32/221 [00:10<00:52,  3.59it/s][A
 15%|█▍        | 33/221 [00:10<00:49,  3.81it/s][A
 15%|█▌        | 34/221 [00:10<00:46,  3.99it/s][A
 16%|█▌        | 35/221 [00:10<00:54,  3.43it/s][A
 16%|█▋        | 36/221 [00:11<01:04,  2.87it/s][A
 17%|█▋        | 37/221 [00:11<01:13,  2.50it/s][A
 17%|█▋        | 38/221 [00:12<01:16,  2.38it/s][A
 18%|█▊        | 39/221 [00:12<01:01,  2.98it/s][A
 18%|█▊        | 40/221 [00:12<00:53,  3.41it/s][A
 19%|█▊        | 41/221 [00:12<00:45,  3.95it/s][A[h264 @ 0x5606aa22cc00] mmco: unref short failure
[h264 @ 0x5606aa22cc00] mmco: unref short failure
[h264 @ 0x55b4f3d0d6c0] mmco: unref short failure
[h264 @ 0x55b4f3d0d6c0] mmco: unref short failure

 19%|█▉        | 42/221 [00:13<01:13,  2.45it/s][A
 19%|█▉        | 43/221 [00:13<01:06,  2.67it/s][A
 20%|█▉        | 44/221 [00:14<00:55,  3.20it/s][A
 20%|██        | 45/221 [00:14<01:23,  2.10it/s][A
 21%|██        | 46/221 [00:15<01:23,  2.10it/s][A
 21%|██▏       | 47/221 [00:16<01:39,  1.75it/s][A
 22%|██▏       | 48/221 [00:16<01:19,  2.17it/s][A
 22%|██▏       | 49/221 [00:16<01:09,  2.49it/s][A
 23%|██▎       | 50/221 [00:16<00:59,  2.86it/s][A
 23%|██▎       | 51/221 [00:17<00:49,  3.43it/s][A
 24%|██▎       | 52/221 [00:17<00:43,  3.91it/s][A
 24%|██▍       | 53/221 [00:17<00:41,  4.08it/s][A
 24%|██▍       | 54/221 [00:18<01:34,  1.76it/s][A
 25%|██▍       | 55/221 [00:19<01:33,  1.78it/s][A
 25%|██▌       | 56/221 [00:19<01:16,  2.14it/s][A
 26%|██▌       | 57/221 [00:19<01:11,  2.28it/s][A
 26%|██▌       | 58/221 [00:20<00:59,  2.72it/s][A
 27%|██▋       | 59/221 [00:20<00:52,  3.11it/s][A
 27%|██▋       | 60/221 [00:21<01:22,  1.96it/s][A
 28%|██▊       | 61/221 [00:21<01:10,  2.26it/s][A
 28%|██▊       | 62/221 [00:21<01:08,  2.32it/s][A
 29%|██▊       | 63/221 [00:22<00:55,  2.86it/s][A
 29%|██▉       | 64/221 [00:22<00:49,  3.15it/s][A
 29%|██▉       | 65/221 [00:22<00:41,  3.72it/s][A
 30%|██▉       | 66/221 [00:23<00:52,  2.94it/s][A
 30%|███       | 67/221 [00:23<00:52,  2.95it/s][A
 31%|███       | 68/221 [00:23<00:43,  3.54it/s][A[h264 @ 0x55e18e445fc0] mmco: unref short failure

 31%|███       | 69/221 [00:24<01:00,  2.50it/s][A
 32%|███▏      | 70/221 [00:24<00:50,  3.01it/s][A
 32%|███▏      | 71/221 [00:24<00:47,  3.16it/s][A
 33%|███▎      | 72/221 [00:25<00:53,  2.78it/s][A[h264 @ 0x56068c76a6c0] mmco: unref short failure

 33%|███▎      | 73/221 [00:25<00:58,  2.52it/s][A
 33%|███▎      | 74/221 [00:25<00:45,  3.24it/s][A
 34%|███▍      | 75/221 [00:26<00:47,  3.10it/s][A
 34%|███▍      | 76/221 [00:26<00:42,  3.41it/s][A
 35%|███▍      | 77/221 [00:26<00:47,  3.02it/s][A
 35%|███▌      | 78/221 [00:26<00:38,  3.76it/s][A
 36%|███▌      | 79/221 [00:27<00:50,  2.82it/s][A
 36%|███▌      | 80/221 [00:27<00:43,  3.26it/s][A
 37%|███▋      | 81/221 [00:27<00:42,  3.32it/s][A[h264 @ 0x55b4f7ff9940] mmco: unref short failure
[h264 @ 0x55b4f7ff9940] mmco: unref short failure

 37%|███▋      | 82/221 [00:28<00:56,  2.44it/s][A
 38%|███▊      | 83/221 [00:28<00:53,  2.56it/s][A
 38%|███▊      | 84/221 [00:29<00:49,  2.74it/s][A
 38%|███▊      | 85/221 [00:29<00:42,  3.18it/s][A
 39%|███▉      | 86/221 [00:29<00:38,  3.49it/s][A
 39%|███▉      | 87/221 [00:30<01:16,  1.75it/s][A
 40%|███▉      | 88/221 [00:31<01:28,  1.50it/s][A
 40%|████      | 89/221 [00:32<01:14,  1.77it/s][A
 41%|████      | 90/221 [00:32<01:03,  2.07it/s][A
 41%|████      | 91/221 [00:32<00:51,  2.51it/s][A
 42%|████▏     | 92/221 [00:32<00:46,  2.75it/s][A
 42%|████▏     | 93/221 [00:33<00:49,  2.58it/s][A
 43%|████▎     | 94/221 [00:33<00:46,  2.72it/s][A
 43%|████▎     | 95/221 [00:33<00:41,  3.02it/s][A[h264 @ 0x5606abcc5dc0] mmco: unref short failure

 43%|████▎     | 96/221 [00:34<00:54,  2.30it/s][A
 44%|████▍     | 97/221 [00:34<00:47,  2.60it/s][A[h264 @ 0x55b4fe473840] mmco: unref short failure
[h264 @ 0x55b4fe473840] mmco: unref short failure

 44%|████▍     | 98/221 [00:35<00:46,  2.66it/s][A
 45%|████▍     | 99/221 [00:35<00:41,  2.97it/s][A
 45%|████▌     | 100/221 [00:35<00:38,  3.11it/s][A
 46%|████▌     | 101/221 [00:35<00:36,  3.28it/s][A
 46%|████▌     | 102/221 [00:36<00:42,  2.82it/s][A
 47%|████▋     | 103/221 [00:36<00:34,  3.43it/s][A
 47%|████▋     | 104/221 [00:36<00:31,  3.74it/s][A
 48%|████▊     | 105/221 [00:37<00:33,  3.51it/s][A
 48%|████▊     | 106/221 [00:37<00:55,  2.09it/s][A
 48%|████▊     | 107/221 [00:38<00:43,  2.60it/s][A
 49%|████▉     | 108/221 [00:38<00:37,  3.02it/s][A
 49%|████▉     | 109/221 [00:38<00:33,  3.35it/s][A
 50%|████▉     | 110/221 [00:38<00:29,  3.72it/s][A
 50%|█████     | 111/221 [00:39<00:39,  2.81it/s][A
 51%|█████     | 112/221 [00:39<00:33,  3.21it/s][A
 51%|█████     | 113/221 [00:39<00:33,  3.23it/s][A
 52%|█████▏    | 115/221 [00:40<00:23,  4.57it/s][A
 52%|█████▏    | 116/221 [00:40<00:40,  2.62it/s][A
 53%|█████▎    | 117/221 [00:41<00:39,  2.61it/s][A
 53%|█████▎    | 118/221 [00:41<00:34,  2.95it/s][A
 54%|█████▍    | 119/221 [00:42<00:39,  2.58it/s][A
 54%|█████▍    | 120/221 [00:42<00:33,  2.97it/s][A
 55%|█████▌    | 122/221 [00:42<00:25,  3.84it/s][A
 56%|█████▌    | 123/221 [00:42<00:23,  4.20it/s][A
 56%|█████▌    | 124/221 [00:43<00:24,  3.99it/s][A[h264 @ 0x55b4f444b4c0] mmco: unref short failure
[h264 @ 0x55b4f444b4c0] mmco: unref short failure
[h264 @ 0x55b4f444b4c0] mmco: unref short failure
[h264 @ 0x55b4f444b4c0] mmco: unref short failure

 57%|█████▋    | 125/221 [00:43<00:32,  2.92it/s][A
 57%|█████▋    | 126/221 [00:43<00:29,  3.18it/s][A
 57%|█████▋    | 127/221 [00:45<01:07,  1.40it/s][A
 58%|█████▊    | 128/221 [00:45<00:56,  1.63it/s][A
 58%|█████▊    | 129/221 [00:46<00:43,  2.11it/s][A
 59%|█████▉    | 130/221 [00:46<00:36,  2.50it/s][A
 59%|█████▉    | 131/221 [00:46<00:29,  3.07it/s][A
 60%|█████▉    | 132/221 [00:47<00:37,  2.36it/s][A
 60%|██████    | 133/221 [00:47<00:37,  2.35it/s][A
 61%|██████    | 134/221 [00:48<00:44,  1.94it/s][A
 61%|██████    | 135/221 [00:48<00:37,  2.27it/s][A
 62%|██████▏   | 136/221 [00:48<00:35,  2.43it/s][A
 62%|██████▏   | 137/221 [00:49<00:29,  2.90it/s][A
 62%|██████▏   | 138/221 [00:49<00:30,  2.73it/s][A
 63%|██████▎   | 139/221 [00:50<00:38,  2.12it/s][A
 63%|██████▎   | 140/221 [00:50<00:37,  2.15it/s][A
 64%|██████▍   | 141/221 [00:51<00:33,  2.36it/s][A
 64%|██████▍   | 142/221 [00:51<00:31,  2.51it/s][A
 65%|██████▍   | 143/221 [00:51<00:30,  2.57it/s][A
 65%|██████▌   | 144/221 [00:52<00:27,  2.81it/s][A
 66%|██████▌   | 145/221 [00:52<00:21,  3.51it/s][A
 66%|██████▌   | 146/221 [00:52<00:17,  4.24it/s][A
 67%|██████▋   | 147/221 [00:52<00:19,  3.89it/s][A
 67%|██████▋   | 148/221 [00:52<00:19,  3.77it/s][A
 67%|██████▋   | 149/221 [00:53<00:19,  3.73it/s][A
 68%|██████▊   | 150/221 [00:53<00:17,  4.13it/s][A
 68%|██████▊   | 151/221 [00:54<00:27,  2.58it/s][A
 69%|██████▉   | 152/221 [00:55<00:47,  1.44it/s][A
 69%|██████▉   | 153/221 [00:55<00:37,  1.79it/s][A
 70%|██████▉   | 154/221 [00:55<00:31,  2.14it/s][A[h264 @ 0x55e198dd4dc0] mmco: unref short failure
[h264 @ 0x55e198dd4dc0] mmco: unref short failure

 70%|███████   | 155/221 [00:56<00:28,  2.30it/s][A
 71%|███████   | 156/221 [00:56<00:31,  2.06it/s][A[h264 @ 0x5606a2f24d00] mmco: unref short failure
[h264 @ 0x5606a2f24d00] mmco: unref short failure

 71%|███████   | 157/221 [00:57<00:37,  1.69it/s][A
 71%|███████▏  | 158/221 [00:57<00:30,  2.06it/s][A
 72%|███████▏  | 159/221 [00:58<00:23,  2.59it/s][A
 72%|███████▏  | 160/221 [00:58<00:22,  2.71it/s][A
 73%|███████▎  | 161/221 [00:58<00:19,  3.09it/s][A
 73%|███████▎  | 162/221 [00:58<00:15,  3.73it/s][A
 74%|███████▍  | 163/221 [00:59<00:14,  3.87it/s][A
 74%|███████▍  | 164/221 [00:59<00:15,  3.65it/s][A
 75%|███████▍  | 165/221 [00:59<00:13,  4.14it/s][A
 75%|███████▌  | 166/221 [00:59<00:16,  3.32it/s][A
 76%|███████▌  | 167/221 [01:00<00:13,  3.98it/s][A
 76%|███████▌  | 168/221 [01:01<00:25,  2.08it/s][A
 76%|███████▋  | 169/221 [01:01<00:19,  2.64it/s][A
 77%|███████▋  | 170/221 [01:01<00:18,  2.79it/s][A
 77%|███████▋  | 171/221 [01:02<00:20,  2.46it/s][A
 78%|███████▊  | 172/221 [01:02<00:19,  2.56it/s][A09/17/2024 00:52:54 - INFO - __main__ -   current idx 9Ralave0cFg.16 from finetune_area returns wrong image/video, use 87295 instead.

 78%|███████▊  | 173/221 [01:02<00:19,  2.45it/s][A
 79%|███████▊  | 174/221 [01:03<00:15,  2.94it/s][A
 79%|███████▉  | 175/221 [01:03<00:14,  3.09it/s][A[h264 @ 0x55b50e7a9540] mmco: unref short failure
[h264 @ 0x55b50e7a9540] mmco: unref short failure

 80%|███████▉  | 176/221 [01:03<00:13,  3.41it/s][A
 80%|████████  | 177/221 [01:03<00:11,  3.95it/s][A
 81%|████████  | 178/221 [01:04<00:15,  2.75it/s][A
 81%|████████  | 179/221 [01:04<00:16,  2.57it/s][A
 81%|████████▏ | 180/221 [01:04<00:12,  3.25it/s][A
 82%|████████▏ | 181/221 [01:05<00:10,  3.87it/s][A
 82%|████████▏ | 182/221 [01:05<00:09,  3.97it/s][A
 83%|████████▎ | 183/221 [01:05<00:09,  4.02it/s][A
 83%|████████▎ | 184/221 [01:05<00:09,  3.75it/s][A
 84%|████████▍ | 186/221 [01:06<00:07,  4.38it/s][A
 85%|████████▍ | 187/221 [01:06<00:08,  3.80it/s][A
 85%|████████▌ | 188/221 [01:06<00:08,  3.91it/s][A
 86%|████████▌ | 189/221 [01:07<00:09,  3.49it/s][A
 86%|████████▌ | 190/221 [01:07<00:10,  2.96it/s][A
 86%|████████▋ | 191/221 [01:07<00:08,  3.67it/s][A
 87%|████████▋ | 192/221 [01:08<00:08,  3.54it/s][A
 87%|████████▋ | 193/221 [01:08<00:06,  4.33it/s][A
 88%|████████▊ | 194/221 [01:09<00:14,  1.85it/s][A
 88%|████████▊ | 195/221 [01:09<00:11,  2.35it/s][A
 89%|████████▊ | 196/221 [01:09<00:09,  2.65it/s][A
 89%|████████▉ | 197/221 [01:10<00:07,  3.02it/s][A
 90%|████████▉ | 198/221 [01:10<00:06,  3.44it/s][A
 90%|█████████ | 199/221 [01:10<00:05,  3.78it/s][A
 90%|█████████ | 200/221 [01:10<00:04,  4.25it/s][A
 91%|█████████ | 201/221 [01:10<00:04,  4.57it/s][A
 91%|█████████▏| 202/221 [01:11<00:04,  4.29it/s][A
 92%|█████████▏| 203/221 [01:11<00:04,  3.98it/s][A
 92%|█████████▏| 204/221 [01:11<00:04,  4.15it/s][A
 93%|█████████▎| 205/221 [01:11<00:03,  4.70it/s][A[h264 @ 0x56069a735ec0] mmco: unref short failure

 93%|█████████▎| 206/221 [01:12<00:05,  2.53it/s][A
 94%|█████████▍| 208/221 [01:12<00:03,  3.50it/s][A
 95%|█████████▍| 209/221 [01:13<00:03,  3.70it/s][A
 95%|█████████▌| 210/221 [01:13<00:02,  4.39it/s][A
 95%|█████████▌| 211/221 [01:13<00:02,  3.47it/s][A
 96%|█████████▌| 212/221 [01:13<00:02,  3.59it/s][A
 96%|█████████▋| 213/221 [01:14<00:02,  3.78it/s][A[h264 @ 0x55a26309fe80] mmco: unref short failure

 97%|█████████▋| 214/221 [01:14<00:02,  2.81it/s][A
 97%|█████████▋| 215/221 [01:15<00:01,  3.04it/s][A
 98%|█████████▊| 216/221 [01:15<00:01,  2.73it/s][A
 98%|█████████▊| 217/221 [01:15<00:01,  2.48it/s][A
 99%|█████████▊| 218/221 [01:16<00:01,  2.60it/s][A
 99%|█████████▉| 219/221 [01:16<00:00,  2.65it/s][A
100%|█████████▉| 220/221 [01:17<00:00,  1.70it/s][A
100%|██████████| 221/221 [01:17<00:00,  2.09it/s][A100%|██████████| 221/221 [01:17<00:00,  2.83it/s]
09/17/2024 00:53:12 - INFO - __main__ -   current idx uFCptSipOAs.53 from finetune_area returns wrong image/video, use 109667 instead.
[h264 @ 0x55b4fb3f2b00] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:08,  3.19it/s][A
  1%|          | 2/221 [00:00<01:07,  3.23it/s][A
  1%|▏         | 3/221 [00:00<01:05,  3.31it/s][A
  2%|▏         | 4/221 [00:01<01:05,  3.34it/s][A
  2%|▏         | 5/221 [00:01<01:04,  3.35it/s][A
  3%|▎         | 6/221 [00:01<01:05,  3.29it/s][A
  3%|▎         | 7/221 [00:02<01:04,  3.32it/s][A
  4%|▎         | 8/221 [00:02<01:03,  3.35it/s][A
  4%|▍         | 9/221 [00:02<01:03,  3.33it/s][A
  5%|▍         | 10/221 [00:03<01:02,  3.35it/s][A
  5%|▍         | 11/221 [00:03<01:02,  3.37it/s][A
  5%|▌         | 12/221 [00:03<01:03,  3.30it/s][A
  6%|▌         | 13/221 [00:03<01:02,  3.33it/s][A
  6%|▋         | 14/221 [00:04<01:02,  3.31it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.32it/s][A
  7%|▋         | 16/221 [00:04<01:02,  3.29it/s][A
  8%|▊         | 17/221 [00:05<01:02,  3.26it/s][A
  8%|▊         | 18/221 [00:05<01:02,  3.26it/s][A
  9%|▊         | 19/221 [00:05<01:01,  3.30it/s][A
  9%|▉         | 20/221 [00:06<01:01,  3.27it/s][A
 10%|▉         | 21/221 [00:06<01:00,  3.30it/s][A
 10%|▉         | 22/221 [00:06<01:00,  3.30it/s][A
 10%|█         | 23/221 [00:06<01:00,  3.29it/s][A
 11%|█         | 24/221 [00:07<00:59,  3.32it/s][A
 11%|█▏        | 25/221 [00:07<00:59,  3.28it/s][A
 12%|█▏        | 26/221 [00:07<00:59,  3.27it/s][A
 12%|█▏        | 27/221 [00:08<00:58,  3.31it/s][A
 13%|█▎        | 28/221 [00:08<00:58,  3.29it/s][A
 13%|█▎        | 29/221 [00:08<00:58,  3.27it/s][A
 14%|█▎        | 30/221 [00:09<00:58,  3.26it/s][A
 14%|█▍        | 31/221 [00:09<00:57,  3.29it/s][A
 14%|█▍        | 32/221 [00:09<00:56,  3.32it/s][A
 15%|█▍        | 33/221 [00:09<00:56,  3.34it/s][A
 15%|█▌        | 34/221 [00:10<00:55,  3.36it/s][A
 16%|█▌        | 35/221 [00:10<00:56,  3.31it/s][A
 16%|█▋        | 36/221 [00:10<00:55,  3.34it/s][A
 17%|█▋        | 37/221 [00:11<00:55,  3.30it/s][A
 17%|█▋        | 38/221 [00:11<00:55,  3.32it/s][A
 18%|█▊        | 39/221 [00:11<00:54,  3.34it/s][A
 18%|█▊        | 40/221 [00:12<00:54,  3.35it/s][A
 19%|█▊        | 41/221 [00:12<00:54,  3.28it/s][A
 19%|█▉        | 42/221 [00:12<00:53,  3.32it/s][A
 19%|█▉        | 43/221 [00:12<00:53,  3.34it/s][A
 20%|█▉        | 44/221 [00:13<00:52,  3.35it/s][A
 20%|██        | 45/221 [00:13<00:52,  3.37it/s][A[h264 @ 0x56068c1459c0] mmco: unref short failure
[h264 @ 0x56068c1459c0] mmco: unref short failure
[h264 @ 0x56068c1459c0] mmco: unref short failure
[h264 @ 0x56068c1459c0] mmco: unref short failure

 21%|██        | 46/221 [00:13<00:51,  3.38it/s][A
 21%|██▏       | 47/221 [00:14<00:52,  3.34it/s][A
 22%|██▏       | 48/221 [00:14<00:52,  3.29it/s][A
 22%|██▏       | 49/221 [00:14<00:51,  3.32it/s][A
 23%|██▎       | 50/221 [00:15<00:51,  3.29it/s][A
 23%|██▎       | 51/221 [00:15<00:51,  3.33it/s][A
 24%|██▎       | 52/221 [00:15<00:50,  3.35it/s][A
 24%|██▍       | 53/221 [00:15<00:50,  3.35it/s][A
 24%|██▍       | 54/221 [00:16<00:49,  3.37it/s][A
 25%|██▍       | 55/221 [00:16<00:49,  3.38it/s][A
 25%|██▌       | 56/221 [00:16<00:49,  3.36it/s][A
 26%|██▌       | 57/221 [00:17<00:48,  3.36it/s][A
 26%|██▌       | 58/221 [00:17<00:48,  3.36it/s][A
 27%|██▋       | 59/221 [00:17<00:48,  3.37it/s][A
 27%|██▋       | 60/221 [00:18<00:47,  3.38it/s][A
 28%|██▊       | 61/221 [00:18<00:47,  3.34it/s][A
 28%|██▊       | 62/221 [00:18<00:47,  3.36it/s][A
 29%|██▊       | 63/221 [00:18<00:46,  3.36it/s][A
 29%|██▉       | 64/221 [00:19<00:46,  3.34it/s][A
 29%|██▉       | 65/221 [00:19<00:47,  3.31it/s][A
 30%|██▉       | 66/221 [00:19<00:46,  3.33it/s][A
 30%|███       | 67/221 [00:20<00:45,  3.35it/s][A
 31%|███       | 68/221 [00:20<00:45,  3.37it/s][A
 31%|███       | 69/221 [00:20<00:45,  3.37it/s][A
 32%|███▏      | 70/221 [00:21<00:44,  3.37it/s][A
 32%|███▏      | 71/221 [00:21<00:45,  3.30it/s][A
 33%|███▎      | 72/221 [00:21<00:44,  3.33it/s][A
 33%|███▎      | 73/221 [00:21<00:44,  3.35it/s][A
 33%|███▎      | 74/221 [00:22<00:43,  3.37it/s][A
 34%|███▍      | 75/221 [00:22<00:43,  3.36it/s][A
 34%|███▍      | 76/221 [00:22<00:43,  3.31it/s][A
 35%|███▍      | 77/221 [00:23<00:43,  3.33it/s][A
 35%|███▌      | 78/221 [00:23<00:42,  3.34it/s][A
 36%|███▌      | 79/221 [00:23<00:42,  3.36it/s][A
 36%|███▌      | 80/221 [00:24<00:41,  3.37it/s][A
 37%|███▋      | 81/221 [00:24<00:41,  3.34it/s][A
 37%|███▋      | 82/221 [00:24<00:41,  3.35it/s][A
 38%|███▊      | 83/221 [00:24<00:41,  3.30it/s][A
 38%|███▊      | 84/221 [00:25<00:43,  3.17it/s][A
 38%|███▊      | 85/221 [00:25<00:42,  3.22it/s][A
 39%|███▉      | 86/221 [00:25<00:41,  3.24it/s][A
 39%|███▉      | 87/221 [00:26<00:40,  3.28it/s][A
 40%|███▉      | 88/221 [00:26<00:40,  3.29it/s][A
 40%|████      | 89/221 [00:26<00:40,  3.28it/s][A
 41%|████      | 90/221 [00:27<00:40,  3.23it/s][A
 41%|████      | 91/221 [00:27<00:40,  3.18it/s][A
 42%|████▏     | 92/221 [00:27<00:40,  3.21it/s][A
 42%|████▏     | 93/221 [00:28<00:39,  3.25it/s][A
 43%|████▎     | 94/221 [00:28<00:39,  3.22it/s][A
 43%|████▎     | 95/221 [00:28<00:38,  3.27it/s][A
 43%|████▎     | 96/221 [00:28<00:38,  3.29it/s][A
 44%|████▍     | 97/221 [00:29<00:37,  3.32it/s][A
 44%|████▍     | 98/221 [00:29<00:36,  3.34it/s][A
 45%|████▍     | 99/221 [00:29<00:36,  3.36it/s][A
 45%|████▌     | 100/221 [00:30<00:36,  3.33it/s][A[h264 @ 0x55b5158aca80] mmco: unref short failure

 46%|████▌     | 101/221 [00:30<00:35,  3.35it/s][A
 46%|████▌     | 102/221 [00:30<00:35,  3.37it/s][A
 47%|████▋     | 103/221 [00:31<00:34,  3.38it/s][A
 47%|████▋     | 104/221 [00:31<00:34,  3.39it/s][A
 48%|████▊     | 105/221 [00:31<00:34,  3.38it/s][A[h264 @ 0x55e191322a00] mmco: unref short failure

 48%|████▊     | 106/221 [00:31<00:33,  3.39it/s][A
 48%|████▊     | 107/221 [00:32<00:34,  3.31it/s][A
 49%|████▉     | 108/221 [00:32<00:33,  3.34it/s][A
 49%|████▉     | 109/221 [00:32<00:33,  3.36it/s][A
 50%|████▉     | 110/221 [00:33<00:32,  3.37it/s][A
 50%|█████     | 111/221 [00:33<00:32,  3.38it/s][A
 51%|█████     | 112/221 [00:33<00:32,  3.39it/s][A
 51%|█████     | 113/221 [00:34<00:31,  3.39it/s][A
 52%|█████▏    | 114/221 [00:34<00:31,  3.40it/s][A
 52%|█████▏    | 115/221 [00:34<00:31,  3.40it/s][A
 52%|█████▏    | 116/221 [00:34<00:30,  3.40it/s][A
 53%|█████▎    | 117/221 [00:35<00:30,  3.40it/s][A
 53%|█████▎    | 118/221 [00:35<00:30,  3.40it/s][A
 54%|█████▍    | 119/221 [00:35<00:29,  3.40it/s][A
 54%|█████▍    | 120/221 [00:36<00:29,  3.41it/s][A
 55%|█████▍    | 121/221 [00:36<00:29,  3.41it/s][A
 55%|█████▌    | 122/221 [00:36<00:29,  3.41it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.41it/s][A
 56%|█████▌    | 124/221 [00:37<00:28,  3.41it/s][A
 57%|█████▋    | 125/221 [00:37<00:28,  3.41it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:38<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:38<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:39<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:39<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:40<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:40<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:41<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:41<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:41<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:42<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:42<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:43<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:43<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:44<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:44<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:45<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:45<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:45<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:46<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:46<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:46<00:19,  3.42it/s][A
 71%|███████   | 157/221 [00:46<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:47<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:47<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:48<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:48<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:48<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:49<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:49<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:49<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:50<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:50<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:50<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:51<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:51<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:52<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:52<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:53<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:53<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:54<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:54<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:55<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:55<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:55<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:56<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:57<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:57<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:57<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:58<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:59<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:59<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [01:00<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [01:00<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:01<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:02<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:02<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:04<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:05<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:05<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.42it/s][A100%|██████████| 221/221 [01:05<00:00,  3.37it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:31,  6.99it/s][A
  1%|          | 2/221 [00:00<01:02,  3.53it/s][A
  1%|▏         | 3/221 [00:01<01:43,  2.10it/s][A
  2%|▏         | 4/221 [00:01<01:16,  2.83it/s][A
  2%|▏         | 5/221 [00:01<00:59,  3.62it/s][A
  3%|▎         | 6/221 [00:01<00:51,  4.20it/s][A
  3%|▎         | 7/221 [00:01<00:45,  4.68it/s][A
  4%|▎         | 8/221 [00:02<00:46,  4.61it/s][A
  4%|▍         | 9/221 [00:02<00:54,  3.90it/s][A
  5%|▍         | 10/221 [00:03<01:16,  2.74it/s][A
  5%|▍         | 11/221 [00:03<01:11,  2.96it/s][A
  5%|▌         | 12/221 [00:03<01:00,  3.43it/s][A
  6%|▌         | 13/221 [00:04<01:25,  2.42it/s][A
  6%|▋         | 14/221 [00:04<01:11,  2.91it/s][A
  7%|▋         | 15/221 [00:04<01:16,  2.69it/s][A
  7%|▋         | 16/221 [00:05<01:10,  2.93it/s][A
  8%|▊         | 17/221 [00:05<01:23,  2.44it/s][A
  8%|▊         | 18/221 [00:05<01:17,  2.61it/s][A
  9%|▊         | 19/221 [00:06<01:05,  3.09it/s][A
  9%|▉         | 20/221 [00:06<01:00,  3.32it/s][A
 10%|▉         | 21/221 [00:06<00:49,  4.00it/s][A
 10%|▉         | 22/221 [00:06<00:45,  4.40it/s][A
 11%|█         | 24/221 [00:06<00:33,  5.87it/s][A
 11%|█▏        | 25/221 [00:07<00:36,  5.34it/s][A
 12%|█▏        | 26/221 [00:07<00:43,  4.47it/s][A
 12%|█▏        | 27/221 [00:07<00:41,  4.63it/s][A
 13%|█▎        | 28/221 [00:08<00:58,  3.30it/s][A
 13%|█▎        | 29/221 [00:08<00:54,  3.52it/s][A
 14%|█▎        | 30/221 [00:08<00:50,  3.81it/s][A
 14%|█▍        | 31/221 [00:09<00:56,  3.38it/s][A
 14%|█▍        | 32/221 [00:09<00:46,  4.10it/s][A
 15%|█▍        | 33/221 [00:09<00:44,  4.23it/s][A
 15%|█▌        | 34/221 [00:09<00:43,  4.32it/s][A
 16%|█▌        | 35/221 [00:09<00:43,  4.28it/s][A
 16%|█▋        | 36/221 [00:10<01:07,  2.75it/s][A
 17%|█▋        | 37/221 [00:10<01:00,  3.03it/s][A
 17%|█▋        | 38/221 [00:11<00:59,  3.09it/s][A
 18%|█▊        | 39/221 [00:11<00:47,  3.87it/s][A
 18%|█▊        | 40/221 [00:11<00:49,  3.62it/s][A
 19%|█▊        | 41/221 [00:11<00:48,  3.71it/s][A
 19%|█▉        | 42/221 [00:11<00:43,  4.10it/s][A
 19%|█▉        | 43/221 [00:12<01:03,  2.81it/s][A
 20%|█▉        | 44/221 [00:12<00:58,  3.02it/s][A
 20%|██        | 45/221 [00:13<01:01,  2.88it/s][A
 21%|██        | 46/221 [00:13<00:55,  3.15it/s][A
 21%|██▏       | 47/221 [00:13<00:45,  3.82it/s][A
 22%|██▏       | 49/221 [00:13<00:32,  5.25it/s][A
 23%|██▎       | 50/221 [00:14<00:40,  4.19it/s][A
 23%|██▎       | 51/221 [00:14<00:42,  3.96it/s][A
 24%|██▎       | 52/221 [00:14<00:36,  4.62it/s][A
 24%|██▍       | 53/221 [00:14<00:42,  4.00it/s][A
 24%|██▍       | 54/221 [00:15<00:40,  4.07it/s][A
 25%|██▍       | 55/221 [00:15<00:35,  4.66it/s][A
 25%|██▌       | 56/221 [00:15<00:42,  3.88it/s][A
 26%|██▌       | 57/221 [00:16<00:48,  3.41it/s][A
 27%|██▋       | 59/221 [00:16<00:38,  4.17it/s][A
 27%|██▋       | 60/221 [00:16<00:36,  4.45it/s][A
 28%|██▊       | 61/221 [00:16<00:35,  4.45it/s][A
 28%|██▊       | 62/221 [00:17<00:37,  4.21it/s][A
 29%|██▉       | 64/221 [00:17<00:32,  4.87it/s][A
 29%|██▉       | 65/221 [00:17<00:32,  4.87it/s][A
 30%|██▉       | 66/221 [00:17<00:36,  4.21it/s][A
 30%|███       | 67/221 [00:18<00:48,  3.19it/s][A
 31%|███       | 68/221 [00:18<00:40,  3.75it/s][A
 31%|███       | 69/221 [00:19<00:51,  2.94it/s][A
 32%|███▏      | 70/221 [00:19<00:44,  3.42it/s][A
 32%|███▏      | 71/221 [00:19<00:46,  3.24it/s][A
 33%|███▎      | 72/221 [00:20<00:54,  2.72it/s][A
 33%|███▎      | 73/221 [00:20<00:52,  2.82it/s][A
 33%|███▎      | 74/221 [00:20<00:46,  3.18it/s][A
 34%|███▍      | 75/221 [00:21<00:52,  2.80it/s][A
 34%|███▍      | 76/221 [00:21<00:44,  3.23it/s][A
 35%|███▍      | 77/221 [00:21<00:45,  3.18it/s][A
 35%|███▌      | 78/221 [00:21<00:41,  3.47it/s][A
 36%|███▌      | 79/221 [00:22<00:42,  3.37it/s][A
 36%|███▌      | 80/221 [00:22<00:39,  3.58it/s][A
 37%|███▋      | 81/221 [00:22<00:38,  3.65it/s][A
 37%|███▋      | 82/221 [00:22<00:38,  3.61it/s][A
 38%|███▊      | 83/221 [00:23<00:32,  4.24it/s][A
 38%|███▊      | 84/221 [00:23<00:32,  4.23it/s][A
 38%|███▊      | 85/221 [00:23<00:28,  4.82it/s][A
 39%|███▉      | 86/221 [00:23<00:24,  5.60it/s][A
 39%|███▉      | 87/221 [00:24<00:43,  3.08it/s][A
 40%|███▉      | 88/221 [00:24<00:45,  2.95it/s][A
 40%|████      | 89/221 [00:25<00:46,  2.86it/s][A
 41%|████      | 90/221 [00:25<00:48,  2.68it/s][A
 41%|████      | 91/221 [00:25<00:43,  3.00it/s][A
 42%|████▏     | 92/221 [00:25<00:38,  3.31it/s][A
 42%|████▏     | 93/221 [00:26<00:40,  3.18it/s][A
 43%|████▎     | 94/221 [00:26<00:34,  3.63it/s][A
 43%|████▎     | 95/221 [00:27<00:49,  2.56it/s][A
 43%|████▎     | 96/221 [00:27<00:46,  2.70it/s][A
 44%|████▍     | 97/221 [00:27<00:42,  2.92it/s][A
 44%|████▍     | 98/221 [00:28<00:43,  2.86it/s][A
 45%|████▍     | 99/221 [00:28<00:38,  3.13it/s][A
 45%|████▌     | 100/221 [00:28<00:34,  3.49it/s][A
 46%|████▌     | 101/221 [00:29<00:40,  2.94it/s][A
 46%|████▌     | 102/221 [00:29<00:36,  3.26it/s][A
 47%|████▋     | 103/221 [00:29<00:30,  3.88it/s][A
 48%|████▊     | 105/221 [00:29<00:24,  4.82it/s][A
 48%|████▊     | 106/221 [00:30<00:29,  3.84it/s][A
 48%|████▊     | 107/221 [00:30<00:25,  4.40it/s][A
 49%|████▉     | 108/221 [00:30<00:27,  4.13it/s][A
 49%|████▉     | 109/221 [00:30<00:30,  3.68it/s][A
 50%|████▉     | 110/221 [00:31<00:27,  4.01it/s][A
 50%|█████     | 111/221 [00:31<00:30,  3.62it/s][A
 51%|█████     | 112/221 [00:31<00:30,  3.63it/s][A
 51%|█████     | 113/221 [00:31<00:28,  3.84it/s][A
 52%|█████▏    | 115/221 [00:32<00:22,  4.69it/s][A
 52%|█████▏    | 116/221 [00:32<00:21,  4.85it/s][A
 53%|█████▎    | 117/221 [00:32<00:22,  4.69it/s][A
 53%|█████▎    | 118/221 [00:33<00:27,  3.78it/s][A
 54%|█████▍    | 119/221 [00:33<00:34,  2.97it/s][A
 54%|█████▍    | 120/221 [00:33<00:34,  2.94it/s][A
 55%|█████▍    | 121/221 [00:34<00:34,  2.94it/s][A
 55%|█████▌    | 122/221 [00:34<00:31,  3.17it/s][A
 56%|█████▌    | 123/221 [00:34<00:27,  3.56it/s][A
 56%|█████▌    | 124/221 [00:35<00:33,  2.93it/s][A
 57%|█████▋    | 125/221 [00:35<00:42,  2.24it/s][A
 57%|█████▋    | 126/221 [00:36<00:34,  2.73it/s][A
 57%|█████▋    | 127/221 [00:36<00:42,  2.19it/s][A
 58%|█████▊    | 128/221 [00:36<00:36,  2.58it/s][A
 58%|█████▊    | 129/221 [00:37<00:28,  3.27it/s][A
 59%|█████▉    | 130/221 [00:37<00:24,  3.77it/s][A
 59%|█████▉    | 131/221 [00:37<00:24,  3.68it/s][A
 60%|█████▉    | 132/221 [00:38<00:33,  2.66it/s][A
 60%|██████    | 133/221 [00:38<00:34,  2.57it/s][A
 61%|██████    | 134/221 [00:39<00:41,  2.08it/s][A
 62%|██████▏   | 136/221 [00:39<00:30,  2.81it/s][A
 62%|██████▏   | 137/221 [00:39<00:26,  3.14it/s][A
 62%|██████▏   | 138/221 [00:40<00:24,  3.36it/s][A
 63%|██████▎   | 139/221 [00:40<00:24,  3.34it/s][A
 63%|██████▎   | 140/221 [00:40<00:23,  3.50it/s][A
 64%|██████▍   | 141/221 [00:40<00:20,  3.87it/s][A
 64%|██████▍   | 142/221 [00:41<00:19,  3.98it/s][A
 65%|██████▍   | 143/221 [00:41<00:20,  3.80it/s][A
 65%|██████▌   | 144/221 [00:41<00:19,  3.93it/s][A
 66%|██████▌   | 145/221 [00:41<00:22,  3.45it/s][A
 66%|██████▌   | 146/221 [00:42<00:20,  3.58it/s][A
 67%|██████▋   | 147/221 [00:42<00:18,  4.01it/s][A
 67%|██████▋   | 148/221 [00:42<00:21,  3.46it/s][A
 67%|██████▋   | 149/221 [00:42<00:18,  3.88it/s][A
 68%|██████▊   | 150/221 [00:43<00:17,  3.99it/s][A
 68%|██████▊   | 151/221 [00:44<00:37,  1.86it/s][A
 69%|██████▉   | 152/221 [00:45<00:40,  1.70it/s][A
 69%|██████▉   | 153/221 [00:45<00:32,  2.08it/s][A
 70%|██████▉   | 154/221 [00:45<00:26,  2.49it/s][A
 70%|███████   | 155/221 [00:45<00:24,  2.68it/s][A
 71%|███████   | 156/221 [00:46<00:24,  2.67it/s][A
 71%|███████   | 157/221 [00:46<00:21,  2.97it/s][A
 71%|███████▏  | 158/221 [00:46<00:22,  2.74it/s][A
 72%|███████▏  | 159/221 [00:47<00:18,  3.33it/s][A
 72%|███████▏  | 160/221 [00:47<00:21,  2.81it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.53it/s][A
 73%|███████▎  | 162/221 [00:47<00:14,  4.16it/s][A
 74%|███████▍  | 163/221 [00:48<00:13,  4.33it/s][A
 74%|███████▍  | 164/221 [00:48<00:11,  4.89it/s][A
 75%|███████▍  | 165/221 [00:48<00:10,  5.45it/s][A
 75%|███████▌  | 166/221 [00:48<00:12,  4.41it/s][A
 76%|███████▌  | 168/221 [00:48<00:10,  5.11it/s][A
 76%|███████▋  | 169/221 [00:49<00:09,  5.77it/s][A
 77%|███████▋  | 170/221 [00:49<00:12,  4.13it/s][A
 77%|███████▋  | 171/221 [00:50<00:16,  3.07it/s][A
 78%|███████▊  | 172/221 [00:50<00:14,  3.50it/s][A
 78%|███████▊  | 173/221 [00:50<00:15,  3.10it/s][A
 79%|███████▉  | 175/221 [00:51<00:12,  3.78it/s][A
 80%|███████▉  | 176/221 [00:51<00:10,  4.29it/s][A
 80%|████████  | 177/221 [00:51<00:10,  4.15it/s][A
 81%|████████  | 178/221 [00:52<00:14,  3.02it/s][A
 81%|████████  | 179/221 [00:52<00:14,  2.99it/s][A
 82%|████████▏ | 181/221 [00:52<00:09,  4.08it/s][A
 82%|████████▏ | 182/221 [00:52<00:09,  4.14it/s][A
 83%|████████▎ | 183/221 [00:53<00:09,  3.93it/s][A
 83%|████████▎ | 184/221 [00:53<00:09,  3.90it/s][A
 84%|████████▍ | 186/221 [00:53<00:07,  4.50it/s][A
 85%|████████▍ | 187/221 [00:53<00:06,  4.96it/s][A
 85%|████████▌ | 188/221 [00:54<00:06,  4.95it/s][A
 86%|████████▌ | 189/221 [00:54<00:06,  5.00it/s][A
 86%|████████▌ | 190/221 [00:54<00:08,  3.52it/s][A
 86%|████████▋ | 191/221 [00:54<00:07,  4.10it/s][A
 87%|████████▋ | 192/221 [00:55<00:08,  3.44it/s][A
 87%|████████▋ | 193/221 [00:55<00:07,  3.77it/s][A
 88%|████████▊ | 194/221 [00:56<00:09,  2.94it/s][A
 88%|████████▊ | 195/221 [00:56<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:56<00:09,  2.58it/s][A
 89%|████████▉ | 197/221 [00:57<00:10,  2.26it/s][A
 90%|████████▉ | 198/221 [00:57<00:09,  2.41it/s][A
 90%|█████████ | 199/221 [00:57<00:07,  3.08it/s][A
 90%|█████████ | 200/221 [00:58<00:05,  3.62it/s][A
 91%|█████████ | 201/221 [00:58<00:04,  4.02it/s][A
 91%|█████████▏| 202/221 [00:58<00:04,  4.27it/s][A
 92%|█████████▏| 203/221 [00:58<00:04,  4.28it/s][A
 92%|█████████▏| 204/221 [00:58<00:03,  4.54it/s][A
 93%|█████████▎| 205/221 [00:59<00:03,  4.23it/s][A
 93%|█████████▎| 206/221 [00:59<00:05,  2.95it/s][A
 94%|█████████▎| 207/221 [00:59<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:00<00:03,  3.29it/s][A
 95%|█████████▍| 209/221 [01:00<00:03,  3.02it/s][A
 95%|█████████▌| 210/221 [01:00<00:02,  3.74it/s][A
 95%|█████████▌| 211/221 [01:00<00:02,  3.93it/s][A
 96%|█████████▌| 212/221 [01:01<00:02,  3.41it/s][A
 96%|█████████▋| 213/221 [01:01<00:02,  3.45it/s][A
 97%|█████████▋| 214/221 [01:02<00:02,  3.09it/s][A
 97%|█████████▋| 215/221 [01:02<00:01,  3.01it/s][A
 98%|█████████▊| 216/221 [01:02<00:01,  3.06it/s][A
 98%|█████████▊| 217/221 [01:03<00:01,  3.03it/s][A
 99%|█████████▊| 218/221 [01:03<00:01,  2.69it/s][A
 99%|█████████▉| 219/221 [01:03<00:00,  2.97it/s][A
100%|█████████▉| 220/221 [01:03<00:00,  3.59it/s][A
100%|██████████| 221/221 [01:04<00:00,  2.96it/s][A100%|██████████| 221/221 [01:04<00:00,  3.43it/s]
09/17/2024 00:55:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 249--===========

09/17/2024 00:55:29 - INFO - __main__ -   {'area_r1': 41.4, 'area_recall': '41.4/68.8/78.3', 'area_ravg': 62.8}
09/17/2024 00:55:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 249--===========

09/17/2024 00:55:29 - INFO - __main__ -   {'forward_r1': 38.5, 'forward_recall': '38.5/65.4/74.7', 'forward_ravg': 59.5}
09/17/2024 00:55:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 249--===========

09/17/2024 00:55:29 - INFO - __main__ -   {'area_video_r1': 39.4, 'area_video_recall': '39.4/67.4/78.8', 'area_video_ravg': 61.9}
09/17/2024 00:55:29 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 249=======

09/17/2024 00:55:29 - INFO - __main__ -   {'area_video_r1': 39.4, 'area_video_recall': '39.4/67.4/78.8', 'area_video_ravg': 61.9}
09/17/2024 00:55:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 249--===========

09/17/2024 00:55:29 - INFO - __main__ -   {'area_video_r1': 51.4, 'area_video_recall': '51.4/74.5/82.6', 'area_video_ravg': 69.5, 'area_video_back_r1': 48.9, 'area_video_back_recall': '48.9/72.1/80.5', 'area_video_back_ravg': 67.2}
09/17/2024 00:55:29 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 199=======

09/17/2024 00:55:29 - INFO - __main__ -   {'area_video_r1': 51.5, 'area_video_recall': '51.5/74.7/83.1', 'area_video_ravg': 69.8, 'area_video_back_r1': 49.3, 'area_video_back_recall': '49.3/72.4/80.0', 'area_video_back_ravg': 67.2}
09/17/2024 00:55:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 249--===========

09/17/2024 00:55:29 - INFO - __main__ -   {'video_r1': 37.1, 'video_recall': '37.1/65.0/74.1', 'video_ravg': 58.7}
09/17/2024 00:55:29 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 249=======

09/17/2024 00:55:29 - INFO - __main__ -   {'video_r1': 37.1, 'video_recall': '37.1/65.0/74.1', 'video_ravg': 58.7}
09/17/2024 00:55:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 249--===========

09/17/2024 00:55:29 - INFO - __main__ -   {'video_r1': 51.1, 'video_recall': '51.1/74.7/82.2', 'video_ravg': 69.3}
09/17/2024 00:55:29 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 249=======

09/17/2024 00:55:29 - INFO - __main__ -   {'video_r1': 51.1, 'video_recall': '51.1/74.7/82.2', 'video_ravg': 69.3}
09/17/2024 00:56:03 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.012368041090667248, 'loss_ret%tv%ta--finetune_area/loss_area': 2.031310796737671, 'loss_ret%tv%ta--finetune_area/total_loss': 2.0436787605285645}
  9%|▊         | 250/2910 [1:34:19<100:04:04, 135.43s/it]  9%|▊         | 251/2910 [1:34:23<70:52:24, 95.96s/it]  [h264 @ 0x55b51940b540] mmco: unref short failure
09/17/2024 00:56:11 - INFO - __main__ -   current idx hvDXjC-_7uo.11 from finetune_area returns wrong image/video, use 17857 instead.
[h264 @ 0x55e183023d00] mmco: unref short failure
  9%|▊         | 252/2910 [1:34:27<50:25:46, 68.30s/it][h264 @ 0x55b4f8d2e500] mmco: unref short failure
[h264 @ 0x55b4f8d2e500] mmco: unref short failure
  9%|▊         | 253/2910 [1:34:32<36:15:48, 49.13s/it]09/17/2024 00:56:17 - INFO - __main__ -   current idx 3B1z5s6SZbQ.15 from finetune_area returns wrong image/video, use 145948 instead.
09/17/2024 00:56:18 - INFO - __main__ -   current idx 5cCEw9Tageg.3 from finetune_area returns wrong image/video, use 141833 instead.
[h264 @ 0x55a270420440] mmco: unref short failure
  9%|▊         | 254/2910 [1:34:36<26:23:01, 35.76s/it]  9%|▉         | 255/2910 [1:34:41<19:28:42, 26.41s/it]  9%|▉         | 256/2910 [1:34:46<14:46:13, 20.04s/it][h264 @ 0x56069d31a680] mmco: unref short failure
[h264 @ 0x56069d31a680] mmco: unref short failure
  9%|▉         | 257/2910 [1:34:52<11:42:46, 15.89s/it]  9%|▉         | 258/2910 [1:34:58<9:25:42, 12.80s/it] [h264 @ 0x56068ebc43c0] mmco: unref short failure
[h264 @ 0x55a278953800] mmco: unref short failure
[h264 @ 0x55a278953800] mmco: unref short failure
[h264 @ 0x56068ebc43c0] mmco: unref short failure
  9%|▉         | 259/2910 [1:35:03<7:43:47, 10.50s/it][h264 @ 0x55e189e32cc0] mmco: unref short failure
[h264 @ 0x55e189e32cc0] mmco: unref short failure
[h264 @ 0x55b512c2e340] mmco: unref short failure
[h264 @ 0x55b512c2e340] mmco: unref short failure
[h264 @ 0x55b512c2e340] mmco: unref short failure
[h264 @ 0x55b512c2e340] mmco: unref short failure
  9%|▉         | 260/2910 [1:35:08<6:31:08,  8.86s/it][h264 @ 0x5606a7f56000] mmco: unref short failure
[h264 @ 0x5606a7f56000] mmco: unref short failure
  9%|▉         | 261/2910 [1:35:13<5:42:54,  7.77s/it][h264 @ 0x55e198cedbc0] mmco: unref short failure
[h264 @ 0x55e198cedbc0] mmco: unref short failure
  9%|▉         | 262/2910 [1:35:18<5:05:12,  6.92s/it][h264 @ 0x55a260a79ec0] mmco: unref short failure
[h264 @ 0x55e1a02aeec0] mmco: unref short failure
  9%|▉         | 263/2910 [1:35:24<4:48:53,  6.55s/it]  9%|▉         | 264/2910 [1:35:29<4:38:15,  6.31s/it][h264 @ 0x55e19ea59740] mmco: unref short failure
[h264 @ 0x55e19ea59740] mmco: unref short failure
[h264 @ 0x55b505376fc0] mmco: unref short failure
  9%|▉         | 265/2910 [1:35:35<4:28:46,  6.10s/it][h264 @ 0x55b4f613f700] mmco: unref short failure
[h264 @ 0x55b4f613f700] mmco: unref short failure
[h264 @ 0x55b4fc50db00] mmco: unref short failure
[h264 @ 0x55b4f5694c80] mmco: unref short failure
[h264 @ 0x55b4f5694c80] mmco: unref short failure
[h264 @ 0x56068fa155c0] mmco: unref short failure
09/17/2024 00:57:39 - INFO - __main__ -   current idx 8XNjcDFNZzM.6 from finetune_area returns wrong image/video, use 85484 instead.
[h264 @ 0x560693dbfe00] mmco: unref short failure
[h264 @ 0x560693dbfe00] mmco: unref short failure
[h264 @ 0x56069daf9300] mmco: unref short failure
[h264 @ 0x56069daf9300] mmco: unref short failure
[h264 @ 0x5606a4f8ae40] mmco: unref short failure
[h264 @ 0x5606aa3c7b00] mmco: unref short failure
[h264 @ 0x5606aa3c7b00] mmco: unref short failure
[h264 @ 0x56069db83f00] mmco: unref short failure
[h264 @ 0x56069db83f00] mmco: unref short failure
  9%|▉         | 266/2910 [1:36:16<12:08:33, 16.53s/it][h264 @ 0x55e18cb45f80] mmco: unref short failure
[h264 @ 0x55e18cb45f80] mmco: unref short failure
[h264 @ 0x55e18cb45f80] mmco: unref short failure
[h264 @ 0x55b5094c95c0] mmco: unref short failure
[h264 @ 0x55b5094c95c0] mmco: unref short failure
[h264 @ 0x55e189a7f000] mmco: unref short failure
  9%|▉         | 267/2910 [1:36:31<11:49:37, 16.11s/it]  9%|▉         | 268/2910 [1:36:48<12:00:15, 16.36s/it][h264 @ 0x55e19ea60f40] mmco: unref short failure
[h264 @ 0x55a277a3aac0] mmco: unref short failure
[h264 @ 0x55a277a3aac0] mmco: unref short failure
[h264 @ 0x55e1a02aeec0] mmco: unref short failure
  9%|▉         | 269/2910 [1:37:07<12:33:13, 17.11s/it][h264 @ 0x55a2625a2540] mmco: unref short failure
[h264 @ 0x55a2625a2540] mmco: unref short failure
  9%|▉         | 270/2910 [1:37:12<9:59:07, 13.62s/it]   9%|▉         | 271/2910 [1:37:17<8:04:24, 11.01s/it]  9%|▉         | 272/2910 [1:37:22<6:42:55,  9.16s/it][h264 @ 0x55e196c33980] mmco: unref short failure
  9%|▉         | 273/2910 [1:37:27<5:43:16,  7.81s/it][h264 @ 0x55b4f980a500] mmco: unref short failure
[h264 @ 0x55e18c664b40] mmco: unref short failure
[h264 @ 0x55e18c664b40] mmco: unref short failure
[h264 @ 0x55b507bf9240] mmco: unref short failure
[h264 @ 0x55b507bf9240] mmco: unref short failure
[h264 @ 0x55e1a11d2500] mmco: unref short failure
[h264 @ 0x55b500b17b40] mmco: unref short failure
not have audios xrsV4ybwavc.40
[h264 @ 0x55a25bbf9280] mmco: unref short failure
[h264 @ 0x55a25bbf9280] mmco: unref short failure
[h264 @ 0x55a2779dbd00] mmco: unref short failure
[h264 @ 0x55a2779dbd00] mmco: unref short failure
[h264 @ 0x5606a744d680] mmco: unref short failure
[h264 @ 0x5606a744d680] mmco: unref short failure
[h264 @ 0x55a269636080] mmco: unref short failure
[h264 @ 0x55a269636080] mmco: unref short failure
[h264 @ 0x55a281648e80] mmco: unref short failure
[h264 @ 0x55e192621d80] mmco: unref short failure
09/17/2024 01:00:17 - INFO - __main__ -   current idx TXiTVBVNPyE.67 from finetune_area returns wrong image/video, use 54888 instead.
[h264 @ 0x55b50e692dc0] mmco: unref short failure
[h264 @ 0x55e183000480] mmco: unref short failure
  9%|▉         | 274/2910 [1:38:42<20:37:03, 28.16s/it][h264 @ 0x56068c7a8840] mmco: unref short failure
[h264 @ 0x56068c7a8840] mmco: unref short failure
[h264 @ 0x56068c7a8840] mmco: unref short failure
[h264 @ 0x56068c7a8840] mmco: unref short failure
[h264 @ 0x56068c7a8840] mmco: unref short failure
[h264 @ 0x56068c7a8840] mmco: unref short failure
[h264 @ 0x56068c7a8840] mmco: unref short failure
[h264 @ 0x56068c7a8840] mmco: unref short failure
[h264 @ 0x56068f7b9f80] mmco: unref short failure
[h264 @ 0x56068f7b9f80] mmco: unref short failure
[h264 @ 0x56068f7b9f80] mmco: unref short failure
[h264 @ 0x56068f7b9f80] mmco: unref short failure
[h264 @ 0x55a260372140] mmco: unref short failure
  9%|▉         | 275/2910 [1:39:04<19:16:07, 26.33s/it][h264 @ 0x56069b90c000] mmco: unref short failure
[h264 @ 0x56069b90c000] mmco: unref short failure
[h264 @ 0x56069b90c000] mmco: unref short failure
[h264 @ 0x56069b90c000] mmco: unref short failure
[h264 @ 0x56069b90c000] mmco: unref short failure
[h264 @ 0x55a277c40480] mmco: unref short failure
[h264 @ 0x55a277c40480] mmco: unref short failure
  9%|▉         | 276/2910 [1:39:18<16:34:48, 22.66s/it][h264 @ 0x55e19fe15500] mmco: unref short failure
[h264 @ 0x55b506ba5dc0] mmco: unref short failure
 10%|▉         | 277/2910 [1:39:39<16:10:24, 22.11s/it][h264 @ 0x55b514190840] mmco: unref short failure
[h264 @ 0x55b514190840] mmco: unref short failure
[h264 @ 0x55a25c731040] mmco: unref short failure
 10%|▉         | 278/2910 [1:39:45<12:31:09, 17.12s/it] 10%|▉         | 279/2910 [1:39:51<10:04:10, 13.78s/it] 10%|▉         | 280/2910 [1:39:56<8:07:30, 11.12s/it] [h264 @ 0x55e1a6f6c400] mmco: unref short failure
[h264 @ 0x5606a08a2a80] mmco: unref short failure
[h264 @ 0x5606a08a2a80] mmco: unref short failure
[h264 @ 0x55e185c4e5c0] mmco: unref short failure
[h264 @ 0x55e185c4e5c0] mmco: unref short failure
[h264 @ 0x55e185c4e5c0] mmco: unref short failure
[h264 @ 0x55e185c4e5c0] mmco: unref short failure
 10%|▉         | 281/2910 [1:40:02<7:04:06,  9.68s/it][h264 @ 0x5606a35a4b80] mmco: unref short failure
[h264 @ 0x5606adb561c0] mmco: unref short failure
[h264 @ 0x56068fcb23c0] mmco: unref short failure
[h264 @ 0x56068fcb23c0] mmco: unref short failure
[h264 @ 0x56068fcb23c0] mmco: unref short failure
[h264 @ 0x56068fcb23c0] mmco: unref short failure
[h264 @ 0x56068fcb23c0] mmco: unref short failure
[h264 @ 0x56068fcb23c0] mmco: unref short failure
[h264 @ 0x56068fcb23c0] mmco: unref short failure
[h264 @ 0x55a26d929880] mmco: unref short failure
[h264 @ 0x55a26d929880] mmco: unref short failure
[h264 @ 0x55e1840872c0] mmco: unref short failure
09/17/2024 01:02:10 - INFO - __main__ -   current idx 4VH9UPwnHCQ.1 from finetune_area returns wrong image/video, use 64300 instead.
[h264 @ 0x55a25ef37b00] mmco: unref short failure
[h264 @ 0x55a26fdbe080] mmco: unref short failure
[h264 @ 0x55a26fdbe080] mmco: unref short failure
[h264 @ 0x5606a3d22b00] mmco: unref short failure
[h264 @ 0x55e18cf75140] mmco: unref short failure
[h264 @ 0x55e18cf75140] mmco: unref short failure
[h264 @ 0x55e18749a680] mmco: unref short failure
[h264 @ 0x55e18749a680] mmco: unref short failure
[h264 @ 0x55e18749a680] mmco: unref short failure
[h264 @ 0x55e18749a680] mmco: unref short failure
09/17/2024 01:02:31 - INFO - __main__ -   current idx aKaIctkC1IU.24 from finetune_area returns wrong image/video, use 39049 instead.
[h264 @ 0x55a2790bbec0] mmco: unref short failure
[h264 @ 0x55a2790bbec0] mmco: unref short failure
[h264 @ 0x55a2790bbec0] mmco: unref short failure
[h264 @ 0x55a2790bbec0] mmco: unref short failure
[h264 @ 0x55a263084100] mmco: unref short failure
[h264 @ 0x55a263084100] mmco: unref short failure
[h264 @ 0x55e18407d440] mmco: unref short failure
[h264 @ 0x55b507aa59c0] mmco: unref short failure
[h264 @ 0x55a265ab5580] mmco: unref short failure
[h264 @ 0x55a265ab5580] mmco: unref short failure
[h264 @ 0x560696e0b0c0] mmco: unref short failure
[h264 @ 0x560696e0b0c0] mmco: unref short failure
[h264 @ 0x55a277a012c0] mmco: unref short failure
 10%|▉         | 282/2910 [1:41:14<20:43:19, 28.39s/it][h264 @ 0x5606acaa1080] mmco: unref short failure
[h264 @ 0x5606acaa1080] mmco: unref short failure
[h264 @ 0x560695924f40] mmco: unref short failure
[h264 @ 0x560695924f40] mmco: unref short failure
 10%|▉         | 283/2910 [1:41:32<18:28:07, 25.31s/it][h264 @ 0x55a26e63ed80] mmco: unref short failure
[h264 @ 0x56069c752280] mmco: unref short failure
[h264 @ 0x55a25e048ac0] mmco: unref short failure
[h264 @ 0x55a25e048ac0] mmco: unref short failure
[h264 @ 0x56068d927440] mmco: unref short failure
[h264 @ 0x56068d927440] mmco: unref short failure
[h264 @ 0x55b4ff02ef40] mmco: unref short failure
[h264 @ 0x55b4ff02ef40] mmco: unref short failure
[h264 @ 0x55a263084100] mmco: unref short failure
[h264 @ 0x55a263084100] mmco: unref short failure
 10%|▉         | 284/2910 [1:41:52<17:19:42, 23.76s/it][h264 @ 0x55a279a18a00] mmco: unref short failure
 10%|▉         | 285/2910 [1:42:06<15:06:41, 20.72s/it] 10%|▉         | 286/2910 [1:42:11<11:39:17, 15.99s/it]09/17/2024 01:04:00 - INFO - __main__ -   current idx edpFNTpJidw.6 from finetune_area returns wrong image/video, use 33504 instead.
[h264 @ 0x55e1a47064c0] mmco: unref short failure
[h264 @ 0x55e1a47064c0] mmco: unref short failure
 10%|▉         | 287/2910 [1:42:16<9:14:31, 12.68s/it] [h264 @ 0x55a263ffa5c0] mmco: unref short failure
[h264 @ 0x5606a863b8c0] mmco: unref short failure
[h264 @ 0x5606a863b8c0] mmco: unref short failure
[h264 @ 0x55b5007eca40] mmco: unref short failure
[h264 @ 0x55b5007eca40] mmco: unref short failure
 10%|▉         | 288/2910 [1:42:23<8:04:40, 11.09s/it][h264 @ 0x55e191ac3740] mmco: unref short failure
 10%|▉         | 289/2910 [1:42:29<6:50:38,  9.40s/it][h264 @ 0x55e18f2cbe80] mmco: unref short failure
[h264 @ 0x55a26990d680] mmco: unref short failure
[h264 @ 0x55a26990d680] mmco: unref short failure
[h264 @ 0x55b50dc40000] mmco: unref short failure
[h264 @ 0x55b50dc40000] mmco: unref short failure
[h264 @ 0x55e186594540] mmco: unref short failure
[h264 @ 0x55a274add2c0] mmco: unref short failure
[h264 @ 0x55a274add2c0] mmco: unref short failure
[h264 @ 0x55b5141ca9c0] mmco: unref short failure
[h264 @ 0x55b5141ca9c0] mmco: unref short failure
[h264 @ 0x55a25c0c1080] mmco: unref short failure
[h264 @ 0x55a25c0c1080] mmco: unref short failure
[h264 @ 0x55b504902900] mmco: unref short failure
[h264 @ 0x55a2735ae300] mmco: unref short failure
[h264 @ 0x55e189ee9d40] mmco: unref short failure
[h264 @ 0x56069c5eb3c0] mmco: unref short failure
[h264 @ 0x55e18ec5c540] mmco: unref short failure
[h264 @ 0x55e18ec5c540] mmco: unref short failure
[h264 @ 0x5606a2f25380] mmco: unref short failure
[h264 @ 0x55a2610105c0] mmco: unref short failure
[h264 @ 0x5606a57d5400] mmco: unref short failure
[h264 @ 0x5606a57d5400] mmco: unref short failure
[h264 @ 0x55e1936743c0] mmco: unref short failure
[h264 @ 0x55e1936743c0] mmco: unref short failure
[h264 @ 0x55e183023d00] mmco: unref short failure
[h264 @ 0x55e183023d00] mmco: unref short failure
[h264 @ 0x55b511eb0700] mmco: unref short failure
[h264 @ 0x55b511eb0700] mmco: unref short failure
[h264 @ 0x55a2659df740] mmco: unref short failure
[h264 @ 0x55a2659df740] mmco: unref short failure
 10%|▉         | 290/2910 [1:43:45<21:24:52, 29.42s/it][h264 @ 0x55b5141cabc0] mmco: unref short failure
09/17/2024 01:05:48 - INFO - __main__ -   current idx Wirilsgk0qk.51 from finetune_area returns wrong image/video, use 128368 instead.
[h264 @ 0x5606a0a07ac0] mmco: unref short failure
[h264 @ 0x5606a0a07ac0] mmco: unref short failure
 10%|█         | 291/2910 [1:44:20<22:43:17, 31.23s/it][h264 @ 0x55a26ed78e80] mmco: unref short failure
[h264 @ 0x55e182363d00] mmco: unref short failure
 10%|█         | 292/2910 [1:44:26<17:02:53, 23.44s/it][h264 @ 0x56068efffac0] mmco: unref short failure
[h264 @ 0x56068efffac0] mmco: unref short failure
[h264 @ 0x56068efffac0] mmco: unref short failure
[h264 @ 0x56068efffac0] mmco: unref short failure
[h264 @ 0x56068efffac0] mmco: unref short failure
[h264 @ 0x56068efffac0] mmco: unref short failure
[h264 @ 0x56068efffac0] mmco: unref short failure
[h264 @ 0x56068efffac0] mmco: unref short failure
 10%|█         | 293/2910 [1:44:33<13:31:47, 18.61s/it][h264 @ 0x55a267aeb480] mmco: unref short failure
[h264 @ 0x55a267aeb480] mmco: unref short failure
 10%|█         | 294/2910 [1:44:38<10:34:27, 14.55s/it][h264 @ 0x55e197029e00] mmco: unref short failure
[h264 @ 0x55e197029e00] mmco: unref short failure
 10%|█         | 295/2910 [1:44:43<8:35:29, 11.83s/it] [h264 @ 0x5606a352b2c0] mmco: unref short failure
[h264 @ 0x55b504902b00] mmco: unref short failure
 10%|█         | 296/2910 [1:44:53<8:00:46, 11.04s/it][h264 @ 0x55e195c7d3c0] mmco: unref short failure
[h264 @ 0x55e195c7d3c0] mmco: unref short failure
 10%|█         | 297/2910 [1:44:58<6:45:28,  9.31s/it][h264 @ 0x56069b90be00] mmco: unref short failure
[h264 @ 0x56069b90be00] mmco: unref short failure
[h264 @ 0x55a270e58d80] mmco: unref short failure
09/17/2024 01:06:47 - INFO - __main__ -   current idx -H9yXYU9VP4.53 from finetune_area returns wrong image/video, use 143939 instead.
[h264 @ 0x55b50ea98980] mmco: unref short failure
[h264 @ 0x55e189fb8d80] mmco: unref short failure
[h264 @ 0x55a25f50a780] mmco: unref short failure
[h264 @ 0x56069dcfde40] mmco: unref short failure
[h264 @ 0x56069dcfde40] mmco: unref short failure
[h264 @ 0x5606a6dc5240] mmco: unref short failure
[h264 @ 0x55b4f423ba80] mmco: unref short failure
[h264 @ 0x55b4f423ba80] mmco: unref short failure
[h264 @ 0x55b4f423ba80] mmco: unref short failure
[h264 @ 0x55b4f423ba80] mmco: unref short failure
[h264 @ 0x55e1872379c0] mmco: unref short failure
[h264 @ 0x55e1872379c0] mmco: unref short failure
[h264 @ 0x55b4fc50db00] mmco: unref short failure
[h264 @ 0x55b4fc50db00] mmco: unref short failure
[h264 @ 0x56068e83f1c0] mmco: unref short failure
[h264 @ 0x55a26f039ac0] mmco: unref short failure
[h264 @ 0x55a26f039ac0] mmco: unref short failure
[h264 @ 0x55a26f039ac0] mmco: unref short failure
[h264 @ 0x55a26f039ac0] mmco: unref short failure
[h264 @ 0x5606917ab900] mmco: unref short failure
[h264 @ 0x5606917ab900] mmco: unref short failure
[h264 @ 0x55e190bbb8c0] mmco: unref short failure
[h264 @ 0x55e190bbb8c0] mmco: unref short failure
[h264 @ 0x55a2754e18c0] mmco: unref short failure
 10%|█         | 298/2910 [1:46:06<19:36:56, 27.04s/it][h264 @ 0x55a260127f40] mmco: unref short failure
[h264 @ 0x55b4fd285040] mmco: unref short failure
[h264 @ 0x55b4fd285040] mmco: unref short failure
[h264 @ 0x55b4fea57880] mmco: unref short failure
[h264 @ 0x5606aa28ebc0] mmco: unref short failure
[h264 @ 0x5606aa28ebc0] mmco: unref short failure
[h264 @ 0x55a262651740] mmco: unref short failure
[h264 @ 0x55a262651740] mmco: unref short failure
 10%|█         | 299/2910 [1:46:42<21:25:02, 29.53s/it]09/17/2024 01:08:28 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 01:08:28 - INFO - __main__ -   start running ret%tva validation...
[h264 @ 0x55a2754aa100] mmco: unref short failure
[h264 @ 0x55a2754aa100] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e19f1f0d40] mmco: unref short failure
[h264 @ 0x55e19f1f0d40] mmco: unref short failure
09/17/2024 01:08:40 - INFO - __main__ -   current idx -Gh2S5bmJFk.26 from finetune_area returns wrong image/video, use 133852 instead.
[h264 @ 0x5606989de540] mmco: unref short failure
[h264 @ 0x55b512431d40] mmco: unref short failure
[h264 @ 0x55b512431d40] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e19cc19fc0] mmco: unref short failure
[h264 @ 0x55e19cc19fc0] mmco: unref short failure
[h264 @ 0x56068f00e380] mmco: unref short failure
[h264 @ 0x56068f00e380] mmco: unref short failure
[h264 @ 0x560697a88e40] mmco: unref short failure
[h264 @ 0x560697a88e40] mmco: unref short failure
[h264 @ 0x55a25b61ef80] mmco: unref short failure
[h264 @ 0x55b4f8bd0fc0] mmco: unref short failure
[h264 @ 0x55b4f8bd0fc0] mmco: unref short failure
09/17/2024 01:09:41 - INFO - __main__ -   current idx 1Ubj2kIiKMw.71 from finetune_area returns wrong image/video, use 105471 instead.
[h264 @ 0x56069d5b2400] mmco: unref short failure
[h264 @ 0x56069d5b2400] mmco: unref short failure
[h264 @ 0x55b4f4db5c00] mmco: unref short failure
09/17/2024 01:10:06 - INFO - __main__ -   current idx GdCloC04v0E.24 from finetune_area returns wrong image/video, use 109565 instead.
[h264 @ 0x5606a44b26c0] mmco: unref short failure
[h264 @ 0x55e1911cff40] mmco: unref short failure
[h264 @ 0x55a272baae00] mmco: unref short failure
[h264 @ 0x55a272baae00] mmco: unref short failure
[h264 @ 0x55a272baae00] mmco: unref short failure
[h264 @ 0x55a272baae00] mmco: unref short failure
[h264 @ 0x55a272d09040] mmco: unref short failure
[h264 @ 0x55a267042e40] mmco: unref short failure
[h264 @ 0x55a26c6e4c00] mmco: unref short failure
[h264 @ 0x55b4f5d8b7c0] mmco: unref short failure
[h264 @ 0x55b4f5d8b7c0] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A[h264 @ 0x5606ab4c3580] mmco: unref short failure
[h264 @ 0x5606ab4c3580] mmco: unref short failure

  0%|          | 1/221 [00:00<02:29,  1.47it/s][A
  1%|          | 2/221 [00:01<02:21,  1.55it/s][A
  1%|▏         | 3/221 [00:01<01:48,  2.01it/s][A
  2%|▏         | 4/221 [00:01<01:23,  2.61it/s][A
  2%|▏         | 5/221 [00:02<01:07,  3.18it/s][A
  3%|▎         | 6/221 [00:02<00:57,  3.74it/s][A
  3%|▎         | 7/221 [00:02<01:09,  3.07it/s][A
  4%|▎         | 8/221 [00:03<01:13,  2.89it/s][A
  4%|▍         | 9/221 [00:03<01:17,  2.73it/s][A
  5%|▍         | 10/221 [00:03<01:29,  2.37it/s][A
  5%|▍         | 11/221 [00:04<01:16,  2.73it/s][A
  5%|▌         | 12/221 [00:04<01:31,  2.27it/s][A
  6%|▌         | 13/221 [00:05<01:23,  2.48it/s][A
  6%|▋         | 14/221 [00:05<01:31,  2.26it/s][A
  7%|▋         | 15/221 [00:05<01:16,  2.68it/s][A
  7%|▋         | 16/221 [00:06<01:25,  2.40it/s][A
  8%|▊         | 17/221 [00:07<01:39,  2.04it/s][A
  8%|▊         | 18/221 [00:07<01:30,  2.23it/s][A
  9%|▊         | 19/221 [00:07<01:15,  2.68it/s][A
  9%|▉         | 20/221 [00:07<01:02,  3.23it/s][A
 10%|▉         | 21/221 [00:08<00:56,  3.56it/s][A
 10%|▉         | 22/221 [00:08<00:52,  3.80it/s][A
 10%|█         | 23/221 [00:08<00:45,  4.39it/s][A
 11%|█         | 24/221 [00:08<00:42,  4.62it/s][A
 11%|█▏        | 25/221 [00:08<00:42,  4.57it/s][A
 12%|█▏        | 26/221 [00:09<00:55,  3.53it/s][A
 12%|█▏        | 27/221 [00:09<00:45,  4.31it/s][A
 13%|█▎        | 28/221 [00:10<01:21,  2.38it/s][A
 13%|█▎        | 29/221 [00:10<01:09,  2.75it/s][A
 14%|█▎        | 30/221 [00:10<01:08,  2.80it/s][A
 14%|█▍        | 31/221 [00:11<01:10,  2.68it/s][A
 14%|█▍        | 32/221 [00:11<00:57,  3.29it/s][A
 15%|█▍        | 33/221 [00:11<00:50,  3.74it/s][A
 15%|█▌        | 34/221 [00:11<00:42,  4.42it/s][A
 16%|█▌        | 35/221 [00:11<00:47,  3.95it/s][A
 16%|█▋        | 36/221 [00:12<01:01,  3.00it/s][A
 17%|█▋        | 37/221 [00:12<01:10,  2.60it/s][A
 17%|█▋        | 38/221 [00:13<01:16,  2.40it/s][A
 18%|█▊        | 39/221 [00:13<01:00,  2.99it/s][A
 18%|█▊        | 40/221 [00:13<01:00,  3.00it/s][A
 19%|█▊        | 41/221 [00:14<00:52,  3.41it/s][A
 19%|█▉        | 42/221 [00:15<01:23,  2.15it/s][A
 19%|█▉        | 43/221 [00:15<01:08,  2.60it/s][A
 20%|█▉        | 44/221 [00:15<00:55,  3.19it/s][A
 20%|██        | 45/221 [00:16<01:13,  2.40it/s][A[h264 @ 0x55e19c321800] mmco: unref short failure
[h264 @ 0x55e19c321800] mmco: unref short failure
[h264 @ 0x55e19c321800] mmco: unref short failure

 21%|██        | 46/221 [00:16<01:22,  2.13it/s][A
 21%|██▏       | 47/221 [00:17<01:25,  2.04it/s][A
 22%|██▏       | 48/221 [00:17<01:11,  2.43it/s][A
 22%|██▏       | 49/221 [00:17<01:19,  2.17it/s][A
 23%|██▎       | 50/221 [00:18<01:17,  2.20it/s][A
 23%|██▎       | 51/221 [00:18<01:05,  2.60it/s][A
 24%|██▎       | 52/221 [00:18<01:00,  2.80it/s][A
 24%|██▍       | 53/221 [00:19<00:56,  2.95it/s][A
 24%|██▍       | 54/221 [00:19<01:15,  2.22it/s][A
 25%|██▍       | 55/221 [00:20<01:13,  2.26it/s][A
 25%|██▌       | 56/221 [00:20<01:03,  2.61it/s][A
 26%|██▌       | 57/221 [00:20<01:01,  2.68it/s][A
 26%|██▌       | 58/221 [00:21<00:49,  3.26it/s][A
 27%|██▋       | 59/221 [00:21<00:45,  3.57it/s][A
 27%|██▋       | 60/221 [00:22<01:37,  1.66it/s][A
 28%|██▊       | 61/221 [00:22<01:20,  1.99it/s][A
 28%|██▊       | 62/221 [00:23<01:16,  2.08it/s][A
 29%|██▊       | 63/221 [00:23<01:07,  2.35it/s][A
 29%|██▉       | 64/221 [00:23<01:01,  2.57it/s][A
 29%|██▉       | 65/221 [00:24<00:53,  2.89it/s][A
 30%|██▉       | 66/221 [00:24<00:54,  2.85it/s][A
 30%|███       | 67/221 [00:25<01:03,  2.43it/s][A
 31%|███       | 68/221 [00:25<00:50,  3.04it/s][A
 31%|███       | 69/221 [00:25<01:02,  2.45it/s][A[h264 @ 0x55a279094fc0] mmco: unref short failure

 32%|███▏      | 70/221 [00:26<00:53,  2.81it/s][A
 32%|███▏      | 71/221 [00:26<00:50,  2.95it/s][A
 33%|███▎      | 72/221 [00:26<00:58,  2.53it/s][A
 33%|███▎      | 73/221 [00:27<01:01,  2.42it/s][A
 33%|███▎      | 74/221 [00:27<00:51,  2.88it/s][A
 34%|███▍      | 75/221 [00:27<00:48,  2.99it/s][A
 34%|███▍      | 76/221 [00:28<00:45,  3.18it/s][A
 35%|███▍      | 77/221 [00:28<00:52,  2.76it/s][A
 35%|███▌      | 78/221 [00:28<00:45,  3.12it/s][A
 36%|███▌      | 79/221 [00:29<01:04,  2.20it/s][A
 36%|███▌      | 80/221 [00:29<00:55,  2.56it/s][A
 37%|███▋      | 81/221 [00:30<00:49,  2.83it/s][A
 37%|███▋      | 82/221 [00:30<01:05,  2.13it/s][A
 38%|███▊      | 83/221 [00:31<01:06,  2.06it/s][A
 38%|███▊      | 84/221 [00:31<01:00,  2.28it/s][A
 38%|███▊      | 85/221 [00:32<00:57,  2.37it/s][A[h264 @ 0x56069a739dc0] mmco: unref short failure
[h264 @ 0x56069a739dc0] mmco: unref short failure

 39%|███▉      | 86/221 [00:32<00:53,  2.55it/s][A
 39%|███▉      | 87/221 [00:33<01:16,  1.75it/s][A[h264 @ 0x55a25ddaab00] mmco: unref short failure

 40%|███▉      | 88/221 [00:34<01:29,  1.48it/s][A
 40%|████      | 89/221 [00:34<01:14,  1.77it/s][A
 41%|████      | 90/221 [00:34<01:03,  2.06it/s][A
 41%|████      | 91/221 [00:35<00:52,  2.47it/s][A
 42%|████▏     | 92/221 [00:35<00:51,  2.50it/s][A
 42%|████▏     | 93/221 [00:35<00:52,  2.45it/s][A
 43%|████▎     | 94/221 [00:36<00:45,  2.79it/s][A[h264 @ 0x55e186212d40] mmco: unref short failure
[h264 @ 0x55e186212d40] mmco: unref short failure
[h264 @ 0x55e186212d40] [h264 @ 0x55a26bbbba00] mmco: unref short failure
mmco: unref short failure
[h264 @ 0x55e186212d40] mmco: unref short failure

 43%|████▎     | 95/221 [00:36<00:42,  2.95it/s][A
 43%|████▎     | 96/221 [00:36<00:40,  3.06it/s][A
 44%|████▍     | 97/221 [00:36<00:35,  3.45it/s][A
 44%|████▍     | 98/221 [00:37<00:39,  3.10it/s][A
 45%|████▍     | 99/221 [00:37<00:36,  3.32it/s][A
 45%|████▌     | 100/221 [00:37<00:37,  3.23it/s][A
 46%|████▌     | 101/221 [00:38<00:37,  3.22it/s][A
 46%|████▌     | 102/221 [00:38<00:46,  2.58it/s][A
 47%|████▋     | 103/221 [00:39<00:43,  2.70it/s][A
 47%|████▋     | 104/221 [00:39<00:38,  3.04it/s][A
 48%|████▊     | 105/221 [00:39<00:40,  2.87it/s][A[h264 @ 0x5606a4b3e9c0] mmco: unref short failure

 48%|████▊     | 106/221 [00:40<01:07,  1.70it/s][A
 48%|████▊     | 107/221 [00:41<00:52,  2.16it/s][A
 49%|████▉     | 108/221 [00:41<00:45,  2.46it/s][A
 49%|████▉     | 109/221 [00:41<00:42,  2.67it/s][A
 50%|████▉     | 110/221 [00:42<00:47,  2.35it/s][A[h264 @ 0x55a2739aee80] mmco: unref short failure

 50%|█████     | 111/221 [00:42<00:54,  2.02it/s][A
 51%|█████     | 112/221 [00:43<00:44,  2.45it/s][A
 51%|█████     | 113/221 [00:43<00:45,  2.36it/s][A
 52%|█████▏    | 114/221 [00:43<00:35,  3.01it/s][A
 52%|█████▏    | 115/221 [00:43<00:28,  3.74it/s][A
 52%|█████▏    | 116/221 [00:44<00:41,  2.56it/s][A
 53%|█████▎    | 117/221 [00:44<00:44,  2.36it/s][A
 53%|█████▎    | 118/221 [00:45<00:41,  2.47it/s][A
 54%|█████▍    | 119/221 [00:45<00:47,  2.16it/s][A
 54%|█████▍    | 120/221 [00:46<00:42,  2.36it/s][A
 55%|█████▍    | 121/221 [00:46<00:33,  2.96it/s][A09/17/2024 01:11:29 - INFO - __main__ -   current idx 0mdFhko5-lk.77 from finetune_area returns wrong image/video, use 30674 instead.

 55%|█████▌    | 122/221 [00:46<00:32,  3.09it/s][A
 56%|█████▌    | 123/221 [00:46<00:28,  3.40it/s][A
 56%|█████▌    | 124/221 [00:47<00:27,  3.49it/s][A
 57%|█████▋    | 125/221 [00:47<00:34,  2.76it/s][A
 57%|█████▋    | 126/221 [00:47<00:29,  3.26it/s][A
 57%|█████▋    | 127/221 [00:48<00:40,  2.31it/s][A
 58%|█████▊    | 128/221 [00:49<00:38,  2.39it/s][A
 58%|█████▊    | 129/221 [00:49<00:31,  2.96it/s][A
 59%|█████▉    | 130/221 [00:49<00:29,  3.12it/s][A
 59%|█████▉    | 131/221 [00:49<00:25,  3.46it/s][A
 60%|█████▉    | 132/221 [00:49<00:25,  3.53it/s][A
 60%|██████    | 133/221 [00:50<00:33,  2.62it/s][A
 61%|██████    | 134/221 [00:50<00:31,  2.80it/s][A
 61%|██████    | 135/221 [00:51<00:27,  3.13it/s][A
 62%|██████▏   | 136/221 [00:51<00:29,  2.91it/s][A
 62%|██████▏   | 137/221 [00:51<00:25,  3.31it/s][A
 62%|██████▏   | 138/221 [00:52<00:31,  2.60it/s][A
 63%|██████▎   | 139/221 [00:52<00:38,  2.14it/s][A
 63%|██████▎   | 140/221 [00:53<00:35,  2.29it/s][A
 64%|██████▍   | 141/221 [00:53<00:31,  2.56it/s][A[h264 @ 0x55e1a1bd15c0] mmco: unref short failure
[h264 @ 0x55e1a1bd15c0] mmco: unref short failure
[h264 @ 0x55e1a1bd15c0] mmco: unref short failure
[h264 @ 0x55e1a1bd15c0] mmco: unref short failure

 64%|██████▍   | 142/221 [00:53<00:29,  2.68it/s][A
 65%|██████▍   | 143/221 [00:54<00:29,  2.64it/s][A
 65%|██████▌   | 144/221 [00:54<00:30,  2.56it/s][A
 66%|██████▌   | 146/221 [00:54<00:19,  3.75it/s][A
 67%|██████▋   | 147/221 [00:55<00:20,  3.69it/s][A
 67%|██████▋   | 148/221 [00:55<00:22,  3.28it/s][A
 67%|██████▋   | 149/221 [00:55<00:21,  3.29it/s][A
 68%|██████▊   | 150/221 [00:56<00:19,  3.59it/s][A
 68%|██████▊   | 151/221 [00:56<00:29,  2.39it/s][A
 69%|██████▉   | 152/221 [00:57<00:40,  1.69it/s][A
 69%|██████▉   | 153/221 [00:58<00:37,  1.83it/s][A
 70%|██████▉   | 154/221 [00:58<00:36,  1.82it/s][A
 70%|███████   | 155/221 [00:59<00:32,  2.02it/s][A
 71%|███████   | 156/221 [00:59<00:33,  1.96it/s][A
 71%|███████   | 157/221 [01:00<00:37,  1.73it/s][A
 71%|███████▏  | 158/221 [01:00<00:32,  1.94it/s][A
 72%|███████▏  | 159/221 [01:01<00:27,  2.26it/s][A
 72%|███████▏  | 160/221 [01:01<00:29,  2.04it/s][A
 73%|███████▎  | 161/221 [01:02<00:25,  2.34it/s][A
 73%|███████▎  | 162/221 [01:02<00:24,  2.46it/s][A
 74%|███████▍  | 163/221 [01:02<00:24,  2.38it/s][A
 74%|███████▍  | 164/221 [01:03<00:25,  2.26it/s][A
 75%|███████▍  | 165/221 [01:03<00:25,  2.24it/s][A
 75%|███████▌  | 166/221 [01:04<00:29,  1.89it/s][A
 76%|███████▌  | 167/221 [01:04<00:22,  2.41it/s][A
 76%|███████▌  | 168/221 [01:05<00:24,  2.21it/s][A
 76%|███████▋  | 169/221 [01:05<00:19,  2.61it/s][A
 77%|███████▋  | 170/221 [01:05<00:18,  2.70it/s][A
 77%|███████▋  | 171/221 [01:06<00:21,  2.30it/s][A
 78%|███████▊  | 172/221 [01:06<00:17,  2.85it/s][A
 78%|███████▊  | 173/221 [01:06<00:16,  2.85it/s][A
 79%|███████▊  | 174/221 [01:07<00:13,  3.43it/s][A
 79%|███████▉  | 175/221 [01:07<00:14,  3.07it/s][A
 80%|███████▉  | 176/221 [01:07<00:13,  3.28it/s][A
 80%|████████  | 177/221 [01:08<00:14,  3.03it/s][A
 81%|████████  | 178/221 [01:08<00:15,  2.79it/s][A
 81%|████████  | 179/221 [01:08<00:15,  2.65it/s][A
 81%|████████▏ | 180/221 [01:09<00:12,  3.19it/s][A
 82%|████████▏ | 181/221 [01:09<00:12,  3.28it/s][A
 82%|████████▏ | 182/221 [01:09<00:10,  3.68it/s][A
 83%|████████▎ | 183/221 [01:09<00:09,  4.05it/s][A[h264 @ 0x55e185ee56c0] mmco: unref short failure

 83%|████████▎ | 184/221 [01:10<00:10,  3.41it/s][A
 84%|████████▎ | 185/221 [01:10<00:09,  3.98it/s][A
 84%|████████▍ | 186/221 [01:10<00:08,  3.96it/s][A
 85%|████████▍ | 187/221 [01:10<00:09,  3.47it/s][A
 85%|████████▌ | 188/221 [01:11<00:09,  3.60it/s][A
 86%|████████▌ | 189/221 [01:11<00:09,  3.27it/s][A[h264 @ 0x55a26a679180] mmco: unref short failure

 86%|████████▌ | 190/221 [01:12<00:11,  2.77it/s][A
 86%|████████▋ | 191/221 [01:12<00:09,  3.20it/s][A[h264 @ 0x56069db2f240] mmco: unref short failure

 87%|████████▋ | 192/221 [01:12<00:08,  3.31it/s][A
 87%|████████▋ | 193/221 [01:12<00:06,  4.13it/s][A[h264 @ 0x55a266c94240] mmco: unref short failure
[h264 @ 0x55a266c94240] mmco: unref short failure
[h264 @ 0x55a266c94240] mmco: unref short failure
[h264 @ 0x55a266c94240] mmco: unref short failure

 88%|████████▊ | 194/221 [01:13<00:13,  2.07it/s][A
 88%|████████▊ | 195/221 [01:14<00:11,  2.28it/s][A
 89%|████████▊ | 196/221 [01:14<00:10,  2.40it/s][A[h264 @ 0x56068c6e3e00] mmco: unref short failure
[h264 @ 0x56068c6e3e00] mmco: unref short failure

 89%|████████▉ | 197/221 [01:14<00:09,  2.66it/s][A
 90%|████████▉ | 198/221 [01:15<00:08,  2.62it/s][A
 90%|█████████ | 199/221 [01:15<00:07,  2.88it/s][A
 90%|█████████ | 200/221 [01:15<00:07,  2.64it/s][A
 91%|█████████ | 201/221 [01:16<00:06,  3.07it/s][A
 91%|█████████▏| 202/221 [01:16<00:05,  3.17it/s][A[h264 @ 0x55a264890740] mmco: unref short failure

 92%|█████████▏| 203/221 [01:16<00:05,  3.15it/s][A
 92%|█████████▏| 204/221 [01:16<00:05,  3.32it/s][A
 93%|█████████▎| 205/221 [01:17<00:03,  4.02it/s][A
 93%|█████████▎| 206/221 [01:17<00:06,  2.44it/s][A
 94%|█████████▎| 207/221 [01:17<00:04,  3.06it/s][A
 94%|█████████▍| 208/221 [01:18<00:03,  3.61it/s][A
 95%|█████████▍| 209/221 [01:18<00:03,  3.64it/s][A
 95%|█████████▌| 210/221 [01:18<00:02,  4.19it/s][A
 95%|█████████▌| 211/221 [01:18<00:03,  3.32it/s][A
 96%|█████████▌| 212/221 [01:19<00:02,  3.72it/s][A
 96%|█████████▋| 213/221 [01:19<00:02,  3.75it/s][A
 97%|█████████▋| 214/221 [01:19<00:01,  3.78it/s][A
 97%|█████████▋| 215/221 [01:20<00:01,  3.19it/s][A
 98%|█████████▊| 216/221 [01:20<00:01,  2.97it/s][A
 98%|█████████▊| 217/221 [01:20<00:01,  2.81it/s][A
 99%|█████████▊| 218/221 [01:21<00:01,  2.65it/s][A
 99%|█████████▉| 219/221 [01:21<00:00,  2.97it/s][A
100%|█████████▉| 220/221 [01:22<00:00,  1.69it/s][A
100%|██████████| 221/221 [01:23<00:00,  2.00it/s][A100%|██████████| 221/221 [01:23<00:00,  2.66it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:09,  3.15it/s][A
  1%|          | 2/221 [00:00<01:08,  3.22it/s][A
  1%|▏         | 3/221 [00:00<01:06,  3.30it/s][A
  2%|▏         | 4/221 [00:01<01:10,  3.07it/s][A
  2%|▏         | 5/221 [00:01<01:11,  3.02it/s][A
  3%|▎         | 6/221 [00:01<01:10,  3.05it/s][A
  3%|▎         | 7/221 [00:02<01:08,  3.13it/s][A
  4%|▎         | 8/221 [00:02<01:06,  3.21it/s][A
  4%|▍         | 9/221 [00:02<01:05,  3.26it/s][A
  5%|▍         | 10/221 [00:03<01:04,  3.25it/s][A
  5%|▍         | 11/221 [00:03<01:03,  3.29it/s][A
  5%|▌         | 12/221 [00:03<01:03,  3.28it/s][A
  6%|▌         | 13/221 [00:04<01:03,  3.29it/s][A
  6%|▋         | 14/221 [00:04<01:02,  3.32it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.34it/s][A
  7%|▋         | 16/221 [00:04<01:01,  3.34it/s][A
  8%|▊         | 17/221 [00:05<01:00,  3.36it/s][A
  8%|▊         | 18/221 [00:05<01:00,  3.37it/s][A[h264 @ 0x55b50f279d40] mmco: unref short failure
[h264 @ 0x55b50f279d40] mmco: unref short failure
[h264 @ 0x55b50f279d40] mmco: unref short failure
[h264 @ 0x55b50f279d40] mmco: unref short failure

  9%|▊         | 19/221 [00:05<00:59,  3.38it/s][A09/17/2024 01:12:15 - INFO - __main__ -   current idx hDAA1fIvxDY.2 from finetune_area returns wrong image/video, use 96774 instead.

  9%|▉         | 20/221 [00:06<00:59,  3.37it/s][A
 10%|▉         | 21/221 [00:06<01:00,  3.32it/s][A
 10%|▉         | 22/221 [00:06<01:01,  3.26it/s][A
 10%|█         | 23/221 [00:07<01:01,  3.23it/s][A
 11%|█         | 24/221 [00:07<01:00,  3.26it/s][A
 11%|█▏        | 25/221 [00:07<01:00,  3.26it/s][A
 12%|█▏        | 26/221 [00:07<00:59,  3.27it/s][A
 12%|█▏        | 27/221 [00:08<00:59,  3.24it/s][A
 13%|█▎        | 28/221 [00:08<00:59,  3.27it/s][A
 13%|█▎        | 29/221 [00:08<00:58,  3.31it/s][A
 14%|█▎        | 30/221 [00:09<00:57,  3.33it/s][A
 14%|█▍        | 31/221 [00:09<00:56,  3.35it/s][A
 14%|█▍        | 32/221 [00:09<00:56,  3.37it/s][A
 15%|█▍        | 33/221 [00:10<00:56,  3.32it/s][A
 15%|█▌        | 34/221 [00:10<00:56,  3.29it/s][A
 16%|█▌        | 35/221 [00:10<00:56,  3.32it/s][A
 16%|█▋        | 36/221 [00:10<00:55,  3.34it/s][A
 17%|█▋        | 37/221 [00:11<00:54,  3.36it/s][A
 17%|█▋        | 38/221 [00:11<00:54,  3.37it/s][A
 18%|█▊        | 39/221 [00:11<00:54,  3.33it/s][A
 18%|█▊        | 40/221 [00:12<00:54,  3.29it/s][A
 19%|█▊        | 41/221 [00:12<00:54,  3.33it/s][A
 19%|█▉        | 42/221 [00:12<00:54,  3.30it/s][A
 19%|█▉        | 43/221 [00:13<00:54,  3.24it/s][A
 20%|█▉        | 44/221 [00:13<00:54,  3.23it/s][A
 20%|██        | 45/221 [00:13<00:53,  3.28it/s][A
 21%|██        | 46/221 [00:14<00:53,  3.28it/s][A
 21%|██▏       | 47/221 [00:14<00:52,  3.32it/s][A
 22%|██▏       | 48/221 [00:14<00:52,  3.29it/s][A
 22%|██▏       | 49/221 [00:14<00:52,  3.29it/s][A
 23%|██▎       | 50/221 [00:15<00:51,  3.32it/s][A
 23%|██▎       | 51/221 [00:15<00:52,  3.26it/s][A
 24%|██▎       | 52/221 [00:15<00:51,  3.26it/s][A
 24%|██▍       | 53/221 [00:16<00:50,  3.30it/s][A
 24%|██▍       | 54/221 [00:16<00:50,  3.29it/s][A
 25%|██▍       | 55/221 [00:16<00:50,  3.31it/s][A
 25%|██▌       | 56/221 [00:17<00:49,  3.33it/s][A
 26%|██▌       | 57/221 [00:17<00:49,  3.34it/s][A
 26%|██▌       | 58/221 [00:17<00:48,  3.36it/s][A[h264 @ 0x55b507534b00] mmco: unref short failure
[h264 @ 0x55b507534b00] mmco: unref short failure
[h264 @ 0x55b507534b00] mmco: unref short failure
[h264 @ 0x55b507534b00] mmco: unref short failure

 27%|██▋       | 59/221 [00:17<00:48,  3.36it/s][A
 27%|██▋       | 60/221 [00:18<00:47,  3.37it/s][A
 28%|██▊       | 61/221 [00:18<00:47,  3.38it/s][A
 28%|██▊       | 62/221 [00:18<00:50,  3.17it/s][A
 29%|██▊       | 63/221 [00:19<00:48,  3.23it/s][A
 29%|██▉       | 64/221 [00:19<00:48,  3.21it/s][A
 29%|██▉       | 65/221 [00:19<00:49,  3.16it/s][A
 30%|██▉       | 66/221 [00:20<00:48,  3.22it/s][A
 30%|███       | 67/221 [00:20<00:48,  3.20it/s][A
 31%|███       | 68/221 [00:20<00:46,  3.26it/s][A
 31%|███       | 69/221 [00:21<00:47,  3.22it/s][A[h264 @ 0x55a267042e40] mmco: unref short failure
[h264 @ 0x55a267042e40] mmco: unref short failure
[h264 @ 0x55a267042e40] mmco: unref short failure
[h264 @ 0x55a267042e40] mmco: unref short failure

 32%|███▏      | 70/221 [00:21<00:46,  3.24it/s][A
 32%|███▏      | 71/221 [00:21<00:45,  3.28it/s][A
 33%|███▎      | 72/221 [00:21<00:44,  3.32it/s][A
 33%|███▎      | 73/221 [00:22<00:45,  3.28it/s][A
 33%|███▎      | 74/221 [00:22<00:44,  3.31it/s][A
 34%|███▍      | 75/221 [00:22<00:43,  3.33it/s][A
 34%|███▍      | 76/221 [00:23<00:43,  3.35it/s][A
 35%|███▍      | 77/221 [00:23<00:43,  3.30it/s][A
 35%|███▌      | 78/221 [00:23<00:42,  3.33it/s][A
 36%|███▌      | 79/221 [00:24<00:42,  3.34it/s][A
 36%|███▌      | 80/221 [00:24<00:43,  3.28it/s][A
 37%|███▋      | 81/221 [00:24<00:42,  3.32it/s][A
 37%|███▋      | 82/221 [00:24<00:41,  3.32it/s][A
 38%|███▊      | 83/221 [00:25<00:41,  3.35it/s][A
 38%|███▊      | 84/221 [00:25<00:40,  3.36it/s][A
 38%|███▊      | 85/221 [00:25<00:40,  3.37it/s][A
 39%|███▉      | 86/221 [00:26<00:39,  3.38it/s][A
 39%|███▉      | 87/221 [00:26<00:39,  3.38it/s][A
 40%|███▉      | 88/221 [00:26<00:39,  3.36it/s][A
 40%|████      | 89/221 [00:27<00:39,  3.37it/s][A
 41%|████      | 90/221 [00:27<00:38,  3.38it/s][A
 41%|████      | 91/221 [00:27<00:38,  3.38it/s][A
 42%|████▏     | 92/221 [00:27<00:38,  3.39it/s][A
 42%|████▏     | 93/221 [00:28<00:37,  3.39it/s][A
 43%|████▎     | 94/221 [00:28<00:37,  3.40it/s][A
 43%|████▎     | 95/221 [00:28<00:37,  3.40it/s][A
 43%|████▎     | 96/221 [00:29<00:36,  3.40it/s][A
 44%|████▍     | 97/221 [00:29<00:36,  3.40it/s][A
 44%|████▍     | 98/221 [00:29<00:36,  3.40it/s][A
 45%|████▍     | 99/221 [00:29<00:35,  3.40it/s][A
 45%|████▌     | 100/221 [00:30<00:35,  3.40it/s][A
 46%|████▌     | 101/221 [00:30<00:35,  3.40it/s][A
 46%|████▌     | 102/221 [00:30<00:34,  3.40it/s][A
 47%|████▋     | 103/221 [00:31<00:34,  3.40it/s][A
 47%|████▋     | 104/221 [00:31<00:34,  3.40it/s][A
 48%|████▊     | 105/221 [00:31<00:34,  3.41it/s][A
 48%|████▊     | 106/221 [00:32<00:33,  3.41it/s][A
 48%|████▊     | 107/221 [00:32<00:33,  3.41it/s][A
 49%|████▉     | 108/221 [00:32<00:33,  3.41it/s][A
 49%|████▉     | 109/221 [00:32<00:32,  3.41it/s][A
 50%|████▉     | 110/221 [00:33<00:32,  3.41it/s][A
 50%|█████     | 111/221 [00:33<00:32,  3.41it/s][A
 51%|█████     | 112/221 [00:33<00:31,  3.41it/s][A
 51%|█████     | 113/221 [00:34<00:31,  3.41it/s][A
 52%|█████▏    | 114/221 [00:34<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:34<00:31,  3.42it/s][A
 52%|█████▏    | 116/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:35<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:35<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:35<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:36<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:36<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:37<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:37<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:38<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:38<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:39<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:39<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:39<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:40<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:40<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:41<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:41<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:41<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:42<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:42<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:43<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:43<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:44<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:44<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:44<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:45<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:45<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:45<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:46<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:46<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:46<00:18,  3.42it/s][A
 71%|███████   | 157/221 [00:46<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:47<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:47<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:48<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:48<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:48<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:49<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:49<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:49<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:50<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:50<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:50<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:51<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:51<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:51<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:52<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:52<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:53<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:53<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:54<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:54<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:55<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:55<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:55<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:56<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:57<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:57<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:57<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:58<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:58<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:59<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:59<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [01:00<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [01:00<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:01<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:02<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:02<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:03<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:04<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:05<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:05<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.42it/s][A100%|██████████| 221/221 [01:05<00:00,  3.37it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:26,  8.37it/s][A
  1%|          | 2/221 [00:00<01:04,  3.37it/s][A
  1%|▏         | 3/221 [00:01<01:39,  2.19it/s][A
  2%|▏         | 4/221 [00:01<01:17,  2.78it/s][A
  2%|▏         | 5/221 [00:01<01:00,  3.59it/s][A
  3%|▎         | 7/221 [00:01<00:49,  4.34it/s][A
  4%|▎         | 8/221 [00:02<00:51,  4.14it/s][A
  4%|▍         | 9/221 [00:02<00:49,  4.25it/s][A
  5%|▍         | 10/221 [00:02<00:56,  3.75it/s][A
  5%|▍         | 11/221 [00:02<00:51,  4.06it/s][A
  5%|▌         | 12/221 [00:03<00:47,  4.42it/s][A
  6%|▌         | 13/221 [00:03<01:22,  2.52it/s][A
  6%|▋         | 14/221 [00:04<01:04,  3.20it/s][A
  7%|▋         | 15/221 [00:04<01:04,  3.17it/s][A
  7%|▋         | 16/221 [00:04<01:08,  3.01it/s][A
  8%|▊         | 17/221 [00:05<01:13,  2.79it/s][A
  8%|▊         | 18/221 [00:05<01:11,  2.83it/s][A
  9%|▊         | 19/221 [00:05<01:01,  3.30it/s][A
  9%|▉         | 20/221 [00:06<01:03,  3.15it/s][A
 10%|▉         | 21/221 [00:06<00:54,  3.68it/s][A
 10%|▉         | 22/221 [00:06<00:49,  3.98it/s][A
 10%|█         | 23/221 [00:06<00:41,  4.78it/s][A
 11%|█         | 24/221 [00:06<00:38,  5.12it/s][A
 11%|█▏        | 25/221 [00:06<00:41,  4.70it/s][A
 12%|█▏        | 26/221 [00:07<00:46,  4.22it/s][A
 12%|█▏        | 27/221 [00:07<00:46,  4.22it/s][A
 13%|█▎        | 28/221 [00:07<00:56,  3.41it/s][A
 13%|█▎        | 29/221 [00:08<00:59,  3.23it/s][A
 14%|█▎        | 30/221 [00:08<00:54,  3.49it/s][A
 14%|█▍        | 31/221 [00:08<00:59,  3.19it/s][A
 14%|█▍        | 32/221 [00:08<00:49,  3.78it/s][A
 15%|█▍        | 33/221 [00:09<00:47,  3.96it/s][A
 15%|█▌        | 34/221 [00:09<00:46,  4.03it/s][A
 16%|█▌        | 35/221 [00:09<00:48,  3.86it/s][A
 16%|█▋        | 36/221 [00:10<01:05,  2.82it/s][A
 17%|█▋        | 37/221 [00:10<00:59,  3.12it/s][A
 17%|█▋        | 38/221 [00:10<00:55,  3.31it/s][A
 18%|█▊        | 40/221 [00:11<00:48,  3.72it/s][A
 19%|█▊        | 41/221 [00:11<00:44,  4.02it/s][A
 19%|█▉        | 42/221 [00:11<00:40,  4.38it/s][A
 19%|█▉        | 43/221 [00:12<00:49,  3.63it/s][A
 20%|█▉        | 44/221 [00:12<00:44,  3.95it/s][A
 20%|██        | 45/221 [00:12<00:51,  3.44it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.79it/s][A
 22%|██▏       | 48/221 [00:12<00:30,  5.60it/s][A
 22%|██▏       | 49/221 [00:13<00:29,  5.89it/s][A
 23%|██▎       | 50/221 [00:13<00:34,  4.96it/s][A
 23%|██▎       | 51/221 [00:13<00:42,  4.04it/s][A
 24%|██▎       | 52/221 [00:13<00:35,  4.76it/s][A
 24%|██▍       | 53/221 [00:14<00:34,  4.94it/s][A
 24%|██▍       | 54/221 [00:14<00:33,  4.96it/s][A
 25%|██▍       | 55/221 [00:14<00:31,  5.25it/s][A
 25%|██▌       | 56/221 [00:14<00:33,  4.87it/s][A
 26%|██▌       | 57/221 [00:15<00:40,  4.07it/s][A
 26%|██▌       | 58/221 [00:15<00:33,  4.83it/s][A
 27%|██▋       | 59/221 [00:15<00:35,  4.52it/s][A
 27%|██▋       | 60/221 [00:15<00:36,  4.42it/s][A
 28%|██▊       | 61/221 [00:15<00:34,  4.58it/s][A
 28%|██▊       | 62/221 [00:16<00:35,  4.49it/s][A
 29%|██▊       | 63/221 [00:16<00:31,  4.98it/s][A
 29%|██▉       | 64/221 [00:16<00:32,  4.77it/s][A
 29%|██▉       | 65/221 [00:16<00:28,  5.56it/s][A
 30%|██▉       | 66/221 [00:16<00:30,  5.05it/s][A
 30%|███       | 67/221 [00:17<00:45,  3.38it/s][A
 31%|███       | 68/221 [00:17<00:41,  3.71it/s][A
 31%|███       | 69/221 [00:17<00:43,  3.52it/s][A
 32%|███▏      | 70/221 [00:17<00:36,  4.14it/s][A
 32%|███▏      | 71/221 [00:18<00:41,  3.58it/s][A
 33%|███▎      | 72/221 [00:18<00:50,  2.93it/s][A
 33%|███▎      | 73/221 [00:19<00:48,  3.02it/s][A
 33%|███▎      | 74/221 [00:19<00:46,  3.19it/s][A
 34%|███▍      | 75/221 [00:19<00:51,  2.86it/s][A
 34%|███▍      | 76/221 [00:19<00:40,  3.56it/s][A
 35%|███▍      | 77/221 [00:20<00:40,  3.56it/s][A
 35%|███▌      | 78/221 [00:20<00:38,  3.76it/s][A
 36%|███▌      | 79/221 [00:20<00:39,  3.56it/s][A
 36%|███▌      | 80/221 [00:21<00:40,  3.52it/s][A
 37%|███▋      | 81/221 [00:21<00:41,  3.35it/s][A
 37%|███▋      | 82/221 [00:21<00:40,  3.42it/s][A
 38%|███▊      | 83/221 [00:21<00:35,  3.87it/s][A
 38%|███▊      | 84/221 [00:22<00:35,  3.91it/s][A
 38%|███▊      | 85/221 [00:22<00:40,  3.34it/s][A
 39%|███▉      | 86/221 [00:22<00:36,  3.67it/s][A
 39%|███▉      | 87/221 [00:23<00:52,  2.54it/s][A
 40%|███▉      | 88/221 [00:23<00:43,  3.06it/s][A
 40%|████      | 89/221 [00:23<00:43,  3.00it/s][A
 41%|████      | 90/221 [00:24<00:46,  2.84it/s][A
 41%|████      | 91/221 [00:24<00:40,  3.19it/s][A
 42%|████▏     | 92/221 [00:24<00:36,  3.50it/s][A
 42%|████▏     | 93/221 [00:25<00:37,  3.40it/s][A
 43%|████▎     | 94/221 [00:25<00:36,  3.48it/s][A
 43%|████▎     | 95/221 [00:25<00:47,  2.64it/s][A
 43%|████▎     | 96/221 [00:26<00:42,  2.91it/s][A
 44%|████▍     | 97/221 [00:26<00:41,  3.01it/s][A
 44%|████▍     | 98/221 [00:26<00:41,  2.99it/s][A
 45%|████▍     | 99/221 [00:27<00:35,  3.48it/s][A
 45%|████▌     | 100/221 [00:27<00:28,  4.22it/s][A
 46%|████▌     | 101/221 [00:27<00:36,  3.26it/s][A
 46%|████▌     | 102/221 [00:27<00:32,  3.68it/s][A
 47%|████▋     | 103/221 [00:28<00:29,  3.95it/s][A
 47%|████▋     | 104/221 [00:28<00:24,  4.75it/s][A
 48%|████▊     | 105/221 [00:28<00:25,  4.57it/s][A
 48%|████▊     | 106/221 [00:28<00:33,  3.38it/s][A
 48%|████▊     | 107/221 [00:29<00:29,  3.81it/s][A
 49%|████▉     | 108/221 [00:29<00:27,  4.09it/s][A
 49%|████▉     | 109/221 [00:29<00:30,  3.65it/s][A
 50%|████▉     | 110/221 [00:29<00:33,  3.36it/s][A
 50%|█████     | 111/221 [00:30<00:31,  3.50it/s][A
 51%|█████     | 112/221 [00:30<00:29,  3.64it/s][A
 51%|█████     | 113/221 [00:30<00:26,  4.04it/s][A
 52%|█████▏    | 115/221 [00:30<00:21,  5.03it/s][A
 52%|█████▏    | 116/221 [00:31<00:20,  5.19it/s][A
 53%|█████▎    | 117/221 [00:31<00:22,  4.65it/s][A
 53%|█████▎    | 118/221 [00:31<00:27,  3.75it/s][A
 54%|█████▍    | 119/221 [00:32<00:34,  2.97it/s][A
 54%|█████▍    | 120/221 [00:32<00:32,  3.09it/s][A
 55%|█████▍    | 121/221 [00:32<00:27,  3.70it/s][A
 55%|█████▌    | 122/221 [00:32<00:25,  3.82it/s][A
 56%|█████▌    | 123/221 [00:33<00:25,  3.82it/s][A
 56%|█████▌    | 124/221 [00:33<00:29,  3.31it/s][A
 57%|█████▋    | 125/221 [00:34<00:42,  2.27it/s][A
 57%|█████▋    | 126/221 [00:34<00:34,  2.74it/s][A
 57%|█████▋    | 127/221 [00:35<00:43,  2.18it/s][A
 58%|█████▊    | 128/221 [00:35<00:36,  2.55it/s][A
 58%|█████▊    | 129/221 [00:35<00:28,  3.26it/s][A
 59%|█████▉    | 130/221 [00:35<00:24,  3.64it/s][A
 59%|█████▉    | 131/221 [00:36<00:25,  3.60it/s][A
 60%|█████▉    | 132/221 [00:36<00:32,  2.75it/s][A
 60%|██████    | 133/221 [00:37<00:34,  2.52it/s][A
 61%|██████    | 134/221 [00:37<00:35,  2.47it/s][A
 62%|██████▏   | 136/221 [00:37<00:26,  3.17it/s][A
 62%|██████▏   | 137/221 [00:38<00:24,  3.40it/s][A
 62%|██████▏   | 138/221 [00:38<00:23,  3.47it/s][A
 63%|██████▎   | 139/221 [00:38<00:24,  3.33it/s][A
 63%|██████▎   | 140/221 [00:39<00:22,  3.58it/s][A
 64%|██████▍   | 141/221 [00:39<00:21,  3.76it/s][A
 64%|██████▍   | 142/221 [00:39<00:20,  3.88it/s][A
 65%|██████▍   | 143/221 [00:39<00:19,  3.99it/s][A
 65%|██████▌   | 144/221 [00:40<00:20,  3.70it/s][A
 66%|██████▌   | 145/221 [00:40<00:22,  3.33it/s][A
 66%|██████▌   | 146/221 [00:40<00:23,  3.22it/s][A
 67%|██████▋   | 147/221 [00:40<00:21,  3.49it/s][A
 67%|██████▋   | 148/221 [00:41<00:22,  3.32it/s][A
 67%|██████▋   | 149/221 [00:41<00:20,  3.48it/s][A
 68%|██████▊   | 150/221 [00:41<00:21,  3.32it/s][A
 68%|██████▊   | 151/221 [00:42<00:37,  1.84it/s][A
 69%|██████▉   | 152/221 [00:43<00:42,  1.64it/s][A
 69%|██████▉   | 153/221 [00:43<00:33,  2.02it/s][A
 70%|██████▉   | 154/221 [00:44<00:27,  2.43it/s][A
 70%|███████   | 155/221 [00:44<00:27,  2.36it/s][A
 71%|███████   | 156/221 [00:44<00:25,  2.52it/s][A
 71%|███████   | 157/221 [00:45<00:23,  2.78it/s][A
 71%|███████▏  | 158/221 [00:45<00:25,  2.48it/s][A
 72%|███████▏  | 159/221 [00:45<00:20,  3.07it/s][A
 72%|███████▏  | 160/221 [00:46<00:21,  2.84it/s][A
 73%|███████▎  | 161/221 [00:46<00:17,  3.36it/s][A
 73%|███████▎  | 162/221 [00:46<00:14,  3.99it/s][A
 74%|███████▍  | 163/221 [00:46<00:13,  4.15it/s][A
 74%|███████▍  | 164/221 [00:46<00:12,  4.73it/s][A
 75%|███████▍  | 165/221 [00:47<00:10,  5.47it/s][A
 75%|███████▌  | 166/221 [00:47<00:13,  4.11it/s][A
 76%|███████▌  | 167/221 [00:47<00:11,  4.72it/s][A
 76%|███████▌  | 168/221 [00:47<00:11,  4.64it/s][A
 76%|███████▋  | 169/221 [00:47<00:09,  5.23it/s][A
 77%|███████▋  | 170/221 [00:48<00:14,  3.50it/s][A
 77%|███████▋  | 171/221 [00:49<00:18,  2.70it/s][A
 78%|███████▊  | 172/221 [00:49<00:15,  3.20it/s][A
 78%|███████▊  | 173/221 [00:49<00:14,  3.39it/s][A
 79%|███████▉  | 175/221 [00:49<00:11,  4.15it/s][A
 80%|███████▉  | 176/221 [00:50<00:10,  4.40it/s][A
 80%|████████  | 177/221 [00:50<00:10,  4.23it/s][A
 81%|████████  | 178/221 [00:50<00:13,  3.07it/s][A
 81%|████████  | 179/221 [00:51<00:13,  3.10it/s][A
 82%|████████▏ | 181/221 [00:51<00:09,  4.00it/s][A
 82%|████████▏ | 182/221 [00:51<00:09,  3.92it/s][A
 83%|████████▎ | 183/221 [00:52<00:10,  3.59it/s][A
 83%|████████▎ | 184/221 [00:52<00:10,  3.57it/s][A
 84%|████████▎ | 185/221 [00:52<00:08,  4.01it/s][A
 84%|████████▍ | 186/221 [00:52<00:09,  3.72it/s][A
 85%|████████▍ | 187/221 [00:53<00:09,  3.76it/s][A
 85%|████████▌ | 188/221 [00:53<00:09,  3.54it/s][A
 86%|████████▌ | 189/221 [00:53<00:08,  3.97it/s][A
 86%|████████▌ | 190/221 [00:54<00:10,  3.03it/s][A
 86%|████████▋ | 191/221 [00:54<00:08,  3.68it/s][A
 87%|████████▋ | 192/221 [00:54<00:07,  3.81it/s][A
 87%|████████▋ | 193/221 [00:54<00:06,  4.10it/s][A
 88%|████████▊ | 194/221 [00:55<00:08,  3.20it/s][A
 88%|████████▊ | 195/221 [00:55<00:06,  3.85it/s][A
 89%|████████▊ | 196/221 [00:55<00:08,  2.86it/s][A
 89%|████████▉ | 197/221 [00:56<00:09,  2.64it/s][A
 90%|████████▉ | 198/221 [00:56<00:08,  2.73it/s][A
 90%|█████████ | 199/221 [00:56<00:06,  3.37it/s][A
 90%|█████████ | 200/221 [00:57<00:06,  3.27it/s][A
 91%|█████████ | 201/221 [00:57<00:05,  3.67it/s][A
 91%|█████████▏| 202/221 [00:57<00:04,  4.30it/s][A
 92%|█████████▏| 203/221 [00:57<00:04,  4.09it/s][A
 92%|█████████▏| 204/221 [00:57<00:03,  4.27it/s][A
 93%|█████████▎| 205/221 [00:58<00:04,  3.84it/s][A
 93%|█████████▎| 206/221 [00:58<00:05,  2.86it/s][A
 94%|█████████▎| 207/221 [00:59<00:04,  3.28it/s][A
 94%|█████████▍| 208/221 [00:59<00:03,  3.44it/s][A
 95%|█████████▍| 209/221 [00:59<00:03,  3.25it/s][A
 95%|█████████▌| 210/221 [00:59<00:02,  3.98it/s][A
 95%|█████████▌| 211/221 [01:00<00:02,  4.08it/s][A
 96%|█████████▌| 212/221 [01:00<00:02,  3.17it/s][A
 96%|█████████▋| 213/221 [01:00<00:02,  3.15it/s][A
 97%|█████████▋| 214/221 [01:01<00:02,  3.25it/s][A
 97%|█████████▋| 215/221 [01:01<00:01,  3.20it/s][A
 98%|█████████▊| 216/221 [01:01<00:01,  3.14it/s][A
 98%|█████████▊| 217/221 [01:02<00:01,  3.15it/s][A
 99%|█████████▊| 218/221 [01:02<00:00,  3.10it/s][A
 99%|█████████▉| 219/221 [01:02<00:00,  3.05it/s][A
100%|█████████▉| 220/221 [01:02<00:00,  3.67it/s][A
100%|██████████| 221/221 [01:03<00:00,  3.05it/s][A100%|██████████| 221/221 [01:03<00:00,  3.49it/s]
09/17/2024 01:14:23 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 299--===========

09/17/2024 01:14:23 - INFO - __main__ -   {'area_r1': 40.4, 'area_recall': '40.4/67.5/75.6', 'area_ravg': 61.2}
09/17/2024 01:14:23 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 299--===========

09/17/2024 01:14:23 - INFO - __main__ -   {'forward_r1': 36.3, 'forward_recall': '36.3/62.7/72.9', 'forward_ravg': 57.3}
09/17/2024 01:14:23 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 299--===========

09/17/2024 01:14:23 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 01:14:23 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 299=======

09/17/2024 01:14:23 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 01:14:23 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 299--===========

09/17/2024 01:14:23 - INFO - __main__ -   {'area_video_r1': 51.9, 'area_video_recall': '51.9/74.3/82.1', 'area_video_ravg': 69.5, 'area_video_back_r1': 49.1, 'area_video_back_recall': '49.1/73.2/81.7', 'area_video_back_ravg': 68.0}
09/17/2024 01:14:23 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 299=======

09/17/2024 01:14:23 - INFO - __main__ -   {'area_video_r1': 51.9, 'area_video_recall': '51.9/74.3/82.1', 'area_video_ravg': 69.5, 'area_video_back_r1': 49.1, 'area_video_back_recall': '49.1/73.2/81.7', 'area_video_back_ravg': 68.0}
09/17/2024 01:14:23 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 299--===========

09/17/2024 01:14:23 - INFO - __main__ -   {'video_r1': 35.9, 'video_recall': '35.9/65.0/73.6', 'video_ravg': 58.2}
09/17/2024 01:14:23 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 249=======

09/17/2024 01:14:23 - INFO - __main__ -   {'video_r1': 37.1, 'video_recall': '37.1/65.0/74.1', 'video_ravg': 58.7}
09/17/2024 01:14:23 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 299--===========

09/17/2024 01:14:23 - INFO - __main__ -   {'video_r1': 51.8, 'video_recall': '51.8/75.0/82.5', 'video_ravg': 69.8}
09/17/2024 01:14:23 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 299=======

09/17/2024 01:14:23 - INFO - __main__ -   {'video_r1': 51.8, 'video_recall': '51.8/75.0/82.5', 'video_ravg': 69.8}
09/17/2024 01:14:57 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.011156119406223297, 'loss_ret%tv%ta--finetune_area/loss_area': 1.6636534929275513, 'loss_ret%tv%ta--finetune_area/total_loss': 1.6748095750808716}
 10%|█         | 300/2910 [1:53:14<100:19:10, 138.37s/it][h264 @ 0x55b511552b00] mmco: unref short failure
[h264 @ 0x55b511552b00] mmco: unref short failure
[h264 @ 0x55b511552b00] mmco: unref short failure
[h264 @ 0x55b511552b00] mmco: unref short failure
 10%|█         | 301/2910 [1:53:17<70:56:49, 97.90s/it]  [h264 @ 0x55b50eed1780] mmco: unref short failure
 10%|█         | 302/2910 [1:53:22<50:31:50, 69.75s/it][h264 @ 0x55b5017ac580] mmco: unref short failure
[h264 @ 0x56068fc3c140] mmco: unref short failure
[h264 @ 0x56068fc3c140] mmco: unref short failure
 10%|█         | 303/2910 [1:53:26<36:19:34, 50.16s/it][h264 @ 0x55a2796d0880] mmco: unref short failure
[h264 @ 0x55a2796d0880] mmco: unref short failure
 10%|█         | 304/2910 [1:53:31<26:29:53, 36.61s/it] 10%|█         | 305/2910 [1:53:35<19:31:04, 26.97s/it][h264 @ 0x55a27a1b3d00] mmco: unref short failure
[h264 @ 0x55a27a1b3d00] mmco: unref short failure
[h264 @ 0x55a27a1b3d00] mmco: unref short failure
[h264 @ 0x55a27a1b3d00] mmco: unref short failure
[h264 @ 0x55a260301e40] mmco: unref short failure
[h264 @ 0x55e1a1bd17c0] mmco: unref short failure
[h264 @ 0x55e1a1bd17c0] mmco: unref short failure
 11%|█         | 306/2910 [1:53:41<14:45:59, 20.41s/it][h264 @ 0x55e1967091c0] mmco: unref short failure
 11%|█         | 307/2910 [1:53:46<11:24:20, 15.77s/it]09/17/2024 01:15:34 - INFO - __main__ -   current idx KPOxRziYDzs.2 from finetune_area returns wrong image/video, use 119381 instead.
[h264 @ 0x56069409a180] mmco: unref short failure
[h264 @ 0x56069409a180] mmco: unref short failure
 11%|█         | 308/2910 [1:53:51<9:05:11, 12.57s/it] [h264 @ 0x560690631b00] mmco: unref short failure
[h264 @ 0x560690631b00] mmco: unref short failure
[h264 @ 0x560690631b00] mmco: unref short failure
[h264 @ 0x560690631b00] mmco: unref short failure
[h264 @ 0x560690631b00] mmco: unref short failure
[h264 @ 0x560690631b00] mmco: unref short failure
[h264 @ 0x560690631b00] mmco: unref short failure
[h264 @ 0x560690631b00] mmco: unref short failure
 11%|█         | 309/2910 [1:53:57<7:37:38, 10.56s/it][h264 @ 0x55b4f39caf80] mmco: unref short failure
[h264 @ 0x55b4f39caf80] mmco: unref short failure
 11%|█         | 310/2910 [1:54:02<6:32:46,  9.06s/it][h264 @ 0x55b50f2f8700] mmco: unref short failure
 11%|█         | 311/2910 [1:54:07<5:43:56,  7.94s/it] 11%|█         | 312/2910 [1:54:13<5:11:01,  7.18s/it] 11%|█         | 313/2910 [1:54:18<4:48:27,  6.66s/it] 11%|█         | 314/2910 [1:54:24<4:32:05,  6.29s/it] 11%|█         | 315/2910 [1:54:29<4:25:19,  6.13s/it][h264 @ 0x55b4fa182800] mmco: unref short failure
[h264 @ 0x55b4fa182800] mmco: unref short failure
[h264 @ 0x55b4fa182800] mmco: unref short failure
[h264 @ 0x56068dcf7f00] mmco: unref short failure
[h264 @ 0x56068dcf7f00] mmco: unref short failure
[h264 @ 0x5606abe77b40] mmco: unref short failure
[h264 @ 0x5606abe77b40] mmco: unref short failure
[h264 @ 0x5606abe77b40] mmco: unref short failure
[h264 @ 0x5606abe77b40] mmco: unref short failure
[h264 @ 0x55b511724980] mmco: unref short failure
[h264 @ 0x55b511724980] mmco: unref short failure
[h264 @ 0x56069d005e00] mmco: unref short failure
[h264 @ 0x560696456440] mmco: unref short failure
[h264 @ 0x560696456440] mmco: unref short failure
[h264 @ 0x55e1a3d7ae00] mmco: unref short failure
[h264 @ 0x55e1a3d7ae00] mmco: unref short failure
[h264 @ 0x55b4f47d7f80] mmco: unref short failure
[h264 @ 0x55b4f47d7f80] mmco: unref short failure
[h264 @ 0x55a27a1cb200] mmco: unref short failure
[h264 @ 0x55a27a1cb200] mmco: unref short failure
[h264 @ 0x55a273664b40] mmco: unref short failure
[h264 @ 0x55a273664b40] mmco: unref short failure
[h264 @ 0x55a273664b40] mmco: unref short failure
[h264 @ 0x55a273664b40] mmco: unref short failure
 11%|█         | 316/2910 [1:55:24<14:51:07, 20.61s/it] 11%|█         | 317/2910 [1:55:35<12:53:40, 17.90s/it][h264 @ 0x560689e15c80] mmco: unref short failure
 11%|█         | 318/2910 [1:55:43<10:40:26, 14.83s/it][h264 @ 0x55a263466100] mmco: unref short failure
[h264 @ 0x55a263466100] mmco: unref short failure
09/17/2024 01:17:31 - INFO - __main__ -   current idx QRr-nFmU9s8.3 from finetune_area returns wrong image/video, use 113549 instead.
[h264 @ 0x55a2772c2f40] mmco: unref short failure
[h264 @ 0x55a2772c2f40] mmco: unref short failure
 11%|█         | 319/2910 [1:55:56<10:21:51, 14.40s/it][h264 @ 0x56068c313580] mmco: unref short failure
[h264 @ 0x56068c313580] mmco: unref short failure
[h264 @ 0x56069bf7fd00] mmco: unref short failure
[h264 @ 0x56069bf7fd00] mmco: unref short failure
 11%|█         | 320/2910 [1:56:02<8:27:25, 11.76s/it] 09/17/2024 01:17:53 - INFO - __main__ -   current idx 9lm2wYzoyd4.69 from finetune_area returns wrong image/video, use 76286 instead.
[h264 @ 0x55b5151a7f00] mmco: unref short failure
[h264 @ 0x55b5151a7f00] mmco: unref short failure
[h264 @ 0x55b5151a7f00] mmco: unref short failure
[h264 @ 0x55b5151a7f00] mmco: unref short failure
[h264 @ 0x55b5151a7f00] mmco: unref short failure
[h264 @ 0x55b5151a7f00] mmco: unref short failure
[h264 @ 0x55a26d927780] mmco: unref short failure
[h264 @ 0x5606a4dfbcc0] mmco: unref short failure
[h264 @ 0x5606a4dfbcc0] mmco: unref short failure
[h264 @ 0x55b50ca2f640] mmco: unref short failure
[h264 @ 0x55b50ca2f640] mmco: unref short failure
[h264 @ 0x55b4f80f4080] mmco: unref short failure
 11%|█         | 321/2910 [1:56:20<9:52:52, 13.74s/it][h264 @ 0x5606aa8a8100] mmco: unref short failure
[h264 @ 0x55e182e4ab00] mmco: unref short failure
[h264 @ 0x55e182e4ab00] mmco: unref short failure
 11%|█         | 322/2910 [1:56:26<8:03:14, 11.20s/it][h264 @ 0x55b4ffee8b40] mmco: unref short failure
09/17/2024 01:18:16 - INFO - __main__ -   current idx U2DBfiveIQ0.26 from finetune_area returns wrong image/video, use 128011 instead.
 11%|█         | 323/2910 [1:56:31<6:43:03,  9.35s/it][h264 @ 0x55a27722ce80] mmco: unref short failure
[h264 @ 0x55a27722ce80] mmco: unref short failure
[h264 @ 0x56068d8decc0] mmco: unref short failure
[h264 @ 0x56068d8decc0] mmco: unref short failure
[h264 @ 0x56068d8decc0] mmco: unref short failure
[h264 @ 0x56068d8decc0] mmco: unref short failure
[h264 @ 0x55e19ea40300] mmco: unref short failure
[h264 @ 0x55e19ea40300] mmco: unref short failure
[h264 @ 0x55e19ea40300] mmco: unref short failure
[h264 @ 0x55e19ea40300] mmco: unref short failure
[h264 @ 0x55e19ea40300] mmco: unref short failure
[h264 @ 0x55e19ea40300] mmco: unref short failure
[h264 @ 0x55b51344ff40] mmco: unref short failure
[h264 @ 0x55e18316e440] mmco: unref short failure
[h264 @ 0x55a25e1d3140] mmco: unref short failure
[h264 @ 0x55a25e1d3140] mmco: unref short failure
[h264 @ 0x55a25e1d3140] mmco: unref short failure
[h264 @ 0x55a25e1d3140] mmco: unref short failure
[h264 @ 0x55b50461fcc0] mmco: unref short failure
[h264 @ 0x55b50461fcc0] mmco: unref short failure
[h264 @ 0x55a25e1d3140] mmco: unref short failure
[h264 @ 0x55a25e1d3140] mmco: unref short failure
[h264 @ 0x55a25e1d3140] mmco: unref short failure
[h264 @ 0x55a25e1d3140] mmco: unref short failure
09/17/2024 01:19:04 - INFO - __main__ -   current idx gVhwSbu4UfU.1 from finetune_area returns wrong image/video, use 132935 instead.
[h264 @ 0x55a278e88300] mmco: unref short failure
[h264 @ 0x55a2796dd2c0] mmco: unref short failure
[h264 @ 0x55b50d522b40] mmco: unref short failure
[h264 @ 0x55b50d522b40] mmco: unref short failure
[h264 @ 0x55e1a22561c0] mmco: unref short failure
[h264 @ 0x55b4ffe19ec0] mmco: unref short failure
[h264 @ 0x55a26e758d00] mmco: unref short failure
[h264 @ 0x55a26e758d00] mmco: unref short failure
[h264 @ 0x55a26e758d00] mmco: unref short failure
[h264 @ 0x55a26e758d00] mmco: unref short failure
 11%|█         | 324/2910 [1:57:50<21:52:04, 30.44s/it][h264 @ 0x55b50a057940] mmco: unref short failure
[h264 @ 0x55b50a057940] mmco: unref short failure
[h264 @ 0x55b50461fcc0] mmco: unref short failure
[h264 @ 0x55b50461fcc0] mmco: unref short failure
[h264 @ 0x55e18e154300] mmco: unref short failure
[h264 @ 0x55e18e154300] mmco: unref short failure
[h264 @ 0x55e18e154300] mmco: unref short failure
[h264 @ 0x55e18e154300] mmco: unref short failure
[h264 @ 0x55b4f49fd0c0] mmco: unref short failure
[h264 @ 0x55b4f49fd0c0] mmco: unref short failure
[h264 @ 0x55a270b84200] mmco: unref short failure
[h264 @ 0x55a270b84200] mmco: unref short failure
 11%|█         | 325/2910 [1:58:07<18:55:19, 26.35s/it][h264 @ 0x55b4fd888b80] mmco: unref short failure
[h264 @ 0x55b4fd888b80] mmco: unref short failure
[h264 @ 0x55b4fbe0ef80] mmco: unref short failure
 11%|█         | 326/2910 [1:58:21<16:13:57, 22.62s/it][h264 @ 0x5606ac990a80] mmco: unref short failure
[h264 @ 0x55e18b781800] mmco: unref short failure
[h264 @ 0x55a25c479bc0] mmco: unref short failure
[h264 @ 0x55b50854f180] mmco: unref short failure
[h264 @ 0x55b50854f180] mmco: unref short failure
 11%|█         | 327/2910 [1:58:51<17:53:51, 24.94s/it][h264 @ 0x55e188848c40] mmco: unref short failure
[h264 @ 0x55e188848c40] mmco: unref short failure
[h264 @ 0x55e188848c40] mmco: unref short failure
[h264 @ 0x55e188848c40] mmco: unref short failure
[h264 @ 0x55e188848c40] mmco: unref short failure
[h264 @ 0x55e188848c40] mmco: unref short failure
09/17/2024 01:20:42 - INFO - __main__ -   current idx _4-lJ7UF30Y.22 from finetune_area returns wrong image/video, use 148252 instead.
 11%|█▏        | 328/2910 [1:58:57<13:42:01, 19.10s/it][h264 @ 0x5606a7bd7cc0] mmco: unref short failure
[h264 @ 0x5606a7bd7cc0] mmco: unref short failure
 11%|█▏        | 329/2910 [1:59:04<11:01:54, 15.39s/it][h264 @ 0x55a26546cc80] mmco: unref short failure
[h264 @ 0x55a26546cc80] mmco: unref short failure
[h264 @ 0x55a26546cc80] mmco: unref short failure
[h264 @ 0x55a26546cc80] mmco: unref short failure
[h264 @ 0x55b5026fa480] mmco: unref short failure
[h264 @ 0x55b5026fa480] mmco: unref short failure
 11%|█▏        | 330/2910 [1:59:09<8:48:25, 12.29s/it] [h264 @ 0x55a26701c680] mmco: unref short failure
[h264 @ 0x55a26701c680] mmco: unref short failure
[h264 @ 0x55a26701c680] mmco: unref short failure
[h264 @ 0x55a26701c680] mmco: unref short failure
 11%|█▏        | 331/2910 [1:59:15<7:26:50, 10.40s/it][h264 @ 0x56069cb2d9c0] mmco: unref short failure
[h264 @ 0x56069cb2d9c0] mmco: unref short failure
[h264 @ 0x55b513d1f380] mmco: unref short failure
[h264 @ 0x55b513d1f380] mmco: unref short failure
[h264 @ 0x55b50d522b40] mmco: unref short failure
[h264 @ 0x55e1813dcb40] mmco: unref short failure
[h264 @ 0x55e1813dcb40] mmco: unref short failure
[h264 @ 0x55a278ac3600] mmco: unref short failure
[h264 @ 0x55e19c42c100] mmco: unref short failure
[h264 @ 0x55e19c42c100] mmco: unref short failure
09/17/2024 01:21:37 - INFO - __main__ -   current idx NplowkZTvc0.7 from finetune_area returns wrong image/video, use 60065 instead.
[h264 @ 0x5606abe77940] mmco: unref short failure
[h264 @ 0x55b4f82f15c0] mmco: unref short failure
[h264 @ 0x55b4f82f15c0] mmco: unref short failure
[h264 @ 0x56068fa19d80] mmco: unref short failure
[h264 @ 0x56068fa19d80] mmco: unref short failure
09/17/2024 01:21:46 - INFO - __main__ -   current idx MuqZDGESIMY.30 from finetune_area returns wrong image/video, use 101214 instead.
 11%|█▏        | 332/2910 [2:00:21<19:31:31, 27.27s/it][h264 @ 0x55a2625f7e80] mmco: unref short failure
[h264 @ 0x55a2625f7e80] mmco: unref short failure
[h264 @ 0x55a25d1a2940] mmco: unref short failure
[h264 @ 0x55a25d1a2940] mmco: unref short failure
[h264 @ 0x55e199e34500] mmco: unref short failure
[h264 @ 0x55a25ca330c0] mmco: unref short failure
[h264 @ 0x5606ac07e400] mmco: unref short failure
[h264 @ 0x5606ac07e400] mmco: unref short failure
[h264 @ 0x5606ac07e400] mmco: unref short failure
[h264 @ 0x5606ac07e400] mmco: unref short failure
[h264 @ 0x55e18888d480] mmco: unref short failure
[h264 @ 0x55e18888d480] mmco: unref short failure
[h264 @ 0x55b50a32de40] mmco: unref short failure
[h264 @ 0x55b50a32de40] mmco: unref short failure
 11%|█▏        | 333/2910 [2:00:43<18:14:02, 25.47s/it][h264 @ 0x56069d005e00] mmco: unref short failure
[h264 @ 0x56069d005e00] mmco: unref short failure
 11%|█▏        | 334/2910 [2:01:02<16:56:42, 23.68s/it][h264 @ 0x55a27374dc00] mmco: unref short failure
[h264 @ 0x55a27374dc00] mmco: unref short failure
[h264 @ 0x55a272ea79c0] mmco: unref short failure
[h264 @ 0x55a2708e0b00] mmco: unref short failure
[h264 @ 0x55a2708e0b00] mmco: unref short failure
[h264 @ 0x5606a0386a00] mmco: unref short failure
[h264 @ 0x5606a0386a00] mmco: unref short failure
 12%|█▏        | 335/2910 [2:01:21<15:53:15, 22.21s/it][h264 @ 0x55e19a179400] mmco: unref short failure
[h264 @ 0x55b507c71f00] mmco: unref short failure
[h264 @ 0x55b507c71f00] mmco: unref short failure
 12%|█▏        | 336/2910 [2:01:26<12:08:05, 16.97s/it][h264 @ 0x55b4f5cb37c0] mmco: unref short failure
[h264 @ 0x55a26b1df040] mmco: unref short failure
[h264 @ 0x55a26b1df040] mmco: unref short failure
 12%|█▏        | 337/2910 [2:01:32<9:52:33, 13.82s/it] [h264 @ 0x55a2625f8080] mmco: unref short failure
[h264 @ 0x55a2625f8080] mmco: unref short failure
 12%|█▏        | 338/2910 [2:01:37<7:56:23, 11.11s/it] 12%|█▏        | 339/2910 [2:01:42<6:35:57,  9.24s/it][h264 @ 0x5606ac1d2580] mmco: unref short failure
[h264 @ 0x55a2779ae280] mmco: unref short failure
[h264 @ 0x55e1a4b69640] mmco: unref short failure
[h264 @ 0x56068f7cc740] mmco: unref short failure
[h264 @ 0x5606a68593c0] mmco: unref short failure
[h264 @ 0x5606a68593c0] mmco: unref short failure
[h264 @ 0x55a2793e8b00] mmco: unref short failure
09/17/2024 01:24:00 - INFO - __main__ -   current idx DTaJjznuY74.20 from finetune_area returns wrong image/video, use 138921 instead.
[h264 @ 0x55b4fb1b9040] mmco: unref short failure
[h264 @ 0x55b4fb1b9040] mmco: unref short failure
[h264 @ 0x55a25e51a0c0] mmco: unref short failure
[h264 @ 0x55a25e51a0c0] mmco: unref short failure
[h264 @ 0x55a25e51a0c0] mmco: unref short failure
[h264 @ 0x55a25e51a0c0] mmco: unref short failure
[h264 @ 0x55a278f50f00] mmco: unref short failure
[h264 @ 0x55a278f50f00] mmco: unref short failure
[h264 @ 0x55a278f50f00] mmco: unref short failure
[h264 @ 0x55a278f50f00] mmco: unref short failure
[h264 @ 0x55a26bc31b00] mmco: unref short failure
[h264 @ 0x55b513d1f380] mmco: unref short failure
[h264 @ 0x55e185a7a580] mmco: unref short failure
[h264 @ 0x55e185a7a580] mmco: unref short failure
[h264 @ 0x560698362bc0] mmco: unref short failure
 12%|█▏        | 340/2910 [2:02:49<19:01:44, 26.66s/it][h264 @ 0x55b4f4bf0040] mmco: unref short failure
[h264 @ 0x5606a6c82980] mmco: unref short failure
[h264 @ 0x55a26b27e500] mmco: unref short failure
 12%|█▏        | 341/2910 [2:03:12<18:16:47, 25.62s/it][h264 @ 0x55a269552200] mmco: unref short failure
[h264 @ 0x55a269552200] mmco: unref short failure
09/17/2024 01:25:05 - INFO - __main__ -   current idx vMl-g-GJ1Ac.24 from finetune_area returns wrong image/video, use 12696 instead.
[h264 @ 0x55a26397b5c0] mmco: unref short failure
[h264 @ 0x55a26397b5c0] mmco: unref short failure
[h264 @ 0x55e18af04680] mmco: unref short failure
[h264 @ 0x55e18af04680] mmco: unref short failure
[h264 @ 0x55a270b8ec40] mmco: unref short failure
[h264 @ 0x55b4f3e2b080] mmco: unref short failure
 12%|█▏        | 342/2910 [2:03:42<19:14:32, 26.98s/it][h264 @ 0x55b507bd09c0] mmco: unref short failure
[h264 @ 0x55b507bd09c0] mmco: unref short failure
 12%|█▏        | 343/2910 [2:03:52<15:35:26, 21.86s/it][h264 @ 0x5606a50f2c80] mmco: unref short failure
[h264 @ 0x5606a50f2c80] mmco: unref short failure
 12%|█▏        | 344/2910 [2:03:57<11:57:56, 16.79s/it][h264 @ 0x55b50a068e40] mmco: unref short failure
[h264 @ 0x55a26a892800] mmco: unref short failure
[h264 @ 0x55b4f3b12ac0] mmco: unref short failure
[h264 @ 0x55e1a19ddd40] mmco: unref short failure
[h264 @ 0x55b506b1f7c0] mmco: unref short failure
[h264 @ 0x55b506b1f7c0] mmco: unref short failure
 12%|█▏        | 345/2910 [2:04:03<9:31:59, 13.38s/it] [h264 @ 0x56068fb3b5c0] mmco: unref short failure
[h264 @ 0x56068fb3b5c0] mmco: unref short failure
 12%|█▏        | 346/2910 [2:04:08<7:52:25, 11.06s/it]09/17/2024 01:25:57 - INFO - __main__ -   current idx 1HAnFYVSFkk.3 from finetune_area returns wrong image/video, use 35169 instead.
 12%|█▏        | 347/2910 [2:04:14<6:47:15,  9.53s/it][h264 @ 0x5606a50f2c80] mmco: unref short failure
[h264 @ 0x55b4f3a24d80] mmco: unref short failure
[h264 @ 0x55b4f3a24d80] mmco: unref short failure
[h264 @ 0x55b512625bc0] mmco: unref short failure
[h264 @ 0x55b512625bc0] mmco: unref short failure
[h264 @ 0x55b512625bc0] mmco: unref short failure
[h264 @ 0x55b512625bc0] mmco: unref short failure
[h264 @ 0x55b511c84300] mmco: unref short failure
[h264 @ 0x55e18f4e37c0] mmco: unref short failure
[h264 @ 0x55e18f4e37c0] mmco: unref short failure
[h264 @ 0x55e18f4e37c0] mmco: unref short failure
[h264 @ 0x55e18f4e37c0] mmco: unref short failure
[h264 @ 0x55a25ee476c0] mmco: unref short failure
[h264 @ 0x55a25ee476c0] mmco: unref short failure
[h264 @ 0x55a25ee476c0] mmco: unref short failure
[h264 @ 0x55a25ee476c0] mmco: unref short failure
 12%|█▏        | 348/2910 [2:05:22<19:16:24, 27.08s/it][h264 @ 0x55e19a6313c0] mmco: unref short failure
[h264 @ 0x55e19a6313c0] mmco: unref short failure
 12%|█▏        | 349/2910 [2:05:41<17:32:02, 24.65s/it]09/17/2024 01:27:27 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 01:27:27 - INFO - __main__ -   start running ret%tva validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e1a1223ac0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x5606a57f0a80] mmco: unref short failure
[h264 @ 0x560692e09bc0] mmco: unref short failure
[h264 @ 0x560692e09bc0] mmco: unref short failure
[h264 @ 0x56069382fb80] mmco: unref short failure
[h264 @ 0x55a26ece4900] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55b50d9687c0] mmco: unref short failure
[h264 @ 0x55b50d9687c0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x56068f7e8f80] mmco: unref short failure
[h264 @ 0x56068c313580] mmco: unref short failure
[h264 @ 0x56068c313580] mmco: unref short failure
[h264 @ 0x55a25cb58940] mmco: unref short failure
[h264 @ 0x55a25cb58940] mmco: unref short failure
[h264 @ 0x56069ebfa8c0] mmco: unref short failure
[h264 @ 0x5606a5ad1200] mmco: unref short failure
[h264 @ 0x5606a5ad1200] mmco: unref short failure
[h264 @ 0x55a2772bf900] mmco: unref short failure
[h264 @ 0x55a2772bf900] mmco: unref short failure
[h264 @ 0x55b4f4041bc0] mmco: unref short failure
[h264 @ 0x55b4f4041bc0] mmco: unref short failure
09/17/2024 01:29:43 - INFO - __main__ -   current idx T9SsQafdxnY.19 from finetune_area returns wrong image/video, use 67620 instead.

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:50,  1.29it/s][A
  1%|          | 2/221 [00:01<02:36,  1.40it/s][A
  1%|▏         | 3/221 [00:01<01:50,  1.97it/s][A
  2%|▏         | 4/221 [00:01<01:22,  2.62it/s][A
  2%|▏         | 5/221 [00:02<01:09,  3.11it/s][A
  3%|▎         | 6/221 [00:02<01:00,  3.58it/s][A
  3%|▎         | 7/221 [00:02<01:02,  3.40it/s][A
  4%|▎         | 8/221 [00:03<01:08,  3.11it/s][A[h264 @ 0x55e183b32440] mmco: unref short failure
[h264 @ 0x55e183b32440] mmco: unref short failure

  4%|▍         | 9/221 [00:03<01:10,  2.99it/s][A[h264 @ 0x55a2772bf900] mmco: unref short failure

  5%|▍         | 10/221 [00:04<01:34,  2.22it/s][A
  5%|▍         | 11/221 [00:04<01:22,  2.55it/s][A
  5%|▌         | 12/221 [00:05<01:41,  2.05it/s][A
  6%|▌         | 13/221 [00:05<01:34,  2.20it/s][A
  6%|▋         | 14/221 [00:06<01:56,  1.78it/s][A
  7%|▋         | 15/221 [00:06<01:32,  2.22it/s][A
  7%|▋         | 16/221 [00:07<01:40,  2.05it/s][A
  8%|▊         | 17/221 [00:07<01:50,  1.85it/s][A[h264 @ 0x55e19a650cc0] mmco: unref short failure

  8%|▊         | 18/221 [00:07<01:35,  2.13it/s][A
  9%|▊         | 19/221 [00:08<01:15,  2.67it/s][A
  9%|▉         | 20/221 [00:08<01:06,  3.00it/s][A
 10%|▉         | 21/221 [00:08<00:59,  3.39it/s][A
 10%|▉         | 22/221 [00:08<00:54,  3.64it/s][A
 10%|█         | 23/221 [00:09<00:53,  3.73it/s][A
 11%|█         | 24/221 [00:09<00:54,  3.59it/s][A
 11%|█▏        | 25/221 [00:09<00:48,  4.06it/s][A
 12%|█▏        | 26/221 [00:10<01:07,  2.87it/s][A
 12%|█▏        | 27/221 [00:10<00:56,  3.42it/s][A
 13%|█▎        | 28/221 [00:11<01:24,  2.28it/s][A
 13%|█▎        | 29/221 [00:11<01:25,  2.25it/s][A
 14%|█▎        | 30/221 [00:11<01:17,  2.46it/s][A
 14%|█▍        | 31/221 [00:12<01:12,  2.63it/s][A
 14%|█▍        | 32/221 [00:12<01:01,  3.05it/s][A
 15%|█▍        | 33/221 [00:12<01:01,  3.04it/s][A
 15%|█▌        | 34/221 [00:12<00:50,  3.68it/s][A[h264 @ 0x560696cafb80] mmco: unref short failure
[h264 @ 0x560696cafb80] mmco: unref short failure
[h264 @ 0x560696cafb80] mmco: unref short failure
[h264 @ 0x560696cafb80] mmco: unref short failure

 16%|█▌        | 35/221 [00:13<00:54,  3.44it/s][A
 16%|█▋        | 36/221 [00:13<01:01,  3.03it/s][A
 17%|█▋        | 37/221 [00:14<01:17,  2.38it/s][A[h264 @ 0x55b4f3fca600] mmco: unref short failure
[h264 @ 0x55b4f3fca600] mmco: unref short failure

 17%|█▋        | 38/221 [00:14<01:19,  2.31it/s][A
 18%|█▊        | 39/221 [00:15<01:14,  2.45it/s][A
 18%|█▊        | 40/221 [00:15<01:12,  2.49it/s][A
 19%|█▊        | 41/221 [00:15<00:57,  3.13it/s][A
 19%|█▉        | 42/221 [00:16<01:07,  2.65it/s][A
 19%|█▉        | 43/221 [00:16<00:53,  3.32it/s][A
 20%|██        | 45/221 [00:16<01:00,  2.89it/s][A
 21%|██        | 46/221 [00:17<01:05,  2.68it/s][A
 21%|██▏       | 47/221 [00:17<01:08,  2.54it/s][A
 22%|██▏       | 48/221 [00:18<00:57,  3.00it/s][A
 22%|██▏       | 49/221 [00:18<01:08,  2.52it/s][A
 23%|██▎       | 50/221 [00:19<01:13,  2.31it/s][A
 23%|██▎       | 51/221 [00:19<00:57,  2.97it/s][A[h264 @ 0x55a26c162c40] mmco: unref short failure
[h264 @ 0x55a26c162c40] mmco: unref short failure

 24%|██▎       | 52/221 [00:19<00:48,  3.46it/s][A
 24%|██▍       | 53/221 [00:19<00:41,  4.09it/s][A
 24%|██▍       | 54/221 [00:20<01:36,  1.73it/s][A
 25%|██▍       | 55/221 [00:21<01:28,  1.87it/s][A
 25%|██▌       | 56/221 [00:21<01:14,  2.23it/s][A
 26%|██▌       | 57/221 [00:21<01:01,  2.65it/s][A
 26%|██▌       | 58/221 [00:21<00:52,  3.10it/s][A
 27%|██▋       | 59/221 [00:22<00:51,  3.16it/s][A
 27%|██▋       | 60/221 [00:23<01:21,  1.98it/s][A
 28%|██▊       | 61/221 [00:23<01:07,  2.36it/s][A
 28%|██▊       | 62/221 [00:23<01:03,  2.51it/s][A
 29%|██▊       | 63/221 [00:24<01:02,  2.54it/s][A[h264 @ 0x55a25f4cf200] mmco: unref short failure

 29%|██▉       | 64/221 [00:24<00:54,  2.88it/s][A
 29%|██▉       | 65/221 [00:24<00:49,  3.14it/s][A
 30%|██▉       | 66/221 [00:25<00:50,  3.07it/s][A
 30%|███       | 67/221 [00:25<01:13,  2.11it/s][A
 31%|███       | 68/221 [00:26<00:58,  2.62it/s][A
 31%|███       | 69/221 [00:26<01:20,  1.89it/s][A
 32%|███▏      | 70/221 [00:27<01:04,  2.33it/s][A
 32%|███▏      | 71/221 [00:27<01:07,  2.21it/s][A
 33%|███▎      | 72/221 [00:28<01:04,  2.30it/s][A
 33%|███▎      | 73/221 [00:28<01:04,  2.28it/s][A
 33%|███▎      | 74/221 [00:28<00:52,  2.79it/s][A
 34%|███▍      | 75/221 [00:28<00:52,  2.81it/s][A
 34%|███▍      | 76/221 [00:29<00:41,  3.52it/s][A
 35%|███▍      | 77/221 [00:29<00:39,  3.63it/s][A
 35%|███▌      | 78/221 [00:29<00:41,  3.45it/s][A
 36%|███▌      | 79/221 [00:30<01:01,  2.32it/s][A
 36%|███▌      | 80/221 [00:30<00:54,  2.61it/s][A
 37%|███▋      | 81/221 [00:30<00:46,  3.04it/s][A
 37%|███▋      | 82/221 [00:31<01:04,  2.15it/s][A
 38%|███▊      | 83/221 [00:32<01:05,  2.11it/s][A
 38%|███▊      | 84/221 [00:32<00:57,  2.39it/s][A
 38%|███▊      | 85/221 [00:32<00:47,  2.89it/s][A
 39%|███▉      | 86/221 [00:32<00:44,  3.05it/s][A
 39%|███▉      | 87/221 [00:33<01:05,  2.04it/s][A
 40%|███▉      | 88/221 [00:34<01:12,  1.83it/s][A[h264 @ 0x560695aac800] mmco: unref short failure

 40%|████      | 89/221 [00:34<01:07,  1.95it/s][A
 41%|████      | 90/221 [00:35<01:04,  2.04it/s][A
 41%|████      | 91/221 [00:35<00:52,  2.49it/s][A
 42%|████▏     | 92/221 [00:35<00:48,  2.65it/s][A
 42%|████▏     | 93/221 [00:36<00:52,  2.42it/s][A
 43%|████▎     | 94/221 [00:36<00:43,  2.90it/s][A
 43%|████▎     | 95/221 [00:36<00:43,  2.91it/s][A
 43%|████▎     | 96/221 [00:37<00:41,  2.99it/s][A
 44%|████▍     | 97/221 [00:37<00:39,  3.14it/s][A[h264 @ 0x55a25d126780] mmco: unref short failure

 44%|████▍     | 98/221 [00:37<00:42,  2.90it/s][A
 45%|████▍     | 99/221 [00:38<00:39,  3.08it/s][A
 45%|████▌     | 100/221 [00:38<00:41,  2.88it/s][A
 46%|████▌     | 101/221 [00:38<00:36,  3.28it/s][A
 46%|████▌     | 102/221 [00:39<00:37,  3.17it/s][A
 47%|████▋     | 103/221 [00:39<00:35,  3.34it/s][A
 47%|████▋     | 104/221 [00:39<00:33,  3.49it/s][A
 48%|████▊     | 105/221 [00:39<00:32,  3.59it/s][A
 48%|████▊     | 106/221 [00:40<00:53,  2.16it/s][A
 48%|████▊     | 107/221 [00:41<00:45,  2.53it/s][A
 49%|████▉     | 108/221 [00:41<00:38,  2.92it/s][A
 49%|████▉     | 109/221 [00:41<00:37,  3.02it/s][A
 50%|████▉     | 110/221 [00:42<00:45,  2.43it/s][A
 50%|█████     | 111/221 [00:42<00:52,  2.11it/s][A
 51%|█████     | 112/221 [00:42<00:43,  2.53it/s][A
[h264 @ 0x55b5023a5f80] mmco: unref short failure
 51%|█████     | 113/221 [00:43<00:41,  2.60it/s][A
 52%|█████▏    | 114/221 [00:43<00:34,  3.06it/s][A
 52%|█████▏    | 115/221 [00:43<00:27,  3.82it/s][A
 52%|█████▏    | 116/221 [00:44<00:51,  2.04it/s][A
 53%|█████▎    | 117/221 [00:45<00:47,  2.17it/s][A
 53%|█████▎    | 118/221 [00:45<00:42,  2.44it/s][A
 54%|█████▍    | 119/221 [00:45<00:43,  2.32it/s][A
 54%|█████▍    | 120/221 [00:46<00:40,  2.48it/s][A
 55%|█████▍    | 121/221 [00:46<00:33,  3.03it/s][A
 55%|█████▌    | 122/221 [00:46<00:29,  3.37it/s][A
 56%|█████▌    | 123/221 [00:46<00:26,  3.75it/s][A[h264 @ 0x55a265304c80] mmco: unref short failure
[h264 @ 0x55a265304c80] mmco: unref short failure

 56%|█████▌    | 124/221 [00:46<00:26,  3.73it/s][A
 57%|█████▋    | 125/221 [00:47<00:28,  3.34it/s][A
 57%|█████▋    | 126/221 [00:47<00:26,  3.62it/s][A
 57%|█████▋    | 127/221 [00:48<00:36,  2.55it/s][A
 58%|█████▊    | 128/221 [00:48<00:36,  2.55it/s][A
 58%|█████▊    | 129/221 [00:48<00:29,  3.13it/s][A
 59%|█████▉    | 130/221 [00:49<00:28,  3.20it/s][A[h264 @ 0x55e1a3010280] mmco: unref short failure
[h264 @ 0x55e1a3010280] mmco: unref short failure

 59%|█████▉    | 131/221 [00:49<00:25,  3.51it/s][A
 60%|█████▉    | 132/221 [00:49<00:22,  3.92it/s][A
 60%|██████    | 133/221 [00:50<00:28,  3.04it/s][A
 61%|██████    | 134/221 [00:50<00:26,  3.32it/s][A
 61%|██████    | 135/221 [00:50<00:25,  3.38it/s][A
 62%|██████▏   | 136/221 [00:50<00:28,  3.00it/s][A
 62%|██████▏   | 137/221 [00:51<00:26,  3.21it/s][A
 62%|██████▏   | 138/221 [00:51<00:27,  2.97it/s][A[h264 @ 0x560695250a40] mmco: unref short failure

[h264 @ 0x55e1834051c0] mmco: unref short failure
 63%|██████▎   | 139/221 [00:52<00:31,  2.61it/s][A[h264 @ 0x55e1834051c0] mmco: unref short failure

 63%|██████▎   | 140/221 [00:52<00:29,  2.77it/s][A
 64%|██████▍   | 141/221 [00:52<00:27,  2.87it/s][A
 64%|██████▍   | 142/221 [00:53<00:31,  2.52it/s][A
 65%|██████▍   | 143/221 [00:53<00:30,  2.53it/s][A[h264 @ 0x55e183f712c0] mmco: unref short failure
[h264 @ 0x55e183f712c0] mmco: unref short failure

 65%|██████▌   | 144/221 [00:53<00:29,  2.58it/s][A
 66%|██████▌   | 145/221 [00:54<00:23,  3.29it/s][A
 66%|██████▌   | 146/221 [00:54<00:19,  3.78it/s][A
 67%|██████▋   | 147/221 [00:54<00:20,  3.63it/s][A
 67%|██████▋   | 148/221 [00:54<00:22,  3.28it/s][A
 67%|██████▋   | 149/221 [00:55<00:20,  3.55it/s][A
 68%|██████▊   | 150/221 [00:55<00:18,  3.74it/s][A
 68%|██████▊   | 151/221 [00:56<00:31,  2.20it/s][A
 69%|██████▉   | 152/221 [00:57<00:47,  1.44it/s][A
 69%|██████▉   | 153/221 [00:58<00:42,  1.62it/s][A
 70%|██████▉   | 154/221 [00:58<00:34,  1.92it/s][A
 70%|███████   | 155/221 [00:58<00:29,  2.26it/s][A
 71%|███████   | 156/221 [00:58<00:26,  2.47it/s][A09/17/2024 01:30:51 - INFO - __main__ -   current idx DhOkpvuskU4.32 from finetune_area returns wrong image/video, use 112773 instead.

 71%|███████   | 157/221 [00:59<00:27,  2.36it/s][A
 71%|███████▏  | 158/221 [00:59<00:24,  2.56it/s][A
 72%|███████▏  | 159/221 [00:59<00:20,  3.06it/s][A
 72%|███████▏  | 160/221 [01:00<00:22,  2.72it/s][A
 73%|███████▎  | 161/221 [01:00<00:18,  3.28it/s][A
 73%|███████▎  | 162/221 [01:00<00:19,  3.02it/s][A
 74%|███████▍  | 163/221 [01:01<00:19,  3.00it/s][A
 74%|███████▍  | 164/221 [01:01<00:23,  2.42it/s][A
 75%|███████▍  | 165/221 [01:01<00:19,  2.90it/s][A
 75%|███████▌  | 166/221 [01:02<00:22,  2.49it/s][A
 76%|███████▌  | 167/221 [01:02<00:17,  3.06it/s][A[h264 @ 0x55a25cb58940] mmco: unref short failure
[h264 @ 0x55a25cb58940] mmco: unref short failure

 76%|███████▌  | 168/221 [01:03<00:18,  2.82it/s][A
 76%|███████▋  | 169/221 [01:03<00:16,  3.25it/s][A
 77%|███████▋  | 170/221 [01:03<00:17,  3.00it/s][A
 77%|███████▋  | 171/221 [01:04<00:19,  2.60it/s][A
 78%|███████▊  | 172/221 [01:04<00:15,  3.22it/s][A
 78%|███████▊  | 173/221 [01:04<00:13,  3.62it/s][A
 79%|███████▊  | 174/221 [01:04<00:12,  3.65it/s][A
 79%|███████▉  | 175/221 [01:05<00:15,  3.02it/s][A
 80%|███████▉  | 176/221 [01:05<00:13,  3.39it/s][A
 80%|████████  | 177/221 [01:05<00:11,  3.93it/s][A
 81%|████████  | 178/221 [01:05<00:12,  3.47it/s][A
 81%|████████  | 179/221 [01:06<00:13,  3.19it/s][A
 82%|████████▏ | 181/221 [01:06<00:11,  3.45it/s][A
 82%|████████▏ | 182/221 [01:07<00:10,  3.77it/s][A
 83%|████████▎ | 183/221 [01:07<00:09,  3.82it/s][h264 @ 0x5606ae9f1c80] mmco: unref short failure
[A
 83%|████████▎ | 184/221 [01:07<00:10,  3.48it/s][A
 84%|████████▍ | 186/221 [01:08<00:09,  3.85it/s][A
 85%|████████▍ | 187/221 [01:08<00:08,  3.81it/s][A
 85%|████████▌ | 188/221 [01:08<00:08,  3.68it/s][A
 86%|████████▌ | 189/221 [01:09<00:09,  3.38it/s][A
 86%|████████▌ | 190/221 [01:09<00:10,  2.85it/s][A
 86%|████████▋ | 191/221 [01:09<00:08,  3.35it/s][A
 87%|████████▋ | 192/221 [01:09<00:08,  3.56it/s][A
 88%|████████▊ | 194/221 [01:10<00:09,  2.73it/s][A
 88%|████████▊ | 195/221 [01:11<00:09,  2.85it/s][A
 89%|████████▊ | 196/221 [01:11<00:10,  2.32it/s][A
 89%|████████▉ | 197/221 [01:12<00:08,  2.69it/s][A
 90%|████████▉ | 198/221 [01:12<00:08,  2.83it/s][A
 90%|█████████ | 199/221 [01:12<00:06,  3.38it/s][A
 90%|█████████ | 200/221 [01:12<00:06,  3.21it/s][A
 91%|█████████ | 201/221 [01:13<00:05,  3.41it/s][A
 91%|█████████▏| 202/221 [01:13<00:05,  3.55it/s][A
 92%|█████████▏| 203/221 [01:13<00:04,  4.01it/s][A
 92%|█████████▏| 204/221 [01:13<00:04,  4.03it/s][A
 93%|█████████▎| 205/221 [01:13<00:03,  4.75it/s][A
 93%|█████████▎| 206/221 [01:14<00:05,  2.74it/s][A
 94%|█████████▎| 207/221 [01:14<00:04,  3.44it/s][A
 94%|█████████▍| 208/221 [01:14<00:03,  3.74it/s][A
 95%|█████████▍| 209/221 [01:15<00:03,  3.93it/s][A
 95%|█████████▌| 210/221 [01:15<00:02,  4.71it/s][A
 95%|█████████▌| 211/221 [01:15<00:02,  3.54it/s][A
 96%|█████████▌| 212/221 [01:15<00:02,  3.97it/s][A
 96%|█████████▋| 213/221 [01:16<00:02,  3.78it/s][A
 97%|█████████▋| 214/221 [01:16<00:02,  3.45it/s][A
 97%|█████████▋| 215/221 [01:16<00:01,  3.56it/s][A
 98%|█████████▊| 216/221 [01:17<00:01,  3.32it/s][A
 98%|█████████▊| 217/221 [01:17<00:01,  3.05it/s][A
 99%|█████████▊| 218/221 [01:17<00:00,  3.02it/s][A
 99%|█████████▉| 219/221 [01:18<00:00,  3.37it/s][A[h264 @ 0x55e1830cf280] mmco: unref short failure
[h264 @ 0x55e1830cf280] mmco: unref short failure

100%|█████████▉| 220/221 [01:19<00:00,  1.39it/s][A
100%|██████████| 221/221 [01:20<00:00,  1.69it/s][A100%|██████████| 221/221 [01:20<00:00,  2.76it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A[h264 @ 0x55b4f54ee240] mmco: unref short failure
[h264 @ 0x55b4f54ee240] mmco: unref short failure

  0%|          | 1/221 [00:00<01:04,  3.41it/s][A
  1%|          | 2/221 [00:00<01:05,  3.36it/s][A
  1%|▏         | 3/221 [00:00<01:04,  3.38it/s][A
  2%|▏         | 4/221 [00:01<01:04,  3.37it/s][A
  2%|▏         | 5/221 [00:01<01:03,  3.38it/s][A
  3%|▎         | 6/221 [00:01<01:03,  3.39it/s][A
  3%|▎         | 7/221 [00:02<01:03,  3.37it/s][A
  4%|▎         | 8/221 [00:02<01:03,  3.38it/s][A
  4%|▍         | 9/221 [00:02<01:02,  3.39it/s][A
  5%|▍         | 10/221 [00:02<01:02,  3.39it/s][A
  5%|▍         | 11/221 [00:03<01:01,  3.39it/s][A
  5%|▌         | 12/221 [00:03<01:02,  3.35it/s][A
  6%|▌         | 13/221 [00:03<01:01,  3.36it/s][A
  6%|▋         | 14/221 [00:04<01:01,  3.37it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.33it/s][A
  7%|▋         | 16/221 [00:04<01:01,  3.32it/s][A
  8%|▊         | 17/221 [00:05<01:00,  3.34it/s][A
  8%|▊         | 18/221 [00:05<01:00,  3.35it/s][A
  9%|▊         | 19/221 [00:05<01:00,  3.36it/s][A
  9%|▉         | 20/221 [00:05<01:00,  3.34it/s][A
 10%|▉         | 21/221 [00:06<00:59,  3.36it/s][A
 10%|▉         | 22/221 [00:06<00:59,  3.36it/s][A
 10%|█         | 23/221 [00:06<00:59,  3.34it/s][A
 11%|█         | 24/221 [00:07<00:58,  3.36it/s][A
 11%|█▏        | 25/221 [00:07<00:58,  3.37it/s][A
 12%|█▏        | 26/221 [00:07<00:57,  3.38it/s][A
 12%|█▏        | 27/221 [00:08<00:57,  3.39it/s][A
 13%|█▎        | 28/221 [00:08<00:56,  3.39it/s][A
 13%|█▎        | 29/221 [00:08<00:56,  3.37it/s][A
 14%|█▎        | 30/221 [00:08<00:57,  3.30it/s][A
 14%|█▍        | 31/221 [00:09<00:57,  3.33it/s][A
 14%|█▍        | 32/221 [00:09<00:56,  3.35it/s][A
 15%|█▍        | 33/221 [00:09<00:55,  3.37it/s][A09/17/2024 01:31:25 - INFO - __main__ -   current idx R8HHCsDQ1cs.27 from finetune_area returns wrong image/video, use 15213 instead.

 15%|█▌        | 34/221 [00:10<00:55,  3.38it/s][A
 16%|█▌        | 35/221 [00:10<00:55,  3.36it/s][A
 16%|█▋        | 36/221 [00:10<00:54,  3.38it/s][A
 17%|█▋        | 37/221 [00:11<00:57,  3.19it/s][A
 17%|█▋        | 38/221 [00:11<00:56,  3.23it/s][A
 18%|█▊        | 39/221 [00:11<00:56,  3.23it/s][A
 18%|█▊        | 40/221 [00:11<00:55,  3.28it/s][A
 19%|█▊        | 41/221 [00:12<00:55,  3.26it/s][A
 19%|█▉        | 42/221 [00:12<00:54,  3.30it/s][A
 19%|█▉        | 43/221 [00:12<00:53,  3.30it/s][A
 20%|█▉        | 44/221 [00:13<00:53,  3.33it/s][A
 20%|██        | 45/221 [00:13<00:53,  3.31it/s][A
 21%|██        | 46/221 [00:13<00:52,  3.34it/s][A
 21%|██▏       | 47/221 [00:14<00:51,  3.36it/s][A
 22%|██▏       | 48/221 [00:14<00:51,  3.37it/s][A
 22%|██▏       | 49/221 [00:14<00:50,  3.38it/s][A
 23%|██▎       | 50/221 [00:14<00:51,  3.35it/s][A
 23%|██▎       | 51/221 [00:15<00:50,  3.36it/s][A
 24%|██▎       | 52/221 [00:15<00:52,  3.24it/s][A
 24%|██▍       | 53/221 [00:15<00:51,  3.28it/s][A
 24%|██▍       | 54/221 [00:16<00:50,  3.30it/s][A
 25%|██▍       | 55/221 [00:16<00:50,  3.32it/s][A
 25%|██▌       | 56/221 [00:16<00:49,  3.30it/s][A
 26%|██▌       | 57/221 [00:17<00:49,  3.31it/s][A
 26%|██▌       | 58/221 [00:17<00:48,  3.34it/s][A
 27%|██▋       | 59/221 [00:17<00:48,  3.36it/s][A
 27%|██▋       | 60/221 [00:17<00:48,  3.35it/s][A
 28%|██▊       | 61/221 [00:18<00:47,  3.36it/s][A
 28%|██▊       | 62/221 [00:18<00:47,  3.37it/s][A
 29%|██▊       | 63/221 [00:18<00:46,  3.36it/s][A
 29%|██▉       | 64/221 [00:19<00:46,  3.38it/s][A
 29%|██▉       | 65/221 [00:19<00:46,  3.39it/s][A
 30%|██▉       | 66/221 [00:19<00:45,  3.39it/s][A
 30%|███       | 67/221 [00:20<00:45,  3.37it/s][A
 31%|███       | 68/221 [00:20<00:45,  3.38it/s][A
 31%|███       | 69/221 [00:20<00:44,  3.39it/s][A
 32%|███▏      | 70/221 [00:20<00:44,  3.39it/s][A
 32%|███▏      | 71/221 [00:21<00:44,  3.38it/s][A[h264 @ 0x55a26564b780] mmco: unref short failure
[h264 @ 0x55a26564b780] mmco: unref short failure

 33%|███▎      | 72/221 [00:21<00:43,  3.39it/s][A
 33%|███▎      | 73/221 [00:21<00:43,  3.40it/s][A
 33%|███▎      | 74/221 [00:22<00:43,  3.40it/s][A
 34%|███▍      | 75/221 [00:22<00:42,  3.40it/s][A
 34%|███▍      | 76/221 [00:22<00:42,  3.40it/s][A
 35%|███▍      | 77/221 [00:22<00:42,  3.40it/s][A
 35%|███▌      | 78/221 [00:23<00:42,  3.40it/s][A
 36%|███▌      | 79/221 [00:23<00:41,  3.41it/s][A
 36%|███▌      | 80/221 [00:23<00:41,  3.41it/s][A
 37%|███▋      | 81/221 [00:24<00:41,  3.41it/s][A
 37%|███▋      | 82/221 [00:24<00:40,  3.41it/s][A
 38%|███▊      | 83/221 [00:24<00:40,  3.41it/s][A
 38%|███▊      | 84/221 [00:25<00:40,  3.41it/s][A
 38%|███▊      | 85/221 [00:25<00:39,  3.41it/s][A
 39%|███▉      | 86/221 [00:25<00:39,  3.41it/s][A
 39%|███▉      | 87/221 [00:25<00:39,  3.41it/s][A
 40%|███▉      | 88/221 [00:26<00:38,  3.41it/s][A
 40%|████      | 89/221 [00:26<00:38,  3.41it/s][A
 41%|████      | 90/221 [00:26<00:38,  3.41it/s][A
 41%|████      | 91/221 [00:27<00:38,  3.41it/s][A
 42%|████▏     | 92/221 [00:27<00:37,  3.41it/s][A
 42%|████▏     | 93/221 [00:27<00:37,  3.41it/s][A
 43%|████▎     | 94/221 [00:27<00:37,  3.41it/s][A
 43%|████▎     | 95/221 [00:28<00:36,  3.41it/s][A
 43%|████▎     | 96/221 [00:28<00:36,  3.41it/s][A
 44%|████▍     | 97/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 98/221 [00:29<00:35,  3.42it/s][A
 45%|████▍     | 99/221 [00:29<00:35,  3.42it/s][A
 45%|████▌     | 100/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 101/221 [00:30<00:35,  3.42it/s][A
 46%|████▌     | 102/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 104/221 [00:30<00:34,  3.42it/s][A
 48%|████▊     | 105/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 107/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 108/221 [00:32<00:33,  3.42it/s][A
 49%|████▉     | 109/221 [00:32<00:32,  3.42it/s][A
 50%|████▉     | 110/221 [00:32<00:32,  3.42it/s][A
 50%|█████     | 111/221 [00:32<00:32,  3.42it/s][A
 51%|█████     | 112/221 [00:33<00:31,  3.42it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 114/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:34<00:30,  3.42it/s][A
 52%|█████▏    | 116/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:34<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:35<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:35<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:37<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:38<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:39<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:39<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:40<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:41<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:41<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:44<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:45<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:45<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:46<00:18,  3.42it/s][A
 71%|███████   | 157/221 [00:46<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:47<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:48<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:48<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:49<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:49<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:49<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:50<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:51<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:51<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:52<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:54<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:55<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:56<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:57<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:57<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:58<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:03<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.42it/s][A100%|██████████| 221/221 [01:05<00:00,  3.40it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:25,  8.65it/s][A
  1%|          | 2/221 [00:00<01:02,  3.52it/s][A
  1%|▏         | 3/221 [00:01<01:35,  2.29it/s][A
  2%|▏         | 4/221 [00:01<01:17,  2.81it/s][A
  2%|▏         | 5/221 [00:01<01:02,  3.46it/s][A
  3%|▎         | 7/221 [00:01<00:48,  4.43it/s][A
  4%|▎         | 8/221 [00:02<00:51,  4.14it/s][A
  4%|▍         | 9/221 [00:02<00:50,  4.22it/s][A
  5%|▍         | 10/221 [00:02<00:58,  3.62it/s][A
  5%|▍         | 11/221 [00:02<00:52,  4.03it/s][A
  5%|▌         | 12/221 [00:03<00:50,  4.12it/s][A
  6%|▌         | 13/221 [00:03<01:24,  2.48it/s][A
  6%|▋         | 14/221 [00:04<01:06,  3.10it/s][A
  7%|▋         | 15/221 [00:04<01:07,  3.06it/s][A
  7%|▋         | 16/221 [00:04<01:11,  2.85it/s][A
  8%|▊         | 17/221 [00:05<01:14,  2.76it/s][A
  8%|▊         | 18/221 [00:05<01:13,  2.75it/s][A
  9%|▊         | 19/221 [00:05<01:01,  3.27it/s][A
  9%|▉         | 20/221 [00:06<01:06,  3.04it/s][A
 10%|▉         | 21/221 [00:06<00:54,  3.64it/s][A
 10%|▉         | 22/221 [00:06<00:52,  3.78it/s][A
 11%|█         | 24/221 [00:06<00:38,  5.13it/s][A
 11%|█▏        | 25/221 [00:07<00:40,  4.80it/s][A
 12%|█▏        | 26/221 [00:07<00:44,  4.34it/s][A
 12%|█▏        | 27/221 [00:07<00:47,  4.09it/s][A
 13%|█▎        | 28/221 [00:08<00:59,  3.25it/s][A
 13%|█▎        | 29/221 [00:08<00:59,  3.22it/s][A
 14%|█▎        | 30/221 [00:08<00:55,  3.42it/s][A
 14%|█▍        | 31/221 [00:08<00:58,  3.23it/s][A
 14%|█▍        | 32/221 [00:09<00:52,  3.59it/s][A
 15%|█▍        | 33/221 [00:09<00:47,  3.97it/s][A
 15%|█▌        | 34/221 [00:09<00:46,  4.03it/s][A
 16%|█▌        | 35/221 [00:09<00:43,  4.26it/s][A
 16%|█▋        | 36/221 [00:10<00:54,  3.39it/s][A
 17%|█▋        | 37/221 [00:10<00:50,  3.62it/s][A
 17%|█▋        | 38/221 [00:10<00:49,  3.73it/s][A
 18%|█▊        | 39/221 [00:10<00:42,  4.30it/s][A
 18%|█▊        | 40/221 [00:11<00:46,  3.88it/s][A
 19%|█▉        | 42/221 [00:11<00:36,  4.91it/s][A
 19%|█▉        | 43/221 [00:11<00:41,  4.27it/s][A
 20%|█▉        | 44/221 [00:11<00:36,  4.83it/s][A
 20%|██        | 45/221 [00:12<00:48,  3.64it/s][A
 21%|██        | 46/221 [00:12<00:42,  4.07it/s][A
 22%|██▏       | 48/221 [00:12<00:29,  5.87it/s][A
 22%|██▏       | 49/221 [00:12<00:28,  6.05it/s][A
 23%|██▎       | 50/221 [00:13<00:35,  4.81it/s][A
 23%|██▎       | 51/221 [00:13<00:45,  3.72it/s][A
 24%|██▎       | 52/221 [00:13<00:37,  4.47it/s][A
 24%|██▍       | 53/221 [00:13<00:35,  4.79it/s][A
 24%|██▍       | 54/221 [00:14<00:37,  4.51it/s][A
 25%|██▍       | 55/221 [00:14<00:36,  4.53it/s][A
 25%|██▌       | 56/221 [00:14<00:35,  4.63it/s][A
 26%|██▌       | 57/221 [00:14<00:40,  4.04it/s][A
 26%|██▌       | 58/221 [00:15<00:35,  4.58it/s][A
 27%|██▋       | 59/221 [00:15<00:34,  4.70it/s][A
 27%|██▋       | 60/221 [00:15<00:39,  4.08it/s][A
 28%|██▊       | 61/221 [00:15<00:36,  4.38it/s][A
 28%|██▊       | 62/221 [00:15<00:34,  4.65it/s][A
 29%|██▊       | 63/221 [00:16<00:34,  4.62it/s][A
 29%|██▉       | 64/221 [00:16<00:34,  4.61it/s][A
 30%|██▉       | 66/221 [00:16<00:30,  5.12it/s][A
 30%|███       | 67/221 [00:17<00:51,  3.00it/s][A
 31%|███       | 68/221 [00:17<00:46,  3.27it/s][A
 31%|███       | 69/221 [00:18<00:49,  3.10it/s][A
 32%|███▏      | 70/221 [00:18<00:41,  3.60it/s][A
 32%|███▏      | 71/221 [00:18<00:46,  3.25it/s][A
 33%|███▎      | 72/221 [00:19<00:53,  2.80it/s][A
 33%|███▎      | 73/221 [00:19<00:49,  3.00it/s][A
 33%|███▎      | 74/221 [00:19<00:45,  3.22it/s][A
 34%|███▍      | 75/221 [00:20<00:50,  2.89it/s][A
 34%|███▍      | 76/221 [00:20<00:40,  3.55it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.89it/s][A
 35%|███▌      | 78/221 [00:20<00:35,  4.00it/s][A
 36%|███▌      | 79/221 [00:20<00:39,  3.62it/s][A
 36%|███▌      | 80/221 [00:21<00:41,  3.41it/s][A
 37%|███▋      | 81/221 [00:21<00:40,  3.44it/s][A
 37%|███▋      | 82/221 [00:21<00:38,  3.66it/s][A
 38%|███▊      | 83/221 [00:21<00:33,  4.12it/s][A
 38%|███▊      | 84/221 [00:22<00:36,  3.77it/s][A
 38%|███▊      | 85/221 [00:22<00:47,  2.87it/s][A
 39%|███▉      | 86/221 [00:23<00:43,  3.10it/s][A
 39%|███▉      | 87/221 [00:23<00:59,  2.26it/s][A
 40%|███▉      | 88/221 [00:23<00:48,  2.76it/s][A
 40%|████      | 89/221 [00:24<00:47,  2.80it/s][A
 41%|████      | 90/221 [00:24<00:49,  2.63it/s][A
 41%|████      | 91/221 [00:24<00:40,  3.23it/s][A
 42%|████▏     | 92/221 [00:25<00:37,  3.47it/s][A
 42%|████▏     | 93/221 [00:25<00:39,  3.27it/s][A
 43%|████▎     | 94/221 [00:25<00:36,  3.52it/s][A
 43%|████▎     | 95/221 [00:26<00:45,  2.75it/s][A
 43%|████▎     | 96/221 [00:26<00:40,  3.09it/s][A
 44%|████▍     | 97/221 [00:26<00:39,  3.14it/s][A
 44%|████▍     | 98/221 [00:27<00:37,  3.27it/s][A
 45%|████▍     | 99/221 [00:27<00:33,  3.65it/s][A
 45%|████▌     | 100/221 [00:27<00:27,  4.42it/s][A
 46%|████▌     | 101/221 [00:27<00:33,  3.57it/s][A
 46%|████▌     | 102/221 [00:28<00:31,  3.73it/s][A
 47%|████▋     | 103/221 [00:28<00:29,  3.99it/s][A
 47%|████▋     | 104/221 [00:28<00:24,  4.80it/s][A
 48%|████▊     | 105/221 [00:28<00:24,  4.65it/s][A
 48%|████▊     | 106/221 [00:29<00:34,  3.31it/s][A
 48%|████▊     | 107/221 [00:29<00:30,  3.71it/s][A
 49%|████▉     | 108/221 [00:29<00:27,  4.10it/s][A
 49%|████▉     | 109/221 [00:29<00:27,  4.01it/s][A
 50%|████▉     | 110/221 [00:30<00:30,  3.65it/s][A
 50%|█████     | 111/221 [00:30<00:30,  3.63it/s][A
 51%|█████     | 112/221 [00:30<00:28,  3.77it/s][A
 51%|█████     | 113/221 [00:30<00:26,  4.08it/s][A
 52%|█████▏    | 115/221 [00:31<00:23,  4.52it/s][A
 52%|█████▏    | 116/221 [00:31<00:22,  4.72it/s][A
 53%|█████▎    | 117/221 [00:31<00:23,  4.48it/s][A
 53%|█████▎    | 118/221 [00:32<00:27,  3.70it/s][A
 54%|█████▍    | 119/221 [00:32<00:34,  2.94it/s][A
 54%|█████▍    | 120/221 [00:32<00:32,  3.06it/s][A
 55%|█████▌    | 122/221 [00:33<00:24,  3.97it/s][A
 56%|█████▌    | 123/221 [00:33<00:25,  3.87it/s][A
 56%|█████▌    | 124/221 [00:33<00:29,  3.32it/s][A
 57%|█████▋    | 125/221 [00:34<00:39,  2.41it/s][A
 57%|█████▋    | 126/221 [00:34<00:33,  2.82it/s][A
 57%|█████▋    | 127/221 [00:35<00:44,  2.13it/s][A
 58%|█████▊    | 128/221 [00:35<00:37,  2.49it/s][A
 58%|█████▊    | 129/221 [00:35<00:29,  3.07it/s][A
 59%|█████▉    | 130/221 [00:36<00:27,  3.33it/s][A
 59%|█████▉    | 131/221 [00:36<00:25,  3.49it/s][A
 60%|█████▉    | 132/221 [00:36<00:31,  2.82it/s][A
 60%|██████    | 133/221 [00:37<00:34,  2.54it/s][A
 61%|██████    | 134/221 [00:37<00:34,  2.54it/s][A
 61%|██████    | 135/221 [00:37<00:27,  3.17it/s][A
 62%|██████▏   | 136/221 [00:38<00:26,  3.24it/s][A
 62%|██████▏   | 137/221 [00:38<00:24,  3.48it/s][A
 62%|██████▏   | 138/221 [00:38<00:23,  3.51it/s][A
 63%|██████▎   | 139/221 [00:39<00:24,  3.33it/s][A
 63%|██████▎   | 140/221 [00:39<00:21,  3.72it/s][A
 64%|██████▍   | 141/221 [00:39<00:21,  3.71it/s][A
 64%|██████▍   | 142/221 [00:39<00:19,  4.00it/s][A
 65%|██████▍   | 143/221 [00:39<00:19,  4.06it/s][A
 65%|██████▌   | 144/221 [00:40<00:21,  3.63it/s][A
 66%|██████▌   | 145/221 [00:40<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:41<00:23,  3.22it/s][A
 67%|██████▋   | 147/221 [00:41<00:20,  3.57it/s][A
 67%|██████▋   | 148/221 [00:41<00:20,  3.53it/s][A
 67%|██████▋   | 149/221 [00:41<00:19,  3.64it/s][A
 68%|██████▊   | 150/221 [00:42<00:19,  3.60it/s][A
 68%|██████▊   | 151/221 [00:43<00:34,  2.03it/s][A
 69%|██████▉   | 152/221 [00:43<00:40,  1.72it/s][A
 69%|██████▉   | 153/221 [00:44<00:31,  2.13it/s][A
 70%|██████▉   | 154/221 [00:44<00:26,  2.50it/s][A
 70%|███████   | 155/221 [00:44<00:28,  2.36it/s][A
 71%|███████   | 156/221 [00:45<00:25,  2.60it/s][A
 71%|███████   | 157/221 [00:45<00:22,  2.82it/s][A
 71%|███████▏  | 158/221 [00:45<00:26,  2.39it/s][A
 72%|███████▏  | 159/221 [00:46<00:20,  3.00it/s][A
 72%|███████▏  | 160/221 [00:46<00:20,  3.02it/s][A
 73%|███████▎  | 161/221 [00:46<00:18,  3.32it/s][A
 73%|███████▎  | 162/221 [00:46<00:15,  3.85it/s][A
 74%|███████▍  | 163/221 [00:46<00:14,  3.99it/s][A
 74%|███████▍  | 164/221 [00:47<00:12,  4.58it/s][A
 75%|███████▌  | 166/221 [00:47<00:12,  4.24it/s][A
 76%|███████▌  | 167/221 [00:47<00:11,  4.59it/s][A
 76%|███████▌  | 168/221 [00:48<00:11,  4.48it/s][A
 76%|███████▋  | 169/221 [00:48<00:11,  4.70it/s][A
 77%|███████▋  | 170/221 [00:48<00:16,  3.14it/s][A
 77%|███████▋  | 171/221 [00:49<00:20,  2.40it/s][A
 78%|███████▊  | 172/221 [00:49<00:16,  2.96it/s][A
 78%|███████▊  | 173/221 [00:49<00:14,  3.35it/s][A
 79%|███████▊  | 174/221 [00:50<00:12,  3.72it/s][A
 79%|███████▉  | 175/221 [00:50<00:12,  3.78it/s][A
 80%|███████▉  | 176/221 [00:50<00:10,  4.23it/s][A
 80%|████████  | 177/221 [00:50<00:10,  4.22it/s][A
 81%|████████  | 178/221 [00:51<00:14,  2.97it/s][A
 81%|████████  | 179/221 [00:51<00:13,  3.02it/s][A
 82%|████████▏ | 181/221 [00:51<00:10,  3.94it/s][A
 82%|████████▏ | 182/221 [00:52<00:10,  3.80it/s][A
 83%|████████▎ | 183/221 [00:52<00:11,  3.37it/s][A
 83%|████████▎ | 184/221 [00:52<00:11,  3.23it/s][A
 84%|████████▎ | 185/221 [00:53<00:09,  3.61it/s][A
 84%|████████▍ | 186/221 [00:53<00:11,  3.16it/s][A
 85%|████████▍ | 187/221 [00:53<00:10,  3.28it/s][A
 85%|████████▌ | 188/221 [00:54<00:10,  3.16it/s][A
 86%|████████▌ | 189/221 [00:54<00:08,  3.65it/s][A
 86%|████████▌ | 190/221 [00:54<00:10,  2.98it/s][A
 86%|████████▋ | 191/221 [00:54<00:08,  3.72it/s][A
 87%|████████▋ | 192/221 [00:55<00:06,  4.16it/s][A
 87%|████████▋ | 193/221 [00:55<00:05,  4.83it/s][A
 88%|████████▊ | 194/221 [00:55<00:06,  4.12it/s][A
 88%|████████▊ | 195/221 [00:55<00:05,  4.44it/s][A
 89%|████████▊ | 196/221 [00:56<00:08,  2.80it/s][A
 89%|████████▉ | 197/221 [00:56<00:08,  2.72it/s][A
 90%|████████▉ | 198/221 [00:57<00:08,  2.73it/s][A
 90%|█████████ | 199/221 [00:57<00:06,  3.39it/s][A
 90%|█████████ | 200/221 [00:57<00:06,  3.35it/s][A
 91%|█████████ | 201/221 [00:57<00:05,  3.51it/s][A
 91%|█████████▏| 202/221 [00:58<00:05,  3.77it/s][A
 92%|█████████▏| 203/221 [00:58<00:04,  3.84it/s][A
 92%|█████████▏| 204/221 [00:58<00:04,  4.18it/s][A
 93%|█████████▎| 205/221 [00:58<00:04,  3.83it/s][A
 93%|█████████▎| 206/221 [00:59<00:04,  3.04it/s][A
 94%|█████████▎| 207/221 [00:59<00:04,  3.35it/s][A
 94%|█████████▍| 208/221 [00:59<00:03,  3.62it/s][A
 95%|█████████▍| 209/221 [01:00<00:03,  3.56it/s][A
 95%|█████████▌| 210/221 [01:00<00:02,  4.22it/s][A
 95%|█████████▌| 211/221 [01:00<00:02,  4.32it/s][A
 96%|█████████▌| 212/221 [01:00<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:01<00:02,  3.19it/s][A
 97%|█████████▋| 214/221 [01:01<00:02,  3.12it/s][A
 97%|█████████▋| 215/221 [01:01<00:01,  3.07it/s][A
 98%|█████████▊| 216/221 [01:02<00:01,  3.08it/s][A
 98%|█████████▊| 217/221 [01:02<00:01,  3.18it/s][A
 99%|█████████▊| 218/221 [01:02<00:00,  3.25it/s][A
 99%|█████████▉| 219/221 [01:03<00:00,  2.94it/s][A
100%|█████████▉| 220/221 [01:03<00:00,  3.46it/s][A
100%|██████████| 221/221 [01:03<00:00,  3.16it/s][A100%|██████████| 221/221 [01:03<00:00,  3.47it/s]
09/17/2024 01:33:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 349--===========

09/17/2024 01:33:29 - INFO - __main__ -   {'area_r1': 39.6, 'area_recall': '39.6/66.4/75.0', 'area_ravg': 60.3}
09/17/2024 01:33:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 349--===========

09/17/2024 01:33:29 - INFO - __main__ -   {'forward_r1': 37.6, 'forward_recall': '37.6/62.9/74.0', 'forward_ravg': 58.1}
09/17/2024 01:33:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 349--===========

09/17/2024 01:33:29 - INFO - __main__ -   {'area_video_r1': 40.3, 'area_video_recall': '40.3/67.6/78.5', 'area_video_ravg': 62.1}
09/17/2024 01:33:29 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 299=======

09/17/2024 01:33:29 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 01:33:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 349--===========

09/17/2024 01:33:29 - INFO - __main__ -   {'area_video_r1': 52.5, 'area_video_recall': '52.5/74.7/82.8', 'area_video_ravg': 70.0, 'area_video_back_r1': 50.6, 'area_video_back_recall': '50.6/74.1/81.4', 'area_video_back_ravg': 68.7}
09/17/2024 01:33:29 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 349=======

09/17/2024 01:33:29 - INFO - __main__ -   {'area_video_r1': 52.5, 'area_video_recall': '52.5/74.7/82.8', 'area_video_ravg': 70.0, 'area_video_back_r1': 50.6, 'area_video_back_recall': '50.6/74.1/81.4', 'area_video_back_ravg': 68.7}
09/17/2024 01:33:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 349--===========

09/17/2024 01:33:29 - INFO - __main__ -   {'video_r1': 36.0, 'video_recall': '36.0/64.8/74.1', 'video_ravg': 58.3}
09/17/2024 01:33:29 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 249=======

09/17/2024 01:33:29 - INFO - __main__ -   {'video_r1': 37.1, 'video_recall': '37.1/65.0/74.1', 'video_ravg': 58.7}
09/17/2024 01:33:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 349--===========

09/17/2024 01:33:29 - INFO - __main__ -   {'video_r1': 52.5, 'video_recall': '52.5/74.9/82.8', 'video_ravg': 70.1}
09/17/2024 01:33:29 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 349=======

09/17/2024 01:33:29 - INFO - __main__ -   {'video_r1': 52.5, 'video_recall': '52.5/74.9/82.8', 'video_ravg': 70.1}
09/17/2024 01:34:00 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.008596250787377357, 'loss_ret%tv%ta--finetune_area/loss_area': 1.4419143199920654, 'loss_ret%tv%ta--finetune_area/total_loss': 1.4505106210708618}
[h264 @ 0x5606ad263a40] mmco: unref short failure
 12%|█▏        | 350/2910 [2:12:16<96:31:06, 135.73s/it] 12%|█▏        | 351/2910 [2:12:20<68:17:32, 96.07s/it]  12%|█▏        | 352/2910 [2:12:24<48:39:31, 68.48s/it][h264 @ 0x56068ce24b80] mmco: unref short failure
 12%|█▏        | 353/2910 [2:12:28<34:55:30, 49.17s/it][h264 @ 0x55e1830a6d00] mmco: unref short failure
[h264 @ 0x55e1830a6d00] mmco: unref short failure
 12%|█▏        | 354/2910 [2:12:32<25:23:18, 35.76s/it][h264 @ 0x560693861e80] mmco: unref short failure
[h264 @ 0x560693861e80] mmco: unref short failure
[h264 @ 0x560693861e80] mmco: unref short failure
[h264 @ 0x560693861e80] mmco: unref short failure
 12%|█▏        | 355/2910 [2:12:38<18:52:53, 26.60s/it][h264 @ 0x5606ab123ec0] mmco: unref short failure
[h264 @ 0x5606ab123ec0] mmco: unref short failure
[h264 @ 0x55a269c77d80] mmco: unref short failure
[h264 @ 0x55a269c77d80] mmco: unref short failure
 12%|█▏        | 356/2910 [2:12:43<14:15:30, 20.10s/it] 12%|█▏        | 357/2910 [2:12:48<11:07:28, 15.69s/it][h264 @ 0x55a25cda4c40] mmco: unref short failure
 12%|█▏        | 358/2910 [2:12:54<9:02:14, 12.75s/it]  12%|█▏        | 359/2910 [2:12:59<7:28:28, 10.55s/it][h264 @ 0x55b4fbccb200] mmco: unref short failure
[h264 @ 0x55b4f4067980] mmco: unref short failure
 12%|█▏        | 360/2910 [2:13:05<6:22:01,  8.99s/it][h264 @ 0x56069b5c27c0] mmco: unref short failure
[h264 @ 0x56069b5c27c0] mmco: unref short failure
 12%|█▏        | 361/2910 [2:13:09<5:28:07,  7.72s/it] 12%|█▏        | 362/2910 [2:13:15<4:56:28,  6.98s/it] 12%|█▏        | 363/2910 [2:13:21<4:47:00,  6.76s/it] 13%|█▎        | 364/2910 [2:13:26<4:26:08,  6.27s/it][h264 @ 0x55b50b5824c0] mmco: unref short failure
[h264 @ 0x55b50b5824c0] mmco: unref short failure
[h264 @ 0x55b50b5824c0] mmco: unref short failure
[h264 @ 0x55b50b5824c0] mmco: unref short failure
[h264 @ 0x55b4f4762700] mmco: unref short failure
[h264 @ 0x55b4f4762700] mmco: unref short failure
 13%|█▎        | 365/2910 [2:13:32<4:22:57,  6.20s/it][h264 @ 0x5606a8d99e40] mmco: unref short failure
[h264 @ 0x5606a8d99e40] mmco: unref short failure
[h264 @ 0x55e190897e00] mmco: unref short failure
[h264 @ 0x55e190897e00] mmco: unref short failure
09/17/2024 01:35:37 - INFO - __main__ -   current idx 3bpzUtvVmrY.16 from finetune_area returns wrong image/video, use 28433 instead.
[h264 @ 0x55a2735b7f00] mmco: unref short failure
[h264 @ 0x55b4fc590040] mmco: unref short failure
[h264 @ 0x55b4fc590040] mmco: unref short failure
[h264 @ 0x55a25bd54e00] mmco: unref short failure
[h264 @ 0x55b4ff9b3040] mmco: unref short failure
[h264 @ 0x55a25bcb2d80] mmco: unref short failure
[h264 @ 0x55a25bcb2d80] mmco: unref short failure
[h264 @ 0x55b5006465c0] mmco: unref short failure
[h264 @ 0x55b5006465c0] mmco: unref short failure
[h264 @ 0x56069fce29c0] mmco: unref short failure
[h264 @ 0x56069fce29c0] mmco: unref short failure
[h264 @ 0x56069fce29c0] mmco: unref short failure
[h264 @ 0x56069fce29c0] mmco: unref short failure
[h264 @ 0x55b5153aa8c0] mmco: unref short failure
[h264 @ 0x55b5153aa8c0] mmco: unref short failure
[h264 @ 0x55e19c8ce540] mmco: unref short failure
[h264 @ 0x55e19c8ce540] mmco: unref short failure
 13%|█▎        | 366/2910 [2:14:26<14:24:11, 20.38s/it][h264 @ 0x55b50ca2f640] mmco: unref short failure
[h264 @ 0x5606ac389740] mmco: unref short failure
[h264 @ 0x56068eabe540] mmco: unref short failure
[h264 @ 0x56068eabe540] mmco: unref short failure
09/17/2024 01:36:22 - INFO - __main__ -   current idx Qvo7ULfoowQ.43 from finetune_area returns wrong image/video, use 120356 instead.
 13%|█▎        | 367/2910 [2:14:40<13:08:17, 18.60s/it][h264 @ 0x55a276bb3700] mmco: unref short failure
[h264 @ 0x55a276bb3700] mmco: unref short failure
[h264 @ 0x55a278930a80] mmco: unref short failure
[h264 @ 0x55a278930a80] mmco: unref short failure
[h264 @ 0x55e1a29fbb00] mmco: unref short failure
[h264 @ 0x55e1a29fbb00] mmco: unref short failure
[h264 @ 0x55b50ed205c0] mmco: unref short failure
 13%|█▎        | 368/2910 [2:14:50<11:20:49, 16.07s/it][h264 @ 0x56068bcb4840] mmco: unref short failure
[h264 @ 0x56068bcb4840] mmco: unref short failure
[h264 @ 0x55a25e154f40] mmco: unref short failure
 13%|█▎        | 369/2910 [2:14:56<9:04:54, 12.87s/it] [h264 @ 0x55b501587440] mmco: unref short failure
[h264 @ 0x55a278d86580] mmco: unref short failure
[h264 @ 0x55a278d86580] mmco: unref short failure
 13%|█▎        | 370/2910 [2:15:11<9:31:39, 13.50s/it][av1 @ 0x55b4f4b47a00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f4b47a00] Failed to get pixel format.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f4b47a00] Failed to get pixel format.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f4b47a00] Missing Sequence Header.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Missing Sequence Header.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Missing Sequence Header.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Missing Sequence Header.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Missing Sequence Header.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Missing Sequence Header.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Missing Sequence Header.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Missing Sequence Header.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Missing Sequence Header.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Missing Sequence Header.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Missing Sequence Header.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Missing Sequence Header.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Missing Sequence Header.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Missing Sequence Header.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Missing Sequence Header.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Missing Sequence Header.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Missing Sequence Header.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Missing Sequence Header.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[av1 @ 0x55b4f452ff00] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b4f452ff00] Failed to get pixel format.
[h264 @ 0x5606a14a5f00] mmco: unref short failure
[h264 @ 0x5606a14a5f00] mmco: unref short failure
 13%|█▎        | 371/2910 [2:15:17<7:56:44, 11.27s/it] 13%|█▎        | 372/2910 [2:15:22<6:41:14,  9.49s/it][h264 @ 0x55a26ef7da40] mmco: unref short failure
[h264 @ 0x55a26ef7da40] mmco: unref short failure
[h264 @ 0x55a26ef7da40] mmco: unref short failure
[h264 @ 0x55a25bd59f00] mmco: unref short failure
 13%|█▎        | 373/2910 [2:15:32<6:51:56,  9.74s/it][h264 @ 0x5606afaf7140] mmco: unref short failure
[h264 @ 0x56068d55f0c0] mmco: unref short failure
[h264 @ 0x56068d55f0c0] mmco: unref short failure
[h264 @ 0x56068d55f0c0] mmco: unref short failure
[h264 @ 0x56068d55f0c0] mmco: unref short failure
[h264 @ 0x55b4f403ed40] mmco: unref short failure
[h264 @ 0x55b4f403ed40] mmco: unref short failure
[h264 @ 0x55b4fff409c0] mmco: unref short failure
[h264 @ 0x55b4fff409c0] mmco: unref short failure
09/17/2024 01:37:43 - INFO - __main__ -   current idx budftLR432g.60 from finetune_area returns wrong image/video, use 61327 instead.
[h264 @ 0x56069281a400] mmco: unref short failure
[h264 @ 0x55a25bcd46c0] mmco: unref short failure
[h264 @ 0x55a25bcd46c0] mmco: unref short failure
[h264 @ 0x5606949d0640] mmco: unref short failure
[h264 @ 0x5606949d0640] mmco: unref short failure
09/17/2024 01:37:50 - INFO - __main__ -   current idx WwLGb5RDcG0.21 from finetune_area returns wrong image/video, use 84277 instead.
09/17/2024 01:37:53 - INFO - __main__ -   current idx JZAjDUTk1oc.91 from finetune_area returns wrong image/video, use 146093 instead.
[h264 @ 0x55e187a34a80] mmco: unref short failure
[h264 @ 0x55e19a740d00] mmco: unref short failure
[h264 @ 0x55e19a740d00] mmco: unref short failure
[h264 @ 0x55e19a740d00] mmco: unref short failure
09/17/2024 01:38:01 - INFO - __main__ -   current idx _-um52MYvA8.26 from finetune_area returns wrong image/video, use 60048 instead.
[h264 @ 0x55a25bd54e00] mmco: unref short failure
09/17/2024 01:38:16 - INFO - __main__ -   current idx ybadhoHjH4Q.28 from finetune_area returns wrong image/video, use 77530 instead.
[h264 @ 0x55e199ae8d40] mmco: unref short failure
[h264 @ 0x55e185e16240] mmco: unref short failure
[h264 @ 0x55e185e16240] mmco: unref short failure
[h264 @ 0x55a2607a2180] mmco: unref short failure
[h264 @ 0x55a2607a2180] mmco: unref short failure
[h264 @ 0x55a278a3cbc0] mmco: unref short failure
[h264 @ 0x55a278a3cbc0] mmco: unref short failure
 13%|█▎        | 374/2910 [2:16:56<22:33:22, 32.02s/it][h264 @ 0x5606a1831540] mmco: unref short failure
[h264 @ 0x55b4f3fc9880] mmco: unref short failure
[h264 @ 0x55b4f3fc9880] mmco: unref short failure
[h264 @ 0x55b4f4042c00] mmco: unref short failure
[h264 @ 0x55b4f4042c00] mmco: unref short failure
 13%|█▎        | 375/2910 [2:17:12<19:04:04, 27.08s/it][h264 @ 0x5606aaf7c500] mmco: unref short failure
[h264 @ 0x55a26ced8c40] mmco: unref short failure
[h264 @ 0x560693b556c0] mmco: unref short failure
[h264 @ 0x560693b556c0] mmco: unref short failure
 13%|█▎        | 376/2910 [2:17:21<15:15:10, 21.67s/it] 13%|█▎        | 377/2910 [2:17:27<11:51:57, 16.86s/it][h264 @ 0x55a275960f00] mmco: unref short failure
[h264 @ 0x55b4fee3bf40] mmco: unref short failure
[h264 @ 0x55b4fee3bf40] mmco: unref short failure
[h264 @ 0x55a25bd22380] mmco: unref short failure
[h264 @ 0x55a25bd22380] mmco: unref short failure
[h264 @ 0x55b4f4041bc0] mmco: unref short failure
[h264 @ 0x55b4f4041bc0] mmco: unref short failure
[h264 @ 0x55b4f4041bc0] mmco: unref short failure
[h264 @ 0x55b4f4041bc0] mmco: unref short failure
 13%|█▎        | 378/2910 [2:17:50<13:10:12, 18.73s/it][h264 @ 0x55b4f36122c0] mmco: unref short failure
[h264 @ 0x55b4f36122c0] mmco: unref short failure
[h264 @ 0x55b4f36122c0] mmco: unref short failure
[h264 @ 0x55b4f36122c0] mmco: unref short failure
 13%|█▎        | 379/2910 [2:17:55<10:23:51, 14.79s/it][h264 @ 0x55e1907434c0] mmco: unref short failure
[h264 @ 0x55b50980cec0] mmco: unref short failure
[h264 @ 0x55b50980cec0] mmco: unref short failure
[h264 @ 0x56069526fa40] mmco: unref short failure
 13%|█▎        | 380/2910 [2:18:03<8:52:28, 12.63s/it] [h264 @ 0x55e1830c0680] mmco: unref short failure
[h264 @ 0x55e1830c0680] mmco: unref short failure
[h264 @ 0x55b50be62700] mmco: unref short failure
 13%|█▎        | 381/2910 [2:18:08<7:19:44, 10.43s/it][h264 @ 0x55b50163ef00] mmco: unref short failure
[h264 @ 0x55b50163ef00] mmco: unref short failure
[h264 @ 0x55e18f99edc0] mmco: unref short failure
[h264 @ 0x55e18f99edc0] mmco: unref short failure
[h264 @ 0x55e1866833c0] mmco: unref short failure
[h264 @ 0x55e1866833c0] mmco: unref short failure
[h264 @ 0x55e184857dc0] mmco: unref short failure
[h264 @ 0x55e184857dc0] mmco: unref short failure
[h264 @ 0x55a27bbdd000] mmco: unref short failure
[h264 @ 0x55a27bbdd000] mmco: unref short failure
[h264 @ 0x55e195a8bc80] mmco: unref short failure
[h264 @ 0x55e195a8bc80] mmco: unref short failure
[h264 @ 0x55b4f3f39c80] mmco: unref short failure
[h264 @ 0x55b4f3f39c80] mmco: unref short failure
[h264 @ 0x55b511170c80] mmco: unref short failure
[h264 @ 0x56069ebe3e80] mmco: unref short failure
[h264 @ 0x56069ebe3e80] mmco: unref short failure
09/17/2024 01:40:37 - INFO - __main__ -   current idx VIh8Li4uUFk.0 from finetune_area returns wrong image/video, use 28920 instead.
[h264 @ 0x55b4f4065340] mmco: unref short failure
[h264 @ 0x55b4f4065340] mmco: unref short failure
[h264 @ 0x55e191da4740] mmco: unref short failure
[h264 @ 0x55a27643b3c0] mmco: unref short failure
[h264 @ 0x55a27643b3c0] mmco: unref short failure
[h264 @ 0x55a27643b3c0] mmco: unref short failure
[h264 @ 0x55a27643b3c0] mmco: unref short failure
[h264 @ 0x55a25e45f7c0] mmco: unref short failure
[h264 @ 0x55a25e45f7c0] mmco: unref short failure
[h264 @ 0x55a25e45f7c0] mmco: unref short failure
[h264 @ 0x55a25e45f7c0] mmco: unref short failure
[h264 @ 0x55a25bcd46c0] mmco: unref short failure
[h264 @ 0x56068c564940] mmco: unref short failure
[h264 @ 0x56068c564940] mmco: unref short failure
[h264 @ 0x55e1813dcb40] mmco: unref short failure
[h264 @ 0x5606a8e15ec0] mmco: unref short failure
[h264 @ 0x5606a8e15ec0] mmco: unref short failure
[h264 @ 0x5606a8e15ec0] mmco: unref short failure
[h264 @ 0x5606a8e15ec0] mmco: unref short failure
[h264 @ 0x5606a8e15ec0] mmco: unref short failure
[h264 @ 0x5606a8e15ec0] mmco: unref short failure
 13%|█▎        | 382/2910 [2:19:33<23:04:50, 32.87s/it][h264 @ 0x56069fd24640] mmco: unref short failure
[h264 @ 0x55e18946bd40] mmco: unref short failure
[h264 @ 0x55e18946bd40] mmco: unref short failure
 13%|█▎        | 383/2910 [2:19:46<18:49:11, 26.81s/it][h264 @ 0x5606a92c77c0] mmco: unref short failure
[h264 @ 0x55a25de3e500] mmco: unref short failure
[h264 @ 0x55a25de3e500] mmco: unref short failure
 13%|█▎        | 384/2910 [2:19:58<15:39:52, 22.32s/it][h264 @ 0x55b4f42adb80] mmco: unref short failure
 13%|█▎        | 385/2910 [2:20:03<12:01:50, 17.15s/it][h264 @ 0x55b507cb3040] mmco: unref short failure
[h264 @ 0x55b507cb3040] mmco: unref short failure
[h264 @ 0x55b507cb3040] mmco: unref short failure
[h264 @ 0x55b507cb3040] mmco: unref short failure
[h264 @ 0x55b4fe7187c0] mmco: unref short failure
[h264 @ 0x55b4fe7187c0] mmco: unref short failure
[h264 @ 0x56069e480280] mmco: unref short failure
[h264 @ 0x56069e480280] mmco: unref short failure
[h264 @ 0x55a25d126780] mmco: unref short failure
[h264 @ 0x55a25d126780] mmco: unref short failure
 13%|█▎        | 386/2910 [2:20:18<11:36:55, 16.57s/it] 13%|█▎        | 387/2910 [2:20:23<9:12:51, 13.15s/it] 09/17/2024 01:42:09 - INFO - __main__ -   current idx cUO419RDXpY.18 from finetune_area returns wrong image/video, use 142751 instead.
[h264 @ 0x55e18bff88c0] mmco: unref short failure
[h264 @ 0x55e18bff88c0] mmco: unref short failure
 13%|█▎        | 388/2910 [2:20:35<8:53:59, 12.70s/it] 13%|█▎        | 389/2910 [2:20:41<7:31:18, 10.74s/it][h264 @ 0x55b4f403ed40] mmco: unref short failure
09/17/2024 01:42:31 - INFO - __main__ -   current idx bFHOzJ5hSFg.79 from finetune_area returns wrong image/video, use 93857 instead.
09/17/2024 01:42:33 - INFO - __main__ -   current idx aan7-sOxqOc.37 from finetune_area returns wrong image/video, use 133099 instead.
[h264 @ 0x55a27be3ed80] mmco: unref short failure
[h264 @ 0x55a27be3ed80] mmco: unref short failure
[h264 @ 0x55a25bd16900] mmco: unref short failure
[h264 @ 0x55a265d3ec80] mmco: unref short failure
[h264 @ 0x55a265d3ec80] mmco: unref short failure
[h264 @ 0x55a265d3ec80] mmco: unref short failure
[h264 @ 0x55a265d3ec80] mmco: unref short failure
[h264 @ 0x55a269db5540] mmco: unref short failure
[h264 @ 0x55a269db5540] mmco: unref short failure
[h264 @ 0x5606af5de080] mmco: unref short failure
[h264 @ 0x5606af5de080] mmco: unref short failure
[h264 @ 0x55e182c16e40] mmco: unref short failure
[h264 @ 0x55e182c16e40] mmco: unref short failure
[h264 @ 0x55e19809af00] mmco: unref short failure
[h264 @ 0x55e19809af00] mmco: unref short failure
09/17/2024 01:43:09 - INFO - __main__ -   current idx ulxAF450jro.5 from finetune_area returns wrong image/video, use 50708 instead.
[h264 @ 0x55e1813dcb40] mmco: unref short failure
[h264 @ 0x55e1813dcb40] mmco: unref short failure
[h264 @ 0x55b50efaa000] mmco: unref short failure
[h264 @ 0x55b50efaa000] mmco: unref short failure
[h264 @ 0x55b50efaa000] mmco: unref short failure
[h264 @ 0x55b50efaa000] mmco: unref short failure
[h264 @ 0x55e183098d80] mmco: unref short failure
[h264 @ 0x5606a6818a00] mmco: unref short failure
[h264 @ 0x5606a6818a00] mmco: unref short failure
[h264 @ 0x55b4f44d8a80] mmco: unref short failure
 13%|█▎        | 390/2910 [2:21:58<21:26:15, 30.63s/it][h264 @ 0x55b4f7d7d340] mmco: unref short failure
[h264 @ 0x55b4f7d7d340] mmco: unref short failure
[h264 @ 0x55e1866833c0] mmco: unref short failure
[h264 @ 0x55e1866833c0] mmco: unref short failure
[h264 @ 0x55e1866833c0] mmco: unref short failure
[h264 @ 0x55e1866833c0] mmco: unref short failure
 13%|█▎        | 391/2910 [2:22:09<17:14:10, 24.63s/it] 13%|█▎        | 392/2910 [2:22:19<14:13:36, 20.34s/it][h264 @ 0x55b511170c80] mmco: unref short failure
[h264 @ 0x55b511170c80] mmco: unref short failure
[h264 @ 0x55b511170c80] mmco: unref short failure
 14%|█▎        | 393/2910 [2:22:27<11:33:21, 16.53s/it][h264 @ 0x55b507cecdc0] mmco: unref short failure
[h264 @ 0x55a267a2b780] mmco: unref short failure
[h264 @ 0x55a267a2b780] mmco: unref short failure
[h264 @ 0x55a267a2b780] mmco: unref short failure
[h264 @ 0x55a267a2b780] mmco: unref short failure
[h264 @ 0x55b4f4762700] mmco: unref short failure
[h264 @ 0x55b4f4762700] mmco: unref short failure
 14%|█▎        | 394/2910 [2:22:38<10:29:03, 15.00s/it][h264 @ 0x55e18f99edc0] mmco: unref short failure
[h264 @ 0x55e18f99edc0] mmco: unref short failure
[h264 @ 0x55a26bf15040] mmco: unref short failure
[h264 @ 0x55a26bf15040] mmco: unref short failure
[h264 @ 0x55a26bf15040] mmco: unref short failure
[h264 @ 0x55a26bf15040] mmco: unref short failure
[h264 @ 0x5606a681f680] mmco: unref short failure
[h264 @ 0x5606a681f680] mmco: unref short failure
[h264 @ 0x56068e0b1800] mmco: unref short failure
[h264 @ 0x56068dbd2980] mmco: unref short failure
[h264 @ 0x56068dbd2980] mmco: unref short failure
[h264 @ 0x56068dbd2980] mmco: unref short failure
[h264 @ 0x56068dbd2980] mmco: unref short failure
 14%|█▎        | 395/2910 [2:22:57<11:11:45, 16.03s/it][h264 @ 0x56068dbd2980] mmco: unref short failure
[h264 @ 0x56068dbd2980] mmco: unref short failure
[h264 @ 0x55b513b91740] mmco: unref short failure
[h264 @ 0x56069fd36f40] mmco: unref short failure
[h264 @ 0x55a25cb81300] mmco: unref short failure
[h264 @ 0x55a25cb81300] mmco: unref short failure
[h264 @ 0x55a25cb81300] mmco: unref short failure
[h264 @ 0x55a25cb81300] mmco: unref short failure
[h264 @ 0x5606ad26f280] mmco: unref short failure
[h264 @ 0x5606ad26f280] mmco: unref short failure
 14%|█▎        | 396/2910 [2:23:06<9:46:55, 14.01s/it] [h264 @ 0x55e183038800] mmco: unref short failure
 14%|█▎        | 397/2910 [2:23:11<7:55:02, 11.34s/it][h264 @ 0x5606ace17bc0] mmco: unref short failure
[h264 @ 0x5606ace17bc0] mmco: unref short failure
[h264 @ 0x5606959603c0] mmco: unref short failure
[h264 @ 0x56069f0ef580] mmco: unref short failure
[h264 @ 0x55b4fb25aa40] mmco: unref short failure
[h264 @ 0x55b4fb25aa40] mmco: unref short failure
[h264 @ 0x55b4f82f15c0] mmco: unref short failure
[h264 @ 0x55b4f82f15c0] mmco: unref short failure
[h264 @ 0x55e189bf3fc0] mmco: unref short failure
[h264 @ 0x55e189bf3fc0] mmco: unref short failure
[h264 @ 0x55a26b27e500] mmco: unref short failure
[h264 @ 0x55a26b27e500] mmco: unref short failure
[h264 @ 0x55a274aa0840] mmco: unref short failure
[h264 @ 0x55a274aa0840] mmco: unref short failure
[h264 @ 0x55a25bd462c0] mmco: unref short failure
[h264 @ 0x55a25bd462c0] mmco: unref short failure
[h264 @ 0x5606a375cac0] mmco: unref short failure
[h264 @ 0x55e1865ad9c0] mmco: unref short failure
[h264 @ 0x55e1865ad9c0] mmco: unref short failure
[h264 @ 0x55a2708d9e40] mmco: unref short failure
09/17/2024 01:45:48 - INFO - __main__ -   current idx eBDMGQmep9I.8 from finetune_area returns wrong image/video, use 47055 instead.
[h264 @ 0x560693ed3a00] mmco: unref short failure
[h264 @ 0x55e18885b240] mmco: unref short failure
[h264 @ 0x55e18885b240] mmco: unref short failure
[h264 @ 0x55e18885b240] mmco: unref short failure
[h264 @ 0x55e18885b240] mmco: unref short failure
[h264 @ 0x55a26b27e500] mmco: unref short failure
[h264 @ 0x55a2794b1fc0] mmco: unref short failure
[h264 @ 0x55a26ccbad80] mmco: unref short failure
[h264 @ 0x5606ad2f2ec0] mmco: unref short failure
 14%|█▎        | 398/2910 [2:24:28<21:35:59, 30.96s/it] 14%|█▎        | 399/2910 [2:24:33<16:15:16, 23.30s/it]09/17/2024 01:46:19 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 01:46:19 - INFO - __main__ -   start running ret%tva validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a25e199740] mmco: unref short failure
[h264 @ 0x55a25e199740] mmco: unref short failure
[h264 @ 0x55a2779864c0] mmco: unref short failure
[h264 @ 0x55a2779864c0] mmco: unref short failure
[h264 @ 0x560695583900] mmco: unref short failure
[h264 @ 0x55a276b843c0] mmco: unref short failure
[h264 @ 0x55a276b843c0] mmco: unref short failure
[h264 @ 0x55a276b843c0] mmco: unref short failure
[h264 @ 0x55a276b843c0] mmco: unref short failure
[h264 @ 0x55e1a671a200] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e1a2bd9a40] mmco: unref short failure
[h264 @ 0x55e1a2bd9a40] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
09/17/2024 01:47:12 - INFO - __main__ -   current idx YSb87fytH2o.16 from finetune_area returns wrong image/video, use 57613 instead.
[h264 @ 0x55b509a35cc0] mmco: unref short failure
[h264 @ 0x55e19d034d00] mmco: unref short failure
[h264 @ 0x55a25bd22380] mmco: unref short failure
[h264 @ 0x55a25bd22380] mmco: unref short failure
[h264 @ 0x55b513b91740] mmco: unref short failure
[h264 @ 0x55e189b48000] mmco: unref short failure
[h264 @ 0x55e189b48000] mmco: unref short failure
[h264 @ 0x55b50f548bc0] mmco: unref short failure
[h264 @ 0x5606938ac980] mmco: unref short failure
[h264 @ 0x5606938ac980] mmco: unref short failure
[h264 @ 0x55a26402e2c0] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A[h264 @ 0x56068daf58c0] mmco: unref short failure

  0%|          | 1/221 [00:00<03:13,  1.14it/s][A
  1%|          | 2/221 [00:01<02:42,  1.35it/s][A
  1%|▏         | 3/221 [00:01<02:11,  1.65it/s][A
  2%|▏         | 4/221 [00:02<01:50,  1.97it/s][A
  2%|▏         | 5/221 [00:02<01:44,  2.07it/s][A
  3%|▎         | 6/221 [00:03<01:29,  2.41it/s][A
  3%|▎         | 7/221 [00:03<01:28,  2.42it/s][A
  4%|▎         | 8/221 [00:03<01:34,  2.24it/s][A
  4%|▍         | 9/221 [00:04<01:30,  2.34it/s][A
  5%|▍         | 10/221 [00:04<01:41,  2.08it/s][A
  5%|▍         | 11/221 [00:05<01:30,  2.33it/s][A
  5%|▌         | 12/221 [00:06<01:55,  1.81it/s][A
  6%|▌         | 13/221 [00:06<01:47,  1.93it/s][A
  6%|▋         | 14/221 [00:07<02:12,  1.56it/s][A
  7%|▋         | 15/221 [00:07<01:42,  2.01it/s][A
  7%|▋         | 16/221 [00:08<01:36,  2.12it/s][A
  8%|▊         | 17/221 [00:08<01:53,  1.79it/s][A
  8%|▊         | 18/221 [00:09<01:40,  2.02it/s][A
  9%|▊         | 19/221 [00:09<01:16,  2.64it/s][A
  9%|▉         | 20/221 [00:09<01:05,  3.06it/s][A
 10%|▉         | 21/221 [00:09<01:02,  3.22it/s][A
 10%|▉         | 22/221 [00:09<00:53,  3.69it/s][A
 10%|█         | 23/221 [00:10<00:45,  4.38it/s][A
 11%|█         | 24/221 [00:10<00:39,  4.93it/s][A
 11%|█▏        | 25/221 [00:10<00:41,  4.73it/s][A
 12%|█▏        | 26/221 [00:11<01:03,  3.09it/s][A
 12%|█▏        | 27/221 [00:11<00:52,  3.70it/s][A
 13%|█▎        | 28/221 [00:11<01:09,  2.80it/s][A[h264 @ 0x55e182fe8680] mmco: unref short failure

 13%|█▎        | 29/221 [00:12<01:27,  2.19it/s][A
 14%|█▎        | 30/221 [00:12<01:21,  2.34it/s][A
 14%|█▍        | 31/221 [00:13<01:12,  2.61it/s][A
 14%|█▍        | 32/221 [00:13<00:57,  3.27it/s][A
 15%|█▍        | 33/221 [00:13<00:54,  3.44it/s][A
 15%|█▌        | 34/221 [00:13<00:50,  3.69it/s][A
 16%|█▌        | 35/221 [00:14<01:00,  3.09it/s][A
 16%|█▋        | 36/221 [00:14<01:09,  2.67it/s][A
 17%|█▋        | 37/221 [00:15<01:41,  1.82it/s][A
 17%|█▋        | 38/221 [00:15<01:33,  1.95it/s][A
 18%|█▊        | 39/221 [00:16<01:30,  2.02it/s][A
 18%|█▊        | 40/221 [00:16<01:29,  2.01it/s][A
 19%|█▊        | 41/221 [00:17<01:17,  2.33it/s][A
 19%|█▉        | 42/221 [00:17<01:22,  2.18it/s][A
 19%|█▉        | 43/221 [00:18<01:13,  2.41it/s][A
 20%|█▉        | 44/221 [00:18<01:02,  2.84it/s][A
 20%|██        | 45/221 [00:18<01:19,  2.21it/s][A
 21%|██        | 46/221 [00:19<01:14,  2.36it/s][A
 21%|██▏       | 47/221 [00:19<01:11,  2.43it/s][A
 22%|██▏       | 48/221 [00:19<00:58,  2.94it/s][A
 22%|██▏       | 49/221 [00:20<01:13,  2.34it/s][A
 23%|██▎       | 50/221 [00:20<01:13,  2.33it/s][A
 23%|██▎       | 51/221 [00:21<01:02,  2.74it/s][A
 24%|██▎       | 52/221 [00:21<00:54,  3.08it/s][A
 24%|██▍       | 53/221 [00:21<00:48,  3.44it/s][A[h264 @ 0x55a262d76540] mmco: unref short failure
[h264 @ 0x55a262d76540] mmco: unref short failure

 24%|██▍       | 54/221 [00:23<01:47,  1.55it/s][A
 25%|██▍       | 55/221 [00:23<01:30,  1.84it/s][A
 25%|██▌       | 56/221 [00:23<01:14,  2.21it/s][A
 26%|██▌       | 57/221 [00:23<01:04,  2.55it/s][A
 26%|██▌       | 58/221 [00:24<00:54,  3.00it/s][A
 27%|██▋       | 59/221 [00:24<00:49,  3.30it/s][A
 27%|██▋       | 60/221 [00:24<01:08,  2.35it/s][A
 28%|██▊       | 61/221 [00:25<00:59,  2.71it/s][A
 28%|██▊       | 62/221 [00:25<00:58,  2.70it/s][A
 29%|██▊       | 63/221 [00:25<00:55,  2.82it/s][A
 29%|██▉       | 64/221 [00:26<00:48,  3.21it/s][A
 29%|██▉       | 65/221 [00:26<00:45,  3.43it/s][A
 30%|██▉       | 66/221 [00:26<00:45,  3.42it/s][A
 30%|███       | 67/221 [00:27<01:08,  2.26it/s][A
 31%|███       | 68/221 [00:27<00:56,  2.71it/s][A[h264 @ 0x55e185cb9740] mmco: unref short failure
[h264 @ 0x55e185cb9740] mmco: unref short failure

 31%|███       | 69/221 [00:28<01:05,  2.33it/s][A
 32%|███▏      | 70/221 [00:28<00:55,  2.71it/s][A
 32%|███▏      | 71/221 [00:29<01:09,  2.15it/s][A
 33%|███▎      | 72/221 [00:29<01:04,  2.31it/s][A
 33%|███▎      | 73/221 [00:29<01:02,  2.37it/s][A
 33%|███▎      | 74/221 [00:30<00:55,  2.63it/s][A
 34%|███▍      | 75/221 [00:30<00:54,  2.68it/s][A
 34%|███▍      | 76/221 [00:30<00:43,  3.32it/s][A
 35%|███▍      | 77/221 [00:30<00:42,  3.42it/s][A
 35%|███▌      | 78/221 [00:31<00:44,  3.21it/s][A
 36%|███▌      | 79/221 [00:31<00:57,  2.48it/s][A
 36%|███▌      | 80/221 [00:32<00:51,  2.72it/s][A
 37%|███▋      | 81/221 [00:32<00:50,  2.79it/s][A
 37%|███▋      | 82/221 [00:33<01:08,  2.02it/s][A
 38%|███▊      | 83/221 [00:33<01:10,  1.95it/s][A
 38%|███▊      | 84/221 [00:34<01:02,  2.18it/s][A
 38%|███▊      | 85/221 [00:34<00:52,  2.59it/s][A
 39%|███▉      | 86/221 [00:34<00:54,  2.46it/s][A
 39%|███▉      | 87/221 [00:35<01:08,  1.95it/s][A
 40%|███▉      | 88/221 [00:36<01:11,  1.86it/s][A
 40%|████      | 89/221 [00:36<01:11,  1.84it/s][A
 41%|████      | 90/221 [00:37<01:09,  1.89it/s][A
 41%|████      | 91/221 [00:37<00:56,  2.28it/s][A
 42%|████▏     | 92/221 [00:37<00:50,  2.56it/s][A
 42%|████▏     | 93/221 [00:38<00:50,  2.52it/s][A
 43%|████▎     | 94/221 [00:38<00:42,  3.02it/s][A
 43%|████▎     | 95/221 [00:38<00:41,  3.02it/s][A
 43%|████▎     | 96/221 [00:39<00:39,  3.18it/s][A
 44%|████▍     | 97/221 [00:39<00:32,  3.83it/s][A
 44%|████▍     | 98/221 [00:39<00:31,  3.96it/s][A
 45%|████▍     | 99/221 [00:39<00:27,  4.50it/s][A
 45%|████▌     | 100/221 [00:39<00:26,  4.57it/s][A
 46%|████▌     | 101/221 [00:39<00:23,  5.02it/s][A
 46%|████▌     | 102/221 [00:40<00:26,  4.52it/s][A
 47%|████▋     | 103/221 [00:40<00:25,  4.57it/s][A
 47%|████▋     | 104/221 [00:40<00:25,  4.52it/s][A
 48%|████▊     | 105/221 [00:40<00:29,  3.92it/s][A
 48%|████▊     | 106/221 [00:41<00:46,  2.48it/s][A
 48%|████▊     | 107/221 [00:41<00:39,  2.86it/s][A
 49%|████▉     | 108/221 [00:42<00:39,  2.83it/s][A[h264 @ 0x560698bcb280] mmco: unref short failure
[h264 @ 0x560698bcb280] mmco: unref short failure

 49%|████▉     | 109/221 [00:42<00:44,  2.52it/s][A[h264 @ 0x55b4f403ed40] mmco: unref short failure

 50%|████▉     | 110/221 [00:43<00:51,  2.16it/s][A
 50%|█████     | 111/221 [00:43<00:52,  2.09it/s][A
 51%|█████     | 112/221 [00:44<00:43,  2.52it/s][A
 51%|█████     | 113/221 [00:44<00:41,  2.58it/s][A
 52%|█████▏    | 115/221 [00:44<00:27,  3.89it/s][A
 52%|█████▏    | 116/221 [00:46<01:16,  1.37it/s][A
 53%|█████▎    | 117/221 [00:47<01:05,  1.60it/s][A
 53%|█████▎    | 118/221 [00:47<00:55,  1.85it/s][A
 54%|█████▍    | 119/221 [00:47<00:51,  1.96it/s][A
 54%|█████▍    | 120/221 [00:48<00:49,  2.05it/s][A
 55%|█████▍    | 121/221 [00:48<00:39,  2.55it/s][A
 55%|█████▌    | 122/221 [00:48<00:33,  2.93it/s][A
 56%|█████▌    | 123/221 [00:48<00:29,  3.34it/s][A
 56%|█████▌    | 124/221 [00:49<00:27,  3.53it/s][A
 57%|█████▋    | 125/221 [00:49<00:29,  3.22it/s][A
 57%|█████▋    | 126/221 [00:49<00:29,  3.19it/s][A
 57%|█████▋    | 127/221 [00:50<00:36,  2.60it/s][A
 58%|█████▊    | 128/221 [00:50<00:36,  2.52it/s][A
 58%|█████▊    | 129/221 [00:50<00:29,  3.10it/s][A
 59%|█████▉    | 130/221 [00:51<00:29,  3.11it/s][A
 59%|█████▉    | 131/221 [00:51<00:26,  3.40it/s][A
 60%|█████▉    | 132/221 [00:51<00:23,  3.86it/s][A
 60%|██████    | 133/221 [00:52<00:31,  2.82it/s][A
 61%|██████    | 134/221 [00:52<00:30,  2.82it/s][A
 61%|██████    | 135/221 [00:52<00:28,  2.97it/s][A[h264 @ 0x56068f53ccc0] mmco: unref short failure
[h264 @ 0x56068f53ccc0] mmco: unref short failure

 62%|██████▏   | 136/221 [00:53<00:34,  2.47it/s][A
 62%|██████▏   | 137/221 [00:53<00:31,  2.70it/s][A
 62%|██████▏   | 138/221 [00:54<00:32,  2.56it/s][A
 63%|██████▎   | 139/221 [00:54<00:34,  2.38it/s][A
 63%|██████▎   | 140/221 [00:55<00:30,  2.65it/s][A
 64%|██████▍   | 141/221 [00:55<00:26,  3.05it/s][A
 64%|██████▍   | 142/221 [00:55<00:25,  3.13it/s][A
 65%|██████▍   | 143/221 [00:55<00:26,  2.94it/s][A
 65%|██████▌   | 144/221 [00:56<00:26,  2.87it/s][A
 66%|██████▌   | 145/221 [00:56<00:22,  3.41it/s][A
 66%|██████▌   | 146/221 [00:56<00:18,  4.02it/s][A
 67%|██████▋   | 147/221 [00:56<00:19,  3.85it/s][A
 67%|██████▋   | 148/221 [00:57<00:21,  3.42it/s][A[h264 @ 0x55a25e463300] mmco: unref short failure
[h264 @ 0x55a25e463300] mmco: unref short failure

 67%|██████▋   | 149/221 [00:57<00:19,  3.78it/s][A
 68%|██████▊   | 150/221 [00:57<00:19,  3.71it/s][A
 68%|██████▊   | 151/221 [00:58<00:30,  2.29it/s][A
 69%|██████▉   | 152/221 [01:00<00:55,  1.25it/s][A
 69%|██████▉   | 153/221 [01:00<00:45,  1.48it/s][A
 70%|██████▉   | 154/221 [01:00<00:36,  1.82it/s][A
 70%|███████   | 155/221 [01:01<00:29,  2.22it/s][A
 71%|███████   | 156/221 [01:01<00:25,  2.57it/s][A
 71%|███████   | 157/221 [01:01<00:29,  2.14it/s][A
 71%|███████▏  | 158/221 [01:02<00:27,  2.26it/s][A
 72%|███████▏  | 159/221 [01:02<00:23,  2.67it/s][A
 72%|███████▏  | 160/221 [01:02<00:23,  2.60it/s][A[h264 @ 0x5606aadb8940] mmco: unref short failure

 73%|███████▎  | 161/221 [01:03<00:18,  3.25it/s][A
 73%|███████▎  | 162/221 [01:03<00:20,  2.90it/s][A
 74%|███████▍  | 163/221 [01:03<00:19,  3.04it/s][A
 74%|███████▍  | 164/221 [01:04<00:23,  2.38it/s][A
 75%|███████▍  | 165/221 [01:04<00:18,  3.03it/s][A
 75%|███████▌  | 166/221 [01:05<00:23,  2.37it/s][A
 76%|███████▌  | 167/221 [01:05<00:19,  2.76it/s][A
 76%|███████▌  | 168/221 [01:05<00:21,  2.46it/s][A
 76%|███████▋  | 169/221 [01:06<00:18,  2.75it/s][A
 77%|███████▋  | 170/221 [01:06<00:19,  2.66it/s][A
 77%|███████▋  | 171/221 [01:06<00:18,  2.63it/s][A
 78%|███████▊  | 172/221 [01:07<00:15,  3.12it/s][A
 78%|███████▊  | 173/221 [01:07<00:14,  3.41it/s][A
 79%|███████▊  | 174/221 [01:07<00:13,  3.36it/s][A
 79%|███████▉  | 175/221 [01:08<00:17,  2.69it/s][A
 80%|███████▉  | 176/221 [01:08<00:15,  2.91it/s][A
 80%|████████  | 177/221 [01:08<00:13,  3.35it/s][A
 81%|████████  | 178/221 [01:08<00:11,  3.66it/s][A
 81%|████████  | 179/221 [01:09<00:14,  2.97it/s][A
 81%|████████▏ | 180/221 [01:09<00:12,  3.24it/s][A
 82%|████████▏ | 181/221 [01:09<00:11,  3.46it/s][A
 82%|████████▏ | 182/221 [01:10<00:09,  4.20it/s][A
 83%|████████▎ | 183/221 [01:10<00:08,  4.36it/s][A
 83%|████████▎ | 184/221 [01:10<00:09,  3.70it/s][A
 84%|████████▎ | 185/221 [01:10<00:08,  4.26it/s][A
 84%|████████▍ | 186/221 [01:11<00:09,  3.60it/s][A
 85%|████████▍ | 187/221 [01:11<00:09,  3.67it/s][A
 85%|████████▌ | 188/221 [01:11<00:09,  3.61it/s][A
 86%|████████▌ | 189/221 [01:12<00:11,  2.83it/s][A
 86%|████████▌ | 190/221 [01:12<00:12,  2.50it/s][A
 86%|████████▋ | 191/221 [01:12<00:09,  3.07it/s][A
 87%|████████▋ | 192/221 [01:13<00:08,  3.28it/s][A
 87%|████████▋ | 193/221 [01:13<00:07,  3.97it/s][A
 88%|████████▊ | 194/221 [01:13<00:10,  2.57it/s][A
 88%|████████▊ | 195/221 [01:14<00:09,  2.88it/s][A
 89%|████████▊ | 196/221 [01:14<00:11,  2.15it/s][A
 89%|████████▉ | 197/221 [01:15<00:09,  2.63it/s][A
 90%|████████▉ | 198/221 [01:15<00:08,  2.81it/s][A
 90%|█████████ | 199/221 [01:15<00:06,  3.29it/s][A
[h264 @ 0x55a25e974080] mmco: unref short failure
 90%|█████████ | 200/221 [01:16<00:07,  3.00it/s][A[h264 @ 0x55b4f4042c00] mmco: unref short failure

 91%|█████████ | 201/221 [01:16<00:06,  3.13it/s][A
 91%|█████████▏| 202/221 [01:16<00:05,  3.66it/s][A
 92%|█████████▏| 203/221 [01:16<00:04,  4.07it/s][A
 92%|█████████▏| 204/221 [01:17<00:04,  3.59it/s][A
 93%|█████████▎| 205/221 [01:17<00:04,  3.82it/s][A
 93%|█████████▎| 206/221 [01:17<00:06,  2.49it/s][A
 94%|█████████▎| 207/221 [01:18<00:05,  2.78it/s][A
 94%|█████████▍| 208/221 [01:18<00:03,  3.27it/s][A
 95%|█████████▍| 209/221 [01:18<00:03,  3.26it/s][A
 95%|█████████▌| 210/221 [01:18<00:03,  3.56it/s][A
 95%|█████████▌| 211/221 [01:19<00:03,  3.21it/s][A
 96%|█████████▌| 212/221 [01:19<00:02,  3.60it/s][A
 96%|█████████▋| 213/221 [01:19<00:02,  3.53it/s][A
 97%|█████████▋| 214/221 [01:20<00:02,  3.40it/s][A
 97%|█████████▋| 215/221 [01:20<00:01,  3.11it/s][A
 98%|█████████▊| 216/221 [01:20<00:01,  2.98it/s][A
 98%|█████████▊| 217/221 [01:21<00:01,  2.80it/s][A
 99%|█████████▊| 218/221 [01:21<00:01,  2.75it/s][A
 99%|█████████▉| 219/221 [01:22<00:00,  2.67it/s][A
100%|█████████▉| 220/221 [01:24<00:01,  1.04s/it][A
100%|██████████| 221/221 [01:24<00:00,  1.22it/s][A100%|██████████| 221/221 [01:24<00:00,  2.60it/s]
[h264 @ 0x55e185cb9740] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:05,  3.37it/s][A
  1%|          | 2/221 [00:00<01:07,  3.25it/s][A
  1%|▏         | 3/221 [00:00<01:06,  3.29it/s][A[h264 @ 0x5606a4680a80] mmco: unref short failure
[h264 @ 0x5606a4680a80] mmco: unref short failure

  2%|▏         | 4/221 [00:01<01:08,  3.16it/s][A
  2%|▏         | 5/221 [00:01<01:06,  3.24it/s][A
  3%|▎         | 6/221 [00:01<01:05,  3.29it/s][A
  3%|▎         | 7/221 [00:02<01:09,  3.06it/s][A
  4%|▎         | 8/221 [00:02<01:08,  3.09it/s][A
  4%|▍         | 9/221 [00:02<01:06,  3.18it/s][A
  5%|▍         | 10/221 [00:03<01:04,  3.25it/s][A
  5%|▍         | 11/221 [00:03<01:04,  3.28it/s][A
  5%|▌         | 12/221 [00:03<01:04,  3.25it/s][A
  6%|▌         | 13/221 [00:04<01:03,  3.29it/s][A
  6%|▋         | 14/221 [00:04<01:04,  3.23it/s][A
  7%|▋         | 15/221 [00:04<01:06,  3.08it/s][A
  7%|▋         | 16/221 [00:05<01:07,  3.04it/s][A
  8%|▊         | 17/221 [00:05<01:05,  3.10it/s][A
  8%|▊         | 18/221 [00:05<01:04,  3.14it/s][A
  9%|▊         | 19/221 [00:05<01:03,  3.17it/s][A
  9%|▉         | 20/221 [00:06<01:02,  3.21it/s][A
 10%|▉         | 21/221 [00:06<01:01,  3.24it/s][A
 10%|▉         | 22/221 [00:06<01:01,  3.25it/s][A[h264 @ 0x5606a4680a80] mmco: unref short failure

 10%|█         | 23/221 [00:07<01:00,  3.29it/s][A[h264 @ 0x5606a0c84380] mmco: unref short failure
[h264 @ 0x5606a0c84380] mmco: unref short failure

 11%|█         | 24/221 [00:07<00:59,  3.28it/s][A
 11%|█▏        | 25/221 [00:07<00:59,  3.32it/s][A
 12%|█▏        | 26/221 [00:08<00:58,  3.34it/s][A
 12%|█▏        | 27/221 [00:08<00:57,  3.35it/s][A
 13%|█▎        | 28/221 [00:08<00:57,  3.33it/s][A
 13%|█▎        | 29/221 [00:08<00:58,  3.30it/s][A
 14%|█▎        | 30/221 [00:09<00:59,  3.19it/s][A
 14%|█▍        | 31/221 [00:09<00:59,  3.20it/s][A
 14%|█▍        | 32/221 [00:09<00:58,  3.23it/s][A
 15%|█▍        | 33/221 [00:10<00:59,  3.18it/s][A
 15%|█▌        | 34/221 [00:10<00:57,  3.23it/s][A
 16%|█▌        | 35/221 [00:10<00:56,  3.28it/s][A
 16%|█▋        | 36/221 [00:11<00:55,  3.31it/s][A
 17%|█▋        | 37/221 [00:11<00:55,  3.34it/s][A
 17%|█▋        | 38/221 [00:11<00:54,  3.35it/s][A
 18%|█▊        | 39/221 [00:12<00:54,  3.37it/s][A
 18%|█▊        | 40/221 [00:12<00:53,  3.38it/s][A
 19%|█▊        | 41/221 [00:12<00:53,  3.37it/s][A
 19%|█▉        | 42/221 [00:12<00:54,  3.29it/s][A
 19%|█▉        | 43/221 [00:13<00:54,  3.25it/s][A
 20%|█▉        | 44/221 [00:13<00:54,  3.26it/s][A
 20%|██        | 45/221 [00:13<00:54,  3.26it/s][A
 21%|██        | 46/221 [00:14<00:53,  3.28it/s][A
 21%|██▏       | 47/221 [00:14<00:52,  3.31it/s][A
 22%|██▏       | 48/221 [00:14<00:53,  3.26it/s][A
 22%|██▏       | 49/221 [00:15<00:52,  3.28it/s][A
 23%|██▎       | 50/221 [00:15<00:51,  3.30it/s][A
 23%|██▎       | 51/221 [00:15<00:51,  3.31it/s][A
 24%|██▎       | 52/221 [00:15<00:50,  3.34it/s][A
 24%|██▍       | 53/221 [00:16<00:50,  3.36it/s][A
 24%|██▍       | 54/221 [00:16<00:49,  3.37it/s][A
 25%|██▍       | 55/221 [00:16<00:49,  3.34it/s][A
 25%|██▌       | 56/221 [00:17<00:49,  3.33it/s][A
 26%|██▌       | 57/221 [00:17<00:48,  3.35it/s][A
 26%|██▌       | 58/221 [00:17<00:48,  3.37it/s][A
 27%|██▋       | 59/221 [00:18<00:47,  3.38it/s][A
 27%|██▋       | 60/221 [00:18<00:48,  3.31it/s][A
 28%|██▊       | 61/221 [00:18<00:48,  3.30it/s][A
 28%|██▊       | 62/221 [00:18<00:48,  3.25it/s][A
 29%|██▊       | 63/221 [00:19<00:48,  3.26it/s][A
 29%|██▉       | 64/221 [00:19<00:47,  3.30it/s][A
 29%|██▉       | 65/221 [00:19<00:47,  3.31it/s][A
 30%|██▉       | 66/221 [00:20<00:46,  3.31it/s][A
 30%|███       | 67/221 [00:20<00:46,  3.30it/s][A
 31%|███       | 68/221 [00:20<00:45,  3.33it/s][A
 31%|███       | 69/221 [00:21<00:45,  3.30it/s][A
 32%|███▏      | 70/221 [00:21<00:45,  3.33it/s][A
 32%|███▏      | 71/221 [00:21<00:45,  3.32it/s][A
 33%|███▎      | 72/221 [00:21<00:44,  3.34it/s][A
 33%|███▎      | 73/221 [00:22<00:44,  3.36it/s][A
 33%|███▎      | 74/221 [00:22<00:43,  3.37it/s][A
 34%|███▍      | 75/221 [00:22<00:43,  3.36it/s][A
 34%|███▍      | 76/221 [00:23<00:43,  3.35it/s][A
 35%|███▍      | 77/221 [00:23<00:43,  3.33it/s][A
 35%|███▌      | 78/221 [00:23<00:43,  3.30it/s][A
 36%|███▌      | 79/221 [00:24<00:42,  3.31it/s][A
 36%|███▌      | 80/221 [00:24<00:42,  3.34it/s][A
 37%|███▋      | 81/221 [00:24<00:41,  3.36it/s][A
 37%|███▋      | 82/221 [00:24<00:41,  3.36it/s][A
 38%|███▊      | 83/221 [00:25<00:41,  3.36it/s][A
 38%|███▊      | 84/221 [00:25<00:40,  3.34it/s][A
 38%|███▊      | 85/221 [00:25<00:40,  3.32it/s][A
 39%|███▉      | 86/221 [00:26<00:40,  3.34it/s][A
 39%|███▉      | 87/221 [00:26<00:40,  3.31it/s][A
 40%|███▉      | 88/221 [00:26<00:40,  3.29it/s][A
 40%|████      | 89/221 [00:27<00:40,  3.29it/s][A
 41%|████      | 90/221 [00:27<00:39,  3.32it/s][A
 41%|████      | 91/221 [00:27<00:39,  3.29it/s][A
 42%|████▏     | 92/221 [00:28<00:39,  3.28it/s][A
 42%|████▏     | 93/221 [00:28<00:39,  3.28it/s][A[h264 @ 0x55b5065a5d40] mmco: unref short failure
[h264 @ 0x55b5065a5d40] mmco: unref short failure

 43%|████▎     | 94/221 [00:28<00:38,  3.27it/s][A
 43%|████▎     | 95/221 [00:28<00:39,  3.16it/s][A
 43%|████▎     | 96/221 [00:29<00:39,  3.20it/s][A
 44%|████▍     | 97/221 [00:29<00:38,  3.26it/s][A
 44%|████▍     | 98/221 [00:29<00:37,  3.26it/s][A
 45%|████▍     | 99/221 [00:30<00:37,  3.27it/s][A
 45%|████▌     | 100/221 [00:30<00:36,  3.31it/s][A
 46%|████▌     | 101/221 [00:30<00:36,  3.32it/s][A
 46%|████▌     | 102/221 [00:31<00:35,  3.34it/s][A
 47%|████▋     | 103/221 [00:31<00:35,  3.36it/s][A
 47%|████▋     | 104/221 [00:31<00:34,  3.37it/s][A
 48%|████▊     | 105/221 [00:31<00:34,  3.33it/s][A
 48%|████▊     | 106/221 [00:32<00:34,  3.35it/s][A
 48%|████▊     | 107/221 [00:32<00:34,  3.35it/s][A
 49%|████▉     | 108/221 [00:32<00:33,  3.36it/s][A
 49%|████▉     | 109/221 [00:33<00:33,  3.38it/s][A
 50%|████▉     | 110/221 [00:33<00:32,  3.38it/s][A
 50%|█████     | 111/221 [00:33<00:32,  3.35it/s][A
 51%|█████     | 112/221 [00:34<00:32,  3.37it/s][A
 51%|█████     | 113/221 [00:34<00:32,  3.32it/s][A
 52%|█████▏    | 114/221 [00:34<00:32,  3.33it/s][A
 52%|█████▏    | 115/221 [00:34<00:31,  3.35it/s][A
 52%|█████▏    | 116/221 [00:35<00:31,  3.36it/s][A
 53%|█████▎    | 117/221 [00:35<00:30,  3.37it/s][A
 53%|█████▎    | 118/221 [00:35<00:30,  3.38it/s][A
 54%|█████▍    | 119/221 [00:36<00:30,  3.38it/s][A
 54%|█████▍    | 120/221 [00:36<00:29,  3.39it/s][A
 55%|█████▍    | 121/221 [00:36<00:29,  3.39it/s][A
 55%|█████▌    | 122/221 [00:36<00:29,  3.40it/s][A
 56%|█████▌    | 123/221 [00:37<00:28,  3.40it/s][A
 56%|█████▌    | 124/221 [00:37<00:28,  3.40it/s][A
 57%|█████▋    | 125/221 [00:37<00:28,  3.40it/s][A
 57%|█████▋    | 126/221 [00:38<00:27,  3.40it/s][A
 57%|█████▋    | 127/221 [00:38<00:27,  3.40it/s][A
 58%|█████▊    | 128/221 [00:38<00:27,  3.40it/s][A
 58%|█████▊    | 129/221 [00:39<00:27,  3.40it/s][A
 59%|█████▉    | 130/221 [00:39<00:26,  3.41it/s][A
 59%|█████▉    | 131/221 [00:39<00:26,  3.41it/s][A
 60%|█████▉    | 132/221 [00:39<00:26,  3.41it/s][A
 60%|██████    | 133/221 [00:40<00:25,  3.41it/s][A
 61%|██████    | 134/221 [00:40<00:25,  3.41it/s][A
 61%|██████    | 135/221 [00:40<00:25,  3.41it/s][A
 62%|██████▏   | 136/221 [00:41<00:24,  3.41it/s][A
 62%|██████▏   | 137/221 [00:41<00:24,  3.41it/s][A
 62%|██████▏   | 138/221 [00:41<00:24,  3.41it/s][A
 63%|██████▎   | 139/221 [00:41<00:24,  3.42it/s][A
 63%|██████▎   | 140/221 [00:42<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:42<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:42<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:43<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:43<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:43<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:44<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:44<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:44<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:44<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:45<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:45<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:45<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:46<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:46<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:46<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:46<00:19,  3.42it/s][A
 71%|███████   | 157/221 [00:47<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:47<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:47<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:48<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:48<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:48<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:48<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:49<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:49<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:49<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:50<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:50<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:50<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:51<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:51<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:51<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:51<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:52<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:52<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:52<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:53<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:53<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:53<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:54<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:54<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:54<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:55<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:55<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:55<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:56<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:56<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:56<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:57<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:57<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:57<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:58<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:58<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:58<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:59<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:59<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:59<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [01:00<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [01:00<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [01:00<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:01<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:01<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:02<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:02<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:02<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:03<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:03<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:04<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:04<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:05<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:05<00:00,  2.62it/s][A
100%|█████████▉| 220/221 [01:05<00:00,  2.81it/s][A
100%|██████████| 221/221 [01:06<00:00,  2.97it/s][A100%|██████████| 221/221 [01:06<00:00,  3.34it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:26,  8.37it/s][A
  1%|          | 2/221 [00:00<01:01,  3.57it/s][A
  1%|▏         | 3/221 [00:01<01:34,  2.30it/s][A
  2%|▏         | 4/221 [00:01<01:14,  2.93it/s][A
  2%|▏         | 5/221 [00:01<01:02,  3.47it/s][A
  3%|▎         | 7/221 [00:01<00:53,  4.03it/s][A
  4%|▎         | 8/221 [00:02<00:57,  3.73it/s][A
  4%|▍         | 9/221 [00:02<00:54,  3.91it/s][A
  5%|▍         | 10/221 [00:02<00:59,  3.53it/s][A
  5%|▍         | 11/221 [00:03<00:57,  3.66it/s][A
  5%|▌         | 12/221 [00:03<00:56,  3.70it/s][A
  6%|▌         | 13/221 [00:04<01:37,  2.14it/s][A
  6%|▋         | 14/221 [00:04<01:16,  2.71it/s][A
  7%|▋         | 15/221 [00:04<01:14,  2.75it/s][A
  7%|▋         | 16/221 [00:05<01:17,  2.66it/s][A
  8%|▊         | 17/221 [00:05<01:21,  2.50it/s][A
  8%|▊         | 18/221 [00:06<01:21,  2.50it/s][A
  9%|▊         | 19/221 [00:06<01:04,  3.12it/s][A
  9%|▉         | 20/221 [00:06<01:03,  3.16it/s][A
 10%|▉         | 21/221 [00:06<00:54,  3.69it/s][A
 10%|▉         | 22/221 [00:06<00:50,  3.96it/s][A
 10%|█         | 23/221 [00:06<00:41,  4.80it/s][A
 11%|█         | 24/221 [00:07<00:37,  5.25it/s][A
 11%|█▏        | 25/221 [00:07<00:44,  4.39it/s][A
 12%|█▏        | 26/221 [00:07<00:52,  3.69it/s][A
 12%|█▏        | 27/221 [00:08<00:52,  3.66it/s][A
 13%|█▎        | 28/221 [00:08<01:01,  3.13it/s][A
 13%|█▎        | 29/221 [00:08<01:02,  3.05it/s][A
 14%|█▎        | 30/221 [00:09<01:00,  3.15it/s][A
 14%|█▍        | 31/221 [00:09<01:01,  3.08it/s][A
 14%|█▍        | 32/221 [00:09<00:54,  3.46it/s][A
 15%|█▍        | 33/221 [00:09<00:50,  3.73it/s][A
 15%|█▌        | 34/221 [00:10<00:49,  3.81it/s][A
 16%|█▌        | 35/221 [00:10<00:49,  3.75it/s][A
 16%|█▋        | 36/221 [00:10<00:52,  3.49it/s][A
 17%|█▋        | 37/221 [00:11<00:50,  3.63it/s][A
 17%|█▋        | 38/221 [00:11<00:50,  3.61it/s][A
 18%|█▊        | 39/221 [00:11<00:43,  4.19it/s][A
 18%|█▊        | 40/221 [00:11<00:46,  3.92it/s][A
 19%|█▊        | 41/221 [00:11<00:38,  4.67it/s][A
 19%|█▉        | 42/221 [00:12<00:37,  4.84it/s][A
 19%|█▉        | 43/221 [00:12<00:44,  4.00it/s][A
 20%|█▉        | 44/221 [00:12<00:40,  4.37it/s][A
 20%|██        | 45/221 [00:12<00:49,  3.55it/s][A
 21%|██        | 46/221 [00:13<00:44,  3.96it/s][A
 22%|██▏       | 48/221 [00:13<00:31,  5.51it/s][A
 22%|██▏       | 49/221 [00:13<00:31,  5.53it/s][A
 23%|██▎       | 50/221 [00:13<00:34,  5.00it/s][A
 23%|██▎       | 51/221 [00:14<00:39,  4.26it/s][A
 24%|██▎       | 52/221 [00:14<00:34,  4.97it/s][A
 24%|██▍       | 53/221 [00:14<00:31,  5.36it/s][A
 24%|██▍       | 54/221 [00:14<00:34,  4.82it/s][A
 25%|██▍       | 55/221 [00:14<00:34,  4.88it/s][A
 25%|██▌       | 56/221 [00:15<00:34,  4.75it/s][A
 26%|██▌       | 57/221 [00:15<00:36,  4.55it/s][A
 26%|██▌       | 58/221 [00:15<00:33,  4.92it/s][A
 27%|██▋       | 59/221 [00:15<00:36,  4.47it/s][A
 27%|██▋       | 60/221 [00:16<00:37,  4.25it/s][A
 28%|██▊       | 61/221 [00:16<00:35,  4.45it/s][A
 28%|██▊       | 62/221 [00:16<00:37,  4.29it/s][A
 29%|██▊       | 63/221 [00:16<00:33,  4.71it/s][A
 29%|██▉       | 64/221 [00:16<00:34,  4.54it/s][A
 29%|██▉       | 65/221 [00:16<00:29,  5.30it/s][A
 30%|██▉       | 66/221 [00:17<00:33,  4.61it/s][A
 30%|███       | 67/221 [00:18<00:58,  2.64it/s][A
 31%|███       | 68/221 [00:18<00:51,  2.99it/s][A
 31%|███       | 69/221 [00:18<00:48,  3.11it/s][A
 32%|███▏      | 70/221 [00:18<00:41,  3.62it/s][A
 32%|███▏      | 71/221 [00:19<00:49,  3.03it/s][A
 33%|███▎      | 72/221 [00:19<00:54,  2.72it/s][A
 33%|███▎      | 73/221 [00:19<00:50,  2.94it/s][A
 33%|███▎      | 74/221 [00:20<00:49,  2.99it/s][A
 34%|███▍      | 75/221 [00:20<00:52,  2.78it/s][A
 34%|███▍      | 76/221 [00:20<00:41,  3.49it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.86it/s][A
 35%|███▌      | 78/221 [00:21<00:39,  3.62it/s][A
 36%|███▌      | 79/221 [00:21<00:40,  3.48it/s][A
 36%|███▌      | 80/221 [00:21<00:42,  3.32it/s][A
 37%|███▋      | 81/221 [00:22<00:40,  3.49it/s][A
 37%|███▋      | 82/221 [00:22<00:37,  3.71it/s][A
 38%|███▊      | 83/221 [00:22<00:35,  3.90it/s][A
 38%|███▊      | 84/221 [00:22<00:39,  3.45it/s][A
 38%|███▊      | 85/221 [00:23<00:43,  3.11it/s][A
 39%|███▉      | 86/221 [00:23<00:43,  3.08it/s][A
 39%|███▉      | 87/221 [00:24<00:58,  2.31it/s][A
 40%|███▉      | 88/221 [00:24<00:48,  2.75it/s][A
 40%|████      | 89/221 [00:24<00:48,  2.73it/s][A
 41%|████      | 90/221 [00:25<00:51,  2.56it/s][A
 41%|████      | 91/221 [00:25<00:42,  3.08it/s][A
 42%|████▏     | 92/221 [00:25<00:38,  3.31it/s][A
 42%|████▏     | 93/221 [00:26<00:42,  3.01it/s][A
 43%|████▎     | 94/221 [00:26<00:37,  3.39it/s][A
 43%|████▎     | 95/221 [00:27<00:46,  2.71it/s][A
 43%|████▎     | 96/221 [00:27<00:39,  3.13it/s][A
 44%|████▍     | 97/221 [00:27<00:38,  3.21it/s][A
 44%|████▍     | 98/221 [00:27<00:35,  3.49it/s][A
 45%|████▍     | 99/221 [00:27<00:31,  3.88it/s][A
 45%|████▌     | 100/221 [00:28<00:26,  4.56it/s][A
 46%|████▌     | 101/221 [00:28<00:30,  3.95it/s][A
 46%|████▌     | 102/221 [00:28<00:34,  3.48it/s][A
 47%|████▋     | 103/221 [00:28<00:31,  3.75it/s][A
 47%|████▋     | 104/221 [00:29<00:27,  4.24it/s][A
 48%|████▊     | 105/221 [00:29<00:26,  4.42it/s][A
 48%|████▊     | 106/221 [00:29<00:36,  3.17it/s][A
 48%|████▊     | 107/221 [00:30<00:32,  3.56it/s][A
 49%|████▉     | 108/221 [00:30<00:27,  4.14it/s][A
 49%|████▉     | 109/221 [00:30<00:29,  3.77it/s][A
 50%|████▉     | 110/221 [00:30<00:33,  3.32it/s][A
 50%|█████     | 111/221 [00:31<00:32,  3.37it/s][A
 51%|█████     | 112/221 [00:31<00:33,  3.24it/s][A
 51%|█████     | 113/221 [00:31<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:32<00:25,  4.15it/s][A
 52%|█████▏    | 116/221 [00:32<00:23,  4.39it/s][A
 53%|█████▎    | 117/221 [00:32<00:24,  4.32it/s][A
 53%|█████▎    | 118/221 [00:32<00:29,  3.54it/s][A
 54%|█████▍    | 119/221 [00:33<00:34,  2.96it/s][A
 54%|█████▍    | 120/221 [00:33<00:32,  3.12it/s][A
 55%|█████▌    | 122/221 [00:34<00:23,  4.13it/s][A
 56%|█████▌    | 123/221 [00:34<00:24,  3.99it/s][A
 56%|█████▌    | 124/221 [00:34<00:28,  3.38it/s][A
 57%|█████▋    | 125/221 [00:35<00:41,  2.29it/s][A
 57%|█████▋    | 126/221 [00:35<00:36,  2.62it/s][A
 57%|█████▋    | 127/221 [00:36<00:43,  2.17it/s][A
 58%|█████▊    | 128/221 [00:36<00:37,  2.51it/s][A
 58%|█████▊    | 129/221 [00:36<00:29,  3.17it/s][A
 59%|█████▉    | 130/221 [00:37<00:27,  3.29it/s][A
 59%|█████▉    | 131/221 [00:37<00:24,  3.74it/s][A
 60%|█████▉    | 132/221 [00:37<00:27,  3.29it/s][A
 60%|██████    | 133/221 [00:38<00:32,  2.67it/s][A
 61%|██████    | 134/221 [00:38<00:32,  2.67it/s][A
 61%|██████    | 135/221 [00:38<00:25,  3.37it/s][A
 62%|██████▏   | 136/221 [00:39<00:26,  3.22it/s][A
 62%|██████▏   | 137/221 [00:39<00:24,  3.39it/s][A
 62%|██████▏   | 138/221 [00:39<00:24,  3.40it/s][A
 63%|██████▎   | 139/221 [00:39<00:25,  3.18it/s][A
 63%|██████▎   | 140/221 [00:40<00:22,  3.53it/s][A
 64%|██████▍   | 141/221 [00:40<00:21,  3.71it/s][A
 64%|██████▍   | 142/221 [00:40<00:20,  3.88it/s][A
 65%|██████▍   | 143/221 [00:40<00:21,  3.64it/s][A
 65%|██████▌   | 144/221 [00:41<00:20,  3.71it/s][A
 66%|██████▌   | 145/221 [00:41<00:21,  3.62it/s][A
 66%|██████▌   | 146/221 [00:41<00:23,  3.20it/s][A
 67%|██████▋   | 147/221 [00:42<00:21,  3.47it/s][A
 67%|██████▋   | 148/221 [00:42<00:20,  3.49it/s][A
 67%|██████▋   | 149/221 [00:42<00:20,  3.60it/s][A
 68%|██████▊   | 150/221 [00:42<00:19,  3.62it/s][A
 68%|██████▊   | 151/221 [00:43<00:31,  2.22it/s][A
 69%|██████▉   | 152/221 [00:44<00:38,  1.81it/s][A
 69%|██████▉   | 153/221 [00:44<00:31,  2.16it/s][A
 70%|██████▉   | 154/221 [00:45<00:25,  2.60it/s][A
 70%|███████   | 155/221 [00:45<00:27,  2.37it/s][A
 71%|███████   | 156/221 [00:45<00:25,  2.56it/s][A
 71%|███████   | 157/221 [00:46<00:23,  2.67it/s][A
 71%|███████▏  | 158/221 [00:46<00:25,  2.49it/s][A
 72%|███████▏  | 159/221 [00:46<00:20,  3.03it/s][A
 72%|███████▏  | 160/221 [00:47<00:18,  3.32it/s][A
 73%|███████▎  | 161/221 [00:47<00:16,  3.54it/s][A
 73%|███████▎  | 162/221 [00:47<00:14,  4.16it/s][A
 74%|███████▍  | 163/221 [00:47<00:13,  4.20it/s][A
 74%|███████▍  | 164/221 [00:47<00:11,  4.79it/s][A
 75%|███████▍  | 165/221 [00:47<00:09,  5.62it/s][A
 75%|███████▌  | 166/221 [00:48<00:13,  4.06it/s][A
 76%|███████▌  | 167/221 [00:48<00:11,  4.67it/s][A
 76%|███████▌  | 168/221 [00:48<00:12,  4.38it/s][A
 76%|███████▋  | 169/221 [00:48<00:11,  4.52it/s][A
 77%|███████▋  | 170/221 [00:49<00:20,  2.54it/s][A
 77%|███████▋  | 171/221 [00:50<00:21,  2.29it/s][A
 78%|███████▊  | 172/221 [00:50<00:17,  2.81it/s][A
 78%|███████▊  | 173/221 [00:50<00:15,  3.06it/s][A
 79%|███████▊  | 174/221 [00:50<00:13,  3.40it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.31it/s][A
 80%|███████▉  | 176/221 [00:51<00:12,  3.72it/s][A
 80%|████████  | 177/221 [00:51<00:11,  3.89it/s][A
 81%|████████  | 178/221 [00:52<00:15,  2.87it/s][A
 81%|████████  | 179/221 [00:52<00:14,  2.92it/s][A
 82%|████████▏ | 181/221 [00:52<00:10,  3.81it/s][A
 82%|████████▏ | 182/221 [00:53<00:10,  3.75it/s][A
 83%|████████▎ | 183/221 [00:53<00:10,  3.66it/s][A
 83%|████████▎ | 184/221 [00:53<00:09,  3.70it/s][A
 84%|████████▎ | 185/221 [00:54<00:09,  3.65it/s][A
 84%|████████▍ | 186/221 [00:54<00:10,  3.24it/s][A
 85%|████████▍ | 187/221 [00:54<00:10,  3.31it/s][A
 85%|████████▌ | 188/221 [00:55<00:11,  2.93it/s][A
 86%|████████▌ | 189/221 [00:55<00:09,  3.39it/s][A
 86%|████████▌ | 190/221 [00:55<00:11,  2.79it/s][A
 87%|████████▋ | 192/221 [00:56<00:07,  3.71it/s][A
 87%|████████▋ | 193/221 [00:56<00:06,  4.21it/s][A
 88%|████████▊ | 194/221 [00:56<00:07,  3.67it/s][A
 88%|████████▊ | 195/221 [00:56<00:06,  4.25it/s][A
 89%|████████▊ | 196/221 [00:57<00:08,  2.83it/s][A
 89%|████████▉ | 197/221 [00:57<00:08,  2.72it/s][A
 90%|████████▉ | 198/221 [00:58<00:08,  2.66it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.35it/s][A
 90%|█████████ | 200/221 [00:58<00:06,  3.33it/s][A
 91%|█████████ | 201/221 [00:58<00:05,  3.40it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.52it/s][A
 92%|█████████▏| 203/221 [00:59<00:04,  3.63it/s][A
 92%|█████████▏| 204/221 [00:59<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.70it/s][A
 93%|█████████▎| 206/221 [01:00<00:05,  2.99it/s][A
 94%|█████████▎| 207/221 [01:00<00:04,  3.27it/s][A
 94%|█████████▍| 208/221 [01:00<00:03,  3.50it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.40it/s][A
 95%|█████████▌| 210/221 [01:01<00:02,  3.99it/s][A
 95%|█████████▌| 211/221 [01:01<00:02,  4.20it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.36it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.09it/s][A
 97%|█████████▋| 214/221 [01:02<00:02,  3.05it/s][A
 97%|█████████▋| 215/221 [01:03<00:02,  2.91it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  2.97it/s][A
 98%|█████████▊| 217/221 [01:03<00:01,  3.11it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.33it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  2.98it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.48it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.12it/s][A100%|██████████| 221/221 [01:05<00:00,  3.40it/s]
09/17/2024 01:52:19 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 399--===========

09/17/2024 01:52:19 - INFO - __main__ -   {'area_r1': 39.9, 'area_recall': '39.9/66.4/75.5', 'area_ravg': 60.6}
09/17/2024 01:52:19 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 399--===========

09/17/2024 01:52:19 - INFO - __main__ -   {'forward_r1': 35.9, 'forward_recall': '35.9/64.4/74.9', 'forward_ravg': 58.4}
09/17/2024 01:52:19 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 399--===========

09/17/2024 01:52:19 - INFO - __main__ -   {'area_video_r1': 40.0, 'area_video_recall': '40.0/68.6/77.1', 'area_video_ravg': 61.9}
09/17/2024 01:52:19 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 299=======

09/17/2024 01:52:19 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 01:52:19 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 399--===========

09/17/2024 01:52:19 - INFO - __main__ -   {'area_video_r1': 54.0, 'area_video_recall': '54.0/74.4/82.9', 'area_video_ravg': 70.4, 'area_video_back_r1': 49.7, 'area_video_back_recall': '49.7/74.5/81.4', 'area_video_back_ravg': 68.6}
09/17/2024 01:52:19 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 399=======

09/17/2024 01:52:19 - INFO - __main__ -   {'area_video_r1': 54.0, 'area_video_recall': '54.0/74.4/82.9', 'area_video_ravg': 70.4, 'area_video_back_r1': 49.7, 'area_video_back_recall': '49.7/74.5/81.4', 'area_video_back_ravg': 68.6}
09/17/2024 01:52:19 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 399--===========

09/17/2024 01:52:19 - INFO - __main__ -   {'video_r1': 36.3, 'video_recall': '36.3/64.8/73.5', 'video_ravg': 58.2}
09/17/2024 01:52:19 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 249=======

09/17/2024 01:52:19 - INFO - __main__ -   {'video_r1': 37.1, 'video_recall': '37.1/65.0/74.1', 'video_ravg': 58.7}
09/17/2024 01:52:19 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 399--===========

09/17/2024 01:52:19 - INFO - __main__ -   {'video_r1': 53.6, 'video_recall': '53.6/75.6/83.3', 'video_ravg': 70.8}
09/17/2024 01:52:19 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 399=======

09/17/2024 01:52:19 - INFO - __main__ -   {'video_r1': 53.6, 'video_recall': '53.6/75.6/83.3', 'video_ravg': 70.8}
09/17/2024 01:52:49 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.010281790047883987, 'loss_ret%tv%ta--finetune_area/loss_area': 1.331146001815796, 'loss_ret%tv%ta--finetune_area/total_loss': 1.3414278030395508}
not have audios ua_Kowav7hg.20
 14%|█▎        | 400/2910 [2:31:06<93:30:13, 134.11s/it] 14%|█▍        | 401/2910 [2:31:09<66:10:19, 94.95s/it] [h264 @ 0x55e18e853a00] mmco: unref short failure
 14%|█▍        | 402/2910 [2:31:13<47:06:39, 67.62s/it] 14%|█▍        | 403/2910 [2:31:17<33:49:00, 48.56s/it] 14%|█▍        | 404/2910 [2:31:22<24:35:16, 35.32s/it] 14%|█▍        | 405/2910 [2:31:26<18:09:50, 26.10s/it] 14%|█▍        | 406/2910 [2:31:31<13:44:13, 19.75s/it] 14%|█▍        | 407/2910 [2:31:37<10:46:40, 15.50s/it][h264 @ 0x55b4f7027380] mmco: unref short failure
[h264 @ 0x55b4f7027380] mmco: unref short failure
[h264 @ 0x5606aa18c980] mmco: unref short failure
 14%|█▍        | 408/2910 [2:31:42<8:38:06, 12.42s/it]  14%|█▍        | 409/2910 [2:31:48<7:12:12, 10.37s/it] 14%|█▍        | 410/2910 [2:31:53<6:04:31,  8.75s/it][h264 @ 0x56069f244a00] mmco: unref short failure
[h264 @ 0x56069f244a00] mmco: unref short failure
[h264 @ 0x55e186684c80] mmco: unref short failure
[h264 @ 0x55e186684c80] mmco: unref short failure
 14%|█▍        | 411/2910 [2:31:59<5:32:07,  7.97s/it] 14%|█▍        | 412/2910 [2:32:04<4:59:20,  7.19s/it] 14%|█▍        | 413/2910 [2:32:09<4:32:05,  6.54s/it][h264 @ 0x5606a37c70c0] mmco: unref short failure
[h264 @ 0x5606a37c70c0] mmco: unref short failure
09/17/2024 01:53:56 - INFO - __main__ -   current idx ayNV3g3-K8g.35 from finetune_area returns wrong image/video, use 17312 instead.
[h264 @ 0x55e18f5682c0] mmco: unref short failure
[h264 @ 0x55e18f5682c0] mmco: unref short failure
 14%|█▍        | 414/2910 [2:32:14<4:13:48,  6.10s/it][h264 @ 0x55b4fe7187c0] mmco: unref short failure
 14%|█▍        | 415/2910 [2:32:19<4:00:08,  5.78s/it][h264 @ 0x56068bfc35c0] mmco: unref short failure
[h264 @ 0x55a25baf9000] mmco: unref short failure
[h264 @ 0x55a25baf9000] mmco: unref short failure
[h264 @ 0x55a25baf9000] mmco: unref short failure
[h264 @ 0x55a25baf9000] mmco: unref short failure
[h264 @ 0x5606aa6921c0] mmco: unref short failure
[h264 @ 0x55b50a013f80] mmco: unref short failure
[h264 @ 0x5606a889e3c0] mmco: unref short failure
[h264 @ 0x5606a889e3c0] mmco: unref short failure
[h264 @ 0x5606a889e3c0] mmco: unref short failure
[h264 @ 0x5606a889e3c0] mmco: unref short failure
[h264 @ 0x55b50aedcdc0] mmco: unref short failure
[h264 @ 0x55e19e5da280] mmco: unref short failure
[h264 @ 0x55e19e5da280] mmco: unref short failure
[h264 @ 0x55b50a013f80] mmco: unref short failure
[h264 @ 0x55b50a013f80] mmco: unref short failure
[h264 @ 0x55b50a013f80] mmco: unref short failure
[h264 @ 0x55b50a013f80] mmco: unref short failure
[h264 @ 0x560698c862c0] mmco: unref short failure
[h264 @ 0x55b50638a100] mmco: unref short failure
[h264 @ 0x55a27508d340] mmco: unref short failure
[h264 @ 0x55a27508d340] mmco: unref short failure
[h264 @ 0x55a27508d340] mmco: unref short failure
[h264 @ 0x55a27508d340] mmco: unref short failure
[h264 @ 0x55a2764909c0] mmco: unref short failure
[h264 @ 0x55b4fe7a6740] mmco: unref short failure
[h264 @ 0x55b4fe7a6740] mmco: unref short failure
 14%|█▍        | 416/2910 [2:33:11<13:30:08, 19.49s/it] 14%|█▍        | 417/2910 [2:33:28<12:59:30, 18.76s/it][h264 @ 0x55e18ccbf4c0] mmco: unref short failure
[h264 @ 0x55e1a8642700] mmco: unref short failure
[h264 @ 0x55e1a8642700] mmco: unref short failure
[h264 @ 0x55e182fe8680] mmco: unref short failure
[h264 @ 0x55e182fe8680] mmco: unref short failure
[h264 @ 0x55a2623bf040] mmco: unref short failure
[h264 @ 0x55a2623bf040] mmco: unref short failure
[h264 @ 0x55a26ccc0b40] mmco: unref short failure
 14%|█▍        | 418/2910 [2:33:48<13:13:01, 19.09s/it] 14%|█▍        | 419/2910 [2:33:53<10:16:29, 14.85s/it][h264 @ 0x5606a85f1b40] mmco: unref short failure
[h264 @ 0x5606a85f1b40] mmco: unref short failure
 14%|█▍        | 420/2910 [2:33:58<8:16:18, 11.96s/it] [h264 @ 0x56069b733c00] mmco: unref short failure
[h264 @ 0x56069b733c00] mmco: unref short failure
 14%|█▍        | 421/2910 [2:34:03<6:53:28,  9.97s/it] 15%|█▍        | 422/2910 [2:34:11<6:23:57,  9.26s/it] 15%|█▍        | 423/2910 [2:34:16<5:33:12,  8.04s/it][h264 @ 0x55b50a013f80] mmco: unref short failure
[h264 @ 0x55b50a013f80] mmco: unref short failure
[h264 @ 0x55b50a013f80] mmco: unref short failure
[h264 @ 0x560696bfc0c0] mmco: unref short failure
[h264 @ 0x560696bfc0c0] mmco: unref short failure
[h264 @ 0x55a26d5eab80] mmco: unref short failure
[h264 @ 0x55e183225000] mmco: unref short failure
[h264 @ 0x55b50ab72380] mmco: unref short failure
09/17/2024 01:56:31 - INFO - __main__ -   current idx 5kvk51WxHH4.68 from finetune_area returns wrong image/video, use 114661 instead.
[h264 @ 0x55b513b91740] mmco: unref short failure
[h264 @ 0x55b513b91740] mmco: unref short failure
[h264 @ 0x55b513b91740] mmco: unref short failure
[h264 @ 0x55b513b91740] mmco: unref short failure
[h264 @ 0x55a275784a40] mmco: unref short failure
[h264 @ 0x55a275784a40] mmco: unref short failure
[h264 @ 0x55b4f3f3c800] mmco: unref short failure
[h264 @ 0x55b4f3f3c800] mmco: unref short failure
[h264 @ 0x55e1895d5c80] mmco: unref short failure
[h264 @ 0x55b501f76240] mmco: unref short failure
[h264 @ 0x55b501f76240] mmco: unref short failure
[h264 @ 0x55b501f76240] mmco: unref short failure
[h264 @ 0x55b501f76240] mmco: unref short failure
[h264 @ 0x5606a12b8300] mmco: unref short failure
[h264 @ 0x5606a12b8300] mmco: unref short failure
[h264 @ 0x56069a65bd40] mmco: unref short failure
[h264 @ 0x55b4fbe2cb40] mmco: unref short failure
[h264 @ 0x55b4fbe2cb40] mmco: unref short failure
[h264 @ 0x55b5023a5f80] mmco: unref short failure
[h264 @ 0x55b5023a5f80] mmco: unref short failure
[h264 @ 0x55b5023a5f80] mmco: unref short failure
[h264 @ 0x55b5023a5f80] mmco: unref short failure
[h264 @ 0x55a2765b1480] mmco: unref short failure
[h264 @ 0x55a2765b1480] mmco: unref short failure
[h264 @ 0x55a2652957c0] mmco: unref short failure
[h264 @ 0x55a2652957c0] mmco: unref short failure
[h264 @ 0x55a2652957c0] mmco: unref short failure
[h264 @ 0x55a2652957c0] mmco: unref short failure
[h264 @ 0x56069eca5a00] mmco: unref short failure
[h264 @ 0x56069eca5a00] mmco: unref short failure
[h264 @ 0x55e1980d3b00] mmco: unref short failure
09/17/2024 01:57:13 - INFO - __main__ -   current idx JtVvdxUGRsg.70 from finetune_area returns wrong image/video, use 145939 instead.
[h264 @ 0x55b4f3f3f600] mmco: unref short failure
[h264 @ 0x5606a8e15ec0] mmco: unref short failure
[h264 @ 0x5606a8e15ec0] mmco: unref short failure
 15%|█▍        | 424/2910 [2:35:42<21:40:58, 31.40s/it] 15%|█▍        | 425/2910 [2:35:56<18:10:12, 26.32s/it][h264 @ 0x55a271130e40] mmco: unref short failure
[h264 @ 0x55a271130e40] mmco: unref short failure
[h264 @ 0x55e183041040] mmco: unref short failure
[h264 @ 0x55b4f58f9800] mmco: unref short failure
[h264 @ 0x55e18346c2c0] mmco: unref short failure
[h264 @ 0x55e18346c2c0] mmco: unref short failure
[h264 @ 0x56069ca7d900] mmco: unref short failure
[h264 @ 0x56069ca7d900] mmco: unref short failure
[h264 @ 0x55e18cf41440] mmco: unref short failure
 15%|█▍        | 426/2910 [2:36:26<18:44:49, 27.17s/it] 15%|█▍        | 427/2910 [2:36:31<14:12:38, 20.60s/it][h264 @ 0x55e183450040] mmco: unref short failure
[h264 @ 0x55e183450040] mmco: unref short failure
[h264 @ 0x56069ca7d900] mmco: unref short failure
[h264 @ 0x56069ca7d900] mmco: unref short failure
[h264 @ 0x55a25bc1fa80] mmco: unref short failure
 15%|█▍        | 428/2910 [2:36:38<11:28:45, 16.65s/it][h264 @ 0x55a25bcd5740] mmco: unref short failure
[h264 @ 0x55b4f44d8a80] mmco: unref short failure
[h264 @ 0x55b4f44d8a80] mmco: unref short failure
[h264 @ 0x55e190f91340] mmco: unref short failure
[h264 @ 0x56069a65bd40] mmco: unref short failure
[h264 @ 0x56069a65bd40] mmco: unref short failure
[h264 @ 0x55e190f91340] mmco: unref short failure
 15%|█▍        | 429/2910 [2:36:44<9:16:09, 13.45s/it] [h264 @ 0x56069b1e1000] mmco: unref short failure
[h264 @ 0x56069b1e1000] mmco: unref short failure
 15%|█▍        | 430/2910 [2:36:49<7:30:59, 10.91s/it] 15%|█▍        | 431/2910 [2:36:56<6:33:10,  9.52s/it][h264 @ 0x55a25bcd5740] mmco: unref short failure
[h264 @ 0x55a25bcd5740] mmco: unref short failure
[h264 @ 0x55b4f3f30b00] mmco: unref short failure
[h264 @ 0x55b507dca440] mmco: unref short failure
[h264 @ 0x55b4f4084100] mmco: unref short failure
[h264 @ 0x55b4f4084100] mmco: unref short failure
[h264 @ 0x55e183042580] mmco: unref short failure
[h264 @ 0x55e183042580] mmco: unref short failure
[h264 @ 0x55b4f40b4800] mmco: unref short failure
[h264 @ 0x55b4f40b4800] mmco: unref short failure
[h264 @ 0x55b4f5241580] mmco: unref short failure
[h264 @ 0x55a25bacfc40] mmco: unref short failure
[h264 @ 0x55a25be39800] mmco: unref short failure
[h264 @ 0x55a25be39800] mmco: unref short failure
[h264 @ 0x55e1830f2600] mmco: unref short failure
[h264 @ 0x55e1830f2600] mmco: unref short failure
[h264 @ 0x55b4f41564c0] mmco: unref short failure
[h264 @ 0x55b4f41564c0] mmco: unref short failure
[h264 @ 0x55a25bfcf580] mmco: unref short failure
[h264 @ 0x55a25bfcf580] mmco: unref short failure
[h264 @ 0x55b507dca440] mmco: unref short failure
[h264 @ 0x560698c862c0] mmco: unref short failure
[h264 @ 0x560698c862c0] mmco: unref short failure
[h264 @ 0x55a25baa94c0] mmco: unref short failure
 15%|█▍        | 432/2910 [2:38:12<20:20:16, 29.55s/it][h264 @ 0x55a25b156b40] mmco: unref short failure
[h264 @ 0x55a25b156b40] mmco: unref short failure
 15%|█▍        | 433/2910 [2:38:19<15:39:27, 22.76s/it][h264 @ 0x55e183105440] mmco: unref short failure
[h264 @ 0x55a26a8110c0] mmco: unref short failure
[h264 @ 0x55a26a8110c0] mmco: unref short failure
[h264 @ 0x55e183105440] mmco: unref short failure
[h264 @ 0x55a27c4026c0] mmco: unref short failure
[h264 @ 0x55a27c4026c0] mmco: unref short failure
[h264 @ 0x55b4f3660700] mmco: unref short failure
[h264 @ 0x55e1834bba40] mmco: unref short failure
[h264 @ 0x55e1834bba40] mmco: unref short failure
 15%|█▍        | 434/2910 [2:38:46<16:34:21, 24.10s/it]09/17/2024 02:00:33 - INFO - __main__ -   current idx hq2NNhzo-Lg.4 from finetune_area returns wrong image/video, use 114076 instead.
[h264 @ 0x560698c862c0] mmco: unref short failure
 15%|█▍        | 435/2910 [2:38:52<12:45:50, 18.57s/it] 15%|█▍        | 436/2910 [2:38:57<9:59:15, 14.53s/it] [h264 @ 0x55a25bbac2c0] mmco: unref short failure
 15%|█▌        | 437/2910 [2:39:16<10:53:31, 15.86s/it][h264 @ 0x56069246d5c0] mmco: unref short failure
 15%|█▌        | 438/2910 [2:39:21<8:40:48, 12.64s/it]  15%|█▌        | 439/2910 [2:39:26<7:14:25, 10.55s/it][h264 @ 0x55b4f3fae880] mmco: unref short failure
[h264 @ 0x55b4f3fae880] mmco: unref short failure
[h264 @ 0x55b4f3fae880] mmco: unref short failure
[h264 @ 0x55b4f407db40] mmco: unref short failure
[h264 @ 0x55b4f407db40] mmco: unref short failure
09/17/2024 02:01:28 - INFO - __main__ -   current idx 4ZmeUj7cFu4.36 from finetune_area returns wrong image/video, use 90779 instead.
[h264 @ 0x55a2764be3c0] mmco: unref short failure
[h264 @ 0x55a2764be3c0] mmco: unref short failure
[h264 @ 0x55a2764be3c0] mmco: unref short failure
[h264 @ 0x56069ec59680] mmco: unref short failure
[h264 @ 0x55a25bb2b6c0] mmco: unref short failure
[h264 @ 0x55a25bb2b6c0] mmco: unref short failure
[h264 @ 0x55b4f44d8a80] mmco: unref short failure
[h264 @ 0x55b4f44d8a80] mmco: unref short failure
[h264 @ 0x55b4f3fae880] mmco: unref short failure
[h264 @ 0x55b4f3fae880] mmco: unref short failure
[h264 @ 0x55b4f3fae880] mmco: unref short failure
[h264 @ 0x55b50617bb00] mmco: unref short failure
[h264 @ 0x55b50617bb00] mmco: unref short failure
[h264 @ 0x55e183165cc0] mmco: unref short failure
[h264 @ 0x55e183165cc0] mmco: unref short failure
[h264 @ 0x55a25bb40d40] mmco: unref short failure
[h264 @ 0x55a25bb40d40] mmco: unref short failure
 15%|█▌        | 440/2910 [2:40:30<18:11:20, 26.51s/it][h264 @ 0x55a25bbfab00] mmco: unref short failure
[h264 @ 0x55a25bbfab00] mmco: unref short failure
[h264 @ 0x55e1934ed300] mmco: unref short failure
[h264 @ 0x55e1934ed300] mmco: unref short failure
 15%|█▌        | 441/2910 [2:40:54<17:38:02, 25.71s/it]09/17/2024 02:02:41 - INFO - __main__ -   current idx g6Wl0SZpFMk.13 from finetune_area returns wrong image/video, use 141986 instead.
[h264 @ 0x55b5023a5f80] mmco: unref short failure
[h264 @ 0x55b5023a5f80] mmco: unref short failure
[h264 @ 0x55b5023a5f80] mmco: unref short failure
[h264 @ 0x55b5023a5f80] mmco: unref short failure
[h264 @ 0x55b5023a5f80] mmco: unref short failure
[h264 @ 0x55b5023a5f80] mmco: unref short failure
[h264 @ 0x55e1830ba040] mmco: unref short failure
[h264 @ 0x55e1830ba040] mmco: unref short failure
[h264 @ 0x55e19e63e340] mmco: unref short failure
[h264 @ 0x55e19e63e340] mmco: unref short failure
 15%|█▌        | 442/2910 [2:41:24<18:27:35, 26.93s/it][h264 @ 0x55b4f40077c0] mmco: unref short failure
 15%|█▌        | 443/2910 [2:41:30<14:04:55, 20.55s/it] 15%|█▌        | 444/2910 [2:41:35<10:55:05, 15.94s/it][h264 @ 0x55e19e63e340] mmco: unref short failure
 15%|█▌        | 445/2910 [2:41:47<10:03:55, 14.70s/it] 15%|█▌        | 446/2910 [2:41:52<8:10:47, 11.95s/it] 09/17/2024 02:03:40 - INFO - __main__ -   current idx Pj4BTw_2jIM.11 from finetune_area returns wrong image/video, use 88573 instead.
[h264 @ 0x55b4f4065340] mmco: unref short failure
 15%|█▌        | 447/2910 [2:41:58<6:51:42, 10.03s/it][h264 @ 0x560697aa6d40] mmco: unref short failure
[h264 @ 0x560697aa6d40] mmco: unref short failure
[h264 @ 0x55e183a87e00] mmco: unref short failure
[h264 @ 0x55e183a87e00] mmco: unref short failure
[h264 @ 0x55a25baebdc0] mmco: unref short failure
[h264 @ 0x55a25baebdc0] mmco: unref short failure
[h264 @ 0x56069a5325c0] mmco: unref short failure
[h264 @ 0x56069a5325c0] mmco: unref short failure
[h264 @ 0x55b4f3e7f740] mmco: unref short failure
[h264 @ 0x55b4f3e7f740] mmco: unref short failure
[h264 @ 0x55b4f3e7f740] mmco: unref short failure
[h264 @ 0x55b4f3e7f740] mmco: unref short failure
[h264 @ 0x55e182fd47c0] mmco: unref short failure
[h264 @ 0x55e182fd47c0] mmco: unref short failure
[h264 @ 0x5606aa56e3c0] mmco: unref short failure
[h264 @ 0x5606aa56e3c0] mmco: unref short failure
[h264 @ 0x5606aa56e3c0] mmco: unref short failure
[h264 @ 0x5606aa56e3c0] mmco: unref short failure
[h264 @ 0x5606a363e3c0] mmco: unref short failure
[h264 @ 0x55e18915c8c0] mmco: unref short failure
[h264 @ 0x55e18915c8c0] mmco: unref short failure
[h264 @ 0x55e183410780] mmco: unref short failure
[h264 @ 0x55e183410780] mmco: unref short failure
[h264 @ 0x55e183165cc0] mmco: unref short failure
 15%|█▌        | 448/2910 [2:42:59<17:24:06, 25.45s/it][h264 @ 0x55b4f9d72200] mmco: unref short failure
[h264 @ 0x55b4f411ff40] mmco: unref short failure
[h264 @ 0x55b4f411ff40] mmco: unref short failure
[h264 @ 0x55e1830f0600] mmco: unref short failure
[h264 @ 0x55e1830f0600] mmco: unref short failure
[h264 @ 0x55b5105cef00] mmco: unref short failure
[h264 @ 0x55a26a8110c0] mmco: unref short failure
[h264 @ 0x55a26a8110c0] mmco: unref short failure
[h264 @ 0x55e1830b6ec0] mmco: unref short failure
[h264 @ 0x55e1830b6ec0] mmco: unref short failure
[h264 @ 0x55e1830b6ec0] mmco: unref short failure
[h264 @ 0x55e1830b6ec0] mmco: unref short failure
[h264 @ 0x55a25c03c180] mmco: unref short failure
[h264 @ 0x55a25c03c180] mmco: unref short failure
[h264 @ 0x55b4f426f900] mmco: unref short failure
 15%|█▌        | 449/2910 [2:43:31<18:43:44, 27.40s/it]09/17/2024 02:05:17 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 02:05:17 - INFO - __main__ -   start running ret%tva validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55b5076f3bc0] mmco: unref short failure
[h264 @ 0x55b5076f3bc0] mmco: unref short failure
[h264 @ 0x55a25bf59ac0] mmco: unref short failure
[h264 @ 0x55a25bf59ac0] mmco: unref short failure
[h264 @ 0x55e19d52e5c0] mmco: unref short failure
[h264 @ 0x55e19d52e5c0] mmco: unref short failure
09/17/2024 02:06:50 - INFO - __main__ -   current idx WTKFIwRqMwk.18 from finetune_area returns wrong image/video, use 117529 instead.
[h264 @ 0x55b50ebac140] mmco: unref short failure
[h264 @ 0x55b50ebac140] mmco: unref short failure
[h264 @ 0x55b50ebac140] mmco: unref short failure
[h264 @ 0x55b50ebac140] mmco: unref short failure
[h264 @ 0x55b4f4247740] mmco: unref short failure
[h264 @ 0x55a25bbf0a00] mmco: unref short failure
[h264 @ 0x55a25bbf0a00] mmco: unref short failure
[h264 @ 0x55e18305be40] mmco: unref short failure
[h264 @ 0x55a25bb39240] mmco: unref short failure
[h264 @ 0x55a25bb39240] mmco: unref short failure
[h264 @ 0x55a25bb39240] mmco: unref short failure
[h264 @ 0x55a25bb39240] mmco: unref short failure
[h264 @ 0x55a25bb39240] mmco: unref short failure
[h264 @ 0x55b4f4037640] mmco: unref short failure
[h264 @ 0x55b4f4037640] mmco: unref short failure
[h264 @ 0x55b4f4037640] mmco: unref short failure
[h264 @ 0x55b4f4037640] mmco: unref short failure
[h264 @ 0x55e1830c3340] mmco: unref short failure
[h264 @ 0x55e1830c3340] mmco: unref short failure
[h264 @ 0x55a2679e32c0] mmco: unref short failure
[h264 @ 0x55a2679e32c0] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:52,  1.28it/s][A[h264 @ 0x55b5148fe0c0] mmco: unref short failure

  1%|          | 2/221 [00:01<02:44,  1.33it/s][A
  1%|▏         | 3/221 [00:01<01:55,  1.88it/s][A
  2%|▏         | 4/221 [00:01<01:25,  2.55it/s][A
  2%|▏         | 5/221 [00:02<01:12,  2.97it/s][A
  3%|▎         | 6/221 [00:02<01:00,  3.53it/s][A
  3%|▎         | 7/221 [00:02<00:57,  3.75it/s][A
  4%|▎         | 8/221 [00:03<01:09,  3.07it/s][A
  4%|▍         | 9/221 [00:03<01:08,  3.08it/s][A
  5%|▍         | 10/221 [00:04<01:29,  2.37it/s][A
  5%|▍         | 11/221 [00:04<01:18,  2.69it/s][A
  5%|▌         | 12/221 [00:05<01:39,  2.10it/s][A
  6%|▌         | 13/221 [00:05<01:32,  2.26it/s][A
  6%|▋         | 14/221 [00:06<02:04,  1.66it/s][A
  7%|▋         | 15/221 [00:06<01:38,  2.09it/s][A
  7%|▋         | 16/221 [00:06<01:32,  2.23it/s][A
  8%|▊         | 17/221 [00:07<01:45,  1.93it/s][A
  8%|▊         | 18/221 [00:07<01:30,  2.25it/s][A
  9%|▊         | 19/221 [00:07<01:10,  2.85it/s][A
  9%|▉         | 20/221 [00:08<01:05,  3.07it/s][A
 10%|▉         | 21/221 [00:08<00:59,  3.38it/s][A
 10%|▉         | 22/221 [00:08<00:51,  3.84it/s][A
 10%|█         | 23/221 [00:08<00:42,  4.67it/s][A
 11%|█         | 24/221 [00:08<00:39,  5.01it/s][A
 11%|█▏        | 25/221 [00:09<00:37,  5.27it/s][A
 12%|█▏        | 26/221 [00:09<00:56,  3.45it/s][A
 12%|█▏        | 27/221 [00:09<00:52,  3.68it/s][A[h264 @ 0x55b50617bac0] mmco: unref short failure

 13%|█▎        | 28/221 [00:10<01:15,  2.56it/s][A
 13%|█▎        | 29/221 [00:11<01:39,  1.92it/s][A
 14%|█▎        | 30/221 [00:11<01:24,  2.27it/s][A
 14%|█▍        | 31/221 [00:11<01:16,  2.49it/s][A
 14%|█▍        | 32/221 [00:12<00:59,  3.20it/s][A
 15%|█▍        | 33/221 [00:12<00:56,  3.30it/s][A
 15%|█▌        | 34/221 [00:12<00:50,  3.70it/s][A
 16%|█▌        | 35/221 [00:12<00:50,  3.65it/s][A[h264 @ 0x55e1a470fe40] mmco: unref short failure
[h264 @ 0x55e1a470fe40] mmco: unref short failure
[h264 @ 0x55e1a470fe40] mmco: unref short failure
[h264 @ 0x55e1a470fe40] mmco: unref short failure

 16%|█▋        | 36/221 [00:13<00:53,  3.47it/s][A09/17/2024 02:07:46 - INFO - __main__ -   current idx My9wyuAl8zM.76 from finetune_area returns wrong image/video, use 19048 instead.

 17%|█▋        | 37/221 [00:13<01:14,  2.47it/s][A
 17%|█▋        | 38/221 [00:14<01:17,  2.36it/s][A
 18%|█▊        | 39/221 [00:14<01:13,  2.48it/s][A
 18%|█▊        | 40/221 [00:14<01:08,  2.64it/s][A
 19%|█▊        | 41/221 [00:15<00:54,  3.28it/s][A[h264 @ 0x55e183042c80] mmco: unref short failure

 19%|█▉        | 42/221 [00:15<01:01,  2.90it/s][A
 19%|█▉        | 43/221 [00:15<00:56,  3.17it/s][A
 20%|█▉        | 44/221 [00:15<00:45,  3.85it/s][A
 20%|██        | 45/221 [00:16<01:24,  2.09it/s][A[h264 @ 0x55b50aedcdc0] mmco: unref short failure
[h264 @ 0x55b50aedcdc0] mmco: unref short failure

 21%|██        | 46/221 [00:17<01:18,  2.24it/s][A
 21%|██▏       | 47/221 [00:17<01:19,  2.20it/s][A
 22%|██▏       | 48/221 [00:17<01:01,  2.83it/s][A
 22%|██▏       | 49/221 [00:18<01:16,  2.25it/s][A
 23%|██▎       | 50/221 [00:18<01:19,  2.16it/s][A
 23%|██▎       | 51/221 [00:19<01:06,  2.57it/s][A
 24%|██▎       | 52/221 [00:19<00:57,  2.95it/s][A
 24%|██▍       | 53/221 [00:19<00:46,  3.60it/s][A
 24%|██▍       | 54/221 [00:21<01:53,  1.47it/s][A
 25%|██▍       | 55/221 [00:21<01:34,  1.75it/s][A
 25%|██▌       | 56/221 [00:21<01:21,  2.02it/s][A
 26%|██▌       | 57/221 [00:22<01:07,  2.44it/s][A
 26%|██▌       | 58/221 [00:22<00:57,  2.81it/s][A
 27%|██▋       | 59/221 [00:22<00:51,  3.14it/s][A
 27%|██▋       | 60/221 [00:23<01:04,  2.49it/s][A
 28%|██▊       | 61/221 [00:23<00:56,  2.84it/s][A
 28%|██▊       | 62/221 [00:23<00:52,  3.01it/s][A
 29%|██▊       | 63/221 [00:23<00:53,  2.97it/s][A
 29%|██▉       | 64/221 [00:24<00:45,  3.43it/s][A
 29%|██▉       | 65/221 [00:24<00:44,  3.53it/s][A
 30%|██▉       | 66/221 [00:24<00:49,  3.15it/s][A
 30%|███       | 67/221 [00:25<01:07,  2.30it/s][A
 31%|███       | 68/221 [00:25<00:56,  2.71it/s][A[h264 @ 0x55e198c90100] mmco: unref short failure
[h264 @ 0x55e198c90100] mmco: unref short failure

 31%|███       | 69/221 [00:26<01:09,  2.19it/s][A
 32%|███▏      | 70/221 [00:26<00:57,  2.64it/s][A
 32%|███▏      | 71/221 [00:27<01:14,  2.02it/s][A
 33%|███▎      | 72/221 [00:27<01:03,  2.36it/s][A
 33%|███▎      | 73/221 [00:27<00:59,  2.47it/s][A
 33%|███▎      | 74/221 [00:28<00:48,  3.04it/s][A
 34%|███▍      | 75/221 [00:28<00:50,  2.88it/s][A
 34%|███▍      | 76/221 [00:28<00:41,  3.51it/s][A
 35%|███▍      | 77/221 [00:28<00:39,  3.66it/s][A
 35%|███▌      | 78/221 [00:29<00:39,  3.58it/s][A
 36%|███▌      | 79/221 [00:29<00:49,  2.89it/s][A
 36%|███▌      | 80/221 [00:29<00:46,  3.01it/s][A
 37%|███▋      | 81/221 [00:30<00:42,  3.32it/s][A
 37%|███▋      | 82/221 [00:31<01:12,  1.93it/s][A
 38%|███▊      | 83/221 [00:31<01:11,  1.94it/s][A
 38%|███▊      | 84/221 [00:32<00:59,  2.28it/s][A
 38%|███▊      | 85/221 [00:32<00:49,  2.76it/s][A[h264 @ 0x55a25bf921c0] mmco: unref short failure

 39%|███▉      | 86/221 [00:32<00:46,  2.92it/s][A[h264 @ 0x55e1a470fe40] mmco: unref short failure

 39%|███▉      | 87/221 [00:33<00:55,  2.41it/s][A
 40%|███▉      | 88/221 [00:33<01:00,  2.20it/s][A
 40%|████      | 89/221 [00:34<01:09,  1.89it/s][A
 41%|████      | 90/221 [00:34<01:00,  2.15it/s][A
 41%|████      | 91/221 [00:34<00:51,  2.52it/s][A
 42%|████▏     | 92/221 [00:35<00:44,  2.88it/s][A
 42%|████▏     | 93/221 [00:35<00:47,  2.67it/s][A
 43%|████▎     | 94/221 [00:35<00:40,  3.13it/s][A
 43%|████▎     | 95/221 [00:36<00:43,  2.89it/s][A
 43%|████▎     | 96/221 [00:36<00:39,  3.20it/s][A
 44%|████▍     | 97/221 [00:36<00:34,  3.61it/s][A
 44%|████▍     | 98/221 [00:36<00:33,  3.69it/s][A
 45%|████▍     | 99/221 [00:37<00:31,  3.87it/s][A
 45%|████▌     | 100/221 [00:37<00:28,  4.18it/s][A
 46%|████▌     | 101/221 [00:37<00:24,  4.97it/s][A
 46%|████▌     | 102/221 [00:37<00:24,  4.80it/s][A
 47%|████▋     | 103/221 [00:37<00:22,  5.27it/s][A
 47%|████▋     | 104/221 [00:37<00:20,  5.77it/s][A
 48%|████▊     | 105/221 [00:38<00:22,  5.27it/s][A
 48%|████▊     | 106/221 [00:38<00:36,  3.18it/s][A
 48%|████▊     | 107/221 [00:39<00:36,  3.08it/s][A
 49%|████▉     | 108/221 [00:39<00:33,  3.38it/s][A
 49%|████▉     | 109/221 [00:39<00:36,  3.06it/s][A
 50%|████▉     | 110/221 [00:40<00:39,  2.78it/s][A
 50%|█████     | 111/221 [00:40<00:47,  2.34it/s][A
 51%|█████     | 112/221 [00:40<00:38,  2.85it/s][A
 51%|█████     | 113/221 [00:41<00:36,  2.98it/s][A
 52%|█████▏    | 114/221 [00:41<00:28,  3.75it/s][A
 52%|█████▏    | 115/221 [00:41<00:24,  4.32it/s][A09/17/2024 02:08:15 - INFO - __main__ -   current idx 0dGVRi4angY.7 from finetune_area returns wrong image/video, use 3133 instead.

 52%|█████▏    | 116/221 [00:44<02:01,  1.15s/it][A
 53%|█████▎    | 117/221 [00:45<01:35,  1.08it/s][A
 53%|█████▎    | 118/221 [00:45<01:17,  1.33it/s][A
 54%|█████▍    | 119/221 [00:45<01:01,  1.66it/s][A
 54%|█████▍    | 120/221 [00:46<00:53,  1.89it/s][A
 55%|█████▍    | 121/221 [00:46<00:40,  2.49it/s][A
 55%|█████▌    | 122/221 [00:46<00:33,  2.98it/s][A
 56%|█████▌    | 123/221 [00:46<00:28,  3.43it/s][A[h264 @ 0x55e19c71c640] mmco: unref short failure
[h264 @ 0x55e19c71c640] mmco: unref short failure

 56%|█████▌    | 124/221 [00:46<00:30,  3.15it/s][A
 57%|█████▋    | 125/221 [00:47<00:32,  2.94it/s][A
 57%|█████▋    | 126/221 [00:47<00:30,  3.14it/s][A
 57%|█████▋    | 127/221 [00:48<00:45,  2.07it/s][A
 58%|█████▊    | 128/221 [00:48<00:41,  2.22it/s][A
 58%|█████▊    | 129/221 [00:49<00:35,  2.57it/s][A
 59%|█████▉    | 130/221 [00:49<00:31,  2.86it/s][A
 59%|█████▉    | 131/221 [00:49<00:26,  3.35it/s][A
 60%|█████▉    | 132/221 [00:49<00:21,  4.14it/s][A
 60%|██████    | 133/221 [00:49<00:24,  3.60it/s][A
 61%|██████    | 134/221 [00:50<00:22,  3.85it/s][A
 61%|██████    | 135/221 [00:50<00:22,  3.87it/s][A
 62%|██████▏   | 136/221 [00:50<00:25,  3.39it/s][A
 62%|██████▏   | 137/221 [00:51<00:22,  3.67it/s][A
 62%|██████▏   | 138/221 [00:51<00:24,  3.32it/s][A
 63%|██████▎   | 139/221 [00:51<00:28,  2.93it/s][A
 63%|██████▎   | 140/221 [00:52<00:26,  3.05it/s][A
 64%|██████▍   | 141/221 [00:52<00:22,  3.53it/s][A
 64%|██████▍   | 142/221 [00:52<00:22,  3.50it/s][A[h264 @ 0x560692a7ce80] mmco: unref short failure

 65%|██████▍   | 143/221 [00:53<00:25,  3.12it/s][A
 65%|██████▌   | 144/221 [00:53<00:25,  3.08it/s][A
 66%|██████▌   | 145/221 [00:53<00:21,  3.55it/s][A
 66%|██████▌   | 146/221 [00:53<00:18,  4.10it/s][A
 67%|██████▋   | 147/221 [00:53<00:17,  4.33it/s][A
 67%|██████▋   | 148/221 [00:54<00:17,  4.26it/s][A
 67%|██████▋   | 149/221 [00:54<00:15,  4.74it/s][A
 68%|██████▊   | 150/221 [00:54<00:15,  4.55it/s][A
 68%|██████▊   | 151/221 [00:55<00:33,  2.08it/s][A
 69%|██████▉   | 152/221 [00:57<00:59,  1.15it/s][A
 69%|██████▉   | 153/221 [00:57<00:49,  1.38it/s][A
 70%|██████▉   | 154/221 [00:58<00:39,  1.69it/s][A
 70%|███████   | 155/221 [00:58<00:31,  2.13it/s][A
 71%|███████   | 156/221 [00:58<00:26,  2.48it/s][A
 71%|███████   | 157/221 [00:59<00:28,  2.28it/s][A
 71%|███████▏  | 158/221 [00:59<00:25,  2.48it/s][A
 72%|███████▏  | 159/221 [00:59<00:20,  3.01it/s][A
 72%|███████▏  | 160/221 [00:59<00:21,  2.87it/s][A
 73%|███████▎  | 161/221 [01:00<00:17,  3.47it/s][A
 73%|███████▎  | 162/221 [01:00<00:19,  2.96it/s][A
 74%|███████▍  | 163/221 [01:00<00:19,  2.96it/s][A
 74%|███████▍  | 164/221 [01:01<00:25,  2.26it/s][A
 75%|███████▍  | 165/221 [01:01<00:19,  2.83it/s][A
 75%|███████▌  | 166/221 [01:02<00:22,  2.50it/s][A
 76%|███████▌  | 167/221 [01:02<00:17,  3.04it/s][A
 76%|███████▌  | 168/221 [01:02<00:18,  2.83it/s][A
 76%|███████▋  | 169/221 [01:02<00:16,  3.15it/s][A
 77%|███████▋  | 170/221 [01:03<00:17,  2.94it/s][A
 77%|███████▋  | 171/221 [01:03<00:17,  2.82it/s][A
 78%|███████▊  | 172/221 [01:03<00:14,  3.35it/s][A
 78%|███████▊  | 173/221 [01:04<00:12,  3.78it/s][A
 79%|███████▊  | 174/221 [01:04<00:12,  3.76it/s][A
 79%|███████▉  | 175/221 [01:04<00:16,  2.78it/s][A
 80%|███████▉  | 176/221 [01:05<00:15,  2.89it/s][A
 80%|████████  | 177/221 [01:05<00:12,  3.59it/s][A
 81%|████████  | 178/221 [01:05<00:10,  4.21it/s][A
 81%|████████  | 179/221 [01:05<00:11,  3.52it/s][A
 81%|████████▏ | 180/221 [01:06<00:09,  4.15it/s][A
 82%|████████▏ | 181/221 [01:06<00:09,  4.07it/s][A
 82%|████████▏ | 182/221 [01:06<00:08,  4.65it/s][A
 83%|████████▎ | 183/221 [01:06<00:07,  5.18it/s][A
 83%|████████▎ | 184/221 [01:06<00:08,  4.55it/s][A09/17/2024 02:08:39 - INFO - __main__ -   current idx YejxNzlOkeM.23 from finetune_area returns wrong image/video, use 104493 instead.

 84%|████████▎ | 185/221 [01:07<00:07,  4.91it/s][A[h264 @ 0x560698d7a940] mmco: unref short failure

 84%|████████▍ | 186/221 [01:07<00:10,  3.39it/s][A
 85%|████████▍ | 187/221 [01:07<00:08,  3.87it/s][A
 85%|████████▌ | 188/221 [01:08<00:08,  3.90it/s][A
 86%|████████▌ | 189/221 [01:08<00:09,  3.28it/s][A
 86%|████████▌ | 190/221 [01:08<00:10,  2.95it/s][A
 86%|████████▋ | 191/221 [01:08<00:08,  3.57it/s][A
 87%|████████▋ | 192/221 [01:09<00:07,  3.80it/s][A
 88%|████████▊ | 194/221 [01:09<00:08,  3.11it/s][A
 88%|████████▊ | 195/221 [01:10<00:07,  3.71it/s][A
 89%|████████▊ | 196/221 [01:10<00:08,  2.79it/s][A
 89%|████████▉ | 197/221 [01:10<00:06,  3.43it/s][A
 90%|████████▉ | 198/221 [01:11<00:06,  3.34it/s][A
 90%|█████████ | 199/221 [01:11<00:05,  3.88it/s][A
 90%|█████████ | 200/221 [01:11<00:05,  3.95it/s][A
 91%|█████████ | 201/221 [01:11<00:05,  3.99it/s][A
 91%|█████████▏| 202/221 [01:12<00:04,  4.15it/s][A
 92%|█████████▏| 203/221 [01:12<00:03,  4.56it/s][A
 92%|█████████▏| 204/221 [01:12<00:04,  3.94it/s][A
 93%|█████████▎| 205/221 [01:12<00:03,  4.77it/s][A
 93%|█████████▎| 206/221 [01:13<00:05,  2.65it/s][A
 94%|█████████▎| 207/221 [01:13<00:04,  3.16it/s][A
 94%|█████████▍| 208/221 [01:13<00:03,  3.88it/s][A
 95%|█████████▍| 209/221 [01:14<00:03,  3.54it/s][A
 95%|█████████▌| 211/221 [01:14<00:02,  3.70it/s][A
 96%|█████████▌| 212/221 [01:14<00:02,  3.93it/s][A
 96%|█████████▋| 213/221 [01:14<00:02,  3.97it/s][A
 97%|█████████▋| 214/221 [01:15<00:01,  3.87it/s][A
 97%|█████████▋| 215/221 [01:15<00:01,  3.95it/s][A
 98%|█████████▊| 216/221 [01:15<00:01,  3.60it/s][A
 98%|█████████▊| 217/221 [01:16<00:01,  3.28it/s][A
 99%|█████████▊| 218/221 [01:16<00:00,  3.11it/s][A[h264 @ 0x55b4f4145f80] mmco: unref short failure

 99%|█████████▉| 219/221 [01:16<00:00,  3.53it/s][A
100%|█████████▉| 220/221 [01:19<00:01,  1.09s/it][A
100%|██████████| 221/221 [01:20<00:00,  1.17it/s][A100%|██████████| 221/221 [01:20<00:00,  2.76it/s]
[h264 @ 0x5606956a3500] mmco: unref short failure
[h264 @ 0x5606956a3500] mmco: unref short failure
[h264 @ 0x55a25bb909c0] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:05,  3.38it/s][A
  1%|          | 2/221 [00:00<01:04,  3.39it/s][A
  1%|▏         | 3/221 [00:00<01:05,  3.33it/s][A
  2%|▏         | 4/221 [00:01<01:04,  3.36it/s][A
  2%|▏         | 5/221 [00:01<01:03,  3.38it/s][A
  3%|▎         | 6/221 [00:01<01:03,  3.38it/s][A
  3%|▎         | 7/221 [00:02<01:03,  3.39it/s][A
  4%|▎         | 8/221 [00:02<01:02,  3.39it/s][A
  4%|▍         | 9/221 [00:02<01:02,  3.40it/s][A
  5%|▍         | 10/221 [00:02<01:02,  3.40it/s][A
  5%|▍         | 11/221 [00:03<01:01,  3.40it/s][A
  5%|▌         | 12/221 [00:03<01:01,  3.40it/s][A
  6%|▌         | 13/221 [00:03<01:01,  3.39it/s][A
  6%|▋         | 14/221 [00:04<01:01,  3.36it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.37it/s][A
  7%|▋         | 16/221 [00:04<01:00,  3.38it/s][A
  8%|▊         | 17/221 [00:05<01:00,  3.38it/s][A
  8%|▊         | 18/221 [00:05<01:01,  3.31it/s][A
  9%|▊         | 19/221 [00:05<01:01,  3.29it/s][A
  9%|▉         | 20/221 [00:05<01:02,  3.22it/s][A
 10%|▉         | 21/221 [00:06<01:02,  3.21it/s][A
 10%|▉         | 22/221 [00:06<01:01,  3.22it/s][A
 10%|█         | 23/221 [00:06<01:00,  3.28it/s][A
 11%|█         | 24/221 [00:07<01:00,  3.27it/s][A
 11%|█▏        | 25/221 [00:07<00:59,  3.31it/s][A
 12%|█▏        | 26/221 [00:07<00:58,  3.34it/s][A[h264 @ 0x55a275784a40] mmco: unref short failure
[h264 @ 0x55a275784a40] mmco: unref short failure

 12%|█▏        | 27/221 [00:08<00:57,  3.36it/s][A
 13%|█▎        | 28/221 [00:08<00:58,  3.30it/s][A
 13%|█▎        | 29/221 [00:08<00:57,  3.33it/s][A
 14%|█▎        | 30/221 [00:08<00:56,  3.35it/s][A
 14%|█▍        | 31/221 [00:09<00:56,  3.35it/s][A
 14%|█▍        | 32/221 [00:09<00:57,  3.28it/s][A
 15%|█▍        | 33/221 [00:09<00:58,  3.22it/s][A
 15%|█▌        | 34/221 [00:10<00:58,  3.22it/s][A[h264 @ 0x55e18306b440] mmco: unref short failure

 16%|█▌        | 35/221 [00:10<00:57,  3.25it/s][A
 16%|█▋        | 36/221 [00:10<00:56,  3.26it/s][A
 17%|█▋        | 37/221 [00:11<00:55,  3.30it/s][A
 17%|█▋        | 38/221 [00:11<00:54,  3.33it/s][A
 18%|█▊        | 39/221 [00:11<00:54,  3.34it/s][A
 18%|█▊        | 40/221 [00:12<00:54,  3.32it/s][A
 19%|█▊        | 41/221 [00:12<00:54,  3.33it/s][A
 19%|█▉        | 42/221 [00:12<00:53,  3.32it/s][A
 19%|█▉        | 43/221 [00:12<00:53,  3.34it/s][A
 20%|█▉        | 44/221 [00:13<00:53,  3.33it/s][A
 20%|██        | 45/221 [00:13<00:52,  3.35it/s][A
 21%|██        | 46/221 [00:13<00:52,  3.35it/s][A
 21%|██▏       | 47/221 [00:14<00:52,  3.31it/s][A
 22%|██▏       | 48/221 [00:14<00:52,  3.31it/s][A
 22%|██▏       | 49/221 [00:14<00:52,  3.29it/s][A
 23%|██▎       | 50/221 [00:15<00:52,  3.28it/s][A
 23%|██▎       | 51/221 [00:15<00:51,  3.28it/s][A
 24%|██▎       | 52/221 [00:15<00:51,  3.30it/s][A
 24%|██▍       | 53/221 [00:15<00:50,  3.33it/s][A
 24%|██▍       | 54/221 [00:16<00:50,  3.33it/s][A
 25%|██▍       | 55/221 [00:16<00:49,  3.32it/s][A
 25%|██▌       | 56/221 [00:16<00:50,  3.29it/s][A
 26%|██▌       | 57/221 [00:17<00:50,  3.25it/s][A
 26%|██▌       | 58/221 [00:17<00:49,  3.28it/s][A
 27%|██▋       | 59/221 [00:17<00:49,  3.28it/s][A
 27%|██▋       | 60/221 [00:18<00:48,  3.31it/s][A
 28%|██▊       | 61/221 [00:18<00:48,  3.31it/s][A
 28%|██▊       | 62/221 [00:18<00:47,  3.34it/s][A
 29%|██▊       | 63/221 [00:18<00:47,  3.32it/s][A
 29%|██▉       | 64/221 [00:19<00:46,  3.34it/s][A
 29%|██▉       | 65/221 [00:19<00:46,  3.35it/s][A
 30%|██▉       | 66/221 [00:19<00:46,  3.32it/s][A
 30%|███       | 67/221 [00:20<00:46,  3.34it/s][A
 31%|███       | 68/221 [00:20<00:45,  3.36it/s][A
 31%|███       | 69/221 [00:20<00:45,  3.37it/s][A
 32%|███▏      | 70/221 [00:21<00:44,  3.38it/s][A
 32%|███▏      | 71/221 [00:21<00:44,  3.39it/s][A
 33%|███▎      | 72/221 [00:21<00:44,  3.38it/s][A
 33%|███▎      | 73/221 [00:21<00:43,  3.39it/s][A
 33%|███▎      | 74/221 [00:22<00:43,  3.39it/s][A
 34%|███▍      | 75/221 [00:22<00:43,  3.34it/s][A
 34%|███▍      | 76/221 [00:22<00:43,  3.36it/s][A
 35%|███▍      | 77/221 [00:23<00:42,  3.36it/s][A
 35%|███▌      | 78/221 [00:23<00:42,  3.36it/s][A
 36%|███▌      | 79/221 [00:23<00:42,  3.38it/s][A
 36%|███▌      | 80/221 [00:24<00:41,  3.39it/s][A
 37%|███▋      | 81/221 [00:24<00:41,  3.39it/s][A
 37%|███▋      | 82/221 [00:24<00:40,  3.40it/s][A
 38%|███▊      | 83/221 [00:24<00:40,  3.40it/s][A
 38%|███▊      | 84/221 [00:25<00:40,  3.40it/s][A
 38%|███▊      | 85/221 [00:25<00:39,  3.40it/s][A
 39%|███▉      | 86/221 [00:25<00:39,  3.40it/s][A
 39%|███▉      | 87/221 [00:26<00:39,  3.41it/s][A
 40%|███▉      | 88/221 [00:26<00:39,  3.41it/s][A
 40%|████      | 89/221 [00:26<00:38,  3.41it/s][A
 41%|████      | 90/221 [00:26<00:38,  3.41it/s][A
 41%|████      | 91/221 [00:27<00:38,  3.41it/s][A
 42%|████▏     | 92/221 [00:27<00:37,  3.41it/s][A
 42%|████▏     | 93/221 [00:27<00:37,  3.41it/s][A
 43%|████▎     | 94/221 [00:28<00:37,  3.41it/s][A
 43%|████▎     | 95/221 [00:28<00:36,  3.41it/s][A
 43%|████▎     | 96/221 [00:28<00:36,  3.41it/s][A
 44%|████▍     | 97/221 [00:29<00:36,  3.41it/s][A
 44%|████▍     | 98/221 [00:29<00:36,  3.42it/s][A
 45%|████▍     | 99/221 [00:29<00:35,  3.42it/s][A
 45%|████▌     | 100/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 101/221 [00:30<00:35,  3.42it/s][A
 46%|████▌     | 102/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 104/221 [00:31<00:34,  3.42it/s][A
 48%|████▊     | 105/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 107/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 108/221 [00:32<00:33,  3.42it/s][A
 49%|████▉     | 109/221 [00:32<00:32,  3.42it/s][A
 50%|████▉     | 110/221 [00:32<00:32,  3.42it/s][A
 50%|█████     | 111/221 [00:33<00:32,  3.42it/s][A
 51%|█████     | 112/221 [00:33<00:31,  3.42it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 114/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:34<00:30,  3.42it/s][A
 52%|█████▏    | 116/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:35<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:35<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:36<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:37<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:38<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:38<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:39<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:40<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:40<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:41<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:42<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:43<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:44<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:45<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:45<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:45<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:46<00:18,  3.42it/s][A
 71%|███████   | 157/221 [00:46<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:47<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:47<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:48<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:48<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:49<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:49<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:50<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:50<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:51<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:52<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:52<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:54<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:55<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:55<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:57<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:57<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:57<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:59<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:02<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.42it/s][A100%|██████████| 221/221 [01:05<00:00,  3.39it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:28,  7.70it/s][A
  1%|          | 2/221 [00:00<01:01,  3.58it/s][A
  1%|▏         | 3/221 [00:01<01:22,  2.65it/s][A
  2%|▏         | 4/221 [00:01<01:07,  3.21it/s][A
  2%|▏         | 5/221 [00:01<00:58,  3.69it/s][A
  3%|▎         | 7/221 [00:01<00:50,  4.27it/s][A
  4%|▎         | 8/221 [00:02<00:53,  4.00it/s][A
  4%|▍         | 9/221 [00:02<00:52,  4.01it/s][A
  5%|▍         | 10/221 [00:02<00:56,  3.74it/s][A
  5%|▍         | 11/221 [00:02<00:52,  3.99it/s][A
  5%|▌         | 12/221 [00:03<00:50,  4.14it/s][A
  6%|▌         | 13/221 [00:03<01:30,  2.31it/s][A
  6%|▋         | 14/221 [00:04<01:11,  2.89it/s][A
  7%|▋         | 15/221 [00:04<01:12,  2.85it/s][A
  7%|▋         | 16/221 [00:04<01:13,  2.79it/s][A
  8%|▊         | 17/221 [00:05<01:20,  2.54it/s][A
  8%|▊         | 18/221 [00:05<01:18,  2.58it/s][A
  9%|▊         | 19/221 [00:05<01:05,  3.08it/s][A
  9%|▉         | 20/221 [00:06<01:04,  3.13it/s][A
 10%|▉         | 21/221 [00:06<00:54,  3.64it/s][A
 10%|▉         | 22/221 [00:06<00:50,  3.95it/s][A
 10%|█         | 23/221 [00:06<00:42,  4.69it/s][A
 11%|█         | 24/221 [00:06<00:38,  5.15it/s][A
 11%|█▏        | 25/221 [00:07<00:45,  4.33it/s][A
 12%|█▏        | 26/221 [00:07<00:52,  3.68it/s][A
 12%|█▏        | 27/221 [00:07<00:55,  3.49it/s][A
 13%|█▎        | 28/221 [00:08<01:03,  3.02it/s][A
 13%|█▎        | 29/221 [00:08<01:00,  3.15it/s][A
 14%|█▎        | 30/221 [00:08<00:58,  3.29it/s][A
 14%|█▍        | 31/221 [00:09<00:59,  3.17it/s][A
 14%|█▍        | 32/221 [00:09<00:51,  3.71it/s][A
 15%|█▍        | 33/221 [00:09<00:47,  3.98it/s][A
 15%|█▌        | 34/221 [00:09<00:46,  4.04it/s][A
 16%|█▌        | 35/221 [00:10<00:47,  3.88it/s][A
 16%|█▋        | 36/221 [00:10<00:49,  3.73it/s][A
 17%|█▋        | 37/221 [00:10<00:46,  3.92it/s][A
 17%|█▋        | 38/221 [00:10<00:50,  3.66it/s][A
 18%|█▊        | 39/221 [00:11<00:44,  4.12it/s][A
 18%|█▊        | 40/221 [00:11<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:11<00:42,  4.28it/s][A
 19%|█▉        | 42/221 [00:11<00:39,  4.54it/s][A
 19%|█▉        | 43/221 [00:12<00:45,  3.87it/s][A
 20%|█▉        | 44/221 [00:12<00:40,  4.35it/s][A
 20%|██        | 45/221 [00:12<00:47,  3.69it/s][A
 21%|██        | 46/221 [00:12<00:42,  4.08it/s][A
 22%|██▏       | 48/221 [00:13<00:30,  5.69it/s][A
 22%|██▏       | 49/221 [00:13<00:30,  5.58it/s][A
 23%|██▎       | 50/221 [00:13<00:35,  4.83it/s][A
 23%|██▎       | 51/221 [00:13<00:41,  4.12it/s][A
 24%|██▍       | 53/221 [00:14<00:32,  5.18it/s][A
 24%|██▍       | 54/221 [00:14<00:34,  4.91it/s][A
 25%|██▍       | 55/221 [00:14<00:31,  5.31it/s][A
 25%|██▌       | 56/221 [00:14<00:33,  4.86it/s][A
 26%|██▌       | 57/221 [00:14<00:36,  4.54it/s][A
 26%|██▌       | 58/221 [00:15<00:35,  4.55it/s][A
 27%|██▋       | 59/221 [00:15<00:36,  4.43it/s][A
 27%|██▋       | 60/221 [00:15<00:36,  4.39it/s][A
 28%|██▊       | 61/221 [00:15<00:35,  4.53it/s][A
 28%|██▊       | 62/221 [00:16<00:37,  4.29it/s][A
 29%|██▊       | 63/221 [00:16<00:35,  4.46it/s][A
 29%|██▉       | 64/221 [00:16<00:33,  4.75it/s][A
 29%|██▉       | 65/221 [00:16<00:28,  5.45it/s][A
 30%|██▉       | 66/221 [00:16<00:33,  4.63it/s][A
 30%|███       | 67/221 [00:17<00:58,  2.62it/s][A
 31%|███       | 68/221 [00:17<00:50,  3.03it/s][A
 31%|███       | 69/221 [00:18<00:49,  3.05it/s][A
 32%|███▏      | 70/221 [00:18<00:42,  3.55it/s][A
 32%|███▏      | 71/221 [00:18<00:47,  3.16it/s][A
 33%|███▎      | 72/221 [00:19<00:50,  2.94it/s][A
 33%|███▎      | 73/221 [00:19<00:46,  3.16it/s][A
 33%|███▎      | 74/221 [00:19<00:46,  3.16it/s][A
 34%|███▍      | 75/221 [00:20<00:50,  2.91it/s][A
 34%|███▍      | 76/221 [00:20<00:39,  3.67it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.88it/s][A
 35%|███▌      | 78/221 [00:20<00:37,  3.81it/s][A
 36%|███▌      | 79/221 [00:21<00:37,  3.77it/s][A
 36%|███▌      | 80/221 [00:21<00:40,  3.45it/s][A
 37%|███▋      | 81/221 [00:21<00:39,  3.55it/s][A
 37%|███▋      | 82/221 [00:21<00:37,  3.66it/s][A
 38%|███▊      | 83/221 [00:22<00:33,  4.11it/s][A
 38%|███▊      | 84/221 [00:22<00:35,  3.88it/s][A
 38%|███▊      | 85/221 [00:22<00:40,  3.39it/s][A
 39%|███▉      | 86/221 [00:23<00:39,  3.45it/s][A
 39%|███▉      | 87/221 [00:23<01:00,  2.23it/s][A
 40%|███▉      | 88/221 [00:24<00:49,  2.66it/s][A
 40%|████      | 89/221 [00:24<00:48,  2.71it/s][A
 41%|████      | 90/221 [00:24<00:51,  2.53it/s][A
 41%|████      | 91/221 [00:25<00:42,  3.07it/s][A
 42%|████▏     | 92/221 [00:25<00:39,  3.23it/s][A
 42%|████▏     | 93/221 [00:25<00:42,  3.04it/s][A
 43%|████▎     | 94/221 [00:25<00:36,  3.43it/s][A
 43%|████▎     | 95/221 [00:26<00:45,  2.78it/s][A
 43%|████▎     | 96/221 [00:26<00:39,  3.20it/s][A
 44%|████▍     | 97/221 [00:26<00:38,  3.18it/s][A
 44%|████▍     | 98/221 [00:27<00:35,  3.42it/s][A
 45%|████▍     | 99/221 [00:27<00:32,  3.70it/s][A
 45%|████▌     | 100/221 [00:27<00:27,  4.36it/s][A
 46%|████▌     | 101/221 [00:27<00:26,  4.51it/s][A
 46%|████▌     | 102/221 [00:28<00:30,  3.95it/s][A
 47%|████▋     | 103/221 [00:28<00:27,  4.24it/s][A
 47%|████▋     | 104/221 [00:28<00:25,  4.67it/s][A
 48%|████▊     | 105/221 [00:28<00:24,  4.74it/s][A
 48%|████▊     | 106/221 [00:29<00:33,  3.41it/s][A
 48%|████▊     | 107/221 [00:29<00:30,  3.77it/s][A
 49%|████▉     | 108/221 [00:29<00:25,  4.43it/s][A
 49%|████▉     | 109/221 [00:29<00:28,  3.97it/s][A
 50%|████▉     | 110/221 [00:30<00:34,  3.19it/s][A
 50%|█████     | 111/221 [00:30<00:34,  3.15it/s][A
 51%|█████     | 112/221 [00:30<00:34,  3.16it/s][A
 51%|█████     | 113/221 [00:31<00:31,  3.38it/s][A
 52%|█████▏    | 115/221 [00:31<00:26,  4.04it/s][A
 52%|█████▏    | 116/221 [00:31<00:24,  4.36it/s][A
 53%|█████▎    | 117/221 [00:31<00:24,  4.26it/s][A
 53%|█████▎    | 118/221 [00:32<00:28,  3.57it/s][A
 54%|█████▍    | 119/221 [00:32<00:33,  3.04it/s][A
 54%|█████▍    | 120/221 [00:33<00:33,  3.02it/s][A
 55%|█████▌    | 122/221 [00:33<00:24,  4.09it/s][A
 56%|█████▌    | 123/221 [00:33<00:24,  3.96it/s][A
 56%|█████▌    | 124/221 [00:34<00:29,  3.27it/s][A
 57%|█████▋    | 125/221 [00:34<00:43,  2.23it/s][A
 57%|█████▋    | 126/221 [00:35<00:37,  2.54it/s][A
 57%|█████▋    | 127/221 [00:35<00:43,  2.16it/s][A
 58%|█████▊    | 128/221 [00:36<00:37,  2.50it/s][A
 58%|█████▊    | 129/221 [00:36<00:28,  3.17it/s][A
 59%|█████▉    | 130/221 [00:36<00:26,  3.45it/s][A
 59%|█████▉    | 131/221 [00:36<00:22,  3.93it/s][A
 60%|█████▉    | 132/221 [00:36<00:25,  3.49it/s][A
 60%|██████    | 133/221 [00:37<00:31,  2.79it/s][A
 61%|██████    | 134/221 [00:37<00:29,  2.95it/s][A
 61%|██████    | 135/221 [00:37<00:23,  3.60it/s][A
 62%|██████▏   | 136/221 [00:38<00:25,  3.38it/s][A
 62%|██████▏   | 137/221 [00:38<00:23,  3.52it/s][A
 62%|██████▏   | 138/221 [00:38<00:24,  3.38it/s][A
 63%|██████▎   | 139/221 [00:39<00:26,  3.14it/s][A
 63%|██████▎   | 140/221 [00:39<00:23,  3.52it/s][A
 64%|██████▍   | 141/221 [00:39<00:22,  3.54it/s][A
 64%|██████▍   | 142/221 [00:39<00:21,  3.75it/s][A
 65%|██████▍   | 143/221 [00:40<00:23,  3.39it/s][A
 65%|██████▌   | 144/221 [00:40<00:21,  3.61it/s][A
 66%|██████▌   | 145/221 [00:40<00:21,  3.58it/s][A
 66%|██████▌   | 146/221 [00:41<00:22,  3.37it/s][A
 67%|██████▋   | 147/221 [00:41<00:20,  3.64it/s][A
 67%|██████▋   | 148/221 [00:41<00:18,  3.94it/s][A
 67%|██████▋   | 149/221 [00:41<00:18,  3.86it/s][A
 68%|██████▊   | 150/221 [00:42<00:18,  3.76it/s][A
 68%|██████▊   | 151/221 [00:42<00:29,  2.36it/s][A
 69%|██████▉   | 152/221 [00:43<00:35,  1.96it/s][A
 69%|██████▉   | 153/221 [00:43<00:29,  2.30it/s][A
 70%|██████▉   | 154/221 [00:44<00:24,  2.77it/s][A
 70%|███████   | 155/221 [00:44<00:26,  2.52it/s][A
 71%|███████   | 156/221 [00:44<00:24,  2.67it/s][A
 71%|███████   | 157/221 [00:45<00:23,  2.78it/s][A
 71%|███████▏  | 158/221 [00:45<00:23,  2.63it/s][A
 72%|███████▏  | 159/221 [00:45<00:19,  3.13it/s][A
 72%|███████▏  | 160/221 [00:45<00:17,  3.57it/s][A
 73%|███████▎  | 161/221 [00:46<00:15,  3.77it/s][A
 73%|███████▎  | 162/221 [00:46<00:13,  4.40it/s][A
 74%|███████▍  | 163/221 [00:46<00:13,  4.22it/s][A
 74%|███████▍  | 164/221 [00:46<00:11,  4.80it/s][A
 75%|███████▍  | 165/221 [00:46<00:10,  5.37it/s][A
 75%|███████▌  | 166/221 [00:47<00:13,  4.13it/s][A
 76%|███████▌  | 167/221 [00:47<00:11,  4.57it/s][A
 76%|███████▌  | 168/221 [00:47<00:12,  4.36it/s][A
 76%|███████▋  | 169/221 [00:47<00:11,  4.64it/s][A
 77%|███████▋  | 170/221 [00:48<00:19,  2.55it/s][A
 77%|███████▋  | 171/221 [00:49<00:21,  2.31it/s][A
 78%|███████▊  | 172/221 [00:49<00:17,  2.83it/s][A
 78%|███████▊  | 173/221 [00:49<00:16,  2.89it/s][A
 79%|███████▊  | 174/221 [00:49<00:14,  3.31it/s][A
 79%|███████▉  | 175/221 [00:50<00:14,  3.22it/s][A
 80%|███████▉  | 176/221 [00:50<00:12,  3.62it/s][A
 80%|████████  | 177/221 [00:50<00:11,  3.86it/s][A
 81%|████████  | 178/221 [00:51<00:13,  3.09it/s][A
 81%|████████  | 179/221 [00:51<00:13,  3.05it/s][A
 82%|████████▏ | 181/221 [00:51<00:10,  3.87it/s][A
 82%|████████▏ | 182/221 [00:52<00:09,  3.94it/s][A
 83%|████████▎ | 183/221 [00:52<00:10,  3.61it/s][A
 83%|████████▎ | 184/221 [00:52<00:10,  3.66it/s][A
 84%|████████▎ | 185/221 [00:52<00:10,  3.47it/s][A
 84%|████████▍ | 186/221 [00:53<00:12,  2.81it/s][A
 85%|████████▍ | 187/221 [00:53<00:11,  3.04it/s][A
 85%|████████▌ | 188/221 [00:54<00:10,  3.02it/s][A
 86%|████████▌ | 189/221 [00:54<00:09,  3.51it/s][A
 86%|████████▌ | 190/221 [00:54<00:11,  2.72it/s][A
 86%|████████▋ | 191/221 [00:54<00:08,  3.41it/s][A
 87%|████████▋ | 192/221 [00:55<00:07,  3.81it/s][A
 87%|████████▋ | 193/221 [00:55<00:06,  4.64it/s][A
 88%|████████▊ | 194/221 [00:55<00:06,  3.94it/s][A
 88%|████████▊ | 195/221 [00:55<00:05,  4.42it/s][A
 89%|████████▊ | 196/221 [00:56<00:09,  2.73it/s][A
 89%|████████▉ | 197/221 [00:56<00:08,  2.69it/s][A
 90%|████████▉ | 198/221 [00:57<00:08,  2.56it/s][A
 90%|█████████ | 199/221 [00:57<00:06,  3.20it/s][A
 90%|█████████ | 200/221 [00:57<00:06,  3.19it/s][A
 91%|█████████ | 201/221 [00:57<00:05,  3.43it/s][A
 91%|█████████▏| 202/221 [00:58<00:05,  3.66it/s][A
 92%|█████████▏| 203/221 [00:58<00:04,  3.74it/s][A
 92%|█████████▏| 204/221 [00:58<00:04,  3.58it/s][A
 93%|█████████▎| 205/221 [00:58<00:03,  4.02it/s][A
 93%|█████████▎| 206/221 [00:59<00:04,  3.03it/s][A
 94%|█████████▎| 207/221 [00:59<00:04,  3.31it/s][A
 94%|█████████▍| 208/221 [00:59<00:03,  3.90it/s][A
 95%|█████████▍| 209/221 [01:00<00:03,  3.47it/s][A
 95%|█████████▌| 210/221 [01:00<00:02,  3.95it/s][A
 95%|█████████▌| 211/221 [01:00<00:02,  4.31it/s][A
 96%|█████████▌| 212/221 [01:01<00:02,  3.26it/s][A
 96%|█████████▋| 213/221 [01:01<00:02,  3.06it/s][A
 97%|█████████▋| 214/221 [01:01<00:02,  3.10it/s][A
 97%|█████████▋| 215/221 [01:01<00:01,  3.19it/s][A
 98%|█████████▊| 216/221 [01:02<00:01,  3.10it/s][A
 98%|█████████▊| 217/221 [01:02<00:01,  3.13it/s][A
 99%|█████████▊| 218/221 [01:02<00:00,  3.33it/s][A
 99%|█████████▉| 219/221 [01:03<00:00,  2.97it/s][A
100%|█████████▉| 220/221 [01:03<00:00,  3.48it/s][A
100%|██████████| 221/221 [01:03<00:00,  2.90it/s][A100%|██████████| 221/221 [01:03<00:00,  3.45it/s]
09/17/2024 02:11:11 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 449--===========

09/17/2024 02:11:11 - INFO - __main__ -   {'area_r1': 40.2, 'area_recall': '40.2/65.4/74.4', 'area_ravg': 60.0}
09/17/2024 02:11:11 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 449--===========

09/17/2024 02:11:11 - INFO - __main__ -   {'forward_r1': 36.4, 'forward_recall': '36.4/63.7/74.0', 'forward_ravg': 58.0}
09/17/2024 02:11:11 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 449--===========

09/17/2024 02:11:11 - INFO - __main__ -   {'area_video_r1': 39.7, 'area_video_recall': '39.7/67.0/77.7', 'area_video_ravg': 61.5}
09/17/2024 02:11:11 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 299=======

09/17/2024 02:11:11 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 02:11:11 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 449--===========

09/17/2024 02:11:11 - INFO - __main__ -   {'area_video_r1': 53.1, 'area_video_recall': '53.1/74.3/81.8', 'area_video_ravg': 69.7, 'area_video_back_r1': 49.7, 'area_video_back_recall': '49.7/74.9/81.8', 'area_video_back_ravg': 68.8}
09/17/2024 02:11:11 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 399=======

09/17/2024 02:11:11 - INFO - __main__ -   {'area_video_r1': 54.0, 'area_video_recall': '54.0/74.4/82.9', 'area_video_ravg': 70.4, 'area_video_back_r1': 49.7, 'area_video_back_recall': '49.7/74.5/81.4', 'area_video_back_ravg': 68.6}
09/17/2024 02:11:11 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 449--===========

09/17/2024 02:11:11 - INFO - __main__ -   {'video_r1': 36.3, 'video_recall': '36.3/64.0/73.8', 'video_ravg': 58.0}
09/17/2024 02:11:11 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 249=======

09/17/2024 02:11:11 - INFO - __main__ -   {'video_r1': 37.1, 'video_recall': '37.1/65.0/74.1', 'video_ravg': 58.7}
09/17/2024 02:11:11 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 449--===========

09/17/2024 02:11:11 - INFO - __main__ -   {'video_r1': 53.5, 'video_recall': '53.5/75.8/83.7', 'video_ravg': 71.0}
09/17/2024 02:11:11 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 399=======

09/17/2024 02:11:11 - INFO - __main__ -   {'video_r1': 53.6, 'video_recall': '53.6/75.6/83.3', 'video_ravg': 70.8}
09/17/2024 02:11:32 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.009800133295357227, 'loss_ret%tv%ta--finetune_area/loss_area': 1.2512521743774414, 'loss_ret%tv%ta--finetune_area/total_loss': 1.2610522508621216}
 15%|█▌        | 450/2910 [2:49:48<90:29:43, 132.43s/it] 15%|█▌        | 451/2910 [2:49:52<64:01:35, 93.74s/it]  16%|█▌        | 452/2910 [2:49:56<45:36:29, 66.80s/it][h264 @ 0x55e182f0f280] mmco: unref short failure
 16%|█▌        | 453/2910 [2:50:00<32:45:55, 48.01s/it] 16%|█▌        | 454/2910 [2:50:06<24:05:06, 35.30s/it] 16%|█▌        | 455/2910 [2:50:10<17:46:51, 26.07s/it][h264 @ 0x55b5023a5f80] mmco: unref short failure
[h264 @ 0x55b5023a5f80] mmco: unref short failure
[h264 @ 0x55b5023a5f80] mmco: unref short failure
 16%|█▌        | 456/2910 [2:50:15<13:25:11, 19.69s/it] 16%|█▌        | 457/2910 [2:50:21<10:33:18, 15.49s/it][h264 @ 0x55a25bbf0a00] mmco: unref short failure
09/17/2024 02:12:11 - INFO - __main__ -   current idx 37nPbMq5QY0.46 from finetune_area returns wrong image/video, use 120240 instead.
 16%|█▌        | 458/2910 [2:50:25<8:21:43, 12.28s/it] [h264 @ 0x55a25bcb2d80] mmco: unref short failure
 16%|█▌        | 459/2910 [2:50:31<7:01:08, 10.31s/it][h264 @ 0x55e1a470fe40] mmco: unref short failure
[h264 @ 0x55e1a470fe40] mmco: unref short failure
 16%|█▌        | 460/2910 [2:50:37<5:59:43,  8.81s/it][h264 @ 0x55a25ee1b340] mmco: unref short failure
[h264 @ 0x55a25ee1b340] mmco: unref short failure
[h264 @ 0x55a25bbec480] mmco: unref short failure
[h264 @ 0x55a25bbec480] mmco: unref short failure
[h264 @ 0x55a25bbec480] mmco: unref short failure
[h264 @ 0x55a25bbec480] mmco: unref short failure
[h264 @ 0x55b50404e180] mmco: unref short failure
 16%|█▌        | 461/2910 [2:50:43<5:26:33,  8.00s/it] 16%|█▌        | 462/2910 [2:50:48<4:57:18,  7.29s/it][h264 @ 0x55e1830f2600] mmco: unref short failure
[h264 @ 0x55e1830f2600] mmco: unref short failure
 16%|█▌        | 463/2910 [2:50:54<4:42:21,  6.92s/it][h264 @ 0x55b50638a100] mmco: unref short failure
[h264 @ 0x55b50638a100] mmco: unref short failure
[h264 @ 0x55e19c71c640] mmco: unref short failure
[h264 @ 0x55e19c71c640] mmco: unref short failure
 16%|█▌        | 464/2910 [2:51:00<4:32:00,  6.67s/it][h264 @ 0x56068eca1f00] mmco: unref short failure
 16%|█▌        | 465/2910 [2:51:06<4:12:43,  6.20s/it][h264 @ 0x55b505acb780] mmco: unref short failure
[h264 @ 0x55b5076f3bc0] mmco: unref short failure
[h264 @ 0x55b5076f3bc0] mmco: unref short failure
[h264 @ 0x55e18bb055c0] mmco: unref short failure
[h264 @ 0x55e18bb055c0] mmco: unref short failure
[h264 @ 0x55e18bb055c0] mmco: unref short failure
[h264 @ 0x55e18bb055c0] mmco: unref short failure
[h264 @ 0x55b509615d40] mmco: unref short failure
[h264 @ 0x55b509615d40] mmco: unref short failure
[h264 @ 0x55b509615d40] mmco: unref short failure
[h264 @ 0x55b509615d40] mmco: unref short failure
[h264 @ 0x55e1830042c0] mmco: unref short failure
[h264 @ 0x55e1830042c0] mmco: unref short failure
[h264 @ 0x55b509615d40] mmco: unref short failure
[h264 @ 0x55b509615d40] mmco: unref short failure
[h264 @ 0x55b4f41221c0] mmco: unref short failure
09/17/2024 02:13:22 - INFO - __main__ -   current idx rJOs530YXYo.53 from finetune_area returns wrong image/video, use 140395 instead.
 16%|█▌        | 466/2910 [2:51:54<12:43:59, 18.76s/it][h264 @ 0x55e1831044c0] mmco: unref short failure
[h264 @ 0x55e1831044c0] mmco: unref short failure
[h264 @ 0x55e1831044c0] mmco: unref short failure
[h264 @ 0x55e1831044c0] mmco: unref short failure
 16%|█▌        | 467/2910 [2:52:08<11:51:45, 17.48s/it]09/17/2024 02:13:58 - INFO - __main__ -   current idx EboJj8xv0Wo.48 from finetune_area returns wrong image/video, use 102431 instead.
 16%|█▌        | 468/2910 [2:52:28<12:18:47, 18.15s/it][h264 @ 0x5606900d24c0] mmco: unref short failure
[h264 @ 0x5606900d24c0] mmco: unref short failure
 16%|█▌        | 469/2910 [2:52:33<9:44:54, 14.38s/it] [h264 @ 0x55b4f4107340] mmco: unref short failure
 16%|█▌        | 470/2910 [2:52:39<7:54:32, 11.67s/it][h264 @ 0x5606a909e2c0] mmco: unref short failure
 16%|█▌        | 471/2910 [2:52:44<6:38:44,  9.81s/it][h264 @ 0x55a25edb7040] mmco: unref short failure
[h264 @ 0x55a25edb7040] mmco: unref short failure
[h264 @ 0x55a25edb7040] mmco: unref short failure
[h264 @ 0x55a25edb7040] mmco: unref short failure
[h264 @ 0x55a274b498c0] mmco: unref short failure
[h264 @ 0x55a274b498c0] mmco: unref short failure
 16%|█▌        | 472/2910 [2:52:51<6:00:41,  8.88s/it][h264 @ 0x55e1830eeb00] mmco: unref short failure
 16%|█▋        | 473/2910 [2:52:56<5:16:45,  7.80s/it][h264 @ 0x55b4f4120740] mmco: unref short failure
[h264 @ 0x55b4f4120740] mmco: unref short failure
[h264 @ 0x55b4f4120740] mmco: unref short failure
[h264 @ 0x55b4f4120740] mmco: unref short failure
[h264 @ 0x55a25b9200c0] mmco: unref short failure
[h264 @ 0x55a25bb91300] mmco: unref short failure
[h264 @ 0x56068d78fb80] mmco: unref short failure
[h264 @ 0x55b4f40b8c40] mmco: unref short failure
[h264 @ 0x55b4f40b8c40] mmco: unref short failure
[h264 @ 0x55e18ff178c0] mmco: unref short failure
[h264 @ 0x55e18ff178c0] mmco: unref short failure
[h264 @ 0x55b4f3fe1a80] mmco: unref short failure
[h264 @ 0x55e191d85c40] mmco: unref short failure
[h264 @ 0x55e191d85c40] mmco: unref short failure
[h264 @ 0x5606900d24c0] mmco: unref short failure
[h264 @ 0x5606900d24c0] mmco: unref short failure
[h264 @ 0x55b4f44d8a80] mmco: unref short failure
[h264 @ 0x55b4f8289540] mmco: unref short failure
[h264 @ 0x55b4f8289540] mmco: unref short failure
[h264 @ 0x55e18ff178c0] mmco: unref short failure
[h264 @ 0x55e18ff178c0] mmco: unref short failure
[h264 @ 0x55e184209100] mmco: unref short failure
[h264 @ 0x55a2679e32c0] mmco: unref short failure
[h264 @ 0x55e1830ae240] mmco: unref short failure
[h264 @ 0x55e1830ae240] mmco: unref short failure
[h264 @ 0x55e182f3a040] mmco: unref short failure
[h264 @ 0x55e182f3a040] mmco: unref short failure
[h264 @ 0x55e196e26c40] mmco: unref short failure
 16%|█▋        | 474/2910 [2:54:29<22:32:07, 33.30s/it][h264 @ 0x55b4f4041400] mmco: unref short failure
[h264 @ 0x55b4f4041400] mmco: unref short failure
[h264 @ 0x55b4f4041400] mmco: unref short failure
[h264 @ 0x55b4f4041400] mmco: unref short failure
[h264 @ 0x55e19a4888c0] mmco: unref short failure
[h264 @ 0x55e183420140] mmco: unref short failure
 16%|█▋        | 475/2910 [2:54:36<17:16:18, 25.54s/it][h264 @ 0x55a25bb083c0] mmco: unref short failure
[h264 @ 0x55a25bb083c0] mmco: unref short failure
[h264 @ 0x55a25bb083c0] mmco: unref short failure
[h264 @ 0x55a25bb083c0] mmco: unref short failure
[h264 @ 0x55a25c043f00] mmco: unref short failure
[h264 @ 0x55a25c043f00] mmco: unref short failure
 16%|█▋        | 476/2910 [2:54:59<16:43:15, 24.73s/it]09/17/2024 02:16:47 - INFO - __main__ -   current idx JyHu6qXDg1E.525 from finetune_area returns wrong image/video, use 123006 instead.
 16%|█▋        | 477/2910 [2:55:06<13:02:53, 19.31s/it][h264 @ 0x55a25bb1a2c0] mmco: unref short failure
[h264 @ 0x55a25bb1a2c0] mmco: unref short failure
 16%|█▋        | 478/2910 [2:55:11<10:11:45, 15.09s/it]09/17/2024 02:16:58 - INFO - __main__ -   current idx bgTXI7WKWoY.26 from finetune_area returns wrong image/video, use 83183 instead.
[h264 @ 0x55e1a470fe40] mmco: unref short failure
[h264 @ 0x55e1a470fe40] mmco: unref short failure
 16%|█▋        | 479/2910 [2:55:16<8:12:52, 12.16s/it] [h264 @ 0x55a25bc93540] mmco: unref short failure
09/17/2024 02:17:07 - INFO - __main__ -   current idx 1wKPYAWLNkA.112 from finetune_area returns wrong image/video, use 50961 instead.
 16%|█▋        | 480/2910 [2:55:23<7:02:19, 10.43s/it][h264 @ 0x55a25bc85980] mmco: unref short failure
[h264 @ 0x55a25bc85980] mmco: unref short failure
[h264 @ 0x55a26319fb80] mmco: unref short failure
[h264 @ 0x55a26319fb80] mmco: unref short failure
 17%|█▋        | 481/2910 [2:55:28<6:01:20,  8.93s/it][h264 @ 0x55b4f403ed40] mmco: unref short failure
[h264 @ 0x55b4f4129140] mmco: unref short failure
[h264 @ 0x55e1834206c0] mmco: unref short failure
[h264 @ 0x55a25bb083c0] mmco: unref short failure
[h264 @ 0x55a25bb083c0] mmco: unref short failure
[h264 @ 0x560690e43c00] mmco: unref short failure
[h264 @ 0x560690e43c00] mmco: unref short failure
[h264 @ 0x55b50c9d3600] mmco: unref short failure
[h264 @ 0x55b50c9d3600] mmco: unref short failure
[h264 @ 0x55b50c9d3600] mmco: unref short failure
[h264 @ 0x55b50c9d3600] mmco: unref short failure
[h264 @ 0x560697f67d80] mmco: unref short failure
[h264 @ 0x55e182f0f280] mmco: unref short failure
[h264 @ 0x55b4fc3b40c0] mmco: unref short failure
[h264 @ 0x55b506d8e900] mmco: unref short failure
[h264 @ 0x55b506d8e900] mmco: unref short failure
09/17/2024 02:18:05 - INFO - __main__ -   current idx WdVJ8VSAKso.55 from finetune_area returns wrong image/video, use 115551 instead.
[h264 @ 0x55e196e26c40] mmco: unref short failure
[h264 @ 0x55e196e26c40] mmco: unref short failure
[h264 @ 0x55e183096500] mmco: unref short failure
[h264 @ 0x55e183096500] mmco: unref short failure
[h264 @ 0x55e183148940] mmco: unref short failure
[h264 @ 0x55e194e46000] mmco: unref short failure
[h264 @ 0x55a25ee1b340] mmco: unref short failure
[h264 @ 0x55e184e73840] mmco: unref short failure
[h264 @ 0x55e184e73840] mmco: unref short failure
[h264 @ 0x55b505acb780] mmco: unref short failure
[h264 @ 0x55b505acb780] mmco: unref short failure
[h264 @ 0x55a26d887040] mmco: unref short failure
[h264 @ 0x55a26d887040] mmco: unref short failure
 17%|█▋        | 482/2910 [2:57:05<23:42:30, 35.15s/it][h264 @ 0x56068c696b00] mmco: unref short failure
 17%|█▋        | 483/2910 [2:57:11<17:49:32, 26.44s/it]09/17/2024 02:18:58 - INFO - __main__ -   current idx 0Hu1HI7Jvzs.159 from finetune_area returns wrong image/video, use 104011 instead.
[h264 @ 0x55b4f5f80580] mmco: unref short failure
[h264 @ 0x55b50dc10640] mmco: unref short failure
[h264 @ 0x55b4f6f03e40] mmco: unref short failure
 17%|█▋        | 484/2910 [2:57:32<16:44:36, 24.85s/it]09/17/2024 02:19:21 - INFO - __main__ -   current idx GuiTdPE-2G8.5 from finetune_area returns wrong image/video, use 36650 instead.
 17%|█▋        | 485/2910 [2:57:37<12:50:05, 19.05s/it][h264 @ 0x5606983cf780] mmco: unref short failure
[h264 @ 0x5606983cf780] mmco: unref short failure
[h264 @ 0x5606a5f22180] mmco: unref short failure
[h264 @ 0x5606a5f22180] mmco: unref short failure
 17%|█▋        | 486/2910 [2:57:43<10:00:57, 14.88s/it]09/17/2024 02:19:29 - INFO - __main__ -   current idx 9Dbcu8BMaBw.7 from finetune_area returns wrong image/video, use 76933 instead.
 17%|█▋        | 487/2910 [2:57:48<8:08:01, 12.08s/it] [h264 @ 0x5606ae572180] mmco: unref short failure
[h264 @ 0x5606ae572180] mmco: unref short failure
 17%|█▋        | 488/2910 [2:57:55<7:02:02, 10.46s/it][h264 @ 0x55a25bb50e00] mmco: unref short failure
[h264 @ 0x55a25bb50e00] mmco: unref short failure
[h264 @ 0x56069cce9200] mmco: unref short failure
[h264 @ 0x56069cce9200] mmco: unref short failure
[h264 @ 0x56069cce9200] mmco: unref short failure
[h264 @ 0x55e1830bb2c0] mmco: unref short failure
[h264 @ 0x55e1830bb2c0] mmco: unref short failure
 17%|█▋        | 489/2910 [2:58:14<8:44:03, 12.99s/it][h264 @ 0x56069b08cf40] mmco: unref short failure
[h264 @ 0x56069b08cf40] mmco: unref short failure
[h264 @ 0x55e1a122bd40] mmco: unref short failure
[h264 @ 0x55e1a122bd40] mmco: unref short failure
[h264 @ 0x55b4f3663580] mmco: unref short failure
[h264 @ 0x55e18947fc40] mmco: unref short failure
[h264 @ 0x55e18947fc40] mmco: unref short failure
[h264 @ 0x55a2679e32c0] mmco: unref short failure
[h264 @ 0x55a2679e32c0] mmco: unref short failure
[h264 @ 0x55a264662580] mmco: unref short failure
[h264 @ 0x55b509615d40] mmco: unref short failure
[h264 @ 0x55b509615d40] mmco: unref short failure
[h264 @ 0x55b509615d40] mmco: unref short failure
[h264 @ 0x55b509615d40] mmco: unref short failure
[h264 @ 0x55b509615d40] mmco: unref short failure
[h264 @ 0x55b509615d40] mmco: unref short failure
[h264 @ 0x55b4fa346900] mmco: unref short failure
[h264 @ 0x56069a7b4780] mmco: unref short failure
[h264 @ 0x55e186c5bf40] mmco: unref short failure
[h264 @ 0x55a260ae8500] mmco: unref short failure
[h264 @ 0x55a260ae8500] mmco: unref short failure
[h264 @ 0x55b501109d00] mmco: unref short failure
[h264 @ 0x55a25bb904c0] mmco: unref short failure
[h264 @ 0x55a28077bcc0] mmco: unref short failure
[h264 @ 0x55a28077bcc0] mmco: unref short failure
[h264 @ 0x55b4fc3b40c0] mmco: unref short failure
[h264 @ 0x55b4fc3b40c0] mmco: unref short failure
[h264 @ 0x55b5118aa5c0] mmco: unref short failure
[h264 @ 0x55b5118aa5c0] mmco: unref short failure
[h264 @ 0x55a260ae8500] mmco: unref short failure
[h264 @ 0x55a260ae8500] mmco: unref short failure
 17%|█▋        | 490/2910 [2:59:36<22:45:27, 33.85s/it] 17%|█▋        | 491/2910 [2:59:41<16:57:16, 25.23s/it][h264 @ 0x55e1859ad280] mmco: unref short failure
[h264 @ 0x55e1859ad280] mmco: unref short failure
[h264 @ 0x56068c696b00] mmco: unref short failure
[h264 @ 0x56068c696b00] mmco: unref short failure
[h264 @ 0x55b4f9d72200] mmco: unref short failure
[h264 @ 0x55b4f9d72200] mmco: unref short failure
[h264 @ 0x55e185800440] mmco: unref short failure
[h264 @ 0x55e185800440] mmco: unref short failure
09/17/2024 02:21:50 - INFO - __main__ -   current idx DWhC_3SVyTc.13 from finetune_area returns wrong image/video, use 22882 instead.
[h264 @ 0x55e18ff178c0] mmco: unref short failure
 17%|█▋        | 492/2910 [3:00:12<18:00:52, 26.82s/it] 17%|█▋        | 493/2910 [3:00:17<13:41:32, 20.39s/it][h264 @ 0x55b4fdc20d40] mmco: unref short failure
[h264 @ 0x55b4fdc20d40] mmco: unref short failure
[h264 @ 0x55e195dc4580] mmco: unref short failure
[h264 @ 0x55e195dc4580] mmco: unref short failure
 17%|█▋        | 494/2910 [3:00:23<10:49:15, 16.12s/it][h264 @ 0x55e1830d6b40] mmco: unref short failure
09/17/2024 02:22:14 - INFO - __main__ -   current idx sisprxhsc6I.5 from finetune_area returns wrong image/video, use 53399 instead.
 17%|█▋        | 495/2910 [3:00:29<8:38:49, 12.89s/it] [h264 @ 0x55e19028df00] mmco: unref short failure
[h264 @ 0x55e19028df00] mmco: unref short failure
[h264 @ 0x55e19028df00] mmco: unref short failure
[h264 @ 0x55a2617958c0] mmco: unref short failure
 17%|█▋        | 496/2910 [3:00:39<8:10:41, 12.20s/it][h264 @ 0x56069eb43d40] mmco: unref short failure
[h264 @ 0x56069eb43d40] mmco: unref short failure
[h264 @ 0x55b50eafadc0] mmco: unref short failure
[h264 @ 0x55b50eafadc0] mmco: unref short failure
[h264 @ 0x55b50eafadc0] mmco: unref short failure
 17%|█▋        | 497/2910 [3:00:46<6:59:00, 10.42s/it][h264 @ 0x55b4f3f3f600] mmco: unref short failure
[h264 @ 0x55b4f3f3f600] mmco: unref short failure
[h264 @ 0x55e19ed5b840] mmco: unref short failure
[h264 @ 0x560698a76080] mmco: unref short failure
[h264 @ 0x560698a76080] mmco: unref short failure
[h264 @ 0x560698a76080] mmco: unref short failure
[h264 @ 0x560698a76080] mmco: unref short failure
[h264 @ 0x55e18306b440] mmco: unref short failure
[h264 @ 0x55e18306b440] mmco: unref short failure
[h264 @ 0x55e18306b440] mmco: unref short failure
[h264 @ 0x55e18306b440] mmco: unref short failure
[h264 @ 0x55a269a66040] mmco: unref short failure
[h264 @ 0x55a26319fb80] mmco: unref short failure
[h264 @ 0x55b4fc3b40c0] mmco: unref short failure
[h264 @ 0x55e194e46000] mmco: unref short failure
[h264 @ 0x55e194e46000] mmco: unref short failure
[h264 @ 0x55e194e46000] mmco: unref short failure
[h264 @ 0x55e194e46000] mmco: unref short failure
[h264 @ 0x55e19d52e5c0] mmco: unref short failure
[h264 @ 0x5606a2effe80] mmco: unref short failure
[h264 @ 0x5606a2effe80] mmco: unref short failure
[h264 @ 0x5606a2effe80] mmco: unref short failure
[h264 @ 0x5606a2effe80] mmco: unref short failure
[h264 @ 0x56068d177b40] mmco: unref short failure
[h264 @ 0x5606a410d580] mmco: unref short failure
[h264 @ 0x5606a410d580] mmco: unref short failure
[h264 @ 0x55b4fc3b40c0] mmco: unref short failure
[h264 @ 0x5606aab23a40] mmco: unref short failure
[h264 @ 0x5606aab23a40] mmco: unref short failure
[h264 @ 0x55b4f3f106c0] mmco: unref short failure
[h264 @ 0x55b4f3f106c0] mmco: unref short failure
[h264 @ 0x560694107740] mmco: unref short failure
[h264 @ 0x560694107740] mmco: unref short failure
[h264 @ 0x55b4f3fee000] mmco: unref short failure
[h264 @ 0x55b4f3fee000] mmco: unref short failure
[h264 @ 0x55e1851fd640] mmco: unref short failure
[h264 @ 0x55e1851fd640] mmco: unref short failure
[h264 @ 0x5606a410d580] mmco: unref short failure
 17%|█▋        | 498/2910 [3:02:19<23:38:01, 35.27s/it] 17%|█▋        | 499/2910 [3:02:25<17:41:06, 26.41s/it]09/17/2024 02:24:10 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 02:24:10 - INFO - __main__ -   start running ret%tva validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a262b67a40] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e19fade980] mmco: unref short failure
[h264 @ 0x55e19fade980] mmco: unref short failure
[h264 @ 0x55e19fade980] mmco: unref short failure
[h264 @ 0x55e19fade980] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55b50c6dcf80] mmco: unref short failure
[h264 @ 0x55b50c6dcf80] mmco: unref short failure
[h264 @ 0x55b50c6dcf80] mmco: unref short failure
[h264 @ 0x55b50c6dcf80] mmco: unref short failure
09/17/2024 02:26:02 - INFO - __main__ -   current idx -A-7FmorgRU.15 from finetune_area returns wrong image/video, use 18171 instead.
[h264 @ 0x5606932af480] mmco: unref short failure
[h264 @ 0x5606932af480] mmco: unref short failure
[h264 @ 0x5606ac060b40] mmco: unref short failure
[h264 @ 0x5606ac060b40] mmco: unref short failure
[h264 @ 0x55b4f7ff4b00] mmco: unref short failure
[h264 @ 0x55b4fdc20d40] mmco: unref short failure
[h264 @ 0x55b4fdc20d40] mmco: unref short failure
[h264 @ 0x5606932af480] mmco: unref short failure
[h264 @ 0x5606932af480] mmco: unref short failure
[h264 @ 0x55a260ae8500] mmco: unref short failure
[h264 @ 0x55e194e46000] mmco: unref short failure
[h264 @ 0x56068ca58840] mmco: unref short failure
[h264 @ 0x56068ca58840] mmco: unref short failure
[h264 @ 0x55e1a30c2580] mmco: unref short failure
[h264 @ 0x55e1a30c2580] mmco: unref short failure
[h264 @ 0x55e1a2157fc0] mmco: unref short failure
[h264 @ 0x55a269a66040] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:23,  1.53it/s][A
  1%|          | 2/221 [00:01<02:17,  1.59it/s][A
  1%|▏         | 3/221 [00:01<01:38,  2.20it/s][A
  2%|▏         | 4/221 [00:01<01:13,  2.96it/s][A
  2%|▏         | 5/221 [00:01<01:04,  3.37it/s][A
  3%|▎         | 6/221 [00:02<00:52,  4.11it/s][A
  3%|▎         | 7/221 [00:02<00:49,  4.32it/s][A
  4%|▎         | 8/221 [00:02<01:03,  3.37it/s][A
  4%|▍         | 9/221 [00:02<01:01,  3.45it/s][A
  5%|▍         | 10/221 [00:03<01:11,  2.93it/s][A
  5%|▍         | 11/221 [00:03<01:03,  3.29it/s][A
  5%|▌         | 12/221 [00:04<01:25,  2.44it/s][A
  6%|▌         | 13/221 [00:04<01:23,  2.48it/s][A
  6%|▋         | 14/221 [00:05<01:52,  1.84it/s][A
  7%|▋         | 15/221 [00:05<01:27,  2.35it/s][A
  7%|▋         | 16/221 [00:05<01:20,  2.56it/s][A
  8%|▊         | 17/221 [00:06<01:45,  1.94it/s][A
  8%|▊         | 18/221 [00:07<01:29,  2.27it/s][A
  9%|▊         | 19/221 [00:07<01:13,  2.76it/s][A
  9%|▉         | 20/221 [00:07<01:03,  3.18it/s][A
 10%|▉         | 21/221 [00:07<00:53,  3.71it/s][A
 10%|▉         | 22/221 [00:07<00:49,  4.06it/s][A
 11%|█         | 24/221 [00:08<00:37,  5.29it/s][A
 11%|█▏        | 25/221 [00:08<00:43,  4.48it/s][A
[h264 @ 0x55e1895dd700] mmco: unref short failure
[h264 @ 0x55e1895dd700] mmco: unref short failure
 12%|█▏        | 26/221 [00:08<01:00,  3.24it/s][A
 12%|█▏        | 27/221 [00:09<00:51,  3.77it/s][A
 13%|█▎        | 28/221 [00:09<01:07,  2.86it/s][A
 13%|█▎        | 29/221 [00:10<01:39,  1.93it/s][A
 14%|█▎        | 30/221 [00:10<01:26,  2.21it/s][A
 14%|█▍        | 31/221 [00:11<01:16,  2.47it/s][A
 14%|█▍        | 32/221 [00:11<01:07,  2.81it/s][A
 15%|█▍        | 33/221 [00:11<01:00,  3.11it/s][A
 15%|█▌        | 34/221 [00:11<00:54,  3.46it/s][A
 16%|█▌        | 35/221 [00:12<00:47,  3.88it/s][A
 16%|█▋        | 36/221 [00:12<00:51,  3.60it/s][A
 17%|█▋        | 37/221 [00:13<01:14,  2.47it/s][A
 17%|█▋        | 38/221 [00:13<01:20,  2.29it/s][A
 18%|█▊        | 39/221 [00:14<01:20,  2.26it/s][A
 18%|█▊        | 40/221 [00:14<01:17,  2.32it/s][A
 19%|█▊        | 41/221 [00:14<01:00,  2.97it/s][A
 19%|█▉        | 42/221 [00:15<01:06,  2.70it/s][A
 19%|█▉        | 43/221 [00:15<00:51,  3.44it/s][A
 20%|█▉        | 44/221 [00:15<00:41,  4.25it/s][A
 20%|██        | 45/221 [00:16<01:13,  2.38it/s][A[h264 @ 0x55e19be7a940] mmco: unref short failure
[h264 @ 0x55e19be7a940] mmco: unref short failure

 21%|██        | 46/221 [00:16<01:20,  2.17it/s][A
 21%|██▏       | 47/221 [00:17<01:30,  1.92it/s][A[h264 @ 0x55e19be7a940] mmco: unref short failure
[h264 @ 0x55e19be7a940] mmco: unref short failure

 22%|██▏       | 48/221 [00:17<01:10,  2.47it/s][A
 22%|██▏       | 49/221 [00:17<01:17,  2.21it/s][A[h264 @ 0x55e19be7a940] mmco: unref short failure
[h264 @ 0x55e19be7a940] mmco: unref short failure

 23%|██▎       | 50/221 [00:18<01:31,  1.87it/s][A
 23%|██▎       | 51/221 [00:18<01:15,  2.26it/s][A
 24%|██▎       | 52/221 [00:19<01:02,  2.69it/s][A
 24%|██▍       | 53/221 [00:19<00:49,  3.41it/s][A[h264 @ 0x55e19be7a940] mmco: unref short failure
[h264 @ 0x55e19be7a940] mmco: unref short failure
[h264 @ 0x5606932af480] mmco: unref short failure
[h264 @ 0x5606932af480] mmco: unref short failure
[h264 @ 0x55e19be7a940] mmco: unref short failure
[h264 @ 0x55e19be7a940] mmco: unref short failure
[h264 @ 0x55e19be7a940] mmco: unref short failure
[h264 @ 0x55e19be7a940] mmco: unref short failure

 24%|██▍       | 54/221 [00:21<02:32,  1.10it/s][A
 25%|██▍       | 55/221 [00:21<01:58,  1.40it/s][A
 25%|██▌       | 56/221 [00:22<01:35,  1.73it/s][A
 26%|██▌       | 57/221 [00:22<01:15,  2.17it/s][A
 26%|██▌       | 58/221 [00:22<01:04,  2.53it/s][A
 27%|██▋       | 59/221 [00:22<00:57,  2.81it/s][A
 27%|██▋       | 60/221 [00:23<01:09,  2.33it/s][A
 28%|██▊       | 61/221 [00:23<00:58,  2.73it/s][A[h264 @ 0x5606a1fdcf40] mmco: unref short failure
[h264 @ 0x5606a1fdcf40] mmco: unref short failure
[h264 @ 0x5606a1fdcf40] mmco: unref short failure
[h264 @ 0x5606a1fdcf40] mmco: unref short failure

 28%|██▊       | 62/221 [00:23<00:53,  2.94it/s][A
 29%|██▊       | 63/221 [00:24<00:51,  3.05it/s][A
 29%|██▉       | 64/221 [00:24<00:44,  3.56it/s][A
 29%|██▉       | 65/221 [00:24<00:42,  3.70it/s][A
 30%|██▉       | 66/221 [00:24<00:45,  3.39it/s][A
 30%|███       | 67/221 [00:25<00:57,  2.69it/s][A
 31%|███       | 68/221 [00:25<00:48,  3.15it/s][A
 31%|███       | 69/221 [00:26<01:03,  2.38it/s][A
 32%|███▏      | 70/221 [00:26<00:52,  2.89it/s][A
 32%|███▏      | 71/221 [00:27<01:05,  2.30it/s][A
 33%|███▎      | 72/221 [00:27<00:57,  2.58it/s][A
 33%|███▎      | 73/221 [00:27<01:01,  2.40it/s][A
 33%|███▎      | 74/221 [00:28<00:50,  2.91it/s][A[h264 @ 0x5606956e83c0] mmco: unref short failure
[h264 @ 0x5606956e83c0] mmco: unref short failure

 34%|███▍      | 75/221 [00:28<00:50,  2.86it/s][A
 34%|███▍      | 76/221 [00:28<00:44,  3.25it/s][A
 35%|███▍      | 77/221 [00:28<00:42,  3.37it/s][A
 35%|███▌      | 78/221 [00:29<00:39,  3.64it/s][A
 36%|███▌      | 79/221 [00:29<00:52,  2.70it/s][A
 36%|███▌      | 80/221 [00:30<00:45,  3.11it/s][A
 37%|███▋      | 81/221 [00:30<00:48,  2.90it/s][A
 37%|███▋      | 82/221 [00:31<01:15,  1.84it/s][A[h264 @ 0x55e182f59900] mmco: unref short failure
[h264 @ 0x55e182f59900] mmco: unref short failure

 38%|███▊      | 83/221 [00:31<01:12,  1.91it/s][A
 38%|███▊      | 84/221 [00:32<01:01,  2.21it/s][A
 38%|███▊      | 85/221 [00:32<00:50,  2.70it/s][A
 39%|███▉      | 86/221 [00:32<00:49,  2.72it/s][A
 39%|███▉      | 87/221 [00:33<00:57,  2.34it/s][A
 40%|███▉      | 88/221 [00:33<01:00,  2.21it/s][A
 40%|████      | 89/221 [00:34<01:05,  2.01it/s][A
 41%|████      | 90/221 [00:34<00:59,  2.18it/s][A
 41%|████      | 91/221 [00:34<00:49,  2.61it/s][A
 42%|████▏     | 92/221 [00:35<00:42,  3.03it/s][A
 42%|████▏     | 93/221 [00:35<00:43,  2.93it/s][A
 43%|████▎     | 94/221 [00:35<00:38,  3.27it/s][A
 43%|████▎     | 95/221 [00:36<00:39,  3.22it/s][A
 43%|████▎     | 96/221 [00:36<00:37,  3.29it/s][A
 44%|████▍     | 97/221 [00:36<00:31,  3.96it/s][A
 44%|████▍     | 98/221 [00:36<00:35,  3.46it/s][A
 45%|████▍     | 99/221 [00:37<00:29,  4.10it/s][A
 45%|████▌     | 100/221 [00:37<00:26,  4.53it/s][A
 46%|████▌     | 101/221 [00:37<00:24,  4.96it/s][A
 46%|████▌     | 102/221 [00:37<00:26,  4.41it/s][A
 47%|████▋     | 103/221 [00:37<00:23,  5.07it/s][A
 47%|████▋     | 104/221 [00:37<00:21,  5.53it/s][A
 48%|████▊     | 105/221 [00:38<00:25,  4.51it/s][A
 48%|████▊     | 106/221 [00:38<00:43,  2.63it/s][A
 48%|████▊     | 107/221 [00:39<00:35,  3.18it/s][h264 @ 0x55e1a30c2580] mmco: unref short failure
[A
 49%|████▉     | 108/221 [00:39<00:32,  3.52it/s][A
 49%|████▉     | 109/221 [00:39<00:30,  3.72it/s][A
 50%|████▉     | 110/221 [00:39<00:29,  3.80it/s][A
 50%|█████     | 111/221 [00:40<00:35,  3.11it/s][A
 51%|█████     | 112/221 [00:40<00:31,  3.44it/s][A
 51%|█████     | 113/221 [00:40<00:35,  3.06it/s][A
 52%|█████▏    | 114/221 [00:41<00:28,  3.81it/s][A
 52%|█████▏    | 115/221 [00:41<00:23,  4.53it/s][A[h264 @ 0x5606ad4d8fc0] mmco: unref short failure
[h264 @ 0x5606ad4d8fc0] mmco: unref short failure

[h264 @ 0x55b4f6f01b00] mmco: unref short failure
 52%|█████▏    | 116/221 [00:44<02:00,  1.15s/it][A
 53%|█████▎    | 117/221 [00:44<01:33,  1.11it/s][A
 53%|█████▎    | 118/221 [00:45<01:12,  1.41it/s][A
 54%|█████▍    | 119/221 [00:45<01:00,  1.70it/s][A
 54%|█████▍    | 120/221 [00:45<00:52,  1.93it/s][A
 55%|█████▍    | 121/221 [00:45<00:41,  2.39it/s][A
 55%|█████▌    | 122/221 [00:46<00:34,  2.84it/s][A
 56%|█████▌    | 123/221 [00:46<00:29,  3.35it/s][A
 56%|█████▌    | 124/221 [00:46<00:26,  3.61it/s][A[h264 @ 0x55a274b498c0] mmco: unref short failure
[h264 @ 0x55a274b498c0] mmco: unref short failure
[h264 @ 0x55a274b498c0] mmco: unref short failure

 57%|█████▋    | 125/221 [00:46<00:30,  3.11it/s][A
 57%|█████▋    | 126/221 [00:47<00:28,  3.30it/s][A
 57%|█████▋    | 127/221 [00:47<00:33,  2.78it/s][A
 58%|█████▊    | 128/221 [00:48<00:35,  2.65it/s][A
 58%|█████▊    | 129/221 [00:48<00:28,  3.25it/s][A
 59%|█████▉    | 130/221 [00:48<00:27,  3.29it/s][A
 59%|█████▉    | 131/221 [00:48<00:22,  4.08it/s][A
 60%|█████▉    | 132/221 [00:48<00:20,  4.33it/s][A
 60%|██████    | 133/221 [00:49<00:26,  3.28it/s][A
 61%|██████    | 134/221 [00:49<00:23,  3.72it/s][A
 61%|██████    | 135/221 [00:49<00:23,  3.64it/s][A
 62%|██████▏   | 136/221 [00:50<00:26,  3.15it/s][A
 62%|██████▏   | 137/221 [00:50<00:24,  3.43it/s][A
 62%|██████▏   | 138/221 [00:50<00:26,  3.13it/s][A
 63%|██████▎   | 139/221 [00:51<00:30,  2.68it/s][A
 63%|██████▎   | 140/221 [00:51<00:28,  2.82it/s][A
 64%|██████▍   | 141/221 [00:51<00:24,  3.26it/s][A
 64%|██████▍   | 142/221 [00:52<00:23,  3.31it/s][A
 65%|██████▍   | 143/221 [00:52<00:25,  3.04it/s][A
 65%|██████▌   | 144/221 [00:52<00:22,  3.49it/s][A
 66%|██████▌   | 145/221 [00:52<00:18,  4.17it/s][A[h264 @ 0x5606a410d580] mmco: unref short failure
[h264 @ 0x5606a410d580] mmco: unref short failure
[h264 @ 0x5606a410d580] mmco: unref short failure
[h264 @ 0x5606a410d580] mmco: unref short failure

 67%|██████▋   | 147/221 [00:53<00:15,  4.84it/s][A
 67%|██████▋   | 148/221 [00:53<00:17,  4.11it/s][A
 67%|██████▋   | 149/221 [00:53<00:16,  4.43it/s][A[h264 @ 0x55b50aedcdc0] mmco: unref short failure

 68%|██████▊   | 150/221 [00:54<00:17,  4.01it/s][A
 68%|██████▊   | 151/221 [00:54<00:25,  2.72it/s][A
 69%|██████▉   | 152/221 [00:56<00:49,  1.38it/s][A
 69%|██████▉   | 153/221 [00:56<00:42,  1.59it/s][A
 70%|██████▉   | 154/221 [00:57<00:36,  1.84it/s][A
 70%|███████   | 155/221 [00:57<00:28,  2.33it/s][A
 71%|███████   | 156/221 [00:57<00:23,  2.77it/s][A
 71%|███████   | 157/221 [00:58<00:28,  2.23it/s][A
 71%|███████▏  | 158/221 [00:58<00:25,  2.46it/s][A
 72%|███████▏  | 159/221 [00:58<00:21,  2.83it/s][A
 72%|███████▏  | 160/221 [00:59<00:23,  2.57it/s][A
 73%|███████▎  | 161/221 [00:59<00:20,  2.89it/s][A
 73%|███████▎  | 162/221 [00:59<00:19,  3.03it/s][A
 74%|███████▍  | 163/221 [00:59<00:18,  3.15it/s][A
 74%|███████▍  | 164/221 [01:00<00:26,  2.15it/s][A
 75%|███████▍  | 165/221 [01:00<00:20,  2.77it/s][A
 75%|███████▌  | 166/221 [01:01<00:19,  2.77it/s][A
 76%|███████▌  | 167/221 [01:01<00:16,  3.31it/s][A
 76%|███████▌  | 168/221 [01:01<00:19,  2.70it/s][A
 76%|███████▋  | 169/221 [01:02<00:17,  2.97it/s][A
 77%|███████▋  | 170/221 [01:02<00:18,  2.76it/s][A
 77%|███████▋  | 171/221 [01:02<00:16,  2.95it/s][A
 78%|███████▊  | 172/221 [01:03<00:14,  3.39it/s][A
 78%|███████▊  | 173/221 [01:03<00:12,  3.88it/s][A
 79%|███████▊  | 174/221 [01:03<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [01:04<00:19,  2.39it/s][A
 80%|███████▉  | 176/221 [01:04<00:16,  2.71it/s][A
 80%|████████  | 177/221 [01:04<00:13,  3.23it/s][A
 81%|████████  | 178/221 [01:04<00:11,  3.61it/s][A
 81%|████████  | 179/221 [01:05<00:13,  3.05it/s][A
 81%|████████▏ | 180/221 [01:05<00:11,  3.72it/s][A
 82%|████████▏ | 181/221 [01:05<00:09,  4.03it/s][A
 82%|████████▏ | 182/221 [01:05<00:08,  4.41it/s][A[h264 @ 0x55e1823e5a00] mmco: unref short failure

 83%|████████▎ | 183/221 [01:06<00:08,  4.61it/s][A[h264 @ 0x56068da57100] mmco: unref short failure
[h264 @ 0x56068da57100] mmco: unref short failure

 83%|████████▎ | 184/221 [01:06<00:08,  4.21it/s][A
 84%|████████▎ | 185/221 [01:06<00:08,  4.23it/s][A
 84%|████████▍ | 186/221 [01:07<00:10,  3.34it/s][A
 85%|████████▍ | 187/221 [01:07<00:09,  3.62it/s][A
 85%|████████▌ | 188/221 [01:07<00:08,  3.88it/s][A
 86%|████████▌ | 189/221 [01:07<00:10,  3.16it/s][A
 86%|████████▌ | 190/221 [01:08<00:09,  3.14it/s][A
 86%|████████▋ | 191/221 [01:08<00:07,  3.90it/s][A
 87%|████████▋ | 192/221 [01:08<00:07,  3.99it/s][A
 88%|████████▊ | 194/221 [01:09<00:08,  3.02it/s][A
 88%|████████▊ | 195/221 [01:09<00:07,  3.48it/s][A
 89%|████████▊ | 196/221 [01:10<00:09,  2.53it/s][A
 89%|████████▉ | 197/221 [01:10<00:07,  3.15it/s][A
 90%|████████▉ | 198/221 [01:10<00:07,  3.23it/s][A
 90%|█████████ | 199/221 [01:10<00:05,  3.74it/s][A
 90%|█████████ | 200/221 [01:11<00:06,  3.50it/s][A
 91%|█████████ | 201/221 [01:11<00:05,  3.80it/s][A
 91%|█████████▏| 202/221 [01:11<00:04,  3.99it/s][A
 92%|█████████▏| 203/221 [01:11<00:04,  4.48it/s][A
 92%|█████████▏| 204/221 [01:12<00:04,  3.70it/s][A
 93%|█████████▎| 205/221 [01:12<00:03,  4.45it/s][A
 93%|█████████▎| 206/221 [01:12<00:05,  2.99it/s][A
 94%|█████████▎| 207/221 [01:13<00:04,  3.33it/s][A
 94%|█████████▍| 208/221 [01:13<00:03,  4.01it/s][A
 95%|█████████▍| 209/221 [01:13<00:02,  4.01it/s][A
 95%|█████████▌| 211/221 [01:13<00:02,  4.10it/s][A
 96%|█████████▌| 212/221 [01:14<00:01,  4.65it/s][A
 96%|█████████▋| 213/221 [01:14<00:01,  4.43it/s][A
 97%|█████████▋| 214/221 [01:14<00:01,  4.15it/s][A
 97%|█████████▋| 215/221 [01:14<00:01,  4.13it/s][A
 98%|█████████▊| 216/221 [01:15<00:01,  3.74it/s][A
 98%|█████████▊| 217/221 [01:15<00:01,  3.07it/s][A
 99%|█████████▊| 218/221 [01:16<00:01,  2.93it/s][A
 99%|█████████▉| 219/221 [01:16<00:00,  3.28it/s][A[h264 @ 0x55b507dca440] mmco: unref short failure

100%|█████████▉| 220/221 [01:19<00:01,  1.25s/it][A
100%|██████████| 221/221 [01:19<00:00,  1.07it/s][A100%|██████████| 221/221 [01:19<00:00,  2.77it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:04,  3.41it/s][A
  1%|          | 2/221 [00:00<01:05,  3.33it/s][A
  1%|▏         | 3/221 [00:00<01:05,  3.32it/s][A
  2%|▏         | 4/221 [00:01<01:07,  3.21it/s][A
  2%|▏         | 5/221 [00:01<01:05,  3.28it/s][A
  3%|▎         | 6/221 [00:01<01:04,  3.32it/s][A
  3%|▎         | 7/221 [00:02<01:03,  3.35it/s][A
  4%|▎         | 8/221 [00:02<01:03,  3.36it/s][A
  4%|▍         | 9/221 [00:02<01:02,  3.38it/s][A
  5%|▍         | 10/221 [00:02<01:02,  3.38it/s][A
  5%|▍         | 11/221 [00:03<01:02,  3.37it/s][A
  5%|▌         | 12/221 [00:03<01:02,  3.34it/s][A[h264 @ 0x55a25befe300] mmco: unref short failure

  6%|▌         | 13/221 [00:03<01:01,  3.36it/s][A
  6%|▋         | 14/221 [00:04<01:01,  3.37it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.36it/s][A
  7%|▋         | 16/221 [00:04<01:00,  3.36it/s][A
  8%|▊         | 17/221 [00:05<01:00,  3.35it/s][A
  8%|▊         | 18/221 [00:05<01:01,  3.32it/s][A
  9%|▊         | 19/221 [00:05<01:01,  3.31it/s][A
  9%|▉         | 20/221 [00:05<01:00,  3.33it/s][A
 10%|▉         | 21/221 [00:06<00:59,  3.34it/s][A
 10%|▉         | 22/221 [00:06<00:59,  3.33it/s][A
 10%|█         | 23/221 [00:06<00:59,  3.31it/s][A
 11%|█         | 24/221 [00:07<00:59,  3.30it/s][A
 11%|█▏        | 25/221 [00:07<00:59,  3.30it/s][A
 12%|█▏        | 26/221 [00:07<00:58,  3.31it/s][A
 12%|█▏        | 27/221 [00:08<00:58,  3.33it/s][A
 13%|█▎        | 28/221 [00:08<00:58,  3.32it/s][A
 13%|█▎        | 29/221 [00:08<00:57,  3.32it/s][A
 14%|█▎        | 30/221 [00:09<00:57,  3.31it/s][A
 14%|█▍        | 31/221 [00:09<00:57,  3.33it/s][A
 14%|█▍        | 32/221 [00:09<00:57,  3.31it/s][A
 15%|█▍        | 33/221 [00:09<00:56,  3.33it/s][A
 15%|█▌        | 34/221 [00:10<00:56,  3.32it/s][A
 16%|█▌        | 35/221 [00:10<00:55,  3.35it/s][A
 16%|█▋        | 36/221 [00:10<00:55,  3.34it/s][A
 17%|█▋        | 37/221 [00:11<00:55,  3.32it/s][A
 17%|█▋        | 38/221 [00:11<00:55,  3.30it/s][A
 18%|█▊        | 39/221 [00:11<00:54,  3.32it/s][A
 18%|█▊        | 40/221 [00:12<00:54,  3.35it/s][A
 19%|█▊        | 41/221 [00:12<00:53,  3.36it/s][A
 19%|█▉        | 42/221 [00:12<00:53,  3.37it/s][A
 19%|█▉        | 43/221 [00:12<00:52,  3.38it/s][A
 20%|█▉        | 44/221 [00:13<00:52,  3.39it/s][A
 20%|██        | 45/221 [00:13<00:51,  3.39it/s][A
 21%|██        | 46/221 [00:13<00:51,  3.37it/s][A
 21%|██▏       | 47/221 [00:14<00:51,  3.36it/s][A
 22%|██▏       | 48/221 [00:14<00:51,  3.35it/s][A
 22%|██▏       | 49/221 [00:14<00:51,  3.34it/s][A
 23%|██▎       | 50/221 [00:14<00:51,  3.35it/s][A
 23%|██▎       | 51/221 [00:15<00:50,  3.37it/s][A
 24%|██▎       | 52/221 [00:15<00:50,  3.34it/s][A
 24%|██▍       | 53/221 [00:15<00:50,  3.30it/s][A
 24%|██▍       | 54/221 [00:16<00:50,  3.33it/s][A
 25%|██▍       | 55/221 [00:16<00:49,  3.35it/s][A
 25%|██▌       | 56/221 [00:16<00:48,  3.37it/s][A
 26%|██▌       | 57/221 [00:17<00:48,  3.38it/s][A
 26%|██▌       | 58/221 [00:17<00:48,  3.39it/s][A
 27%|██▋       | 59/221 [00:17<00:47,  3.39it/s][A
 27%|██▋       | 60/221 [00:17<00:47,  3.40it/s][A
 28%|██▊       | 61/221 [00:18<00:47,  3.40it/s][A
 28%|██▊       | 62/221 [00:18<00:46,  3.39it/s][A
 29%|██▊       | 63/221 [00:18<00:46,  3.39it/s][A
 29%|██▉       | 64/221 [00:19<00:46,  3.39it/s][A
 29%|██▉       | 65/221 [00:19<00:45,  3.40it/s][A
 30%|██▉       | 66/221 [00:19<00:45,  3.40it/s][A
 30%|███       | 67/221 [00:20<00:45,  3.40it/s][A
 31%|███       | 68/221 [00:20<00:44,  3.40it/s][A
 31%|███       | 69/221 [00:20<00:44,  3.40it/s][A
 32%|███▏      | 70/221 [00:20<00:44,  3.40it/s][A
 32%|███▏      | 71/221 [00:21<00:44,  3.40it/s][A
 33%|███▎      | 72/221 [00:21<00:43,  3.40it/s][A
 33%|███▎      | 73/221 [00:21<00:43,  3.40it/s][A
 33%|███▎      | 74/221 [00:22<00:43,  3.40it/s][A
 34%|███▍      | 75/221 [00:22<00:42,  3.40it/s][A
 34%|███▍      | 76/221 [00:22<00:42,  3.40it/s][A
 35%|███▍      | 77/221 [00:22<00:42,  3.41it/s][A[h264 @ 0x55e1a3bc3b40] mmco: unref short failure
[h264 @ 0x55e1a3bc3b40] mmco: unref short failure

 35%|███▌      | 78/221 [00:23<00:41,  3.41it/s][A
 36%|███▌      | 79/221 [00:23<00:41,  3.41it/s][A
 36%|███▌      | 80/221 [00:23<00:41,  3.41it/s][A
 37%|███▋      | 81/221 [00:24<00:41,  3.41it/s][A
 37%|███▋      | 82/221 [00:24<00:40,  3.41it/s][A
 38%|███▊      | 83/221 [00:24<00:40,  3.41it/s][A
 38%|███▊      | 84/221 [00:24<00:40,  3.41it/s][A
 38%|███▊      | 85/221 [00:25<00:39,  3.42it/s][A
 39%|███▉      | 86/221 [00:25<00:39,  3.42it/s][A
 39%|███▉      | 87/221 [00:25<00:39,  3.42it/s][A
 40%|███▉      | 88/221 [00:26<00:38,  3.42it/s][A
 40%|████      | 89/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 90/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 91/221 [00:27<00:38,  3.42it/s][A
 42%|████▏     | 92/221 [00:27<00:37,  3.42it/s][A
 42%|████▏     | 93/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 94/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 95/221 [00:28<00:36,  3.42it/s][A
 43%|████▎     | 96/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 97/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 98/221 [00:29<00:35,  3.42it/s][A
 45%|████▍     | 99/221 [00:29<00:35,  3.42it/s][A
 45%|████▌     | 100/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 101/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 102/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 104/221 [00:30<00:34,  3.42it/s][A
 48%|████▊     | 105/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 107/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 108/221 [00:32<00:33,  3.42it/s][A
 49%|████▉     | 109/221 [00:32<00:32,  3.42it/s][A
 50%|████▉     | 110/221 [00:32<00:32,  3.42it/s][A
 50%|█████     | 111/221 [00:32<00:32,  3.42it/s][A
 51%|█████     | 112/221 [00:33<00:31,  3.42it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 114/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:34<00:30,  3.42it/s][A
 52%|█████▏    | 116/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:34<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:35<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:35<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:38<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:39<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:39<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:40<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:41<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:41<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:43<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:45<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:45<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:46<00:18,  3.42it/s][A
 71%|███████   | 157/221 [00:46<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:47<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:48<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:48<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:48<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:49<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:49<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:50<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:51<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:51<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:52<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:54<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:55<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:55<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:56<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:57<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:57<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:58<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:03<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.42it/s][A100%|██████████| 221/221 [01:05<00:00,  3.40it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:28,  7.71it/s][A
  1%|          | 2/221 [00:00<00:55,  3.97it/s][A
  1%|▏         | 3/221 [00:00<01:18,  2.77it/s][A
  2%|▏         | 4/221 [00:01<01:04,  3.35it/s][A
  2%|▏         | 5/221 [00:01<01:01,  3.54it/s][A
  3%|▎         | 7/221 [00:01<00:48,  4.37it/s][A
  4%|▎         | 8/221 [00:02<00:55,  3.83it/s][A
  4%|▍         | 9/221 [00:02<00:54,  3.86it/s][A
  5%|▍         | 10/221 [00:02<00:59,  3.54it/s][A
  5%|▍         | 11/221 [00:02<00:56,  3.72it/s][A
  5%|▌         | 12/221 [00:03<00:54,  3.85it/s][A
  6%|▌         | 13/221 [00:04<01:37,  2.13it/s][A
  6%|▋         | 14/221 [00:04<01:19,  2.62it/s][A
  7%|▋         | 15/221 [00:04<01:15,  2.72it/s][A
  7%|▋         | 16/221 [00:05<01:17,  2.66it/s][A
  8%|▊         | 17/221 [00:05<01:23,  2.45it/s][A
  8%|▊         | 18/221 [00:05<01:20,  2.51it/s][A
  9%|▊         | 19/221 [00:06<01:06,  3.02it/s][A
  9%|▉         | 20/221 [00:06<01:00,  3.30it/s][A
 10%|▉         | 21/221 [00:06<00:52,  3.78it/s][A
 10%|▉         | 22/221 [00:06<00:46,  4.27it/s][A
 10%|█         | 23/221 [00:06<00:39,  5.01it/s][A
 11%|█         | 24/221 [00:06<00:37,  5.21it/s][A
 11%|█▏        | 25/221 [00:07<00:55,  3.55it/s][A
 12%|█▏        | 26/221 [00:07<00:59,  3.27it/s][A
 12%|█▏        | 27/221 [00:08<00:57,  3.38it/s][A
 13%|█▎        | 28/221 [00:08<01:07,  2.86it/s][A
 13%|█▎        | 29/221 [00:08<01:03,  3.04it/s][A
 14%|█▎        | 30/221 [00:09<01:00,  3.16it/s][A
 14%|█▍        | 31/221 [00:09<00:57,  3.33it/s][A
 14%|█▍        | 32/221 [00:09<00:50,  3.73it/s][A
 15%|█▍        | 33/221 [00:09<00:48,  3.89it/s][A
 15%|█▌        | 34/221 [00:10<00:49,  3.77it/s][A
 16%|█▌        | 35/221 [00:10<00:46,  4.02it/s][A
 16%|█▋        | 36/221 [00:10<00:50,  3.68it/s][A
 17%|█▋        | 37/221 [00:10<00:47,  3.85it/s][A
 17%|█▋        | 38/221 [00:11<00:50,  3.63it/s][A
 18%|█▊        | 39/221 [00:11<00:40,  4.45it/s][A
 18%|█▊        | 40/221 [00:11<00:48,  3.76it/s][A
 19%|█▊        | 41/221 [00:11<00:39,  4.51it/s][A
 19%|█▉        | 42/221 [00:11<00:35,  5.00it/s][A
 19%|█▉        | 43/221 [00:12<00:40,  4.45it/s][A
 20%|█▉        | 44/221 [00:12<00:36,  4.79it/s][A
 20%|██        | 45/221 [00:12<00:43,  4.07it/s][A
 21%|██        | 46/221 [00:12<00:43,  4.03it/s][A
 22%|██▏       | 48/221 [00:13<00:31,  5.54it/s][A
 22%|██▏       | 49/221 [00:13<00:29,  5.79it/s][A
 23%|██▎       | 50/221 [00:13<00:33,  5.10it/s][A
 23%|██▎       | 51/221 [00:13<00:37,  4.55it/s][A
 24%|██▍       | 53/221 [00:14<00:29,  5.75it/s][A
 24%|██▍       | 54/221 [00:14<00:33,  4.95it/s][A
 25%|██▍       | 55/221 [00:14<00:33,  5.00it/s][A
 25%|██▌       | 56/221 [00:14<00:34,  4.81it/s][A
 26%|██▌       | 57/221 [00:15<00:36,  4.49it/s][A
 26%|██▌       | 58/221 [00:15<00:33,  4.85it/s][A
 27%|██▋       | 59/221 [00:15<00:33,  4.83it/s][A
 27%|██▋       | 60/221 [00:15<00:38,  4.19it/s][A
 28%|██▊       | 61/221 [00:15<00:36,  4.43it/s][A
 28%|██▊       | 62/221 [00:16<00:36,  4.40it/s][A
 29%|██▊       | 63/221 [00:16<00:33,  4.73it/s][A
 29%|██▉       | 64/221 [00:16<00:32,  4.81it/s][A
 29%|██▉       | 65/221 [00:16<00:29,  5.31it/s][A
 30%|██▉       | 66/221 [00:17<00:34,  4.47it/s][A
 30%|███       | 67/221 [00:17<00:55,  2.76it/s][A
 31%|███       | 68/221 [00:17<00:48,  3.13it/s][A
 31%|███       | 69/221 [00:18<00:48,  3.15it/s][A
 32%|███▏      | 70/221 [00:18<00:41,  3.60it/s][A
 32%|███▏      | 71/221 [00:18<00:48,  3.08it/s][A
 33%|███▎      | 72/221 [00:19<00:52,  2.86it/s][A
 33%|███▎      | 73/221 [00:19<00:48,  3.05it/s][A
 33%|███▎      | 74/221 [00:19<00:44,  3.27it/s][A
 34%|███▍      | 75/221 [00:20<00:50,  2.90it/s][A
 35%|███▍      | 77/221 [00:20<00:35,  4.00it/s][A
 35%|███▌      | 78/221 [00:20<00:38,  3.70it/s][A
 36%|███▌      | 79/221 [00:21<00:41,  3.38it/s][A
 36%|███▌      | 80/221 [00:21<00:40,  3.46it/s][A
 37%|███▋      | 81/221 [00:21<00:39,  3.56it/s][A
 37%|███▋      | 82/221 [00:21<00:36,  3.78it/s][A
 38%|███▊      | 83/221 [00:22<00:33,  4.17it/s][A
 38%|███▊      | 84/221 [00:22<00:40,  3.42it/s][A
 38%|███▊      | 85/221 [00:22<00:43,  3.14it/s][A
 39%|███▉      | 86/221 [00:23<00:44,  3.00it/s][A
 39%|███▉      | 87/221 [00:23<00:55,  2.41it/s][A
 40%|███▉      | 88/221 [00:24<00:48,  2.75it/s][A
 40%|████      | 89/221 [00:24<00:48,  2.73it/s][A
 41%|████      | 90/221 [00:24<00:50,  2.60it/s][A
 41%|████      | 91/221 [00:25<00:41,  3.11it/s][A
 42%|████▏     | 92/221 [00:25<00:37,  3.44it/s][A
 42%|████▏     | 93/221 [00:25<00:45,  2.79it/s][A
 43%|████▎     | 94/221 [00:26<00:38,  3.27it/s][A
 43%|████▎     | 95/221 [00:26<00:46,  2.73it/s][A
 43%|████▎     | 96/221 [00:26<00:41,  2.99it/s][A
 44%|████▍     | 97/221 [00:27<00:40,  3.07it/s][A
 44%|████▍     | 98/221 [00:27<00:35,  3.44it/s][A
 45%|████▍     | 99/221 [00:27<00:33,  3.65it/s][A
 45%|████▌     | 100/221 [00:27<00:27,  4.40it/s][A
 46%|████▌     | 101/221 [00:27<00:28,  4.15it/s][A
 46%|████▌     | 102/221 [00:28<00:33,  3.56it/s][A
 47%|████▋     | 103/221 [00:28<00:29,  3.97it/s][A
 47%|████▋     | 104/221 [00:28<00:26,  4.38it/s][A
 48%|████▊     | 105/221 [00:28<00:26,  4.31it/s][A
 48%|████▊     | 106/221 [00:29<00:37,  3.10it/s][A
 48%|████▊     | 107/221 [00:29<00:33,  3.36it/s][A
 49%|████▉     | 108/221 [00:29<00:27,  4.10it/s][A
 49%|████▉     | 109/221 [00:30<00:30,  3.70it/s][A
 50%|████▉     | 110/221 [00:30<00:34,  3.18it/s][A
 50%|█████     | 111/221 [00:30<00:35,  3.07it/s][A
 51%|█████     | 112/221 [00:31<00:36,  3.01it/s][A
 51%|█████     | 113/221 [00:31<00:32,  3.29it/s][A
 52%|█████▏    | 115/221 [00:31<00:25,  4.20it/s][A
 52%|█████▏    | 116/221 [00:31<00:23,  4.50it/s][A
 53%|█████▎    | 117/221 [00:32<00:23,  4.46it/s][A
 53%|█████▎    | 118/221 [00:32<00:28,  3.62it/s][A
 54%|█████▍    | 119/221 [00:33<00:33,  3.05it/s][A
 54%|█████▍    | 120/221 [00:33<00:32,  3.11it/s][A
 55%|█████▌    | 122/221 [00:33<00:23,  4.15it/s][A
 56%|█████▌    | 123/221 [00:33<00:24,  4.00it/s][A
 56%|█████▌    | 124/221 [00:34<00:27,  3.55it/s][A
 57%|█████▋    | 125/221 [00:35<00:39,  2.40it/s][A
 57%|█████▋    | 126/221 [00:35<00:35,  2.69it/s][A
 57%|█████▋    | 127/221 [00:36<00:42,  2.20it/s][A
 58%|█████▊    | 128/221 [00:36<00:36,  2.54it/s][A
 58%|█████▊    | 129/221 [00:36<00:29,  3.13it/s][A
 59%|█████▉    | 130/221 [00:36<00:28,  3.24it/s][A
 59%|█████▉    | 131/221 [00:36<00:23,  3.76it/s][A
 60%|█████▉    | 132/221 [00:37<00:24,  3.57it/s][A
 60%|██████    | 133/221 [00:37<00:35,  2.50it/s][A
 61%|██████    | 134/221 [00:38<00:33,  2.63it/s][A
 61%|██████    | 135/221 [00:38<00:27,  3.17it/s][A
 62%|██████▏   | 136/221 [00:38<00:27,  3.08it/s][A
 62%|██████▏   | 137/221 [00:38<00:25,  3.28it/s][A
 62%|██████▏   | 138/221 [00:39<00:25,  3.25it/s][A
 63%|██████▎   | 139/221 [00:39<00:27,  2.97it/s][A
 63%|██████▎   | 140/221 [00:39<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:40<00:22,  3.49it/s][A
 64%|██████▍   | 142/221 [00:40<00:20,  3.84it/s][A
 65%|██████▍   | 143/221 [00:40<00:23,  3.33it/s][A
 65%|██████▌   | 144/221 [00:40<00:20,  3.79it/s][A
 66%|██████▌   | 145/221 [00:41<00:21,  3.62it/s][A
 66%|██████▌   | 146/221 [00:41<00:20,  3.58it/s][A
 67%|██████▋   | 147/221 [00:41<00:19,  3.87it/s][A
 67%|██████▋   | 148/221 [00:41<00:18,  3.97it/s][A
 67%|██████▋   | 149/221 [00:42<00:18,  3.98it/s][A
 68%|██████▊   | 150/221 [00:42<00:18,  3.86it/s][A
 68%|██████▊   | 151/221 [00:43<00:31,  2.19it/s][A
 69%|██████▉   | 152/221 [00:44<00:41,  1.66it/s][A
 69%|██████▉   | 153/221 [00:44<00:33,  2.03it/s][A
 70%|██████▉   | 154/221 [00:44<00:27,  2.46it/s][A
 70%|███████   | 155/221 [00:45<00:30,  2.18it/s][A
 71%|███████   | 156/221 [00:45<00:26,  2.41it/s][A
 71%|███████   | 157/221 [00:46<00:25,  2.50it/s][A
 71%|███████▏  | 158/221 [00:46<00:25,  2.45it/s][A
 72%|███████▏  | 159/221 [00:46<00:20,  2.96it/s][A
 72%|███████▏  | 160/221 [00:46<00:18,  3.39it/s][A
 73%|███████▎  | 161/221 [00:47<00:16,  3.60it/s][A
 73%|███████▎  | 162/221 [00:47<00:14,  4.10it/s][A
 74%|███████▍  | 163/221 [00:47<00:13,  4.23it/s][A
 74%|███████▍  | 164/221 [00:47<00:12,  4.66it/s][A
 75%|███████▍  | 165/221 [00:47<00:10,  5.50it/s][A
 75%|███████▌  | 166/221 [00:48<00:12,  4.32it/s][A
 76%|███████▌  | 167/221 [00:48<00:10,  4.98it/s][A
 76%|███████▌  | 168/221 [00:48<00:11,  4.75it/s][A
 76%|███████▋  | 169/221 [00:48<00:11,  4.69it/s][A
 77%|███████▋  | 170/221 [00:49<00:22,  2.27it/s][A
 77%|███████▋  | 171/221 [00:50<00:22,  2.25it/s][A
 78%|███████▊  | 172/221 [00:50<00:17,  2.75it/s][A
 78%|███████▊  | 173/221 [00:50<00:15,  3.07it/s][A
 79%|███████▊  | 174/221 [00:50<00:14,  3.34it/s][A
 79%|███████▉  | 175/221 [00:51<00:14,  3.08it/s][A
 80%|███████▉  | 176/221 [00:51<00:13,  3.34it/s][A
 80%|████████  | 177/221 [00:51<00:12,  3.52it/s][A
 81%|████████  | 178/221 [00:52<00:15,  2.77it/s][A
 81%|████████  | 179/221 [00:52<00:14,  2.82it/s][A
 81%|████████▏ | 180/221 [00:52<00:11,  3.53it/s][A
 82%|████████▏ | 181/221 [00:52<00:10,  3.79it/s][A
 82%|████████▏ | 182/221 [00:53<00:10,  3.80it/s][A
 83%|████████▎ | 183/221 [00:53<00:11,  3.37it/s][A
 83%|████████▎ | 184/221 [00:53<00:10,  3.50it/s][A
 84%|████████▎ | 185/221 [00:53<00:09,  3.94it/s][A
 84%|████████▍ | 186/221 [00:54<00:11,  3.11it/s][A
 85%|████████▍ | 187/221 [00:54<00:10,  3.22it/s][A
 85%|████████▌ | 188/221 [00:54<00:10,  3.15it/s][A
 86%|████████▌ | 189/221 [00:55<00:08,  3.62it/s][A
 86%|████████▌ | 190/221 [00:55<00:10,  2.94it/s][A
 86%|████████▋ | 191/221 [00:55<00:08,  3.71it/s][A
 87%|████████▋ | 192/221 [00:56<00:07,  3.75it/s][A
 87%|████████▋ | 193/221 [00:56<00:06,  4.52it/s][A
 88%|████████▊ | 194/221 [00:56<00:07,  3.80it/s][A
 88%|████████▊ | 195/221 [00:56<00:06,  4.28it/s][A
 89%|████████▊ | 196/221 [00:57<00:10,  2.44it/s][A
 89%|████████▉ | 197/221 [00:57<00:08,  2.71it/s][A
 90%|████████▉ | 198/221 [00:58<00:08,  2.59it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.27it/s][A
 90%|█████████ | 200/221 [00:58<00:06,  3.17it/s][A
 91%|█████████ | 201/221 [00:58<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.37it/s][A
 92%|█████████▏| 203/221 [00:59<00:04,  3.62it/s][A
 92%|█████████▏| 204/221 [00:59<00:04,  3.45it/s][A
 93%|█████████▎| 205/221 [00:59<00:04,  3.85it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.20it/s][A
 94%|█████████▎| 207/221 [01:00<00:04,  3.20it/s][A
 94%|█████████▍| 208/221 [01:00<00:03,  3.84it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.76it/s][A
 95%|█████████▌| 210/221 [01:01<00:02,  4.02it/s][A
 95%|█████████▌| 211/221 [01:01<00:02,  4.11it/s][A
 96%|█████████▌| 212/221 [01:01<00:02,  3.67it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.27it/s][A
 97%|█████████▋| 214/221 [01:02<00:02,  3.12it/s][A
 97%|█████████▋| 215/221 [01:02<00:01,  3.13it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.04it/s][A
 98%|█████████▊| 217/221 [01:03<00:01,  3.17it/s][A
 99%|█████████▊| 218/221 [01:03<00:00,  3.49it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.02it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.41it/s][A
100%|██████████| 221/221 [01:04<00:00,  2.92it/s][A100%|██████████| 221/221 [01:04<00:00,  3.41it/s]
09/17/2024 02:30:09 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 499--===========

09/17/2024 02:30:09 - INFO - __main__ -   {'area_r1': 39.7, 'area_recall': '39.7/66.4/75.0', 'area_ravg': 60.4}
09/17/2024 02:30:09 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 499--===========

09/17/2024 02:30:09 - INFO - __main__ -   {'forward_r1': 36.0, 'forward_recall': '36.0/65.0/75.2', 'forward_ravg': 58.7}
09/17/2024 02:30:09 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 499--===========

09/17/2024 02:30:09 - INFO - __main__ -   {'area_video_r1': 39.9, 'area_video_recall': '39.9/67.5/77.4', 'area_video_ravg': 61.6}
09/17/2024 02:30:09 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 299=======

09/17/2024 02:30:09 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 02:30:09 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 499--===========

09/17/2024 02:30:09 - INFO - __main__ -   {'area_video_r1': 53.2, 'area_video_recall': '53.2/74.9/83.1', 'area_video_ravg': 70.4, 'area_video_back_r1': 50.3, 'area_video_back_recall': '50.3/75.5/81.8', 'area_video_back_ravg': 69.2}
09/17/2024 02:30:09 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 399=======

09/17/2024 02:30:09 - INFO - __main__ -   {'area_video_r1': 54.0, 'area_video_recall': '54.0/74.4/82.9', 'area_video_ravg': 70.4, 'area_video_back_r1': 49.7, 'area_video_back_recall': '49.7/74.5/81.4', 'area_video_back_ravg': 68.6}
09/17/2024 02:30:09 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 499--===========

09/17/2024 02:30:09 - INFO - __main__ -   {'video_r1': 35.9, 'video_recall': '35.9/64.3/73.8', 'video_ravg': 58.0}
09/17/2024 02:30:09 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 249=======

09/17/2024 02:30:09 - INFO - __main__ -   {'video_r1': 37.1, 'video_recall': '37.1/65.0/74.1', 'video_ravg': 58.7}
09/17/2024 02:30:09 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 499--===========

09/17/2024 02:30:09 - INFO - __main__ -   {'video_r1': 53.8, 'video_recall': '53.8/75.7/83.4', 'video_ravg': 71.0}
09/17/2024 02:30:09 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 499=======

09/17/2024 02:30:09 - INFO - __main__ -   {'video_r1': 53.8, 'video_recall': '53.8/75.7/83.4', 'video_ravg': 71.0}
09/17/2024 02:30:38 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.010271865874528885, 'loss_ret%tv%ta--finetune_area/loss_area': 1.20875084400177, 'loss_ret%tv%ta--finetune_area/total_loss': 1.2190227508544922}
[h264 @ 0x55a260ae8500] mmco: unref short failure
[h264 @ 0x55a260ae8500] mmco: unref short failure
[h264 @ 0x55a260ae8500] mmco: unref short failure
[h264 @ 0x55a260ae8500] mmco: unref short failure
[h264 @ 0x55e1a30c2580] mmco: unref short failure
 17%|█▋        | 500/2910 [3:08:55<90:48:52, 135.66s/it] 17%|█▋        | 501/2910 [3:08:59<64:15:53, 96.04s/it] [h264 @ 0x55e19b021480] mmco: unref short failure
[h264 @ 0x55e19b021480] mmco: unref short failure
 17%|█▋        | 502/2910 [3:09:03<45:47:39, 68.46s/it] 17%|█▋        | 503/2910 [3:09:07<32:56:16, 49.26s/it]09/17/2024 02:30:57 - INFO - __main__ -   current idx OTXYBNGzWpQ.110 from finetune_area returns wrong image/video, use 97549 instead.
 17%|█▋        | 504/2910 [3:09:12<24:00:05, 35.91s/it][h264 @ 0x5606a388e940] mmco: unref short failure
 17%|█▋        | 505/2910 [3:09:17<17:45:25, 26.58s/it] 17%|█▋        | 506/2910 [3:09:22<13:22:27, 20.03s/it][h264 @ 0x55b4f36bc9c0] mmco: unref short failure
 17%|█▋        | 507/2910 [3:09:28<10:33:21, 15.81s/it] 17%|█▋        | 508/2910 [3:09:33<8:25:27, 12.63s/it]  17%|█▋        | 509/2910 [3:09:38<6:59:14, 10.48s/it] 18%|█▊        | 510/2910 [3:09:44<5:56:49,  8.92s/it][h264 @ 0x55e183d01640] mmco: unref short failure
[h264 @ 0x55e183d01640] mmco: unref short failure
 18%|█▊        | 511/2910 [3:09:49<5:18:58,  7.98s/it][h264 @ 0x55e1830d7a40] mmco: unref short failure
[h264 @ 0x55e1830d7a40] mmco: unref short failure
 18%|█▊        | 512/2910 [3:09:58<5:24:53,  8.13s/it][h264 @ 0x55a25cb87640] mmco: unref short failure
[h264 @ 0x55a25cb87640] mmco: unref short failure
[h264 @ 0x55a25cb87640] mmco: unref short failure
 18%|█▊        | 513/2910 [3:10:06<5:23:05,  8.09s/it][h264 @ 0x5606a0ab0dc0] mmco: unref short failure
[h264 @ 0x5606a0ab0dc0] mmco: unref short failure
[h264 @ 0x55e19321cac0] mmco: unref short failure
 18%|█▊        | 514/2910 [3:10:12<4:55:34,  7.40s/it] 18%|█▊        | 515/2910 [3:10:17<4:31:44,  6.81s/it][h264 @ 0x55e187a13080] mmco: unref short failure
[h264 @ 0x55e187a13080] mmco: unref short failure
[h264 @ 0x55e187a13080] mmco: unref short failure
[h264 @ 0x55e187a13080] mmco: unref short failure
[h264 @ 0x55a26a9924c0] mmco: unref short failure
[h264 @ 0x55a26a9924c0] mmco: unref short failure
[h264 @ 0x55b4f39f9400] mmco: unref short failure
[h264 @ 0x55b4f39f9400] mmco: unref short failure
[h264 @ 0x55e18f399c80] mmco: unref short failure
[h264 @ 0x55e19dc07440] mmco: unref short failure
[h264 @ 0x55e19dc07440] mmco: unref short failure
[h264 @ 0x55a25befe300] mmco: unref short failure
[h264 @ 0x55a25befe300] mmco: unref short failure
[h264 @ 0x56068c4ac0c0] mmco: unref short failure
[h264 @ 0x55a26319fb80] mmco: unref short failure
[h264 @ 0x55a26319fb80] mmco: unref short failure
[h264 @ 0x55e1980bdd40] mmco: unref short failure
[h264 @ 0x55e187a13080] mmco: unref short failure
[h264 @ 0x55e187a13080] mmco: unref short failure
[h264 @ 0x55e187a13080] mmco: unref short failure
[h264 @ 0x55e187a13080] mmco: unref short failure
[h264 @ 0x55e190afe500] mmco: unref short failure
[h264 @ 0x55e190afe500] mmco: unref short failure
[h264 @ 0x55a272a1c380] mmco: unref short failure
[h264 @ 0x55a272a1c380] mmco: unref short failure
[h264 @ 0x55a272a1c380] mmco: unref short failure
[h264 @ 0x55a272a1c380] mmco: unref short failure
[h264 @ 0x5606aeb2f300] mmco: unref short failure
 18%|█▊        | 516/2910 [3:11:16<15:01:50, 22.60s/it][h264 @ 0x55e18302cb40] mmco: unref short failure
[h264 @ 0x55e18302cb40] mmco: unref short failure
 18%|█▊        | 517/2910 [3:11:23<11:44:28, 17.66s/it][h264 @ 0x55e1a30c2580] mmco: unref short failure
 18%|█▊        | 518/2910 [3:11:28<9:18:44, 14.02s/it] [h264 @ 0x5606a388e940] mmco: unref short failure
[h264 @ 0x55e1a4a49700] mmco: unref short failure
[h264 @ 0x560690c959c0] mmco: unref short failure
[h264 @ 0x560690c959c0] mmco: unref short failure
[h264 @ 0x560690c959c0] mmco: unref short failure
[h264 @ 0x55b4f3fee000] mmco: unref short failure
[h264 @ 0x55b4f3fee000] mmco: unref short failure
[h264 @ 0x55a27c4026c0] mmco: unref short failure
[h264 @ 0x55a27c4026c0] mmco: unref short failure
 18%|█▊        | 519/2910 [3:11:35<7:57:40, 11.99s/it][h264 @ 0x5606ad5e0e40] mmco: unref short failure
[h264 @ 0x560691b18b40] mmco: unref short failure
[h264 @ 0x560691b18b40] mmco: unref short failure
 18%|█▊        | 520/2910 [3:11:41<6:40:46, 10.06s/it][h264 @ 0x55b4fc827900] mmco: unref short failure
[h264 @ 0x55b4fc827900] mmco: unref short failure
[h264 @ 0x56069d7f2ac0] mmco: unref short failure
[h264 @ 0x56069d7f2ac0] mmco: unref short failure
[h264 @ 0x56068f214f40] mmco: unref short failure
 18%|█▊        | 521/2910 [3:12:01<8:45:28, 13.20s/it] 18%|█▊        | 522/2910 [3:12:06<7:04:17, 10.66s/it][h264 @ 0x56069e6a2900] mmco: unref short failure
 18%|█▊        | 523/2910 [3:12:17<7:05:14, 10.69s/it][h264 @ 0x5606910166c0] mmco: unref short failure
[h264 @ 0x5606910166c0] mmco: unref short failure
[h264 @ 0x55a26cfa57c0] mmco: unref short failure
[h264 @ 0x55b503873880] mmco: unref short failure
[h264 @ 0x55b4fa346900] mmco: unref short failure
[h264 @ 0x55a27ce7c240] mmco: unref short failure
[h264 @ 0x55a27ce7c240] mmco: unref short failure
09/17/2024 02:34:34 - INFO - __main__ -   current idx ZJ3l8xjgJQw.15 from finetune_area returns wrong image/video, use 19056 instead.
[h264 @ 0x55e18364c300] mmco: unref short failure
[h264 @ 0x55b505409a40] mmco: unref short failure
[h264 @ 0x55b505409a40] mmco: unref short failure
[h264 @ 0x55b4fab56800] mmco: unref short failure
[h264 @ 0x55b512c82b80] mmco: unref short failure
[h264 @ 0x55b50e2890c0] mmco: unref short failure
[h264 @ 0x55b50e2890c0] mmco: unref short failure
[h264 @ 0x56069a937b00] mmco: unref short failure
[h264 @ 0x55e1a4a49700] mmco: unref short failure
[h264 @ 0x55e1a4a49700] mmco: unref short failure
[h264 @ 0x55e1a4a49700] mmco: unref short failure
[h264 @ 0x55e1a4a49700] mmco: unref short failure
[h264 @ 0x5606ad2493c0] mmco: unref short failure
[h264 @ 0x5606ad2493c0] mmco: unref short failure
[h264 @ 0x55a27ce7c240] mmco: unref short failure
 18%|█▊        | 524/2910 [3:13:48<23:09:20, 34.94s/it][h264 @ 0x5606a968c840] mmco: unref short failure
[h264 @ 0x560697395d40] mmco: unref short failure
[h264 @ 0x560697395d40] mmco: unref short failure
[h264 @ 0x560697395d40] mmco: unref short failure
[h264 @ 0x560697395d40] mmco: unref short failure
 18%|█▊        | 525/2910 [3:13:57<17:57:07, 27.10s/it]09/17/2024 02:35:45 - INFO - __main__ -   current idx cXoOWKkZ_K0.13 from finetune_area returns wrong image/video, use 51075 instead.
[h264 @ 0x55a25bb58940] mmco: unref short failure
[h264 @ 0x55a25bb58940] mmco: unref short failure
 18%|█▊        | 526/2910 [3:14:04<13:51:11, 20.92s/it][h264 @ 0x55e19dc07440] mmco: unref short failure
[h264 @ 0x55e19dc07440] mmco: unref short failure
[h264 @ 0x55e19dc07440] mmco: unref short failure
 18%|█▊        | 527/2910 [3:14:09<10:40:40, 16.13s/it][h264 @ 0x55a27ce7c240] mmco: unref short failure
[h264 @ 0x55a25befe300] mmco: unref short failure
[h264 @ 0x55a25befe300] mmco: unref short failure
 18%|█▊        | 528/2910 [3:14:14<8:35:09, 12.98s/it] [h264 @ 0x55a25bb58940] mmco: unref short failure
[h264 @ 0x55a25bb58940] mmco: unref short failure
 18%|█▊        | 529/2910 [3:14:29<8:56:26, 13.52s/it][h264 @ 0x55e1826cbb00] mmco: unref short failure
[h264 @ 0x55e1826cbb00] mmco: unref short failure
 18%|█▊        | 530/2910 [3:14:34<7:16:10, 11.00s/it][h264 @ 0x56069b2e4680] mmco: unref short failure
[h264 @ 0x56069b2e4680] mmco: unref short failure
 18%|█▊        | 531/2910 [3:14:51<8:21:04, 12.64s/it][h264 @ 0x55b50f80f000] mmco: unref short failure
[h264 @ 0x55a28077bcc0] mmco: unref short failure
[h264 @ 0x55a28077bcc0] mmco: unref short failure
[h264 @ 0x55a28077bcc0] mmco: unref short failure
[h264 @ 0x55a28077bcc0] mmco: unref short failure
[h264 @ 0x56069de1c140] mmco: unref short failure
[h264 @ 0x56069de1c140] mmco: unref short failure
[h264 @ 0x55b4fb039dc0] mmco: unref short failure
[h264 @ 0x55b4fb039dc0] mmco: unref short failure
[h264 @ 0x55e18e80dc80] mmco: unref short failure
[h264 @ 0x55a25befe300] mmco: unref short failure
[h264 @ 0x55a25befe300] mmco: unref short failure
[h264 @ 0x55a27ce7c240] mmco: unref short failure
[h264 @ 0x55a27ce7c240] mmco: unref short failure
[h264 @ 0x55a25befe300] mmco: unref short failure
[h264 @ 0x55a25befe300] mmco: unref short failure
[h264 @ 0x55a25befe300] mmco: unref short failure
[h264 @ 0x55a25befe300] mmco: unref short failure
[h264 @ 0x5606a3ffbac0] mmco: unref short failure
[h264 @ 0x5606a3ffbac0] mmco: unref short failure
[h264 @ 0x55b500ddc180] mmco: unref short failure
09/17/2024 02:37:46 - INFO - __main__ -   current idx EMPLLx_tfq8.250 from finetune_area returns wrong image/video, use 27288 instead.
[h264 @ 0x56069b2e4680] mmco: unref short failure
 18%|█▊        | 532/2910 [3:16:19<23:24:08, 35.43s/it]09/17/2024 02:38:07 - INFO - __main__ -   current idx 4Svr6BsWgeU.14 from finetune_area returns wrong image/video, use 37350 instead.
09/17/2024 02:38:08 - INFO - __main__ -   current idx hvuxWKYHJlQ.82 from finetune_area returns wrong image/video, use 113831 instead.
 18%|█▊        | 533/2910 [3:16:25<17:26:47, 26.42s/it][h264 @ 0x560696bf32c0] mmco: unref short failure
[h264 @ 0x560696bf32c0] mmco: unref short failure
09/17/2024 02:38:13 - INFO - __main__ -   current idx DfKw_sMqEaA.16 from finetune_area returns wrong image/video, use 33748 instead.
[h264 @ 0x55a25befe300] mmco: unref short failure
 18%|█▊        | 534/2910 [3:16:31<13:28:20, 20.41s/it][h264 @ 0x5606abd43780] mmco: unref short failure
 18%|█▊        | 535/2910 [3:16:37<10:37:12, 16.10s/it][h264 @ 0x55b50617bac0] mmco: unref short failure
[h264 @ 0x55b50617bac0] mmco: unref short failure
[h264 @ 0x55b50617bac0] mmco: unref short failure
[h264 @ 0x55b50617bac0] mmco: unref short failure
[h264 @ 0x55a25bbb8840] mmco: unref short failure
 18%|█▊        | 536/2910 [3:16:43<8:31:06, 12.92s/it] [h264 @ 0x560695a20e00] mmco: unref short failure
[h264 @ 0x560695a20e00] mmco: unref short failure
[h264 @ 0x56068c69cd80] mmco: unref short failure
[h264 @ 0x55a27ce7c240] mmco: unref short failure
 18%|█▊        | 537/2910 [3:16:57<8:51:19, 13.43s/it][h264 @ 0x55e19262ef00] mmco: unref short failure
[h264 @ 0x55a27137d940] mmco: unref short failure
[h264 @ 0x55b4f88409c0] mmco: unref short failure
[h264 @ 0x55b4f88409c0] mmco: unref short failure
 18%|█▊        | 538/2910 [3:17:04<7:26:04, 11.28s/it][h264 @ 0x55e19a8d1740] mmco: unref short failure
[h264 @ 0x55e19a8d1740] mmco: unref short failure
[h264 @ 0x55e19a8d1740] mmco: unref short failure
[h264 @ 0x560691b1dac0] mmco: unref short failure
[h264 @ 0x560691b1dac0] mmco: unref short failure
[h264 @ 0x5606ad226900] mmco: unref short failure
[h264 @ 0x5606ad226900] mmco: unref short failure
[h264 @ 0x5606ad226900] mmco: unref short failure
[h264 @ 0x5606ad226900] mmco: unref short failure
[h264 @ 0x5606ad0dc100] mmco: unref short failure
[h264 @ 0x55e1843fc7c0] mmco: unref short failure
[h264 @ 0x55b4f6de9900] mmco: unref short failure
[h264 @ 0x55b4f6de9900] mmco: unref short failure
[h264 @ 0x55b4f6de9900] mmco: unref short failure
 19%|█▊        | 539/2910 [3:17:24<9:09:51, 13.91s/it][h264 @ 0x55b4fe1cee00] mmco: unref short failure
[h264 @ 0x56068ee9b400] mmco: unref short failure
[h264 @ 0x56068ee9b400] mmco: unref short failure
[h264 @ 0x55a2780c6e40] mmco: unref short failure
[h264 @ 0x5606ad226900] mmco: unref short failure
[h264 @ 0x5606ad226900] mmco: unref short failure
[h264 @ 0x55a2780c6e40] mmco: unref short failure
[h264 @ 0x55b4fbc9b200] mmco: unref short failure
[h264 @ 0x55a26a255900] mmco: unref short failure
[h264 @ 0x55a261902c00] mmco: unref short failure
[h264 @ 0x55a261902c00] mmco: unref short failure
[h264 @ 0x55a261902c00] mmco: unref short failure
[h264 @ 0x55b4f3ffcf80] mmco: unref short failure
[h264 @ 0x55a25bcf6f40] mmco: unref short failure
[h264 @ 0x55a25bcf6f40] mmco: unref short failure
[h264 @ 0x55b512274640] mmco: unref short failure
[h264 @ 0x5606a7b15700] mmco: unref short failure
[h264 @ 0x5606a7b15700] mmco: unref short failure
 19%|█▊        | 540/2910 [3:18:52<23:56:48, 36.38s/it]09/17/2024 02:40:46 - INFO - __main__ -   current idx 4hOPcrHDBvU.10 from finetune_area returns wrong image/video, use 131957 instead.
[h264 @ 0x56068d5e9cc0] mmco: unref short failure
[h264 @ 0x56068d5e9cc0] mmco: unref short failure
[h264 @ 0x56069060dd40] mmco: unref short failure
[h264 @ 0x56069060dd40] mmco: unref short failure
[h264 @ 0x55e1843fc7c0] mmco: unref short failure
[h264 @ 0x55e1843fc7c0] mmco: unref short failure
[h264 @ 0x55e18701aec0] mmco: unref short failure
 19%|█▊        | 541/2910 [3:19:22<22:36:00, 34.34s/it] 19%|█▊        | 542/2910 [3:19:27<16:47:23, 25.53s/it] 19%|█▊        | 543/2910 [3:19:32<12:46:59, 19.44s/it][h264 @ 0x5606aab23a40] mmco: unref short failure
 19%|█▊        | 544/2910 [3:19:37<9:58:40, 15.18s/it]  19%|█▊        | 545/2910 [3:19:43<8:03:33, 12.27s/it][h264 @ 0x55a281df4ec0] mmco: unref short failure
[h264 @ 0x55a281df4ec0] mmco: unref short failure
[h264 @ 0x55b5134bbd40] mmco: unref short failure
[h264 @ 0x55e19a8d1740] mmco: unref short failure
[h264 @ 0x55b4fab56800] mmco: unref short failure
[h264 @ 0x55b4fab56800] mmco: unref short failure
 19%|█▉        | 546/2910 [3:19:49<6:46:32, 10.32s/it] 19%|█▉        | 547/2910 [3:19:55<5:56:48,  9.06s/it][h264 @ 0x55e194e46000] mmco: unref short failure
[h264 @ 0x55e194e46000] mmco: unref short failure
[h264 @ 0x55e194e46000] mmco: unref short failure
[h264 @ 0x55e194e46000] mmco: unref short failure
09/17/2024 02:41:45 - INFO - __main__ -   current idx E852WPZZnME.32 from finetune_area returns wrong image/video, use 83757 instead.
[h264 @ 0x55e18bcdf600] mmco: unref short failure
[h264 @ 0x55e18bcdf600] mmco: unref short failure
[h264 @ 0x55b4fb039dc0] mmco: unref short failure
[h264 @ 0x55b4fb039dc0] mmco: unref short failure
[h264 @ 0x55b4f3f43900] mmco: unref short failure
[h264 @ 0x55b4f3f43900] mmco: unref short failure
[h264 @ 0x55e1826c1b80] mmco: unref short failure
[h264 @ 0x55e1826c1b80] mmco: unref short failure
[h264 @ 0x56068bf59d40] mmco: unref short failure
[h264 @ 0x56068bf59d40] mmco: unref short failure
[h264 @ 0x560691d4a980] mmco: unref short failure
09/17/2024 02:42:08 - INFO - __main__ -   current idx _Z6qrnWrgYM.80 from finetune_area returns wrong image/video, use 87635 instead.
[h264 @ 0x56068e838dc0] mmco: unref short failure
[h264 @ 0x55b4fd9cf7c0] mmco: unref short failure
[h264 @ 0x55b4fd9cf7c0] mmco: unref short failure
[h264 @ 0x55b4fd9cf7c0] mmco: unref short failure
[h264 @ 0x55b4fd9cf7c0] mmco: unref short failure
[h264 @ 0x55b505409a40] mmco: unref short failure
[h264 @ 0x55b4f6de9900] mmco: unref short failure
[h264 @ 0x55e1830bb2c0] mmco: unref short failure
[h264 @ 0x55a277d67680] mmco: unref short failure
[h264 @ 0x55b4f9fc4b40] mmco: unref short failure
[h264 @ 0x55b4f9fc4b40] mmco: unref short failure
[h264 @ 0x56069f0e1cc0] mmco: unref short failure
[h264 @ 0x56069f0e1cc0] mmco: unref short failure
 19%|█▉        | 548/2910 [3:21:21<21:10:26, 32.27s/it][h264 @ 0x55e19a465680] mmco: unref short failure
[h264 @ 0x55e19a465680] mmco: unref short failure
[h264 @ 0x55e19a465680] mmco: unref short failure
[h264 @ 0x55e19a465680] mmco: unref short failure
[h264 @ 0x55e198c041c0] mmco: unref short failure
[h264 @ 0x55b5097ae440] mmco: unref short failure
[h264 @ 0x55b5097ae440] mmco: unref short failure
[h264 @ 0x5606a559d480] mmco: unref short failure
[h264 @ 0x56068ee9b400] mmco: unref short failure
[h264 @ 0x56068c69cd80] mmco: unref short failure
[h264 @ 0x56068c69cd80] mmco: unref short failure
[h264 @ 0x56068c69cd80] mmco: unref short failure
[h264 @ 0x56068c69cd80] mmco: unref short failure
[h264 @ 0x56069f8a0600] mmco: unref short failure
[h264 @ 0x56069f8a0600] mmco: unref short failure
[h264 @ 0x56069b22e980] mmco: unref short failure
[h264 @ 0x56069b22e980] mmco: unref short failure
[h264 @ 0x5606aca96300] mmco: unref short failure
[h264 @ 0x5606aca96300] mmco: unref short failure
[h264 @ 0x55e1843fc7c0] mmco: unref short failure
[h264 @ 0x55e1843fc7c0] mmco: unref short failure
 19%|█▉        | 549/2910 [3:21:50<20:32:22, 31.32s/it]09/17/2024 02:43:36 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 02:43:36 - INFO - __main__ -   start running ret%tva validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x56068ee9b400] mmco: unref short failure
[h264 @ 0x55e1826c1b80] mmco: unref short failure
[h264 @ 0x55e1826c1b80] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a25cd74c00] mmco: unref short failure
[h264 @ 0x55a25cd74c00] mmco: unref short failure
[h264 @ 0x55a25bbf0a00] mmco: unref short failure
[h264 @ 0x55b4f6de9900] mmco: unref short failure
[h264 @ 0x56068ee9b400] mmco: unref short failure
[h264 @ 0x56068ee9b400] mmco: unref short failure
[h264 @ 0x5606a3dc89c0] mmco: unref short failure
[h264 @ 0x5606a3dc89c0] mmco: unref short failure
[h264 @ 0x55a27c4026c0] mmco: unref short failure
[h264 @ 0x55e1a1acfdc0] mmco: unref short failure
[h264 @ 0x56068ee9b400] mmco: unref short failure
[h264 @ 0x56068ee9b400] mmco: unref short failure
[h264 @ 0x5606aca96300] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:44,  1.34it/s][A
  1%|          | 2/221 [00:01<02:16,  1.60it/s][A
  1%|▏         | 3/221 [00:01<01:41,  2.14it/s][A
  2%|▏         | 4/221 [00:01<01:22,  2.64it/s][A
  2%|▏         | 5/221 [00:02<01:14,  2.89it/s][A
  3%|▎         | 6/221 [00:02<01:00,  3.53it/s][A
  3%|▎         | 7/221 [00:02<00:55,  3.83it/s][A
  4%|▎         | 8/221 [00:02<01:08,  3.09it/s][A
  4%|▍         | 9/221 [00:03<01:06,  3.16it/s][A
  5%|▍         | 10/221 [00:03<01:18,  2.67it/s][A
  5%|▍         | 11/221 [00:03<01:07,  3.09it/s][A
  5%|▌         | 12/221 [00:04<01:21,  2.56it/s][A
  6%|▌         | 13/221 [00:04<01:14,  2.78it/s][A
  6%|▋         | 14/221 [00:05<01:59,  1.73it/s][A
  7%|▋         | 15/221 [00:06<01:33,  2.20it/s][A
  7%|▋         | 16/221 [00:06<01:27,  2.34it/s][A
  8%|▊         | 17/221 [00:07<01:48,  1.88it/s][A
  8%|▊         | 18/221 [00:07<01:33,  2.18it/s][A
  9%|▊         | 19/221 [00:07<01:14,  2.73it/s][A
  9%|▉         | 20/221 [00:07<01:01,  3.27it/s][A[h264 @ 0x55e1a247cdc0] mmco: unref short failure
[h264 @ 0x55e1a247cdc0] mmco: unref short failure

 10%|▉         | 21/221 [00:07<00:55,  3.59it/s][A
 10%|▉         | 22/221 [00:08<01:00,  3.31it/s][A
 10%|█         | 23/221 [00:08<00:52,  3.79it/s][A
 11%|█         | 24/221 [00:08<00:46,  4.22it/s][A
 11%|█▏        | 25/221 [00:08<00:45,  4.34it/s][A
 12%|█▏        | 26/221 [00:09<00:59,  3.27it/s][A
 12%|█▏        | 27/221 [00:09<00:48,  3.99it/s][A
 13%|█▎        | 28/221 [00:10<01:05,  2.96it/s][A
 13%|█▎        | 29/221 [00:10<01:25,  2.24it/s][A[h264 @ 0x55b4f2319680] mmco: unref short failure
[h264 @ 0x55b4f2319680] mmco: unref short failure

 14%|█▎        | 30/221 [00:11<01:14,  2.55it/s][A
 14%|█▍        | 31/221 [00:11<01:10,  2.69it/s][A[h264 @ 0x55a25be8c900] mmco: unref short failure
[h264 @ 0x55a25be8c900] mmco: unref short failure

 14%|█▍        | 32/221 [00:11<00:56,  3.35it/s][A
 15%|█▍        | 33/221 [00:11<00:51,  3.63it/s][A
 15%|█▌        | 34/221 [00:11<00:48,  3.88it/s][A
 16%|█▌        | 35/221 [00:12<00:43,  4.27it/s][A
 16%|█▋        | 36/221 [00:12<00:51,  3.60it/s][A
 17%|█▋        | 37/221 [00:13<01:07,  2.72it/s][A
 17%|█▋        | 38/221 [00:13<01:16,  2.38it/s][A
 18%|█▊        | 39/221 [00:13<01:12,  2.52it/s][A
 18%|█▊        | 40/221 [00:14<01:12,  2.50it/s][A
 19%|█▊        | 41/221 [00:14<01:03,  2.82it/s][A
 19%|█▉        | 42/221 [00:15<01:09,  2.57it/s][A
 19%|█▉        | 43/221 [00:15<00:54,  3.25it/s][A
 20%|█▉        | 44/221 [00:15<00:46,  3.81it/s][A
 20%|██        | 45/221 [00:16<01:39,  1.77it/s][A
 21%|██        | 46/221 [00:17<01:36,  1.82it/s][A
 21%|██▏       | 47/221 [00:17<01:43,  1.69it/s][A
 22%|██▏       | 48/221 [00:17<01:19,  2.18it/s][A
 22%|██▏       | 49/221 [00:18<01:28,  1.93it/s][A
 23%|██▎       | 50/221 [00:19<01:31,  1.87it/s][A
 23%|██▎       | 51/221 [00:19<01:10,  2.42it/s][A
 24%|██▎       | 52/221 [00:19<01:03,  2.65it/s][A
 24%|██▍       | 53/221 [00:19<00:51,  3.25it/s][A
 24%|██▍       | 54/221 [00:22<02:29,  1.12it/s][A
 25%|██▍       | 55/221 [00:22<02:00,  1.37it/s][A
 25%|██▌       | 56/221 [00:22<01:36,  1.72it/s][A[h264 @ 0x56069269f080] mmco: unref short failure

 26%|██▌       | 57/221 [00:23<01:32,  1.77it/s][A
 26%|██▌       | 58/221 [00:23<01:16,  2.12it/s][A
 27%|██▋       | 59/221 [00:23<01:05,  2.46it/s][A
 27%|██▋       | 60/221 [00:24<01:13,  2.19it/s][A
 28%|██▊       | 61/221 [00:24<01:01,  2.59it/s][A[h264 @ 0x55a25bc45580] mmco: unref short failure

 28%|██▊       | 62/221 [00:24<00:56,  2.81it/s][A
 29%|██▊       | 63/221 [00:25<00:56,  2.79it/s][A
 29%|██▉       | 64/221 [00:25<00:47,  3.32it/s][A
 29%|██▉       | 65/221 [00:25<00:40,  3.88it/s][A
 30%|██▉       | 66/221 [00:25<00:46,  3.35it/s][A
 30%|███       | 67/221 [00:26<00:57,  2.67it/s][A
 31%|███       | 68/221 [00:26<00:48,  3.14it/s][A
 31%|███       | 69/221 [00:27<01:08,  2.23it/s][A
 32%|███▏      | 70/221 [00:27<00:53,  2.80it/s][A
 32%|███▏      | 71/221 [00:28<01:32,  1.62it/s][A
 33%|███▎      | 72/221 [00:28<01:15,  1.98it/s][A
 33%|███▎      | 73/221 [00:29<01:06,  2.23it/s][A
 33%|███▎      | 74/221 [00:29<00:55,  2.63it/s][A[h264 @ 0x55e1a1acfdc0] mmco: unref short failure
[h264 @ 0x55e1a1acfdc0] mmco: unref short failure

 34%|███▍      | 75/221 [00:29<00:54,  2.66it/s][A
 34%|███▍      | 76/221 [00:29<00:44,  3.29it/s][A[h264 @ 0x55a25c966c80] mmco: unref short failure

 35%|███▍      | 77/221 [00:30<00:42,  3.38it/s][A
 35%|███▌      | 78/221 [00:30<00:41,  3.49it/s][A
 36%|███▌      | 79/221 [00:31<00:53,  2.65it/s][A
 36%|███▌      | 80/221 [00:31<00:46,  3.03it/s][A
 37%|███▋      | 81/221 [00:31<00:45,  3.09it/s][A
 37%|███▋      | 82/221 [00:32<01:04,  2.16it/s][A
 38%|███▊      | 83/221 [00:32<01:01,  2.23it/s][A
 38%|███▊      | 84/221 [00:33<00:53,  2.56it/s][A
 38%|███▊      | 85/221 [00:33<00:48,  2.79it/s][A
 39%|███▉      | 86/221 [00:33<00:49,  2.71it/s][A
 39%|███▉      | 87/221 [00:34<00:57,  2.32it/s][A
 40%|███▉      | 88/221 [00:34<00:57,  2.31it/s][A
 40%|████      | 89/221 [00:35<00:59,  2.20it/s][A
 41%|████      | 90/221 [00:35<00:50,  2.60it/s][A
 41%|████      | 91/221 [00:35<00:39,  3.32it/s][A
 42%|████▏     | 92/221 [00:35<00:34,  3.79it/s][A
 42%|████▏     | 93/221 [00:36<00:37,  3.44it/s][A
 43%|████▎     | 94/221 [00:36<00:36,  3.49it/s][A
 43%|████▎     | 95/221 [00:36<00:36,  3.49it/s][A
 43%|████▎     | 96/221 [00:36<00:35,  3.55it/s][A
 44%|████▍     | 97/221 [00:37<00:29,  4.17it/s][A
 44%|████▍     | 98/221 [00:37<00:31,  3.95it/s][A
 45%|████▍     | 99/221 [00:37<00:25,  4.71it/s][A
 45%|████▌     | 100/221 [00:37<00:25,  4.73it/s][A
 46%|████▌     | 101/221 [00:37<00:21,  5.51it/s][A
 46%|████▌     | 102/221 [00:38<00:26,  4.45it/s][A
 47%|████▋     | 103/221 [00:38<00:24,  4.79it/s][A
 47%|████▋     | 104/221 [00:38<00:26,  4.39it/s][A[h264 @ 0x55b4f7130000] mmco: unref short failure

 48%|████▊     | 105/221 [00:38<00:31,  3.66it/s][A
 48%|████▊     | 106/221 [00:39<00:43,  2.65it/s][A
 48%|████▊     | 107/221 [00:39<00:35,  3.22it/s][A
 49%|████▉     | 108/221 [00:39<00:31,  3.55it/s][A
 49%|████▉     | 109/221 [00:40<00:29,  3.76it/s][A
 50%|████▉     | 110/221 [00:40<00:28,  3.84it/s][A
 50%|█████     | 111/221 [00:40<00:37,  2.97it/s][A
 51%|█████     | 112/221 [00:41<00:30,  3.56it/s][A
 51%|█████     | 113/221 [00:41<00:30,  3.56it/s][A
 52%|█████▏    | 115/221 [00:41<00:20,  5.22it/s][A
 52%|█████▏    | 116/221 [00:46<02:12,  1.26s/it][A
 53%|█████▎    | 117/221 [00:46<01:44,  1.01s/it][A
 53%|█████▎    | 118/221 [00:46<01:21,  1.26it/s][A
 54%|█████▍    | 119/221 [00:46<01:04,  1.58it/s][A
 54%|█████▍    | 120/221 [00:47<00:53,  1.89it/s][A
 55%|█████▌    | 122/221 [00:47<00:34,  2.85it/s][A
 56%|█████▌    | 123/221 [00:47<00:29,  3.37it/s][A
 56%|█████▌    | 124/221 [00:47<00:26,  3.73it/s][A
 57%|█████▋    | 125/221 [00:47<00:25,  3.73it/s][A
 57%|█████▋    | 126/221 [00:48<00:24,  3.82it/s][A
 57%|█████▋    | 127/221 [00:48<00:32,  2.87it/s][A
 58%|█████▊    | 128/221 [00:49<00:32,  2.82it/s][A
 58%|█████▊    | 129/221 [00:49<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:49<00:25,  3.63it/s][A
 60%|█████▉    | 132/221 [00:49<00:17,  5.03it/s][A
 60%|██████    | 133/221 [00:50<00:22,  3.94it/s][A
 61%|██████    | 134/221 [00:50<00:20,  4.25it/s][A
 61%|██████    | 135/221 [00:50<00:23,  3.63it/s][A
 62%|██████▏   | 136/221 [00:51<00:26,  3.23it/s][A
 62%|██████▏   | 137/221 [00:51<00:22,  3.66it/s][A
 62%|██████▏   | 138/221 [00:51<00:23,  3.46it/s][A
 63%|██████▎   | 139/221 [00:52<00:27,  3.00it/s][A
 63%|██████▎   | 140/221 [00:52<00:25,  3.12it/s][A
 64%|██████▍   | 141/221 [00:52<00:21,  3.68it/s][A
 64%|██████▍   | 142/221 [00:52<00:21,  3.64it/s][A
 65%|██████▍   | 143/221 [00:53<00:25,  3.09it/s][A
 65%|██████▌   | 144/221 [00:53<00:21,  3.59it/s][A
 66%|██████▌   | 146/221 [00:53<00:13,  5.56it/s][A
 67%|██████▋   | 147/221 [00:53<00:13,  5.50it/s][A
 67%|██████▋   | 148/221 [00:53<00:15,  4.85it/s][A
 67%|██████▋   | 149/221 [00:54<00:13,  5.54it/s][A
 68%|██████▊   | 150/221 [00:54<00:12,  5.51it/s][A
 68%|██████▊   | 151/221 [00:54<00:23,  2.93it/s][A
 69%|██████▉   | 152/221 [00:55<00:36,  1.89it/s][A
 69%|██████▉   | 153/221 [00:56<00:30,  2.24it/s][A
 70%|██████▉   | 154/221 [00:56<00:27,  2.42it/s][A
 70%|███████   | 155/221 [00:56<00:22,  2.99it/s][A
 71%|███████   | 156/221 [00:56<00:18,  3.48it/s][A
 71%|███████   | 157/221 [00:57<00:28,  2.22it/s][A
 71%|███████▏  | 158/221 [00:57<00:24,  2.55it/s][A
 72%|███████▏  | 159/221 [00:58<00:19,  3.11it/s][A
 72%|███████▏  | 160/221 [00:58<00:19,  3.11it/s][A
 73%|███████▎  | 162/221 [00:58<00:16,  3.55it/s][A
 74%|███████▍  | 163/221 [00:59<00:15,  3.71it/s][A
 74%|███████▍  | 164/221 [00:59<00:21,  2.68it/s][A
 75%|███████▍  | 165/221 [00:59<00:16,  3.34it/s][A
 75%|███████▌  | 166/221 [01:00<00:16,  3.34it/s][A
 76%|███████▌  | 167/221 [01:00<00:13,  3.99it/s][A
 76%|███████▌  | 168/221 [01:00<00:19,  2.74it/s][A
 76%|███████▋  | 169/221 [01:01<00:17,  3.04it/s][A
 77%|███████▋  | 170/221 [01:01<00:17,  2.89it/s][A
 77%|███████▋  | 171/221 [01:01<00:17,  2.90it/s][A
 78%|███████▊  | 172/221 [01:02<00:14,  3.37it/s][A
 78%|███████▊  | 173/221 [01:02<00:12,  3.94it/s][A
 79%|███████▊  | 174/221 [01:02<00:13,  3.54it/s][A
 79%|███████▉  | 175/221 [01:03<00:17,  2.64it/s][A
 80%|███████▉  | 176/221 [01:03<00:15,  2.87it/s][A
 80%|████████  | 177/221 [01:03<00:12,  3.52it/s][A
 81%|████████  | 178/221 [01:03<00:11,  3.63it/s][A[h264 @ 0x5606a1967280] mmco: unref short failure
[h264 @ 0x5606a1967280] mmco: unref short failure

 81%|████████  | 179/221 [01:04<00:12,  3.23it/s][A
 81%|████████▏ | 180/221 [01:04<00:10,  3.97it/s][A
 82%|████████▏ | 181/221 [01:04<00:09,  4.13it/s][A
 82%|████████▏ | 182/221 [01:04<00:08,  4.51it/s][A
 83%|████████▎ | 183/221 [01:04<00:08,  4.74it/s][A
 83%|████████▎ | 184/221 [01:05<00:09,  3.94it/s][A
 84%|████████▎ | 185/221 [01:05<00:08,  4.20it/s][A
 84%|████████▍ | 186/221 [01:05<00:10,  3.38it/s][A
 85%|████████▍ | 187/221 [01:06<00:08,  3.86it/s][A
 85%|████████▌ | 188/221 [01:06<00:08,  3.97it/s][A
 86%|████████▌ | 189/221 [01:06<00:11,  2.88it/s][A
 86%|████████▌ | 190/221 [01:07<00:10,  2.94it/s][A
 87%|████████▋ | 192/221 [01:07<00:07,  3.85it/s][A
 88%|████████▊ | 194/221 [01:08<00:08,  3.33it/s][A
 88%|████████▊ | 195/221 [01:08<00:07,  3.67it/s][A
 89%|████████▊ | 196/221 [01:09<00:08,  2.89it/s][A
 89%|████████▉ | 197/221 [01:09<00:06,  3.49it/s][A
 90%|████████▉ | 198/221 [01:09<00:07,  3.25it/s][A
 90%|█████████ | 199/221 [01:09<00:06,  3.63it/s][A[h264 @ 0x55e18b6279c0] mmco: unref short failure

 90%|█████████ | 200/221 [01:10<00:05,  3.56it/s][A
 91%|█████████ | 201/221 [01:10<00:05,  3.59it/s][A
 91%|█████████▏| 202/221 [01:10<00:04,  4.14it/s][A
 92%|█████████▏| 203/221 [01:10<00:03,  4.73it/s][A
 92%|█████████▏| 204/221 [01:10<00:04,  3.95it/s][A
 93%|█████████▎| 205/221 [01:11<00:03,  4.76it/s][A
 93%|█████████▎| 206/221 [01:11<00:04,  3.43it/s][A
 94%|█████████▎| 207/221 [01:11<00:03,  4.01it/s][A
 94%|█████████▍| 208/221 [01:11<00:02,  4.67it/s][A
 95%|█████████▍| 209/221 [01:12<00:02,  4.73it/s][A
 95%|█████████▌| 211/221 [01:12<00:02,  4.88it/s][A
 96%|█████████▌| 212/221 [01:12<00:01,  5.20it/s][A
 96%|█████████▋| 213/221 [01:12<00:01,  4.55it/s][A
 97%|█████████▋| 214/221 [01:13<00:01,  4.15it/s][A
 97%|█████████▋| 215/221 [01:13<00:01,  4.21it/s][A
 98%|█████████▊| 216/221 [01:13<00:01,  3.88it/s][A
 98%|█████████▊| 217/221 [01:14<00:01,  3.34it/s][A
 99%|█████████▊| 218/221 [01:14<00:00,  3.21it/s][A
 99%|█████████▉| 219/221 [01:14<00:00,  3.57it/s][A
100%|█████████▉| 220/221 [01:18<00:01,  1.33s/it][A
100%|██████████| 221/221 [01:18<00:00,  1.01it/s][A100%|██████████| 221/221 [01:18<00:00,  2.81it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:04,  3.39it/s][A
  1%|          | 2/221 [00:00<01:05,  3.34it/s][A
  1%|▏         | 3/221 [00:00<01:04,  3.37it/s][A
  2%|▏         | 4/221 [00:01<01:04,  3.38it/s][A
  2%|▏         | 5/221 [00:01<01:04,  3.34it/s][A
  3%|▎         | 6/221 [00:01<01:04,  3.33it/s][A
  3%|▎         | 7/221 [00:02<01:03,  3.35it/s][A
  4%|▎         | 8/221 [00:02<01:03,  3.37it/s][A
  4%|▍         | 9/221 [00:02<01:02,  3.38it/s][A
  5%|▍         | 10/221 [00:02<01:02,  3.38it/s][A
  5%|▍         | 11/221 [00:03<01:02,  3.37it/s][A
  5%|▌         | 12/221 [00:03<01:01,  3.38it/s][A
  6%|▌         | 13/221 [00:03<01:01,  3.39it/s][A
  6%|▋         | 14/221 [00:04<01:00,  3.39it/s][A
  7%|▋         | 15/221 [00:04<01:00,  3.40it/s][A
  7%|▋         | 16/221 [00:04<01:00,  3.40it/s][A
  8%|▊         | 17/221 [00:05<00:59,  3.40it/s][A
  8%|▊         | 18/221 [00:05<00:59,  3.40it/s][A
  9%|▊         | 19/221 [00:05<00:59,  3.40it/s][A
  9%|▉         | 20/221 [00:05<00:59,  3.40it/s][A
 10%|▉         | 21/221 [00:06<00:58,  3.40it/s][A
 10%|▉         | 22/221 [00:06<00:58,  3.40it/s][A
 10%|█         | 23/221 [00:06<00:58,  3.40it/s][A
 11%|█         | 24/221 [00:07<00:57,  3.40it/s][A
 11%|█▏        | 25/221 [00:07<00:57,  3.40it/s][A
 12%|█▏        | 26/221 [00:07<00:57,  3.41it/s][A
 12%|█▏        | 27/221 [00:07<00:56,  3.41it/s][A
 13%|█▎        | 28/221 [00:08<00:56,  3.41it/s][A
 13%|█▎        | 29/221 [00:08<00:56,  3.41it/s][A
 14%|█▎        | 30/221 [00:08<00:56,  3.41it/s][A
 14%|█▍        | 31/221 [00:09<00:55,  3.41it/s][A
 14%|█▍        | 32/221 [00:09<00:55,  3.41it/s][A
 15%|█▍        | 33/221 [00:09<00:55,  3.41it/s][A
 15%|█▌        | 34/221 [00:10<00:54,  3.41it/s][A
 16%|█▌        | 35/221 [00:10<00:54,  3.41it/s][A
 16%|█▋        | 36/221 [00:10<00:54,  3.41it/s][A[h264 @ 0x55e1a247cdc0] mmco: unref short failure

 17%|█▋        | 37/221 [00:10<00:53,  3.41it/s][A
 17%|█▋        | 38/221 [00:11<00:53,  3.41it/s][A
 18%|█▊        | 39/221 [00:11<00:53,  3.41it/s][A
 18%|█▊        | 40/221 [00:11<00:53,  3.41it/s][A
 19%|█▊        | 41/221 [00:12<00:52,  3.42it/s][A
 19%|█▉        | 42/221 [00:12<00:52,  3.42it/s][A
 19%|█▉        | 43/221 [00:12<00:52,  3.42it/s][A
 20%|█▉        | 44/221 [00:12<00:51,  3.42it/s][A
 20%|██        | 45/221 [00:13<00:51,  3.42it/s][A
 21%|██        | 46/221 [00:13<00:51,  3.42it/s][A
 21%|██▏       | 47/221 [00:13<00:50,  3.42it/s][A
 22%|██▏       | 48/221 [00:14<00:50,  3.42it/s][A
 22%|██▏       | 49/221 [00:14<00:50,  3.42it/s][A
 23%|██▎       | 50/221 [00:14<00:50,  3.42it/s][A
 23%|██▎       | 51/221 [00:14<00:49,  3.42it/s][A
 24%|██▎       | 52/221 [00:15<00:49,  3.42it/s][A
 24%|██▍       | 53/221 [00:15<00:49,  3.42it/s][A
 24%|██▍       | 54/221 [00:15<00:48,  3.42it/s][A
 25%|██▍       | 55/221 [00:16<00:48,  3.42it/s][A
 25%|██▌       | 56/221 [00:16<00:48,  3.42it/s][A
 26%|██▌       | 57/221 [00:16<00:47,  3.42it/s][A
 26%|██▌       | 58/221 [00:17<00:47,  3.42it/s][A
 27%|██▋       | 59/221 [00:17<00:47,  3.42it/s][A
 27%|██▋       | 60/221 [00:17<00:47,  3.42it/s][A
 28%|██▊       | 61/221 [00:17<00:46,  3.42it/s][A
 28%|██▊       | 62/221 [00:18<00:46,  3.42it/s][A
 29%|██▊       | 63/221 [00:18<00:46,  3.42it/s][A
 29%|██▉       | 64/221 [00:18<00:45,  3.42it/s][A
 29%|██▉       | 65/221 [00:19<00:45,  3.42it/s][A
 30%|██▉       | 66/221 [00:19<00:45,  3.42it/s][A
 30%|███       | 67/221 [00:19<00:45,  3.42it/s][A
 31%|███       | 68/221 [00:19<00:44,  3.42it/s][A
 31%|███       | 69/221 [00:20<00:44,  3.42it/s][A
 32%|███▏      | 70/221 [00:20<00:44,  3.42it/s][A
 32%|███▏      | 71/221 [00:20<00:43,  3.42it/s][A
 33%|███▎      | 72/221 [00:21<00:43,  3.42it/s][A
 33%|███▎      | 73/221 [00:21<00:43,  3.42it/s][A
 33%|███▎      | 74/221 [00:21<00:42,  3.42it/s][A
 34%|███▍      | 75/221 [00:22<00:42,  3.42it/s][A
 34%|███▍      | 76/221 [00:22<00:42,  3.42it/s][A
 35%|███▍      | 77/221 [00:22<00:42,  3.42it/s][A
 35%|███▌      | 78/221 [00:22<00:41,  3.42it/s][A
 36%|███▌      | 79/221 [00:23<00:41,  3.42it/s][A
 36%|███▌      | 80/221 [00:23<00:41,  3.42it/s][A
 37%|███▋      | 81/221 [00:23<00:40,  3.42it/s][A
 37%|███▋      | 82/221 [00:24<00:40,  3.42it/s][A
 38%|███▊      | 83/221 [00:24<00:40,  3.42it/s][A
 38%|███▊      | 84/221 [00:24<00:40,  3.42it/s][A
 38%|███▊      | 85/221 [00:24<00:39,  3.42it/s][A
 39%|███▉      | 86/221 [00:25<00:39,  3.42it/s][A
 39%|███▉      | 87/221 [00:25<00:39,  3.42it/s][A
 40%|███▉      | 88/221 [00:25<00:38,  3.42it/s][A
 40%|████      | 89/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 90/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 91/221 [00:26<00:38,  3.42it/s][A
 42%|████▏     | 92/221 [00:26<00:37,  3.42it/s][A
 42%|████▏     | 93/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 94/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 95/221 [00:27<00:36,  3.42it/s][A
 43%|████▎     | 96/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 97/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 98/221 [00:28<00:35,  3.42it/s][A
 45%|████▍     | 99/221 [00:29<00:35,  3.42it/s][A
 45%|████▌     | 100/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 101/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 102/221 [00:29<00:34,  3.42it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 104/221 [00:30<00:34,  3.42it/s][A
 48%|████▊     | 105/221 [00:30<00:33,  3.42it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 107/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 108/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 109/221 [00:31<00:32,  3.42it/s][A
 50%|████▉     | 110/221 [00:32<00:32,  3.42it/s][A
 50%|█████     | 111/221 [00:32<00:32,  3.42it/s][A
 51%|█████     | 112/221 [00:32<00:31,  3.42it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 114/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:33<00:30,  3.42it/s][A
 52%|█████▏    | 116/221 [00:33<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:34<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:34<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:35<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:35<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:36<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:37<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:38<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:38<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:38<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:39<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:39<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:40<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:40<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:41<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:41<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:42<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:43<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:43<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:44<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:45<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:45<00:18,  3.42it/s][A
 71%|███████   | 157/221 [00:45<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:46<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:47<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:47<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:48<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:48<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:48<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:49<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:49<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:50<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:50<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:51<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:51<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:52<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:52<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:52<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:53<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:54<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:54<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:55<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:55<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:56<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:56<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:57<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:57<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:57<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:58<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:58<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [00:59<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:00<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:01<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:02<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:03<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:03<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:04<00:00,  3.42it/s][A100%|██████████| 221/221 [01:04<00:00,  3.42it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:28,  7.69it/s][A
  1%|          | 2/221 [00:00<00:45,  4.86it/s][A
  1%|▏         | 3/221 [00:00<01:16,  2.85it/s][A
  2%|▏         | 4/221 [00:01<01:01,  3.51it/s][A
  2%|▏         | 5/221 [00:01<00:57,  3.75it/s][A
  3%|▎         | 7/221 [00:01<00:43,  4.90it/s][A
  4%|▎         | 8/221 [00:01<00:51,  4.15it/s][A
  4%|▍         | 9/221 [00:02<00:56,  3.74it/s][A
  5%|▍         | 10/221 [00:02<00:58,  3.59it/s][A
  5%|▍         | 11/221 [00:02<00:56,  3.75it/s][A
  5%|▌         | 12/221 [00:03<00:55,  3.78it/s][A
  6%|▌         | 13/221 [00:04<01:34,  2.20it/s][A
  6%|▋         | 14/221 [00:04<01:17,  2.67it/s][A
  7%|▋         | 15/221 [00:04<01:13,  2.81it/s][A
  7%|▋         | 16/221 [00:04<01:19,  2.59it/s][A
  8%|▊         | 17/221 [00:05<01:23,  2.45it/s][A
  8%|▊         | 18/221 [00:05<01:16,  2.65it/s][A
  9%|▊         | 19/221 [00:05<01:03,  3.19it/s][A
  9%|▉         | 20/221 [00:06<00:56,  3.56it/s][A
 10%|▉         | 21/221 [00:06<00:50,  3.95it/s][A
 10%|▉         | 22/221 [00:06<00:46,  4.30it/s][A
 10%|█         | 23/221 [00:06<00:38,  5.10it/s][A
 11%|█         | 24/221 [00:06<00:37,  5.28it/s][A
 11%|█▏        | 25/221 [00:07<00:55,  3.56it/s][A
 12%|█▏        | 26/221 [00:07<00:58,  3.36it/s][A
 12%|█▏        | 27/221 [00:07<00:59,  3.28it/s][A
 13%|█▎        | 28/221 [00:08<01:08,  2.81it/s][A
 13%|█▎        | 29/221 [00:08<01:05,  2.91it/s][A
 14%|█▎        | 30/221 [00:08<01:00,  3.14it/s][A
 14%|█▍        | 31/221 [00:09<01:00,  3.15it/s][A
 14%|█▍        | 32/221 [00:09<00:52,  3.58it/s][A
 15%|█▍        | 33/221 [00:09<00:49,  3.83it/s][A
 15%|█▌        | 34/221 [00:09<00:50,  3.74it/s][A
 16%|█▌        | 35/221 [00:10<00:48,  3.85it/s][A
 16%|█▋        | 36/221 [00:10<00:52,  3.52it/s][A
 17%|█▋        | 37/221 [00:10<00:49,  3.69it/s][A
 17%|█▋        | 38/221 [00:11<00:50,  3.60it/s][A
 18%|█▊        | 39/221 [00:11<00:41,  4.35it/s][A
 18%|█▊        | 40/221 [00:11<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:11<00:42,  4.28it/s][A
 19%|█▉        | 42/221 [00:11<00:38,  4.66it/s][A
 19%|█▉        | 43/221 [00:12<00:44,  4.00it/s][A
 20%|█▉        | 44/221 [00:12<00:39,  4.47it/s][A
 20%|██        | 45/221 [00:12<00:46,  3.81it/s][A
 21%|██        | 46/221 [00:12<00:46,  3.77it/s][A
 21%|██▏       | 47/221 [00:13<00:38,  4.56it/s][A
 22%|██▏       | 48/221 [00:13<00:32,  5.40it/s][A
 22%|██▏       | 49/221 [00:13<00:31,  5.53it/s][A
 23%|██▎       | 50/221 [00:13<00:33,  5.03it/s][A
 23%|██▎       | 51/221 [00:13<00:37,  4.59it/s][A
 24%|██▍       | 53/221 [00:14<00:28,  5.81it/s][A
 24%|██▍       | 54/221 [00:14<00:31,  5.31it/s][A
 25%|██▍       | 55/221 [00:14<00:33,  4.95it/s][A
 25%|██▌       | 56/221 [00:14<00:34,  4.72it/s][A
 26%|██▌       | 57/221 [00:15<00:37,  4.32it/s][A
 26%|██▌       | 58/221 [00:15<00:33,  4.85it/s][A
 27%|██▋       | 59/221 [00:15<00:34,  4.64it/s][A
 27%|██▋       | 60/221 [00:15<00:37,  4.28it/s][A
 28%|██▊       | 61/221 [00:16<00:36,  4.36it/s][A
 28%|██▊       | 62/221 [00:16<00:37,  4.25it/s][A
 29%|██▊       | 63/221 [00:16<00:32,  4.87it/s][A
 29%|██▉       | 64/221 [00:16<00:32,  4.85it/s][A
 29%|██▉       | 65/221 [00:16<00:28,  5.55it/s][A
 30%|██▉       | 66/221 [00:17<00:35,  4.40it/s][A
 30%|███       | 67/221 [00:17<00:56,  2.75it/s][A
 31%|███       | 68/221 [00:17<00:49,  3.12it/s][A
 31%|███       | 69/221 [00:18<00:50,  2.99it/s][A
 32%|███▏      | 70/221 [00:18<00:43,  3.50it/s][A
 32%|███▏      | 71/221 [00:18<00:52,  2.87it/s][A
 33%|███▎      | 72/221 [00:19<00:54,  2.74it/s][A
 33%|███▎      | 73/221 [00:19<00:51,  2.86it/s][A
 33%|███▎      | 74/221 [00:19<00:46,  3.17it/s][A
 34%|███▍      | 75/221 [00:20<00:50,  2.87it/s][A
 35%|███▍      | 77/221 [00:20<00:38,  3.76it/s][A
 35%|███▌      | 78/221 [00:21<00:39,  3.60it/s][A
 36%|███▌      | 79/221 [00:21<00:43,  3.24it/s][A
 36%|███▌      | 80/221 [00:21<00:42,  3.31it/s][A
 37%|███▋      | 81/221 [00:21<00:41,  3.36it/s][A
 37%|███▋      | 82/221 [00:22<00:38,  3.58it/s][A
 38%|███▊      | 83/221 [00:22<00:32,  4.31it/s][A
 38%|███▊      | 84/221 [00:22<00:37,  3.62it/s][A
 38%|███▊      | 85/221 [00:23<00:42,  3.21it/s][A
 39%|███▉      | 86/221 [00:23<00:47,  2.83it/s][A
 39%|███▉      | 87/221 [00:24<00:58,  2.31it/s][A
 40%|███▉      | 88/221 [00:24<00:51,  2.58it/s][A
 40%|████      | 89/221 [00:24<00:51,  2.57it/s][A
 41%|████      | 90/221 [00:25<00:55,  2.36it/s][A
 41%|████      | 91/221 [00:25<00:46,  2.78it/s][A
 42%|████▏     | 92/221 [00:25<00:41,  3.14it/s][A
 42%|████▏     | 93/221 [00:26<00:48,  2.62it/s][A
 43%|████▎     | 94/221 [00:26<00:41,  3.08it/s][A
 43%|████▎     | 95/221 [00:26<00:45,  2.76it/s][A
 43%|████▎     | 96/221 [00:27<00:44,  2.82it/s][A
 44%|████▍     | 97/221 [00:27<00:41,  2.98it/s][A
 44%|████▍     | 98/221 [00:27<00:37,  3.29it/s][A
 45%|████▍     | 99/221 [00:28<00:34,  3.59it/s][A
 45%|████▌     | 100/221 [00:28<00:29,  4.06it/s][A
 46%|████▌     | 101/221 [00:28<00:29,  4.09it/s][A
 46%|████▌     | 102/221 [00:28<00:31,  3.75it/s][A
 47%|████▋     | 103/221 [00:28<00:29,  4.04it/s][A
 47%|████▋     | 104/221 [00:29<00:25,  4.63it/s][A
 48%|████▊     | 105/221 [00:29<00:26,  4.37it/s][A
 48%|████▊     | 106/221 [00:29<00:35,  3.21it/s][A
 48%|████▊     | 107/221 [00:30<00:34,  3.32it/s][A
 49%|████▉     | 108/221 [00:30<00:28,  3.98it/s][A
 49%|████▉     | 109/221 [00:30<00:30,  3.70it/s][A
 50%|████▉     | 110/221 [00:31<00:34,  3.26it/s][A
 50%|█████     | 111/221 [00:31<00:35,  3.08it/s][A
 51%|█████     | 112/221 [00:31<00:34,  3.17it/s][A
 51%|█████     | 113/221 [00:31<00:31,  3.45it/s][A
 52%|█████▏    | 115/221 [00:32<00:23,  4.49it/s][A
 52%|█████▏    | 116/221 [00:32<00:22,  4.69it/s][A
 53%|█████▎    | 117/221 [00:32<00:22,  4.55it/s][A
 53%|█████▎    | 118/221 [00:33<00:28,  3.66it/s][A
 54%|█████▍    | 119/221 [00:33<00:32,  3.18it/s][A
 54%|█████▍    | 120/221 [00:33<00:30,  3.28it/s][A
 55%|█████▌    | 122/221 [00:34<00:23,  4.19it/s][A
 56%|█████▌    | 123/221 [00:34<00:24,  4.05it/s][A
 56%|█████▌    | 124/221 [00:34<00:28,  3.44it/s][A
 57%|█████▋    | 125/221 [00:35<00:40,  2.35it/s][A
 57%|█████▋    | 126/221 [00:35<00:34,  2.78it/s][A
 57%|█████▋    | 127/221 [00:36<00:45,  2.05it/s][A
 58%|█████▊    | 128/221 [00:36<00:38,  2.41it/s][A
 58%|█████▊    | 129/221 [00:36<00:32,  2.87it/s][A
 59%|█████▉    | 130/221 [00:37<00:29,  3.09it/s][A
 59%|█████▉    | 131/221 [00:37<00:24,  3.71it/s][A
 60%|█████▉    | 132/221 [00:37<00:27,  3.25it/s][A
 60%|██████    | 133/221 [00:38<00:39,  2.24it/s][A
 61%|██████    | 134/221 [00:38<00:36,  2.38it/s][A
 61%|██████    | 135/221 [00:39<00:31,  2.77it/s][A
 62%|██████▏   | 136/221 [00:39<00:30,  2.83it/s][A
 62%|██████▏   | 137/221 [00:39<00:26,  3.16it/s][A
 62%|██████▏   | 138/221 [00:39<00:26,  3.13it/s][A
 63%|██████▎   | 139/221 [00:40<00:27,  2.96it/s][A
 63%|██████▎   | 140/221 [00:40<00:24,  3.31it/s][A
 64%|██████▍   | 141/221 [00:40<00:23,  3.44it/s][A
 64%|██████▍   | 142/221 [00:41<00:21,  3.72it/s][A
 65%|██████▍   | 143/221 [00:41<00:23,  3.29it/s][A
 65%|██████▌   | 144/221 [00:41<00:20,  3.82it/s][A
 66%|██████▌   | 145/221 [00:41<00:20,  3.76it/s][A
 66%|██████▌   | 146/221 [00:42<00:19,  3.79it/s][A
 67%|██████▋   | 147/221 [00:42<00:17,  4.14it/s][A
 67%|██████▋   | 148/221 [00:42<00:18,  3.99it/s][A
 67%|██████▋   | 149/221 [00:42<00:18,  3.99it/s][A
 68%|██████▊   | 150/221 [00:43<00:18,  3.94it/s][A
 68%|██████▊   | 151/221 [00:43<00:28,  2.44it/s][A
 69%|██████▉   | 152/221 [00:44<00:33,  2.06it/s][A
 69%|██████▉   | 153/221 [00:44<00:27,  2.49it/s][A
 70%|██████▉   | 154/221 [00:44<00:23,  2.87it/s][A
 70%|███████   | 155/221 [00:45<00:25,  2.58it/s][A
 71%|███████   | 156/221 [00:45<00:22,  2.85it/s][A
 71%|███████   | 157/221 [00:46<00:22,  2.85it/s][A
 71%|███████▏  | 158/221 [00:46<00:23,  2.72it/s][A
 72%|███████▏  | 159/221 [00:46<00:19,  3.19it/s][A
 72%|███████▏  | 160/221 [00:46<00:17,  3.46it/s][A
 73%|███████▎  | 161/221 [00:47<00:15,  3.82it/s][A
 73%|███████▎  | 162/221 [00:47<00:13,  4.25it/s][A
 74%|███████▍  | 163/221 [00:47<00:13,  4.26it/s][A
 74%|███████▍  | 164/221 [00:47<00:11,  4.83it/s][A
 75%|███████▍  | 165/221 [00:47<00:09,  5.61it/s][A
 75%|███████▌  | 166/221 [00:48<00:12,  4.37it/s][A
 76%|███████▌  | 167/221 [00:48<00:10,  5.10it/s][A
 76%|███████▌  | 168/221 [00:48<00:11,  4.63it/s][A
 76%|███████▋  | 169/221 [00:48<00:10,  4.81it/s][A
 77%|███████▋  | 170/221 [00:49<00:20,  2.53it/s][A
 77%|███████▋  | 171/221 [00:50<00:23,  2.16it/s][A
 78%|███████▊  | 172/221 [00:50<00:18,  2.64it/s][A
 78%|███████▊  | 173/221 [00:50<00:16,  2.87it/s][A
 79%|███████▊  | 174/221 [00:50<00:14,  3.17it/s][A
 79%|███████▉  | 175/221 [00:51<00:14,  3.09it/s][A
 80%|███████▉  | 176/221 [00:51<00:12,  3.49it/s][A
 80%|████████  | 177/221 [00:51<00:12,  3.62it/s][A
 81%|████████  | 178/221 [00:52<00:15,  2.74it/s][A
 81%|████████  | 179/221 [00:52<00:14,  2.84it/s][A
 82%|████████▏ | 181/221 [00:52<00:11,  3.52it/s][A
 82%|████████▏ | 182/221 [00:53<00:10,  3.60it/s][A
 83%|████████▎ | 183/221 [00:53<00:10,  3.50it/s][A
 83%|████████▎ | 184/221 [00:53<00:11,  3.31it/s][A
 84%|████████▎ | 185/221 [00:54<00:09,  3.80it/s][A
 84%|████████▍ | 186/221 [00:54<00:11,  3.07it/s][A
 85%|████████▍ | 187/221 [00:54<00:10,  3.13it/s][A
 85%|████████▌ | 188/221 [00:55<00:11,  2.92it/s][A
 86%|████████▌ | 189/221 [00:55<00:09,  3.32it/s][A
 86%|████████▌ | 190/221 [00:55<00:11,  2.74it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.38it/s][A
 87%|████████▋ | 193/221 [00:56<00:07,  3.77it/s][A
 88%|████████▊ | 194/221 [00:56<00:07,  3.47it/s][A
 88%|████████▊ | 195/221 [00:57<00:06,  3.79it/s][A
 89%|████████▊ | 196/221 [00:57<00:10,  2.37it/s][A
 89%|████████▉ | 197/221 [00:58<00:09,  2.50it/s][A
 90%|████████▉ | 198/221 [00:58<00:09,  2.47it/s][A
 90%|█████████ | 199/221 [00:58<00:07,  2.96it/s][A
 90%|█████████ | 200/221 [00:59<00:06,  3.10it/s][A
 91%|█████████ | 201/221 [00:59<00:06,  3.29it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.43it/s][A
 92%|█████████▏| 203/221 [00:59<00:04,  3.79it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.86it/s][A
 93%|█████████▎| 205/221 [01:00<00:03,  4.25it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.34it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  3.40it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.99it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.48it/s][A
 95%|█████████▌| 210/221 [01:01<00:02,  3.88it/s][A
 95%|█████████▌| 211/221 [01:01<00:02,  4.16it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.46it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.06it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  2.95it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.02it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  2.92it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.02it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.22it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  2.97it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.37it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.10it/s][A100%|██████████| 221/221 [01:05<00:00,  3.38it/s]
09/17/2024 02:49:31 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 549--===========

09/17/2024 02:49:31 - INFO - __main__ -   {'area_r1': 40.4, 'area_recall': '40.4/66.4/75.7', 'area_ravg': 60.8}
09/17/2024 02:49:31 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 549--===========

09/17/2024 02:49:31 - INFO - __main__ -   {'forward_r1': 36.4, 'forward_recall': '36.4/65.7/76.0', 'forward_ravg': 59.4}
09/17/2024 02:49:31 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 549--===========

09/17/2024 02:49:31 - INFO - __main__ -   {'area_video_r1': 38.1, 'area_video_recall': '38.1/67.9/77.5', 'area_video_ravg': 61.2}
09/17/2024 02:49:31 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 299=======

09/17/2024 02:49:31 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 02:49:31 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 549--===========

09/17/2024 02:49:31 - INFO - __main__ -   {'area_video_r1': 54.1, 'area_video_recall': '54.1/75.5/82.4', 'area_video_ravg': 70.6, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.5/82.1', 'area_video_back_ravg': 68.7}
09/17/2024 02:49:31 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 549=======

09/17/2024 02:49:31 - INFO - __main__ -   {'area_video_r1': 54.1, 'area_video_recall': '54.1/75.5/82.4', 'area_video_ravg': 70.6, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.5/82.1', 'area_video_back_ravg': 68.7}
09/17/2024 02:49:31 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 549--===========

09/17/2024 02:49:31 - INFO - __main__ -   {'video_r1': 36.5, 'video_recall': '36.5/64.4/74.3', 'video_ravg': 58.4}
09/17/2024 02:49:31 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 249=======

09/17/2024 02:49:31 - INFO - __main__ -   {'video_r1': 37.1, 'video_recall': '37.1/65.0/74.1', 'video_ravg': 58.7}
09/17/2024 02:49:31 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 549--===========

09/17/2024 02:49:31 - INFO - __main__ -   {'video_r1': 54.5, 'video_recall': '54.5/76.1/83.4', 'video_ravg': 71.3}
09/17/2024 02:49:31 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 549=======

09/17/2024 02:49:31 - INFO - __main__ -   {'video_r1': 54.5, 'video_recall': '54.5/76.1/83.4', 'video_ravg': 71.3}
09/17/2024 02:50:06 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.007708295714110136, 'loss_ret%tv%ta--finetune_area/loss_area': 1.0743820667266846, 'loss_ret%tv%ta--finetune_area/total_loss': 1.0820903778076172}
[h264 @ 0x5606a093bb40] mmco: unref short failure
[h264 @ 0x5606a093bb40] mmco: unref short failure
[h264 @ 0x5606a093bb40] mmco: unref short failure
[h264 @ 0x5606a093bb40] mmco: unref short failure
[h264 @ 0x5606a093bb40] mmco: unref short failure
[h264 @ 0x5606a093bb40] mmco: unref short failure
 19%|█▉        | 550/2910 [3:28:23<91:36:17, 139.74s/it] 19%|█▉        | 551/2910 [3:28:27<64:50:20, 98.95s/it] [h264 @ 0x55e1833445c0] mmco: unref short failure
[h264 @ 0x55e1833445c0] mmco: unref short failure
 19%|█▉        | 552/2910 [3:28:31<46:07:46, 70.43s/it][h264 @ 0x56069d008c40] mmco: unref short failure
 19%|█▉        | 553/2910 [3:28:35<33:12:25, 50.72s/it][h264 @ 0x5606a093bb40] mmco: unref short failure
 19%|█▉        | 554/2910 [3:28:40<24:13:09, 37.01s/it][h264 @ 0x56068ee9b400] mmco: unref short failure
[h264 @ 0x56068ee9b400] mmco: unref short failure
 19%|█▉        | 555/2910 [3:28:45<17:54:10, 27.37s/it][h264 @ 0x55e199175cc0] mmco: unref short failure
[h264 @ 0x55e199175cc0] mmco: unref short failure
[h264 @ 0x55e199175cc0] mmco: unref short failure
[h264 @ 0x55a277d67680] mmco: unref short failure
[h264 @ 0x55a277d67680] mmco: unref short failure
not have audios CqzowavAOpc.38
 19%|█▉        | 556/2910 [3:28:51<13:33:31, 20.74s/it] 19%|█▉        | 557/2910 [3:28:56<10:30:52, 16.09s/it] 19%|█▉        | 558/2910 [3:29:02<8:29:08, 12.99s/it] [h264 @ 0x5606925d4d80] mmco: unref short failure
[h264 @ 0x5606925d4d80] mmco: unref short failure
 19%|█▉        | 559/2910 [3:29:07<7:00:44, 10.74s/it]09/17/2024 02:50:55 - INFO - __main__ -   current idx _wZn-Jd_Dhg.25 from finetune_area returns wrong image/video, use 148226 instead.
[h264 @ 0x55a2609b4200] mmco: unref short failure
[h264 @ 0x560692db58c0] mmco: unref short failure
 19%|█▉        | 560/2910 [3:29:12<5:54:16,  9.05s/it][h264 @ 0x55b4f9c83e00] mmco: unref short failure
 19%|█▉        | 561/2910 [3:29:17<5:10:30,  7.93s/it] 19%|█▉        | 562/2910 [3:29:23<4:40:04,  7.16s/it][h264 @ 0x5606a7425f40] mmco: unref short failure
[h264 @ 0x5606a7425f40] mmco: unref short failure
 19%|█▉        | 563/2910 [3:29:28<4:17:22,  6.58s/it] 19%|█▉        | 564/2910 [3:29:34<4:13:25,  6.48s/it] 19%|█▉        | 565/2910 [3:29:41<4:12:18,  6.46s/it][h264 @ 0x55a26cf98480] mmco: unref short failure
[h264 @ 0x55a26cf98480] mmco: unref short failure
[h264 @ 0x55a27c4026c0] mmco: unref short failure
[h264 @ 0x55a266fbba00] mmco: unref short failure
[h264 @ 0x55a266fbba00] mmco: unref short failure
[h264 @ 0x55a266fbba00] mmco: unref short failure
[h264 @ 0x55a266fbba00] mmco: unref short failure
[h264 @ 0x55a27bf46a80] mmco: unref short failure
[h264 @ 0x55a261620b00] mmco: unref short failure
[h264 @ 0x55b4fc827900] mmco: unref short failure
[h264 @ 0x55b4fc827900] mmco: unref short failure
[h264 @ 0x55b50ad83980] mmco: unref short failure
[h264 @ 0x55b50ad83980] mmco: unref short failure
[h264 @ 0x5606a861ba40] mmco: unref short failure
[h264 @ 0x55b4f3ee68c0] mmco: unref short failure
[h264 @ 0x55e186462d80] mmco: unref short failure
[h264 @ 0x55e186462d80] mmco: unref short failure
[h264 @ 0x55a26319fb80] mmco: unref short failure
[h264 @ 0x55a26319fb80] mmco: unref short failure
[h264 @ 0x55a266fbba00] mmco: unref short failure
 19%|█▉        | 566/2910 [3:30:29<12:17:56, 18.89s/it][h264 @ 0x55e18e788800] mmco: unref short failure
[h264 @ 0x55e18e788800] mmco: unref short failure
[h264 @ 0x55e18e788800] mmco: unref short failure
[h264 @ 0x55e18e788800] mmco: unref short failure
[h264 @ 0x55b4fd9cf7c0] mmco: unref short failure
 19%|█▉        | 567/2910 [3:30:37<10:17:18, 15.81s/it][h264 @ 0x55e1933d3400] mmco: unref short failure
[h264 @ 0x55e1933d3400] mmco: unref short failure
[h264 @ 0x55e1933d3400] mmco: unref short failure
[h264 @ 0x55e1933d3400] mmco: unref short failure
 20%|█▉        | 568/2910 [3:30:49<9:27:20, 14.53s/it] [h264 @ 0x55e189ee3380] mmco: unref short failure
[h264 @ 0x55e189ee3380] mmco: unref short failure
[h264 @ 0x55a25c5b5f40] mmco: unref short failure
[h264 @ 0x55a25c5b5f40] mmco: unref short failure
[h264 @ 0x55b501cf4e80] mmco: unref short failure
[h264 @ 0x55b501cf4e80] mmco: unref short failure
[h264 @ 0x55b501cf4e80] mmco: unref short failure
[h264 @ 0x55b501cf4e80] mmco: unref short failure
[h264 @ 0x55e19918bd00] mmco: unref short failure
[h264 @ 0x55b508920180] mmco: unref short failure
[h264 @ 0x55b508920180] mmco: unref short failure
[h264 @ 0x55a25b157900] mmco: unref short failure
[h264 @ 0x55e18306a3c0] mmco: unref short failure
[h264 @ 0x5606aa165500] mmco: unref short failure
[h264 @ 0x5606aa165500] mmco: unref short failure
[h264 @ 0x55a2679e32c0] mmco: unref short failure
[h264 @ 0x55a2679e32c0] mmco: unref short failure
[h264 @ 0x56069c302f00] mmco: unref short failure
[h264 @ 0x56069c302f00] mmco: unref short failure
[h264 @ 0x55e18306af40] mmco: unref short failure
[h264 @ 0x55e18306af40] mmco: unref short failure
 20%|█▉        | 569/2910 [3:31:15<11:47:45, 18.14s/it] 20%|█▉        | 570/2910 [3:31:21<9:18:24, 14.32s/it] [h264 @ 0x55a25bb8fcc0] mmco: unref short failure
[h264 @ 0x55a25bb8fcc0] mmco: unref short failure
[h264 @ 0x55a25bb8fcc0] mmco: unref short failure
[h264 @ 0x55a25bb8fcc0] mmco: unref short failure
 20%|█▉        | 571/2910 [3:31:33<8:54:26, 13.71s/it][h264 @ 0x55a281df4ec0] mmco: unref short failure
[h264 @ 0x55a281df4ec0] mmco: unref short failure
[h264 @ 0x5606ad226900] mmco: unref short failure
[h264 @ 0x5606ad226900] mmco: unref short failure
 20%|█▉        | 572/2910 [3:31:39<7:21:25, 11.33s/it] 20%|█▉        | 573/2910 [3:31:44<6:05:49,  9.39s/it][h264 @ 0x55a25c628f40] mmco: unref short failure
[h264 @ 0x55a25bb58940] mmco: unref short failure
[h264 @ 0x55a25bb58940] mmco: unref short failure
[h264 @ 0x55a277d67680] mmco: unref short failure
[h264 @ 0x55e184de5b80] mmco: unref short failure
[h264 @ 0x55e184de5b80] mmco: unref short failure
[h264 @ 0x55e18d4b9a40] mmco: unref short failure
[h264 @ 0x55e18d4b9a40] mmco: unref short failure
[h264 @ 0x55e18d4b9a40] mmco: unref short failure
[h264 @ 0x55e18d4b9a40] mmco: unref short failure
[h264 @ 0x5606a861ba40] mmco: unref short failure
[h264 @ 0x5606a861ba40] mmco: unref short failure
[h264 @ 0x55e18d4b9a40] mmco: unref short failure
[h264 @ 0x55e18d4b9a40] mmco: unref short failure
[h264 @ 0x55e18306a3c0] mmco: unref short failure
[h264 @ 0x55e18306a3c0] mmco: unref short failure
[h264 @ 0x5606a22358c0] mmco: unref short failure
[h264 @ 0x5606a3ffbac0] mmco: unref short failure
[h264 @ 0x5606a3ffbac0] mmco: unref short failure
[h264 @ 0x55e1826c1b80] mmco: unref short failure
[h264 @ 0x5606a90c4a40] mmco: unref short failure
[h264 @ 0x5606a90c4a40] mmco: unref short failure
[h264 @ 0x55b50ad83980] mmco: unref short failure
[h264 @ 0x55b50ad83980] mmco: unref short failure
 20%|█▉        | 574/2910 [3:33:02<19:35:59, 30.21s/it] 20%|█▉        | 575/2910 [3:33:07<14:31:19, 22.39s/it][h264 @ 0x55a25bafd200] mmco: unref short failure
[h264 @ 0x55b4f9db7f00] mmco: unref short failure
[h264 @ 0x55a272947f40] mmco: unref short failure
[h264 @ 0x55a272947f40] mmco: unref short failure
[h264 @ 0x55b4f9db7f00] mmco: unref short failure
 20%|█▉        | 576/2910 [3:33:16<11:54:36, 18.37s/it][h264 @ 0x55a25bafd200] mmco: unref short failure
[h264 @ 0x55a25bafd200] mmco: unref short failure
 20%|█▉        | 577/2910 [3:33:25<10:10:01, 15.69s/it] 20%|█▉        | 578/2910 [3:33:28<7:45:39, 11.98s/it]  20%|█▉        | 579/2910 [3:33:32<6:04:04,  9.37s/it] 20%|█▉        | 580/2910 [3:33:35<4:53:29,  7.56s/it] 20%|█▉        | 581/2910 [3:33:38<4:04:04,  6.29s/it]/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e235a85740] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x56074179fbc0] mmco: unref short failure
[h264 @ 0x56074179fbc0] mmco: unref short failure
[h264 @ 0x560741570d40] mmco: unref short failure
[h264 @ 0x55e237ca3f40] mmco: unref short failure
[h264 @ 0x55e237ca3f40] mmco: unref short failure
[h264 @ 0x560740d662c0] mmco: unref short failure
[h264 @ 0x55e237ab4c80] mmco: unref short failure
[h264 @ 0x55e237ab4c80] mmco: unref short failure
[h264 @ 0x55e237ab4c80] mmco: unref short failure
[h264 @ 0x56074181bb80] mmco: unref short failure
[h264 @ 0x56074181bb80] mmco: unref short failure
[h264 @ 0x56074181bb80] mmco: unref short failure
[h264 @ 0x56074181bb80] mmco: unref short failure
[h264 @ 0x56074180c280] mmco: unref short failure
[h264 @ 0x56074180c280] mmco: unref short failure
[h264 @ 0x55a30eb26f00] mmco: unref short failure
[h264 @ 0x560741609280] mmco: unref short failure
[h264 @ 0x560741609280] mmco: unref short failure
[h264 @ 0x55b5a975b400] mmco: unref short failure
[h264 @ 0x55b5a975b400] mmco: unref short failure
[h264 @ 0x55b5a975b400] mmco: unref short failure
[h264 @ 0x55b5a975b400] mmco: unref short failure
[h264 @ 0x560742031240] mmco: unref short failure
[h264 @ 0x55b5aae21ec0] mmco: unref short failure
[h264 @ 0x55b5aae21ec0] mmco: unref short failure
[h264 @ 0x560742a3cf00] mmco: unref short failure
[h264 @ 0x560742a3cf00] mmco: unref short failure
[h264 @ 0x55b5aae52c00] mmco: unref short failure
[h264 @ 0x55b5aae52c00] mmco: unref short failure
[h264 @ 0x5607411c80c0] mmco: unref short failure
[h264 @ 0x5607411c80c0] mmco: unref short failure
[h264 @ 0x5607411c80c0] mmco: unref short failure
[h264 @ 0x5607411c80c0] mmco: unref short failure
[h264 @ 0x560746deaa00] mmco: unref short failure
[h264 @ 0x560746deaa00] mmco: unref short failure
[h264 @ 0x55b5aad2e000] mmco: unref short failure
[h264 @ 0x55b5aad2e000] mmco: unref short failure
[h264 @ 0x55e23d620180] mmco: unref short failure
[h264 @ 0x55b5aa4de180] mmco: unref short failure
[h264 @ 0x55e23bda8f40] mmco: unref short failure
[h264 @ 0x55e23bda8f40] mmco: unref short failure
[h264 @ 0x55e23bda8f40] mmco: unref short failure
[h264 @ 0x55e23bda8f40] mmco: unref short failure
[h264 @ 0x560744bbe0c0] mmco: unref short failure
[h264 @ 0x560744bbe0c0] mmco: unref short failure
[h264 @ 0x55b5a99791c0] mmco: unref short failure
[h264 @ 0x55b5a99791c0] mmco: unref short failure
09/17/2024 02:57:49 - INFO - __main__ -   current idx A2e7HyCQqvE.54 from finetune_area returns wrong image/video, use 23649 instead.
[h264 @ 0x55a312e3f580] mmco: unref short failure
[h264 @ 0x55a312e3f580] mmco: unref short failure
[h264 @ 0x56074b9ba600] mmco: unref short failure
[h264 @ 0x560747f29d00] mmco: unref short failure
[h264 @ 0x560747f29d00] mmco: unref short failure
[h264 @ 0x55a313e6dbc0] mmco: unref short failure
[h264 @ 0x55a313e6dbc0] mmco: unref short failure
[h264 @ 0x55a313e6dbc0] mmco: unref short failure
[h264 @ 0x55b5af3753c0] mmco: unref short failure
[h264 @ 0x55b5af3753c0] mmco: unref short failure
 20%|██        | 582/2910 [3:36:37<37:27:18, 57.92s/it] 20%|██        | 583/2910 [3:36:42<27:16:31, 42.20s/it][h264 @ 0x55e2377212c0] mmco: unref short failure
[h264 @ 0x55e2377212c0] mmco: unref short failure
 20%|██        | 584/2910 [3:36:47<20:04:29, 31.07s/it][h264 @ 0x55b5a95a0000] mmco: unref short failure
09/17/2024 02:58:35 - INFO - __main__ -   current idx PHgL4zWa_eU.158 from finetune_area returns wrong image/video, use 134332 instead.
 20%|██        | 585/2910 [3:36:52<14:59:02, 23.20s/it][h264 @ 0x55a31c330500] mmco: unref short failure
[h264 @ 0x55a31c330500] mmco: unref short failure
[h264 @ 0x55e2390a4340] mmco: unref short failure
[h264 @ 0x55e2390a4340] mmco: unref short failure
 20%|██        | 586/2910 [3:36:57<11:24:32, 17.67s/it] 20%|██        | 587/2910 [3:37:02<9:01:29, 13.99s/it]  20%|██        | 588/2910 [3:37:07<7:18:19, 11.33s/it][h264 @ 0x55a3150ca4c0] mmco: unref short failure
[h264 @ 0x55a3150ca4c0] mmco: unref short failure
 20%|██        | 589/2910 [3:37:12<6:05:16,  9.44s/it][h264 @ 0x55b5b13c9940] mmco: unref short failure
[h264 @ 0x55b5b13c9940] mmco: unref short failure
[h264 @ 0x55e2410dc880] mmco: unref short failure
[h264 @ 0x55e2410dc880] mmco: unref short failure
[h264 @ 0x55a30ffdf540] mmco: unref short failure
[h264 @ 0x55b5aad30040] mmco: unref short failure
[h264 @ 0x55b5aad30040] mmco: unref short failure
[h264 @ 0x55b5aad30040] mmco: unref short failure
[h264 @ 0x55b5aad30040] mmco: unref short failure
[h264 @ 0x55e23d6fad00] mmco: unref short failure
[h264 @ 0x55e23d6fad00] mmco: unref short failure
[h264 @ 0x55b5aadd3900] mmco: unref short failure
[h264 @ 0x56074b38d680] mmco: unref short failure
[h264 @ 0x55b5abcc6000] mmco: unref short failure
[h264 @ 0x55b5abcc6000] mmco: unref short failure
[h264 @ 0x55b5b5d02240] mmco: unref short failure
[h264 @ 0x55b5b5d02240] mmco: unref short failure
[h264 @ 0x55b5b5d02240] mmco: unref short failure
[h264 @ 0x55b5b5d02240] mmco: unref short failure
09/17/2024 02:59:26 - INFO - __main__ -   current idx KQezF6-NY_o.24 from finetune_area returns wrong image/video, use 3469 instead.
[h264 @ 0x55e238d3c7c0] mmco: unref short failure
[h264 @ 0x56074a5d9100] mmco: unref short failure
[h264 @ 0x56074a5d9100] mmco: unref short failure
[h264 @ 0x55e23f75ecc0] mmco: unref short failure
[h264 @ 0x55b5ab01c400] mmco: unref short failure
[h264 @ 0x55a31b19c840] mmco: unref short failure
[h264 @ 0x560746816f00] mmco: unref short failure
[h264 @ 0x560746816f00] mmco: unref short failure
[h264 @ 0x560746816f00] mmco: unref short failure
[h264 @ 0x55b5ac2dad40] mmco: unref short failure
[h264 @ 0x55a30fd0bf00] mmco: unref short failure
 20%|██        | 590/2910 [3:39:03<25:41:18, 39.86s/it][h264 @ 0x55b5aad3dac0] mmco: unref short failure
[h264 @ 0x55b5aad3dac0] mmco: unref short failure
 20%|██        | 591/2910 [3:39:09<18:58:45, 29.46s/it][h264 @ 0x560742a16c80] mmco: unref short failure
 20%|██        | 592/2910 [3:39:14<14:15:12, 22.14s/it] 20%|██        | 593/2910 [3:39:19<11:00:57, 17.12s/it] 20%|██        | 594/2910 [3:39:25<8:50:17, 13.74s/it] [h264 @ 0x560744a32d40] mmco: unref short failure
 20%|██        | 595/2910 [3:39:30<7:15:03, 11.28s/it][h264 @ 0x55a30fbcf1c0] mmco: unref short failure
[h264 @ 0x55a30fbcf1c0] mmco: unref short failure
[h264 @ 0x55a30fbcf1c0] mmco: unref short failure
[h264 @ 0x55a30fbcf1c0] mmco: unref short failure
[h264 @ 0x55e243f0cbc0] mmco: unref short failure
[h264 @ 0x55e243f0cbc0] mmco: unref short failure
[h264 @ 0x55e243f0cbc0] mmco: unref short failure
[h264 @ 0x55e243f0cbc0] mmco: unref short failure
 20%|██        | 596/2910 [3:39:36<6:04:47,  9.46s/it][h264 @ 0x55e2370b5bc0] mmco: unref short failure
[h264 @ 0x55e2370b5bc0] mmco: unref short failure
 21%|██        | 597/2910 [3:39:41<5:17:46,  8.24s/it][h264 @ 0x55b5abb8d840] mmco: unref short failure
[h264 @ 0x55b5abb8d840] mmco: unref short failure
[h264 @ 0x55b5b1d0fd40] mmco: unref short failure
[h264 @ 0x55b5b273a480] mmco: unref short failure
[h264 @ 0x55b5b273a480] mmco: unref short failure
[h264 @ 0x55b5b5f92a00] mmco: unref short failure
[h264 @ 0x55b5b5f92a00] mmco: unref short failure
[h264 @ 0x55a318a2e240] mmco: unref short failure
[h264 @ 0x55a31cb95700] mmco: unref short failure
[h264 @ 0x55a31cb95700] mmco: unref short failure
[h264 @ 0x55b5b7c99180] mmco: unref short failure
[h264 @ 0x55b5b7c99180] mmco: unref short failure
[h264 @ 0x55a31a8665c0] mmco: unref short failure
[h264 @ 0x55a31a8665c0] mmco: unref short failure
not have audios GAwav3sZcGw.4
[h264 @ 0x55a313413a00] mmco: unref short failure
[h264 @ 0x55b5ac028240] mmco: unref short failure
[h264 @ 0x55e23ab7ab40] mmco: unref short failure
[h264 @ 0x55b5b7b23980] mmco: unref short failure
09/17/2024 03:02:20 - INFO - __main__ -   current idx vMl-g-GJ1Ac.24 from finetune_area returns wrong image/video, use 25892 instead.
[h264 @ 0x55e23c52ad40] mmco: unref short failure
[h264 @ 0x55e23c52ad40] mmco: unref short failure
[h264 @ 0x55e23c531240] mmco: unref short failure
[h264 @ 0x55a30e8cfe00] mmco: unref short failure
[h264 @ 0x55a30e8cfe00] mmco: unref short failure
[h264 @ 0x55b5b1d10680] mmco: unref short failure
[h264 @ 0x56074d9971c0] mmco: unref short failure
[h264 @ 0x5607414a2dc0] mmco: unref short failure
[h264 @ 0x5607414a2dc0] mmco: unref short failure
[h264 @ 0x5607414a2dc0] mmco: unref short failure
[h264 @ 0x5607414a2dc0] mmco: unref short failure
09/17/2024 03:02:42 - INFO - __main__ -   current idx -c6ksbh044A.74 from finetune_area returns wrong image/video, use 34459 instead.
[h264 @ 0x560743465680] mmco: unref short failure
[h264 @ 0x560740ea91c0] mmco: unref short failure
[h264 @ 0x55a310eca440] mmco: unref short failure
[h264 @ 0x55a310eca440] mmco: unref short failure
[h264 @ 0x55a310eca440] mmco: unref short failure
[h264 @ 0x55a310eca440] mmco: unref short failure
[h264 @ 0x55e2393c7380] mmco: unref short failure
[h264 @ 0x55e2393c7380] mmco: unref short failure
[h264 @ 0x56074ab61b40] mmco: unref short failure
[h264 @ 0x56074ab61b40] mmco: unref short failure
 21%|██        | 598/2910 [3:41:29<24:36:13, 38.31s/it][h264 @ 0x55e23d2b6640] mmco: unref short failure
[h264 @ 0x55b5ab3a8180] mmco: unref short failure
[h264 @ 0x55e238461880] mmco: unref short failure
[h264 @ 0x55e238461880] mmco: unref short failure
 21%|██        | 599/2910 [3:41:35<18:20:57, 28.58s/it]09/17/2024 03:03:21 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 03:03:21 - INFO - __main__ -   start running ret%tva validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a314d93a80] mmco: unref short failure
[h264 @ 0x55a314d93a80] mmco: unref short failure
[h264 @ 0x560747e3abc0] mmco: unref short failure
[h264 @ 0x55a31b4107c0] mmco: unref short failure
[h264 @ 0x55e239833640] mmco: unref short failure
[h264 @ 0x55e2461cf980] mmco: unref short failure
[h264 @ 0x55e2461cf980] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e237690380] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a31590fe00] mmco: unref short failure
[h264 @ 0x55a31590fe00] mmco: unref short failure
[h264 @ 0x55a31590fe00] mmco: unref short failure
[h264 @ 0x55a31590fe00] mmco: unref short failure
[h264 @ 0x55b5b556e240] mmco: unref short failure
[h264 @ 0x55b5b556e240] mmco: unref short failure
[h264 @ 0x55b5b2efce40] mmco: unref short failure
[h264 @ 0x55e248e25c40] mmco: unref short failure
[h264 @ 0x55a30ecb8080] mmco: unref short failure
[h264 @ 0x55a30ecb8080] mmco: unref short failure
[h264 @ 0x55a3105e0a40] mmco: unref short failure
[h264 @ 0x55e242849640] mmco: unref short failure
[h264 @ 0x55e242849640] mmco: unref short failure
[h264 @ 0x55e23ba35900] mmco: unref short failure
[h264 @ 0x55b5b7044c80] mmco: unref short failure
09/17/2024 03:05:16 - INFO - __main__ -   current idx zpVEmyBr_Hg.14 from finetune_area returns wrong image/video, use 126865 instead.
[h264 @ 0x5607487e1f80] mmco: unref short failure
[h264 @ 0x5607487e1f80] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<03:24,  1.08it/s][A
  1%|          | 2/221 [00:01<02:38,  1.38it/s][A
  1%|▏         | 3/221 [00:01<01:47,  2.02it/s][A[h264 @ 0x55e23a33e100] mmco: unref short failure

  2%|▏         | 4/221 [00:01<01:25,  2.54it/s][A
  2%|▏         | 5/221 [00:02<01:12,  3.00it/s][A
  3%|▎         | 6/221 [00:02<01:06,  3.25it/s][A
  3%|▎         | 7/221 [00:02<01:07,  3.18it/s][A
  4%|▎         | 8/221 [00:03<01:19,  2.68it/s][A
  4%|▍         | 9/221 [00:03<01:16,  2.76it/s][A
  5%|▍         | 10/221 [00:04<01:23,  2.53it/s][A
  5%|▌         | 12/221 [00:04<01:15,  2.75it/s][A
  6%|▌         | 13/221 [00:04<01:05,  3.18it/s][A[h264 @ 0x560745728100] mmco: unref short failure
[h264 @ 0x560745728100] mmco: unref short failure

  6%|▋         | 14/221 [00:06<02:02,  1.69it/s][A
  7%|▋         | 15/221 [00:06<01:39,  2.06it/s][A
  7%|▋         | 16/221 [00:06<01:36,  2.13it/s][A
  8%|▊         | 17/221 [00:07<01:30,  2.25it/s][A
  8%|▊         | 18/221 [00:07<01:24,  2.39it/s][A
  9%|▊         | 19/221 [00:07<01:07,  2.99it/s][A
  9%|▉         | 20/221 [00:07<00:56,  3.55it/s][A
 10%|▉         | 21/221 [00:08<00:50,  3.94it/s][A
 10%|▉         | 22/221 [00:08<00:49,  4.05it/s][A
 10%|█         | 23/221 [00:08<00:40,  4.89it/s][A
 11%|█         | 24/221 [00:08<00:37,  5.29it/s][A
 11%|█▏        | 25/221 [00:08<00:38,  5.11it/s][A
 12%|█▏        | 26/221 [00:09<00:51,  3.82it/s][A
 12%|█▏        | 27/221 [00:09<00:45,  4.25it/s][A
 13%|█▎        | 28/221 [00:10<01:08,  2.80it/s][A
 13%|█▎        | 29/221 [00:10<00:55,  3.46it/s][A
 14%|█▎        | 30/221 [00:10<00:54,  3.53it/s][A
 14%|█▍        | 31/221 [00:10<00:53,  3.54it/s][A
 15%|█▍        | 33/221 [00:11<00:48,  3.87it/s][A
 15%|█▌        | 34/221 [00:11<00:42,  4.45it/s][A
 16%|█▌        | 35/221 [00:11<00:40,  4.62it/s][A
 16%|█▋        | 36/221 [00:11<00:45,  4.11it/s][A
 17%|█▋        | 37/221 [00:12<01:15,  2.43it/s][A
 17%|█▋        | 38/221 [00:13<01:11,  2.55it/s][A
 18%|█▊        | 39/221 [00:13<00:57,  3.18it/s][A
 18%|█▊        | 40/221 [00:13<00:58,  3.11it/s][A
 19%|█▊        | 41/221 [00:13<00:47,  3.75it/s][A
 19%|█▉        | 42/221 [00:14<01:01,  2.93it/s][A
 19%|█▉        | 43/221 [00:14<00:49,  3.56it/s][A
 20%|█▉        | 44/221 [00:14<00:48,  3.64it/s][A
 20%|██        | 45/221 [00:16<01:54,  1.54it/s][A
 21%|██        | 46/221 [00:16<01:48,  1.61it/s][A
 21%|██▏       | 47/221 [00:17<01:51,  1.56it/s][A
 22%|██▏       | 48/221 [00:17<01:27,  1.97it/s][A
 22%|██▏       | 49/221 [00:17<01:09,  2.48it/s][A
 23%|██▎       | 50/221 [00:17<00:55,  3.10it/s][A
 23%|██▎       | 51/221 [00:17<00:45,  3.76it/s][A
 24%|██▎       | 52/221 [00:18<00:42,  3.98it/s][A
 24%|██▍       | 53/221 [00:18<00:35,  4.67it/s][A
 24%|██▍       | 54/221 [00:20<02:33,  1.09it/s][A
 25%|██▍       | 55/221 [00:21<02:06,  1.31it/s][A
 25%|██▌       | 56/221 [00:21<01:45,  1.56it/s][A
 26%|██▌       | 57/221 [00:21<01:26,  1.90it/s][A
 26%|██▌       | 58/221 [00:21<01:05,  2.47it/s][A
 27%|██▋       | 59/221 [00:22<00:55,  2.91it/s][A
 27%|██▋       | 60/221 [00:22<01:05,  2.44it/s][A
 28%|██▊       | 61/221 [00:23<00:59,  2.69it/s][A
 28%|██▊       | 62/221 [00:23<00:54,  2.91it/s][A
 29%|██▊       | 63/221 [00:23<00:53,  2.93it/s][A
 29%|██▉       | 64/221 [00:23<00:45,  3.47it/s][A
 29%|██▉       | 65/221 [00:24<00:45,  3.44it/s][A
 30%|██▉       | 66/221 [00:24<00:53,  2.89it/s][A
 30%|███       | 67/221 [00:25<01:04,  2.38it/s][A
 31%|███       | 68/221 [00:25<00:55,  2.77it/s][A
 31%|███       | 69/221 [00:26<01:16,  1.99it/s][A
 32%|███▏      | 70/221 [00:26<01:00,  2.50it/s][A[h264 @ 0x560747f2d880] mmco: unref short failure

 32%|███▏      | 71/221 [00:27<01:47,  1.40it/s][A
 33%|███▎      | 72/221 [00:28<01:28,  1.68it/s][A
 33%|███▎      | 73/221 [00:28<01:16,  1.94it/s][A
 33%|███▎      | 74/221 [00:28<00:58,  2.52it/s][A
 34%|███▍      | 75/221 [00:28<00:56,  2.57it/s][A
 34%|███▍      | 76/221 [00:29<00:45,  3.19it/s][A
 35%|███▍      | 77/221 [00:29<00:42,  3.42it/s][A
 35%|███▌      | 78/221 [00:29<00:41,  3.41it/s][A
 36%|███▌      | 79/221 [00:30<00:53,  2.67it/s][A
 36%|███▌      | 80/221 [00:30<00:46,  3.04it/s][A
 37%|███▋      | 81/221 [00:30<00:46,  3.02it/s][A
 37%|███▋      | 82/221 [00:30<00:40,  3.40it/s][A
 38%|███▊      | 83/221 [00:31<00:34,  3.96it/s][A[h264 @ 0x55a31d92a2c0] 
mmco: unref short failure
 38%|███▊      | 84/221 [00:31<00:35,  3.82it/s][A
 38%|███▊      | 85/221 [00:31<00:29,  4.59it/s][A
 39%|███▉      | 86/221 [00:31<00:33,  4.07it/s][A
 39%|███▉      | 87/221 [00:32<00:47,  2.85it/s][A[h264 @ 0x55a31c0d4940] mmco: unref short failure
[h264 @ 0x55a31c0d4940] mmco: unref short failure
[h264 @ 0x55a31c0d4940] mmco: unref short failure
[h264 @ 0x55a31c0d4940] mmco: unref short failure

 40%|███▉      | 88/221 [00:33<00:59,  2.25it/s][A
 40%|████      | 89/221 [00:33<01:14,  1.77it/s][A
 41%|████      | 90/221 [00:34<01:02,  2.09it/s][A
 41%|████      | 91/221 [00:34<00:49,  2.64it/s][A
 42%|████▏     | 92/221 [00:34<00:42,  3.06it/s][A
 42%|████▏     | 93/221 [00:35<00:49,  2.60it/s][A
 43%|████▎     | 94/221 [00:35<00:43,  2.90it/s][A
 43%|████▎     | 95/221 [00:35<00:35,  3.56it/s][A
 43%|████▎     | 96/221 [00:35<00:38,  3.28it/s][A
 44%|████▍     | 97/221 [00:35<00:31,  3.99it/s][A
 44%|████▍     | 98/221 [00:36<00:31,  3.88it/s][A
 45%|████▍     | 99/221 [00:36<00:31,  3.86it/s][A
 45%|████▌     | 100/221 [00:36<00:30,  4.00it/s][A
 46%|████▌     | 101/221 [00:36<00:25,  4.69it/s][A
 46%|████▌     | 102/221 [00:37<00:30,  3.91it/s][A
 47%|████▋     | 103/221 [00:37<00:25,  4.63it/s][A
 47%|████▋     | 104/221 [00:37<00:21,  5.37it/s][A
 48%|████▊     | 105/221 [00:37<00:25,  4.53it/s][A
 48%|████▊     | 106/221 [00:38<00:44,  2.61it/s][A
 48%|████▊     | 107/221 [00:38<00:35,  3.25it/s][A
 49%|████▉     | 108/221 [00:38<00:30,  3.65it/s][A
 49%|████▉     | 109/221 [00:39<00:29,  3.78it/s][A
 50%|████▉     | 110/221 [00:39<00:30,  3.61it/s][A
 50%|█████     | 111/221 [00:39<00:35,  3.11it/s][A
 51%|█████     | 112/221 [00:39<00:30,  3.59it/s][A
 51%|█████     | 113/221 [00:40<00:30,  3.55it/s][A
 52%|█████▏    | 115/221 [00:40<00:20,  5.18it/s][A
 52%|█████▏    | 116/221 [00:44<02:10,  1.25s/it][A
 53%|█████▎    | 117/221 [00:45<01:44,  1.00s/it][A
 53%|█████▎    | 118/221 [00:45<01:23,  1.23it/s][A
 54%|█████▍    | 119/221 [00:45<01:06,  1.53it/s][A
 54%|█████▍    | 120/221 [00:46<00:55,  1.81it/s][A
 55%|█████▌    | 122/221 [00:46<00:36,  2.75it/s][A
 56%|█████▌    | 123/221 [00:46<00:33,  2.95it/s][A
 56%|█████▌    | 124/221 [00:46<00:29,  3.29it/s][A
 57%|█████▋    | 125/221 [00:47<00:29,  3.23it/s][A
 57%|█████▋    | 126/221 [00:47<00:27,  3.43it/s][A
 57%|█████▋    | 127/221 [00:48<00:37,  2.50it/s][A
 58%|█████▊    | 128/221 [00:48<00:35,  2.60it/s][A
 58%|█████▊    | 129/221 [00:48<00:30,  3.05it/s][A
 59%|█████▉    | 130/221 [00:48<00:28,  3.22it/s][A
 60%|█████▉    | 132/221 [00:49<00:20,  4.30it/s][A
 60%|██████    | 133/221 [00:49<00:26,  3.34it/s][A
 61%|██████    | 134/221 [00:49<00:23,  3.68it/s][A
 61%|██████    | 135/221 [00:50<00:26,  3.23it/s][A
 62%|██████▏   | 136/221 [00:50<00:27,  3.05it/s][A
 62%|██████▏   | 137/221 [00:50<00:25,  3.31it/s][A[h264 @ 0x55b5ae0e9080] mmco: unref short failure
[h264 @ 0x55b5ae0e9080] mmco: unref short failure
[h264 @ 0x55b5ae0e9080] mmco: unref short failure
[h264 @ 0x55b5ae0e9080] mmco: unref short failure

 62%|██████▏   | 138/221 [00:51<00:26,  3.11it/s][A
 63%|██████▎   | 139/221 [00:51<00:30,  2.71it/s][A
 63%|██████▎   | 140/221 [00:51<00:27,  2.91it/s][A
 64%|██████▍   | 141/221 [00:52<00:23,  3.37it/s][A
 64%|██████▍   | 142/221 [00:52<00:22,  3.51it/s][A
 65%|██████▍   | 143/221 [00:52<00:26,  2.91it/s][A
 65%|██████▌   | 144/221 [00:53<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:53<00:13,  5.46it/s][A
 67%|██████▋   | 147/221 [00:53<00:13,  5.42it/s][A
 67%|██████▋   | 148/221 [00:53<00:13,  5.22it/s][A[h264 @ 0x560748266c00] mmco: unref short failure
[h264 @ 0x560748266c00] mmco: unref short failure

 67%|██████▋   | 149/221 [00:53<00:12,  5.77it/s][A
 68%|██████▊   | 150/221 [00:53<00:14,  4.89it/s][A
 68%|██████▊   | 151/221 [00:54<00:26,  2.67it/s][A
 69%|██████▉   | 152/221 [00:55<00:27,  2.49it/s][A
 69%|██████▉   | 153/221 [00:55<00:25,  2.67it/s][A
 70%|██████▉   | 154/221 [00:55<00:23,  2.82it/s][A
 70%|███████   | 155/221 [00:56<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:56<00:17,  3.67it/s][A
 71%|███████   | 157/221 [00:57<00:31,  2.01it/s][A
 71%|███████▏  | 158/221 [00:57<00:28,  2.22it/s][A
 72%|███████▏  | 159/221 [00:57<00:22,  2.76it/s][A
 72%|███████▏  | 160/221 [00:58<00:20,  2.99it/s][A
 73%|███████▎  | 161/221 [00:58<00:16,  3.57it/s][A
 73%|███████▎  | 162/221 [00:58<00:13,  4.38it/s][A
 74%|███████▍  | 163/221 [00:58<00:13,  4.23it/s][A
 74%|███████▍  | 164/221 [00:58<00:11,  5.12it/s][A
 75%|███████▍  | 165/221 [00:58<00:09,  5.90it/s][A
 75%|███████▌  | 166/221 [00:59<00:14,  3.90it/s][A
 76%|███████▌  | 167/221 [00:59<00:12,  4.41it/s][A
 76%|███████▌  | 168/221 [01:00<00:20,  2.60it/s][A
 76%|███████▋  | 169/221 [01:00<00:17,  3.01it/s][A
 77%|███████▋  | 170/221 [01:00<00:16,  3.11it/s][A
 77%|███████▋  | 171/221 [01:00<00:16,  2.99it/s][A
 78%|███████▊  | 172/221 [01:01<00:14,  3.37it/s][A
 78%|███████▊  | 173/221 [01:01<00:11,  4.02it/s][A[h264 @ 0x55e24b5a08c0] mmco: unref short failure
[h264 @ 0x55e24b5a08c0] mmco: unref short failure

 79%|███████▉  | 175/221 [01:01<00:09,  4.79it/s][A
 80%|███████▉  | 176/221 [01:01<00:10,  4.36it/s][A
 80%|████████  | 177/221 [01:02<00:09,  4.85it/s][A
 81%|████████  | 178/221 [01:02<00:10,  4.07it/s][A
 81%|████████  | 179/221 [01:02<00:12,  3.46it/s][A
 82%|████████▏ | 181/221 [01:03<00:08,  4.45it/s][A
 82%|████████▏ | 182/221 [01:03<00:08,  4.83it/s][A
 83%|████████▎ | 183/221 [01:03<00:07,  5.01it/s][A[h264 @ 0x56075276bec0] mmco: unref short failure

 83%|████████▎ | 184/221 [01:03<00:09,  4.05it/s][A
 84%|████████▎ | 185/221 [01:04<00:08,  4.01it/s][A
 84%|████████▍ | 186/221 [01:04<00:10,  3.19it/s][A
 85%|████████▍ | 187/221 [01:04<00:09,  3.70it/s][A
 85%|████████▌ | 188/221 [01:05<00:08,  3.69it/s][A
 86%|████████▌ | 189/221 [01:05<00:07,  4.04it/s][A
 86%|████████▌ | 190/221 [01:05<00:08,  3.51it/s][A
 86%|████████▋ | 191/221 [01:05<00:06,  4.34it/s][A
 87%|████████▋ | 192/221 [01:05<00:06,  4.46it/s][A
 88%|████████▊ | 194/221 [01:06<00:08,  3.08it/s][A
 88%|████████▊ | 195/221 [01:06<00:07,  3.60it/s][A
 89%|████████▊ | 196/221 [01:07<00:05,  4.25it/s][A[h264 @ 0x55b5b8035380] mmco: unref short failure
[h264 @ 0x55b5b8035380] mmco: unref short failure

 89%|████████▉ | 197/221 [01:07<00:05,  4.74it/s][A
 90%|████████▉ | 198/221 [01:07<00:05,  4.12it/s][A
 90%|█████████ | 199/221 [01:07<00:04,  4.50it/s][A
 90%|█████████ | 200/221 [01:07<00:05,  4.04it/s][A
 91%|█████████ | 201/221 [01:08<00:05,  3.98it/s][A
 91%|█████████▏| 202/221 [01:08<00:04,  3.99it/s][A
 92%|█████████▏| 203/221 [01:08<00:03,  4.59it/s][A
 92%|█████████▏| 204/221 [01:08<00:03,  5.20it/s][A
 93%|█████████▎| 205/221 [01:08<00:02,  5.98it/s][A
 93%|█████████▎| 206/221 [01:09<00:04,  3.64it/s][A
 94%|█████████▍| 208/221 [01:09<00:02,  5.34it/s][A
 95%|█████████▌| 210/221 [01:09<00:01,  7.10it/s][A
 95%|█████████▌| 211/221 [01:10<00:01,  5.31it/s][A
 96%|█████████▌| 212/221 [01:10<00:01,  5.58it/s][A
 97%|█████████▋| 214/221 [01:10<00:01,  5.14it/s][A09/17/2024 03:06:50 - INFO - __main__ -   current idx MVC6nKCrOgI.12 from finetune_area returns wrong image/video, use 25694 instead.

 97%|█████████▋| 215/221 [01:10<00:01,  4.66it/s][A
 98%|█████████▊| 216/221 [01:11<00:01,  4.37it/s][A
 98%|█████████▊| 217/221 [01:11<00:01,  3.65it/s][A
 99%|█████████▊| 218/221 [01:11<00:00,  3.41it/s][A
 99%|█████████▉| 219/221 [01:12<00:00,  3.51it/s][A[h264 @ 0x55a31b4ed440] mmco: unref short failure
[h264 @ 0x55a31b4ed440] mmco: unref short failure

100%|█████████▉| 220/221 [01:15<00:01,  1.28s/it][A
100%|██████████| 221/221 [01:16<00:00,  1.03it/s][A100%|██████████| 221/221 [01:16<00:00,  2.90it/s]
[h264 @ 0x56074681eec0] mmco: unref short failure
[h264 @ 0x56074681eec0] mmco: unref short failure
[h264 @ 0x56074681eec0] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:04,  3.39it/s][A
  1%|          | 2/221 [00:00<01:04,  3.40it/s][A
  1%|▏         | 3/221 [00:00<01:04,  3.40it/s][A
  2%|▏         | 4/221 [00:01<01:04,  3.35it/s][A
  2%|▏         | 5/221 [00:01<01:04,  3.37it/s][A
  3%|▎         | 6/221 [00:01<01:04,  3.34it/s][A
  3%|▎         | 7/221 [00:02<01:07,  3.19it/s][A
  4%|▎         | 8/221 [00:02<01:06,  3.21it/s][A
  4%|▍         | 9/221 [00:02<01:04,  3.26it/s][A
  5%|▍         | 10/221 [00:03<01:03,  3.30it/s][A
  5%|▍         | 11/221 [00:03<01:03,  3.33it/s][A
  5%|▌         | 12/221 [00:03<01:02,  3.35it/s][A
  6%|▌         | 13/221 [00:03<01:01,  3.36it/s][A
  6%|▋         | 14/221 [00:04<01:01,  3.37it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.36it/s][A
  7%|▋         | 16/221 [00:04<01:00,  3.37it/s][A
  8%|▊         | 17/221 [00:05<01:00,  3.38it/s][A
  8%|▊         | 18/221 [00:05<00:59,  3.39it/s][A
  9%|▊         | 19/221 [00:05<00:59,  3.39it/s][A
  9%|▉         | 20/221 [00:05<00:59,  3.39it/s][A
 10%|▉         | 21/221 [00:06<00:59,  3.37it/s][A
 10%|▉         | 22/221 [00:06<00:58,  3.38it/s][A
 10%|█         | 23/221 [00:06<00:59,  3.34it/s][A
 11%|█         | 24/221 [00:07<00:58,  3.36it/s][A
 11%|█▏        | 25/221 [00:07<00:58,  3.37it/s][A
 12%|█▏        | 26/221 [00:07<00:57,  3.38it/s][A
 12%|█▏        | 27/221 [00:08<00:57,  3.39it/s][A
 13%|█▎        | 28/221 [00:08<00:56,  3.39it/s][A
 13%|█▎        | 29/221 [00:08<00:56,  3.40it/s][A
 14%|█▎        | 30/221 [00:08<00:56,  3.40it/s][A
 14%|█▍        | 31/221 [00:09<00:55,  3.40it/s][A
 14%|█▍        | 32/221 [00:09<00:55,  3.41it/s][A
 15%|█▍        | 33/221 [00:09<00:55,  3.41it/s][A
 15%|█▌        | 34/221 [00:10<00:54,  3.41it/s][A
 16%|█▌        | 35/221 [00:10<00:54,  3.41it/s][A
 16%|█▋        | 36/221 [00:10<00:54,  3.42it/s][A
 17%|█▋        | 37/221 [00:10<00:53,  3.42it/s][A
 17%|█▋        | 38/221 [00:11<00:53,  3.42it/s][A
 18%|█▊        | 39/221 [00:11<00:53,  3.42it/s][A
 18%|█▊        | 40/221 [00:11<00:52,  3.42it/s][A
 19%|█▊        | 41/221 [00:12<00:52,  3.42it/s][A
 19%|█▉        | 42/221 [00:12<00:52,  3.42it/s][A
 19%|█▉        | 43/221 [00:12<00:52,  3.42it/s][A
 20%|█▉        | 44/221 [00:13<00:51,  3.42it/s][A
 20%|██        | 45/221 [00:13<00:51,  3.42it/s][A
 21%|██        | 46/221 [00:13<00:51,  3.42it/s][A
 21%|██▏       | 47/221 [00:13<00:50,  3.42it/s][A
 22%|██▏       | 48/221 [00:14<00:50,  3.42it/s][A
 22%|██▏       | 49/221 [00:14<00:50,  3.42it/s][A
 23%|██▎       | 50/221 [00:14<00:50,  3.42it/s][A
 23%|██▎       | 51/221 [00:15<00:49,  3.42it/s][A
 24%|██▎       | 52/221 [00:15<00:49,  3.42it/s][A
 24%|██▍       | 53/221 [00:15<00:49,  3.42it/s][A
 24%|██▍       | 54/221 [00:15<00:48,  3.42it/s][A
 25%|██▍       | 55/221 [00:16<00:48,  3.42it/s][A
 25%|██▌       | 56/221 [00:16<00:48,  3.42it/s][A
 26%|██▌       | 57/221 [00:16<00:47,  3.42it/s][A
 26%|██▌       | 58/221 [00:17<00:47,  3.42it/s][A
 27%|██▋       | 59/221 [00:17<00:47,  3.42it/s][A
 27%|██▋       | 60/221 [00:17<00:47,  3.42it/s][A
 28%|██▊       | 61/221 [00:17<00:46,  3.42it/s][A
 28%|██▊       | 62/221 [00:18<00:46,  3.42it/s][A
 29%|██▊       | 63/221 [00:18<00:46,  3.42it/s][A
 29%|██▉       | 64/221 [00:18<00:45,  3.42it/s][A
 29%|██▉       | 65/221 [00:19<00:45,  3.42it/s][A
 30%|██▉       | 66/221 [00:19<00:45,  3.42it/s][A
 30%|███       | 67/221 [00:19<00:45,  3.42it/s][A
 31%|███       | 68/221 [00:20<00:44,  3.42it/s][A
 31%|███       | 69/221 [00:20<00:44,  3.42it/s][A
 32%|███▏      | 70/221 [00:20<00:44,  3.42it/s][A
 32%|███▏      | 71/221 [00:20<00:43,  3.42it/s][A
 33%|███▎      | 72/221 [00:21<00:43,  3.42it/s][A
 33%|███▎      | 73/221 [00:21<00:43,  3.42it/s][A
 33%|███▎      | 74/221 [00:21<00:42,  3.42it/s][A
 34%|███▍      | 75/221 [00:22<00:42,  3.42it/s][A
 34%|███▍      | 76/221 [00:22<00:42,  3.42it/s][A
 35%|███▍      | 77/221 [00:22<00:42,  3.42it/s][A
 35%|███▌      | 78/221 [00:22<00:41,  3.42it/s][A
 36%|███▌      | 79/221 [00:23<00:41,  3.42it/s][A
 36%|███▌      | 80/221 [00:23<00:41,  3.42it/s][A
 37%|███▋      | 81/221 [00:23<00:40,  3.42it/s][A
 37%|███▋      | 82/221 [00:24<00:40,  3.42it/s][A
 38%|███▊      | 83/221 [00:24<00:40,  3.42it/s][A
 38%|███▊      | 84/221 [00:24<00:40,  3.42it/s][A
 38%|███▊      | 85/221 [00:25<00:39,  3.42it/s][A
 39%|███▉      | 86/221 [00:25<00:39,  3.42it/s][A
 39%|███▉      | 87/221 [00:25<00:39,  3.42it/s][A
 40%|███▉      | 88/221 [00:25<00:38,  3.42it/s][A
 40%|████      | 89/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 90/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 91/221 [00:26<00:38,  3.42it/s][A
 42%|████▏     | 92/221 [00:27<00:37,  3.42it/s][A
 42%|████▏     | 93/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 94/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 95/221 [00:27<00:36,  3.42it/s][A
 43%|████▎     | 96/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 97/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 98/221 [00:28<00:35,  3.42it/s][A
 45%|████▍     | 99/221 [00:29<00:35,  3.42it/s][A
 45%|████▌     | 100/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 101/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 102/221 [00:29<00:34,  3.42it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 104/221 [00:30<00:34,  3.42it/s][A
 48%|████▊     | 105/221 [00:30<00:33,  3.42it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 107/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 108/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 109/221 [00:32<00:32,  3.42it/s][A
 50%|████▉     | 110/221 [00:32<00:32,  3.42it/s][A
 50%|█████     | 111/221 [00:32<00:32,  3.42it/s][A
 51%|█████     | 112/221 [00:32<00:31,  3.42it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 114/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:33<00:30,  3.42it/s][A
 52%|█████▏    | 116/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:34<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:34<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:35<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:35<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:37<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:38<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:38<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:39<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:39<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:40<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:40<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:41<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:41<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:42<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:43<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:44<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:45<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:45<00:19,  3.42it/s][A
 71%|███████   | 157/221 [00:46<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:46<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:47<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:47<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:48<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:48<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:48<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:49<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:49<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:50<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:51<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:51<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:52<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:52<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:53<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:54<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:54<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:55<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:56<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:56<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:57<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:57<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:58<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:58<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [00:59<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:00<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:01<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:03<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:03<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:04<00:00,  3.42it/s][A100%|██████████| 221/221 [01:04<00:00,  3.41it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:25,  8.63it/s][A
  1%|          | 2/221 [00:00<00:43,  5.00it/s][A
  1%|▏         | 3/221 [00:00<01:12,  2.99it/s][A
  2%|▏         | 4/221 [00:01<00:56,  3.82it/s][A
  2%|▏         | 5/221 [00:01<00:54,  3.98it/s][A
  3%|▎         | 7/221 [00:01<00:46,  4.63it/s][A
  4%|▎         | 8/221 [00:01<00:52,  4.03it/s][A
  4%|▍         | 9/221 [00:02<00:52,  4.02it/s][A
  5%|▍         | 10/221 [00:02<00:51,  4.07it/s][A
  5%|▍         | 11/221 [00:02<00:52,  3.99it/s][A
  5%|▌         | 12/221 [00:02<00:50,  4.12it/s][A
  6%|▌         | 13/221 [00:03<01:35,  2.18it/s][A
  6%|▋         | 14/221 [00:04<01:16,  2.69it/s][A
  7%|▋         | 15/221 [00:04<01:14,  2.77it/s][A
  7%|▋         | 16/221 [00:04<01:20,  2.54it/s][A
  8%|▊         | 17/221 [00:05<01:26,  2.37it/s][A
  8%|▊         | 18/221 [00:05<01:19,  2.54it/s][A
  9%|▊         | 19/221 [00:05<01:03,  3.18it/s][A
  9%|▉         | 20/221 [00:06<01:01,  3.29it/s][A
 10%|▉         | 21/221 [00:06<00:53,  3.75it/s][A
 10%|▉         | 22/221 [00:06<00:48,  4.11it/s][A
 10%|█         | 23/221 [00:06<00:40,  4.95it/s][A
 11%|█         | 24/221 [00:06<00:36,  5.37it/s][A
 11%|█▏        | 25/221 [00:07<00:55,  3.55it/s][A
 12%|█▏        | 26/221 [00:07<00:57,  3.40it/s][A
 12%|█▏        | 27/221 [00:07<00:58,  3.32it/s][A
 13%|█▎        | 28/221 [00:08<01:07,  2.86it/s][A
 13%|█▎        | 29/221 [00:08<01:01,  3.11it/s][A
 14%|█▎        | 30/221 [00:08<01:01,  3.12it/s][A
 14%|█▍        | 31/221 [00:09<00:57,  3.30it/s][A
 14%|█▍        | 32/221 [00:09<00:49,  3.83it/s][A
 15%|█▍        | 33/221 [00:09<00:47,  3.93it/s][A
 15%|█▌        | 34/221 [00:09<00:54,  3.41it/s][A
 16%|█▌        | 35/221 [00:10<00:50,  3.67it/s][A
 16%|█▋        | 36/221 [00:10<00:49,  3.73it/s][A
 17%|█▋        | 37/221 [00:10<00:46,  3.92it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.80it/s][A
 18%|█▊        | 39/221 [00:11<00:40,  4.54it/s][A
 18%|█▊        | 40/221 [00:11<00:46,  3.87it/s][A
 19%|█▊        | 41/221 [00:11<00:42,  4.24it/s][A
 19%|█▉        | 42/221 [00:11<00:39,  4.54it/s][A
 19%|█▉        | 43/221 [00:12<00:47,  3.78it/s][A
 20%|█▉        | 44/221 [00:12<00:44,  3.94it/s][A
 20%|██        | 45/221 [00:12<00:48,  3.60it/s][A
 21%|██        | 46/221 [00:12<00:44,  3.91it/s][A
 21%|██▏       | 47/221 [00:13<00:37,  4.66it/s][A
 22%|██▏       | 49/221 [00:13<00:28,  6.04it/s][A
 23%|██▎       | 50/221 [00:13<00:32,  5.21it/s][A
 23%|██▎       | 51/221 [00:13<00:36,  4.69it/s][A
 24%|██▎       | 52/221 [00:13<00:31,  5.33it/s][A
 24%|██▍       | 53/221 [00:14<00:29,  5.79it/s][A
 24%|██▍       | 54/221 [00:14<00:32,  5.10it/s][A
 25%|██▍       | 55/221 [00:14<00:36,  4.52it/s][A
 25%|██▌       | 56/221 [00:14<00:36,  4.51it/s][A
 26%|██▌       | 57/221 [00:15<00:41,  3.91it/s][A
 26%|██▌       | 58/221 [00:15<00:40,  4.03it/s][A
 27%|██▋       | 59/221 [00:15<00:41,  3.91it/s][A
 27%|██▋       | 60/221 [00:15<00:40,  3.99it/s][A
 28%|██▊       | 61/221 [00:16<00:37,  4.25it/s][A
 28%|██▊       | 62/221 [00:16<00:37,  4.22it/s][A
 29%|██▊       | 63/221 [00:16<00:33,  4.75it/s][A
 29%|██▉       | 64/221 [00:16<00:32,  4.90it/s][A
 29%|██▉       | 65/221 [00:16<00:27,  5.59it/s][A
 30%|██▉       | 66/221 [00:17<00:36,  4.25it/s][A
 30%|███       | 67/221 [00:17<00:54,  2.84it/s][A
 31%|███       | 68/221 [00:18<00:48,  3.17it/s][A
 31%|███       | 69/221 [00:18<00:51,  2.98it/s][A
 32%|███▏      | 70/221 [00:18<00:43,  3.48it/s][A
 32%|███▏      | 71/221 [00:19<00:52,  2.86it/s][A
 33%|███▎      | 72/221 [00:19<00:51,  2.88it/s][A
 33%|███▎      | 73/221 [00:19<00:48,  3.04it/s][A
 33%|███▎      | 74/221 [00:19<00:42,  3.43it/s][A
 34%|███▍      | 75/221 [00:20<00:46,  3.16it/s][A
 35%|███▍      | 77/221 [00:20<00:34,  4.19it/s][A
 35%|███▌      | 78/221 [00:20<00:38,  3.75it/s][A
 36%|███▌      | 79/221 [00:21<00:41,  3.41it/s][A
 36%|███▌      | 80/221 [00:21<00:40,  3.45it/s][A
 37%|███▋      | 81/221 [00:21<00:38,  3.65it/s][A
 37%|███▋      | 82/221 [00:21<00:35,  3.92it/s][A
 38%|███▊      | 83/221 [00:22<00:30,  4.51it/s][A
 38%|███▊      | 84/221 [00:22<00:45,  3.01it/s][A
 38%|███▊      | 85/221 [00:23<00:45,  2.96it/s][A
 39%|███▉      | 86/221 [00:23<00:48,  2.79it/s][A
 39%|███▉      | 87/221 [00:24<00:56,  2.36it/s][A
 40%|███▉      | 88/221 [00:24<00:52,  2.55it/s][A
 40%|████      | 89/221 [00:24<00:51,  2.57it/s][A
 41%|████      | 90/221 [00:25<00:53,  2.45it/s][A
 41%|████      | 91/221 [00:25<00:46,  2.82it/s][A
 42%|████▏     | 92/221 [00:25<00:41,  3.12it/s][A
 42%|████▏     | 93/221 [00:26<00:54,  2.36it/s][A
 43%|████▎     | 94/221 [00:26<00:44,  2.86it/s][A
 43%|████▎     | 95/221 [00:27<00:51,  2.42it/s][A
 43%|████▎     | 96/221 [00:27<00:49,  2.55it/s][A
 44%|████▍     | 97/221 [00:27<00:43,  2.84it/s][A
 44%|████▍     | 98/221 [00:27<00:39,  3.10it/s][A
 45%|████▍     | 99/221 [00:28<00:35,  3.41it/s][A
 45%|████▌     | 100/221 [00:28<00:30,  4.00it/s][A
 46%|████▌     | 101/221 [00:28<00:27,  4.31it/s][A
 46%|████▌     | 102/221 [00:28<00:30,  3.93it/s][A
 47%|████▋     | 103/221 [00:29<00:27,  4.32it/s][A
 47%|████▋     | 104/221 [00:29<00:24,  4.69it/s][A
 48%|████▊     | 105/221 [00:29<00:28,  4.04it/s][A
 48%|████▊     | 106/221 [00:30<00:37,  3.06it/s][A
 48%|████▊     | 107/221 [00:30<00:34,  3.35it/s][A
 49%|████▉     | 108/221 [00:30<00:27,  4.09it/s][A
 49%|████▉     | 109/221 [00:30<00:29,  3.86it/s][A
 50%|████▉     | 110/221 [00:31<00:32,  3.45it/s][A
 50%|█████     | 111/221 [00:31<00:34,  3.14it/s][A
 51%|█████     | 112/221 [00:31<00:37,  2.94it/s][A
 51%|█████     | 113/221 [00:32<00:33,  3.23it/s][A
 52%|█████▏    | 115/221 [00:32<00:25,  4.23it/s][A
 52%|█████▏    | 116/221 [00:32<00:23,  4.50it/s][A
 53%|█████▎    | 117/221 [00:32<00:23,  4.44it/s][A
 53%|█████▎    | 118/221 [00:33<00:29,  3.47it/s][A
 54%|█████▍    | 119/221 [00:33<00:34,  2.98it/s][A
 54%|█████▍    | 120/221 [00:33<00:31,  3.19it/s][A
 55%|█████▍    | 121/221 [00:34<00:25,  3.95it/s][A
 55%|█████▌    | 122/221 [00:34<00:23,  4.26it/s][A
 56%|█████▌    | 123/221 [00:34<00:24,  4.07it/s][A
 56%|█████▌    | 124/221 [00:34<00:27,  3.57it/s][A
 57%|█████▋    | 125/221 [00:35<00:39,  2.43it/s][A
 57%|█████▋    | 126/221 [00:35<00:33,  2.81it/s][A
 57%|█████▋    | 127/221 [00:36<00:46,  2.02it/s][A
 58%|█████▊    | 128/221 [00:36<00:38,  2.41it/s][A
 58%|█████▊    | 129/221 [00:37<00:32,  2.84it/s][A
 59%|█████▉    | 130/221 [00:37<00:33,  2.69it/s][A
 59%|█████▉    | 131/221 [00:37<00:27,  3.31it/s][A
 60%|█████▉    | 132/221 [00:37<00:27,  3.28it/s][A
 60%|██████    | 133/221 [00:38<00:40,  2.19it/s][A
 61%|██████    | 134/221 [00:39<00:38,  2.27it/s][A
 61%|██████    | 135/221 [00:39<00:29,  2.90it/s][A
 62%|██████▏   | 136/221 [00:39<00:28,  2.93it/s][A
 62%|██████▏   | 137/221 [00:39<00:25,  3.28it/s][A
 62%|██████▏   | 138/221 [00:40<00:24,  3.36it/s][A
 63%|██████▎   | 139/221 [00:40<00:28,  2.89it/s][A
 63%|██████▎   | 140/221 [00:40<00:24,  3.31it/s][A
 64%|██████▍   | 141/221 [00:41<00:24,  3.26it/s][A
 64%|██████▍   | 142/221 [00:41<00:21,  3.73it/s][A
 65%|██████▍   | 143/221 [00:41<00:24,  3.14it/s][A
 65%|██████▌   | 144/221 [00:41<00:21,  3.62it/s][A
 66%|██████▌   | 145/221 [00:42<00:21,  3.61it/s][A
 66%|██████▌   | 146/221 [00:42<00:20,  3.61it/s][A
 67%|██████▋   | 147/221 [00:42<00:19,  3.83it/s][A
 67%|██████▋   | 148/221 [00:42<00:17,  4.17it/s][A
 67%|██████▋   | 149/221 [00:43<00:16,  4.34it/s][A
 68%|██████▊   | 150/221 [00:43<00:17,  3.95it/s][A
 68%|██████▊   | 151/221 [00:44<00:29,  2.38it/s][A
 69%|██████▉   | 152/221 [00:44<00:37,  1.84it/s][A
 69%|██████▉   | 153/221 [00:45<00:30,  2.22it/s][A
 70%|██████▉   | 154/221 [00:45<00:25,  2.58it/s][A
 70%|███████   | 155/221 [00:45<00:28,  2.35it/s][A
 71%|███████   | 156/221 [00:46<00:24,  2.65it/s][A
 71%|███████   | 157/221 [00:46<00:23,  2.72it/s][A
 71%|███████▏  | 158/221 [00:46<00:23,  2.65it/s][A
 72%|███████▏  | 159/221 [00:47<00:19,  3.18it/s][A
 72%|███████▏  | 160/221 [00:47<00:16,  3.77it/s][A
 73%|███████▎  | 161/221 [00:47<00:14,  4.13it/s][A
 73%|███████▎  | 162/221 [00:47<00:13,  4.48it/s][A
 74%|███████▍  | 163/221 [00:47<00:12,  4.57it/s][A
 74%|███████▍  | 164/221 [00:48<00:11,  5.10it/s][A
 75%|███████▍  | 165/221 [00:48<00:09,  5.86it/s][A
 75%|███████▌  | 166/221 [00:48<00:12,  4.48it/s][A
 76%|███████▌  | 167/221 [00:48<00:10,  5.08it/s][A
 76%|███████▌  | 168/221 [00:48<00:11,  4.67it/s][A
 76%|███████▋  | 169/221 [00:48<00:09,  5.26it/s][A
 77%|███████▋  | 170/221 [00:49<00:20,  2.45it/s][A
 77%|███████▋  | 171/221 [00:50<00:21,  2.28it/s][A
 78%|███████▊  | 172/221 [00:50<00:18,  2.60it/s][A
 78%|███████▊  | 173/221 [00:50<00:16,  2.85it/s][A
 79%|███████▊  | 174/221 [00:51<00:14,  3.15it/s][A
 79%|███████▉  | 175/221 [00:51<00:16,  2.83it/s][A
 80%|███████▉  | 176/221 [00:51<00:13,  3.23it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.40it/s][A
 81%|████████  | 178/221 [00:52<00:17,  2.48it/s][A
 81%|████████  | 179/221 [00:53<00:15,  2.64it/s][A
 81%|████████▏ | 180/221 [00:53<00:12,  3.36it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.38it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.43it/s][A
 83%|████████▎ | 183/221 [00:54<00:11,  3.23it/s][A
 83%|████████▎ | 184/221 [00:54<00:11,  3.14it/s][A
 84%|████████▎ | 185/221 [00:54<00:09,  3.87it/s][A
 84%|████████▍ | 186/221 [00:55<00:11,  3.01it/s][A
 85%|████████▍ | 187/221 [00:55<00:10,  3.14it/s][A
 85%|████████▌ | 188/221 [00:55<00:10,  3.04it/s][A
 86%|████████▌ | 189/221 [00:55<00:08,  3.56it/s][A
 86%|████████▌ | 190/221 [00:56<00:11,  2.80it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.53it/s][A
 87%|████████▋ | 192/221 [00:56<00:07,  3.83it/s][A
 87%|████████▋ | 193/221 [00:56<00:06,  4.31it/s][A
 88%|████████▊ | 194/221 [00:57<00:06,  3.90it/s][A
 88%|████████▊ | 195/221 [00:57<00:06,  4.16it/s][A
 89%|████████▊ | 196/221 [00:58<00:10,  2.35it/s][A
 89%|████████▉ | 197/221 [00:58<00:09,  2.43it/s][A
 90%|████████▉ | 198/221 [00:59<00:10,  2.29it/s][A
 90%|█████████ | 199/221 [00:59<00:07,  2.87it/s][A
 90%|█████████ | 200/221 [00:59<00:07,  2.90it/s][A
 91%|█████████ | 201/221 [00:59<00:06,  3.15it/s][A
 91%|█████████▏| 202/221 [01:00<00:05,  3.18it/s][A
 92%|█████████▏| 203/221 [01:00<00:05,  3.48it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.66it/s][A
 93%|█████████▎| 205/221 [01:00<00:03,  4.03it/s][A
 93%|█████████▎| 206/221 [01:01<00:04,  3.06it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  3.18it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.63it/s][A
 95%|█████████▍| 209/221 [01:02<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:02<00:03,  3.62it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.95it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.46it/s][A
 96%|█████████▋| 213/221 [01:03<00:02,  3.20it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.01it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.18it/s][A
 98%|█████████▊| 216/221 [01:04<00:01,  3.12it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.10it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.28it/s][A
 99%|█████████▉| 219/221 [01:05<00:00,  2.87it/s][A
100%|█████████▉| 220/221 [01:05<00:00,  3.20it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.02it/s][A100%|██████████| 221/221 [01:05<00:00,  3.35it/s]
09/17/2024 03:09:16 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 599--===========

09/17/2024 03:09:16 - INFO - __main__ -   {'area_r1': 38.6, 'area_recall': '38.6/64.6/74.8', 'area_ravg': 59.3}
09/17/2024 03:09:16 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 599--===========

09/17/2024 03:09:16 - INFO - __main__ -   {'forward_r1': 36.9, 'forward_recall': '36.9/64.9/76.1', 'forward_ravg': 59.3}
09/17/2024 03:09:16 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 599--===========

09/17/2024 03:09:16 - INFO - __main__ -   {'area_video_r1': 39.4, 'area_video_recall': '39.4/66.3/77.0', 'area_video_ravg': 60.9}
09/17/2024 03:09:16 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 299=======

09/17/2024 03:09:16 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 03:09:16 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 599--===========

09/17/2024 03:09:16 - INFO - __main__ -   {'area_video_r1': 53.1, 'area_video_recall': '53.1/75.8/83.3', 'area_video_ravg': 70.7, 'area_video_back_r1': 48.6, 'area_video_back_recall': '48.6/74.1/81.7', 'area_video_back_ravg': 68.1}
09/17/2024 03:09:16 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 549=======

09/17/2024 03:09:16 - INFO - __main__ -   {'area_video_r1': 54.1, 'area_video_recall': '54.1/75.5/82.4', 'area_video_ravg': 70.6, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.5/82.1', 'area_video_back_ravg': 68.7}
09/17/2024 03:09:16 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 599--===========

09/17/2024 03:09:16 - INFO - __main__ -   {'video_r1': 35.7, 'video_recall': '35.7/64.5/74.2', 'video_ravg': 58.1}
09/17/2024 03:09:16 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 249=======

09/17/2024 03:09:16 - INFO - __main__ -   {'video_r1': 37.1, 'video_recall': '37.1/65.0/74.1', 'video_ravg': 58.7}
09/17/2024 03:09:16 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 599--===========

09/17/2024 03:09:16 - INFO - __main__ -   {'video_r1': 53.3, 'video_recall': '53.3/75.3/82.7', 'video_ravg': 70.4}
09/17/2024 03:09:16 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 549=======

09/17/2024 03:09:16 - INFO - __main__ -   {'video_r1': 54.5, 'video_recall': '54.5/76.1/83.4', 'video_ravg': 71.3}
09/17/2024 03:09:40 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.007344195619225502, 'loss_ret%tv%ta--finetune_area/loss_area': 1.1689233779907227, 'loss_ret%tv%ta--finetune_area/total_loss': 1.1762676239013672}
 21%|██        | 600/2910 [3:47:56<86:11:22, 134.32s/it] 21%|██        | 601/2910 [3:48:00<61:00:57, 95.13s/it]  21%|██        | 602/2910 [3:48:04<43:26:15, 67.75s/it][h264 @ 0x55a314c7d580] mmco: unref short failure
 21%|██        | 603/2910 [3:48:08<31:11:32, 48.67s/it] 21%|██        | 604/2910 [3:48:13<22:41:54, 35.44s/it] 21%|██        | 605/2910 [3:48:17<16:46:12, 26.19s/it][h264 @ 0x56074b84a980] mmco: unref short failure
 21%|██        | 606/2910 [3:48:22<12:43:06, 19.87s/it][h264 @ 0x55b5ae0e9540] mmco: unref short failure
[h264 @ 0x55b5ae0e9540] mmco: unref short failure
[h264 @ 0x55b5ae0e9540] mmco: unref short failure
[h264 @ 0x55b5ae0e9540] mmco: unref short failure
 21%|██        | 607/2910 [3:48:27<9:51:22, 15.41s/it]  21%|██        | 608/2910 [3:48:33<7:55:49, 12.40s/it][h264 @ 0x56074fe07600] mmco: unref short failure
 21%|██        | 609/2910 [3:48:38<6:37:33, 10.37s/it][h264 @ 0x55b5b7ea6640] mmco: unref short failure
 21%|██        | 610/2910 [3:48:44<5:41:33,  8.91s/it][h264 @ 0x55a311471940] mmco: unref short failure
[h264 @ 0x55a311471940] mmco: unref short failure
[h264 @ 0x5607499b9740] mmco: unref short failure
[h264 @ 0x5607499b9740] mmco: unref short failure
 21%|██        | 611/2910 [3:48:49<4:54:37,  7.69s/it][h264 @ 0x55b5b70c3440] mmco: unref short failure
 21%|██        | 612/2910 [3:48:54<4:26:48,  6.97s/it] 21%|██        | 613/2910 [3:49:00<4:15:20,  6.67s/it][h264 @ 0x55a322d06b80] mmco: unref short failure
[h264 @ 0x55a322d06b80] mmco: unref short failure
 21%|██        | 614/2910 [3:49:06<4:05:47,  6.42s/it] 21%|██        | 615/2910 [3:49:11<3:50:51,  6.04s/it][h264 @ 0x55b5b24a5b40] mmco: unref short failure
[h264 @ 0x55b5b24a5b40] mmco: unref short failure
[h264 @ 0x55b5b24a5b40] mmco: unref short failure
[h264 @ 0x55e23d48cb00] mmco: unref short failure
[h264 @ 0x55b5afc46bc0] mmco: unref short failure
[h264 @ 0x55b5afc46bc0] mmco: unref short failure
[h264 @ 0x55a316af2a80] mmco: unref short failure
[h264 @ 0x55e238254900] mmco: unref short failure
[h264 @ 0x55e238254900] mmco: unref short failure
[h264 @ 0x55b5ac8d05c0] mmco: unref short failure
[h264 @ 0x55b5b65159c0] mmco: unref short failure
[h264 @ 0x55b5b65159c0] mmco: unref short failure
[h264 @ 0x55b5b65159c0] mmco: unref short failure
[h264 @ 0x55b5b65159c0] mmco: unref short failure
09/17/2024 03:11:23 - INFO - __main__ -   current idx S4W-P5aCWJs.99 from finetune_area returns wrong image/video, use 18278 instead.
[h264 @ 0x55e23c3ff2c0] mmco: unref short failure
[h264 @ 0x560751d98000] mmco: unref short failure
[h264 @ 0x560751d98000] mmco: unref short failure
[h264 @ 0x55b5aa43f680] mmco: unref short failure
[h264 @ 0x55b5afdf3940] mmco: unref short failure
[h264 @ 0x55e23e163a80] mmco: unref short failure
[h264 @ 0x55e23e163a80] mmco: unref short failure
[h264 @ 0x55b5aa9cef00] mmco: unref short failure
[h264 @ 0x55b5aa9cef00] mmco: unref short failure
[h264 @ 0x55b5aa9cef00] mmco: unref short failure
[h264 @ 0x55b5aa9cef00] mmco: unref short failure
[h264 @ 0x55b5ae518800] mmco: unref short failure
[h264 @ 0x55b5abe7a200] mmco: unref short failure
[h264 @ 0x560748934640] mmco: unref short failure
[h264 @ 0x560748934640] mmco: unref short failure
 21%|██        | 616/2910 [3:50:05<13:06:03, 20.56s/it][h264 @ 0x55a31c0ec780] mmco: unref short failure
[h264 @ 0x55e23f5a3980] mmco: unref short failure
[h264 @ 0x55e23f5a3980] mmco: unref short failure
 21%|██        | 617/2910 [3:50:16<11:16:05, 17.69s/it][h264 @ 0x55b5b3c9b640] mmco: unref short failure
[h264 @ 0x55b5b3c9b640] mmco: unref short failure
[h264 @ 0x55b5b5ea49c0] mmco: unref short failure
[h264 @ 0x55b5b5ea49c0] mmco: unref short failure
[h264 @ 0x55b5b5ea49c0] mmco: unref short failure
[h264 @ 0x55b5b5ea49c0] mmco: unref short failure
 21%|██        | 618/2910 [3:50:32<10:50:39, 17.03s/it][h264 @ 0x55e241dfb000] mmco: unref short failure
[h264 @ 0x55e241dfb000] mmco: unref short failure
[h264 @ 0x55e241dfb000] mmco: unref short failure
[h264 @ 0x55e241dfb000] mmco: unref short failure
 21%|██▏       | 619/2910 [3:50:37<8:31:24, 13.39s/it] [h264 @ 0x560749c6a2c0] mmco: unref short failure
[h264 @ 0x56075383c580] mmco: unref short failure
[h264 @ 0x56075383c580] mmco: unref short failure
 21%|██▏       | 620/2910 [3:50:51<8:44:38, 13.75s/it]09/17/2024 03:12:39 - INFO - __main__ -   current idx 3Dl8wLo1W6E.35 from finetune_area returns wrong image/video, use 143646 instead.
 21%|██▏       | 621/2910 [3:50:56<7:01:22, 11.05s/it] 21%|██▏       | 622/2910 [3:51:01<5:55:35,  9.32s/it] 21%|██▏       | 623/2910 [3:51:07<5:17:25,  8.33s/it][h264 @ 0x55e23e40b380] mmco: unref short failure
[h264 @ 0x55e24df23e00] mmco: unref short failure
[h264 @ 0x55e24df23e00] mmco: unref short failure
[h264 @ 0x55a3249e6700] mmco: unref short failure
[h264 @ 0x55a3249e6700] mmco: unref short failure
[h264 @ 0x55a3249e6700] mmco: unref short failure
[h264 @ 0x56074a24fac0] mmco: unref short failure
[h264 @ 0x56074a24fac0] mmco: unref short failure
[h264 @ 0x55e23d005c40] mmco: unref short failure
[h264 @ 0x56074bd1ebc0] mmco: unref short failure
[h264 @ 0x55e23e3fab00] mmco: unref short failure
[h264 @ 0x55e23e3fab00] mmco: unref short failure
[h264 @ 0x55e23949d4c0] mmco: unref short failure
[h264 @ 0x55a318de6380] mmco: unref short failure
09/17/2024 03:13:32 - INFO - __main__ -   current idx EAcu0rdv1mY.94 from finetune_area returns wrong image/video, use 77101 instead.
[h264 @ 0x55a319287ec0] mmco: unref short failure
[h264 @ 0x55a319287ec0] mmco: unref short failure
[h264 @ 0x560749981fc0] mmco: unref short failure
[h264 @ 0x55e23bb95140] mmco: unref short failure
[h264 @ 0x55b5b8270040] mmco: unref short failure
[h264 @ 0x55a321e0fb00] mmco: unref short failure
[h264 @ 0x55a321e0fb00] mmco: unref short failure
[h264 @ 0x55a31dd3c400] mmco: unref short failure
[h264 @ 0x55a31dd3c400] mmco: unref short failure
[h264 @ 0x56074da34900] mmco: unref short failure
[h264 @ 0x56074da34900] mmco: unref short failure
[h264 @ 0x560753fdfc40] mmco: unref short failure
[h264 @ 0x56074a250f80] mmco: unref short failure
[h264 @ 0x56074a250f80] mmco: unref short failure
[h264 @ 0x55e241c9e740] mmco: unref short failure
 21%|██▏       | 624/2910 [3:52:30<19:22:13, 30.50s/it][h264 @ 0x55b5ae803880] mmco: unref short failure
[h264 @ 0x55e246871840] mmco: unref short failure
 21%|██▏       | 625/2910 [3:52:46<16:42:59, 26.34s/it][h264 @ 0x55e24b2daa80] mmco: unref short failure
[h264 @ 0x55e24c09fac0] mmco: unref short failure
[h264 @ 0x55e24c09fac0] mmco: unref short failure
 22%|██▏       | 626/2910 [3:52:58<14:00:33, 22.08s/it]09/17/2024 03:14:48 - INFO - __main__ -   current idx QzpF1yDPHf0.29 from finetune_area returns wrong image/video, use 96137 instead.
 22%|██▏       | 627/2910 [3:53:04<10:51:28, 17.12s/it][h264 @ 0x55b5baae44c0] mmco: unref short failure
[h264 @ 0x55b5baae44c0] mmco: unref short failure
[h264 @ 0x56074998aec0] mmco: unref short failure
[h264 @ 0x56074998aec0] mmco: unref short failure
 22%|██▏       | 628/2910 [3:53:15<9:46:46, 15.43s/it] [h264 @ 0x55e24afd9e80] mmco: unref short failure
[h264 @ 0x5607564cf800] mmco: unref short failure
[h264 @ 0x5607564cf800] mmco: unref short failure
 22%|██▏       | 629/2910 [3:53:24<8:25:47, 13.30s/it][h264 @ 0x55b5bd66c9c0] mmco: unref short failure
 22%|██▏       | 630/2910 [3:53:29<6:50:53, 10.81s/it][h264 @ 0x55b5bcfaca80] mmco: unref short failure
 22%|██▏       | 631/2910 [3:53:34<5:47:59,  9.16s/it][h264 @ 0x56074d9d4100] mmco: unref short failure
09/17/2024 03:15:26 - INFO - __main__ -   current idx g_6rVdVgpd0.43 from finetune_area returns wrong image/video, use 48645 instead.
[h264 @ 0x55b5aec67500] mmco: unref short failure
[h264 @ 0x560747e2eec0] mmco: unref short failure
[h264 @ 0x55e23d142900] mmco: unref short failure
[h264 @ 0x55e23d142900] mmco: unref short failure
[h264 @ 0x560746a72100] mmco: unref short failure
[h264 @ 0x560746a72100] mmco: unref short failure
[h264 @ 0x55a3180f5c00] mmco: unref short failure
[h264 @ 0x55e245a932c0] mmco: unref short failure
[h264 @ 0x560743c0ce80] mmco: unref short failure
[h264 @ 0x560743c0ce80] mmco: unref short failure
[h264 @ 0x560743c0ce80] mmco: unref short failure
[h264 @ 0x560743c0ce80] mmco: unref short failure
09/17/2024 03:16:19 - INFO - __main__ -   current idx O_qInVZBZaw.18 from finetune_area returns wrong image/video, use 66880 instead.
[h264 @ 0x55e2467a9180] mmco: unref short failure
[h264 @ 0x55e2467a9180] mmco: unref short failure
[h264 @ 0x55e23f4d7d00] mmco: unref short failure
09/17/2024 03:16:23 - INFO - __main__ -   current idx eB3AXJxM634.13 from finetune_area returns wrong image/video, use 33993 instead.
[h264 @ 0x56075906b380] mmco: unref short failure
[h264 @ 0x55a318de6a40] mmco: unref short failure
[h264 @ 0x55b5ae7bf900] mmco: unref short failure
 22%|██▏       | 632/2910 [3:54:59<20:05:36, 31.75s/it][h264 @ 0x55a3221633c0] mmco: unref short failure
[h264 @ 0x55a3221633c0] mmco: unref short failure
[h264 @ 0x55e249712e80] mmco: unref short failure
[h264 @ 0x55e249712e80] mmco: unref short failure
[h264 @ 0x55e249712e80] mmco: unref short failure
[h264 @ 0x55b5af958d80] mmco: unref short failure
[h264 @ 0x55e24d17ac40] mmco: unref short failure
[h264 @ 0x55e24d17ac40] mmco: unref short failure
 22%|██▏       | 633/2910 [3:55:18<17:41:56, 27.98s/it][h264 @ 0x55e23d4ae540] mmco: unref short failure
 22%|██▏       | 634/2910 [3:55:23<13:26:24, 21.26s/it][h264 @ 0x55a31dc293c0] mmco: unref short failure
 22%|██▏       | 635/2910 [3:55:28<10:22:49, 16.43s/it][h264 @ 0x55a319f838c0] mmco: unref short failure
[h264 @ 0x55a319f838c0] mmco: unref short failure
[h264 @ 0x55e2453e75c0] mmco: unref short failure
[h264 @ 0x55e2453e75c0] mmco: unref short failure
[h264 @ 0x55e23e1dc100] mmco: unref short failure
[h264 @ 0x55e23e1dc100] mmco: unref short failure
 22%|██▏       | 636/2910 [3:55:44<10:15:53, 16.25s/it][h264 @ 0x55e23ec79180] mmco: unref short failure
 22%|██▏       | 637/2910 [3:55:49<8:08:43, 12.90s/it]  22%|██▏       | 638/2910 [3:55:56<6:51:16, 10.86s/it][h264 @ 0x55b5b9415600] mmco: unref short failure
[h264 @ 0x55b5b9415600] mmco: unref short failure
 22%|██▏       | 639/2910 [3:56:06<6:47:38, 10.77s/it][h264 @ 0x560756a28ec0] mmco: unref short failure
[h264 @ 0x55e243044540] mmco: unref short failure
[h264 @ 0x55e243044540] mmco: unref short failure
[h264 @ 0x55b5b5fdb340] mmco: unref short failure
[h264 @ 0x55b5b5fdb340] mmco: unref short failure
[h264 @ 0x55b5a95e1680] mmco: unref short failure
[h264 @ 0x55b5a95e1680] mmco: unref short failure
[h264 @ 0x55e24a5ca900] mmco: unref short failure
[h264 @ 0x55e24a5ca900] mmco: unref short failure
[h264 @ 0x55e24a5ca900] mmco: unref short failure
[h264 @ 0x55e247226100] mmco: unref short failure
[h264 @ 0x55a310047fc0] mmco: unref short failure
[h264 @ 0x55a310047fc0] mmco: unref short failure
[h264 @ 0x55b5aac89a00] mmco: unref short failure
[h264 @ 0x55b5aac89a00] mmco: unref short failure
[h264 @ 0x55e24a3bf800] mmco: unref short failure
[h264 @ 0x55e24a3bf800] mmco: unref short failure
[h264 @ 0x55e242765140] mmco: unref short failure
[h264 @ 0x56074a4aba00] mmco: unref short failure
[h264 @ 0x56074a4aba00] mmco: unref short failure
[h264 @ 0x56074a4aba00] mmco: unref short failure
[h264 @ 0x56074a4aba00] mmco: unref short failure
[h264 @ 0x56074a4aba00] mmco: unref short failure
[h264 @ 0x56074a4aba00] mmco: unref short failure
[h264 @ 0x56074a4aba00] mmco: unref short failure
[h264 @ 0x56074a4aba00] mmco: unref short failure
[h264 @ 0x55e2511f89c0] mmco: unref short failure
[h264 @ 0x55e2511f89c0] mmco: unref short failure
[h264 @ 0x55e2511f89c0] mmco: unref short failure
[h264 @ 0x55a3244d7c00] mmco: unref short failure
[h264 @ 0x55a31ef72d80] mmco: unref short failure
[h264 @ 0x55a31ef72d80] mmco: unref short failure
[h264 @ 0x55e24a5c4a40] mmco: unref short failure
09/17/2024 03:18:58 - INFO - __main__ -   current idx TjXtZRjeWIo.2 from finetune_area returns wrong image/video, use 118793 instead.
 22%|██▏       | 640/2910 [3:57:22<19:04:52, 30.26s/it][h264 @ 0x55e23c40cbc0] mmco: unref short failure
09/17/2024 03:19:16 - INFO - __main__ -   current idx 7i_0A4oZMd4.75 from finetune_area returns wrong image/video, use 44474 instead.
[h264 @ 0x55e241cce940] mmco: unref short failure
[h264 @ 0x55e241cce940] mmco: unref short failure
 22%|██▏       | 641/2910 [3:57:42<17:04:20, 27.09s/it][h264 @ 0x55e24a832640] mmco: unref short failure
[h264 @ 0x55e24a832640] mmco: unref short failure
[h264 @ 0x55e24a832640] mmco: unref short failure
[h264 @ 0x55e24a832640] mmco: unref short failure
[h264 @ 0x5607426e6a00] mmco: unref short failure
[h264 @ 0x5607426e6a00] mmco: unref short failure
[h264 @ 0x5607426e6a00] mmco: unref short failure
 22%|██▏       | 642/2910 [3:57:46<12:51:31, 20.41s/it] 22%|██▏       | 643/2910 [3:57:58<11:10:33, 17.75s/it][h264 @ 0x55b5b59adf00] mmco: unref short failure
[h264 @ 0x55b5b6f53440] mmco: unref short failure
[h264 @ 0x55b5b6f53440] mmco: unref short failure
[h264 @ 0x55e2434e8b80] mmco: unref short failure
[h264 @ 0x55e2434e8b80] mmco: unref short failure
[h264 @ 0x55e2434e8b80] mmco: unref short failure
[h264 @ 0x55e2434e8b80] mmco: unref short failure
09/17/2024 03:19:48 - INFO - __main__ -   current idx 1o1hMc8PbOU.62 from finetune_area returns wrong image/video, use 91762 instead.
[h264 @ 0x56074f3bac40] mmco: unref short failure
 22%|██▏       | 644/2910 [3:58:20<11:56:06, 18.96s/it][h264 @ 0x5607590c3c00] mmco: unref short failure
 22%|██▏       | 645/2910 [3:58:25<9:26:42, 15.01s/it] [h264 @ 0x55e245a40500] mmco: unref short failure
[h264 @ 0x55e245a40500] mmco: unref short failure
 22%|██▏       | 646/2910 [3:58:30<7:33:07, 12.01s/it] 22%|██▏       | 647/2910 [3:58:39<6:54:50, 11.00s/it][h264 @ 0x55e24338a3c0] mmco: unref short failure
[h264 @ 0x560743225b80] mmco: unref short failure
[h264 @ 0x560743225b80] mmco: unref short failure
[h264 @ 0x55b5c2131c40] mmco: unref short failure
[h264 @ 0x5607462ade00] mmco: unref short failure
[h264 @ 0x5607462ade00] mmco: unref short failure
[h264 @ 0x5607462ade00] mmco: unref short failure
[h264 @ 0x5607462ade00] mmco: unref short failure
[h264 @ 0x55a310435000] mmco: unref short failure
[h264 @ 0x55a310435000] mmco: unref short failure
[h264 @ 0x55a310435000] mmco: unref short failure
[h264 @ 0x55a310435000] mmco: unref short failure
[h264 @ 0x560743ebac00] mmco: unref short failure
[h264 @ 0x5607432ca4c0] mmco: unref short failure
[h264 @ 0x5607432ca4c0] mmco: unref short failure
[h264 @ 0x55b5ae708380] mmco: unref short failure
[h264 @ 0x55b5ae708380] mmco: unref short failure
[h264 @ 0x55b5ae708380] mmco: unref short failure
[h264 @ 0x55b5ae708380] mmco: unref short failure
[h264 @ 0x55b5b6cee480] mmco: unref short failure
 22%|██▏       | 648/2910 [3:59:53<18:40:32, 29.72s/it][h264 @ 0x55b5aac73280] mmco: unref short failure
[h264 @ 0x55b5aac73280] mmco: unref short failure
[h264 @ 0x55e2508bfd80] mmco: unref short failure
[h264 @ 0x55e2508bfd80] mmco: unref short failure
[h264 @ 0x55e2508bfd80] mmco: unref short failure
[h264 @ 0x55e2508bfd80] mmco: unref short failure
[h264 @ 0x55e24d9a9c80] mmco: unref short failure
[h264 @ 0x55e248861740] mmco: unref short failure
 22%|██▏       | 649/2910 [4:00:13<16:56:13, 26.97s/it]09/17/2024 03:21:59 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 03:21:59 - INFO - __main__ -   start running ret%tva validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e245b004c0] mmco: unref short failure
[h264 @ 0x55e245b004c0] mmco: unref short failure
[h264 @ 0x560746da5c00] mmco: unref short failure
[h264 @ 0x560746da5c00] mmco: unref short failure
[h264 @ 0x56075d2929c0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e239e4c080] mmco: unref short failure
[h264 @ 0x55e239e4c080] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x560756548900] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
09/17/2024 03:22:53 - INFO - __main__ -   current idx SQ8PD29d_RE.6 from finetune_area returns wrong image/video, use 136394 instead.
[h264 @ 0x55b5c5471680] mmco: unref short failure
[h264 @ 0x55b5b6cee200] mmco: unref short failure
[h264 @ 0x55b5b6cee200] mmco: unref short failure
[h264 @ 0x55e23c126f80] mmco: unref short failure
[h264 @ 0x56075a166840] mmco: unref short failure
[h264 @ 0x56075a166840] mmco: unref short failure
[h264 @ 0x55b5ae81fb40] mmco: unref short failure
09/17/2024 03:23:34 - INFO - __main__ -   current idx 2xMe1diCHmI.53 from finetune_area returns wrong image/video, use 19642 instead.
[h264 @ 0x56075c10d000] mmco: unref short failure
[h264 @ 0x55a31664f500] mmco: unref short failure
[h264 @ 0x55a31664f500] mmco: unref short failure
[h264 @ 0x55a31664f500] mmco: unref short failure
[h264 @ 0x55a31664f500] mmco: unref short failure
[h264 @ 0x55b5bef5d280] mmco: unref short failure
[h264 @ 0x55a319de5c40] mmco: unref short failure
[h264 @ 0x55b5c2589480] mmco: unref short failure
[h264 @ 0x55b5c2589480] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:15,  1.62it/s][A
  1%|          | 2/221 [00:01<02:06,  1.73it/s][A
  1%|▏         | 3/221 [00:01<01:34,  2.30it/s][A
  2%|▏         | 4/221 [00:01<01:08,  3.17it/s][A
  2%|▏         | 5/221 [00:01<00:51,  4.20it/s][A
  3%|▎         | 6/221 [00:01<00:51,  4.18it/s][A
  3%|▎         | 7/221 [00:02<01:01,  3.47it/s][A
  4%|▎         | 8/221 [00:02<01:21,  2.60it/s][A
  4%|▍         | 9/221 [00:03<01:20,  2.62it/s][A
  5%|▍         | 10/221 [00:03<01:22,  2.57it/s][A
  5%|▍         | 11/221 [00:03<01:06,  3.16it/s][A
  5%|▌         | 12/221 [00:04<01:16,  2.73it/s][A
  6%|▌         | 13/221 [00:04<01:08,  3.05it/s][A
  6%|▋         | 14/221 [00:06<02:19,  1.48it/s][A
  7%|▋         | 15/221 [00:06<01:51,  1.85it/s][A
  7%|▋         | 16/221 [00:06<01:42,  2.01it/s][A
  8%|▊         | 17/221 [00:06<01:25,  2.38it/s][A
  8%|▊         | 18/221 [00:07<01:17,  2.61it/s][A
  9%|▊         | 19/221 [00:07<01:01,  3.30it/s][A
  9%|▉         | 20/221 [00:07<00:54,  3.68it/s][A
 10%|▉         | 21/221 [00:07<00:51,  3.89it/s][A
 10%|▉         | 22/221 [00:08<00:53,  3.70it/s][A[h264 @ 0x55e23f6d8780] mmco: unref short failure

 10%|█         | 23/221 [00:08<00:44,  4.49it/s][h264 @ 0x55e23f6d8780] mmco: unref short failure
[A
 11%|█         | 24/221 [00:08<00:38,  5.06it/s][A
 11%|█▏        | 25/221 [00:08<00:38,  5.04it/s][A
 12%|█▏        | 26/221 [00:08<00:39,  4.97it/s][A
 12%|█▏        | 27/221 [00:08<00:34,  5.70it/s][A
 13%|█▎        | 28/221 [00:09<00:49,  3.87it/s][A
 13%|█▎        | 29/221 [00:09<00:41,  4.59it/s][A
 14%|█▎        | 30/221 [00:09<00:42,  4.46it/s][A
 14%|█▍        | 31/221 [00:10<00:53,  3.53it/s][A
 14%|█▍        | 32/221 [00:10<00:44,  4.27it/s][A
 15%|█▍        | 33/221 [00:10<00:47,  3.99it/s][A
 15%|█▌        | 34/221 [00:10<00:38,  4.83it/s][A
 16%|█▌        | 35/221 [00:10<00:37,  4.96it/s][A
 16%|█▋        | 36/221 [00:11<00:45,  4.05it/s][A
 17%|█▋        | 37/221 [00:12<01:39,  1.84it/s][A
 17%|█▋        | 38/221 [00:12<01:31,  2.01it/s][A
 18%|█▊        | 39/221 [00:12<01:10,  2.57it/s][A
 18%|█▊        | 40/221 [00:13<01:06,  2.73it/s][A
 19%|█▊        | 41/221 [00:13<00:53,  3.39it/s][A
 19%|█▉        | 42/221 [00:13<01:01,  2.92it/s][A[h264 @ 0x560747ef74c0] mmco: unref short failure

 19%|█▉        | 43/221 [00:13<00:48,  3.67it/s][A
 20%|█▉        | 44/221 [00:14<00:41,  4.24it/s][A
 20%|██        | 45/221 [00:15<01:25,  2.05it/s][A
 21%|██        | 46/221 [00:15<01:24,  2.08it/s][A
 21%|██▏       | 47/221 [00:16<01:45,  1.64it/s][A
 22%|██▏       | 48/221 [00:16<01:24,  2.05it/s][A
 22%|██▏       | 49/221 [00:16<01:10,  2.43it/s][A
 23%|██▎       | 50/221 [00:17<00:57,  3.00it/s][A
 23%|██▎       | 51/221 [00:17<00:45,  3.72it/s][A
 24%|██▎       | 52/221 [00:17<00:39,  4.24it/s][A
 24%|██▍       | 53/221 [00:17<00:35,  4.69it/s][A[h264 @ 0x5607560b3300] mmco: unref short failure

 24%|██▍       | 54/221 [00:19<02:19,  1.20it/s][A
 25%|██▍       | 55/221 [00:20<01:55,  1.44it/s][A
 25%|██▌       | 56/221 [00:20<01:30,  1.82it/s][A
 26%|██▌       | 57/221 [00:20<01:16,  2.14it/s][A
 26%|██▌       | 58/221 [00:20<01:03,  2.55it/s][A
 27%|██▋       | 59/221 [00:21<01:03,  2.57it/s][A
 27%|██▋       | 60/221 [00:21<01:12,  2.21it/s][A
 28%|██▊       | 61/221 [00:22<01:02,  2.57it/s][A[h264 @ 0x55e24eac8040] mmco: unref short failure
[h264 @ 0x55e24eac8040] mmco: unref short failure

 28%|██▊       | 62/221 [00:22<00:57,  2.75it/s][A[h264 @ 0x55a314c8c380] mmco: unref short failure

 29%|██▊       | 63/221 [00:22<00:51,  3.08it/s][A
 29%|██▉       | 64/221 [00:22<00:45,  3.48it/s][A
 29%|██▉       | 65/221 [00:22<00:39,  3.94it/s][A[h264 @ 0x55a31a2f1900] mmco: unref short failure

 30%|██▉       | 66/221 [00:23<00:50,  3.05it/s][A
 30%|███       | 67/221 [00:23<00:58,  2.65it/s][A
 31%|███       | 68/221 [00:24<00:50,  3.04it/s][A[h264 @ 0x55e24c03e5c0] mmco: unref short failure

 31%|███       | 69/221 [00:24<01:07,  2.25it/s][A
 32%|███▏      | 70/221 [00:25<00:53,  2.83it/s][A[h264 @ 0x55b5b67d6f40] mmco: unref short failure

 32%|███▏      | 71/221 [00:26<01:39,  1.50it/s][A
 33%|███▎      | 72/221 [00:26<01:23,  1.78it/s][A
 33%|███▎      | 73/221 [00:27<01:11,  2.08it/s][A
 33%|███▎      | 74/221 [00:27<01:00,  2.42it/s][A
 34%|███▍      | 75/221 [00:27<00:58,  2.50it/s][A
 34%|███▍      | 76/221 [00:27<00:46,  3.09it/s][A
 35%|███▍      | 77/221 [00:28<00:43,  3.33it/s][A[h264 @ 0x56075347e200] mmco: unref short failure
[h264 @ 0x56075347e200] mmco: unref short failure
[h264 @ 0x56075347e200] mmco: unref short failure
[h264 @ 0x56075347e200] mmco: unref short failure

 35%|███▌      | 78/221 [00:28<00:43,  3.27it/s][A
 36%|███▌      | 79/221 [00:28<00:55,  2.57it/s][A
 36%|███▌      | 80/221 [00:29<00:48,  2.91it/s][A
 37%|███▋      | 81/221 [00:29<00:46,  2.98it/s][A
 37%|███▋      | 82/221 [00:29<00:39,  3.55it/s][A
 38%|███▊      | 83/221 [00:29<00:31,  4.36it/s][A
 38%|███▊      | 84/221 [00:30<00:34,  4.00it/s][A
 38%|███▊      | 85/221 [00:30<00:28,  4.74it/s][A
 39%|███▉      | 86/221 [00:30<00:32,  4.21it/s][A
 39%|███▉      | 87/221 [00:31<00:45,  2.95it/s][A
 40%|███▉      | 88/221 [00:31<00:52,  2.54it/s][A[h264 @ 0x55a324d83140] mmco: unref short failure
[h264 @ 0x55a324d83140] mmco: unref short failure

 40%|████      | 89/221 [00:33<01:35,  1.38it/s][A
 41%|████      | 90/221 [00:33<01:17,  1.68it/s][A
 41%|████      | 91/221 [00:33<00:58,  2.24it/s][A
 42%|████▏     | 92/221 [00:33<00:49,  2.62it/s][A
 42%|████▏     | 93/221 [00:34<00:53,  2.37it/s][A
 43%|████▎     | 94/221 [00:34<00:47,  2.65it/s][A
 43%|████▎     | 95/221 [00:34<00:38,  3.30it/s][A
 43%|████▎     | 96/221 [00:34<00:37,  3.37it/s][A
 44%|████▍     | 97/221 [00:35<00:37,  3.35it/s][A
 44%|████▍     | 98/221 [00:35<00:37,  3.29it/s][A
 45%|████▍     | 99/221 [00:35<00:30,  4.05it/s][A
 45%|████▌     | 100/221 [00:35<00:28,  4.30it/s][A
 46%|████▌     | 101/221 [00:35<00:24,  4.90it/s][A
 46%|████▌     | 102/221 [00:36<00:31,  3.78it/s][A
 47%|████▋     | 103/221 [00:36<00:29,  4.05it/s][A
 47%|████▋     | 104/221 [00:36<00:24,  4.74it/s][A
 48%|████▊     | 105/221 [00:37<00:27,  4.25it/s][A
 48%|████▊     | 106/221 [00:37<00:47,  2.40it/s][A
 48%|████▊     | 107/221 [00:38<00:39,  2.90it/s][A
 49%|████▉     | 108/221 [00:38<00:34,  3.32it/s][A
 49%|████▉     | 109/221 [00:38<00:37,  3.00it/s][A
 50%|████▉     | 110/221 [00:39<00:40,  2.73it/s][A
 50%|█████     | 111/221 [00:39<00:46,  2.39it/s][A
 51%|█████     | 112/221 [00:39<00:40,  2.71it/s][A
 51%|█████     | 113/221 [00:40<00:40,  2.65it/s][A
 52%|█████▏    | 114/221 [00:40<00:31,  3.39it/s][A
 52%|█████▏    | 115/221 [00:40<00:25,  4.09it/s][A[h264 @ 0x55a31f0134c0] mmco: unref short failure

 52%|█████▏    | 116/221 [00:45<02:43,  1.55s/it][A
 53%|█████▎    | 117/221 [00:45<02:02,  1.17s/it][A
 53%|█████▎    | 118/221 [00:45<01:35,  1.08it/s][A
 54%|█████▍    | 119/221 [00:45<01:12,  1.40it/s][A
 54%|█████▍    | 120/221 [00:46<01:01,  1.63it/s][A
 55%|█████▍    | 121/221 [00:46<00:46,  2.17it/s][A
 55%|█████▌    | 122/221 [00:46<00:39,  2.53it/s][A
 56%|█████▌    | 123/221 [00:46<00:32,  3.00it/s][A
 56%|█████▌    | 124/221 [00:47<00:28,  3.37it/s][A
 57%|█████▋    | 125/221 [00:47<00:30,  3.12it/s][A
 57%|█████▋    | 126/221 [00:47<00:33,  2.87it/s][A
 57%|█████▋    | 127/221 [00:48<00:38,  2.46it/s][A
 58%|█████▊    | 128/221 [00:48<00:37,  2.46it/s][A
 58%|█████▊    | 129/221 [00:49<00:33,  2.73it/s][A
 59%|█████▉    | 130/221 [00:49<00:30,  3.02it/s][A
 59%|█████▉    | 131/221 [00:49<00:24,  3.75it/s][A
 60%|█████▉    | 132/221 [00:49<00:20,  4.36it/s][A
 60%|██████    | 133/221 [00:50<00:29,  2.96it/s][A
 61%|██████    | 134/221 [00:50<00:26,  3.22it/s][A
 61%|██████    | 135/221 [00:50<00:28,  2.97it/s][A
 62%|██████▏   | 136/221 [00:51<00:31,  2.66it/s][A
 62%|██████▏   | 137/221 [00:51<00:27,  3.07it/s][A
 62%|██████▏   | 138/221 [00:51<00:28,  2.93it/s][A
 63%|██████▎   | 139/221 [00:52<00:31,  2.58it/s][A[h264 @ 0x55a3193a3540] mmco: unref short failure
[h264 @ 0x55a3193a3540] mmco: unref short failure

 63%|██████▎   | 140/221 [00:52<00:28,  2.82it/s][A
 64%|██████▍   | 141/221 [00:52<00:27,  2.96it/s][A
 64%|██████▍   | 142/221 [00:53<00:26,  2.98it/s][A
 65%|██████▍   | 143/221 [00:53<00:31,  2.50it/s][A
 65%|██████▌   | 144/221 [00:54<00:26,  2.95it/s][A
 66%|██████▌   | 145/221 [00:54<00:20,  3.69it/s][A
 66%|██████▌   | 146/221 [00:54<00:17,  4.27it/s][A
 67%|██████▋   | 147/221 [00:54<00:16,  4.47it/s][A
 67%|██████▋   | 148/221 [00:54<00:18,  4.02it/s][A
 67%|██████▋   | 149/221 [00:54<00:16,  4.44it/s][A
 68%|██████▊   | 150/221 [00:55<00:15,  4.54it/s][A
 68%|██████▊   | 151/221 [00:56<00:27,  2.52it/s][A
 69%|██████▉   | 152/221 [00:56<00:31,  2.18it/s][A
 69%|██████▉   | 153/221 [00:56<00:28,  2.39it/s][A
 70%|██████▉   | 154/221 [00:57<00:28,  2.38it/s][A
 70%|███████   | 155/221 [00:57<00:22,  2.90it/s][A
 71%|███████   | 156/221 [00:57<00:20,  3.17it/s][A[h264 @ 0x560741e537c0] mmco: unref short failure
[h264 @ 0x560741e537c0] mmco: unref short failure

 71%|███████   | 157/221 [00:59<00:46,  1.36it/s][A
 71%|███████▏  | 158/221 [00:59<00:39,  1.59it/s][A
 72%|███████▏  | 159/221 [01:00<00:31,  2.00it/s][A
 72%|███████▏  | 160/221 [01:00<00:27,  2.23it/s][A
 73%|███████▎  | 161/221 [01:00<00:20,  2.88it/s][A
 73%|███████▎  | 162/221 [01:00<00:17,  3.37it/s][A
 74%|███████▍  | 163/221 [01:01<00:17,  3.32it/s][A
 74%|███████▍  | 164/221 [01:01<00:14,  3.82it/s][A
 75%|███████▍  | 165/221 [01:01<00:12,  4.44it/s][A
 75%|███████▌  | 166/221 [01:01<00:15,  3.54it/s][A
 76%|███████▌  | 167/221 [01:01<00:14,  3.66it/s][A
 76%|███████▌  | 168/221 [01:03<00:27,  1.91it/s][A
 76%|███████▋  | 169/221 [01:03<00:22,  2.30it/s][A
 77%|███████▋  | 170/221 [01:03<00:22,  2.27it/s][A
 77%|███████▋  | 171/221 [01:04<00:19,  2.54it/s][A
 78%|███████▊  | 172/221 [01:04<00:16,  2.91it/s][A
 78%|███████▊  | 173/221 [01:04<00:13,  3.57it/s][A
 79%|███████▊  | 174/221 [01:04<00:10,  4.38it/s][A
 79%|███████▉  | 175/221 [01:04<00:10,  4.23it/s][A
 80%|███████▉  | 176/221 [01:05<00:11,  3.91it/s][A
 80%|████████  | 177/221 [01:05<00:10,  4.25it/s][A
 81%|████████  | 178/221 [01:05<00:10,  4.14it/s][A
 81%|████████  | 179/221 [01:05<00:12,  3.45it/s][A
 82%|████████▏ | 181/221 [01:06<00:09,  4.31it/s][A
 82%|████████▏ | 182/221 [01:06<00:08,  4.71it/s][A
 83%|████████▎ | 183/221 [01:06<00:08,  4.49it/s][A09/17/2024 03:25:29 - INFO - __main__ -   current idx flS6D6P73vs.20 from finetune_area returns wrong image/video, use 40933 instead.

 83%|████████▎ | 184/221 [01:08<00:25,  1.45it/s][A
 84%|████████▎ | 185/221 [01:08<00:20,  1.76it/s][A
 84%|████████▍ | 186/221 [01:09<00:17,  1.97it/s][A
 85%|████████▍ | 187/221 [01:09<00:14,  2.30it/s][A
 85%|████████▌ | 188/221 [01:09<00:12,  2.58it/s][A
 86%|████████▌ | 189/221 [01:09<00:10,  2.94it/s][A
 86%|████████▌ | 190/221 [01:10<00:11,  2.82it/s][A
 86%|████████▋ | 191/221 [01:10<00:08,  3.55it/s][A
 87%|████████▋ | 192/221 [01:10<00:07,  3.96it/s][A
 88%|████████▊ | 194/221 [01:11<00:11,  2.43it/s][A
 88%|████████▊ | 195/221 [01:12<00:08,  2.91it/s][A
 89%|████████▊ | 196/221 [01:12<00:07,  3.21it/s][A
 89%|████████▉ | 197/221 [01:12<00:06,  3.72it/s][A
 90%|████████▉ | 198/221 [01:12<00:07,  3.18it/s][A
 90%|█████████ | 199/221 [01:12<00:06,  3.52it/s][A
 90%|█████████ | 200/221 [01:13<00:06,  3.43it/s][A
 91%|█████████ | 201/221 [01:13<00:05,  3.75it/s][A
 91%|█████████▏| 202/221 [01:13<00:05,  3.69it/s][A
 92%|█████████▏| 203/221 [01:13<00:04,  4.38it/s][A
 92%|█████████▏| 204/221 [01:14<00:03,  4.41it/s][A
 93%|█████████▎| 205/221 [01:14<00:03,  5.05it/s][A
 93%|█████████▎| 206/221 [01:14<00:04,  3.31it/s][A
 94%|█████████▍| 208/221 [01:14<00:02,  4.88it/s][A
 95%|█████████▍| 209/221 [01:15<00:02,  5.53it/s][A
 95%|█████████▌| 211/221 [01:15<00:02,  4.94it/s][A
 96%|█████████▌| 212/221 [01:15<00:01,  5.38it/s][A
 96%|█████████▋| 213/221 [01:15<00:01,  5.82it/s][A
 97%|█████████▋| 214/221 [01:16<00:01,  4.44it/s][A
 97%|█████████▋| 215/221 [01:16<00:01,  4.06it/s][A
 98%|█████████▊| 216/221 [01:16<00:01,  3.93it/s][A
 98%|█████████▊| 217/221 [01:17<00:01,  3.26it/s][A
 99%|█████████▊| 218/221 [01:17<00:00,  3.15it/s][A
 99%|█████████▉| 219/221 [01:17<00:00,  3.51it/s][A
100%|█████████▉| 220/221 [01:21<00:01,  1.40s/it][A
100%|██████████| 221/221 [01:22<00:00,  1.06s/it][A100%|██████████| 221/221 [01:22<00:00,  2.69it/s]
[h264 @ 0x55b5b445f5c0] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:04,  3.39it/s][A
  1%|          | 2/221 [00:00<01:06,  3.28it/s][A
  1%|▏         | 3/221 [00:00<01:05,  3.34it/s][A
  2%|▏         | 4/221 [00:01<01:08,  3.17it/s][A[h264 @ 0x55b5b1316280] mmco: unref short failure

  2%|▏         | 5/221 [00:01<01:06,  3.25it/s][A
  3%|▎         | 6/221 [00:01<01:05,  3.30it/s][A
  3%|▎         | 7/221 [00:02<01:04,  3.33it/s][A
  4%|▎         | 8/221 [00:02<01:03,  3.35it/s][A
  4%|▍         | 9/221 [00:02<01:02,  3.37it/s][A
  5%|▍         | 10/221 [00:03<01:02,  3.37it/s][A
  5%|▍         | 11/221 [00:03<01:02,  3.38it/s][A
  5%|▌         | 12/221 [00:03<01:01,  3.38it/s][A
  6%|▌         | 13/221 [00:03<01:01,  3.38it/s][A
  6%|▋         | 14/221 [00:04<01:01,  3.38it/s][A
  7%|▋         | 15/221 [00:04<01:00,  3.38it/s][A[h264 @ 0x55b5c0f00a00] mmco: unref short failure
[h264 @ 0x55b5c0f00a00] mmco: unref short failure

  7%|▋         | 16/221 [00:04<01:00,  3.37it/s][A
  8%|▊         | 17/221 [00:05<01:03,  3.21it/s][A
  8%|▊         | 18/221 [00:05<01:02,  3.27it/s][A
  9%|▊         | 19/221 [00:05<01:03,  3.20it/s][A
  9%|▉         | 20/221 [00:06<01:02,  3.24it/s][A
 10%|▉         | 21/221 [00:06<01:00,  3.29it/s][A
 10%|▉         | 22/221 [00:06<01:01,  3.25it/s][A
 10%|█         | 23/221 [00:06<01:00,  3.27it/s][A
 11%|█         | 24/221 [00:07<00:59,  3.31it/s][A
 11%|█▏        | 25/221 [00:07<01:00,  3.26it/s][A
 12%|█▏        | 26/221 [00:07<00:59,  3.30it/s][A
 12%|█▏        | 27/221 [00:08<00:58,  3.29it/s][A
 13%|█▎        | 28/221 [00:08<00:58,  3.32it/s][A
 13%|█▎        | 29/221 [00:08<00:57,  3.32it/s][A
 14%|█▎        | 30/221 [00:09<00:59,  3.20it/s][A
 14%|█▍        | 31/221 [00:09<01:01,  3.09it/s][A
 14%|█▍        | 32/221 [00:09<00:59,  3.18it/s][A
 15%|█▍        | 33/221 [00:10<00:59,  3.15it/s][A
 15%|█▌        | 34/221 [00:10<00:57,  3.23it/s][A
 16%|█▌        | 35/221 [00:10<00:56,  3.28it/s][A
 16%|█▋        | 36/221 [00:10<00:56,  3.30it/s][A[h264 @ 0x55b5b099b900] mmco: unref short failure

 17%|█▋        | 37/221 [00:11<00:55,  3.32it/s][A
 17%|█▋        | 38/221 [00:11<00:54,  3.35it/s][A
 18%|█▊        | 39/221 [00:11<00:55,  3.30it/s][A
 18%|█▊        | 40/221 [00:12<00:54,  3.33it/s][A[h264 @ 0x55e23ef3b280] mmco: unref short failure
[h264 @ 0x55e23ef3b280] mmco: unref short failure

 19%|█▊        | 41/221 [00:12<00:53,  3.35it/s][A
 19%|█▉        | 42/221 [00:12<00:53,  3.37it/s][A
 19%|█▉        | 43/221 [00:13<00:52,  3.38it/s][A
 20%|█▉        | 44/221 [00:13<00:52,  3.38it/s][A
 20%|██        | 45/221 [00:13<00:51,  3.39it/s][A[h264 @ 0x55e23c2c3800] mmco: unref short failure
[h264 @ 0x55e23c2c3800] mmco: unref short failure

 21%|██        | 46/221 [00:13<00:51,  3.39it/s][A
 21%|██▏       | 47/221 [00:14<00:51,  3.39it/s][A
 22%|██▏       | 48/221 [00:14<00:50,  3.40it/s][A
 22%|██▏       | 49/221 [00:14<00:50,  3.39it/s][A
 23%|██▎       | 50/221 [00:15<00:50,  3.37it/s][A
 23%|██▎       | 51/221 [00:15<00:51,  3.33it/s][A
 24%|██▎       | 52/221 [00:15<00:51,  3.30it/s][A
 24%|██▍       | 53/221 [00:16<00:50,  3.33it/s][A
 24%|██▍       | 54/221 [00:16<00:49,  3.35it/s][A
 25%|██▍       | 55/221 [00:16<00:49,  3.36it/s][A
 25%|██▌       | 56/221 [00:16<00:49,  3.35it/s][A
 26%|██▌       | 57/221 [00:17<00:48,  3.36it/s][A[h264 @ 0x55e23f7a2b00] mmco: unref short failure
[h264 @ 0x55e23f7a2b00] mmco: unref short failure

 26%|██▌       | 58/221 [00:17<00:48,  3.37it/s][A
 27%|██▋       | 59/221 [00:17<00:47,  3.38it/s][A
 27%|██▋       | 60/221 [00:18<00:47,  3.39it/s][A
 28%|██▊       | 61/221 [00:18<00:47,  3.38it/s][A
 28%|██▊       | 62/221 [00:18<00:46,  3.39it/s][A
 29%|██▊       | 63/221 [00:18<00:46,  3.39it/s][A
 29%|██▉       | 64/221 [00:19<00:46,  3.39it/s][A
 29%|██▉       | 65/221 [00:19<00:45,  3.39it/s][A
 30%|██▉       | 66/221 [00:19<00:45,  3.40it/s][A
 30%|███       | 67/221 [00:20<00:45,  3.39it/s][A
 31%|███       | 68/221 [00:20<00:46,  3.33it/s][A
 31%|███       | 69/221 [00:20<00:45,  3.34it/s][A
 32%|███▏      | 70/221 [00:21<00:45,  3.36it/s][A
 32%|███▏      | 71/221 [00:21<00:44,  3.37it/s][A
 33%|███▎      | 72/221 [00:21<00:44,  3.38it/s][A
 33%|███▎      | 73/221 [00:21<00:43,  3.39it/s][A
 33%|███▎      | 74/221 [00:22<00:43,  3.39it/s][A
 34%|███▍      | 75/221 [00:22<00:43,  3.39it/s][A
 34%|███▍      | 76/221 [00:22<00:42,  3.40it/s][A
 35%|███▍      | 77/221 [00:23<00:42,  3.40it/s][A
 35%|███▌      | 78/221 [00:23<00:42,  3.40it/s][A
 36%|███▌      | 79/221 [00:23<00:41,  3.40it/s][A
 36%|███▌      | 80/221 [00:23<00:41,  3.40it/s][A
 37%|███▋      | 81/221 [00:24<00:41,  3.40it/s][A
 37%|███▋      | 82/221 [00:24<00:40,  3.40it/s][A
 38%|███▊      | 83/221 [00:24<00:40,  3.40it/s][A[h264 @ 0x55b5bc0f66c0] mmco: unref short failure
[h264 @ 0x55b5bc0f66c0] mmco: unref short failure

 38%|███▊      | 84/221 [00:25<00:40,  3.40it/s][A
 38%|███▊      | 85/221 [00:25<00:39,  3.40it/s][A
 39%|███▉      | 86/221 [00:25<00:39,  3.40it/s][A
 39%|███▉      | 87/221 [00:26<00:39,  3.41it/s][A
 40%|███▉      | 88/221 [00:26<00:39,  3.41it/s][A
 40%|████      | 89/221 [00:26<00:38,  3.41it/s][A
 41%|████      | 90/221 [00:26<00:38,  3.41it/s][A
 41%|████      | 91/221 [00:27<00:38,  3.41it/s][A
 42%|████▏     | 92/221 [00:27<00:37,  3.41it/s][A
 42%|████▏     | 93/221 [00:27<00:37,  3.41it/s][A
 43%|████▎     | 94/221 [00:28<00:37,  3.42it/s][A
 43%|████▎     | 95/221 [00:28<00:36,  3.42it/s][A
 43%|████▎     | 96/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 97/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 98/221 [00:29<00:35,  3.42it/s][A
 45%|████▍     | 99/221 [00:29<00:35,  3.42it/s][A
 45%|████▌     | 100/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 101/221 [00:30<00:35,  3.42it/s][A
 46%|████▌     | 102/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 104/221 [00:31<00:34,  3.42it/s][A
 48%|████▊     | 105/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 107/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 108/221 [00:32<00:33,  3.42it/s][A
 49%|████▉     | 109/221 [00:32<00:32,  3.42it/s][A
 50%|████▉     | 110/221 [00:32<00:32,  3.42it/s][A
 50%|█████     | 111/221 [00:33<00:32,  3.42it/s][A
 51%|█████     | 112/221 [00:33<00:31,  3.42it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 114/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:34<00:30,  3.42it/s][A
 52%|█████▏    | 116/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:35<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:35<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:35<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:37<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:38<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:38<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:39<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:40<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:40<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:41<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:42<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:43<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:44<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:45<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:45<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:45<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:46<00:18,  3.42it/s][A
 71%|███████   | 157/221 [00:46<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:47<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:47<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:48<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:48<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:49<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:49<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:50<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:50<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:51<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:52<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:52<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:54<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:54<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:55<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:57<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:57<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:57<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:59<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:02<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.42it/s][A100%|██████████| 221/221 [01:05<00:00,  3.39it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:30,  7.16it/s][A
  1%|          | 2/221 [00:00<00:45,  4.83it/s][A
  1%|▏         | 3/221 [00:00<01:07,  3.21it/s][A
  2%|▏         | 4/221 [00:00<00:52,  4.11it/s][A
  2%|▏         | 5/221 [00:01<00:49,  4.33it/s][A
  3%|▎         | 7/221 [00:01<00:45,  4.66it/s][A
  4%|▎         | 8/221 [00:01<00:54,  3.92it/s][A
  4%|▍         | 9/221 [00:02<00:58,  3.60it/s][A
  5%|▍         | 10/221 [00:02<00:52,  4.00it/s][A
  5%|▍         | 11/221 [00:02<00:51,  4.09it/s][A
  5%|▌         | 12/221 [00:02<00:48,  4.30it/s][A
  6%|▌         | 13/221 [00:03<01:29,  2.32it/s][A
  6%|▋         | 14/221 [00:03<01:12,  2.87it/s][A
  7%|▋         | 15/221 [00:04<01:18,  2.61it/s][A
  7%|▋         | 16/221 [00:04<01:19,  2.57it/s][A
  8%|▊         | 17/221 [00:05<01:24,  2.40it/s][A
  8%|▊         | 18/221 [00:05<01:17,  2.61it/s][A
  9%|▊         | 19/221 [00:05<01:00,  3.31it/s][A
  9%|▉         | 20/221 [00:05<00:55,  3.59it/s][A
 10%|▉         | 21/221 [00:06<00:49,  4.04it/s][A
 10%|▉         | 22/221 [00:06<00:46,  4.29it/s][A
 11%|█         | 24/221 [00:06<00:35,  5.48it/s][A
 11%|█▏        | 25/221 [00:07<00:55,  3.52it/s][A
 12%|█▏        | 26/221 [00:07<00:58,  3.35it/s][A
 12%|█▏        | 27/221 [00:07<00:57,  3.39it/s][A
 13%|█▎        | 28/221 [00:08<01:02,  3.09it/s][A
 13%|█▎        | 29/221 [00:08<00:59,  3.22it/s][A
 14%|█▎        | 30/221 [00:08<00:57,  3.30it/s][A
 14%|█▍        | 31/221 [00:08<00:54,  3.46it/s][A
 14%|█▍        | 32/221 [00:09<00:46,  4.04it/s][A
 15%|█▍        | 33/221 [00:09<00:48,  3.86it/s][A
 15%|█▌        | 34/221 [00:09<00:59,  3.15it/s][A
 16%|█▌        | 35/221 [00:10<00:54,  3.40it/s][A
 16%|█▋        | 36/221 [00:10<00:55,  3.32it/s][A
 17%|█▋        | 37/221 [00:10<00:51,  3.60it/s][A
 17%|█▋        | 38/221 [00:10<00:53,  3.44it/s][A
 18%|█▊        | 39/221 [00:11<00:44,  4.09it/s][A
 18%|█▊        | 40/221 [00:11<00:51,  3.54it/s][A
 19%|█▊        | 41/221 [00:11<00:47,  3.77it/s][A
 19%|█▉        | 42/221 [00:11<00:40,  4.38it/s][A
 19%|█▉        | 43/221 [00:12<00:49,  3.57it/s][A
 20%|█▉        | 44/221 [00:12<00:49,  3.58it/s][A
 20%|██        | 45/221 [00:12<00:51,  3.39it/s][A
 21%|██        | 46/221 [00:13<00:48,  3.58it/s][A
 21%|██▏       | 47/221 [00:13<00:40,  4.27it/s][A
 22%|██▏       | 49/221 [00:13<00:30,  5.69it/s][A
 23%|██▎       | 50/221 [00:13<00:34,  4.94it/s][A
 23%|██▎       | 51/221 [00:13<00:36,  4.61it/s][A
 24%|██▍       | 53/221 [00:14<00:28,  5.81it/s][A
 24%|██▍       | 54/221 [00:14<00:31,  5.33it/s][A
 25%|██▍       | 55/221 [00:14<00:32,  5.05it/s][A
 25%|██▌       | 56/221 [00:14<00:34,  4.73it/s][A
 26%|██▌       | 57/221 [00:15<00:42,  3.87it/s][A
 26%|██▌       | 58/221 [00:15<00:38,  4.21it/s][A
 27%|██▋       | 59/221 [00:15<00:37,  4.28it/s][A
 27%|██▋       | 60/221 [00:15<00:37,  4.25it/s][A
 28%|██▊       | 61/221 [00:16<00:37,  4.26it/s][A
 28%|██▊       | 62/221 [00:16<00:37,  4.27it/s][A
 29%|██▊       | 63/221 [00:16<00:31,  5.00it/s][A
 29%|██▉       | 64/221 [00:16<00:31,  5.04it/s][A
 29%|██▉       | 65/221 [00:16<00:28,  5.53it/s][A
 30%|██▉       | 66/221 [00:17<00:35,  4.34it/s][A
 30%|███       | 67/221 [00:17<00:53,  2.87it/s][A
 31%|███       | 68/221 [00:18<00:47,  3.22it/s][A
 31%|███       | 69/221 [00:18<00:51,  2.96it/s][A
 32%|███▏      | 70/221 [00:18<00:44,  3.39it/s][A
 32%|███▏      | 71/221 [00:19<00:50,  2.97it/s][A
 33%|███▎      | 72/221 [00:19<00:53,  2.80it/s][A
 33%|███▎      | 73/221 [00:19<00:49,  2.98it/s][A
 33%|███▎      | 74/221 [00:20<00:44,  3.28it/s][A
 34%|███▍      | 75/221 [00:20<00:47,  3.07it/s][A
 34%|███▍      | 76/221 [00:20<00:38,  3.80it/s][A
 35%|███▍      | 77/221 [00:20<00:37,  3.84it/s][A
 35%|███▌      | 78/221 [00:21<00:42,  3.36it/s][A
 36%|███▌      | 79/221 [00:21<00:45,  3.10it/s][A
 36%|███▌      | 80/221 [00:21<00:44,  3.19it/s][A
 37%|███▋      | 81/221 [00:22<00:42,  3.30it/s][A
 37%|███▋      | 82/221 [00:22<00:38,  3.58it/s][A
 38%|███▊      | 83/221 [00:22<00:31,  4.39it/s][A
 38%|███▊      | 84/221 [00:22<00:42,  3.25it/s][A
 38%|███▊      | 85/221 [00:23<00:49,  2.77it/s][A
 39%|███▉      | 86/221 [00:23<00:51,  2.64it/s][A
 39%|███▉      | 87/221 [00:24<00:59,  2.25it/s][A
 40%|███▉      | 88/221 [00:24<00:50,  2.62it/s][A
 40%|████      | 89/221 [00:25<00:48,  2.73it/s][A
 41%|████      | 90/221 [00:25<00:54,  2.42it/s][A
 41%|████      | 91/221 [00:25<00:45,  2.88it/s][A
 42%|████▏     | 92/221 [00:26<00:42,  3.06it/s][A
 42%|████▏     | 93/221 [00:26<00:51,  2.51it/s][A
 43%|████▎     | 94/221 [00:26<00:42,  2.96it/s][A
 43%|████▎     | 95/221 [00:27<00:52,  2.42it/s][A
 43%|████▎     | 96/221 [00:27<00:48,  2.58it/s][A
 44%|████▍     | 97/221 [00:27<00:45,  2.75it/s][A
 44%|████▍     | 98/221 [00:28<00:39,  3.08it/s][A
 45%|████▍     | 99/221 [00:28<00:33,  3.59it/s][A
 45%|████▌     | 100/221 [00:28<00:29,  4.05it/s][A
 46%|████▌     | 101/221 [00:28<00:26,  4.51it/s][A
 46%|████▌     | 102/221 [00:29<00:29,  4.01it/s][A
 47%|████▋     | 103/221 [00:29<00:26,  4.47it/s][A
 47%|████▋     | 104/221 [00:29<00:25,  4.59it/s][A
 48%|████▊     | 105/221 [00:29<00:26,  4.33it/s][A
 48%|████▊     | 106/221 [00:30<00:36,  3.15it/s][A
 48%|████▊     | 107/221 [00:30<00:34,  3.29it/s][A
 49%|████▉     | 108/221 [00:30<00:29,  3.79it/s][A
 49%|████▉     | 109/221 [00:30<00:32,  3.44it/s][A
 50%|████▉     | 110/221 [00:31<00:35,  3.14it/s][A
 50%|█████     | 111/221 [00:31<00:34,  3.14it/s][A
 51%|█████     | 112/221 [00:32<00:35,  3.05it/s][A
 51%|█████     | 113/221 [00:32<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:32<00:22,  4.65it/s][A
 52%|█████▏    | 116/221 [00:32<00:21,  4.90it/s][A
 53%|█████▎    | 117/221 [00:32<00:22,  4.63it/s][A
 53%|█████▎    | 118/221 [00:33<00:28,  3.58it/s][A
 54%|█████▍    | 119/221 [00:33<00:31,  3.22it/s][A
 54%|█████▍    | 120/221 [00:34<00:31,  3.20it/s][A
 55%|█████▍    | 121/221 [00:34<00:25,  3.96it/s][A
 55%|█████▌    | 122/221 [00:34<00:23,  4.19it/s][A
 56%|█████▌    | 123/221 [00:34<00:23,  4.14it/s][A
 56%|█████▌    | 124/221 [00:35<00:27,  3.52it/s][A
 57%|█████▋    | 125/221 [00:35<00:38,  2.51it/s][A
 57%|█████▋    | 126/221 [00:35<00:31,  3.02it/s][A
 57%|█████▋    | 127/221 [00:36<00:41,  2.28it/s][A
 58%|█████▊    | 128/221 [00:36<00:35,  2.64it/s][A
 58%|█████▊    | 129/221 [00:37<00:30,  3.05it/s][A
 59%|█████▉    | 130/221 [00:37<00:28,  3.17it/s][A
 59%|█████▉    | 131/221 [00:37<00:24,  3.71it/s][A
 60%|█████▉    | 132/221 [00:37<00:24,  3.56it/s][A
 60%|██████    | 133/221 [00:38<00:38,  2.28it/s][A
 61%|██████    | 134/221 [00:39<00:38,  2.29it/s][A
 61%|██████    | 135/221 [00:39<00:29,  2.90it/s][A
 62%|██████▏   | 136/221 [00:39<00:29,  2.93it/s][A
 62%|██████▏   | 137/221 [00:39<00:26,  3.17it/s][A
 62%|██████▏   | 138/221 [00:40<00:25,  3.20it/s][A
 63%|██████▎   | 139/221 [00:40<00:27,  3.02it/s][A
 63%|██████▎   | 140/221 [00:40<00:23,  3.41it/s][A
 64%|██████▍   | 141/221 [00:40<00:25,  3.19it/s][A
 64%|██████▍   | 142/221 [00:41<00:22,  3.58it/s][A
 65%|██████▍   | 143/221 [00:41<00:25,  3.11it/s][A
 65%|██████▌   | 144/221 [00:41<00:22,  3.49it/s][A
 66%|██████▌   | 145/221 [00:42<00:22,  3.39it/s][A
 66%|██████▌   | 146/221 [00:42<00:21,  3.44it/s][A
 67%|██████▋   | 147/221 [00:42<00:20,  3.67it/s][A
 67%|██████▋   | 148/221 [00:42<00:20,  3.65it/s][A
 67%|██████▋   | 149/221 [00:43<00:17,  4.02it/s][A
 68%|██████▊   | 150/221 [00:43<00:17,  4.14it/s][A
 68%|██████▊   | 151/221 [00:43<00:26,  2.68it/s][A
 69%|██████▉   | 152/221 [00:44<00:35,  1.92it/s][A
 69%|██████▉   | 153/221 [00:45<00:29,  2.31it/s][A
 70%|██████▉   | 154/221 [00:45<00:25,  2.63it/s][A
 70%|███████   | 155/221 [00:45<00:25,  2.55it/s][A
 71%|███████   | 156/221 [00:46<00:24,  2.66it/s][A
 71%|███████   | 157/221 [00:46<00:23,  2.69it/s][A
 71%|███████▏  | 158/221 [00:46<00:23,  2.64it/s][A
 72%|███████▏  | 159/221 [00:47<00:19,  3.13it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.55it/s][A
 73%|███████▎  | 161/221 [00:47<00:15,  3.76it/s][A
 73%|███████▎  | 162/221 [00:47<00:14,  4.09it/s][A
 74%|███████▍  | 163/221 [00:47<00:14,  4.11it/s][A
 74%|███████▍  | 164/221 [00:48<00:12,  4.65it/s][A
 75%|███████▍  | 165/221 [00:48<00:10,  5.19it/s][A
 75%|███████▌  | 166/221 [00:48<00:13,  4.16it/s][A
 76%|███████▌  | 167/221 [00:48<00:11,  4.69it/s][A
 76%|███████▌  | 168/221 [00:48<00:12,  4.30it/s][A
 76%|███████▋  | 169/221 [00:49<00:10,  4.96it/s][A
 77%|███████▋  | 170/221 [00:50<00:21,  2.40it/s][A
 77%|███████▋  | 171/221 [00:50<00:20,  2.43it/s][A
 78%|███████▊  | 172/221 [00:50<00:17,  2.82it/s][A
 78%|███████▊  | 173/221 [00:50<00:16,  2.90it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.37it/s][A
 79%|███████▉  | 175/221 [00:51<00:15,  3.01it/s][A
 80%|███████▉  | 176/221 [00:51<00:13,  3.32it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.53it/s][A
 81%|████████  | 178/221 [00:52<00:16,  2.63it/s][A
 81%|████████  | 179/221 [00:52<00:15,  2.77it/s][A
 81%|████████▏ | 180/221 [00:53<00:11,  3.52it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.44it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.54it/s][A
 83%|████████▎ | 183/221 [00:53<00:10,  3.51it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.61it/s][A
 84%|████████▍ | 186/221 [00:54<00:09,  3.56it/s][A
 85%|████████▍ | 187/221 [00:54<00:09,  3.65it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.35it/s][A
 86%|████████▌ | 189/221 [00:55<00:08,  3.72it/s][A
 86%|████████▌ | 190/221 [00:56<00:10,  3.04it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.75it/s][A
 87%|████████▋ | 192/221 [00:56<00:07,  3.82it/s][A
 87%|████████▋ | 193/221 [00:56<00:07,  3.96it/s][A
 88%|████████▊ | 194/221 [00:56<00:07,  3.68it/s][A
 88%|████████▊ | 195/221 [00:57<00:06,  3.76it/s][A
 89%|████████▊ | 196/221 [00:57<00:10,  2.45it/s][A
 89%|████████▉ | 197/221 [00:58<00:10,  2.21it/s][A
 90%|████████▉ | 198/221 [00:59<00:10,  2.11it/s][A
 90%|█████████ | 199/221 [00:59<00:08,  2.65it/s][A
 90%|█████████ | 200/221 [00:59<00:07,  2.81it/s][A
 91%|█████████ | 201/221 [00:59<00:06,  3.20it/s][A
 91%|█████████▏| 202/221 [01:00<00:06,  3.06it/s][A
 92%|█████████▏| 203/221 [01:00<00:05,  3.50it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.55it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.87it/s][A
 93%|█████████▎| 206/221 [01:01<00:04,  3.04it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  3.24it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.99it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.41it/s][A
 95%|█████████▌| 210/221 [01:02<00:02,  3.80it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  4.05it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.65it/s][A
 96%|█████████▋| 213/221 [01:03<00:02,  3.26it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  2.85it/s][A
 97%|█████████▋| 215/221 [01:03<00:02,  2.87it/s][A
 98%|█████████▊| 216/221 [01:04<00:01,  2.81it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  2.91it/s][A
 99%|█████████▊| 218/221 [01:05<00:01,  2.70it/s][A
 99%|█████████▉| 219/221 [01:05<00:00,  2.68it/s][A
100%|█████████▉| 220/221 [01:05<00:00,  3.16it/s][A
100%|██████████| 221/221 [01:05<00:00,  2.97it/s][A100%|██████████| 221/221 [01:05<00:00,  3.35it/s]
09/17/2024 03:28:04 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 649--===========

09/17/2024 03:28:04 - INFO - __main__ -   {'area_r1': 38.7, 'area_recall': '38.7/64.0/74.2', 'area_ravg': 59.0}
09/17/2024 03:28:04 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 649--===========

09/17/2024 03:28:04 - INFO - __main__ -   {'forward_r1': 36.3, 'forward_recall': '36.3/64.7/75.5', 'forward_ravg': 58.8}
09/17/2024 03:28:04 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 649--===========

09/17/2024 03:28:04 - INFO - __main__ -   {'area_video_r1': 38.2, 'area_video_recall': '38.2/66.0/77.0', 'area_video_ravg': 60.4}
09/17/2024 03:28:04 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 299=======

09/17/2024 03:28:04 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 03:28:04 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 649--===========

09/17/2024 03:28:04 - INFO - __main__ -   {'area_video_r1': 52.5, 'area_video_recall': '52.5/75.2/82.8', 'area_video_ravg': 70.2, 'area_video_back_r1': 48.6, 'area_video_back_recall': '48.6/73.5/80.4', 'area_video_back_ravg': 67.5}
09/17/2024 03:28:04 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 549=======

09/17/2024 03:28:04 - INFO - __main__ -   {'area_video_r1': 54.1, 'area_video_recall': '54.1/75.5/82.4', 'area_video_ravg': 70.6, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.5/82.1', 'area_video_back_ravg': 68.7}
09/17/2024 03:28:04 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 649--===========

09/17/2024 03:28:04 - INFO - __main__ -   {'video_r1': 35.6, 'video_recall': '35.6/64.0/73.9', 'video_ravg': 57.8}
09/17/2024 03:28:04 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 249=======

09/17/2024 03:28:04 - INFO - __main__ -   {'video_r1': 37.1, 'video_recall': '37.1/65.0/74.1', 'video_ravg': 58.7}
09/17/2024 03:28:04 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 649--===========

09/17/2024 03:28:04 - INFO - __main__ -   {'video_r1': 52.8, 'video_recall': '52.8/74.7/82.1', 'video_ravg': 69.9}
09/17/2024 03:28:04 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 549=======

09/17/2024 03:28:04 - INFO - __main__ -   {'video_r1': 54.5, 'video_recall': '54.5/76.1/83.4', 'video_ravg': 71.3}
09/17/2024 03:28:25 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.006520678289234638, 'loss_ret%tv%ta--finetune_area/loss_area': 1.144376277923584, 'loss_ret%tv%ta--finetune_area/total_loss': 1.1508969068527222}
 22%|██▏       | 650/2910 [4:06:42<85:03:10, 135.48s/it] 22%|██▏       | 651/2910 [4:06:45<60:09:34, 95.87s/it]  22%|██▏       | 652/2910 [4:06:49<42:49:27, 68.28s/it] 22%|██▏       | 653/2910 [4:06:54<30:48:32, 49.14s/it][h264 @ 0x55e248958380] mmco: unref short failure
[h264 @ 0x55e248958380] mmco: unref short failure
[h264 @ 0x55e248958380] mmco: unref short failure
[h264 @ 0x55e248958380] mmco: unref short failure
[h264 @ 0x560750a9f100] mmco: unref short failure
 22%|██▏       | 654/2910 [4:06:58<22:24:31, 35.76s/it] 23%|██▎       | 655/2910 [4:07:03<16:34:57, 26.47s/it][h264 @ 0x560756ae9d80] mmco: unref short failure
 23%|██▎       | 656/2910 [4:07:08<12:30:56, 19.99s/it] 23%|██▎       | 657/2910 [4:07:13<9:44:29, 15.57s/it] [h264 @ 0x56074d80a9c0] mmco: unref short failure
[h264 @ 0x55a320b54f80] mmco: unref short failure
 23%|██▎       | 658/2910 [4:07:19<7:52:04, 12.58s/it] 23%|██▎       | 659/2910 [4:07:24<6:35:41, 10.55s/it][h264 @ 0x55b5b09ab400] mmco: unref short failure
[h264 @ 0x55b5b09ab400] mmco: unref short failure
 23%|██▎       | 660/2910 [4:07:30<5:34:59,  8.93s/it][h264 @ 0x55e238f45dc0] mmco: unref short failure
[h264 @ 0x55e238f45dc0] mmco: unref short failure
[h264 @ 0x5607469dc9c0] mmco: unref short failure
[h264 @ 0x5607469dc9c0] mmco: unref short failure
[h264 @ 0x5607469dc9c0] mmco: unref short failure
[h264 @ 0x5607469dc9c0] mmco: unref short failure
[h264 @ 0x55b5b9e42b40] mmco: unref short failure
 23%|██▎       | 661/2910 [4:07:35<5:00:39,  8.02s/it][h264 @ 0x55a325278f40] mmco: unref short failure
[h264 @ 0x5607595d9580] mmco: unref short failure
 23%|██▎       | 662/2910 [4:07:42<4:41:51,  7.52s/it][h264 @ 0x55a326029cc0] mmco: unref short failure
 23%|██▎       | 663/2910 [4:07:48<4:26:36,  7.12s/it] 23%|██▎       | 664/2910 [4:07:54<4:14:56,  6.81s/it][h264 @ 0x55b5bc305240] mmco: unref short failure
[h264 @ 0x5607443dac40] mmco: unref short failure
[h264 @ 0x55e24655ad80] mmco: unref short failure
[h264 @ 0x55e24655ad80] mmco: unref short failure
 23%|██▎       | 665/2910 [4:07:59<3:58:47,  6.38s/it][h264 @ 0x55a316784380] mmco: unref short failure
[h264 @ 0x55a316784380] mmco: unref short failure
[h264 @ 0x55e249cfcf40] mmco: unref short failure
[h264 @ 0x55e24fc08680] mmco: unref short failure
[h264 @ 0x55b5c5c3f900] mmco: unref short failure
[h264 @ 0x55b5c5c3f900] mmco: unref short failure
[h264 @ 0x56075b99bf80] mmco: unref short failure
[h264 @ 0x56075b99bf80] mmco: unref short failure
09/17/2024 03:30:01 - INFO - __main__ -   current idx JRTVXn0PfXQ.11 from finetune_area returns wrong image/video, use 53365 instead.
[h264 @ 0x55e245194a40] mmco: unref short failure
[h264 @ 0x55e245194a40] mmco: unref short failure
[h264 @ 0x55a32cb69ec0] mmco: unref short failure
[h264 @ 0x55b5af58f100] mmco: unref short failure
[h264 @ 0x55b5aa739480] mmco: unref short failure
[h264 @ 0x55b5aa739480] mmco: unref short failure
[h264 @ 0x55b5bb4f9f80] mmco: unref short failure
[h264 @ 0x55b5bb4f9f80] mmco: unref short failure
[h264 @ 0x55b5acf9d2c0] mmco: unref short failure
[h264 @ 0x55b5acf9d2c0] mmco: unref short failure
[h264 @ 0x55e2468117c0] mmco: unref short failure
[h264 @ 0x55e2468117c0] mmco: unref short failure
[h264 @ 0x55a325da9180] mmco: unref short failure
[h264 @ 0x55a325da9180] mmco: unref short failure
[h264 @ 0x55a316c06e80] mmco: unref short failure
[h264 @ 0x55e239a52980] mmco: unref short failure
[h264 @ 0x55e239a52980] mmco: unref short failure
 23%|██▎       | 666/2910 [4:08:44<11:03:04, 17.73s/it][h264 @ 0x55e24a6ea6c0] mmco: unref short failure
[h264 @ 0x55e24a6ea6c0] mmco: unref short failure
[h264 @ 0x55e242ba55c0] mmco: unref short failure
 23%|██▎       | 667/2910 [4:08:53<9:33:33, 15.34s/it] [h264 @ 0x55e23c54b540] mmco: unref short failure
[av1 @ 0x55b5b525a5c0] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5b525a5c0] Failed to get pixel format.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5b525a5c0] Failed to get pixel format.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5b525a5c0] Missing Sequence Header.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Missing Sequence Header.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Missing Sequence Header.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Missing Sequence Header.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Missing Sequence Header.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Missing Sequence Header.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Missing Sequence Header.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Missing Sequence Header.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Missing Sequence Header.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Missing Sequence Header.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Missing Sequence Header.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Missing Sequence Header.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Missing Sequence Header.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Missing Sequence Header.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Missing Sequence Header.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Missing Sequence Header.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Missing Sequence Header.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[av1 @ 0x55b5ae248f80] Your platform doesn't suppport hardware accelerated AV1 decoding.
[av1 @ 0x55b5ae248f80] Failed to get pixel format.
[h264 @ 0x55b5aac73700] mmco: unref short failure
[h264 @ 0x55a31cc9e940] mmco: unref short failure
 23%|██▎       | 668/2910 [4:09:15<10:47:48, 17.34s/it][h264 @ 0x55e24d68d5c0] mmco: unref short failure
[h264 @ 0x55e24d68d5c0] mmco: unref short failure
[h264 @ 0x55b5c68b69c0] mmco: unref short failure
[h264 @ 0x55b5c68b69c0] mmco: unref short failure
 23%|██▎       | 669/2910 [4:09:21<8:32:23, 13.72s/it]  23%|██▎       | 670/2910 [4:09:31<7:57:41, 12.80s/it] 23%|██▎       | 671/2910 [4:09:40<7:10:38, 11.54s/it] 23%|██▎       | 672/2910 [4:09:45<5:58:16,  9.61s/it][h264 @ 0x55e242ffd700] mmco: unref short failure
[h264 @ 0x55e242ffd700] mmco: unref short failure
[h264 @ 0x55e242ffd700] mmco: unref short failure
[h264 @ 0x55e242ffd700] mmco: unref short failure
[h264 @ 0x55e242ffd700] mmco: unref short failure
[h264 @ 0x55e242ffd700] mmco: unref short failure
 23%|██▎       | 673/2910 [4:09:52<5:22:34,  8.65s/it][h264 @ 0x55a326f54900] mmco: unref short failure
[h264 @ 0x55a320e4d880] mmco: unref short failure
[h264 @ 0x55a320e4d880] mmco: unref short failure
[h264 @ 0x55e2470ae380] mmco: unref short failure
[h264 @ 0x55b5aeeea3c0] mmco: unref short failure
[h264 @ 0x55b5aeeea3c0] mmco: unref short failure
[h264 @ 0x560750d74dc0] mmco: unref short failure
[h264 @ 0x55b5b93508c0] mmco: unref short failure
[h264 @ 0x560752de8a00] mmco: unref short failure
[h264 @ 0x560752de8a00] mmco: unref short failure
[h264 @ 0x560752de8a00] mmco: unref short failure
[h264 @ 0x560752de8a00] mmco: unref short failure
09/17/2024 03:32:11 - INFO - __main__ -   current idx hI-_iZaM-ZY.36 from finetune_area returns wrong image/video, use 106857 instead.
[h264 @ 0x55b5c34c53c0] mmco: unref short failure
[h264 @ 0x55b5c34c53c0] mmco: unref short failure
[h264 @ 0x55b5bd94c500] mmco: unref short failure
[h264 @ 0x55b5bd94c500] mmco: unref short failure
[h264 @ 0x55b5bd94c500] mmco: unref short failure
[h264 @ 0x55b5bd94c500] mmco: unref short failure
[h264 @ 0x55e23f7a28c0] mmco: unref short failure
[h264 @ 0x55e23f7a28c0] mmco: unref short failure
[h264 @ 0x55e23f7a28c0] mmco: unref short failure
[h264 @ 0x55e23f7a28c0] mmco: unref short failure
[h264 @ 0x5607589300c0] mmco: unref short failure
[h264 @ 0x5607589300c0] mmco: unref short failure
[h264 @ 0x56075bbdec80] mmco: unref short failure
[h264 @ 0x56075bbdec80] mmco: unref short failure
[h264 @ 0x55a31f9eee00] mmco: unref short failure
[h264 @ 0x55a31f9eee00] mmco: unref short failure
[h264 @ 0x55b5c32d51c0] mmco: unref short failure
[h264 @ 0x55b5c32d51c0] mmco: unref short failure
[h264 @ 0x55b5c32d51c0] mmco: unref short failure
[h264 @ 0x55b5c32d51c0] mmco: unref short failure
[h264 @ 0x55e244a4c140] mmco: unref short failure
[h264 @ 0x55e244a4c140] mmco: unref short failure
09/17/2024 03:32:48 - INFO - __main__ -   current idx Lzt-UMekcLY.51 from finetune_area returns wrong image/video, use 130128 instead.
[h264 @ 0x55e24576ec80] mmco: unref short failure
 23%|██▎       | 674/2910 [4:11:07<17:54:48, 28.84s/it][h264 @ 0x55a3142f2a40] mmco: unref short failure
09/17/2024 03:33:06 - INFO - __main__ -   current idx GdCloC04v0E.24 from finetune_area returns wrong image/video, use 20065 instead.
[h264 @ 0x56075cdc3400] mmco: unref short failure
[h264 @ 0x55a319c31900] mmco: unref short failure
 23%|██▎       | 675/2910 [4:11:27<16:12:21, 26.10s/it][h264 @ 0x560749c60a80] mmco: unref short failure
[h264 @ 0x560749c60a80] mmco: unref short failure
[h264 @ 0x55a327a46280] mmco: unref short failure
[h264 @ 0x55a327a46280] mmco: unref short failure
[h264 @ 0x560757451680] mmco: unref short failure
[h264 @ 0x560757451680] mmco: unref short failure
[h264 @ 0x55e23b77c240] mmco: unref short failure
[h264 @ 0x55e23b77c240] mmco: unref short failure
[h264 @ 0x55e23b77c240] mmco: unref short failure
[h264 @ 0x55e23b77c240] mmco: unref short failure
 23%|██▎       | 676/2910 [4:11:47<15:04:30, 24.29s/it]09/17/2024 03:33:42 - INFO - __main__ -   current idx LqXDiwVxwcc.104 from finetune_area returns wrong image/video, use 130907 instead.
 23%|██▎       | 677/2910 [4:11:57<12:25:57, 20.04s/it][h264 @ 0x55a324708b80] mmco: unref short failure
[h264 @ 0x55a324708b80] mmco: unref short failure
09/17/2024 03:33:45 - INFO - __main__ -   current idx jZFMYW2mcas.95 from finetune_area returns wrong image/video, use 70942 instead.
[h264 @ 0x55a319090300] mmco: unref short failure
[h264 @ 0x55a319090300] mmco: unref short failure
[h264 @ 0x55a319090300] mmco: unref short failure
[h264 @ 0x55a319090300] mmco: unref short failure
 23%|██▎       | 678/2910 [4:12:04<9:55:19, 16.00s/it]  23%|██▎       | 679/2910 [4:12:09<7:48:39, 12.60s/it] 23%|██▎       | 680/2910 [4:12:14<6:27:14, 10.42s/it] 23%|██▎       | 681/2910 [4:12:19<5:25:27,  8.76s/it][h264 @ 0x55e2415ae340] mmco: unref short failure
[h264 @ 0x55e2415ae340] mmco: unref short failure
[h264 @ 0x560756c82040] mmco: unref short failure
[h264 @ 0x55b5b1394480] mmco: unref short failure
[h264 @ 0x55a3210cb240] mmco: unref short failure
[h264 @ 0x55e2500fe5c0] mmco: unref short failure
[h264 @ 0x55e245763c40] mmco: unref short failure
[h264 @ 0x55e245763c40] mmco: unref short failure
[h264 @ 0x55e242e674c0] mmco: unref short failure
[h264 @ 0x55e242e674c0] mmco: unref short failure
[h264 @ 0x5607563f7440] mmco: unref short failure
[h264 @ 0x55b5b95a9180] mmco: unref short failure
[h264 @ 0x55b5b95a9180] mmco: unref short failure
[h264 @ 0x55a323b8ef00] mmco: unref short failure
[h264 @ 0x55e2493ab840] mmco: unref short failure
[h264 @ 0x55e2493ab840] mmco: unref short failure
[h264 @ 0x55a312a33f40] mmco: unref short failure
[h264 @ 0x55a31cc9eb40] mmco: unref short failure
[h264 @ 0x55a31cc9eb40] mmco: unref short failure
 23%|██▎       | 682/2910 [4:13:38<18:35:12, 30.03s/it]09/17/2024 03:35:38 - INFO - __main__ -   current idx jfvYACaIdq8.34 from finetune_area returns wrong image/video, use 62458 instead.
[h264 @ 0x55b5b140aa40] mmco: unref short failure
[h264 @ 0x55b5b140aa40] mmco: unref short failure
[h264 @ 0x55a329bbb480] mmco: unref short failure
[h264 @ 0x55a329bbb480] mmco: unref short failure
 23%|██▎       | 683/2910 [4:13:59<16:53:42, 27.31s/it][h264 @ 0x55b5c653d880] mmco: unref short failure
[h264 @ 0x55b5c653d880] mmco: unref short failure
[h264 @ 0x56075bbde380] mmco: unref short failure
[h264 @ 0x56075bbde380] mmco: unref short failure
[h264 @ 0x55b5ab645fc0] mmco: unref short failure
[h264 @ 0x56075707f7c0] mmco: unref short failure
[h264 @ 0x56075707f7c0] mmco: unref short failure
 24%|██▎       | 684/2910 [4:14:11<14:01:41, 22.69s/it][h264 @ 0x55e24576e5c0] mmco: unref short failure
09/17/2024 03:36:08 - INFO - __main__ -   current idx MQg3FQ-2lHU.8 from finetune_area returns wrong image/video, use 8406 instead.
[h264 @ 0x55b5aa1cb340] mmco: unref short failure
[h264 @ 0x55b5aa1cb340] mmco: unref short failure
[h264 @ 0x55b5aa1cb340] mmco: unref short failure
[h264 @ 0x55b5aa1cb340] mmco: unref short failure
 24%|██▎       | 685/2910 [4:14:28<12:50:51, 20.79s/it] 24%|██▎       | 686/2910 [4:14:33<10:00:33, 16.20s/it] 24%|██▎       | 687/2910 [4:14:39<8:01:04, 12.98s/it] [h264 @ 0x55e253f2cfc0] mmco: unref short failure
[h264 @ 0x55e253f2cfc0] mmco: unref short failure
 24%|██▎       | 688/2910 [4:14:45<6:41:35, 10.84s/it] 24%|██▎       | 689/2910 [4:14:50<5:40:51,  9.21s/it][h264 @ 0x55e24bf9b340] mmco: unref short failure
[h264 @ 0x55a31ffb7f80] mmco: unref short failure
[h264 @ 0x560750bf5900] mmco: unref short failure
[h264 @ 0x55a325ecf500] mmco: unref short failure
[h264 @ 0x55a325ecf500] mmco: unref short failure
[h264 @ 0x560757be8380] mmco: unref short failure
[h264 @ 0x55a3231bd000] mmco: unref short failure
[h264 @ 0x55a3231bd000] mmco: unref short failure
[h264 @ 0x55e251110340] mmco: unref short failure
[h264 @ 0x560763b80300] mmco: unref short failure
[h264 @ 0x560763b80300] mmco: unref short failure
[h264 @ 0x55b5c7505980] mmco: unref short failure
[h264 @ 0x55b5c7505980] mmco: unref short failure
[h264 @ 0x560753ebba80] mmco: unref short failure
[h264 @ 0x55a31e94eb00] mmco: unref short failure
[h264 @ 0x55a31e94eb00] mmco: unref short failure
[h264 @ 0x5607429d0cc0] mmco: unref short failure
[h264 @ 0x5607429d0cc0] mmco: unref short failure
[h264 @ 0x55e242ba55c0] mmco: unref short failure
[h264 @ 0x55e242ba55c0] mmco: unref short failure
09/17/2024 03:37:41 - INFO - __main__ -   current idx DyoQruLbYRg.26 from finetune_area returns wrong image/video, use 72161 instead.
[h264 @ 0x55a327752940] mmco: unref short failure
[h264 @ 0x55a327752940] mmco: unref short failure
[h264 @ 0x55a3186a4e40] mmco: unref short failure
[h264 @ 0x55b5bfaf5300] mmco: unref short failure
[h264 @ 0x55b5bfaf5300] mmco: unref short failure
 24%|██▎       | 690/2910 [4:16:04<17:38:00, 28.60s/it][h264 @ 0x560757419f00] mmco: unref short failure
[h264 @ 0x55e24a6ea240] mmco: unref short failure
 24%|██▎       | 691/2910 [4:16:27<16:34:34, 26.89s/it][h264 @ 0x55e23dd64e40] mmco: unref short failure
 24%|██▍       | 692/2910 [4:16:37<13:27:06, 21.83s/it][h264 @ 0x55b5c3a9ce80] mmco: unref short failure
[h264 @ 0x55b5c3a9ce80] mmco: unref short failure
[h264 @ 0x55b5b4a330c0] mmco: unref short failure
[h264 @ 0x55b5b4a330c0] mmco: unref short failure
[h264 @ 0x560746ec38c0] mmco: unref short failure
[h264 @ 0x560746ec38c0] mmco: unref short failure
 24%|██▍       | 693/2910 [4:16:56<12:59:10, 21.09s/it][h264 @ 0x560757672200] mmco: unref short failure
[h264 @ 0x560757672200] mmco: unref short failure
[h264 @ 0x55b5b9c64380] mmco: unref short failure
 24%|██▍       | 694/2910 [4:17:02<10:10:59, 16.54s/it][h264 @ 0x55b5b4c83780] mmco: unref short failure
[h264 @ 0x55b5b4c83780] mmco: unref short failure
 24%|██▍       | 695/2910 [4:17:11<8:51:51, 14.41s/it]  24%|██▍       | 696/2910 [4:17:18<7:25:42, 12.08s/it] 24%|██▍       | 697/2910 [4:17:24<6:13:53, 10.14s/it][h264 @ 0x55e2407c5ec0] mmco: unref short failure
[h264 @ 0x55e2407c5ec0] mmco: unref short failure
[h264 @ 0x55b5b2496740] mmco: unref short failure
[h264 @ 0x55e242cbd3c0] mmco: unref short failure
[h264 @ 0x55e242cbd3c0] mmco: unref short failure
[h264 @ 0x55a31d70d7c0] mmco: unref short failure
[h264 @ 0x55a327bf7b40] mmco: unref short failure
[h264 @ 0x55a327bf7b40] mmco: unref short failure
[h264 @ 0x56075f764f00] mmco: unref short failure
[h264 @ 0x56075c5fff00] mmco: unref short failure
[h264 @ 0x56075c5fff00] mmco: unref short failure
[h264 @ 0x560758d83980] mmco: unref short failure
[h264 @ 0x55a32e909c00] mmco: unref short failure
[h264 @ 0x55b5afa65ec0] mmco: unref short failure
[h264 @ 0x55b5afa65ec0] mmco: unref short failure
[h264 @ 0x55b5afa65ec0] mmco: unref short failure
[h264 @ 0x55e24c0a11c0] mmco: unref short failure
[h264 @ 0x55e24c0a11c0] mmco: unref short failure
[h264 @ 0x56075f5b1800] mmco: unref short failure
09/17/2024 03:40:02 - INFO - __main__ -   current idx EboJj8xv0Wo.48 from finetune_area returns wrong image/video, use 64218 instead.
[h264 @ 0x55a31f2a7880] mmco: unref short failure
[h264 @ 0x55a31f2a7880] mmco: unref short failure
[h264 @ 0x56075e53e800] mmco: unref short failure
[h264 @ 0x55e24029d3c0] mmco: unref short failure
[h264 @ 0x55a31e94ef80] mmco: unref short failure
[h264 @ 0x55e24f2de380] mmco: unref short failure
[h264 @ 0x55e24f2de380] mmco: unref short failure
[h264 @ 0x55e24f2de380] mmco: unref short failure
[h264 @ 0x55e24f2de380] mmco: unref short failure
[h264 @ 0x55a312f4b440] mmco: unref short failure
[h264 @ 0x55b5c2d7eec0] mmco: unref short failure
 24%|██▍       | 698/2910 [4:18:48<19:51:49, 32.33s/it][h264 @ 0x55a31f9ee640] mmco: unref short failure
not have audios ua_Kowav7hg.20
[h264 @ 0x560741d88d80] mmco: unref short failure
[h264 @ 0x560741d88d80] mmco: unref short failure
[h264 @ 0x560741d88d80] mmco: unref short failure
[h264 @ 0x560741d88d80] mmco: unref short failure
[h264 @ 0x55b5c4bbf480] mmco: unref short failure
[h264 @ 0x55b5c66f45c0] mmco: unref short failure
 24%|██▍       | 699/2910 [4:19:03<16:40:01, 27.14s/it]09/17/2024 03:40:49 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 03:40:49 - INFO - __main__ -   start running ret%tva validation...
[h264 @ 0x55b5c3f89c00] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x5607470b33c0] mmco: unref short failure
[h264 @ 0x55b5aa3ab700] mmco: unref short failure
[h264 @ 0x560750786800] mmco: unref short failure
[h264 @ 0x56075f75a900] mmco: unref short failure
[h264 @ 0x56075f75a900] mmco: unref short failure
[h264 @ 0x55b5ad843840] mmco: unref short failure
[h264 @ 0x55b5ad843840] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55b5b9360700] mmco: unref short failure
[h264 @ 0x55b5b9360700] mmco: unref short failure
[h264 @ 0x560750e66b80] mmco: unref short failure
[h264 @ 0x55a329bde940] mmco: unref short failure
[h264 @ 0x55a31587c580] mmco: unref short failure
[h264 @ 0x55a31587c580] mmco: unref short failure
[h264 @ 0x55e253eee780] mmco: unref short failure
09/17/2024 03:42:32 - INFO - __main__ -   current idx LbxDh6D_sq8.17 from finetune_area returns wrong image/video, use 114389 instead.
[h264 @ 0x55b5c8a11cc0] mmco: unref short failure
[h264 @ 0x55b5c8a11cc0] mmco: unref short failure
09/17/2024 03:42:41 - INFO - __main__ -   current idx 3B1z5s6SZbQ.15 from finetune_area returns wrong image/video, use 127013 instead.
[h264 @ 0x5607569ba440] mmco: unref short failure
[h264 @ 0x5607569ba440] mmco: unref short failure
[h264 @ 0x55b5c4e55540] mmco: unref short failure
09/17/2024 03:42:58 - INFO - __main__ -   current idx 6cR1r93ZMGw.233 from finetune_area returns wrong image/video, use 140074 instead.
[h264 @ 0x55a32e2c0e80] mmco: unref short failure
[h264 @ 0x55a32e2c0e80] mmco: unref short failure
[h264 @ 0x560755706880] mmco: unref short failure
[h264 @ 0x560755706880] mmco: unref short failure
[h264 @ 0x55e2435a3140] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:14,  1.63it/s][A
  1%|          | 2/221 [00:01<02:00,  1.82it/s][A[h264 @ 0x55e2435a3a80] mmco: unref short failure

  1%|▏         | 3/221 [00:01<01:25,  2.56it/s][A
  2%|▏         | 5/221 [00:01<00:47,  4.56it/s][A
  3%|▎         | 7/221 [00:01<00:43,  4.93it/s][A
  4%|▎         | 8/221 [00:02<01:01,  3.46it/s][A[h264 @ 0x55a31ef693c0] mmco: unref short failure
[h264 @ 0x55a31ef693c0] mmco: unref short failure

  4%|▍         | 9/221 [00:02<01:02,  3.38it/s][A
  5%|▍         | 10/221 [00:03<01:07,  3.10it/s][A
  5%|▍         | 11/221 [00:03<00:54,  3.83it/s][A
  5%|▌         | 12/221 [00:03<01:15,  2.76it/s][A
  6%|▌         | 13/221 [00:04<01:03,  3.26it/s][A
  6%|▋         | 14/221 [00:05<02:29,  1.38it/s][A
  7%|▋         | 15/221 [00:06<01:59,  1.73it/s][A
  7%|▋         | 16/221 [00:06<01:45,  1.95it/s][A
  8%|▊         | 17/221 [00:06<01:26,  2.36it/s][A
  8%|▊         | 18/221 [00:06<01:16,  2.66it/s][A
  9%|▊         | 19/221 [00:06<01:01,  3.31it/s][A
  9%|▉         | 20/221 [00:07<00:52,  3.86it/s][A
 10%|▉         | 21/221 [00:07<00:44,  4.49it/s][A
 10%|▉         | 22/221 [00:07<00:47,  4.16it/s][A
 11%|█         | 24/221 [00:07<00:37,  5.21it/s][A
 11%|█▏        | 25/221 [00:08<00:38,  5.09it/s][A[h264 @ 0x56075d682640] mmco: unref short failure
[h264 @ 0x56075d682640] mmco: unref short failure

 12%|█▏        | 26/221 [00:08<00:41,  4.75it/s][A
 12%|█▏        | 27/221 [00:08<00:42,  4.54it/s][A
 13%|█▎        | 28/221 [00:09<01:00,  3.19it/s][A
 13%|█▎        | 29/221 [00:09<00:48,  3.95it/s][A
 14%|█▎        | 30/221 [00:09<00:45,  4.21it/s][A
 14%|█▍        | 31/221 [00:09<00:46,  4.08it/s][A[h264 @ 0x55a324480200] mmco: unref short failure

 15%|█▍        | 33/221 [00:10<00:41,  4.49it/s][A
 15%|█▌        | 34/221 [00:10<00:39,  4.70it/s][A
 16%|█▌        | 35/221 [00:10<00:40,  4.60it/s][A
 16%|█▋        | 36/221 [00:10<00:43,  4.30it/s][A
 17%|█▋        | 37/221 [00:11<01:08,  2.68it/s][A
 17%|█▋        | 38/221 [00:11<01:10,  2.59it/s][A
 18%|█▊        | 39/221 [00:12<00:59,  3.04it/s][A
 18%|█▊        | 40/221 [00:12<00:56,  3.23it/s][A
 19%|█▊        | 41/221 [00:12<00:49,  3.60it/s][A
 19%|█▉        | 42/221 [00:12<00:56,  3.19it/s][A
 19%|█▉        | 43/221 [00:13<00:45,  3.90it/s][A
 20%|█▉        | 44/221 [00:13<00:38,  4.55it/s][A
 20%|██        | 45/221 [00:14<01:42,  1.72it/s][A
 21%|██        | 46/221 [00:15<01:38,  1.78it/s][A
 21%|██▏       | 47/221 [00:15<01:54,  1.52it/s][A
 22%|██▏       | 48/221 [00:16<01:28,  1.95it/s][A
 22%|██▏       | 49/221 [00:16<01:09,  2.48it/s][A
 23%|██▎       | 50/221 [00:16<00:55,  3.11it/s][A
 23%|██▎       | 51/221 [00:16<00:48,  3.48it/s][A
 24%|██▎       | 52/221 [00:16<00:44,  3.83it/s][A
 24%|██▍       | 53/221 [00:16<00:36,  4.62it/s][A
 24%|██▍       | 54/221 [00:19<02:29,  1.12it/s][A
 25%|██▍       | 55/221 [00:19<02:06,  1.31it/s][A
 25%|██▌       | 56/221 [00:20<01:39,  1.66it/s][A
 26%|██▌       | 57/221 [00:20<01:19,  2.05it/s][A
 27%|██▋       | 59/221 [00:20<00:53,  3.01it/s][A
 27%|██▋       | 60/221 [00:21<00:57,  2.81it/s][A
 28%|██▊       | 61/221 [00:21<00:56,  2.81it/s][A
 28%|██▊       | 62/221 [00:21<00:55,  2.89it/s][A
 29%|██▊       | 63/221 [00:22<00:54,  2.90it/s][A
 29%|██▉       | 64/221 [00:22<00:50,  3.13it/s][A
 29%|██▉       | 65/221 [00:22<00:44,  3.48it/s][A[h264 @ 0x55e23bcf2cc0] mmco: unref short failure
[h264 @ 0x55e23bcf2cc0] mmco: unref short failure

 30%|██▉       | 66/221 [00:23<01:12,  2.13it/s][A
 30%|███       | 67/221 [00:24<01:26,  1.77it/s][A
 31%|███       | 68/221 [00:24<01:16,  2.00it/s][A
 31%|███       | 69/221 [00:26<01:59,  1.27it/s][A
 32%|███▏      | 70/221 [00:26<01:39,  1.51it/s][A
 32%|███▏      | 71/221 [00:28<02:37,  1.05s/it][A
 33%|███▎      | 72/221 [00:28<02:03,  1.21it/s][A
 33%|███▎      | 73/221 [00:29<01:43,  1.43it/s][A
 33%|███▎      | 74/221 [00:29<01:21,  1.81it/s][A
 34%|███▍      | 75/221 [00:29<01:15,  1.93it/s][A
 34%|███▍      | 76/221 [00:29<01:01,  2.36it/s][A
 35%|███▍      | 77/221 [00:30<00:52,  2.72it/s][A
 35%|███▌      | 78/221 [00:30<00:55,  2.58it/s][A
 36%|███▌      | 79/221 [00:31<01:18,  1.81it/s][A
 36%|███▌      | 80/221 [00:31<01:02,  2.24it/s][A
 37%|███▋      | 81/221 [00:32<00:56,  2.50it/s][A
 37%|███▋      | 82/221 [00:32<00:45,  3.08it/s][A
 38%|███▊      | 83/221 [00:32<00:37,  3.66it/s][A
 38%|███▊      | 84/221 [00:32<00:40,  3.34it/s][A
 38%|███▊      | 85/221 [00:32<00:35,  3.87it/s][A
 39%|███▉      | 86/221 [00:33<00:34,  3.88it/s][A
 39%|███▉      | 87/221 [00:33<00:48,  2.77it/s][A
 40%|███▉      | 88/221 [00:34<00:55,  2.40it/s][A
 40%|████      | 89/221 [00:35<01:41,  1.30it/s][A
 41%|████      | 90/221 [00:36<01:20,  1.64it/s][A
 41%|████      | 91/221 [00:36<00:59,  2.18it/s][A
 42%|████▏     | 92/221 [00:36<00:50,  2.56it/s][A
 42%|████▏     | 93/221 [00:37<00:56,  2.25it/s][A
 43%|████▎     | 94/221 [00:37<00:52,  2.43it/s][A
 43%|████▎     | 95/221 [00:37<00:46,  2.74it/s][A
 43%|████▎     | 96/221 [00:37<00:40,  3.11it/s][A
 44%|████▍     | 97/221 [00:37<00:33,  3.74it/s][A
 44%|████▍     | 98/221 [00:38<00:31,  3.92it/s][A
 45%|████▍     | 99/221 [00:38<00:25,  4.76it/s][A
 45%|████▌     | 100/221 [00:38<00:25,  4.71it/s][A
 46%|████▌     | 101/221 [00:38<00:23,  5.13it/s][A
 46%|████▌     | 102/221 [00:39<00:30,  3.88it/s][A
 47%|████▋     | 103/221 [00:39<00:26,  4.53it/s][A
 47%|████▋     | 104/221 [00:39<00:24,  4.86it/s][A
 48%|████▊     | 105/221 [00:39<00:24,  4.75it/s][A
 48%|████▊     | 106/221 [00:40<00:49,  2.32it/s][A
 48%|████▊     | 107/221 [00:40<00:38,  2.96it/s][A
 49%|████▉     | 108/221 [00:40<00:34,  3.26it/s][A
 49%|████▉     | 109/221 [00:41<00:33,  3.37it/s][A
 50%|████▉     | 110/221 [00:41<00:35,  3.09it/s][A
 50%|█████     | 111/221 [00:42<00:40,  2.71it/s][A
 51%|█████     | 112/221 [00:42<00:35,  3.11it/s][A
 51%|█████     | 113/221 [00:42<00:34,  3.16it/s][A
 52%|█████▏    | 114/221 [00:42<00:27,  3.89it/s][A
 52%|█████▏    | 115/221 [00:42<00:23,  4.53it/s][A09/17/2024 03:43:56 - INFO - __main__ -   current idx BYJeo2oa0SU.13 from finetune_area returns wrong image/video, use 20625 instead.

 52%|█████▏    | 116/221 [00:47<02:44,  1.57s/it][A
 53%|█████▎    | 117/221 [00:47<02:04,  1.20s/it][A
 53%|█████▎    | 118/221 [00:48<01:35,  1.08it/s][A
 54%|█████▍    | 119/221 [00:48<01:13,  1.39it/s][A
 54%|█████▍    | 120/221 [00:48<01:02,  1.62it/s][A
 55%|█████▍    | 121/221 [00:48<00:48,  2.08it/s][A
 55%|█████▌    | 122/221 [00:49<00:40,  2.47it/s][A
 56%|█████▌    | 123/221 [00:49<00:31,  3.07it/s][A
 56%|█████▌    | 124/221 [00:49<00:28,  3.39it/s][A
 57%|█████▋    | 125/221 [00:49<00:29,  3.22it/s][A
 57%|█████▋    | 126/221 [00:50<00:33,  2.81it/s][A[h264 @ 0x55e250239500] mmco: unref short failure
[h264 @ 0x55e250239500] mmco: unref short failure

 57%|█████▋    | 127/221 [00:50<00:40,  2.32it/s][A
 58%|█████▊    | 128/221 [00:51<00:39,  2.35it/s][A
 58%|█████▊    | 129/221 [00:51<00:33,  2.78it/s][A
 59%|█████▉    | 130/221 [00:51<00:29,  3.09it/s][A
 60%|█████▉    | 132/221 [00:52<00:20,  4.42it/s][A
 60%|██████    | 133/221 [00:52<00:25,  3.45it/s][A
 61%|██████    | 134/221 [00:52<00:22,  3.83it/s][A[h264 @ 0x560751669940] mmco: unref short failure
[h264 @ 0x560751669940] mmco: unref short failure

 61%|██████    | 135/221 [00:53<00:25,  3.32it/s][A
 62%|██████▏   | 136/221 [00:53<00:29,  2.93it/s][A
 62%|██████▏   | 137/221 [00:53<00:24,  3.44it/s][A
 62%|██████▏   | 138/221 [00:54<00:26,  3.17it/s][A
 63%|██████▎   | 139/221 [00:54<00:27,  2.96it/s][A
 63%|██████▎   | 140/221 [00:54<00:26,  3.04it/s][A
 64%|██████▍   | 141/221 [00:55<00:24,  3.27it/s][A
 64%|██████▍   | 142/221 [00:55<00:24,  3.29it/s][A
 65%|██████▍   | 143/221 [00:56<00:32,  2.43it/s][A
 65%|██████▌   | 144/221 [00:56<00:25,  2.98it/s][A
 66%|██████▌   | 145/221 [00:56<00:20,  3.67it/s][A
 66%|██████▌   | 146/221 [00:56<00:17,  4.35it/s][A
 67%|██████▋   | 147/221 [00:56<00:15,  4.72it/s][A
 67%|██████▋   | 148/221 [00:56<00:15,  4.75it/s][A
 67%|██████▋   | 149/221 [00:56<00:13,  5.38it/s][A
 68%|██████▊   | 150/221 [00:57<00:12,  5.59it/s][A
 68%|██████▊   | 151/221 [00:58<00:31,  2.20it/s][A
 69%|██████▉   | 152/221 [00:58<00:33,  2.04it/s][A
 69%|██████▉   | 153/221 [00:59<00:29,  2.33it/s][A
 70%|██████▉   | 154/221 [00:59<00:26,  2.52it/s][A
 70%|███████   | 155/221 [00:59<00:23,  2.79it/s][A
 71%|███████   | 156/221 [00:59<00:21,  2.97it/s][A[h264 @ 0x560745d76880] mmco: unref short failure

 71%|███████   | 157/221 [01:02<00:59,  1.07it/s][A
 71%|███████▏  | 158/221 [01:02<00:46,  1.35it/s][A
 72%|███████▏  | 159/221 [01:02<00:35,  1.75it/s][A
 72%|███████▏  | 160/221 [01:02<00:28,  2.15it/s][A
 73%|███████▎  | 161/221 [01:03<00:21,  2.81it/s][A
 73%|███████▎  | 162/221 [01:03<00:17,  3.41it/s][A
 74%|███████▍  | 163/221 [01:03<00:16,  3.58it/s][A
 74%|███████▍  | 164/221 [01:03<00:13,  4.13it/s][A[h264 @ 0x55a31a61b9c0] mmco: unref short failure
[h264 @ 0x55a31a61b9c0] mmco: unref short failure

 75%|███████▌  | 166/221 [01:04<00:14,  3.92it/s][A
 76%|███████▌  | 167/221 [01:04<00:12,  4.27it/s][A
 76%|███████▌  | 168/221 [01:05<00:27,  1.93it/s][A
 76%|███████▋  | 169/221 [01:05<00:22,  2.32it/s][A
 77%|███████▋  | 170/221 [01:06<00:22,  2.25it/s][A
 77%|███████▋  | 171/221 [01:06<00:20,  2.50it/s][A
 78%|███████▊  | 172/221 [01:06<00:17,  2.78it/s][A
 78%|███████▊  | 173/221 [01:06<00:14,  3.40it/s][A
 79%|███████▉  | 175/221 [01:07<00:11,  4.10it/s][A
 80%|███████▉  | 176/221 [01:07<00:10,  4.19it/s][A
 80%|████████  | 177/221 [01:07<00:08,  4.92it/s][A
 81%|████████  | 178/221 [01:07<00:09,  4.34it/s][A
 81%|████████  | 179/221 [01:08<00:12,  3.47it/s][A
 82%|████████▏ | 181/221 [01:08<00:09,  4.38it/s][A
 82%|████████▏ | 182/221 [01:08<00:08,  4.78it/s][A
 83%|████████▎ | 183/221 [01:09<00:07,  4.76it/s][A
 83%|████████▎ | 184/221 [01:09<00:09,  4.10it/s][A
 84%|████████▎ | 185/221 [01:09<00:08,  4.29it/s][A
 84%|████████▍ | 186/221 [01:10<00:10,  3.38it/s][A
 85%|████████▍ | 187/221 [01:10<00:09,  3.76it/s][A[h264 @ 0x55a31df6fd40] mmco: unref short failure

 85%|████████▌ | 188/221 [01:10<00:09,  3.56it/s][A
 86%|████████▌ | 189/221 [01:10<00:08,  3.81it/s][A
 86%|████████▌ | 190/221 [01:11<00:08,  3.71it/s][A
 87%|████████▋ | 192/221 [01:11<00:06,  4.82it/s][A
 87%|████████▋ | 193/221 [01:11<00:05,  5.00it/s][A
 88%|████████▊ | 194/221 [01:12<00:10,  2.60it/s][A
 88%|████████▊ | 195/221 [01:12<00:08,  3.21it/s][A
 89%|████████▉ | 197/221 [01:12<00:05,  4.51it/s][A
 90%|████████▉ | 198/221 [01:13<00:06,  3.76it/s][A
 90%|█████████ | 199/221 [01:13<00:05,  4.24it/s][A
 90%|█████████ | 200/221 [01:13<00:05,  4.02it/s][A
 91%|█████████ | 201/221 [01:13<00:04,  4.04it/s][A[h264 @ 0x55e245836680] mmco: unref short failure
[h264 @ 0x55e245836680] mmco: unref short failure

 91%|█████████▏| 202/221 [01:14<00:04,  3.89it/s][A
 92%|█████████▏| 203/221 [01:14<00:03,  4.65it/s][A
 92%|█████████▏| 204/221 [01:14<00:03,  5.01it/s][A
 93%|█████████▎| 205/221 [01:14<00:03,  5.15it/s][A
 93%|█████████▎| 206/221 [01:15<00:04,  3.25it/s][A
 94%|█████████▍| 208/221 [01:15<00:02,  4.68it/s][A
 95%|█████████▌| 210/221 [01:15<00:01,  6.19it/s][A
 95%|█████████▌| 211/221 [01:15<00:02,  4.66it/s][A
 96%|█████████▌| 212/221 [01:16<00:01,  4.79it/s][A
 96%|█████████▋| 213/221 [01:16<00:01,  5.50it/s][A[h264 @ 0x560760922a00] mmco: unref short failure
[h264 @ 0x560760922a00] mmco: unref short failure
[h264 @ 0x560760922a00] mmco: unref short failure
[h264 @ 0x560760922a00] mmco: unref short failure
[h264 @ 0x560756a29640] mmco: unref short failure

 97%|█████████▋| 214/221 [01:16<00:01,  4.09it/s][A
 97%|█████████▋| 215/221 [01:16<00:01,  4.01it/s][A
 98%|█████████▊| 216/221 [01:17<00:01,  3.94it/s][A
 98%|█████████▊| 217/221 [01:17<00:01,  2.97it/s][A
 99%|█████████▊| 218/221 [01:18<00:01,  2.99it/s][A
 99%|█████████▉| 219/221 [01:18<00:00,  3.26it/s][A
100%|█████████▉| 220/221 [01:22<00:01,  1.36s/it][A
100%|██████████| 221/221 [01:22<00:00,  1.03s/it][A100%|██████████| 221/221 [01:22<00:00,  2.68it/s]
09/17/2024 03:44:37 - INFO - __main__ -   current idx Y91Zr480Tn4.67 from finetune_area returns wrong image/video, use 103848 instead.

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:05,  3.38it/s][A
  1%|          | 2/221 [00:00<01:06,  3.31it/s][A
  1%|▏         | 3/221 [00:00<01:06,  3.26it/s][A
  2%|▏         | 4/221 [00:01<01:05,  3.30it/s][A[h264 @ 0x560761160500] mmco: unref short failure

  2%|▏         | 5/221 [00:01<01:05,  3.29it/s][A
  3%|▎         | 6/221 [00:01<01:04,  3.33it/s][A
  3%|▎         | 7/221 [00:02<01:03,  3.35it/s][A
  4%|▎         | 8/221 [00:02<01:03,  3.37it/s][A
  4%|▍         | 9/221 [00:02<01:03,  3.33it/s][A
  5%|▍         | 10/221 [00:02<01:02,  3.36it/s][A
  5%|▍         | 11/221 [00:03<01:02,  3.37it/s][A
  5%|▌         | 12/221 [00:03<01:02,  3.37it/s][A
  6%|▌         | 13/221 [00:03<01:01,  3.38it/s][A
  6%|▋         | 14/221 [00:04<01:01,  3.38it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.34it/s][A
  7%|▋         | 16/221 [00:04<01:01,  3.34it/s][A
  8%|▊         | 17/221 [00:05<01:02,  3.27it/s][A
  8%|▊         | 18/221 [00:05<01:02,  3.27it/s][A
  9%|▊         | 19/221 [00:05<01:01,  3.31it/s][A
  9%|▉         | 20/221 [00:06<01:00,  3.33it/s][A
 10%|▉         | 21/221 [00:06<00:59,  3.35it/s][A
 10%|▉         | 22/221 [00:06<00:59,  3.36it/s][A
 10%|█         | 23/221 [00:06<00:59,  3.32it/s][A
 11%|█         | 24/221 [00:07<01:00,  3.24it/s][A
 11%|█▏        | 25/221 [00:07<00:59,  3.28it/s][A
 12%|█▏        | 26/221 [00:07<00:58,  3.31it/s][A
 12%|█▏        | 27/221 [00:08<00:58,  3.34it/s][A
 13%|█▎        | 28/221 [00:08<00:57,  3.36it/s][A
 13%|█▎        | 29/221 [00:08<00:56,  3.37it/s][A
 14%|█▎        | 30/221 [00:09<00:56,  3.36it/s][A
 14%|█▍        | 31/221 [00:09<00:56,  3.34it/s][A
 14%|█▍        | 32/221 [00:09<00:56,  3.33it/s][A
 15%|█▍        | 33/221 [00:09<00:58,  3.22it/s][A
 15%|█▌        | 34/221 [00:10<00:58,  3.21it/s][A[h264 @ 0x560740e7f3c0] mmco: unref short failure

 16%|█▌        | 35/221 [00:10<00:56,  3.27it/s][A
 16%|█▋        | 36/221 [00:10<00:55,  3.31it/s][A
 17%|█▋        | 37/221 [00:11<00:55,  3.31it/s][A
 17%|█▋        | 38/221 [00:11<00:55,  3.29it/s][A
 18%|█▊        | 39/221 [00:11<00:54,  3.33it/s][A
 18%|█▊        | 40/221 [00:12<00:54,  3.35it/s][A
 19%|█▊        | 41/221 [00:12<00:53,  3.36it/s][A
 19%|█▉        | 42/221 [00:12<00:53,  3.36it/s][A
 19%|█▉        | 43/221 [00:12<00:52,  3.37it/s][A
 20%|█▉        | 44/221 [00:13<00:52,  3.35it/s][A
 20%|██        | 45/221 [00:13<00:54,  3.26it/s][A
 21%|██        | 46/221 [00:13<00:53,  3.30it/s][A
 21%|██▏       | 47/221 [00:14<00:52,  3.31it/s][A
 22%|██▏       | 48/221 [00:14<00:51,  3.33it/s][A
 22%|██▏       | 49/221 [00:14<00:51,  3.35it/s][A
 23%|██▎       | 50/221 [00:15<00:51,  3.33it/s][A
 23%|██▎       | 51/221 [00:15<00:51,  3.31it/s][A
 24%|██▎       | 52/221 [00:15<00:50,  3.34it/s][A
 24%|██▍       | 53/221 [00:15<00:50,  3.36it/s][A
 24%|██▍       | 54/221 [00:16<00:49,  3.37it/s][A
 25%|██▍       | 55/221 [00:16<00:49,  3.38it/s][A
 25%|██▌       | 56/221 [00:16<00:48,  3.39it/s][A
 26%|██▌       | 57/221 [00:17<00:48,  3.39it/s][A
 26%|██▌       | 58/221 [00:17<00:47,  3.40it/s][A
 27%|██▋       | 59/221 [00:17<00:47,  3.40it/s][A
 27%|██▋       | 60/221 [00:17<00:47,  3.40it/s][A
 28%|██▊       | 61/221 [00:18<00:47,  3.40it/s][A
 28%|██▊       | 62/221 [00:18<00:46,  3.40it/s][A
 29%|██▊       | 63/221 [00:18<00:46,  3.40it/s][A
 29%|██▉       | 64/221 [00:19<00:46,  3.40it/s][A
 29%|██▉       | 65/221 [00:19<00:45,  3.41it/s][A
 30%|██▉       | 66/221 [00:19<00:45,  3.41it/s][A
 30%|███       | 67/221 [00:20<00:45,  3.41it/s][A
 31%|███       | 68/221 [00:20<00:44,  3.41it/s][A
 31%|███       | 69/221 [00:20<00:44,  3.41it/s][A
 32%|███▏      | 70/221 [00:20<00:44,  3.41it/s][A
 32%|███▏      | 71/221 [00:21<00:43,  3.41it/s][A
 33%|███▎      | 72/221 [00:21<00:43,  3.41it/s][A
 33%|███▎      | 73/221 [00:21<00:43,  3.41it/s][A
 33%|███▎      | 74/221 [00:22<00:43,  3.41it/s][A
 34%|███▍      | 75/221 [00:22<00:42,  3.41it/s][A
 34%|███▍      | 76/221 [00:22<00:42,  3.41it/s][A
 35%|███▍      | 77/221 [00:22<00:42,  3.41it/s][A
 35%|███▌      | 78/221 [00:23<00:41,  3.41it/s][A
 36%|███▌      | 79/221 [00:23<00:41,  3.41it/s][A
 36%|███▌      | 80/221 [00:23<00:41,  3.42it/s][A
 37%|███▋      | 81/221 [00:24<00:40,  3.42it/s][A
 37%|███▋      | 82/221 [00:24<00:40,  3.42it/s][A
 38%|███▊      | 83/221 [00:24<00:40,  3.42it/s][A
 38%|███▊      | 84/221 [00:25<00:40,  3.42it/s][A
 38%|███▊      | 85/221 [00:25<00:39,  3.42it/s][A
 39%|███▉      | 86/221 [00:25<00:39,  3.42it/s][A
 39%|███▉      | 87/221 [00:25<00:39,  3.42it/s][A
 40%|███▉      | 88/221 [00:26<00:38,  3.42it/s][A
 40%|████      | 89/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 90/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 91/221 [00:27<00:38,  3.42it/s][A
 42%|████▏     | 92/221 [00:27<00:37,  3.42it/s][A
 42%|████▏     | 93/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 94/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 95/221 [00:28<00:36,  3.42it/s][A
 43%|████▎     | 96/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 97/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 98/221 [00:29<00:35,  3.42it/s][A
 45%|████▍     | 99/221 [00:29<00:35,  3.42it/s][A
 45%|████▌     | 100/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 101/221 [00:30<00:35,  3.42it/s][A
 46%|████▌     | 102/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 104/221 [00:30<00:34,  3.42it/s][A
 48%|████▊     | 105/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 107/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 108/221 [00:32<00:33,  3.42it/s][A
 49%|████▉     | 109/221 [00:32<00:32,  3.42it/s][A
 50%|████▉     | 110/221 [00:32<00:32,  3.42it/s][A
 50%|█████     | 111/221 [00:32<00:32,  3.42it/s][A
 51%|█████     | 112/221 [00:33<00:31,  3.42it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 114/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:34<00:30,  3.42it/s][A
 52%|█████▏    | 116/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:34<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:35<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:35<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:37<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:38<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:39<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:39<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:40<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:41<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:41<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:44<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:45<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:45<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:46<00:18,  3.42it/s][A
 71%|███████   | 157/221 [00:46<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:47<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:48<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:48<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:49<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:49<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:49<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:50<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:51<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:51<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:52<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:54<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:55<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:56<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:57<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:57<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:58<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:03<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.42it/s][A100%|██████████| 221/221 [01:05<00:00,  3.40it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:30,  7.17it/s][A
  1%|          | 2/221 [00:00<00:43,  5.06it/s][A
  1%|▏         | 3/221 [00:00<01:06,  3.27it/s][A
  2%|▏         | 4/221 [00:00<00:51,  4.19it/s][A
  2%|▏         | 5/221 [00:01<00:51,  4.23it/s][A
  3%|▎         | 7/221 [00:01<00:44,  4.77it/s][A
  4%|▎         | 8/221 [00:01<00:53,  3.97it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.81it/s][A
  5%|▍         | 10/221 [00:02<00:46,  4.52it/s][A
  5%|▍         | 11/221 [00:02<00:53,  3.95it/s][A
  5%|▌         | 12/221 [00:02<00:51,  4.06it/s][A
  6%|▌         | 13/221 [00:03<01:32,  2.26it/s][A
  6%|▋         | 14/221 [00:03<01:15,  2.75it/s][A
  7%|▋         | 15/221 [00:04<01:14,  2.78it/s][A
  7%|▋         | 16/221 [00:04<01:19,  2.57it/s][A
  8%|▊         | 17/221 [00:05<01:24,  2.42it/s][A
  8%|▊         | 18/221 [00:05<01:14,  2.72it/s][A
  9%|▊         | 19/221 [00:05<01:00,  3.36it/s][A
  9%|▉         | 20/221 [00:05<01:01,  3.28it/s][A
 10%|▉         | 21/221 [00:06<00:51,  3.90it/s][A
 10%|▉         | 22/221 [00:06<00:46,  4.26it/s][A
 11%|█         | 24/221 [00:06<00:35,  5.58it/s][A
 11%|█▏        | 25/221 [00:07<00:51,  3.78it/s][A
 12%|█▏        | 26/221 [00:07<00:54,  3.56it/s][A
 12%|█▏        | 27/221 [00:07<00:57,  3.39it/s][A
 13%|█▎        | 28/221 [00:08<01:01,  3.13it/s][A
 13%|█▎        | 29/221 [00:08<01:06,  2.90it/s][A
 14%|█▎        | 30/221 [00:08<01:05,  2.91it/s][A
 14%|█▍        | 31/221 [00:09<01:01,  3.08it/s][A
 14%|█▍        | 32/221 [00:09<00:53,  3.51it/s][A
 15%|█▍        | 33/221 [00:09<00:52,  3.61it/s][A
 15%|█▌        | 34/221 [00:10<01:18,  2.39it/s][A
 16%|█▌        | 35/221 [00:10<01:10,  2.65it/s][A
 16%|█▋        | 36/221 [00:10<01:04,  2.89it/s][A
 17%|█▋        | 37/221 [00:11<00:57,  3.21it/s][A
 17%|█▋        | 38/221 [00:11<00:58,  3.10it/s][A
 18%|█▊        | 39/221 [00:11<00:49,  3.70it/s][A
 18%|█▊        | 40/221 [00:11<00:52,  3.48it/s][A
 19%|█▊        | 41/221 [00:12<00:48,  3.70it/s][A
 19%|█▉        | 42/221 [00:12<00:41,  4.33it/s][A
 19%|█▉        | 43/221 [00:12<00:45,  3.91it/s][A
 20%|█▉        | 44/221 [00:12<00:42,  4.14it/s][A
 20%|██        | 45/221 [00:13<00:47,  3.70it/s][A
 21%|██        | 46/221 [00:13<00:44,  3.92it/s][A
 21%|██▏       | 47/221 [00:13<00:38,  4.57it/s][A
 22%|██▏       | 49/221 [00:13<00:28,  6.07it/s][A
 23%|██▎       | 50/221 [00:14<00:34,  4.96it/s][A
 23%|██▎       | 51/221 [00:14<00:37,  4.49it/s][A
 24%|██▎       | 52/221 [00:14<00:33,  5.03it/s][A
 24%|██▍       | 53/221 [00:14<00:33,  4.96it/s][A
 24%|██▍       | 54/221 [00:14<00:34,  4.91it/s][A
 25%|██▍       | 55/221 [00:15<00:38,  4.28it/s][A
 25%|██▌       | 56/221 [00:15<00:39,  4.13it/s][A
 26%|██▌       | 57/221 [00:15<00:44,  3.67it/s][A
 26%|██▌       | 58/221 [00:16<00:44,  3.67it/s][A
 27%|██▋       | 59/221 [00:16<00:43,  3.76it/s][A
 27%|██▋       | 60/221 [00:16<00:39,  4.07it/s][A
 28%|██▊       | 61/221 [00:16<00:38,  4.13it/s][A
 28%|██▊       | 62/221 [00:17<00:40,  3.93it/s][A
 29%|██▊       | 63/221 [00:17<00:33,  4.77it/s][A
 29%|██▉       | 64/221 [00:17<00:31,  5.05it/s][A
 29%|██▉       | 65/221 [00:17<00:29,  5.33it/s][A
 30%|██▉       | 66/221 [00:17<00:38,  4.06it/s][A
 30%|███       | 67/221 [00:18<00:57,  2.69it/s][A
 31%|███       | 68/221 [00:18<00:47,  3.22it/s][A
 31%|███       | 69/221 [00:19<00:51,  2.95it/s][A
 32%|███▏      | 70/221 [00:19<00:43,  3.49it/s][A
 32%|███▏      | 71/221 [00:19<00:50,  2.94it/s][A
 33%|███▎      | 72/221 [00:20<00:56,  2.66it/s][A
 33%|███▎      | 73/221 [00:20<00:49,  2.98it/s][A
 33%|███▎      | 74/221 [00:20<00:47,  3.12it/s][A
 34%|███▍      | 75/221 [00:21<00:48,  3.03it/s][A
 34%|███▍      | 76/221 [00:21<00:38,  3.75it/s][A
 35%|███▍      | 77/221 [00:21<00:38,  3.78it/s][A
 35%|███▌      | 78/221 [00:21<00:40,  3.53it/s][A
 36%|███▌      | 79/221 [00:22<00:45,  3.15it/s][A
 36%|███▌      | 80/221 [00:22<00:43,  3.25it/s][A
 37%|███▋      | 81/221 [00:22<00:42,  3.30it/s][A
 37%|███▋      | 82/221 [00:22<00:39,  3.52it/s][A
 38%|███▊      | 83/221 [00:23<00:34,  3.96it/s][A
 38%|███▊      | 84/221 [00:23<00:45,  3.03it/s][A
 38%|███▊      | 85/221 [00:24<00:51,  2.62it/s][A
 39%|███▉      | 86/221 [00:24<00:52,  2.60it/s][A
 39%|███▉      | 87/221 [00:25<00:59,  2.26it/s][A
 40%|███▉      | 88/221 [00:25<00:50,  2.62it/s][A
 40%|████      | 89/221 [00:25<00:48,  2.70it/s][A
 41%|████      | 90/221 [00:26<00:51,  2.57it/s][A
 41%|████      | 91/221 [00:26<00:42,  3.06it/s][A
 42%|████▏     | 92/221 [00:26<00:41,  3.09it/s][A
 42%|████▏     | 93/221 [00:27<00:52,  2.44it/s][A
 43%|████▎     | 94/221 [00:27<00:43,  2.90it/s][A
 43%|████▎     | 95/221 [00:27<00:48,  2.60it/s][A
 43%|████▎     | 96/221 [00:28<00:45,  2.75it/s][A
 44%|████▍     | 97/221 [00:28<00:40,  3.04it/s][A
 44%|████▍     | 98/221 [00:28<00:38,  3.23it/s][A
 45%|████▍     | 99/221 [00:28<00:32,  3.70it/s][A
 45%|████▌     | 100/221 [00:29<00:29,  4.15it/s][A
 46%|████▌     | 101/221 [00:29<00:26,  4.52it/s][A
 46%|████▌     | 102/221 [00:29<00:30,  3.86it/s][A
 47%|████▋     | 103/221 [00:29<00:28,  4.18it/s][A
 47%|████▋     | 104/221 [00:30<00:26,  4.43it/s][A
 48%|████▊     | 105/221 [00:30<00:28,  4.10it/s][A
 48%|████▊     | 106/221 [00:30<00:35,  3.27it/s][A
 48%|████▊     | 107/221 [00:31<00:34,  3.34it/s][A
 49%|████▉     | 108/221 [00:31<00:29,  3.83it/s][A
 49%|████▉     | 109/221 [00:31<00:28,  3.96it/s][A
 50%|████▉     | 110/221 [00:31<00:29,  3.78it/s][A
 50%|█████     | 111/221 [00:32<00:32,  3.40it/s][A
 51%|█████     | 112/221 [00:32<00:33,  3.21it/s][A
 51%|█████     | 113/221 [00:32<00:30,  3.53it/s][A
 52%|█████▏    | 115/221 [00:32<00:23,  4.42it/s][A
 52%|█████▏    | 116/221 [00:33<00:22,  4.69it/s][A
 53%|█████▎    | 117/221 [00:33<00:22,  4.57it/s][A
 53%|█████▎    | 118/221 [00:33<00:29,  3.52it/s][A
 54%|█████▍    | 119/221 [00:34<00:32,  3.18it/s][A
 54%|█████▍    | 120/221 [00:34<00:31,  3.16it/s][A
 55%|█████▍    | 121/221 [00:34<00:25,  3.87it/s][A
 55%|█████▌    | 122/221 [00:34<00:24,  4.05it/s][A
 56%|█████▌    | 123/221 [00:35<00:23,  4.12it/s][A
 56%|█████▌    | 124/221 [00:35<00:26,  3.67it/s][A
 57%|█████▋    | 125/221 [00:35<00:33,  2.87it/s][A
 57%|█████▋    | 126/221 [00:36<00:28,  3.38it/s][A
 57%|█████▋    | 127/221 [00:36<00:37,  2.52it/s][A
 58%|█████▊    | 128/221 [00:37<00:32,  2.88it/s][A
 58%|█████▊    | 129/221 [00:37<00:27,  3.29it/s][A
 59%|█████▉    | 130/221 [00:37<00:30,  3.01it/s][A
 59%|█████▉    | 131/221 [00:37<00:24,  3.63it/s][A
 60%|█████▉    | 132/221 [00:38<00:24,  3.69it/s][A
 60%|██████    | 133/221 [00:38<00:36,  2.42it/s][A
 61%|██████    | 134/221 [00:39<00:37,  2.31it/s][A
 61%|██████    | 135/221 [00:39<00:29,  2.95it/s][A
 62%|██████▏   | 136/221 [00:39<00:28,  2.95it/s][A
 62%|██████▏   | 137/221 [00:39<00:25,  3.29it/s][A
 62%|██████▏   | 138/221 [00:40<00:24,  3.35it/s][A
 63%|██████▎   | 139/221 [00:40<00:25,  3.22it/s][A
 63%|██████▎   | 140/221 [00:40<00:22,  3.59it/s][A
 64%|██████▍   | 141/221 [00:41<00:25,  3.20it/s][A
 64%|██████▍   | 142/221 [00:41<00:22,  3.57it/s][A
 65%|██████▍   | 143/221 [00:41<00:24,  3.22it/s][A
 65%|██████▌   | 144/221 [00:41<00:22,  3.48it/s][A
 66%|██████▌   | 145/221 [00:42<00:22,  3.34it/s][A
 66%|██████▌   | 146/221 [00:42<00:22,  3.32it/s][A
 67%|██████▋   | 147/221 [00:42<00:20,  3.56it/s][A
 67%|██████▋   | 148/221 [00:43<00:21,  3.43it/s][A
 67%|██████▋   | 149/221 [00:43<00:18,  3.81it/s][A
 68%|██████▊   | 150/221 [00:43<00:19,  3.60it/s][A
 68%|██████▊   | 151/221 [00:44<00:26,  2.67it/s][A
 69%|██████▉   | 152/221 [00:45<00:36,  1.88it/s][A
 69%|██████▉   | 153/221 [00:45<00:29,  2.28it/s][A
 70%|██████▉   | 154/221 [00:45<00:25,  2.67it/s][A
 70%|███████   | 155/221 [00:46<00:25,  2.63it/s][A
 71%|███████   | 156/221 [00:46<00:21,  2.99it/s][A
 71%|███████   | 157/221 [00:46<00:22,  2.89it/s][A
 71%|███████▏  | 158/221 [00:46<00:22,  2.81it/s][A
 72%|███████▏  | 159/221 [00:47<00:19,  3.18it/s][A
 72%|███████▏  | 160/221 [00:47<00:16,  3.69it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.47it/s][A
 73%|███████▎  | 162/221 [00:47<00:15,  3.83it/s][A
 74%|███████▍  | 163/221 [00:48<00:14,  3.93it/s][A
 74%|███████▍  | 164/221 [00:48<00:12,  4.40it/s][A
 75%|███████▍  | 165/221 [00:48<00:11,  5.05it/s][A
 75%|███████▌  | 166/221 [00:48<00:13,  4.20it/s][A
 76%|███████▌  | 167/221 [00:48<00:11,  4.64it/s][A
 76%|███████▌  | 168/221 [00:49<00:13,  3.85it/s][A
 76%|███████▋  | 169/221 [00:49<00:11,  4.60it/s][A
 77%|███████▋  | 170/221 [00:50<00:22,  2.30it/s][A
 77%|███████▋  | 171/221 [00:50<00:22,  2.26it/s][A
 78%|███████▊  | 172/221 [00:51<00:19,  2.58it/s][A
 78%|███████▊  | 173/221 [00:51<00:17,  2.70it/s][A
 79%|███████▊  | 174/221 [00:51<00:14,  3.33it/s][A
 79%|███████▉  | 175/221 [00:51<00:15,  3.02it/s][A
 80%|███████▉  | 176/221 [00:52<00:13,  3.26it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.44it/s][A
 81%|████████  | 178/221 [00:53<00:17,  2.51it/s][A
 81%|████████  | 179/221 [00:53<00:15,  2.70it/s][A
 81%|████████▏ | 180/221 [00:53<00:12,  3.29it/s][A
 82%|████████▏ | 181/221 [00:53<00:12,  3.08it/s][A
 82%|████████▏ | 182/221 [00:54<00:11,  3.30it/s][A
 83%|████████▎ | 183/221 [00:54<00:11,  3.25it/s][A
 83%|████████▎ | 184/221 [00:54<00:11,  3.21it/s][A
 84%|████████▍ | 186/221 [00:55<00:11,  3.01it/s][A
 85%|████████▍ | 187/221 [00:55<00:11,  3.07it/s][A
 85%|████████▌ | 188/221 [00:56<00:11,  2.96it/s][A
 86%|████████▌ | 189/221 [00:56<00:09,  3.36it/s][A
 86%|████████▌ | 190/221 [00:56<00:10,  3.07it/s][A
 87%|████████▋ | 192/221 [00:57<00:07,  3.94it/s][A
 87%|████████▋ | 193/221 [00:57<00:06,  4.37it/s][A
 88%|████████▊ | 194/221 [00:57<00:06,  4.02it/s][A
 88%|████████▊ | 195/221 [00:57<00:06,  4.11it/s][A
 89%|████████▊ | 196/221 [00:58<00:09,  2.68it/s][A
 89%|████████▉ | 197/221 [00:58<00:09,  2.60it/s][A
 90%|████████▉ | 198/221 [00:59<00:10,  2.25it/s][A
 90%|█████████ | 199/221 [00:59<00:07,  2.76it/s][A
 90%|█████████ | 200/221 [00:59<00:06,  3.02it/s][A
 91%|█████████ | 201/221 [01:00<00:05,  3.39it/s][A
 91%|█████████▏| 202/221 [01:00<00:05,  3.21it/s][A
 92%|█████████▏| 203/221 [01:00<00:05,  3.45it/s][A
 92%|█████████▏| 204/221 [01:01<00:05,  3.34it/s][A
 93%|█████████▎| 205/221 [01:01<00:04,  3.50it/s][A
 93%|█████████▎| 206/221 [01:01<00:05,  2.91it/s][A
 94%|█████████▎| 207/221 [01:02<00:04,  3.15it/s][A
 94%|█████████▍| 208/221 [01:02<00:03,  3.81it/s][A
 95%|█████████▍| 209/221 [01:02<00:03,  3.75it/s][A
 95%|█████████▌| 210/221 [01:02<00:02,  3.68it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.91it/s][A
 96%|█████████▌| 212/221 [01:03<00:02,  3.65it/s][A
 96%|█████████▋| 213/221 [01:03<00:02,  3.29it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.25it/s][A
 97%|█████████▋| 215/221 [01:04<00:01,  3.23it/s][A
 98%|█████████▊| 216/221 [01:04<00:01,  3.10it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.07it/s][A
 99%|█████████▊| 218/221 [01:05<00:01,  2.81it/s][A
 99%|█████████▉| 219/221 [01:05<00:00,  2.78it/s][A
100%|█████████▉| 220/221 [01:05<00:00,  3.22it/s][A
100%|██████████| 221/221 [01:06<00:00,  2.76it/s][A100%|██████████| 221/221 [01:06<00:00,  3.33it/s]
09/17/2024 03:46:52 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 699--===========

09/17/2024 03:46:52 - INFO - __main__ -   {'area_r1': 39.5, 'area_recall': '39.5/64.8/75.1', 'area_ravg': 59.8}
09/17/2024 03:46:52 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 699--===========

09/17/2024 03:46:52 - INFO - __main__ -   {'forward_r1': 37.3, 'forward_recall': '37.3/66.5/77.1', 'forward_ravg': 60.3}
09/17/2024 03:46:52 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 699--===========

09/17/2024 03:46:52 - INFO - __main__ -   {'area_video_r1': 38.9, 'area_video_recall': '38.9/67.9/77.6', 'area_video_ravg': 61.5}
09/17/2024 03:46:52 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 299=======

09/17/2024 03:46:52 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 03:46:52 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 699--===========

09/17/2024 03:46:52 - INFO - __main__ -   {'area_video_r1': 52.7, 'area_video_recall': '52.7/75.1/83.5', 'area_video_ravg': 70.4, 'area_video_back_r1': 48.0, 'area_video_back_recall': '48.0/74.8/81.0', 'area_video_back_ravg': 67.9}
09/17/2024 03:46:52 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 549=======

09/17/2024 03:46:52 - INFO - __main__ -   {'area_video_r1': 54.1, 'area_video_recall': '54.1/75.5/82.4', 'area_video_ravg': 70.6, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.5/82.1', 'area_video_back_ravg': 68.7}
09/17/2024 03:46:52 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 699--===========

09/17/2024 03:46:52 - INFO - __main__ -   {'video_r1': 36.0, 'video_recall': '36.0/63.8/74.3', 'video_ravg': 58.0}
09/17/2024 03:46:52 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 249=======

09/17/2024 03:46:52 - INFO - __main__ -   {'video_r1': 37.1, 'video_recall': '37.1/65.0/74.1', 'video_ravg': 58.7}
09/17/2024 03:46:52 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 699--===========

09/17/2024 03:46:52 - INFO - __main__ -   {'video_r1': 53.2, 'video_recall': '53.2/75.1/82.9', 'video_ravg': 70.4}
09/17/2024 03:46:52 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 549=======

09/17/2024 03:46:52 - INFO - __main__ -   {'video_r1': 54.5, 'video_recall': '54.5/76.1/83.4', 'video_ravg': 71.3}
09/17/2024 03:47:14 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.009767713025212288, 'loss_ret%tv%ta--finetune_area/loss_area': 1.133012294769287, 'loss_ret%tv%ta--finetune_area/total_loss': 1.142780065536499}
 24%|██▍       | 700/2910 [4:25:30<83:03:20, 135.29s/it][h264 @ 0x560753f4ca80] mmco: unref short failure
 24%|██▍       | 701/2910 [4:25:34<58:46:44, 95.79s/it] [h264 @ 0x55b5afbfef80] mmco: unref short failure
 24%|██▍       | 702/2910 [4:25:38<41:51:28, 68.25s/it] 24%|██▍       | 703/2910 [4:25:42<30:03:31, 49.03s/it] 24%|██▍       | 704/2910 [4:25:47<21:53:11, 35.72s/it] 24%|██▍       | 705/2910 [4:25:51<16:07:36, 26.33s/it][h264 @ 0x55b5b3343e00] mmco: unref short failure
[h264 @ 0x55b5b3343e00] mmco: unref short failure
[h264 @ 0x55a32e9fe980] mmco: unref short failure
 24%|██▍       | 706/2910 [4:25:56<12:11:30, 19.91s/it][h264 @ 0x55b5c01c8f00] mmco: unref short failure
[h264 @ 0x55b5c01c8f00] mmco: unref short failure
 24%|██▍       | 707/2910 [4:26:02<9:34:10, 15.64s/it] [h264 @ 0x55b5b06c26c0] mmco: unref short failure
 24%|██▍       | 708/2910 [4:26:08<7:48:32, 12.77s/it][h264 @ 0x55a318399900] mmco: unref short failure
[h264 @ 0x55a318399900] mmco: unref short failure
[h264 @ 0x55e244a6e500] mmco: unref short failure
 24%|██▍       | 709/2910 [4:26:14<6:31:00, 10.66s/it][h264 @ 0x55a3112699c0] mmco: unref short failure
[h264 @ 0x55a3112699c0] mmco: unref short failure
[h264 @ 0x55e252712d00] mmco: unref short failure
[h264 @ 0x55e252712d00] mmco: unref short failure
 24%|██▍       | 710/2910 [4:26:21<5:52:39,  9.62s/it] 24%|██▍       | 711/2910 [4:26:26<5:03:42,  8.29s/it] 24%|██▍       | 712/2910 [4:26:31<4:28:52,  7.34s/it][h264 @ 0x5607597e2f40] mmco: unref short failure
[h264 @ 0x5607597e2f40] mmco: unref short failure
[h264 @ 0x55a32df858c0] mmco: unref short failure
[h264 @ 0x55a32df858c0] mmco: unref short failure
[h264 @ 0x55e2540a5540] mmco: unref short failure
[h264 @ 0x55e2540a5540] mmco: unref short failure
[h264 @ 0x55e2540a5540] mmco: unref short failure
[h264 @ 0x55b5aca46f80] mmco: unref short failure
 25%|██▍       | 713/2910 [4:26:37<4:10:29,  6.84s/it][h264 @ 0x55b5ce76d400] mmco: unref short failure
 25%|██▍       | 714/2910 [4:26:42<3:54:45,  6.41s/it][h264 @ 0x560749ccc340] mmco: unref short failure
 25%|██▍       | 715/2910 [4:26:48<3:50:14,  6.29s/it][h264 @ 0x55a31e80e500] mmco: unref short failure
[h264 @ 0x55a31e80e500] mmco: unref short failure
[h264 @ 0x55b5c8bb5980] mmco: unref short failure
[h264 @ 0x55b5c8bb5980] mmco: unref short failure
[h264 @ 0x55e24872ddc0] mmco: unref short failure
[h264 @ 0x55e24872ddc0] mmco: unref short failure
[h264 @ 0x55e24872ddc0] mmco: unref short failure
[h264 @ 0x55e24872ddc0] mmco: unref short failure
[h264 @ 0x55a31a390180] mmco: unref short failure
[h264 @ 0x55a31a390180] mmco: unref short failure
[h264 @ 0x55a31a390180] mmco: unref short failure
[h264 @ 0x55a32f466180] mmco: unref short failure
[h264 @ 0x55a323488540] mmco: unref short failure
 25%|██▍       | 716/2910 [4:27:26<9:39:25, 15.85s/it][h264 @ 0x55b5aca42e00] mmco: unref short failure
[h264 @ 0x55b5aca42e00] mmco: unref short failure
[h264 @ 0x55a334fbfa00] mmco: unref short failure
[h264 @ 0x55b5b7deef40] mmco: unref short failure
[h264 @ 0x55b5b7deef40] mmco: unref short failure
 25%|██▍       | 717/2910 [4:27:50<11:00:47, 18.08s/it][h264 @ 0x55e23e2ff9c0] mmco: unref short failure
[h264 @ 0x55a32a9e1c40] mmco: unref short failure
[h264 @ 0x55b5bacbf480] mmco: unref short failure
[h264 @ 0x55b5bacbf480] mmco: unref short failure
 25%|██▍       | 718/2910 [4:28:01<9:41:33, 15.92s/it] [h264 @ 0x560751673c40] mmco: unref short failure
[h264 @ 0x560751673c40] mmco: unref short failure
[h264 @ 0x55b5ad34cf40] mmco: unref short failure
 25%|██▍       | 719/2910 [4:28:13<8:58:51, 14.76s/it][h264 @ 0x55e242f75ac0] mmco: unref short failure
[h264 @ 0x55e242f75ac0] mmco: unref short failure
[h264 @ 0x55e241b2e640] mmco: unref short failure
[h264 @ 0x55e241b2e640] mmco: unref short failure
 25%|██▍       | 720/2910 [4:28:22<7:55:35, 13.03s/it][h264 @ 0x55a310047fc0] mmco: unref short failure
[h264 @ 0x55a310047fc0] mmco: unref short failure
[h264 @ 0x5607626cb540] mmco: unref short failure
 25%|██▍       | 721/2910 [4:28:27<6:33:43, 10.79s/it][h264 @ 0x55b5c9bc7180] mmco: unref short failure
[h264 @ 0x55b5c9bc7180] mmco: unref short failure
[h264 @ 0x55b5c9bc7180] mmco: unref short failure
[h264 @ 0x55b5c9bc7180] mmco: unref short failure
[h264 @ 0x55e257166180] mmco: unref short failure
[h264 @ 0x55e257166180] mmco: unref short failure
[h264 @ 0x55b5c5c78900] mmco: unref short failure
[h264 @ 0x55b5c5c78900] mmco: unref short failure
[h264 @ 0x55a3234df900] mmco: unref short failure
[h264 @ 0x55a3234df900] mmco: unref short failure
 25%|██▍       | 722/2910 [4:28:41<7:09:22, 11.77s/it] 25%|██▍       | 723/2910 [4:28:46<5:56:37,  9.78s/it][h264 @ 0x56075a1ac440] mmco: unref short failure
[h264 @ 0x560746c94200] mmco: unref short failure
[h264 @ 0x560746c94200] mmco: unref short failure
[h264 @ 0x55e24f20dd40] mmco: unref short failure
[h264 @ 0x560762ca3100] mmco: unref short failure
[h264 @ 0x55b5c5d78380] mmco: unref short failure
[h264 @ 0x55b5c5d78380] mmco: unref short failure
[h264 @ 0x55e244bfe580] mmco: unref short failure
[h264 @ 0x55e24c754f80] mmco: unref short failure
[h264 @ 0x55e24c754f80] mmco: unref short failure
[h264 @ 0x55e242f75d00] mmco: unref short failure
[h264 @ 0x55e242f75d00] mmco: unref short failure
[h264 @ 0x55e23fd51580] mmco: unref short failure
[h264 @ 0x55e23fd51580] mmco: unref short failure
[h264 @ 0x55e23fd51580] mmco: unref short failure
[h264 @ 0x55e23fd51580] mmco: unref short failure
[h264 @ 0x55b5cbb7e1c0] mmco: unref short failure
[h264 @ 0x55b5cbb7e1c0] mmco: unref short failure
 25%|██▍       | 724/2910 [4:29:53<16:20:32, 26.91s/it][h264 @ 0x56075d939f80] mmco: unref short failure
[h264 @ 0x56075d939f80] mmco: unref short failure
09/17/2024 03:51:45 - INFO - __main__ -   current idx OtwONFkH6Us.36 from finetune_area returns wrong image/video, use 112849 instead.
 25%|██▍       | 725/2910 [4:30:17<15:42:04, 25.87s/it][h264 @ 0x5607447d2bc0] mmco: unref short failure
[h264 @ 0x5607447d2bc0] mmco: unref short failure
 25%|██▍       | 726/2910 [4:30:30<13:20:31, 21.99s/it][h264 @ 0x55b5a9e08540] mmco: unref short failure
[h264 @ 0x55b5a9e08540] mmco: unref short failure
[h264 @ 0x55b5c2ae8100] mmco: unref short failure
 25%|██▍       | 727/2910 [4:30:38<10:54:18, 17.98s/it] 25%|██▌       | 728/2910 [4:30:46<9:01:18, 14.88s/it] [h264 @ 0x55e258268500] mmco: unref short failure
[h264 @ 0x55e258268500] mmco: unref short failure
 25%|██▌       | 729/2910 [4:30:54<7:44:51, 12.79s/it][h264 @ 0x55e24e29a0c0] mmco: unref short failure
[h264 @ 0x55a32c47ee00] mmco: unref short failure
 25%|██▌       | 730/2910 [4:31:13<8:57:07, 14.78s/it][h264 @ 0x55a319c16780] mmco: unref short failure
 25%|██▌       | 731/2910 [4:31:19<7:11:58, 11.89s/it][h264 @ 0x560741bdf8c0] mmco: unref short failure
09/17/2024 03:53:16 - INFO - __main__ -   current idx BcbIxaIlq2k.29 from finetune_area returns wrong image/video, use 19799 instead.
[h264 @ 0x55b5bc2beb00] mmco: unref short failure
[h264 @ 0x560754c373c0] mmco: unref short failure
[h264 @ 0x55b5c4abb180] mmco: unref short failure
[h264 @ 0x55b5c4abb180] mmco: unref short failure
[h264 @ 0x55b5b8b7b4c0] mmco: unref short failure
[h264 @ 0x55b5b8b7b4c0] mmco: unref short failure
[h264 @ 0x55b5b8b7b4c0] mmco: unref short failure
[h264 @ 0x55b5b8b7b4c0] mmco: unref short failure
[h264 @ 0x55a310048640] mmco: unref short failure
[h264 @ 0x55a310048640] mmco: unref short failure
[h264 @ 0x55a310048640] mmco: unref short failure
[h264 @ 0x55a310048640] mmco: unref short failure
 25%|██▌       | 732/2910 [4:32:22<16:35:57, 27.44s/it][h264 @ 0x55e252b7a880] mmco: unref short failure
[h264 @ 0x55e252b7a880] mmco: unref short failure
[h264 @ 0x55a331b10040] mmco: unref short failure
[h264 @ 0x55a331b10040] mmco: unref short failure
 25%|██▌       | 733/2910 [4:32:37<14:16:28, 23.61s/it][h264 @ 0x55b5cabcd500] mmco: unref short failure
[h264 @ 0x55b5cabcd500] mmco: unref short failure
[h264 @ 0x55a311861e00] mmco: unref short failure
[h264 @ 0x55a311861e00] mmco: unref short failure
[h264 @ 0x55a311861e00] mmco: unref short failure
[h264 @ 0x55a311861e00] mmco: unref short failure
[h264 @ 0x55b5b4c85c80] mmco: unref short failure
 25%|██▌       | 734/2910 [4:32:57<13:41:26, 22.65s/it][h264 @ 0x55b5c8572cc0] mmco: unref short failure
 25%|██▌       | 735/2910 [4:33:06<11:05:11, 18.35s/it][h264 @ 0x55a31074c8c0] mmco: unref short failure
 25%|██▌       | 736/2910 [4:33:11<8:42:07, 14.41s/it] [h264 @ 0x55b5ca3b3500] mmco: unref short failure
[h264 @ 0x55b5ca3b3500] mmco: unref short failure
[h264 @ 0x55b5ca3b3500] mmco: unref short failure
[h264 @ 0x55a30f1e3b80] mmco: unref short failure
[h264 @ 0x55a30f1e3b80] mmco: unref short failure
 25%|██▌       | 737/2910 [4:33:18<7:24:29, 12.27s/it][h264 @ 0x560760069380] mmco: unref short failure
[h264 @ 0x560760069380] mmco: unref short failure
[h264 @ 0x560760069380] mmco: unref short failure
[h264 @ 0x560760069380] mmco: unref short failure
[h264 @ 0x56075b1d6080] mmco: unref short failure
[h264 @ 0x56075b1d6080] mmco: unref short failure
[h264 @ 0x55b5b03a8d40] mmco: unref short failure
[h264 @ 0x55b5b03a8d40] mmco: unref short failure
 25%|██▌       | 738/2910 [4:33:44<9:50:51, 16.32s/it]09/17/2024 03:55:35 - INFO - __main__ -   current idx FajCFx8uN-s.3 from finetune_area returns wrong image/video, use 68712 instead.
 25%|██▌       | 739/2910 [4:33:50<7:58:14, 13.22s/it][h264 @ 0x56074c03fd80] mmco: unref short failure
[h264 @ 0x55b5c8dcc700] mmco: unref short failure
09/17/2024 03:55:44 - INFO - __main__ -   current idx Xkz6TCSh5Q0.11 from finetune_area returns wrong image/video, use 107601 instead.
[h264 @ 0x55a30f0aab40] mmco: unref short failure
[h264 @ 0x55a30f0aab40] mmco: unref short failure
[h264 @ 0x55a30f0aab40] mmco: unref short failure
[h264 @ 0x55a30f0aab40] mmco: unref short failure
[h264 @ 0x56074bbfae00] mmco: unref short failure
[h264 @ 0x56074bbfae00] mmco: unref short failure
[h264 @ 0x55e25028dfc0] mmco: unref short failure
[h264 @ 0x55e25028dfc0] mmco: unref short failure
[h264 @ 0x55b5b99a0900] mmco: unref short failure
[h264 @ 0x55b5b99a0900] mmco: unref short failure
[h264 @ 0x55b5c36a4c00] mmco: unref short failure
[h264 @ 0x55b5c3da7c80] mmco: unref short failure
[h264 @ 0x55b5c3da7c80] mmco: unref short failure
[h264 @ 0x560758221640] mmco: unref short failure
[h264 @ 0x55e242e32540] mmco: unref short failure
[h264 @ 0x55e242e32540] mmco: unref short failure
[h264 @ 0x55e24957acc0] mmco: unref short failure
09/17/2024 03:56:37 - INFO - __main__ -   current idx hvInlSH5o8c.6 from finetune_area returns wrong image/video, use 102652 instead.
[h264 @ 0x560761eee980] mmco: unref short failure
[h264 @ 0x560761eee980] mmco: unref short failure
 25%|██▌       | 740/2910 [4:34:53<17:01:35, 28.25s/it][h264 @ 0x55a30fb42480] mmco: unref short failure
 25%|██▌       | 741/2910 [4:35:17<16:08:55, 26.80s/it][h264 @ 0x55b5ac053280] mmco: unref short failure
[h264 @ 0x55b5ac053280] mmco: unref short failure
 25%|██▌       | 742/2910 [4:35:34<14:25:31, 23.95s/it][h264 @ 0x55e24ed250c0] mmco: unref short failure
 26%|██▌       | 743/2910 [4:35:39<11:05:03, 18.41s/it][h264 @ 0x55e23802b700] mmco: unref short failure
[h264 @ 0x55e23802b700] mmco: unref short failure
 26%|██▌       | 744/2910 [4:35:45<8:44:46, 14.54s/it] [h264 @ 0x55e240e47dc0] mmco: unref short failure
[h264 @ 0x55e240e47dc0] mmco: unref short failure
[h264 @ 0x55e240e47dc0] mmco: unref short failure
[h264 @ 0x55e240e47dc0] mmco: unref short failure
[h264 @ 0x55e240e47dc0] mmco: unref short failure
[h264 @ 0x55e240e47dc0] mmco: unref short failure
[h264 @ 0x560746ce9cc0] mmco: unref short failure
[h264 @ 0x560746ce9cc0] mmco: unref short failure
[h264 @ 0x560741a43140] mmco: unref short failure
 26%|██▌       | 745/2910 [4:36:00<8:49:03, 14.66s/it][h264 @ 0x5607498eb6c0] mmco: unref short failure
[h264 @ 0x5607423aabc0] mmco: unref short failure
 26%|██▌       | 746/2910 [4:36:20<9:47:42, 16.29s/it] 26%|██▌       | 747/2910 [4:36:26<7:56:27, 13.22s/it][h264 @ 0x56074ae2c6c0] mmco: unref short failure
[h264 @ 0x56074ae2c6c0] mmco: unref short failure
[h264 @ 0x55a30fa292c0] mmco: unref short failure
[h264 @ 0x55b5cc286780] mmco: unref short failure
[h264 @ 0x55b5cc286780] mmco: unref short failure
[h264 @ 0x5607560b8680] mmco: unref short failure
09/17/2024 03:58:47 - INFO - __main__ -   current idx RYisfAHcVJU.5 from finetune_area returns wrong image/video, use 10067 instead.
[h264 @ 0x560743ea8000] mmco: unref short failure
[h264 @ 0x560741a31e80] mmco: unref short failure
[h264 @ 0x560741a31e80] mmco: unref short failure
[h264 @ 0x560741a31e80] mmco: unref short failure
[h264 @ 0x560741a31e80] mmco: unref short failure
[h264 @ 0x560741a31e80] mmco: unref short failure
[h264 @ 0x55e2427055c0] mmco: unref short failure
[h264 @ 0x55a330a3da80] mmco: unref short failure
[h264 @ 0x55a330a3da80] mmco: unref short failure
[h264 @ 0x55e241e16080] mmco: unref short failure
 26%|██▌       | 748/2910 [4:37:26<16:17:10, 27.12s/it][h264 @ 0x56074a690180] mmco: unref short failure
[h264 @ 0x560748ccda80] mmco: unref short failure
[h264 @ 0x56074180d940] mmco: unref short failure
[h264 @ 0x56074180d940] mmco: unref short failure
[h264 @ 0x55a325dd2200] mmco: unref short failure
[h264 @ 0x55a325dd2200] mmco: unref short failure
[h264 @ 0x55e259dcc340] mmco: unref short failure
[h264 @ 0x55e259dcc340] mmco: unref short failure
 26%|██▌       | 749/2910 [4:38:02<17:58:34, 29.95s/it]09/17/2024 03:59:48 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 03:59:48 - INFO - __main__ -   start running ret%tva validation...
[h264 @ 0x56074288cc80] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e24de35240] mmco: unref short failure
[h264 @ 0x55e24de35240] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a31922a080] mmco: unref short failure
[h264 @ 0x55a3154bdd00] mmco: unref short failure
[h264 @ 0x55b5b080bf40] mmco: unref short failure
[h264 @ 0x560760c085c0] mmco: unref short failure
not have audios xrsV4ybwavc.40
[h264 @ 0x55a32e3d7180] mmco: unref short failure
[h264 @ 0x55a32e3d7180] mmco: unref short failure
[h264 @ 0x56076317d900] mmco: unref short failure
[h264 @ 0x56076317d900] mmco: unref short failure
[h264 @ 0x55b5ab776d40] mmco: unref short failure
[h264 @ 0x55b5ab776d40] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:35,  1.42it/s][A
  1%|          | 2/221 [00:01<02:16,  1.60it/s][A
  1%|▏         | 3/221 [00:01<01:35,  2.28it/s][A
  2%|▏         | 4/221 [00:01<01:07,  3.23it/s][A
  2%|▏         | 5/221 [00:01<00:52,  4.10it/s][A
  3%|▎         | 6/221 [00:01<00:42,  5.05it/s][A
  3%|▎         | 7/221 [00:02<00:47,  4.47it/s][A
  4%|▎         | 8/221 [00:02<01:13,  2.90it/s][A
  4%|▍         | 9/221 [00:02<01:05,  3.23it/s][A
  5%|▍         | 10/221 [00:03<01:06,  3.15it/s][A
  5%|▍         | 11/221 [00:03<00:53,  3.93it/s][A
  5%|▌         | 12/221 [00:03<01:13,  2.85it/s][A
  6%|▌         | 13/221 [00:04<01:04,  3.24it/s][A
  6%|▋         | 14/221 [00:05<02:29,  1.38it/s][A
  7%|▋         | 15/221 [00:06<02:00,  1.70it/s][A
  7%|▋         | 16/221 [00:06<01:50,  1.85it/s][A
  8%|▊         | 17/221 [00:06<01:30,  2.26it/s][A
  8%|▊         | 18/221 [00:07<01:18,  2.58it/s][A
  9%|▊         | 19/221 [00:07<01:02,  3.25it/s][A
  9%|▉         | 20/221 [00:07<00:54,  3.67it/s][A
 10%|▉         | 21/221 [00:07<00:48,  4.15it/s][A
 10%|▉         | 22/221 [00:07<00:46,  4.27it/s][A
 11%|█         | 24/221 [00:07<00:34,  5.79it/s][A
 11%|█▏        | 25/221 [00:08<00:40,  4.86it/s][A
 12%|█▏        | 26/221 [00:08<00:43,  4.43it/s][A
 12%|█▏        | 27/221 [00:08<00:37,  5.15it/s][A
 13%|█▎        | 28/221 [00:09<00:51,  3.77it/s][A
 13%|█▎        | 29/221 [00:09<00:42,  4.55it/s][A
 14%|█▎        | 30/221 [00:09<00:42,  4.54it/s][A
 14%|█▍        | 31/221 [00:09<00:43,  4.35it/s][A
 14%|█▍        | 32/221 [00:09<00:37,  5.00it/s][A
 15%|█▍        | 33/221 [00:10<00:43,  4.31it/s][A
 15%|█▌        | 34/221 [00:10<00:39,  4.74it/s][A
 16%|█▌        | 35/221 [00:10<00:39,  4.77it/s][A
 16%|█▋        | 36/221 [00:10<00:45,  4.09it/s][A
 17%|█▋        | 37/221 [00:11<01:17,  2.38it/s][A09/17/2024 04:02:16 - INFO - __main__ -   current idx 1HAnFYVSFkk.3 from finetune_area returns wrong image/video, use 89597 instead.

 17%|█▋        | 38/221 [00:12<01:13,  2.48it/s][A
 18%|█▊        | 39/221 [00:12<00:57,  3.19it/s][A
 18%|█▊        | 40/221 [00:12<00:56,  3.22it/s][A
 19%|█▊        | 41/221 [00:12<00:45,  3.94it/s][A
 19%|█▉        | 42/221 [00:12<00:55,  3.22it/s][A
 19%|█▉        | 43/221 [00:13<00:44,  4.02it/s][A
 20%|█▉        | 44/221 [00:13<00:36,  4.79it/s][A[h264 @ 0x560761b33380] mmco: unref short failure
[h264 @ 0x560761b33380] mmco: unref short failure

 20%|██        | 45/221 [00:14<01:45,  1.67it/s][A[h264 @ 0x560761c13980] mmco: unref short failure
[h264 @ 0x560761c13980] mmco: unref short failure
[h264 @ 0x560761c13980] mmco: unref short failure

 21%|██        | 46/221 [00:15<01:37,  1.80it/s][A
 21%|██▏       | 47/221 [00:15<01:50,  1.57it/s][A
 22%|██▏       | 49/221 [00:16<01:09,  2.46it/s][A
 23%|██▎       | 50/221 [00:16<00:58,  2.94it/s][A
 23%|██▎       | 51/221 [00:16<00:48,  3.51it/s][A
 24%|██▎       | 52/221 [00:16<00:42,  3.94it/s][A
 24%|██▍       | 53/221 [00:16<00:36,  4.65it/s][A[h264 @ 0x560742e80100] mmco: unref short failure
[h264 @ 0x560742e80100] mmco: unref short failure
[h264 @ 0x560742e80100] mmco: unref short failure
[h264 @ 0x560742e80100] mmco: unref short failure

 24%|██▍       | 54/221 [00:18<02:05,  1.33it/s][A[h264 @ 0x5607416cb900] mmco: unref short failure

 25%|██▍       | 55/221 [00:19<01:45,  1.57it/s][A
 25%|██▌       | 56/221 [00:19<01:26,  1.90it/s][A
 26%|██▌       | 57/221 [00:19<01:10,  2.32it/s][A
 27%|██▋       | 59/221 [00:20<00:49,  3.27it/s][A
 27%|██▋       | 60/221 [00:20<00:55,  2.90it/s][A
 28%|██▊       | 61/221 [00:20<00:49,  3.23it/s][A
 28%|██▊       | 62/221 [00:20<00:46,  3.44it/s][A
 29%|██▊       | 63/221 [00:21<00:45,  3.47it/s][A
 29%|██▉       | 64/221 [00:21<00:43,  3.62it/s][A
 29%|██▉       | 65/221 [00:21<00:37,  4.15it/s][A
 30%|██▉       | 66/221 [00:22<00:44,  3.46it/s][A
 30%|███       | 67/221 [00:22<00:50,  3.04it/s][A
 31%|███       | 68/221 [00:22<00:42,  3.60it/s][A
 31%|███       | 69/221 [00:23<01:03,  2.40it/s][A
 32%|███▏      | 70/221 [00:23<00:51,  2.91it/s][A
 32%|███▏      | 71/221 [00:25<01:43,  1.44it/s][A
 33%|███▎      | 72/221 [00:25<01:29,  1.66it/s][A
 33%|███▎      | 73/221 [00:25<01:17,  1.90it/s][A
 33%|███▎      | 74/221 [00:25<01:02,  2.37it/s][A
 34%|███▍      | 75/221 [00:26<00:59,  2.46it/s][A
 34%|███▍      | 76/221 [00:26<00:47,  3.02it/s][A
 35%|███▍      | 77/221 [00:26<00:41,  3.47it/s][A
 35%|███▌      | 78/221 [00:26<00:42,  3.35it/s][A
 36%|███▌      | 79/221 [00:27<01:02,  2.27it/s][A
 36%|███▌      | 80/221 [00:27<00:50,  2.80it/s][A
 37%|███▋      | 81/221 [00:28<00:45,  3.08it/s][A
 37%|███▋      | 82/221 [00:28<00:37,  3.72it/s][A
 38%|███▊      | 83/221 [00:28<00:32,  4.27it/s][A
 38%|███▊      | 84/221 [00:28<00:31,  4.28it/s][A
 38%|███▊      | 85/221 [00:28<00:26,  5.13it/s][A
 39%|███▉      | 86/221 [00:29<00:30,  4.38it/s][A
 39%|███▉      | 87/221 [00:29<00:46,  2.87it/s][A
 40%|███▉      | 88/221 [00:30<00:51,  2.56it/s][A
 40%|████      | 89/221 [00:32<02:02,  1.08it/s][A
 41%|████      | 90/221 [00:32<01:37,  1.35it/s][A
 41%|████      | 91/221 [00:32<01:17,  1.68it/s][A
 42%|████▏     | 92/221 [00:33<01:02,  2.08it/s][A
 42%|████▏     | 93/221 [00:33<01:02,  2.03it/s][A
 43%|████▎     | 94/221 [00:33<00:54,  2.35it/s][A
 43%|████▎     | 95/221 [00:34<00:43,  2.93it/s][A
 43%|████▎     | 96/221 [00:34<00:43,  2.88it/s][A
 44%|████▍     | 97/221 [00:34<00:38,  3.26it/s][A
 44%|████▍     | 98/221 [00:35<00:38,  3.19it/s][A
 45%|████▍     | 99/221 [00:35<00:30,  3.95it/s][A
 45%|████▌     | 100/221 [00:35<00:29,  4.17it/s][A
 46%|████▌     | 101/221 [00:35<00:24,  4.92it/s][A
 46%|████▌     | 102/221 [00:35<00:30,  3.93it/s][A
 47%|████▋     | 103/221 [00:36<00:27,  4.32it/s][A
 47%|████▋     | 104/221 [00:36<00:22,  5.12it/s][A
 48%|████▊     | 105/221 [00:36<00:24,  4.69it/s][A[h264 @ 0x55a3162f30c0] mmco: unref short failure

 48%|████▊     | 106/221 [00:37<00:43,  2.66it/s][A
 48%|████▊     | 107/221 [00:37<00:40,  2.80it/s][A
 49%|████▉     | 108/221 [00:37<00:43,  2.61it/s][A
 49%|████▉     | 109/221 [00:38<00:42,  2.61it/s][A
 50%|████▉     | 110/221 [00:38<00:44,  2.52it/s][A
 50%|█████     | 111/221 [00:39<00:48,  2.27it/s][A[h264 @ 0x55b5aadc7bc0] mmco: unref short failure
[h264 @ 0x55b5aadc7bc0] mmco: unref short failure

 51%|█████     | 112/221 [00:39<00:46,  2.33it/s][A[h264 @ 0x55a312ec8740] mmco: unref short failure

 51%|█████     | 113/221 [00:40<00:45,  2.38it/s][A
 52%|█████▏    | 114/221 [00:40<00:34,  3.07it/s][A
 52%|█████▏    | 115/221 [00:40<00:29,  3.63it/s][A[h264 @ 0x55e257222ac0] mmco: unref short failure
[h264 @ 0x55e257222ac0] mmco: unref short failure
[h264 @ 0x55e2408f7d00] mmco: unref short failure
[h264 @ 0x55e2408f7d00] mmco: unref short failure
[h264 @ 0x55a30e96b8c0] mmco: unref short failure
[h264 @ 0x55a30e96b8c0] mmco: unref short failure
[h264 @ 0x55b5aa20ea00] mmco: unref short failure
[h264 @ 0x55b5aa20ea00] mmco: unref short failure

 52%|█████▏    | 116/221 [00:45<02:52,  1.65s/it][A
 53%|█████▎    | 117/221 [00:45<02:11,  1.27s/it][A
 53%|█████▎    | 118/221 [00:46<01:45,  1.02s/it][A
 54%|█████▍    | 119/221 [00:46<01:22,  1.24it/s][A
 54%|█████▍    | 120/221 [00:46<01:07,  1.49it/s][A
 55%|█████▍    | 121/221 [00:46<00:50,  1.98it/s][A
 55%|█████▌    | 122/221 [00:46<00:40,  2.42it/s][A
 56%|█████▌    | 123/221 [00:47<00:33,  2.91it/s][A
 56%|█████▌    | 124/221 [00:47<00:29,  3.34it/s][A
 57%|█████▋    | 125/221 [00:47<00:29,  3.24it/s][A
 57%|█████▋    | 126/221 [00:48<00:31,  3.03it/s][A
 57%|█████▋    | 127/221 [00:48<00:38,  2.44it/s][A
 58%|█████▊    | 128/221 [00:49<00:36,  2.53it/s][A
 58%|█████▊    | 129/221 [00:49<00:32,  2.86it/s][A
 59%|█████▉    | 130/221 [00:49<00:28,  3.18it/s][A
 59%|█████▉    | 131/221 [00:49<00:24,  3.68it/s][A[h264 @ 0x55e241eebf00] mmco: unref short failure
[h264 @ 0x55e241eebf00] mmco: unref short failure

 60%|█████▉    | 132/221 [00:49<00:22,  4.02it/s][A
 60%|██████    | 133/221 [00:50<00:26,  3.36it/s][A
 61%|██████    | 134/221 [00:50<00:23,  3.75it/s][A
 61%|██████    | 135/221 [00:50<00:24,  3.49it/s][A
 62%|██████▏   | 136/221 [00:51<00:28,  2.96it/s][A
 62%|██████▏   | 137/221 [00:51<00:25,  3.30it/s][A
 62%|██████▏   | 138/221 [00:51<00:27,  3.00it/s][A
 63%|██████▎   | 139/221 [00:52<00:31,  2.61it/s][A
 63%|██████▎   | 140/221 [00:52<00:29,  2.74it/s][A
 64%|██████▍   | 141/221 [00:52<00:25,  3.13it/s][A
 64%|██████▍   | 142/221 [00:53<00:25,  3.07it/s][A
 65%|██████▍   | 143/221 [00:53<00:32,  2.40it/s][A
 65%|██████▌   | 144/221 [00:54<00:28,  2.73it/s][A
 66%|██████▌   | 145/221 [00:54<00:24,  3.16it/s][A
 66%|██████▌   | 146/221 [00:54<00:21,  3.51it/s][A
 67%|██████▋   | 147/221 [00:54<00:21,  3.40it/s][A
 67%|██████▋   | 148/221 [00:55<00:22,  3.27it/s][A
 67%|██████▋   | 149/221 [00:55<00:19,  3.78it/s][A
 68%|██████▊   | 150/221 [00:55<00:18,  3.84it/s][A
 68%|██████▊   | 151/221 [00:56<00:32,  2.16it/s][A
 69%|██████▉   | 152/221 [00:57<00:32,  2.12it/s][A
 69%|██████▉   | 153/221 [00:57<00:28,  2.38it/s][A
 70%|██████▉   | 154/221 [00:57<00:27,  2.43it/s][A
 70%|███████   | 155/221 [00:57<00:22,  3.00it/s][A
 71%|███████   | 156/221 [00:58<00:19,  3.33it/s][A[h264 @ 0x55e23e2447c0] mmco: unref short failure

 71%|███████   | 157/221 [01:00<00:57,  1.11it/s][A
 71%|███████▏  | 158/221 [01:00<00:45,  1.38it/s][A[h264 @ 0x55b5b6c27180] mmco: unref short failure

 72%|███████▏  | 159/221 [01:00<00:35,  1.76it/s][A
 72%|███████▏  | 160/221 [01:01<00:27,  2.22it/s][A
 73%|███████▎  | 162/221 [01:01<00:17,  3.46it/s][A
 74%|███████▍  | 163/221 [01:01<00:16,  3.54it/s][A
 74%|███████▍  | 164/221 [01:01<00:14,  4.02it/s][A
 75%|███████▍  | 165/221 [01:01<00:11,  4.72it/s][A[h264 @ 0x5607429316c0] mmco: unref short failure
09/17/2024 04:03:06 - INFO - __main__ -   current idx h0KWf1ksq5Y.21 from finetune_area returns wrong image/video, use 50171 instead.

 75%|███████▌  | 166/221 [01:02<00:14,  3.73it/s][A
 76%|███████▌  | 167/221 [01:02<00:14,  3.72it/s][A
 76%|███████▌  | 168/221 [01:03<00:30,  1.74it/s][A
 76%|███████▋  | 169/221 [01:04<00:25,  2.06it/s][A
 77%|███████▋  | 170/221 [01:04<00:22,  2.25it/s][A
 77%|███████▋  | 171/221 [01:04<00:20,  2.48it/s][A
 78%|███████▊  | 172/221 [01:05<00:18,  2.70it/s][A
 78%|███████▊  | 173/221 [01:05<00:14,  3.21it/s][A
 79%|███████▉  | 175/221 [01:05<00:11,  4.01it/s][A
 80%|███████▉  | 176/221 [01:05<00:11,  3.95it/s][A
 81%|████████  | 178/221 [01:06<00:10,  4.08it/s][A
 81%|████████  | 179/221 [01:06<00:13,  3.09it/s][A
 81%|████████▏ | 180/221 [01:07<00:11,  3.69it/s][A
 82%|████████▏ | 181/221 [01:07<00:10,  3.80it/s][A
 82%|████████▏ | 182/221 [01:07<00:09,  4.19it/s][A
 83%|████████▎ | 183/221 [01:07<00:09,  4.18it/s][A
 83%|████████▎ | 184/221 [01:08<00:10,  3.44it/s][A
 84%|████████▎ | 185/221 [01:08<00:09,  3.79it/s][A
 84%|████████▍ | 186/221 [01:08<00:10,  3.47it/s][A
 85%|████████▍ | 187/221 [01:08<00:08,  4.01it/s][A
 85%|████████▌ | 188/221 [01:09<00:08,  3.87it/s][A
 86%|████████▌ | 189/221 [01:09<00:08,  3.97it/s][A
 86%|████████▌ | 190/221 [01:09<00:08,  3.72it/s][A
 86%|████████▋ | 191/221 [01:09<00:06,  4.55it/s][A
 87%|████████▋ | 192/221 [01:09<00:06,  4.58it/s][A[h264 @ 0x55a3142d7f00] mmco: unref short failure

 88%|████████▊ | 194/221 [01:10<00:09,  2.92it/s][A
 88%|████████▊ | 195/221 [01:11<00:07,  3.51it/s][A
 89%|████████▊ | 196/221 [01:11<00:06,  4.04it/s][A
 90%|████████▉ | 198/221 [01:11<00:05,  4.19it/s][A
 90%|█████████ | 199/221 [01:11<00:04,  4.46it/s][A
 90%|█████████ | 200/221 [01:12<00:05,  3.91it/s][A
 91%|█████████ | 201/221 [01:12<00:04,  4.05it/s][A
 91%|█████████▏| 202/221 [01:12<00:04,  4.21it/s][A
 92%|█████████▏| 203/221 [01:12<00:03,  4.66it/s][A
 92%|█████████▏| 204/221 [01:12<00:03,  5.01it/s][A
 93%|█████████▎| 205/221 [01:13<00:02,  5.67it/s][A
 93%|█████████▎| 206/221 [01:13<00:04,  3.49it/s][A
 94%|█████████▍| 208/221 [01:13<00:02,  4.59it/s][A
 95%|█████████▌| 210/221 [01:13<00:01,  6.32it/s][A
 95%|█████████▌| 211/221 [01:14<00:02,  4.37it/s][A
 96%|█████████▌| 212/221 [01:14<00:01,  4.79it/s][A
 97%|█████████▋| 214/221 [01:15<00:01,  4.49it/s][A
 97%|█████████▋| 215/221 [01:15<00:01,  4.18it/s][A
 98%|█████████▊| 216/221 [01:15<00:01,  3.98it/s][A
 98%|█████████▊| 217/221 [01:16<00:01,  3.08it/s][A
 99%|█████████▊| 218/221 [01:16<00:00,  3.44it/s][A
 99%|█████████▉| 219/221 [01:16<00:00,  3.78it/s][A[h264 @ 0x55e23897ca80] mmco: unref short failure
[h264 @ 0x55e236a1ce80] mmco: unref short failure

100%|█████████▉| 220/221 [01:20<00:01,  1.41s/it][A
100%|██████████| 221/221 [01:21<00:00,  1.06s/it][A100%|██████████| 221/221 [01:21<00:00,  2.72it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:04,  3.41it/s][A
  1%|          | 2/221 [00:00<01:04,  3.41it/s][A
  1%|▏         | 3/221 [00:00<01:04,  3.40it/s][A
  2%|▏         | 4/221 [00:01<01:03,  3.39it/s][A
  2%|▏         | 5/221 [00:01<01:03,  3.38it/s][A
  3%|▎         | 6/221 [00:01<01:03,  3.37it/s][A
  3%|▎         | 7/221 [00:02<01:03,  3.34it/s][A
  4%|▎         | 8/221 [00:02<01:03,  3.36it/s][A
  4%|▍         | 9/221 [00:02<01:02,  3.37it/s][A
  5%|▍         | 10/221 [00:02<01:02,  3.38it/s][A
  5%|▍         | 11/221 [00:03<01:02,  3.36it/s][A
  5%|▌         | 12/221 [00:03<01:01,  3.37it/s][A[h264 @ 0x55b5ba3c0500] mmco: unref short failure
[h264 @ 0x55b5ba3c0500] mmco: unref short failure

  6%|▌         | 13/221 [00:03<01:02,  3.34it/s][A
  6%|▋         | 14/221 [00:04<01:01,  3.36it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.37it/s][A
  7%|▋         | 16/221 [00:04<01:02,  3.31it/s][A
  8%|▊         | 17/221 [00:05<01:01,  3.29it/s][A
  8%|▊         | 18/221 [00:05<01:01,  3.31it/s][A
  9%|▊         | 19/221 [00:05<01:00,  3.34it/s][A
  9%|▉         | 20/221 [00:05<01:00,  3.34it/s][A
 10%|▉         | 21/221 [00:06<00:59,  3.36it/s][A
 10%|▉         | 22/221 [00:06<00:59,  3.37it/s][A
 10%|█         | 23/221 [00:06<00:58,  3.38it/s][A
 11%|█         | 24/221 [00:07<00:58,  3.38it/s][A
 11%|█▏        | 25/221 [00:07<00:57,  3.38it/s][A
 12%|█▏        | 26/221 [00:07<00:57,  3.39it/s][A
 12%|█▏        | 27/221 [00:08<00:57,  3.39it/s][A
 13%|█▎        | 28/221 [00:08<00:56,  3.39it/s][A[h264 @ 0x55b5b08051c0] mmco: unref short failure
[h264 @ 0x55b5b08051c0] mmco: unref short failure

 13%|█▎        | 29/221 [00:08<00:57,  3.36it/s][A
 14%|█▎        | 30/221 [00:08<00:56,  3.38it/s][A
 14%|█▍        | 31/221 [00:09<00:56,  3.38it/s][A
 14%|█▍        | 32/221 [00:09<00:56,  3.37it/s][A
 15%|█▍        | 33/221 [00:09<00:55,  3.38it/s][A
 15%|█▌        | 34/221 [00:10<00:55,  3.39it/s][A[h264 @ 0x56075ed933c0] mmco: unref short failure

 16%|█▌        | 35/221 [00:10<00:54,  3.39it/s][A
 16%|█▋        | 36/221 [00:10<00:54,  3.39it/s][A
 17%|█▋        | 37/221 [00:10<00:54,  3.40it/s][A
 17%|█▋        | 38/221 [00:11<00:54,  3.37it/s][A
 18%|█▊        | 39/221 [00:11<00:54,  3.37it/s][A
 18%|█▊        | 40/221 [00:11<00:53,  3.38it/s][A
 19%|█▊        | 41/221 [00:12<00:53,  3.39it/s][A
 19%|█▉        | 42/221 [00:12<00:52,  3.38it/s][A
 19%|█▉        | 43/221 [00:12<00:52,  3.39it/s][A
 20%|█▉        | 44/221 [00:13<00:52,  3.39it/s][A
 20%|██        | 45/221 [00:13<00:51,  3.40it/s][A
 21%|██        | 46/221 [00:13<00:51,  3.40it/s][A
 21%|██▏       | 47/221 [00:13<00:51,  3.40it/s][A
 22%|██▏       | 48/221 [00:14<00:50,  3.40it/s][A
 22%|██▏       | 49/221 [00:14<00:50,  3.40it/s][A
 23%|██▎       | 50/221 [00:14<00:50,  3.40it/s][A
 23%|██▎       | 51/221 [00:15<00:50,  3.40it/s][A
 24%|██▎       | 52/221 [00:15<00:50,  3.36it/s][A
 24%|██▍       | 53/221 [00:15<00:49,  3.37it/s][A
 24%|██▍       | 54/221 [00:16<00:49,  3.38it/s][A
 25%|██▍       | 55/221 [00:16<00:48,  3.39it/s][A
 25%|██▌       | 56/221 [00:16<00:48,  3.39it/s][A
 26%|██▌       | 57/221 [00:16<00:48,  3.39it/s][A
 26%|██▌       | 58/221 [00:17<00:47,  3.40it/s][A
 27%|██▋       | 59/221 [00:17<00:47,  3.40it/s][A
 27%|██▋       | 60/221 [00:17<00:47,  3.40it/s][A
 28%|██▊       | 61/221 [00:18<00:47,  3.40it/s][A
 28%|██▊       | 62/221 [00:18<00:46,  3.40it/s][A
 29%|██▊       | 63/221 [00:18<00:46,  3.40it/s][A
 29%|██▉       | 64/221 [00:18<00:46,  3.40it/s][A
 29%|██▉       | 65/221 [00:19<00:45,  3.41it/s][A
 30%|██▉       | 66/221 [00:19<00:45,  3.41it/s][A
 30%|███       | 67/221 [00:19<00:45,  3.41it/s][A
 31%|███       | 68/221 [00:20<00:44,  3.41it/s][A
 31%|███       | 69/221 [00:20<00:44,  3.41it/s][A
 32%|███▏      | 70/221 [00:20<00:44,  3.41it/s][A
 32%|███▏      | 71/221 [00:20<00:43,  3.42it/s][A
 33%|███▎      | 72/221 [00:21<00:43,  3.42it/s][A
 33%|███▎      | 73/221 [00:21<00:43,  3.42it/s][A
 33%|███▎      | 74/221 [00:21<00:43,  3.42it/s][A
 34%|███▍      | 75/221 [00:22<00:42,  3.42it/s][A
 34%|███▍      | 76/221 [00:22<00:42,  3.42it/s][A
 35%|███▍      | 77/221 [00:22<00:42,  3.42it/s][A
 35%|███▌      | 78/221 [00:23<00:41,  3.42it/s][A
 36%|███▌      | 79/221 [00:23<00:41,  3.42it/s][A
 36%|███▌      | 80/221 [00:23<00:41,  3.42it/s][A
 37%|███▋      | 81/221 [00:23<00:40,  3.42it/s][A
 37%|███▋      | 82/221 [00:24<00:40,  3.42it/s][A
 38%|███▊      | 83/221 [00:24<00:40,  3.42it/s][A
 38%|███▊      | 84/221 [00:24<00:40,  3.42it/s][A
 38%|███▊      | 85/221 [00:25<00:39,  3.42it/s][A
 39%|███▉      | 86/221 [00:25<00:39,  3.42it/s][A
 39%|███▉      | 87/221 [00:25<00:39,  3.42it/s][A
 40%|███▉      | 88/221 [00:25<00:38,  3.42it/s][A
 40%|████      | 89/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 90/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 91/221 [00:26<00:38,  3.42it/s][A
 42%|████▏     | 92/221 [00:27<00:37,  3.42it/s][A
 42%|████▏     | 93/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 94/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 95/221 [00:28<00:36,  3.42it/s][A
 43%|████▎     | 96/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 97/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 98/221 [00:28<00:35,  3.42it/s][A
 45%|████▍     | 99/221 [00:29<00:35,  3.42it/s][A
 45%|████▌     | 100/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 101/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 102/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 104/221 [00:30<00:34,  3.42it/s][A
 48%|████▊     | 105/221 [00:30<00:33,  3.42it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 107/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 108/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 109/221 [00:32<00:32,  3.42it/s][A
 50%|████▉     | 110/221 [00:32<00:32,  3.42it/s][A
 50%|█████     | 111/221 [00:32<00:32,  3.42it/s][A
 51%|█████     | 112/221 [00:32<00:31,  3.42it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 114/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:33<00:30,  3.42it/s][A
 52%|█████▏    | 116/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:34<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:35<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:35<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:35<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:37<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:38<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:38<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:39<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:39<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:40<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:40<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:41<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:42<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:43<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:44<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:45<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:45<00:18,  3.42it/s][A
 71%|███████   | 157/221 [00:46<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:47<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:47<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:48<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:48<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:49<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:49<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:49<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:50<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:51<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:51<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:52<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:52<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:54<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:54<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:55<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:56<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:56<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:57<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:57<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:58<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:58<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [00:59<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:01<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:03<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:03<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:04<00:00,  3.42it/s][A100%|██████████| 221/221 [01:04<00:00,  3.41it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:31,  7.00it/s][A
  1%|          | 2/221 [00:00<00:48,  4.56it/s][A
  1%|▏         | 3/221 [00:00<01:11,  3.04it/s][A
  2%|▏         | 4/221 [00:00<00:53,  4.06it/s][A
  2%|▏         | 5/221 [00:01<00:51,  4.16it/s][A
  3%|▎         | 7/221 [00:01<00:46,  4.64it/s][A
  4%|▎         | 8/221 [00:01<00:55,  3.85it/s][A
  4%|▍         | 9/221 [00:02<00:56,  3.78it/s][A
  5%|▍         | 10/221 [00:02<00:47,  4.47it/s][A
  5%|▍         | 11/221 [00:02<00:51,  4.11it/s][A
  5%|▌         | 12/221 [00:02<00:49,  4.20it/s][A
  6%|▌         | 13/221 [00:03<01:27,  2.38it/s][A
  6%|▋         | 14/221 [00:03<01:09,  2.96it/s][A
  7%|▋         | 15/221 [00:04<01:13,  2.81it/s][A
  7%|▋         | 16/221 [00:04<01:21,  2.52it/s][A
  8%|▊         | 17/221 [00:05<01:19,  2.56it/s][A
  8%|▊         | 18/221 [00:05<01:12,  2.79it/s][A
  9%|▊         | 19/221 [00:05<00:58,  3.45it/s][A
  9%|▉         | 20/221 [00:05<00:59,  3.35it/s][A
 10%|▉         | 21/221 [00:06<00:52,  3.83it/s][A
 10%|▉         | 22/221 [00:06<00:47,  4.20it/s][A
 11%|█         | 24/221 [00:06<00:37,  5.28it/s][A
 11%|█▏        | 25/221 [00:07<00:53,  3.63it/s][A
 12%|█▏        | 26/221 [00:07<00:53,  3.63it/s][A
 12%|█▏        | 27/221 [00:07<00:56,  3.43it/s][A
 13%|█▎        | 28/221 [00:08<00:58,  3.27it/s][A
 13%|█▎        | 29/221 [00:08<00:57,  3.31it/s][A
 14%|█▎        | 30/221 [00:08<01:02,  3.08it/s][A
 14%|█▍        | 31/221 [00:09<01:01,  3.11it/s][A
 14%|█▍        | 32/221 [00:09<00:55,  3.43it/s][A
 15%|█▍        | 33/221 [00:09<00:56,  3.36it/s][A
 15%|█▌        | 34/221 [00:10<01:07,  2.77it/s][A
 16%|█▌        | 35/221 [00:10<01:02,  2.99it/s][A
 16%|█▋        | 36/221 [00:10<00:57,  3.22it/s][A
 17%|█▋        | 37/221 [00:10<00:52,  3.53it/s][A
 17%|█▋        | 38/221 [00:11<00:53,  3.41it/s][A
 18%|█▊        | 39/221 [00:11<00:45,  4.00it/s][A
 18%|█▊        | 40/221 [00:11<00:49,  3.64it/s][A
 19%|█▊        | 41/221 [00:11<00:48,  3.69it/s][A
 19%|█▉        | 42/221 [00:11<00:41,  4.30it/s][A
 19%|█▉        | 43/221 [00:12<00:46,  3.83it/s][A
 20%|█▉        | 44/221 [00:12<00:44,  3.93it/s][A
 20%|██        | 45/221 [00:12<00:50,  3.49it/s][A
 21%|██        | 46/221 [00:13<00:45,  3.89it/s][A
 21%|██▏       | 47/221 [00:13<00:38,  4.48it/s][A
 22%|██▏       | 49/221 [00:13<00:27,  6.34it/s][A
 23%|██▎       | 50/221 [00:13<00:31,  5.44it/s][A
 23%|██▎       | 51/221 [00:14<00:39,  4.34it/s][A
 24%|██▎       | 52/221 [00:14<00:34,  4.93it/s][A
 24%|██▍       | 53/221 [00:14<00:37,  4.47it/s][A
 24%|██▍       | 54/221 [00:14<00:37,  4.46it/s][A
 25%|██▍       | 55/221 [00:15<00:42,  3.89it/s][A
 25%|██▌       | 56/221 [00:15<00:41,  3.98it/s][A
 26%|██▌       | 57/221 [00:15<00:46,  3.52it/s][A
 26%|██▌       | 58/221 [00:15<00:41,  3.95it/s][A
 27%|██▋       | 59/221 [00:16<00:40,  4.02it/s][A
 27%|██▋       | 60/221 [00:16<00:39,  4.07it/s][A
 28%|██▊       | 61/221 [00:16<00:37,  4.32it/s][A
 28%|██▊       | 62/221 [00:16<00:40,  3.90it/s][A
 29%|██▊       | 63/221 [00:16<00:36,  4.38it/s][A
 29%|██▉       | 64/221 [00:17<00:34,  4.49it/s][A
 29%|██▉       | 65/221 [00:17<00:32,  4.83it/s][A
 30%|██▉       | 66/221 [00:17<00:37,  4.17it/s][A
 30%|███       | 67/221 [00:18<00:52,  2.95it/s][A
 31%|███       | 68/221 [00:18<00:46,  3.28it/s][A
 31%|███       | 69/221 [00:18<00:50,  2.99it/s][A
 32%|███▏      | 70/221 [00:19<00:44,  3.41it/s][A
 32%|███▏      | 71/221 [00:19<00:51,  2.92it/s][A
 33%|███▎      | 72/221 [00:19<00:53,  2.78it/s][A
 33%|███▎      | 73/221 [00:20<00:51,  2.89it/s][A
 33%|███▎      | 74/221 [00:20<00:47,  3.11it/s][A
 34%|███▍      | 75/221 [00:20<00:48,  3.04it/s][A
 34%|███▍      | 76/221 [00:20<00:39,  3.69it/s][A
 35%|███▍      | 77/221 [00:21<00:40,  3.53it/s][A
 35%|███▌      | 78/221 [00:21<00:47,  3.04it/s][A
 36%|███▌      | 79/221 [00:22<00:46,  3.08it/s][A
 36%|███▌      | 80/221 [00:22<00:44,  3.20it/s][A
 37%|███▋      | 81/221 [00:22<00:41,  3.39it/s][A
 37%|███▋      | 82/221 [00:22<00:39,  3.51it/s][A
 38%|███▊      | 83/221 [00:23<00:35,  3.85it/s][A
 38%|███▊      | 84/221 [00:23<00:46,  2.96it/s][A
 38%|███▊      | 85/221 [00:23<00:49,  2.74it/s][A
 39%|███▉      | 86/221 [00:24<00:52,  2.59it/s][A
 39%|███▉      | 87/221 [00:24<00:56,  2.35it/s][A
 40%|███▉      | 88/221 [00:25<00:50,  2.66it/s][A
 40%|████      | 89/221 [00:25<00:47,  2.75it/s][A
 41%|████      | 90/221 [00:25<00:51,  2.55it/s][A
 41%|████      | 91/221 [00:26<00:44,  2.89it/s][A
 42%|████▏     | 92/221 [00:26<00:42,  3.05it/s][A
 42%|████▏     | 93/221 [00:27<00:53,  2.38it/s][A
 43%|████▎     | 94/221 [00:27<00:45,  2.78it/s][A
 43%|████▎     | 95/221 [00:27<00:53,  2.38it/s][A
 43%|████▎     | 96/221 [00:28<00:47,  2.63it/s][A
 44%|████▍     | 97/221 [00:28<00:43,  2.86it/s][A
 44%|████▍     | 98/221 [00:28<00:40,  3.03it/s][A
 45%|████▍     | 99/221 [00:28<00:35,  3.43it/s][A
 45%|████▌     | 100/221 [00:29<00:30,  3.96it/s][A
 46%|████▌     | 101/221 [00:29<00:27,  4.34it/s][A
 46%|████▌     | 102/221 [00:29<00:31,  3.79it/s][A
 47%|████▋     | 103/221 [00:29<00:27,  4.24it/s][A
 47%|████▋     | 104/221 [00:30<00:26,  4.38it/s][A
 48%|████▊     | 105/221 [00:30<00:31,  3.67it/s][A
 48%|████▊     | 106/221 [00:30<00:35,  3.28it/s][A
 48%|████▊     | 107/221 [00:31<00:35,  3.19it/s][A
 49%|████▉     | 108/221 [00:31<00:30,  3.66it/s][A
 49%|████▉     | 109/221 [00:31<00:31,  3.61it/s][A
 50%|████▉     | 110/221 [00:31<00:29,  3.70it/s][A
 50%|█████     | 111/221 [00:32<00:31,  3.48it/s][A
 51%|█████     | 112/221 [00:32<00:32,  3.31it/s][A
 51%|█████     | 113/221 [00:32<00:29,  3.65it/s][A
 52%|█████▏    | 115/221 [00:33<00:23,  4.42it/s][A
 52%|█████▏    | 116/221 [00:33<00:21,  4.87it/s][A
 53%|█████▎    | 117/221 [00:33<00:22,  4.66it/s][A
 53%|█████▎    | 118/221 [00:33<00:28,  3.57it/s][A
 54%|█████▍    | 119/221 [00:34<00:32,  3.11it/s][A
 54%|█████▍    | 120/221 [00:34<00:32,  3.16it/s][A
 55%|█████▍    | 121/221 [00:34<00:26,  3.81it/s][A
 55%|█████▌    | 122/221 [00:34<00:25,  3.95it/s][A
 56%|█████▌    | 123/221 [00:35<00:27,  3.60it/s][A
 56%|█████▌    | 124/221 [00:35<00:27,  3.49it/s][A
 57%|█████▋    | 125/221 [00:36<00:33,  2.85it/s][A
 57%|█████▋    | 126/221 [00:36<00:28,  3.32it/s][A
 57%|█████▋    | 127/221 [00:36<00:37,  2.51it/s][A
 58%|█████▊    | 128/221 [00:37<00:31,  2.93it/s][A
 58%|█████▊    | 129/221 [00:37<00:27,  3.32it/s][A
 59%|█████▉    | 130/221 [00:37<00:29,  3.07it/s][A
 59%|█████▉    | 131/221 [00:37<00:24,  3.66it/s][A
 60%|█████▉    | 132/221 [00:38<00:23,  3.83it/s][A
 60%|██████    | 133/221 [00:38<00:34,  2.52it/s][A
 61%|██████    | 134/221 [00:39<00:36,  2.38it/s][A
 62%|██████▏   | 136/221 [00:39<00:27,  3.09it/s][A
 62%|██████▏   | 137/221 [00:39<00:25,  3.34it/s][A
 62%|██████▏   | 138/221 [00:40<00:23,  3.46it/s][A
 63%|██████▎   | 139/221 [00:40<00:25,  3.24it/s][A
 63%|██████▎   | 140/221 [00:40<00:22,  3.58it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.35it/s][A
 64%|██████▍   | 142/221 [00:41<00:21,  3.69it/s][A
 65%|██████▍   | 143/221 [00:41<00:23,  3.29it/s][A
 65%|██████▌   | 144/221 [00:41<00:21,  3.53it/s][A
 66%|██████▌   | 145/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:42<00:22,  3.27it/s][A
 67%|██████▋   | 147/221 [00:42<00:21,  3.52it/s][A
 67%|██████▋   | 148/221 [00:43<00:21,  3.40it/s][A
 67%|██████▋   | 149/221 [00:43<00:19,  3.64it/s][A
 68%|██████▊   | 150/221 [00:43<00:19,  3.60it/s][A
 68%|██████▊   | 151/221 [00:44<00:26,  2.65it/s][A
 69%|██████▉   | 152/221 [00:45<00:36,  1.91it/s][A
 69%|██████▉   | 153/221 [00:45<00:29,  2.33it/s][A
 70%|██████▉   | 154/221 [00:45<00:25,  2.67it/s][A
 70%|███████   | 155/221 [00:46<00:25,  2.57it/s][A
 71%|███████   | 156/221 [00:46<00:22,  2.92it/s][A
 71%|███████   | 157/221 [00:46<00:21,  2.94it/s][A
 71%|███████▏  | 158/221 [00:47<00:22,  2.74it/s][A
 72%|███████▏  | 159/221 [00:47<00:20,  3.06it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.52it/s][A
 73%|███████▎  | 161/221 [00:47<00:16,  3.69it/s][A
 73%|███████▎  | 162/221 [00:47<00:13,  4.30it/s][A
 74%|███████▍  | 163/221 [00:48<00:14,  4.09it/s][A
 74%|███████▍  | 164/221 [00:48<00:12,  4.50it/s][A
 75%|███████▍  | 165/221 [00:48<00:11,  4.89it/s][A
 75%|███████▌  | 166/221 [00:48<00:13,  4.12it/s][A
 76%|███████▌  | 167/221 [00:48<00:12,  4.30it/s][A
 76%|███████▌  | 168/221 [00:49<00:12,  4.37it/s][A
 76%|███████▋  | 169/221 [00:49<00:10,  5.11it/s][A
 77%|███████▋  | 170/221 [00:50<00:18,  2.71it/s][A
 77%|███████▋  | 171/221 [00:50<00:19,  2.55it/s][A
 78%|███████▊  | 172/221 [00:50<00:18,  2.61it/s][A
 78%|███████▊  | 173/221 [00:51<00:17,  2.73it/s][A
 79%|███████▊  | 174/221 [00:51<00:14,  3.18it/s][A
 79%|███████▉  | 175/221 [00:51<00:15,  3.01it/s][A
 80%|███████▉  | 176/221 [00:52<00:14,  3.17it/s][A
 80%|████████  | 177/221 [00:52<00:13,  3.35it/s][A
 81%|████████  | 178/221 [00:53<00:18,  2.35it/s][A
 81%|████████  | 179/221 [00:53<00:16,  2.62it/s][A
 81%|████████▏ | 180/221 [00:53<00:13,  3.13it/s][A
 82%|████████▏ | 181/221 [00:53<00:13,  2.90it/s][A
 82%|████████▏ | 182/221 [00:54<00:12,  3.09it/s][A
 83%|████████▎ | 183/221 [00:54<00:12,  3.07it/s][A
 83%|████████▎ | 184/221 [00:54<00:12,  2.89it/s][A
 84%|████████▍ | 186/221 [00:55<00:10,  3.19it/s][A
 85%|████████▍ | 187/221 [00:55<00:10,  3.24it/s][A
 85%|████████▌ | 188/221 [00:56<00:10,  3.23it/s][A
 86%|████████▌ | 189/221 [00:56<00:08,  3.63it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.27it/s][A
 86%|████████▋ | 191/221 [00:56<00:07,  4.00it/s][A
 87%|████████▋ | 192/221 [00:56<00:07,  3.96it/s][A
 87%|████████▋ | 193/221 [00:57<00:06,  4.30it/s][A
 88%|████████▊ | 194/221 [00:57<00:06,  4.09it/s][A
 88%|████████▊ | 195/221 [00:57<00:06,  4.22it/s][A
 89%|████████▊ | 196/221 [00:58<00:08,  3.04it/s][A
 89%|████████▉ | 197/221 [00:58<00:08,  2.85it/s][A
 90%|████████▉ | 198/221 [00:59<00:08,  2.63it/s][A
 90%|█████████ | 199/221 [00:59<00:07,  3.09it/s][A
 90%|█████████ | 200/221 [00:59<00:06,  3.07it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.47it/s][A
 91%|█████████▏| 202/221 [01:00<00:05,  3.27it/s][A
 92%|█████████▏| 203/221 [01:00<00:05,  3.45it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.44it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.64it/s][A
 93%|█████████▎| 206/221 [01:01<00:05,  2.98it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  3.19it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.68it/s][A
 95%|█████████▍| 209/221 [01:02<00:03,  3.72it/s][A
 95%|█████████▌| 210/221 [01:02<00:03,  3.48it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.65it/s][A
 96%|█████████▌| 212/221 [01:03<00:02,  3.06it/s][A
 96%|█████████▋| 213/221 [01:03<00:02,  3.03it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.04it/s][A
 97%|█████████▋| 215/221 [01:04<00:01,  3.05it/s][A
 98%|█████████▊| 216/221 [01:04<00:01,  3.04it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.17it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.26it/s][A
 99%|█████████▉| 219/221 [01:05<00:00,  3.14it/s][A
100%|█████████▉| 220/221 [01:05<00:00,  3.57it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.19it/s][A100%|██████████| 221/221 [01:05<00:00,  3.35it/s]
09/17/2024 04:05:47 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 749--===========

09/17/2024 04:05:47 - INFO - __main__ -   {'area_r1': 40.7, 'area_recall': '40.7/65.2/74.8', 'area_ravg': 60.2}
09/17/2024 04:05:47 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 749--===========

09/17/2024 04:05:47 - INFO - __main__ -   {'forward_r1': 38.7, 'forward_recall': '38.7/67.0/77.5', 'forward_ravg': 61.0}
09/17/2024 04:05:47 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 749--===========

09/17/2024 04:05:47 - INFO - __main__ -   {'area_video_r1': 40.2, 'area_video_recall': '40.2/67.5/77.8', 'area_video_ravg': 61.8}
09/17/2024 04:05:47 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 299=======

09/17/2024 04:05:47 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 04:05:47 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 749--===========

09/17/2024 04:05:47 - INFO - __main__ -   {'area_video_r1': 54.0, 'area_video_recall': '54.0/75.8/83.3', 'area_video_ravg': 71.0, 'area_video_back_r1': 47.9, 'area_video_back_recall': '47.9/75.0/81.3', 'area_video_back_ravg': 68.1}
09/17/2024 04:05:47 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 549=======

09/17/2024 04:05:47 - INFO - __main__ -   {'area_video_r1': 54.1, 'area_video_recall': '54.1/75.5/82.4', 'area_video_ravg': 70.6, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.5/82.1', 'area_video_back_ravg': 68.7}
09/17/2024 04:05:47 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 749--===========

09/17/2024 04:05:47 - INFO - __main__ -   {'video_r1': 37.6, 'video_recall': '37.6/64.6/74.3', 'video_ravg': 58.8}
09/17/2024 04:05:47 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 749=======

09/17/2024 04:05:47 - INFO - __main__ -   {'video_r1': 37.6, 'video_recall': '37.6/64.6/74.3', 'video_ravg': 58.8}
09/17/2024 04:05:47 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 749--===========

09/17/2024 04:05:47 - INFO - __main__ -   {'video_r1': 54.0, 'video_recall': '54.0/74.9/83.3', 'video_ravg': 70.7}
09/17/2024 04:05:47 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 549=======

09/17/2024 04:05:47 - INFO - __main__ -   {'video_r1': 54.5, 'video_recall': '54.5/76.1/83.4', 'video_ravg': 71.3}
09/17/2024 04:06:13 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.007402313407510519, 'loss_ret%tv%ta--finetune_area/loss_area': 1.1145939826965332, 'loss_ret%tv%ta--finetune_area/total_loss': 1.121996283531189}
[h264 @ 0x55e2512b5540] mmco: unref short failure
[h264 @ 0x55e2512b5540] mmco: unref short failure
 26%|██▌       | 750/2910 [4:44:30<82:26:02, 137.39s/it] 26%|██▌       | 751/2910 [4:44:34<58:17:28, 97.20s/it] [h264 @ 0x55a314adb080] mmco: unref short failure
[h264 @ 0x55e24dcb41c0] mmco: unref short failure
[h264 @ 0x55a315ba4340] mmco: unref short failure
[h264 @ 0x55a315ba4340] mmco: unref short failure
 26%|██▌       | 752/2910 [4:44:38<41:30:26, 69.24s/it][h264 @ 0x55b5ab776d40] mmco: unref short failure
 26%|██▌       | 753/2910 [4:44:42<29:47:59, 49.74s/it] 26%|██▌       | 754/2910 [4:44:47<21:41:58, 36.23s/it][h264 @ 0x55b5b434bc40] mmco: unref short failure
[h264 @ 0x55b5b434bc40] mmco: unref short failure
 26%|██▌       | 755/2910 [4:44:51<16:03:46, 26.83s/it][h264 @ 0x55b5bf6f17c0] mmco: unref short failure
[h264 @ 0x560746cea3c0] mmco: unref short failure
[h264 @ 0x560746cea3c0] mmco: unref short failure
[h264 @ 0x560746cea3c0] mmco: unref short failure
[h264 @ 0x560746cea3c0] mmco: unref short failure
 26%|██▌       | 756/2910 [4:44:57<12:09:33, 20.32s/it] 26%|██▌       | 757/2910 [4:45:02<9:25:58, 15.77s/it]  26%|██▌       | 758/2910 [4:45:07<7:29:39, 12.54s/it][h264 @ 0x55e249608240] mmco: unref short failure
[h264 @ 0x55e249608240] mmco: unref short failure
 26%|██▌       | 759/2910 [4:45:12<6:12:08, 10.38s/it] 26%|██▌       | 760/2910 [4:45:18<5:21:20,  8.97s/it][h264 @ 0x55a317cbfa40] mmco: unref short failure
[h264 @ 0x55a317cbfa40] mmco: unref short failure
[h264 @ 0x55a317cbfa40] mmco: unref short failure
[h264 @ 0x55a317cbfa40] mmco: unref short failure
 26%|██▌       | 761/2910 [4:45:23<4:42:56,  7.90s/it] 26%|██▌       | 762/2910 [4:45:29<4:20:18,  7.27s/it][h264 @ 0x55b5c65d5300] mmco: unref short failure
[h264 @ 0x55b5c65d5300] mmco: unref short failure
[h264 @ 0x55b5aad1ebc0] mmco: unref short failure
[h264 @ 0x55b5aad1ebc0] mmco: unref short failure
[h264 @ 0x56075ed931c0] mmco: unref short failure
09/17/2024 04:07:19 - INFO - __main__ -   current idx g5ifWFvvhk4.18 from finetune_area returns wrong image/video, use 144526 instead.
[h264 @ 0x55e245836ac0] mmco: unref short failure
[h264 @ 0x55e245836ac0] mmco: unref short failure
 26%|██▌       | 763/2910 [4:45:35<4:04:49,  6.84s/it] 26%|██▋       | 764/2910 [4:45:40<3:51:43,  6.48s/it][h264 @ 0x55e23cee0c00] mmco: unref short failure
[h264 @ 0x55e23cee0c00] mmco: unref short failure
 26%|██▋       | 765/2910 [4:45:45<3:33:43,  5.98s/it][h264 @ 0x55a3192665c0] mmco: unref short failure
[h264 @ 0x55a3192665c0] mmco: unref short failure
[h264 @ 0x55b5abec8ac0] mmco: unref short failure
[h264 @ 0x55b5abec8ac0] mmco: unref short failure
[h264 @ 0x55b5af108880] mmco: unref short failure
[h264 @ 0x55e236a1d300] mmco: unref short failure
[h264 @ 0x55b5aae97dc0] mmco: unref short failure
[h264 @ 0x55e254c747c0] mmco: unref short failure
[h264 @ 0x55e254c747c0] mmco: unref short failure
[h264 @ 0x5607471db880] mmco: unref short failure
[h264 @ 0x5607471db880] mmco: unref short failure
 26%|██▋       | 766/2910 [4:46:34<11:12:48, 18.83s/it][h264 @ 0x55b5c6b3c780] mmco: unref short failure
 26%|██▋       | 767/2910 [4:46:48<10:15:16, 17.23s/it][h264 @ 0x560741613800] mmco: unref short failure
[h264 @ 0x560741613800] mmco: unref short failure
 26%|██▋       | 768/2910 [4:46:59<9:08:15, 15.36s/it] [h264 @ 0x55e24dcb4900] mmco: unref short failure
[h264 @ 0x55e24dcb4900] mmco: unref short failure
[h264 @ 0x55a3274aba00] mmco: unref short failure
[h264 @ 0x55a3274aba00] mmco: unref short failure
 26%|██▋       | 769/2910 [4:47:06<7:45:18, 13.04s/it][h264 @ 0x55e241511880] mmco: unref short failure
[h264 @ 0x55e241511880] mmco: unref short failure
 26%|██▋       | 770/2910 [4:47:16<7:05:56, 11.94s/it][h264 @ 0x55a322939200] mmco: unref short failure
[h264 @ 0x55a322939200] mmco: unref short failure
 26%|██▋       | 771/2910 [4:47:21<5:52:38,  9.89s/it] 27%|██▋       | 772/2910 [4:47:26<5:06:59,  8.62s/it][h264 @ 0x55a315fed740] mmco: unref short failure
[h264 @ 0x55a315fed740] mmco: unref short failure
[h264 @ 0x55a315fed740] mmco: unref short failure
[h264 @ 0x55a315fed740] mmco: unref short failure
 27%|██▋       | 773/2910 [4:47:35<5:08:47,  8.67s/it][h264 @ 0x55b5ad5a3e00] mmco: unref short failure
[h264 @ 0x55b5ad5a3e00] mmco: unref short failure
[h264 @ 0x55a312a346c0] mmco: unref short failure
[h264 @ 0x55a312a346c0] mmco: unref short failure
[h264 @ 0x55e23a12fe80] mmco: unref short failure
[h264 @ 0x55e23a12fe80] mmco: unref short failure
[h264 @ 0x55e23a12fe80] mmco: unref short failure
[h264 @ 0x55e23a12fe80] mmco: unref short failure
09/17/2024 04:09:36 - INFO - __main__ -   current idx 14WUuya94QE.50 from finetune_area returns wrong image/video, use 96207 instead.
[h264 @ 0x55e23d019840] mmco: unref short failure
[h264 @ 0x55e23d019840] mmco: unref short failure
[h264 @ 0x55a31a0d04c0] mmco: unref short failure
09/17/2024 04:09:58 - INFO - __main__ -   current idx al4svOv9kUI.2 from finetune_area returns wrong image/video, use 123346 instead.
[h264 @ 0x55e239ba1900] mmco: unref short failure
[h264 @ 0x56074a8d6b00] mmco: unref short failure
[h264 @ 0x56074a8d6b00] mmco: unref short failure
[h264 @ 0x56074a8d6b00] mmco: unref short failure
[h264 @ 0x56074a8d6b00] mmco: unref short failure
[h264 @ 0x55b5aadc7500] mmco: unref short failure
[h264 @ 0x55b5aadc7500] mmco: unref short failure
[h264 @ 0x56074410b100] mmco: unref short failure
[h264 @ 0x56074410b100] mmco: unref short failure
[h264 @ 0x56074775ee40] mmco: unref short failure
[h264 @ 0x56074775ee40] mmco: unref short failure
[h264 @ 0x55a315b8b680] mmco: unref short failure
[h264 @ 0x55b5ca30b500] mmco: unref short failure
[h264 @ 0x55b5ca30b500] mmco: unref short failure
[h264 @ 0x55a30f009fc0] mmco: unref short failure
[h264 @ 0x55a30f009fc0] mmco: unref short failure
[h264 @ 0x55a30f009fc0] mmco: unref short failure
[h264 @ 0x55e241511680] mmco: unref short failure
[h264 @ 0x55e241511680] mmco: unref short failure
[h264 @ 0x55e245d7bb40] mmco: unref short failure
 27%|██▋       | 774/2910 [4:48:58<18:25:57, 31.07s/it][h264 @ 0x5607416532c0] mmco: unref short failure
[h264 @ 0x5607416532c0] mmco: unref short failure
[h264 @ 0x55a32e9feb80] mmco: unref short failure
[h264 @ 0x55a32e9feb80] mmco: unref short failure
[h264 @ 0x55b5b8b152c0] mmco: unref short failure
[h264 @ 0x55e23b7df440] mmco: unref short failure
[h264 @ 0x55e23b7df440] mmco: unref short failure
 27%|██▋       | 775/2910 [4:49:20<16:41:27, 28.14s/it][h264 @ 0x55b5cdbfb300] mmco: unref short failure
[h264 @ 0x55b5cdbfb300] mmco: unref short failure
 27%|██▋       | 776/2910 [4:49:28<13:06:54, 22.13s/it][h264 @ 0x55b5b0245140] mmco: unref short failure
[h264 @ 0x55b5b0245140] mmco: unref short failure
 27%|██▋       | 777/2910 [4:49:36<10:40:16, 18.01s/it][h264 @ 0x55e24c9a2200] mmco: unref short failure
[h264 @ 0x55e24c9a2200] mmco: unref short failure
[h264 @ 0x55b5a9e7d440] mmco: unref short failure
 27%|██▋       | 778/2910 [4:49:47<9:26:41, 15.95s/it] [h264 @ 0x55b5b32da240] mmco: unref short failure
[h264 @ 0x55b5b32da240] mmco: unref short failure
[h264 @ 0x56075164fb00] mmco: unref short failure
[h264 @ 0x56075164fb00] mmco: unref short failure
 27%|██▋       | 779/2910 [4:49:53<7:33:24, 12.77s/it][h264 @ 0x56074e9a5480] mmco: unref short failure
[h264 @ 0x56074e9a5480] mmco: unref short failure
 27%|██▋       | 780/2910 [4:49:58<6:12:16, 10.49s/it] 27%|██▋       | 781/2910 [4:50:04<5:20:52,  9.04s/it][h264 @ 0x560749d6a440] mmco: unref short failure
[h264 @ 0x560749d6a440] mmco: unref short failure
[h264 @ 0x560756a34040] mmco: unref short failure
[h264 @ 0x560756a34040] mmco: unref short failure
[h264 @ 0x56075b77fa40] mmco: unref short failure
[h264 @ 0x56075b77fa40] mmco: unref short failure
[h264 @ 0x55b5aae97700] mmco: unref short failure
[h264 @ 0x55b5aae97700] mmco: unref short failure
[h264 @ 0x5607562596c0] mmco: unref short failure
[h264 @ 0x5607562596c0] mmco: unref short failure
[h264 @ 0x560741ce4a00] mmco: unref short failure
[h264 @ 0x560741ce4a00] mmco: unref short failure
[h264 @ 0x5607562596c0] mmco: unref short failure
[h264 @ 0x5607562596c0] mmco: unref short failure
[h264 @ 0x55b5aacf0500] mmco: unref short failure
[h264 @ 0x55e248a63040] mmco: unref short failure
[h264 @ 0x55e248a63040] mmco: unref short failure
[h264 @ 0x55e23ab7a4c0] mmco: unref short failure
[h264 @ 0x55e23ab7a4c0] mmco: unref short failure
[h264 @ 0x55e255b6eb00] mmco: unref short failure
[h264 @ 0x55e255b6eb00] mmco: unref short failure
[h264 @ 0x55e254c51a40] mmco: unref short failure
[h264 @ 0x55e254c51a40] mmco: unref short failure
[h264 @ 0x55e23f7a1fc0] mmco: unref short failure
[h264 @ 0x55e23f7a1fc0] mmco: unref short failure
[h264 @ 0x55e23f7a1fc0] mmco: unref short failure
[h264 @ 0x5607498cd4c0] mmco: unref short failure
[h264 @ 0x5607498cd4c0] mmco: unref short failure
[h264 @ 0x56074dbcb600] mmco: unref short failure
[h264 @ 0x56074dbcb600] mmco: unref short failure
[h264 @ 0x560749084600] mmco: unref short failure
[h264 @ 0x560749084600] mmco: unref short failure
[h264 @ 0x55e238c64480] mmco: unref short failure
[h264 @ 0x55e238c64480] mmco: unref short failure
09/17/2024 04:12:56 - INFO - __main__ -   current idx GAe_04vmNRQ.5 from finetune_area returns wrong image/video, use 133257 instead.
[h264 @ 0x56075efc5c80] mmco: unref short failure
[h264 @ 0x56075efc5c80] mmco: unref short failure
[h264 @ 0x5607488ad980] mmco: unref short failure
 27%|██▋       | 782/2910 [4:51:32<19:29:51, 32.98s/it][h264 @ 0x55e255670480] mmco: unref short failure
[h264 @ 0x55e255670480] mmco: unref short failure
 27%|██▋       | 783/2910 [4:51:45<15:49:23, 26.78s/it][h264 @ 0x55a31dd0a400] mmco: unref short failure
[h264 @ 0x55a31dd0a400] mmco: unref short failure
[h264 @ 0x55b5b8706a40] mmco: unref short failure
 27%|██▋       | 784/2910 [4:51:53<12:34:56, 21.31s/it][h264 @ 0x55e23e45ca80] mmco: unref short failure
[h264 @ 0x55e23e45ca80] mmco: unref short failure
[h264 @ 0x560741da6200] mmco: unref short failure
[h264 @ 0x560741da6200] mmco: unref short failure
[h264 @ 0x560741da6200] mmco: unref short failure
[h264 @ 0x560743688580] mmco: unref short failure
[h264 @ 0x560743688580] mmco: unref short failure
 27%|██▋       | 785/2910 [4:52:03<10:27:42, 17.72s/it][h264 @ 0x55b5aa9b0900] mmco: unref short failure
[h264 @ 0x55a3131e4d80] mmco: unref short failure
[h264 @ 0x55a3131e4d80] mmco: unref short failure
[h264 @ 0x55b5b9cd9800] mmco: unref short failure
 27%|██▋       | 786/2910 [4:52:28<11:46:41, 19.96s/it] 27%|██▋       | 787/2910 [4:52:33<9:13:09, 15.63s/it]  27%|██▋       | 788/2910 [4:52:38<7:20:49, 12.46s/it][h264 @ 0x56075efc55c0] mmco: unref short failure
[h264 @ 0x55e238fbd2c0] mmco: unref short failure
[h264 @ 0x55e238fbd2c0] mmco: unref short failure
[h264 @ 0x55e238fbd2c0] mmco: unref short failure
[h264 @ 0x56075817e7c0] mmco: unref short failure
[h264 @ 0x56075817e7c0] mmco: unref short failure
 27%|██▋       | 789/2910 [4:52:45<6:16:13, 10.64s/it]09/17/2024 04:14:33 - INFO - __main__ -   current idx Ba46lyNCRP8.22 from finetune_area returns wrong image/video, use 18425 instead.
[h264 @ 0x55e23b805cc0] mmco: unref short failure
[h264 @ 0x55e23b805cc0] mmco: unref short failure
[h264 @ 0x55e23b805cc0] mmco: unref short failure
[h264 @ 0x55e23b805cc0] mmco: unref short failure
[h264 @ 0x55e23b805cc0] mmco: unref short failure
[h264 @ 0x55e23b805cc0] mmco: unref short failure
not have audios 7wavFXW3AFw.7
[h264 @ 0x55e23e164880] mmco: unref short failure
[h264 @ 0x55e23e164880] mmco: unref short failure
[h264 @ 0x55e25546a900] mmco: unref short failure
[h264 @ 0x55e25546a900] mmco: unref short failure
09/17/2024 04:15:03 - INFO - __main__ -   current idx hn6DOvhGJJU.6 from finetune_area returns wrong image/video, use 116214 instead.
[h264 @ 0x560751ee3280] mmco: unref short failure
[h264 @ 0x560751ee3280] mmco: unref short failure
[h264 @ 0x560751ee3280] mmco: unref short failure
[h264 @ 0x560751ee3280] mmco: unref short failure
[h264 @ 0x55a3107a40c0] mmco: unref short failure
[h264 @ 0x55a3107a40c0] mmco: unref short failure
09/17/2024 04:15:10 - INFO - __main__ -   current idx Y7G_DDBX8i4.3 from finetune_area returns wrong image/video, use 5065 instead.
[h264 @ 0x560746052600] mmco: unref short failure
09/17/2024 04:15:15 - INFO - __main__ -   current idx 1wKPYAWLNkA.112 from finetune_area returns wrong image/video, use 91421 instead.
[h264 @ 0x55e23b4e8580] mmco: unref short failure
[h264 @ 0x55e2562b7a80] mmco: unref short failure
[h264 @ 0x55e2562b7a80] mmco: unref short failure
[h264 @ 0x55b5af4c6bc0] mmco: unref short failure
[h264 @ 0x55b5af4c6bc0] mmco: unref short failure
[h264 @ 0x56075164fb00] mmco: unref short failure
 27%|██▋       | 790/2910 [4:54:07<18:55:28, 32.14s/it][h264 @ 0x56074dea0b00] mmco: unref short failure
09/17/2024 04:15:59 - INFO - __main__ -   current idx e2ba1avSYzg.223 from finetune_area returns wrong image/video, use 18959 instead.
 27%|██▋       | 791/2910 [4:54:16<14:49:07, 25.18s/it][h264 @ 0x55a30ecc5fc0] mmco: unref short failure
[h264 @ 0x55a30ecc5fc0] mmco: unref short failure
 27%|██▋       | 792/2910 [4:54:25<11:56:09, 20.29s/it][h264 @ 0x55b5b04aac40] mmco: unref short failure
 27%|██▋       | 793/2910 [4:54:38<10:40:47, 18.16s/it][h264 @ 0x55e24fcf0a80] mmco: unref short failure
[h264 @ 0x56075d11e200] mmco: unref short failure
 27%|██▋       | 794/2910 [4:54:58<11:00:21, 18.72s/it] 27%|██▋       | 795/2910 [4:55:04<8:38:50, 14.72s/it]  27%|██▋       | 796/2910 [4:55:09<6:57:12, 11.84s/it] 27%|██▋       | 797/2910 [4:55:14<5:49:48,  9.93s/it]09/17/2024 04:17:00 - INFO - __main__ -   current idx WdVJ8VSAKso.55 from finetune_area returns wrong image/video, use 69991 instead.
[h264 @ 0x56074f394bc0] mmco: unref short failure
[h264 @ 0x56074f394bc0] mmco: unref short failure
[h264 @ 0x55b5b649d180] mmco: unref short failure
[h264 @ 0x55b5b649d180] mmco: unref short failure
[h264 @ 0x55b5af413bc0] mmco: unref short failure
[h264 @ 0x55b5af413bc0] mmco: unref short failure
[h264 @ 0x55b5aa8a73c0] mmco: unref short failure
[h264 @ 0x55e2383a9680] mmco: unref short failure
[h264 @ 0x56075367b680] mmco: unref short failure
[h264 @ 0x56075367b680] mmco: unref short failure
[h264 @ 0x56075367b680] mmco: unref short failure
[h264 @ 0x56075367b680] mmco: unref short failure
[h264 @ 0x55b5b8b152c0] mmco: unref short failure
[h264 @ 0x55b5b8b152c0] mmco: unref short failure
[h264 @ 0x560747902d80] mmco: unref short failure
[h264 @ 0x55e2393e1fc0] mmco: unref short failure
[h264 @ 0x55e2393e1fc0] mmco: unref short failure
[h264 @ 0x560743688a00] mmco: unref short failure
[h264 @ 0x55e2393e1fc0] mmco: unref short failure
[h264 @ 0x55e2393e1fc0] mmco: unref short failure
[h264 @ 0x55e237fd52c0] mmco: unref short failure
[h264 @ 0x55e237fd52c0] mmco: unref short failure
[h264 @ 0x55e237fd52c0] mmco: unref short failure
[h264 @ 0x55e237fd52c0] mmco: unref short failure
[h264 @ 0x55e2393e1fc0] mmco: unref short failure
[h264 @ 0x55e2393e1fc0] mmco: unref short failure
[h264 @ 0x55e248a63500] mmco: unref short failure
[h264 @ 0x55e248a63500] mmco: unref short failure
[h264 @ 0x55e248a63500] mmco: unref short failure
[h264 @ 0x55e248a63500] mmco: unref short failure
 27%|██▋       | 798/2910 [4:56:35<18:21:10, 31.28s/it] 27%|██▋       | 799/2910 [4:56:42<13:58:29, 23.83s/it]09/17/2024 04:18:28 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 04:18:28 - INFO - __main__ -   start running ret%tva validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a3118a7bc0] mmco: unref short failure
09/17/2024 04:18:39 - INFO - __main__ -   current idx bdHJRIWkgos.39 from finetune_area returns wrong image/video, use 64889 instead.
09/17/2024 04:18:40 - INFO - __main__ -   current idx 85jT7k1nw1g.20 from finetune_area returns wrong image/video, use 89708 instead.
[h264 @ 0x55b5b0c65fc0] mmco: unref short failure
[h264 @ 0x55b5b0c65fc0] mmco: unref short failure
[h264 @ 0x55b5c035e600] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55b5cb83b8c0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e2381748c0] mmco: unref short failure
[h264 @ 0x55e2381748c0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e238792c40] mmco: unref short failure
[h264 @ 0x55e238792c40] mmco: unref short failure
[h264 @ 0x55e238792c40] mmco: unref short failure
[h264 @ 0x55e238792c40] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a31976e7c0] mmco: unref short failure
[h264 @ 0x55a31976e7c0] mmco: unref short failure
[h264 @ 0x55a31976e7c0] mmco: unref short failure
[h264 @ 0x55a31976e7c0] mmco: unref short failure
[h264 @ 0x5607411ba380] mmco: unref short failure
[h264 @ 0x55e245032740] mmco: unref short failure
[h264 @ 0x55e24b73cd80] mmco: unref short failure
[h264 @ 0x55e24b73cd80] mmco: unref short failure
[h264 @ 0x56074d597f00] mmco: unref short failure
[h264 @ 0x55b5c8b65c40] mmco: unref short failure
[h264 @ 0x55e238c64280] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<03:11,  1.15it/s][A[h264 @ 0x5607432defc0] mmco: unref short failure

  1%|          | 2/221 [00:01<02:23,  1.52it/s][A
  1%|▏         | 3/221 [00:01<01:48,  2.01it/s][A
  2%|▏         | 4/221 [00:01<01:15,  2.89it/s][A
  2%|▏         | 5/221 [00:01<00:58,  3.70it/s][A
  3%|▎         | 6/221 [00:02<00:47,  4.53it/s][A
  3%|▎         | 7/221 [00:02<00:48,  4.41it/s][A
  4%|▎         | 8/221 [00:03<01:25,  2.50it/s][A
  4%|▍         | 9/221 [00:03<01:14,  2.86it/s][A
  5%|▍         | 10/221 [00:03<01:15,  2.80it/s][A
  5%|▍         | 11/221 [00:03<01:05,  3.21it/s][A[h264 @ 0x55e23854f680] mmco: unref short failure
[h264 @ 0x55e23854f680] mmco: unref short failure
[h264 @ 0x55e23854f680] mmco: unref short failure
[h264 @ 0x55e23854f680] mmco: unref short failure
[h264 @ 0x55e23854f680] mmco: unref short failure
[h264 @ 0x55e23854f680] mmco: unref short failure
[h264 @ 0x55e23854f680] mmco: unref short failure
[h264 @ 0x55e23854f680] mmco: unref short failure
[h264 @ 0x55e23854f680] mmco: unref short failure
[h264 @ 0x55e23854f680] mmco: unref short failure
[h264 @ 0x55e23854f680] mmco: unref short failure
[h264 @ 0x55e23854f680] mmco: unref short failure

  5%|▌         | 12/221 [00:04<01:29,  2.35it/s][A
  6%|▌         | 13/221 [00:04<01:16,  2.71it/s][A
  6%|▋         | 14/221 [00:06<03:00,  1.15it/s][A
  7%|▋         | 15/221 [00:07<02:21,  1.46it/s][A
  7%|▋         | 16/221 [00:07<02:04,  1.65it/s][A
  8%|▊         | 17/221 [00:07<01:42,  1.99it/s][A
  8%|▊         | 18/221 [00:08<01:27,  2.33it/s][A
  9%|▊         | 19/221 [00:08<01:12,  2.77it/s][A
  9%|▉         | 20/221 [00:08<01:01,  3.24it/s][A
 10%|▉         | 21/221 [00:08<00:51,  3.87it/s][A
 10%|▉         | 22/221 [00:08<00:49,  4.02it/s][A
 10%|█         | 23/221 [00:08<00:40,  4.85it/s][A
 11%|█         | 24/221 [00:09<00:35,  5.52it/s][A
 11%|█▏        | 25/221 [00:09<00:34,  5.62it/s][A
 12%|█▏        | 26/221 [00:09<00:35,  5.45it/s][A
 13%|█▎        | 28/221 [00:10<00:47,  4.06it/s][A
 13%|█▎        | 29/221 [00:10<00:46,  4.17it/s][A
 14%|█▎        | 30/221 [00:10<00:48,  3.93it/s][A
 14%|█▍        | 31/221 [00:10<00:50,  3.73it/s][A
 14%|█▍        | 32/221 [00:10<00:43,  4.38it/s][A
 15%|█▍        | 33/221 [00:11<00:53,  3.54it/s][A
 15%|█▌        | 34/221 [00:11<00:43,  4.32it/s][A
 16%|█▌        | 35/221 [00:11<00:42,  4.37it/s][h264 @ 0x55e248a63780] mmco: unref short failure
[h264 @ 0x55e248a63780] mmco: unref short failure
[A[h264 @ 0x55e248a63780] mmco: unref short failure
[h264 @ 0x55e248a63780] mmco: unref short failure

 16%|█▋        | 36/221 [00:11<00:43,  4.24it/s][A
 17%|█▋        | 37/221 [00:12<01:18,  2.34it/s][A
 17%|█▋        | 38/221 [00:13<01:23,  2.20it/s][A
 18%|█▊        | 39/221 [00:13<01:03,  2.86it/s][A
 18%|█▊        | 40/221 [00:13<00:59,  3.04it/s][A
 19%|█▉        | 42/221 [00:14<00:51,  3.50it/s][A
 19%|█▉        | 43/221 [00:14<00:43,  4.12it/s][A
 20%|█▉        | 44/221 [00:14<00:40,  4.39it/s][A[h264 @ 0x55a320315500] mmco: unref short failure

 20%|██        | 45/221 [00:15<01:15,  2.32it/s][A
 21%|██        | 46/221 [00:15<01:17,  2.26it/s][A
 21%|██▏       | 47/221 [00:16<01:21,  2.13it/s][A
 22%|██▏       | 48/221 [00:16<01:03,  2.72it/s][A
 22%|██▏       | 49/221 [00:16<00:51,  3.34it/s][A
 23%|██▎       | 50/221 [00:16<00:44,  3.87it/s][A
 23%|██▎       | 51/221 [00:17<00:39,  4.29it/s][A
 24%|██▎       | 52/221 [00:17<00:38,  4.36it/s][A
 24%|██▍       | 53/221 [00:17<00:44,  3.74it/s][A
 24%|██▍       | 54/221 [00:19<02:21,  1.18it/s][A
 25%|██▍       | 55/221 [00:20<01:55,  1.43it/s][A
 25%|██▌       | 56/221 [00:20<01:31,  1.80it/s][A
 26%|██▌       | 57/221 [00:20<01:13,  2.25it/s][A
 26%|██▌       | 58/221 [00:20<00:57,  2.84it/s][A
 27%|██▋       | 59/221 [00:20<00:47,  3.38it/s][A
 27%|██▋       | 60/221 [00:21<00:55,  2.89it/s][A
 28%|██▊       | 61/221 [00:21<00:46,  3.48it/s][A
 28%|██▊       | 62/221 [00:21<00:43,  3.68it/s][A
 29%|██▊       | 63/221 [00:22<00:44,  3.57it/s][A
 29%|██▉       | 64/221 [00:22<00:44,  3.51it/s][A
 29%|██▉       | 65/221 [00:22<00:41,  3.77it/s][A
 30%|██▉       | 66/221 [00:22<00:45,  3.42it/s][A
 30%|███       | 67/221 [00:23<00:48,  3.15it/s][A
 31%|███       | 68/221 [00:23<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:24<01:05,  2.33it/s][A
 32%|███▏      | 70/221 [00:24<00:54,  2.78it/s][A
 32%|███▏      | 71/221 [00:27<03:05,  1.23s/it][A
 33%|███▎      | 72/221 [00:28<02:22,  1.05it/s][A
 33%|███▎      | 73/221 [00:28<01:50,  1.34it/s][A
 33%|███▎      | 74/221 [00:28<01:24,  1.73it/s][A
 34%|███▍      | 75/221 [00:28<01:17,  1.88it/s][A[h264 @ 0x55e237033880] mmco: unref short failure

 34%|███▍      | 76/221 [00:29<01:02,  2.32it/s][A[h264 @ 0x55e237033880] mmco: unref short failure

 35%|███▍      | 77/221 [00:29<00:53,  2.70it/s][A
 35%|███▌      | 78/221 [00:29<00:48,  2.93it/s][A
 36%|███▌      | 79/221 [00:30<01:07,  2.11it/s][A
 36%|███▌      | 80/221 [00:30<00:57,  2.46it/s][A
 37%|███▋      | 81/221 [00:30<00:51,  2.74it/s][A
 37%|███▋      | 82/221 [00:31<00:42,  3.27it/s][A
 38%|███▊      | 83/221 [00:31<00:38,  3.54it/s][A
 38%|███▊      | 84/221 [00:31<00:38,  3.55it/s][A
 38%|███▊      | 85/221 [00:32<00:42,  3.17it/s][A
 39%|███▉      | 86/221 [00:32<00:50,  2.67it/s][A
 39%|███▉      | 87/221 [00:33<01:03,  2.10it/s][A
 40%|███▉      | 88/221 [00:33<01:05,  2.03it/s][A09/17/2024 04:21:19 - INFO - __main__ -   current idx Ktryr_1EhKk.51 from finetune_area returns wrong image/video, use 125620 instead.

 40%|████      | 89/221 [00:37<03:06,  1.41s/it][A
 41%|████      | 90/221 [00:37<02:20,  1.07s/it][A
 41%|████      | 91/221 [00:37<01:41,  1.28it/s][A
 42%|████▏     | 92/221 [00:37<01:18,  1.65it/s][A
 42%|████▏     | 93/221 [00:38<01:16,  1.67it/s][A
 43%|████▎     | 94/221 [00:38<01:02,  2.02it/s][A
 43%|████▎     | 95/221 [00:38<00:48,  2.61it/s][A
 43%|████▎     | 96/221 [00:39<00:45,  2.75it/s][A
 44%|████▍     | 97/221 [00:39<00:39,  3.12it/s][A
 44%|████▍     | 98/221 [00:39<00:40,  3.06it/s][A
 45%|████▍     | 99/221 [00:39<00:32,  3.77it/s][A[h264 @ 0x560745b54440] mmco: unref short failure

 45%|████▌     | 100/221 [00:40<00:30,  4.01it/s][A
 46%|████▌     | 101/221 [00:40<00:25,  4.63it/s][A
 46%|████▌     | 102/221 [00:40<00:31,  3.81it/s][A
 47%|████▋     | 103/221 [00:40<00:25,  4.64it/s][A
 47%|████▋     | 104/221 [00:40<00:21,  5.34it/s][A
 48%|████▊     | 105/221 [00:41<00:25,  4.61it/s][A
 48%|████▊     | 106/221 [00:41<00:42,  2.69it/s][A
 48%|████▊     | 107/221 [00:41<00:33,  3.37it/s][A
 49%|████▉     | 108/221 [00:42<00:30,  3.70it/s][A
 49%|████▉     | 109/221 [00:42<00:32,  3.45it/s][A
 50%|████▉     | 110/221 [00:42<00:35,  3.12it/s][A
 50%|█████     | 111/221 [00:43<00:42,  2.59it/s][A
 51%|█████     | 112/221 [00:43<00:41,  2.65it/s][A
 51%|█████     | 113/221 [00:44<00:43,  2.48it/s][A
 52%|█████▏    | 115/221 [00:44<00:28,  3.77it/s][A
 52%|█████▏    | 116/221 [00:49<02:23,  1.37s/it][A
 53%|█████▎    | 117/221 [00:49<01:53,  1.09s/it][A
 53%|█████▎    | 118/221 [00:49<01:30,  1.14it/s][A
 54%|█████▍    | 119/221 [00:50<01:12,  1.40it/s][A
 54%|█████▍    | 120/221 [00:50<01:00,  1.66it/s][A
 55%|█████▍    | 121/221 [00:50<00:46,  2.17it/s][A
 55%|█████▌    | 122/221 [00:50<00:40,  2.46it/s][A
 56%|█████▌    | 123/221 [00:50<00:32,  2.99it/s][A
 56%|█████▌    | 124/221 [00:51<00:29,  3.34it/s][A
 57%|█████▋    | 125/221 [00:51<00:30,  3.14it/s][A
 57%|█████▋    | 126/221 [00:52<00:34,  2.77it/s][A
 57%|█████▋    | 127/221 [00:52<00:39,  2.38it/s][A
 58%|█████▊    | 128/221 [00:52<00:36,  2.54it/s][A
 58%|█████▊    | 129/221 [00:53<00:33,  2.78it/s][A
 59%|█████▉    | 130/221 [00:53<00:32,  2.78it/s][A[h264 @ 0x56075367b880] mmco: unref short failure

 59%|█████▉    | 131/221 [00:53<00:30,  3.00it/s][A[h264 @ 0x55b5ae22b780] mmco: unref short failure

 60%|█████▉    | 132/221 [00:54<00:26,  3.38it/s][A
 60%|██████    | 133/221 [00:54<00:27,  3.17it/s][A
 61%|██████    | 134/221 [00:54<00:25,  3.44it/s][A
 61%|██████    | 135/221 [00:55<00:28,  3.06it/s][A
 62%|██████▏   | 136/221 [00:55<00:30,  2.77it/s][A
 62%|██████▏   | 137/221 [00:55<00:26,  3.21it/s][A
 62%|██████▏   | 138/221 [00:55<00:25,  3.26it/s][A
 63%|██████▎   | 139/221 [00:56<00:26,  3.10it/s][A
 63%|██████▎   | 140/221 [00:56<00:25,  3.13it/s][A
 64%|██████▍   | 141/221 [00:56<00:22,  3.56it/s][A
 64%|██████▍   | 142/221 [00:57<00:23,  3.32it/s][A
 65%|██████▍   | 143/221 [00:57<00:28,  2.72it/s][A
 65%|██████▌   | 144/221 [00:57<00:24,  3.10it/s][A
 66%|██████▌   | 145/221 [00:58<00:19,  3.83it/s][A
 66%|██████▌   | 146/221 [00:58<00:17,  4.25it/s][A
 67%|██████▋   | 147/221 [00:58<00:16,  4.59it/s][A[h264 @ 0x55b5cc26c440] mmco: unref short failure
[h264 @ 0x55b5cc26c440] mmco: unref short failure

 67%|██████▋   | 148/221 [00:58<00:18,  4.01it/s][A
 68%|██████▊   | 150/221 [00:58<00:14,  4.99it/s][A[h264 @ 0x55a30efb0040] mmco: unref short failure
[h264 @ 0x55b5aea9b200] mmco: unref short failure
[h264 @ 0x55b5aea9b200] mmco: unref short failure

 68%|██████▊   | 151/221 [01:00<00:31,  2.20it/s][A
 69%|██████▉   | 152/221 [01:00<00:32,  2.10it/s][A
 69%|██████▉   | 153/221 [01:01<00:28,  2.38it/s][A[h264 @ 0x55a320bc3240] mmco: unref short failure
[h264 @ 0x55a320bc3240] mmco: unref short failure

 70%|██████▉   | 154/221 [01:01<00:29,  2.24it/s][A
 70%|███████   | 155/221 [01:01<00:23,  2.76it/s][A
 71%|███████   | 156/221 [01:01<00:20,  3.14it/s][A
 71%|███████   | 157/221 [01:02<00:28,  2.22it/s][A
 71%|███████▏  | 158/221 [01:02<00:25,  2.48it/s][A
 72%|███████▏  | 159/221 [01:03<00:21,  2.83it/s][A
 72%|███████▏  | 160/221 [01:03<00:18,  3.35it/s][A
 73%|███████▎  | 161/221 [01:03<00:15,  3.98it/s][A
 73%|███████▎  | 162/221 [01:03<00:13,  4.35it/s][A
 74%|███████▍  | 163/221 [01:03<00:13,  4.31it/s][A
 74%|███████▍  | 164/221 [01:04<00:11,  4.80it/s][A
 75%|███████▍  | 165/221 [01:04<00:09,  5.60it/s][A
 75%|███████▌  | 166/221 [01:04<00:14,  3.74it/s][A
 76%|███████▌  | 167/221 [01:04<00:13,  3.88it/s][A
 76%|███████▌  | 168/221 [01:06<00:28,  1.85it/s][A
 76%|███████▋  | 169/221 [01:06<00:24,  2.15it/s][A
 77%|███████▋  | 170/221 [01:06<00:22,  2.25it/s][A
 77%|███████▋  | 171/221 [01:07<00:19,  2.59it/s][A
 78%|███████▊  | 172/221 [01:07<00:16,  2.90it/s][A
 78%|███████▊  | 173/221 [01:07<00:14,  3.23it/s][A
 79%|███████▊  | 174/221 [01:07<00:11,  3.98it/s][A
 79%|███████▉  | 175/221 [01:08<00:13,  3.37it/s][A
 80%|███████▉  | 176/221 [01:08<00:13,  3.37it/s][A
 80%|████████  | 177/221 [01:08<00:10,  4.02it/s][A
 81%|████████  | 178/221 [01:08<00:12,  3.37it/s][A
 81%|████████  | 179/221 [01:09<00:14,  2.97it/s][A
 81%|████████▏ | 180/221 [01:09<00:11,  3.67it/s][A
 82%|████████▏ | 181/221 [01:09<00:11,  3.59it/s][A
 82%|████████▏ | 182/221 [01:09<00:10,  3.80it/s][A
 83%|████████▎ | 183/221 [01:10<00:09,  4.07it/s][A
 83%|████████▎ | 184/221 [01:10<00:09,  4.00it/s][A
 84%|████████▎ | 185/221 [01:10<00:08,  4.31it/s][A
 84%|████████▍ | 186/221 [01:11<00:11,  3.12it/s][A
 85%|████████▍ | 187/221 [01:11<00:09,  3.67it/s][A
 85%|████████▌ | 188/221 [01:11<00:09,  3.49it/s][A
 86%|████████▌ | 189/221 [01:11<00:08,  3.69it/s][A
 86%|████████▌ | 190/221 [01:12<00:08,  3.47it/s][A
 86%|████████▋ | 191/221 [01:12<00:07,  3.81it/s][A
 87%|████████▋ | 192/221 [01:12<00:07,  3.93it/s][A
 88%|████████▊ | 194/221 [01:13<00:09,  2.76it/s][A
 88%|████████▊ | 195/221 [01:13<00:07,  3.27it/s][A
 89%|████████▊ | 196/221 [01:13<00:06,  3.85it/s][A
 89%|████████▉ | 197/221 [01:13<00:05,  4.50it/s][A
 90%|████████▉ | 198/221 [01:14<00:06,  3.70it/s][A
 90%|█████████ | 199/221 [01:14<00:05,  3.78it/s][A
 90%|█████████ | 200/221 [01:14<00:06,  3.47it/s][A
 91%|█████████ | 201/221 [01:15<00:05,  3.77it/s][A
 91%|█████████▏| 202/221 [01:15<00:04,  4.14it/s][A
 92%|█████████▏| 203/221 [01:15<00:03,  4.81it/s][A
 92%|█████████▏| 204/221 [01:15<00:03,  5.16it/s][A
 93%|█████████▎| 205/221 [01:15<00:03,  5.20it/s][A
 93%|█████████▎| 206/221 [01:16<00:04,  3.03it/s][A
 94%|█████████▎| 207/221 [01:16<00:03,  3.67it/s][A
 94%|█████████▍| 208/221 [01:16<00:03,  4.04it/s][A
 95%|█████████▌| 210/221 [01:16<00:01,  5.97it/s][A
 95%|█████████▌| 211/221 [01:17<00:02,  4.40it/s][A
 96%|█████████▌| 212/221 [01:17<00:02,  4.46it/s][A
 96%|█████████▋| 213/221 [01:17<00:01,  4.77it/s][A
 97%|█████████▋| 214/221 [01:18<00:02,  2.90it/s][A
 97%|█████████▋| 215/221 [01:18<00:01,  3.14it/s][A
 98%|█████████▊| 216/221 [01:19<00:01,  3.17it/s][A
 98%|█████████▊| 217/221 [01:19<00:01,  2.56it/s][A
 99%|█████████▊| 218/221 [01:19<00:01,  2.71it/s][A
 99%|█████████▉| 219/221 [01:20<00:00,  3.15it/s][A[h264 @ 0x55a31197af40] mmco: unref short failure

100%|█████████▉| 220/221 [01:23<00:01,  1.36s/it][A
100%|██████████| 221/221 [01:24<00:00,  1.04s/it][A100%|██████████| 221/221 [01:24<00:00,  2.63it/s]
[h264 @ 0x55a315840980] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:06,  3.33it/s][A
  1%|          | 2/221 [00:00<01:04,  3.37it/s][A
  1%|▏         | 3/221 [00:00<01:04,  3.36it/s][A
  2%|▏         | 4/221 [00:01<01:04,  3.37it/s][A
  2%|▏         | 5/221 [00:01<01:03,  3.38it/s][A
  3%|▎         | 6/221 [00:01<01:03,  3.38it/s][A
  3%|▎         | 7/221 [00:02<01:03,  3.36it/s][A
  4%|▎         | 8/221 [00:02<01:03,  3.36it/s][A
  4%|▍         | 9/221 [00:02<01:03,  3.32it/s][A
  5%|▍         | 10/221 [00:03<01:05,  3.25it/s][A
  5%|▍         | 11/221 [00:03<01:06,  3.15it/s][A
  5%|▌         | 12/221 [00:03<01:05,  3.19it/s][A
  6%|▌         | 13/221 [00:03<01:04,  3.24it/s][A
  6%|▋         | 14/221 [00:04<01:03,  3.28it/s][A
  7%|▋         | 15/221 [00:04<01:03,  3.24it/s][A
  7%|▋         | 16/221 [00:04<01:02,  3.29it/s][A
  8%|▊         | 17/221 [00:05<01:02,  3.28it/s][A
  8%|▊         | 18/221 [00:05<01:01,  3.31it/s][A
  9%|▊         | 19/221 [00:05<01:01,  3.29it/s][A
  9%|▉         | 20/221 [00:06<01:01,  3.29it/s][A
 10%|▉         | 21/221 [00:06<01:00,  3.31it/s][A
 10%|▉         | 22/221 [00:06<00:59,  3.34it/s][A
 10%|█         | 23/221 [00:06<00:59,  3.36it/s][A
 11%|█         | 24/221 [00:07<00:58,  3.37it/s][A
 11%|█▏        | 25/221 [00:07<00:58,  3.38it/s][A
 12%|█▏        | 26/221 [00:07<00:58,  3.31it/s][A
 12%|█▏        | 27/221 [00:08<00:58,  3.34it/s][A
 13%|█▎        | 28/221 [00:08<00:58,  3.31it/s][A
 13%|█▎        | 29/221 [00:08<00:57,  3.33it/s][A
 14%|█▎        | 30/221 [00:09<00:57,  3.33it/s][A
 14%|█▍        | 31/221 [00:09<00:57,  3.29it/s][A
 14%|█▍        | 32/221 [00:09<00:56,  3.32it/s][A
 15%|█▍        | 33/221 [00:09<00:56,  3.30it/s][A
 15%|█▌        | 34/221 [00:10<00:56,  3.33it/s][A
 16%|█▌        | 35/221 [00:10<00:55,  3.35it/s][A
 16%|█▋        | 36/221 [00:10<00:54,  3.37it/s][A[h264 @ 0x55e244eae5c0] mmco: unref short failure
[h264 @ 0x55e244eae5c0] mmco: unref short failure

 17%|█▋        | 37/221 [00:11<00:54,  3.38it/s][A
 17%|█▋        | 38/221 [00:11<00:54,  3.39it/s][A
 18%|█▊        | 39/221 [00:11<00:53,  3.37it/s][A
 18%|█▊        | 40/221 [00:12<00:54,  3.35it/s][A
 19%|█▊        | 41/221 [00:12<00:53,  3.36it/s][A
 19%|█▉        | 42/221 [00:12<00:53,  3.37it/s][A
 19%|█▉        | 43/221 [00:12<00:53,  3.34it/s][A
 20%|█▉        | 44/221 [00:13<00:53,  3.34it/s][A
 20%|██        | 45/221 [00:13<00:52,  3.36it/s][A
 21%|██        | 46/221 [00:13<00:52,  3.34it/s][A
 21%|██▏       | 47/221 [00:14<00:51,  3.36it/s][A
 22%|██▏       | 48/221 [00:14<00:51,  3.33it/s][A
 22%|██▏       | 49/221 [00:14<00:51,  3.35it/s][A
 23%|██▎       | 50/221 [00:15<00:51,  3.33it/s][A
 23%|██▎       | 51/221 [00:15<00:51,  3.31it/s][A
 24%|██▎       | 52/221 [00:15<00:50,  3.32it/s][A
 24%|██▍       | 53/221 [00:15<00:50,  3.32it/s][A
 24%|██▍       | 54/221 [00:16<00:50,  3.31it/s][A
 25%|██▍       | 55/221 [00:16<00:49,  3.33it/s][A
 25%|██▌       | 56/221 [00:16<00:49,  3.35it/s][A
 26%|██▌       | 57/221 [00:17<00:48,  3.36it/s][A
 26%|██▌       | 58/221 [00:17<00:48,  3.37it/s][A
 27%|██▋       | 59/221 [00:17<00:48,  3.36it/s][A
 27%|██▋       | 60/221 [00:18<00:47,  3.37it/s][A
 28%|██▊       | 61/221 [00:18<00:49,  3.23it/s][A
 28%|██▊       | 62/221 [00:18<00:50,  3.17it/s][A
 29%|██▊       | 63/221 [00:19<00:49,  3.18it/s][A[h264 @ 0x55b5c0490d40] mmco: unref short failure
[h264 @ 0x55b5c0490d40] mmco: unref short failure

 29%|██▉       | 64/221 [00:19<00:48,  3.25it/s][A
 29%|██▉       | 65/221 [00:19<00:47,  3.29it/s][A
 30%|██▉       | 66/221 [00:19<00:46,  3.32it/s][A
 30%|███       | 67/221 [00:20<00:46,  3.33it/s][A
 31%|███       | 68/221 [00:20<00:45,  3.33it/s][A
 31%|███       | 69/221 [00:20<00:45,  3.33it/s][A
 32%|███▏      | 70/221 [00:21<00:45,  3.35it/s][A
 32%|███▏      | 71/221 [00:21<00:45,  3.33it/s][A
 33%|███▎      | 72/221 [00:21<00:44,  3.35it/s][A
 33%|███▎      | 73/221 [00:21<00:43,  3.36it/s][A
 33%|███▎      | 74/221 [00:22<00:43,  3.37it/s][A
 34%|███▍      | 75/221 [00:22<00:43,  3.38it/s][A
 34%|███▍      | 76/221 [00:22<00:42,  3.39it/s][A
 35%|███▍      | 77/221 [00:23<00:42,  3.39it/s][A
 35%|███▌      | 78/221 [00:23<00:42,  3.38it/s][A
 36%|███▌      | 79/221 [00:23<00:41,  3.38it/s][A
 36%|███▌      | 80/221 [00:24<00:42,  3.34it/s][A
 37%|███▋      | 81/221 [00:24<00:41,  3.35it/s][A
 37%|███▋      | 82/221 [00:24<00:41,  3.37it/s][A
 38%|███▊      | 83/221 [00:24<00:40,  3.38it/s][A
 38%|███▊      | 84/221 [00:25<00:40,  3.38it/s][A
 38%|███▊      | 85/221 [00:25<00:40,  3.39it/s][A
 39%|███▉      | 86/221 [00:25<00:39,  3.38it/s][A
 39%|███▉      | 87/221 [00:26<00:39,  3.36it/s][A
 40%|███▉      | 88/221 [00:26<00:39,  3.38it/s][A
 40%|████      | 89/221 [00:26<00:39,  3.38it/s][A
 41%|████      | 90/221 [00:27<00:38,  3.38it/s][A
 41%|████      | 91/221 [00:27<00:38,  3.38it/s][A
 42%|████▏     | 92/221 [00:27<00:38,  3.39it/s][A
 42%|████▏     | 93/221 [00:27<00:37,  3.39it/s][A
 43%|████▎     | 94/221 [00:28<00:37,  3.39it/s][A
 43%|████▎     | 95/221 [00:28<00:37,  3.37it/s][A
 43%|████▎     | 96/221 [00:28<00:36,  3.38it/s][A
 44%|████▍     | 97/221 [00:29<00:36,  3.39it/s][A
 44%|████▍     | 98/221 [00:29<00:36,  3.35it/s][A
 45%|████▍     | 99/221 [00:29<00:36,  3.36it/s][A
 45%|████▌     | 100/221 [00:29<00:35,  3.38it/s][A
 46%|████▌     | 101/221 [00:30<00:35,  3.38it/s][A
 46%|████▌     | 102/221 [00:30<00:35,  3.39it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.39it/s][A
 47%|████▋     | 104/221 [00:31<00:34,  3.39it/s][A
 48%|████▊     | 105/221 [00:31<00:34,  3.40it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.40it/s][A
 48%|████▊     | 107/221 [00:32<00:33,  3.40it/s][A
 49%|████▉     | 108/221 [00:32<00:33,  3.41it/s][A
 49%|████▉     | 109/221 [00:32<00:32,  3.41it/s][A
 50%|████▉     | 110/221 [00:32<00:32,  3.41it/s][A
 50%|█████     | 111/221 [00:33<00:32,  3.41it/s][A
 51%|█████     | 112/221 [00:33<00:31,  3.41it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.41it/s][A
 52%|█████▏    | 114/221 [00:34<00:31,  3.41it/s][A
 52%|█████▏    | 115/221 [00:34<00:31,  3.41it/s][A
 52%|█████▏    | 116/221 [00:34<00:30,  3.41it/s][A
 53%|█████▎    | 117/221 [00:34<00:30,  3.41it/s][A
 53%|█████▎    | 118/221 [00:35<00:30,  3.41it/s][A
 54%|█████▍    | 119/221 [00:35<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:36<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:37<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:37<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:38<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:39<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:39<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:40<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:41<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:41<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:42<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:43<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:44<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:44<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:45<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:45<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:46<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:46<00:19,  3.42it/s][A
 71%|███████   | 157/221 [00:46<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:47<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:48<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:48<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:48<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:49<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:49<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:50<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:50<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:51<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:51<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:52<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:53<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:54<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:55<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:55<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:56<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:57<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:57<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:58<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:59<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [01:00<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:02<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:05<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.42it/s][A100%|██████████| 221/221 [01:05<00:00,  3.38it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:28,  7.71it/s][A
  1%|          | 2/221 [00:00<00:41,  5.24it/s][A
  1%|▏         | 3/221 [00:00<01:16,  2.86it/s][A
  2%|▏         | 5/221 [00:01<00:49,  4.37it/s][A
  3%|▎         | 7/221 [00:01<00:48,  4.45it/s][A
  4%|▎         | 8/221 [00:01<00:52,  4.09it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.81it/s][A
  5%|▍         | 10/221 [00:02<00:48,  4.35it/s][A
  5%|▍         | 11/221 [00:02<00:49,  4.22it/s][A
  5%|▌         | 12/221 [00:02<00:47,  4.37it/s][A
  6%|▌         | 13/221 [00:03<01:19,  2.63it/s][A
  6%|▋         | 14/221 [00:03<01:07,  3.08it/s][A
  7%|▋         | 15/221 [00:04<01:10,  2.92it/s][A
  7%|▋         | 16/221 [00:04<01:18,  2.62it/s][A
  8%|▊         | 17/221 [00:05<01:19,  2.55it/s][A
  8%|▊         | 18/221 [00:05<01:10,  2.89it/s][A
  9%|▊         | 19/221 [00:05<00:55,  3.64it/s][A
  9%|▉         | 20/221 [00:05<00:58,  3.43it/s][A
 10%|▉         | 21/221 [00:05<00:51,  3.90it/s][A
 10%|▉         | 22/221 [00:06<00:47,  4.15it/s][A
 11%|█         | 24/221 [00:06<00:37,  5.27it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.80it/s][A
 12%|█▏        | 26/221 [00:07<00:53,  3.62it/s][A
 12%|█▏        | 27/221 [00:07<00:56,  3.41it/s][A
 13%|█▎        | 28/221 [00:07<01:04,  2.97it/s][A
 13%|█▎        | 29/221 [00:08<01:02,  3.05it/s][A
 14%|█▎        | 30/221 [00:08<01:05,  2.91it/s][A
 14%|█▍        | 31/221 [00:09<01:06,  2.85it/s][A
 14%|█▍        | 32/221 [00:09<00:58,  3.25it/s][A
 15%|█▍        | 33/221 [00:09<00:58,  3.22it/s][A
 15%|█▌        | 34/221 [00:10<01:06,  2.81it/s][A
 16%|█▌        | 35/221 [00:10<01:01,  3.02it/s][A
 16%|█▋        | 36/221 [00:10<00:57,  3.25it/s][A
 17%|█▋        | 37/221 [00:10<00:51,  3.59it/s][A
 17%|█▋        | 38/221 [00:11<00:53,  3.45it/s][A
 18%|█▊        | 39/221 [00:11<00:46,  3.93it/s][A
 18%|█▊        | 40/221 [00:11<00:47,  3.79it/s][A
 19%|█▊        | 41/221 [00:11<00:47,  3.81it/s][A
 19%|█▉        | 42/221 [00:11<00:42,  4.24it/s][A
 19%|█▉        | 43/221 [00:12<00:44,  4.03it/s][A
 20%|█▉        | 44/221 [00:12<00:41,  4.31it/s][A
 20%|██        | 45/221 [00:12<00:53,  3.26it/s][A
 21%|██        | 46/221 [00:13<00:47,  3.71it/s][A
 21%|██▏       | 47/221 [00:13<00:39,  4.39it/s][A
 22%|██▏       | 49/221 [00:13<00:28,  6.04it/s][A
 23%|██▎       | 50/221 [00:13<00:34,  4.92it/s][A
 23%|██▎       | 51/221 [00:14<00:42,  4.04it/s][A
 24%|██▎       | 52/221 [00:14<00:35,  4.75it/s][A
 24%|██▍       | 53/221 [00:14<00:40,  4.16it/s][A
 24%|██▍       | 54/221 [00:14<00:37,  4.43it/s][A
 25%|██▍       | 55/221 [00:15<00:42,  3.90it/s][A
 25%|██▌       | 56/221 [00:15<00:41,  4.02it/s][A
 26%|██▌       | 57/221 [00:15<00:45,  3.64it/s][A
 26%|██▌       | 58/221 [00:15<00:42,  3.81it/s][A
 27%|██▋       | 59/221 [00:16<00:39,  4.08it/s][A
 27%|██▋       | 60/221 [00:16<00:37,  4.27it/s][A
 28%|██▊       | 61/221 [00:16<00:36,  4.44it/s][A
 28%|██▊       | 62/221 [00:16<00:38,  4.11it/s][A
 29%|██▊       | 63/221 [00:16<00:33,  4.65it/s][A
 29%|██▉       | 64/221 [00:17<00:34,  4.53it/s][A
 29%|██▉       | 65/221 [00:17<00:32,  4.86it/s][A
 30%|██▉       | 66/221 [00:17<00:33,  4.63it/s][A
 30%|███       | 67/221 [00:18<00:47,  3.26it/s][A
 31%|███       | 68/221 [00:18<00:42,  3.60it/s][A
 31%|███       | 69/221 [00:18<00:57,  2.64it/s][A
 32%|███▏      | 70/221 [00:19<00:48,  3.10it/s][A
 32%|███▏      | 71/221 [00:19<00:55,  2.72it/s][A
 33%|███▎      | 72/221 [00:20<00:59,  2.50it/s][A
 33%|███▎      | 73/221 [00:20<00:55,  2.66it/s][A
 33%|███▎      | 74/221 [00:20<00:52,  2.81it/s][A
 34%|███▍      | 75/221 [00:20<00:50,  2.87it/s][A
 34%|███▍      | 76/221 [00:21<00:40,  3.61it/s][A
 35%|███▍      | 77/221 [00:21<00:42,  3.37it/s][A
 35%|███▌      | 78/221 [00:21<00:43,  3.27it/s][A
 36%|███▌      | 79/221 [00:22<00:45,  3.10it/s][A
 36%|███▌      | 80/221 [00:22<00:43,  3.25it/s][A
 37%|███▋      | 81/221 [00:22<00:40,  3.45it/s][A
 37%|███▋      | 82/221 [00:22<00:39,  3.56it/s][A
 38%|███▊      | 83/221 [00:23<00:36,  3.77it/s][A
 38%|███▊      | 84/221 [00:23<00:48,  2.83it/s][A
 38%|███▊      | 85/221 [00:24<00:53,  2.54it/s][A
 39%|███▉      | 86/221 [00:24<00:52,  2.58it/s][A
 39%|███▉      | 87/221 [00:25<01:04,  2.09it/s][A
 40%|███▉      | 88/221 [00:25<00:56,  2.37it/s][A
 40%|████      | 89/221 [00:25<00:52,  2.50it/s][A
 41%|████      | 90/221 [00:26<00:57,  2.28it/s][A
 41%|████      | 91/221 [00:26<00:48,  2.66it/s][A
 42%|████▏     | 92/221 [00:26<00:46,  2.76it/s][A
 42%|████▏     | 93/221 [00:27<00:56,  2.26it/s][A
 43%|████▎     | 94/221 [00:27<00:46,  2.76it/s][A
 43%|████▎     | 95/221 [00:28<00:52,  2.39it/s][A
 43%|████▎     | 96/221 [00:28<00:47,  2.64it/s][A
 44%|████▍     | 97/221 [00:28<00:42,  2.94it/s][A
 44%|████▍     | 98/221 [00:29<00:39,  3.13it/s][A
 45%|████▍     | 99/221 [00:29<00:37,  3.24it/s][A
 45%|████▌     | 100/221 [00:29<00:31,  3.90it/s][A
 46%|████▌     | 101/221 [00:29<00:27,  4.34it/s][A
 46%|████▌     | 102/221 [00:30<00:30,  3.95it/s][A
 47%|████▋     | 103/221 [00:30<00:26,  4.38it/s][A
 47%|████▋     | 104/221 [00:30<00:24,  4.79it/s][A
 48%|████▊     | 105/221 [00:30<00:27,  4.16it/s][A
 48%|████▊     | 106/221 [00:31<00:32,  3.50it/s][A
 48%|████▊     | 107/221 [00:31<00:33,  3.40it/s][A
 49%|████▉     | 108/221 [00:31<00:29,  3.88it/s][A
 49%|████▉     | 109/221 [00:31<00:30,  3.73it/s][A
 50%|████▉     | 110/221 [00:32<00:28,  3.94it/s][A
 50%|█████     | 111/221 [00:32<00:30,  3.57it/s][A
 51%|█████     | 112/221 [00:32<00:31,  3.44it/s][A
 51%|█████     | 113/221 [00:32<00:29,  3.66it/s][A
 52%|█████▏    | 115/221 [00:33<00:23,  4.51it/s][A
 52%|█████▏    | 116/221 [00:33<00:21,  4.82it/s][A
 53%|█████▎    | 117/221 [00:33<00:22,  4.53it/s][A
 53%|█████▎    | 118/221 [00:34<00:28,  3.65it/s][A
 54%|█████▍    | 119/221 [00:34<00:30,  3.32it/s][A
 54%|█████▍    | 120/221 [00:34<00:30,  3.35it/s][A
 55%|█████▍    | 121/221 [00:34<00:25,  3.91it/s][A
 55%|█████▌    | 122/221 [00:35<00:24,  4.06it/s][A
 56%|█████▌    | 123/221 [00:35<00:27,  3.60it/s][A
 56%|█████▌    | 124/221 [00:35<00:28,  3.36it/s][A
 57%|█████▋    | 125/221 [00:36<00:36,  2.62it/s][A
 57%|█████▋    | 126/221 [00:36<00:30,  3.16it/s][A
 57%|█████▋    | 127/221 [00:37<00:39,  2.38it/s][A
 58%|█████▊    | 128/221 [00:37<00:33,  2.77it/s][A
 58%|█████▊    | 129/221 [00:37<00:29,  3.17it/s][A
 59%|█████▉    | 130/221 [00:38<00:30,  2.98it/s][A
 59%|█████▉    | 131/221 [00:38<00:25,  3.52it/s][A
 60%|█████▉    | 132/221 [00:38<00:25,  3.53it/s][A
 60%|██████    | 133/221 [00:39<00:31,  2.76it/s][A
 61%|██████    | 134/221 [00:39<00:36,  2.39it/s][A
 61%|██████    | 135/221 [00:39<00:27,  3.08it/s][A
 62%|██████▏   | 136/221 [00:40<00:27,  3.11it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.43it/s][A
 62%|██████▏   | 138/221 [00:40<00:23,  3.54it/s][A
 63%|██████▎   | 139/221 [00:40<00:24,  3.40it/s][A
 63%|██████▎   | 140/221 [00:41<00:21,  3.74it/s][A
 64%|██████▍   | 141/221 [00:41<00:24,  3.28it/s][A
 64%|██████▍   | 142/221 [00:41<00:21,  3.75it/s][A
 65%|██████▍   | 143/221 [00:41<00:23,  3.38it/s][A
 65%|██████▌   | 144/221 [00:42<00:20,  3.71it/s][A
 66%|██████▌   | 145/221 [00:42<00:20,  3.76it/s][A
 66%|██████▌   | 146/221 [00:42<00:21,  3.48it/s][A
 67%|██████▋   | 147/221 [00:42<00:18,  3.92it/s][A
 67%|██████▋   | 148/221 [00:43<00:20,  3.58it/s][A
 67%|██████▋   | 149/221 [00:43<00:18,  3.89it/s][A
 68%|██████▊   | 150/221 [00:43<00:17,  4.02it/s][A
 68%|██████▊   | 151/221 [00:44<00:23,  2.97it/s][A
 69%|██████▉   | 152/221 [00:45<00:31,  2.16it/s][A
 69%|██████▉   | 153/221 [00:45<00:26,  2.60it/s][A
 70%|██████▉   | 154/221 [00:45<00:24,  2.77it/s][A
 70%|███████   | 155/221 [00:45<00:24,  2.74it/s][A
 71%|███████   | 156/221 [00:46<00:21,  3.03it/s][A
 71%|███████   | 157/221 [00:46<00:20,  3.17it/s][A
 71%|███████▏  | 158/221 [00:46<00:22,  2.84it/s][A
 72%|███████▏  | 159/221 [00:47<00:19,  3.24it/s][A
 72%|███████▏  | 160/221 [00:47<00:16,  3.71it/s][A
 73%|███████▎  | 161/221 [00:47<00:14,  4.17it/s][A
 73%|███████▎  | 162/221 [00:47<00:12,  4.91it/s][A
 74%|███████▍  | 163/221 [00:47<00:13,  4.38it/s][A
 74%|███████▍  | 164/221 [00:47<00:12,  4.74it/s][A
 75%|███████▍  | 165/221 [00:48<00:10,  5.32it/s][A
 75%|███████▌  | 166/221 [00:48<00:13,  4.06it/s][A
 76%|███████▌  | 167/221 [00:48<00:11,  4.61it/s][A
 76%|███████▌  | 168/221 [00:48<00:11,  4.76it/s][A
 76%|███████▋  | 169/221 [00:48<00:09,  5.47it/s][A
 77%|███████▋  | 170/221 [00:49<00:18,  2.83it/s][A
 77%|███████▋  | 171/221 [00:50<00:17,  2.78it/s][A
 78%|███████▊  | 172/221 [00:50<00:16,  2.91it/s][A
 78%|███████▊  | 173/221 [00:50<00:16,  2.92it/s][A
 79%|███████▊  | 174/221 [00:50<00:14,  3.25it/s][A
 79%|███████▉  | 175/221 [00:51<00:14,  3.18it/s][A
 80%|███████▉  | 176/221 [00:51<00:13,  3.36it/s][A
 80%|████████  | 177/221 [00:51<00:11,  3.79it/s][A
 81%|████████  | 178/221 [00:52<00:17,  2.42it/s][A
 81%|████████  | 179/221 [00:52<00:15,  2.73it/s][A
 81%|████████▏ | 180/221 [00:52<00:12,  3.24it/s][A
 82%|████████▏ | 181/221 [00:53<00:12,  3.20it/s][A
 82%|████████▏ | 182/221 [00:53<00:12,  3.12it/s][A
 83%|████████▎ | 183/221 [00:54<00:13,  2.79it/s][A
 83%|████████▎ | 184/221 [00:54<00:13,  2.74it/s][A
 84%|████████▍ | 186/221 [00:54<00:11,  3.07it/s][A
 85%|████████▍ | 187/221 [00:55<00:11,  3.07it/s][A
 85%|████████▌ | 188/221 [00:55<00:10,  3.05it/s][A
 86%|████████▌ | 189/221 [00:55<00:09,  3.47it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.15it/s][A
 86%|████████▋ | 191/221 [00:56<00:07,  3.83it/s][A
 87%|████████▋ | 192/221 [00:56<00:07,  3.89it/s][A
 87%|████████▋ | 193/221 [00:56<00:06,  4.47it/s][A
 88%|████████▊ | 194/221 [00:56<00:06,  4.25it/s][A
 88%|████████▊ | 195/221 [00:57<00:06,  4.16it/s][A
 89%|████████▊ | 196/221 [00:57<00:09,  2.74it/s][A
 89%|████████▉ | 197/221 [00:58<00:09,  2.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:09,  2.47it/s][A
 90%|█████████ | 199/221 [00:59<00:07,  2.95it/s][A
 90%|█████████ | 200/221 [00:59<00:06,  3.19it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.57it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.52it/s][A
 92%|█████████▏| 203/221 [00:59<00:04,  3.85it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.87it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.86it/s][A
 93%|█████████▎| 206/221 [01:01<00:05,  2.78it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  3.15it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.81it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.99it/s][A
 95%|█████████▌| 210/221 [01:02<00:03,  3.48it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.70it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.26it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.17it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.12it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.23it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.18it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.28it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.35it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.21it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.70it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.46it/s][A100%|██████████| 221/221 [01:05<00:00,  3.38it/s]
09/17/2024 04:24:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 799--===========

09/17/2024 04:24:29 - INFO - __main__ -   {'area_r1': 39.8, 'area_recall': '39.8/65.0/74.7', 'area_ravg': 59.8}
09/17/2024 04:24:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 799--===========

09/17/2024 04:24:29 - INFO - __main__ -   {'forward_r1': 37.7, 'forward_recall': '37.7/66.3/77.0', 'forward_ravg': 60.3}
09/17/2024 04:24:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 799--===========

09/17/2024 04:24:29 - INFO - __main__ -   {'area_video_r1': 39.4, 'area_video_recall': '39.4/68.9/78.7', 'area_video_ravg': 62.3}
09/17/2024 04:24:29 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 299=======

09/17/2024 04:24:29 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 04:24:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 799--===========

09/17/2024 04:24:29 - INFO - __main__ -   {'area_video_r1': 53.3, 'area_video_recall': '53.3/75.5/82.9', 'area_video_ravg': 70.6, 'area_video_back_r1': 48.0, 'area_video_back_recall': '48.0/74.4/82.0', 'area_video_back_ravg': 68.1}
09/17/2024 04:24:29 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 549=======

09/17/2024 04:24:29 - INFO - __main__ -   {'area_video_r1': 54.1, 'area_video_recall': '54.1/75.5/82.4', 'area_video_ravg': 70.6, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.5/82.1', 'area_video_back_ravg': 68.7}
09/17/2024 04:24:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 799--===========

09/17/2024 04:24:29 - INFO - __main__ -   {'video_r1': 36.5, 'video_recall': '36.5/63.8/74.4', 'video_ravg': 58.3}
09/17/2024 04:24:29 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 749=======

09/17/2024 04:24:29 - INFO - __main__ -   {'video_r1': 37.6, 'video_recall': '37.6/64.6/74.3', 'video_ravg': 58.8}
09/17/2024 04:24:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 799--===========

09/17/2024 04:24:29 - INFO - __main__ -   {'video_r1': 52.9, 'video_recall': '52.9/75.1/83.0', 'video_ravg': 70.4}
09/17/2024 04:24:29 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 549=======

09/17/2024 04:24:29 - INFO - __main__ -   {'video_r1': 54.5, 'video_recall': '54.5/76.1/83.4', 'video_ravg': 71.3}
[h264 @ 0x55e2404d5380] mmco: unref short failure
09/17/2024 04:24:50 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.011660946533083916, 'loss_ret%tv%ta--finetune_area/loss_area': 1.140604019165039, 'loss_ret%tv%ta--finetune_area/total_loss': 1.152264952659607}
 27%|██▋       | 800/2910 [5:03:06<77:24:56, 132.08s/it] 28%|██▊       | 801/2910 [5:03:10<54:48:52, 93.57s/it] [h264 @ 0x55a31f80f400] mmco: unref short failure
 28%|██▊       | 802/2910 [5:03:14<39:02:54, 66.69s/it][h264 @ 0x55a30fcd0400] mmco: unref short failure
[h264 @ 0x55a30fcd0400] mmco: unref short failure
[h264 @ 0x55a30fcd0400] mmco: unref short failure
[h264 @ 0x55a30fcd0400] mmco: unref short failure
 28%|██▊       | 803/2910 [5:03:18<28:00:43, 47.86s/it][h264 @ 0x55b5bfe19540] mmco: unref short failure
[h264 @ 0x55b5bfe19540] mmco: unref short failure
 28%|██▊       | 804/2910 [5:03:22<20:23:46, 34.87s/it] 28%|██▊       | 805/2910 [5:03:27<15:08:50, 25.91s/it] 28%|██▊       | 806/2910 [5:03:32<11:27:22, 19.60s/it] 28%|██▊       | 807/2910 [5:03:38<9:01:52, 15.46s/it] [h264 @ 0x560741a64b00] mmco: unref short failure
[h264 @ 0x560741a64b00] mmco: unref short failure
 28%|██▊       | 808/2910 [5:03:43<7:11:29, 12.32s/it][h264 @ 0x56074176c6c0] mmco: unref short failure
 28%|██▊       | 809/2910 [5:03:50<6:14:38, 10.70s/it]09/17/2024 04:25:37 - INFO - __main__ -   current idx _9yTXjXc3Ko.34 from finetune_area returns wrong image/video, use 103383 instead.
 28%|██▊       | 810/2910 [5:03:55<5:16:47,  9.05s/it] 28%|██▊       | 811/2910 [5:04:01<4:43:18,  8.10s/it][h264 @ 0x55e258c73840] mmco: unref short failure
[h264 @ 0x55e258c73840] mmco: unref short failure
 28%|██▊       | 812/2910 [5:04:07<4:17:48,  7.37s/it][h264 @ 0x560762b51d80] mmco: unref short failure
[h264 @ 0x560762b51d80] mmco: unref short failure
 28%|██▊       | 813/2910 [5:04:12<3:53:27,  6.68s/it] 28%|██▊       | 814/2910 [5:04:17<3:39:56,  6.30s/it][h264 @ 0x5607417d8540] mmco: unref short failure
09/17/2024 04:26:07 - INFO - __main__ -   current idx gVhwSbu4UfU.1 from finetune_area returns wrong image/video, use 63688 instead.
 28%|██▊       | 815/2910 [5:04:23<3:29:44,  6.01s/it][h264 @ 0x55b5aad1f300] mmco: unref short failure
[h264 @ 0x55b5aad1f300] mmco: unref short failure
[h264 @ 0x55e2485bb180] mmco: unref short failure
[h264 @ 0x55e2485bb180] mmco: unref short failure
[h264 @ 0x55e2485bb180] mmco: unref short failure
[h264 @ 0x55e2485bb180] mmco: unref short failure
[h264 @ 0x55b5ab11f680] mmco: unref short failure
[h264 @ 0x55b5ab11f680] mmco: unref short failure
[h264 @ 0x55b5ab11f680] mmco: unref short failure
[h264 @ 0x55a30fa1a140] mmco: unref short failure
[h264 @ 0x55a30fa1a140] mmco: unref short failure
[h264 @ 0x55a32d222940] mmco: unref short failure
[h264 @ 0x55a32d222940] mmco: unref short failure
[h264 @ 0x56075164fb00] mmco: unref short failure
[h264 @ 0x56075164fb00] mmco: unref short failure
09/17/2024 04:26:45 - INFO - __main__ -   current idx TE5UzQ5S57U.27 from finetune_area returns wrong image/video, use 105471 instead.
[h264 @ 0x55b5aac7bd80] mmco: unref short failure
[h264 @ 0x55b5aac7bd80] mmco: unref short failure
[h264 @ 0x55a3172805c0] mmco: unref short failure
[h264 @ 0x5607620efd00] mmco: unref short failure
[h264 @ 0x5607634170c0] mmco: unref short failure
[h264 @ 0x5607634170c0] mmco: unref short failure
 28%|██▊       | 816/2910 [5:05:21<12:39:48, 21.77s/it][h264 @ 0x560755e89e00] mmco: unref short failure
[h264 @ 0x560755e89e00] mmco: unref short failure
[h264 @ 0x560747714780] mmco: unref short failure
[h264 @ 0x560747714780] mmco: unref short failure
 28%|██▊       | 817/2910 [5:05:29<10:10:10, 17.49s/it] 28%|██▊       | 818/2910 [5:05:37<8:33:38, 14.73s/it]  28%|██▊       | 819/2910 [5:05:43<6:58:56, 12.02s/it][h264 @ 0x560741a87300] mmco: unref short failure
[h264 @ 0x560741a87300] mmco: unref short failure
[h264 @ 0x560741a87300] mmco: unref short failure
[h264 @ 0x560741a87300] mmco: unref short failure
[h264 @ 0x55e2514b2f00] mmco: unref short failure
[h264 @ 0x55e2514b2f00] mmco: unref short failure
[h264 @ 0x55e2555e8980] mmco: unref short failure
[h264 @ 0x55e2555e8980] mmco: unref short failure
[h264 @ 0x560755e8a000] mmco: unref short failure
[h264 @ 0x560755e8a000] mmco: unref short failure
[h264 @ 0x55e2562b75c0] mmco: unref short failure
[h264 @ 0x56075f2d3b80] mmco: unref short failure
[h264 @ 0x56075f2d3b80] mmco: unref short failure
 28%|██▊       | 820/2910 [5:06:02<8:15:48, 14.23s/it] 28%|██▊       | 821/2910 [5:06:07<6:41:42, 11.54s/it][h264 @ 0x55b5b2a7ce40] mmco: unref short failure
[h264 @ 0x55b5b2a7ce40] mmco: unref short failure
 28%|██▊       | 822/2910 [5:06:15<5:57:48, 10.28s/it] 28%|██▊       | 823/2910 [5:06:20<5:07:13,  8.83s/it][h264 @ 0x560756542f80] mmco: unref short failure
[h264 @ 0x560756542f80] mmco: unref short failure
09/17/2024 04:28:27 - INFO - __main__ -   current idx RySLUDaYU80.14 from finetune_area returns wrong image/video, use 70644 instead.
[h264 @ 0x55e24dd5f800] mmco: unref short failure
[h264 @ 0x55e24dd5f800] mmco: unref short failure
[h264 @ 0x55e24dd5f800] mmco: unref short failure
[h264 @ 0x55e24dd5f800] mmco: unref short failure
[h264 @ 0x55e24dd5f800] mmco: unref short failure
[h264 @ 0x55e24dd5f800] mmco: unref short failure
[h264 @ 0x55e24dd5f800] mmco: unref short failure
[h264 @ 0x55e24dd5f800] mmco: unref short failure
[h264 @ 0x55b5b1094580] mmco: unref short failure
[h264 @ 0x55b5b1094580] mmco: unref short failure
[h264 @ 0x56074154cd00] mmco: unref short failure
[h264 @ 0x56074154cd00] mmco: unref short failure
[h264 @ 0x55a31215fac0] mmco: unref short failure
09/17/2024 04:28:38 - INFO - __main__ -   current idx q2-SltghBGI.3 from finetune_area returns wrong image/video, use 128584 instead.
[h264 @ 0x55b5aaa6f0c0] mmco: unref short failure
[h264 @ 0x55e250130f80] mmco: unref short failure
[h264 @ 0x55e23939ae00] mmco: unref short failure
[h264 @ 0x55e240a4b640] mmco: unref short failure
[h264 @ 0x55e251980380] mmco: unref short failure
[h264 @ 0x55e251980380] mmco: unref short failure
[h264 @ 0x55b5b2697500] mmco: unref short failure
[h264 @ 0x55b5b2697500] mmco: unref short failure
 28%|██▊       | 824/2910 [5:07:39<17:17:20, 29.84s/it][h264 @ 0x5607432df1c0] mmco: unref short failure
[h264 @ 0x5607432df1c0] mmco: unref short failure
[h264 @ 0x5607432df1c0] mmco: unref short failure
[h264 @ 0x5607432df1c0] mmco: unref short failure
[h264 @ 0x55a30f12e7c0] mmco: unref short failure
 28%|██▊       | 825/2910 [5:07:57<15:11:40, 26.24s/it][h264 @ 0x55e252d8d000] mmco: unref short failure
[h264 @ 0x55e252d8d000] mmco: unref short failure
[h264 @ 0x55e252d8d000] mmco: unref short failure
[h264 @ 0x55e252d8d000] mmco: unref short failure
[h264 @ 0x55b5b4a0f3c0] mmco: unref short failure
[h264 @ 0x55b5b4a0f3c0] mmco: unref short failure
[h264 @ 0x55b5b4a0f3c0] mmco: unref short failure
[h264 @ 0x55b5b4a0f3c0] mmco: unref short failure
[h264 @ 0x56074452e580] mmco: unref short failure
[h264 @ 0x56074452e580] mmco: unref short failure
 28%|██▊       | 826/2910 [5:08:19<14:24:38, 24.89s/it][h264 @ 0x5607620f0140] mmco: unref short failure
[h264 @ 0x55a314877a00] mmco: unref short failure
[h264 @ 0x55a314877a00] mmco: unref short failure
 28%|██▊       | 827/2910 [5:08:23<10:56:22, 18.91s/it] 28%|██▊       | 828/2910 [5:08:37<9:58:57, 17.26s/it]  28%|██▊       | 829/2910 [5:08:42<7:55:47, 13.72s/it]09/17/2024 04:30:29 - INFO - __main__ -   current idx 5l1_DENmn_k.23 from finetune_area returns wrong image/video, use 7698 instead.
 29%|██▊       | 830/2910 [5:08:48<6:29:40, 11.24s/it][h264 @ 0x55b5af1b26c0] mmco: unref short failure
 29%|██▊       | 831/2910 [5:08:54<5:38:42,  9.78s/it][h264 @ 0x55e237f4af40] mmco: unref short failure
[h264 @ 0x55b5ca0a0e80] mmco: unref short failure
[h264 @ 0x55b5ca0a0e80] mmco: unref short failure
[h264 @ 0x55e24b7c9840] mmco: unref short failure
[h264 @ 0x55e24b7c9840] mmco: unref short failure
[h264 @ 0x55e24b7c9840] mmco: unref short failure
[h264 @ 0x56074e8f9000] mmco: unref short failure
[h264 @ 0x55a32b15d600] mmco: unref short failure
[h264 @ 0x55a32b15d600] mmco: unref short failure
[h264 @ 0x55b5cad32d80] mmco: unref short failure
[h264 @ 0x55e2510bf440] mmco: unref short failure
[h264 @ 0x55e2377f1180] mmco: unref short failure
[h264 @ 0x55e2377f1180] mmco: unref short failure
[h264 @ 0x560743bab200] mmco: unref short failure
[h264 @ 0x560743bab200] mmco: unref short failure
 29%|██▊       | 832/2910 [5:10:10<17:08:50, 29.71s/it][h264 @ 0x55b5b7733cc0] mmco: unref short failure
[h264 @ 0x55b5b7733cc0] mmco: unref short failure
[h264 @ 0x55e24a784780] mmco: unref short failure
[h264 @ 0x55b5beda3640] mmco: unref short failure
[h264 @ 0x55b5beda3640] mmco: unref short failure
[h264 @ 0x55b5beda3640] mmco: unref short failure
[h264 @ 0x55b5beda3640] mmco: unref short failure
[h264 @ 0x55e25514d0c0] mmco: unref short failure
[h264 @ 0x55e25514d0c0] mmco: unref short failure
[h264 @ 0x56075c553ac0] mmco: unref short failure
[h264 @ 0x56075c553ac0] mmco: unref short failure
 29%|██▊       | 833/2910 [5:10:36<16:20:42, 28.33s/it][h264 @ 0x56074a35db00] mmco: unref short failure
[h264 @ 0x55a310a45980] mmco: unref short failure
[h264 @ 0x55a310a45980] mmco: unref short failure
[h264 @ 0x55e24a04c040] mmco: unref short failure
[h264 @ 0x55e24a04c040] mmco: unref short failure
 29%|██▊       | 834/2910 [5:10:55<14:47:30, 25.65s/it][h264 @ 0x55b5ada6e400] mmco: unref short failure
 29%|██▊       | 835/2910 [5:11:00<11:12:22, 19.44s/it][h264 @ 0x55a32936ef80] mmco: unref short failure
[h264 @ 0x55a32936ef80] mmco: unref short failure
[h264 @ 0x55a32936ef80] mmco: unref short failure
[h264 @ 0x55a32936ef80] mmco: unref short failure
 29%|██▊       | 836/2910 [5:11:06<8:57:27, 15.55s/it]  29%|██▉       | 837/2910 [5:11:12<7:14:23, 12.57s/it] 29%|██▉       | 838/2910 [5:11:20<6:24:46, 11.14s/it] 29%|██▉       | 839/2910 [5:11:25<5:26:30,  9.46s/it][h264 @ 0x55e2436f6080] mmco: unref short failure
[h264 @ 0x55e2436f6080] mmco: unref short failure
[h264 @ 0x55e23fa73c80] mmco: unref short failure
[h264 @ 0x55e23fa73c80] mmco: unref short failure
[h264 @ 0x55a327072400] mmco: unref short failure
[h264 @ 0x55a327072400] mmco: unref short failure
[h264 @ 0x55a327072400] mmco: unref short failure
[h264 @ 0x55a327072400] mmco: unref short failure
[h264 @ 0x560762384b00] mmco: unref short failure
[h264 @ 0x560762384b00] mmco: unref short failure
[h264 @ 0x560740c03f80] mmco: unref short failure
[h264 @ 0x560740c03f80] mmco: unref short failure
[h264 @ 0x55e2383a9400] mmco: unref short failure
[h264 @ 0x55e2383a9400] mmco: unref short failure
[h264 @ 0x55a332c3ae80] mmco: unref short failure
[h264 @ 0x55e237f4b880] mmco: unref short failure
[h264 @ 0x55e23b5160c0] mmco: unref short failure
[h264 @ 0x55e23b5160c0] mmco: unref short failure
[h264 @ 0x55a30ec6fe80] mmco: unref short failure
[h264 @ 0x55a30ec6fe80] mmco: unref short failure
[h264 @ 0x56075954fa80] mmco: unref short failure
[h264 @ 0x56075954fa80] mmco: unref short failure
[h264 @ 0x55b5bc58c240] mmco: unref short failure
[h264 @ 0x55b5bc58c240] mmco: unref short failure
 29%|██▉       | 840/2910 [5:12:49<18:12:45, 31.67s/it][h264 @ 0x56075730af40] mmco: unref short failure
[h264 @ 0x560741a64680] mmco: unref short failure
[h264 @ 0x560741a64680] mmco: unref short failure
[h264 @ 0x560757313e80] mmco: unref short failure
[h264 @ 0x55a32143bec0] mmco: unref short failure
[h264 @ 0x55a32143bec0] mmco: unref short failure
[h264 @ 0x560755b27500] mmco: unref short failure
[h264 @ 0x560755b27500] mmco: unref short failure
 29%|██▉       | 841/2910 [5:13:13<16:50:08, 29.29s/it] 29%|██▉       | 842/2910 [5:13:22<13:19:32, 23.20s/it][h264 @ 0x55a328de4c00] mmco: unref short failure
[h264 @ 0x55a31ecaf2c0] mmco: unref short failure
 29%|██▉       | 843/2910 [5:13:27<10:19:24, 17.98s/it] 29%|██▉       | 844/2910 [5:13:34<8:25:04, 14.67s/it]  29%|██▉       | 845/2910 [5:13:40<6:54:27, 12.04s/it][h264 @ 0x560741da5b80] mmco: unref short failure
[h264 @ 0x560741da5b80] mmco: unref short failure
[h264 @ 0x560748ba2c00] mmco: unref short failure
 29%|██▉       | 846/2910 [5:13:52<6:49:10, 11.89s/it] 29%|██▉       | 847/2910 [5:13:57<5:40:14,  9.90s/it][h264 @ 0x55b5bdb9e4c0] mmco: unref short failure
[h264 @ 0x55b5bdb9e4c0] mmco: unref short failure
[h264 @ 0x55b5bdb9e4c0] mmco: unref short failure
[h264 @ 0x55b5bdb9e4c0] mmco: unref short failure
[h264 @ 0x560751319b00] mmco: unref short failure
[h264 @ 0x560751319b00] mmco: unref short failure
[h264 @ 0x55a319b3f340] mmco: unref short failure
[h264 @ 0x560745821a00] mmco: unref short failure
[h264 @ 0x55b5b6859a00] mmco: unref short failure
[h264 @ 0x56074e5aac40] mmco: unref short failure
[h264 @ 0x56074e5aac40] mmco: unref short failure
[h264 @ 0x55b5aa1c4540] mmco: unref short failure
[h264 @ 0x560757f0be40] mmco: unref short failure
[h264 @ 0x560757f0be40] mmco: unref short failure
09/17/2024 04:36:17 - INFO - __main__ -   current idx TTyNNu1mIgY.26 from finetune_area returns wrong image/video, use 128569 instead.
[h264 @ 0x5607423ff340] mmco: unref short failure
[h264 @ 0x5607423ff340] mmco: unref short failure
[h264 @ 0x55b5ad567b80] mmco: unref short failure
[h264 @ 0x5607486c7940] mmco: unref short failure
[h264 @ 0x5607486c7940] mmco: unref short failure
[h264 @ 0x55b5b338e340] mmco: unref short failure
[h264 @ 0x55b5b338e340] mmco: unref short failure
[h264 @ 0x55a310bde200] mmco: unref short failure
[h264 @ 0x55e237ceeb40] mmco: unref short failure
[h264 @ 0x55e237ceeb40] mmco: unref short failure
[h264 @ 0x560755454480] mmco: unref short failure
[h264 @ 0x560755454480] mmco: unref short failure
[h264 @ 0x55a31f64ce40] mmco: unref short failure
[h264 @ 0x55e243af6780] mmco: unref short failure
[h264 @ 0x55e243af6780] mmco: unref short failure
[h264 @ 0x55b5b1941280] mmco: unref short failure
[h264 @ 0x55b5b1941280] mmco: unref short failure
 29%|██▉       | 848/2910 [5:15:27<19:27:15, 33.96s/it][h264 @ 0x55b5bc136ec0] mmco: unref short failure
[h264 @ 0x55b5bc136ec0] mmco: unref short failure
[h264 @ 0x55b5bc136ec0] mmco: unref short failure
[h264 @ 0x55b5bc136ec0] mmco: unref short failure
[h264 @ 0x55a31bd8f900] mmco: unref short failure
[h264 @ 0x55b5ac76ac40] mmco: unref short failure
[h264 @ 0x55b5ac76ac40] mmco: unref short failure
[h264 @ 0x56074a260380] mmco: unref short failure
[h264 @ 0x56074a260380] mmco: unref short failure
[h264 @ 0x55a30f018800] mmco: unref short failure
[h264 @ 0x55a30f018800] mmco: unref short failure
[h264 @ 0x55b5afeb5cc0] mmco: unref short failure
[h264 @ 0x55b5afeb5cc0] mmco: unref short failure
 29%|██▉       | 849/2910 [5:15:43<16:23:47, 28.64s/it]09/17/2024 04:37:29 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 04:37:29 - INFO - __main__ -   start running ret%tva validation...
[h264 @ 0x55e245b85f00] mmco: unref short failure
[h264 @ 0x55e245b85f00] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55b5abe232c0] mmco: unref short failure
[h264 @ 0x55b5abe232c0] mmco: unref short failure
[h264 @ 0x560751fb1a00] mmco: unref short failure
[h264 @ 0x560751fb1a00] mmco: unref short failure
[h264 @ 0x55e240510840] mmco: unref short failure
[h264 @ 0x55e240510840] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55b5af1081c0] mmco: unref short failure
[h264 @ 0x55b5af1081c0] mmco: unref short failure
[h264 @ 0x55b5abcd7f00] mmco: unref short failure
[h264 @ 0x55b5be6d8cc0] mmco: unref short failure
[h264 @ 0x56075875a300] mmco: unref short failure
[h264 @ 0x55e247238f40] mmco: unref short failure
[h264 @ 0x55b5bd605480] mmco: unref short failure
[h264 @ 0x55b5bd605480] mmco: unref short failure
[h264 @ 0x55b5c8adb8c0] mmco: unref short failure
[h264 @ 0x55b5c8adb8c0] mmco: unref short failure
[h264 @ 0x5607443cc3c0] mmco: unref short failure
[h264 @ 0x5607443cc3c0] mmco: unref short failure
[h264 @ 0x5607443cc3c0] mmco: unref short failure
[h264 @ 0x5607443cc3c0] mmco: unref short failure
[h264 @ 0x5607443cc3c0] mmco: unref short failure
[h264 @ 0x5607443cc3c0] mmco: unref short failure
[h264 @ 0x56074db4fc80] mmco: unref short failure
[h264 @ 0x56074db4fc80] mmco: unref short failure
[h264 @ 0x55a31780a800] mmco: unref short failure
[h264 @ 0x55a31780a800] mmco: unref short failure
[h264 @ 0x55a31627ba00] mmco: unref short failure
[h264 @ 0x55a31500a4c0] mmco: unref short failure
[h264 @ 0x560747c6e4c0] mmco: unref short failure
[h264 @ 0x560747c6e4c0] mmco: unref short failure
[h264 @ 0x55a3285117c0] mmco: unref short failure
not have audios CqzowavAOpc.38

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<02:37,  1.40it/s][A[h264 @ 0x5607481e02c0] mmco: unref short failure
[h264 @ 0x5607481e02c0] mmco: unref short failure
[h264 @ 0x55b5bd8e87c0] mmco: unref short failure

  1%|          | 2/221 [00:01<02:12,  1.65it/s][A
  1%|▏         | 3/221 [00:01<01:36,  2.27it/s][A
  2%|▏         | 5/221 [00:01<00:51,  4.22it/s][A
  3%|▎         | 6/221 [00:01<00:49,  4.31it/s][A
  3%|▎         | 7/221 [00:02<00:48,  4.37it/s][A
  4%|▎         | 8/221 [00:02<01:19,  2.68it/s][A
  4%|▍         | 9/221 [00:03<01:12,  2.93it/s][A
  5%|▍         | 10/221 [00:03<01:15,  2.80it/s][A
  5%|▌         | 12/221 [00:04<01:10,  2.96it/s][A
  6%|▌         | 13/221 [00:04<01:01,  3.37it/s][A[h264 @ 0x5607596d64c0] mmco: unref short failure
[h264 @ 0x5607596d64c0] mmco: unref short failure

  6%|▋         | 14/221 [00:06<02:34,  1.34it/s][A
  7%|▋         | 15/221 [00:06<02:03,  1.67it/s][A
  7%|▋         | 16/221 [00:06<01:46,  1.92it/s][A
  8%|▊         | 17/221 [00:07<01:30,  2.26it/s][A
  8%|▊         | 18/221 [00:07<01:19,  2.56it/s][A
  9%|▊         | 19/221 [00:07<01:07,  2.99it/s][A
  9%|▉         | 20/221 [00:07<01:04,  3.14it/s][A
 10%|▉         | 21/221 [00:08<00:59,  3.34it/s][A
 10%|▉         | 22/221 [00:08<00:51,  3.87it/s][A
 10%|█         | 23/221 [00:08<00:43,  4.60it/s][A
 11%|█         | 24/221 [00:08<00:38,  5.10it/s][A[h264 @ 0x55e240d565c0] mmco: unref short failure
[h264 @ 0x55e240d565c0] mmco: unref short failure

 11%|█▏        | 25/221 [00:08<00:36,  5.38it/s][A
 12%|█▏        | 26/221 [00:08<00:39,  4.97it/s][A
 12%|█▏        | 27/221 [00:09<00:34,  5.61it/s][A
 13%|█▎        | 28/221 [00:09<00:53,  3.64it/s][A
 13%|█▎        | 29/221 [00:09<00:42,  4.47it/s][A
 14%|█▎        | 30/221 [00:09<00:45,  4.21it/s][A
 14%|█▍        | 31/221 [00:10<00:51,  3.70it/s][A[h264 @ 0x55e240d56180] mmco: unref short failure
[h264 @ 0x55e240d56180] mmco: unref short failure

 15%|█▍        | 33/221 [00:10<00:46,  4.07it/s][A
 15%|█▌        | 34/221 [00:10<00:40,  4.63it/s][A
 16%|█▌        | 35/221 [00:10<00:36,  5.14it/s][A
 16%|█▋        | 36/221 [00:11<00:37,  4.97it/s][A[h264 @ 0x55a327a00380] mmco: unref short failure
[h264 @ 0x55a327a00380] mmco: unref short failure

 17%|█▋        | 37/221 [00:11<01:06,  2.77it/s][A
 17%|█▋        | 38/221 [00:12<01:09,  2.64it/s][A
 18%|█▊        | 39/221 [00:12<00:54,  3.33it/s][A
 18%|█▊        | 40/221 [00:12<00:52,  3.43it/s][A
 19%|█▊        | 41/221 [00:12<00:42,  4.24it/s][A
 19%|█▉        | 42/221 [00:13<00:50,  3.55it/s][A
 19%|█▉        | 43/221 [00:13<00:41,  4.24it/s][A
 20%|█▉        | 44/221 [00:13<00:35,  4.99it/s][A[h264 @ 0x560750b68040] mmco: unref short failure
[h264 @ 0x560750b68040] mmco: unref short failure

 20%|██        | 45/221 [00:14<01:36,  1.83it/s][A
 21%|██        | 46/221 [00:15<01:31,  1.90it/s][A
 21%|██▏       | 47/221 [00:15<01:38,  1.76it/s][A
 22%|██▏       | 49/221 [00:16<01:06,  2.60it/s][A[h264 @ 0x56075b391a00] mmco: unref short failure

 23%|██▎       | 50/221 [00:16<00:57,  2.97it/s][A
 23%|██▎       | 51/221 [00:16<00:47,  3.56it/s][A
 24%|██▎       | 52/221 [00:16<00:43,  3.92it/s][A
 24%|██▍       | 53/221 [00:16<00:37,  4.46it/s][A
 24%|██▍       | 54/221 [00:18<02:00,  1.39it/s][A
 25%|██▍       | 55/221 [00:19<01:43,  1.60it/s][A
 25%|██▌       | 56/221 [00:19<01:23,  1.99it/s][A
 26%|██▌       | 57/221 [00:19<01:07,  2.45it/s][A
 26%|██▌       | 58/221 [00:19<00:53,  3.04it/s][A
 27%|██▋       | 59/221 [00:20<00:46,  3.46it/s][A
 27%|██▋       | 60/221 [00:20<00:51,  3.10it/s][A
 28%|██▊       | 61/221 [00:20<00:47,  3.39it/s][A
 28%|██▊       | 62/221 [00:21<00:51,  3.11it/s][A
 29%|██▊       | 63/221 [00:21<00:52,  3.02it/s][A
 29%|██▉       | 64/221 [00:21<00:47,  3.34it/s][A
 29%|██▉       | 65/221 [00:21<00:40,  3.88it/s][A
 30%|██▉       | 66/221 [00:22<00:45,  3.40it/s][A
 30%|███       | 67/221 [00:22<00:48,  3.15it/s][A
 31%|███       | 68/221 [00:22<00:40,  3.79it/s][A
 31%|███       | 69/221 [00:23<01:01,  2.46it/s][A
 32%|███▏      | 70/221 [00:23<00:49,  3.06it/s][A
 32%|███▏      | 71/221 [00:26<02:50,  1.14s/it][A
 33%|███▎      | 72/221 [00:26<02:08,  1.16it/s][A
 33%|███▎      | 73/221 [00:27<01:42,  1.44it/s][A
 33%|███▎      | 74/221 [00:27<01:18,  1.86it/s][A
 34%|███▍      | 75/221 [00:27<01:08,  2.12it/s][A
 34%|███▍      | 76/221 [00:27<01:00,  2.39it/s][A
 35%|███▍      | 77/221 [00:28<00:49,  2.89it/s][A
 35%|███▌      | 78/221 [00:28<00:46,  3.11it/s][A
 36%|███▌      | 79/221 [00:29<01:03,  2.24it/s][A
 36%|███▌      | 80/221 [00:29<00:49,  2.86it/s][A
 37%|███▋      | 81/221 [00:29<00:42,  3.26it/s][A
 37%|███▋      | 82/221 [00:29<00:35,  3.90it/s][A[h264 @ 0x55e237e1fc80] mmco: unref short failure

 38%|███▊      | 83/221 [00:29<00:34,  4.01it/s][A[h264 @ 0x55a324b57940] mmco: unref short failure
[h264 @ 0x55a324b57940] mmco: unref short failure

 38%|███▊      | 84/221 [00:30<00:35,  3.87it/s][A
 38%|███▊      | 85/221 [00:30<00:30,  4.43it/s][A
 39%|███▉      | 86/221 [00:30<00:31,  4.24it/s][A
 39%|███▉      | 87/221 [00:31<00:49,  2.73it/s][A
 40%|███▉      | 88/221 [00:31<00:49,  2.69it/s][A[h264 @ 0x56074bd421c0] mmco: unref short failure
[h264 @ 0x56074bd421c0] mmco: unref short failure

 40%|████      | 89/221 [00:34<02:20,  1.07s/it][A
 41%|████      | 90/221 [00:34<01:48,  1.21it/s][A
 42%|████▏     | 92/221 [00:34<01:06,  1.93it/s][A
 42%|████▏     | 93/221 [00:35<01:05,  1.94it/s][A
 43%|████▎     | 94/221 [00:35<00:59,  2.13it/s][A
 43%|████▎     | 95/221 [00:35<00:51,  2.45it/s][A
 43%|████▎     | 96/221 [00:36<00:47,  2.61it/s][A
 44%|████▍     | 97/221 [00:36<00:45,  2.75it/s][A
 44%|████▍     | 98/221 [00:36<00:43,  2.80it/s][A
 45%|████▍     | 99/221 [00:37<00:39,  3.08it/s][A
 45%|████▌     | 100/221 [00:37<00:38,  3.12it/s][A
 46%|████▌     | 101/221 [00:37<00:32,  3.68it/s][A
 46%|████▌     | 102/221 [00:37<00:36,  3.27it/s][A[h264 @ 0x55b5aa591c00] mmco: unref short failure
[h264 @ 0x55b5aa591c00] mmco: unref short failure

 47%|████▋     | 103/221 [00:38<00:32,  3.62it/s][A
 47%|████▋     | 104/221 [00:38<00:30,  3.82it/s][A
 48%|████▊     | 105/221 [00:38<00:34,  3.32it/s][A[h264 @ 0x55e24b2248c0] mmco: unref short failure
[h264 @ 0x55e24b2248c0] mmco: unref short failure

 48%|████▊     | 106/221 [00:39<00:53,  2.14it/s][A
 48%|████▊     | 107/221 [00:39<00:42,  2.69it/s][A
 49%|████▉     | 108/221 [00:39<00:36,  3.08it/s][A
 49%|████▉     | 109/221 [00:40<00:36,  3.07it/s][A
 50%|████▉     | 110/221 [00:40<00:34,  3.23it/s][A
 50%|█████     | 111/221 [00:41<00:38,  2.85it/s][A
 51%|█████     | 112/221 [00:41<00:32,  3.30it/s][A
 51%|█████     | 113/221 [00:41<00:32,  3.37it/s][A
 52%|█████▏    | 114/221 [00:41<00:26,  4.07it/s][A
 52%|█████▏    | 115/221 [00:41<00:23,  4.51it/s][A
 52%|█████▏    | 116/221 [00:46<02:50,  1.63s/it][A
 53%|█████▎    | 117/221 [00:47<02:09,  1.24s/it][A
 53%|█████▎    | 118/221 [00:47<01:40,  1.03it/s][A
 54%|█████▍    | 119/221 [00:47<01:13,  1.39it/s][A
 54%|█████▍    | 120/221 [00:47<00:59,  1.70it/s][A
 55%|█████▍    | 121/221 [00:47<00:45,  2.20it/s][A
 55%|█████▌    | 122/221 [00:48<00:37,  2.66it/s][A[h264 @ 0x560741b93600] mmco: unref short failure

 56%|█████▌    | 123/221 [00:48<00:33,  2.95it/s][A
 56%|█████▌    | 124/221 [00:48<00:28,  3.36it/s][A
 57%|█████▋    | 125/221 [00:48<00:29,  3.21it/s][A
 57%|█████▋    | 126/221 [00:49<00:30,  3.08it/s][A[h264 @ 0x55e251960980] mmco: unref short failure
[h264 @ 0x55e251960980] mmco: unref short failure

 57%|█████▋    | 127/221 [00:49<00:39,  2.39it/s][A
 58%|█████▊    | 128/221 [00:50<00:38,  2.44it/s][A
 58%|█████▊    | 129/221 [00:50<00:32,  2.85it/s][A
 59%|█████▉    | 130/221 [00:50<00:29,  3.11it/s][A
 59%|█████▉    | 131/221 [00:50<00:23,  3.87it/s][A
 60%|█████▉    | 132/221 [00:51<00:20,  4.41it/s][A
 60%|██████    | 133/221 [00:51<00:23,  3.74it/s][A
 61%|██████    | 134/221 [00:51<00:22,  3.90it/s][A
 61%|██████    | 135/221 [00:52<00:25,  3.31it/s][A
 62%|██████▏   | 136/221 [00:52<00:28,  2.97it/s][A
 62%|██████▏   | 137/221 [00:52<00:24,  3.37it/s][A
 62%|██████▏   | 138/221 [00:53<00:26,  3.17it/s][A
 63%|██████▎   | 139/221 [00:53<00:27,  3.03it/s][A
 63%|██████▎   | 140/221 [00:53<00:25,  3.15it/s][A[h264 @ 0x55b5b09407c0] mmco: unref short failure
[h264 @ 0x55b5b09407c0] mmco: unref short failure

 64%|██████▍   | 141/221 [00:53<00:23,  3.41it/s][A
 64%|██████▍   | 142/221 [00:54<00:25,  3.14it/s][A
 65%|██████▍   | 143/221 [00:54<00:29,  2.67it/s][A
 65%|██████▌   | 144/221 [00:54<00:23,  3.24it/s][A
 66%|██████▌   | 145/221 [00:55<00:18,  4.06it/s][A
 66%|██████▌   | 146/221 [00:55<00:16,  4.69it/s][A
 67%|██████▋   | 147/221 [00:55<00:14,  5.13it/s][A
 67%|██████▋   | 148/221 [00:55<00:15,  4.73it/s][A
 67%|██████▋   | 149/221 [00:55<00:12,  5.55it/s][A
 68%|██████▊   | 150/221 [00:55<00:12,  5.61it/s][A
 68%|██████▊   | 151/221 [00:57<00:34,  2.04it/s][A
 69%|██████▉   | 152/221 [00:57<00:31,  2.20it/s][A
 69%|██████▉   | 153/221 [00:57<00:26,  2.52it/s][A
 70%|██████▉   | 154/221 [00:58<00:28,  2.38it/s][A
 70%|███████   | 155/221 [00:58<00:22,  2.95it/s][A
 71%|███████   | 156/221 [00:58<00:18,  3.43it/s][A
 71%|███████   | 157/221 [01:00<00:52,  1.22it/s][A
 71%|███████▏  | 158/221 [01:00<00:41,  1.53it/s][A
 72%|███████▏  | 159/221 [01:00<00:30,  2.01it/s][A[h264 @ 0x5607514e9a00] mmco: unref short failure
[h264 @ 0x5607514e9a00] mmco: unref short failure

 72%|███████▏  | 160/221 [01:01<00:26,  2.32it/s][A
 73%|███████▎  | 162/221 [01:01<00:16,  3.59it/s][A
 74%|███████▍  | 163/221 [01:01<00:15,  3.70it/s][A
 74%|███████▍  | 164/221 [01:01<00:14,  3.95it/s][A
 75%|███████▍  | 165/221 [01:02<00:12,  4.41it/s][A
 75%|███████▌  | 166/221 [01:02<00:15,  3.45it/s][A
 76%|███████▌  | 167/221 [01:02<00:15,  3.40it/s][A
 76%|███████▌  | 168/221 [01:04<00:38,  1.36it/s][A
 76%|███████▋  | 169/221 [01:04<00:31,  1.65it/s][A
 77%|███████▋  | 170/221 [01:05<00:26,  1.94it/s][A
 77%|███████▋  | 171/221 [01:05<00:22,  2.24it/s][A
 78%|███████▊  | 172/221 [01:05<00:18,  2.60it/s][A
 78%|███████▊  | 173/221 [01:05<00:15,  3.17it/s][A
 79%|███████▉  | 175/221 [01:06<00:11,  4.07it/s][A
 80%|███████▉  | 176/221 [01:06<00:11,  3.95it/s][A
 81%|████████  | 178/221 [01:06<00:09,  4.37it/s][A[h264 @ 0x55b5b1c521c0] mmco: unref short failure

 81%|████████  | 179/221 [01:07<00:11,  3.62it/s][A
 81%|████████▏ | 180/221 [01:07<00:09,  4.29it/s][A
 82%|████████▏ | 181/221 [01:07<00:10,  3.93it/s][A
 82%|████████▏ | 182/221 [01:07<00:08,  4.38it/s][A
 83%|████████▎ | 183/221 [01:08<00:08,  4.65it/s][A
 83%|████████▎ | 184/221 [01:08<00:09,  4.08it/s][A
 84%|████████▎ | 185/221 [01:08<00:08,  4.08it/s][A
 84%|████████▍ | 186/221 [01:09<00:11,  3.12it/s][A
 85%|████████▍ | 187/221 [01:09<00:10,  3.12it/s][A
 85%|████████▌ | 188/221 [01:09<00:10,  3.11it/s][A
 86%|████████▌ | 189/221 [01:10<00:10,  2.96it/s][A
 86%|████████▌ | 190/221 [01:10<00:11,  2.80it/s][A
 86%|████████▋ | 191/221 [01:10<00:08,  3.41it/s][A
 87%|████████▋ | 192/221 [01:10<00:07,  3.86it/s][A
 88%|████████▊ | 194/221 [01:11<00:08,  3.19it/s][A
 88%|████████▊ | 195/221 [01:11<00:07,  3.52it/s][A
 89%|████████▊ | 196/221 [01:11<00:05,  4.17it/s][A
 89%|████████▉ | 197/221 [01:12<00:04,  4.86it/s][A
 90%|████████▉ | 198/221 [01:12<00:04,  4.63it/s][A
 90%|█████████ | 199/221 [01:12<00:04,  4.69it/s][A
 90%|█████████ | 200/221 [01:12<00:05,  3.96it/s][A
 91%|█████████ | 201/221 [01:13<00:04,  4.18it/s][A
 91%|█████████▏| 202/221 [01:13<00:04,  4.64it/s][A
 92%|█████████▏| 203/221 [01:13<00:03,  5.23it/s][A
 92%|█████████▏| 204/221 [01:13<00:03,  5.45it/s][A
 93%|█████████▎| 206/221 [01:14<00:03,  4.06it/s][A
 94%|█████████▍| 208/221 [01:14<00:02,  5.28it/s][A
 95%|█████████▌| 211/221 [01:14<00:01,  5.77it/s][A
 96%|█████████▌| 212/221 [01:14<00:01,  6.14it/s][A[h264 @ 0x55b5b318c100] mmco: unref short failure
[h264 @ 0x55b5b318c100] mmco: unref short failure
[h264 @ 0x55b5b318c100] mmco: unref short failure
[h264 @ 0x55b5b318c100] mmco: unref short failure
[h264 @ 0x55a321493200] mmco: unref short failure

 97%|█████████▋| 214/221 [01:15<00:01,  3.91it/s][A
 97%|█████████▋| 215/221 [01:16<00:01,  4.08it/s][A
 98%|█████████▊| 216/221 [01:16<00:01,  4.03it/s][A
 98%|█████████▊| 217/221 [01:16<00:01,  3.19it/s][A
 99%|█████████▊| 218/221 [01:17<00:00,  3.19it/s][A
 99%|█████████▉| 219/221 [01:17<00:00,  3.56it/s][A
100%|█████████▉| 220/221 [01:21<00:01,  1.38s/it][A
100%|██████████| 221/221 [01:21<00:00,  1.06s/it][A100%|██████████| 221/221 [01:21<00:00,  2.70it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:08,  3.20it/s][A
  1%|          | 2/221 [00:00<01:06,  3.31it/s][A
  1%|▏         | 3/221 [00:00<01:04,  3.35it/s][A
  2%|▏         | 4/221 [00:01<01:04,  3.35it/s][A
  2%|▏         | 5/221 [00:01<01:04,  3.37it/s][A
  3%|▎         | 6/221 [00:01<01:03,  3.38it/s][A
  3%|▎         | 7/221 [00:02<01:03,  3.38it/s][A
  4%|▎         | 8/221 [00:02<01:03,  3.34it/s][A
  4%|▍         | 9/221 [00:02<01:03,  3.36it/s][A
  5%|▍         | 10/221 [00:02<01:02,  3.38it/s][A
  5%|▍         | 11/221 [00:03<01:02,  3.38it/s][A[h264 @ 0x55a32cacc400] mmco: unref short failure

  5%|▌         | 12/221 [00:03<01:02,  3.37it/s][A
  6%|▌         | 13/221 [00:03<01:01,  3.37it/s][A
  6%|▋         | 14/221 [00:04<01:02,  3.33it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.34it/s][A
  7%|▋         | 16/221 [00:04<01:01,  3.36it/s][A
  8%|▊         | 17/221 [00:05<01:00,  3.37it/s][A
  8%|▊         | 18/221 [00:05<01:00,  3.35it/s][A
  9%|▊         | 19/221 [00:05<01:00,  3.35it/s][A
  9%|▉         | 20/221 [00:05<00:59,  3.36it/s][A
 10%|▉         | 21/221 [00:06<00:59,  3.37it/s][A
 10%|▉         | 22/221 [00:06<01:00,  3.29it/s][A
 10%|█         | 23/221 [00:06<01:00,  3.28it/s][A
 11%|█         | 24/221 [00:07<00:59,  3.32it/s][A
 11%|█▏        | 25/221 [00:07<01:02,  3.12it/s][A
 12%|█▏        | 26/221 [00:07<01:05,  3.00it/s][A
 12%|█▏        | 27/221 [00:08<01:03,  3.07it/s][A
 13%|█▎        | 28/221 [00:08<01:00,  3.16it/s][A
 13%|█▎        | 29/221 [00:08<00:59,  3.23it/s][A
 14%|█▎        | 30/221 [00:09<00:58,  3.28it/s][A
 14%|█▍        | 31/221 [00:09<00:58,  3.26it/s][A[h264 @ 0x55b5aa591c00] mmco: unref short failure

 14%|█▍        | 32/221 [00:09<00:58,  3.24it/s][A[h264 @ 0x55b5aa591c00] mmco: unref short failure
[h264 @ 0x55b5aa591c00] mmco: unref short failure

 15%|█▍        | 33/221 [00:10<00:57,  3.28it/s][A[h264 @ 0x560752e4f440] mmco: unref short failure
[h264 @ 0x55b5aa591c00] mmco: unref short failure

 15%|█▌        | 34/221 [00:10<00:56,  3.29it/s][A
 16%|█▌        | 35/221 [00:10<00:55,  3.33it/s][A
 16%|█▋        | 36/221 [00:10<00:55,  3.34it/s][A
 17%|█▋        | 37/221 [00:11<00:55,  3.32it/s][A
 17%|█▋        | 38/221 [00:11<00:54,  3.35it/s][A
 18%|█▊        | 39/221 [00:11<00:54,  3.36it/s][A
 18%|█▊        | 40/221 [00:12<00:53,  3.38it/s][A
 19%|█▊        | 41/221 [00:12<00:53,  3.38it/s][A[h264 @ 0x56074507dec0] mmco: unref short failure

 19%|█▉        | 42/221 [00:12<00:52,  3.38it/s][A[h264 @ 0x55e241da4600] mmco: unref short failure

 19%|█▉        | 43/221 [00:12<00:52,  3.38it/s][A
 20%|█▉        | 44/221 [00:13<00:52,  3.39it/s][A
 20%|██        | 45/221 [00:13<00:51,  3.39it/s][A
 21%|██        | 46/221 [00:13<00:51,  3.40it/s][A
 21%|██▏       | 47/221 [00:14<00:51,  3.40it/s][A
 22%|██▏       | 48/221 [00:14<00:50,  3.39it/s][A
 22%|██▏       | 49/221 [00:14<00:50,  3.39it/s][A
 23%|██▎       | 50/221 [00:15<00:50,  3.39it/s][A
 23%|██▎       | 51/221 [00:15<00:50,  3.39it/s][A
 24%|██▎       | 52/221 [00:15<00:49,  3.39it/s][A
 24%|██▍       | 53/221 [00:15<00:49,  3.40it/s][A
 24%|██▍       | 54/221 [00:16<00:49,  3.40it/s][A
 25%|██▍       | 55/221 [00:16<00:49,  3.38it/s][A
 25%|██▌       | 56/221 [00:16<00:48,  3.39it/s][A
 26%|██▌       | 57/221 [00:17<00:48,  3.38it/s][A
 26%|██▌       | 58/221 [00:17<00:48,  3.39it/s][A
 27%|██▋       | 59/221 [00:17<00:47,  3.39it/s][A
 27%|██▋       | 60/221 [00:17<00:47,  3.39it/s][A
 28%|██▊       | 61/221 [00:18<00:47,  3.39it/s][A
 28%|██▊       | 62/221 [00:18<00:46,  3.40it/s][A
 29%|██▊       | 63/221 [00:18<00:46,  3.40it/s][A
 29%|██▉       | 64/221 [00:19<00:46,  3.40it/s][A
 29%|██▉       | 65/221 [00:19<00:45,  3.40it/s][A
 30%|██▉       | 66/221 [00:19<00:45,  3.40it/s][A
 30%|███       | 67/221 [00:20<00:45,  3.40it/s][A
 31%|███       | 68/221 [00:20<00:44,  3.40it/s][A
 31%|███       | 69/221 [00:20<00:44,  3.40it/s][A
 32%|███▏      | 70/221 [00:20<00:44,  3.41it/s][A
 32%|███▏      | 71/221 [00:21<00:44,  3.41it/s][A
 33%|███▎      | 72/221 [00:21<00:43,  3.41it/s][A
 33%|███▎      | 73/221 [00:21<00:43,  3.41it/s][A
 33%|███▎      | 74/221 [00:22<00:43,  3.41it/s][A
 34%|███▍      | 75/221 [00:22<00:42,  3.41it/s][A
 34%|███▍      | 76/221 [00:22<00:42,  3.41it/s][A
 35%|███▍      | 77/221 [00:22<00:42,  3.41it/s][A
 35%|███▌      | 78/221 [00:23<00:41,  3.41it/s][A
 36%|███▌      | 79/221 [00:23<00:41,  3.41it/s][A
 36%|███▌      | 80/221 [00:23<00:41,  3.41it/s][A
 37%|███▋      | 81/221 [00:24<00:41,  3.41it/s][A
 37%|███▋      | 82/221 [00:24<00:40,  3.41it/s][A
 38%|███▊      | 83/221 [00:24<00:40,  3.41it/s][A
 38%|███▊      | 84/221 [00:25<00:40,  3.42it/s][A
 38%|███▊      | 85/221 [00:25<00:39,  3.42it/s][A
 39%|███▉      | 86/221 [00:25<00:39,  3.42it/s][A
 39%|███▉      | 87/221 [00:25<00:39,  3.42it/s][A
 40%|███▉      | 88/221 [00:26<00:38,  3.42it/s][A
 40%|████      | 89/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 90/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 91/221 [00:27<00:38,  3.42it/s][A
 42%|████▏     | 92/221 [00:27<00:37,  3.42it/s][A
 42%|████▏     | 93/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 94/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 95/221 [00:28<00:36,  3.42it/s][A
 43%|████▎     | 96/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 97/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 98/221 [00:29<00:35,  3.42it/s][A
 45%|████▍     | 99/221 [00:29<00:35,  3.42it/s][A
 45%|████▌     | 100/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 101/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 102/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 104/221 [00:30<00:34,  3.42it/s][A
 48%|████▊     | 105/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 107/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 108/221 [00:32<00:33,  3.42it/s][A
 49%|████▉     | 109/221 [00:32<00:32,  3.42it/s][A
 50%|████▉     | 110/221 [00:32<00:32,  3.42it/s][A
 50%|█████     | 111/221 [00:32<00:32,  3.42it/s][A
 51%|█████     | 112/221 [00:33<00:31,  3.42it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 114/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:34<00:30,  3.42it/s][A
 52%|█████▏    | 116/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:34<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:35<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:35<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:37<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:38<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:39<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:39<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:40<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:41<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:41<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:44<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:45<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:45<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:46<00:18,  3.42it/s][A
 71%|███████   | 157/221 [00:46<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:47<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:48<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:48<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:48<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:49<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:49<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:50<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:51<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:51<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:52<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:54<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:55<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:56<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:57<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:57<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:58<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:03<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.42it/s][A100%|██████████| 221/221 [01:05<00:00,  3.40it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:28,  7.70it/s][A
  1%|          | 2/221 [00:00<00:40,  5.39it/s][A
  1%|▏         | 3/221 [00:00<01:07,  3.23it/s][A
  2%|▏         | 4/221 [00:00<00:53,  4.06it/s][A
  2%|▏         | 5/221 [00:01<00:51,  4.23it/s][A
  3%|▎         | 7/221 [00:01<00:42,  5.06it/s][A
  4%|▎         | 8/221 [00:01<00:48,  4.38it/s][A
  4%|▍         | 9/221 [00:02<00:54,  3.89it/s][A
  5%|▍         | 10/221 [00:02<00:45,  4.66it/s][A
  5%|▍         | 11/221 [00:02<00:51,  4.12it/s][A
  5%|▌         | 12/221 [00:02<00:49,  4.24it/s][A
  6%|▌         | 13/221 [00:03<01:37,  2.13it/s][A
  6%|▋         | 14/221 [00:04<01:21,  2.55it/s][A
  7%|▋         | 15/221 [00:04<01:20,  2.57it/s][A
  7%|▋         | 16/221 [00:04<01:24,  2.43it/s][A
  8%|▊         | 17/221 [00:05<01:22,  2.48it/s][A
  8%|▊         | 18/221 [00:05<01:11,  2.82it/s][A
  9%|▊         | 19/221 [00:05<00:57,  3.48it/s][A
  9%|▉         | 20/221 [00:05<01:01,  3.28it/s][A
 10%|▉         | 21/221 [00:06<00:52,  3.81it/s][A
 10%|▉         | 22/221 [00:06<00:47,  4.21it/s][A
 10%|█         | 23/221 [00:06<00:39,  4.98it/s][A
 11%|█         | 24/221 [00:06<00:37,  5.21it/s][A
 11%|█▏        | 25/221 [00:06<00:48,  4.02it/s][A
 12%|█▏        | 26/221 [00:07<00:49,  3.96it/s][A
 12%|█▏        | 27/221 [00:07<00:56,  3.42it/s][A
 13%|█▎        | 28/221 [00:07<01:01,  3.16it/s][A
 13%|█▎        | 29/221 [00:08<01:00,  3.16it/s][A
 14%|█▎        | 30/221 [00:08<01:12,  2.63it/s][A
 14%|█▍        | 31/221 [00:09<01:09,  2.75it/s][A
 14%|█▍        | 32/221 [00:09<00:59,  3.15it/s][A
 15%|█▍        | 33/221 [00:09<01:01,  3.08it/s][A
 15%|█▌        | 34/221 [00:10<01:32,  2.02it/s][A
 16%|█▌        | 35/221 [00:10<01:16,  2.42it/s][A
 16%|█▋        | 36/221 [00:11<01:06,  2.77it/s][A
 17%|█▋        | 37/221 [00:11<00:57,  3.18it/s][A
 17%|█▋        | 38/221 [00:11<00:55,  3.28it/s][A
 18%|█▊        | 39/221 [00:11<00:48,  3.74it/s][A
 18%|█▊        | 40/221 [00:11<00:47,  3.80it/s][A
 19%|█▊        | 41/221 [00:12<00:50,  3.58it/s][A
 19%|█▉        | 42/221 [00:12<00:43,  4.09it/s][A
 19%|█▉        | 43/221 [00:12<00:45,  3.95it/s][A
 20%|█▉        | 44/221 [00:12<00:41,  4.25it/s][A
 20%|██        | 45/221 [00:13<00:51,  3.44it/s][A
 21%|██        | 46/221 [00:13<00:44,  3.96it/s][A
 21%|██▏       | 47/221 [00:13<00:39,  4.43it/s][A
 22%|██▏       | 49/221 [00:13<00:29,  5.89it/s][A
 23%|██▎       | 50/221 [00:14<00:37,  4.60it/s][A
 23%|██▎       | 51/221 [00:14<00:40,  4.15it/s][A
 24%|██▎       | 52/221 [00:14<00:37,  4.55it/s][A
 24%|██▍       | 53/221 [00:15<00:44,  3.77it/s][A
 24%|██▍       | 54/221 [00:15<00:40,  4.11it/s][A
 25%|██▍       | 55/221 [00:15<00:49,  3.37it/s][A
 25%|██▌       | 56/221 [00:15<00:46,  3.52it/s][A
 26%|██▌       | 57/221 [00:16<00:50,  3.24it/s][A
 26%|██▌       | 58/221 [00:16<00:50,  3.22it/s][A
 27%|██▋       | 59/221 [00:16<00:47,  3.41it/s][A
 27%|██▋       | 60/221 [00:17<00:41,  3.86it/s][A
 28%|██▊       | 61/221 [00:17<00:38,  4.12it/s][A
 28%|██▊       | 62/221 [00:17<00:39,  4.02it/s][A
 29%|██▊       | 63/221 [00:17<00:33,  4.69it/s][A
 29%|██▉       | 64/221 [00:17<00:31,  4.99it/s][A
 29%|██▉       | 65/221 [00:18<00:29,  5.29it/s][A
 30%|██▉       | 66/221 [00:18<00:34,  4.54it/s][A
 30%|███       | 67/221 [00:18<00:51,  2.97it/s][A
 31%|███       | 68/221 [00:19<00:46,  3.28it/s][A
 31%|███       | 69/221 [00:19<00:58,  2.60it/s][A
 32%|███▏      | 70/221 [00:19<00:50,  3.01it/s][A
 32%|███▏      | 71/221 [00:20<00:55,  2.71it/s][A
 33%|███▎      | 72/221 [00:20<00:57,  2.61it/s][A
 33%|███▎      | 73/221 [00:21<00:53,  2.76it/s][A
 33%|███▎      | 74/221 [00:21<00:50,  2.89it/s][A
 34%|███▍      | 75/221 [00:21<00:49,  2.95it/s][A
 34%|███▍      | 76/221 [00:21<00:39,  3.68it/s][A
 35%|███▍      | 77/221 [00:22<00:43,  3.28it/s][A
 35%|███▌      | 78/221 [00:22<00:46,  3.05it/s][A
 36%|███▌      | 79/221 [00:22<00:45,  3.15it/s][A
 36%|███▌      | 80/221 [00:23<00:43,  3.26it/s][A
 37%|███▋      | 81/221 [00:23<00:40,  3.48it/s][A
 37%|███▋      | 82/221 [00:23<00:37,  3.66it/s][A
 38%|███▊      | 83/221 [00:23<00:35,  3.87it/s][A
 38%|███▊      | 84/221 [00:24<00:53,  2.58it/s][A
 38%|███▊      | 85/221 [00:25<01:00,  2.26it/s][A
 39%|███▉      | 86/221 [00:25<00:57,  2.33it/s][A
 39%|███▉      | 87/221 [00:26<01:03,  2.12it/s][A
 40%|███▉      | 88/221 [00:26<00:53,  2.47it/s][A
 40%|████      | 89/221 [00:26<00:51,  2.57it/s][A
 41%|████      | 90/221 [00:27<00:55,  2.38it/s][A
 41%|████      | 91/221 [00:27<00:47,  2.75it/s][A
 42%|████▏     | 92/221 [00:27<00:47,  2.71it/s][A
 42%|████▏     | 93/221 [00:28<00:58,  2.19it/s][A
 43%|████▎     | 94/221 [00:28<00:48,  2.64it/s][A
 43%|████▎     | 95/221 [00:29<00:53,  2.35it/s][A
 43%|████▎     | 96/221 [00:29<00:47,  2.61it/s][A
 44%|████▍     | 97/221 [00:29<00:41,  2.98it/s][A
 44%|████▍     | 98/221 [00:30<00:39,  3.13it/s][A
 45%|████▍     | 99/221 [00:30<00:35,  3.42it/s][A
 45%|████▌     | 100/221 [00:30<00:29,  4.10it/s][A
 46%|████▌     | 101/221 [00:30<00:24,  4.84it/s][A
 46%|████▌     | 102/221 [00:30<00:27,  4.39it/s][A
 47%|████▋     | 103/221 [00:30<00:26,  4.50it/s][A
 48%|████▊     | 105/221 [00:31<00:24,  4.64it/s][A
 48%|████▊     | 106/221 [00:31<00:28,  3.97it/s][A
 48%|████▊     | 107/221 [00:32<00:28,  4.03it/s][A
 49%|████▉     | 108/221 [00:32<00:25,  4.52it/s][A
 49%|████▉     | 109/221 [00:32<00:24,  4.65it/s][A
 50%|████▉     | 110/221 [00:32<00:25,  4.42it/s][A
 50%|█████     | 111/221 [00:32<00:28,  3.91it/s][A
 51%|█████     | 112/221 [00:33<00:29,  3.66it/s][A
 51%|█████     | 113/221 [00:33<00:28,  3.82it/s][A
 52%|█████▏    | 114/221 [00:33<00:23,  4.58it/s][A
 52%|█████▏    | 115/221 [00:33<00:22,  4.67it/s][A
 52%|█████▏    | 116/221 [00:33<00:20,  5.19it/s][A
 53%|█████▎    | 117/221 [00:34<00:21,  4.74it/s][A
 53%|█████▎    | 118/221 [00:34<00:27,  3.72it/s][A
 54%|█████▍    | 119/221 [00:34<00:30,  3.29it/s][A
 54%|█████▍    | 120/221 [00:35<00:30,  3.26it/s][A
 55%|█████▍    | 121/221 [00:35<00:27,  3.61it/s][A
 55%|█████▌    | 122/221 [00:35<00:25,  3.84it/s][A
 56%|█████▌    | 123/221 [00:36<00:27,  3.51it/s][A
 56%|█████▌    | 124/221 [00:36<00:26,  3.60it/s][A
 57%|█████▋    | 125/221 [00:36<00:33,  2.86it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.41it/s][A
 57%|█████▋    | 127/221 [00:37<00:38,  2.45it/s][A
 58%|█████▊    | 128/221 [00:37<00:31,  2.92it/s][A
 58%|█████▊    | 129/221 [00:38<00:27,  3.32it/s][A
 59%|█████▉    | 130/221 [00:38<00:31,  2.87it/s][A
 59%|█████▉    | 131/221 [00:38<00:25,  3.50it/s][A
 60%|█████▉    | 132/221 [00:38<00:23,  3.83it/s][A
 60%|██████    | 133/221 [00:39<00:30,  2.85it/s][A
 61%|██████    | 134/221 [00:40<00:36,  2.41it/s][A
 61%|██████    | 135/221 [00:40<00:28,  3.07it/s][A
 62%|██████▏   | 136/221 [00:40<00:26,  3.17it/s][A
 62%|██████▏   | 137/221 [00:40<00:22,  3.67it/s][A
 62%|██████▏   | 138/221 [00:40<00:21,  3.85it/s][A
 63%|██████▎   | 139/221 [00:41<00:23,  3.55it/s][A
 63%|██████▎   | 140/221 [00:41<00:20,  3.89it/s][A
 64%|██████▍   | 141/221 [00:41<00:22,  3.51it/s][A
 64%|██████▍   | 142/221 [00:41<00:20,  3.90it/s][A
 65%|██████▍   | 143/221 [00:42<00:23,  3.37it/s][A
 65%|██████▌   | 144/221 [00:42<00:21,  3.61it/s][A
 66%|██████▌   | 145/221 [00:42<00:23,  3.29it/s][A
 66%|██████▌   | 146/221 [00:43<00:23,  3.26it/s][A
 67%|██████▋   | 147/221 [00:43<00:20,  3.60it/s][A
 67%|██████▋   | 148/221 [00:43<00:21,  3.37it/s][A
 67%|██████▋   | 149/221 [00:43<00:19,  3.65it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.50it/s][A
 68%|██████▊   | 151/221 [00:44<00:26,  2.62it/s][A
 69%|██████▉   | 152/221 [00:45<00:35,  1.94it/s][A
 69%|██████▉   | 153/221 [00:45<00:29,  2.32it/s][A
 70%|██████▉   | 154/221 [00:46<00:26,  2.54it/s][A
 70%|███████   | 155/221 [00:46<00:24,  2.68it/s][A
 71%|███████   | 156/221 [00:46<00:21,  3.05it/s][A
 71%|███████   | 157/221 [00:47<00:19,  3.24it/s][A
 71%|███████▏  | 158/221 [00:47<00:20,  3.04it/s][A
 72%|███████▏  | 159/221 [00:47<00:17,  3.47it/s][A
 72%|███████▏  | 160/221 [00:47<00:15,  3.89it/s][A
 73%|███████▎  | 161/221 [00:48<00:14,  4.07it/s][A
 73%|███████▎  | 162/221 [00:48<00:12,  4.84it/s][A
 74%|███████▍  | 163/221 [00:48<00:12,  4.48it/s][A
 74%|███████▍  | 164/221 [00:48<00:11,  4.76it/s][A
 75%|███████▍  | 165/221 [00:48<00:11,  4.84it/s][A
 75%|███████▌  | 166/221 [00:49<00:13,  4.12it/s][A
 76%|███████▌  | 167/221 [00:49<00:11,  4.52it/s][A
 76%|███████▌  | 168/221 [00:49<00:11,  4.63it/s][A
 76%|███████▋  | 169/221 [00:49<00:09,  5.46it/s][A
 77%|███████▋  | 170/221 [00:50<00:18,  2.74it/s][A
 77%|███████▋  | 171/221 [00:50<00:19,  2.60it/s][A
 78%|███████▊  | 172/221 [00:51<00:18,  2.67it/s][A
 78%|███████▊  | 173/221 [00:51<00:17,  2.76it/s][A
 79%|███████▊  | 174/221 [00:51<00:15,  3.07it/s][A
 79%|███████▉  | 175/221 [00:52<00:15,  2.97it/s][A
 80%|███████▉  | 176/221 [00:52<00:14,  3.18it/s][A
 80%|████████  | 177/221 [00:52<00:13,  3.35it/s][A
 81%|████████  | 178/221 [00:53<00:17,  2.41it/s][A
 81%|████████  | 179/221 [00:53<00:15,  2.79it/s][A
 81%|████████▏ | 180/221 [00:53<00:13,  3.10it/s][A
 82%|████████▏ | 181/221 [00:54<00:15,  2.61it/s][A
 82%|████████▏ | 182/221 [00:54<00:13,  2.82it/s][A
 83%|████████▎ | 183/221 [00:55<00:14,  2.66it/s][A
 83%|████████▎ | 184/221 [00:55<00:13,  2.69it/s][A
 84%|████████▍ | 186/221 [00:56<00:12,  2.83it/s][A
 85%|████████▍ | 187/221 [00:56<00:11,  3.02it/s][A
 85%|████████▌ | 188/221 [00:56<00:10,  3.19it/s][A
 86%|████████▌ | 189/221 [00:56<00:08,  3.60it/s][A
 86%|████████▌ | 190/221 [00:57<00:09,  3.27it/s][A
 86%|████████▋ | 191/221 [00:57<00:07,  3.98it/s][A
 87%|████████▋ | 192/221 [00:57<00:06,  4.34it/s][A
 87%|████████▋ | 193/221 [00:57<00:05,  5.06it/s][A
 88%|████████▊ | 194/221 [00:57<00:05,  4.70it/s][A
 88%|████████▊ | 195/221 [00:58<00:05,  4.66it/s][A
 89%|████████▊ | 196/221 [00:58<00:08,  3.12it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.00it/s][A
 90%|████████▉ | 198/221 [00:59<00:08,  2.69it/s][A
 90%|█████████ | 199/221 [00:59<00:06,  3.21it/s][A
 90%|█████████ | 200/221 [00:59<00:06,  3.20it/s][A
 91%|█████████ | 201/221 [01:00<00:05,  3.62it/s][A
 91%|█████████▏| 202/221 [01:00<00:05,  3.69it/s][A
 92%|█████████▏| 203/221 [01:00<00:04,  3.89it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.65it/s][A
 93%|█████████▎| 205/221 [01:01<00:04,  3.98it/s][A
 93%|█████████▎| 206/221 [01:01<00:04,  3.20it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  3.28it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.92it/s][A
 95%|█████████▍| 209/221 [01:02<00:02,  4.09it/s][A
 95%|█████████▌| 210/221 [01:02<00:03,  3.57it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.87it/s][A
 96%|█████████▌| 212/221 [01:03<00:02,  3.40it/s][A
 96%|█████████▋| 213/221 [01:03<00:02,  3.14it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.10it/s][A
 97%|█████████▋| 215/221 [01:04<00:01,  3.38it/s][A
 98%|█████████▊| 216/221 [01:04<00:01,  3.29it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.45it/s][A
 99%|█████████▊| 218/221 [01:05<00:00,  3.29it/s][A
 99%|█████████▉| 219/221 [01:05<00:00,  3.21it/s][A
100%|█████████▉| 220/221 [01:05<00:00,  3.85it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.22it/s][A100%|██████████| 221/221 [01:05<00:00,  3.35it/s]
09/17/2024 04:43:32 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 849--===========

09/17/2024 04:43:32 - INFO - __main__ -   {'area_r1': 40.6, 'area_recall': '40.6/64.8/74.1', 'area_ravg': 59.8}
09/17/2024 04:43:32 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 849--===========

09/17/2024 04:43:32 - INFO - __main__ -   {'forward_r1': 39.3, 'forward_recall': '39.3/66.3/77.1', 'forward_ravg': 60.9}
09/17/2024 04:43:32 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 849--===========

09/17/2024 04:43:32 - INFO - __main__ -   {'area_video_r1': 39.8, 'area_video_recall': '39.8/67.3/78.6', 'area_video_ravg': 61.9}
09/17/2024 04:43:32 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 299=======

09/17/2024 04:43:32 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 04:43:32 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 849--===========

09/17/2024 04:43:32 - INFO - __main__ -   {'area_video_r1': 52.8, 'area_video_recall': '52.8/75.1/82.7', 'area_video_ravg': 70.2, 'area_video_back_r1': 47.5, 'area_video_back_recall': '47.5/74.8/82.2', 'area_video_back_ravg': 68.2}
09/17/2024 04:43:32 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 549=======

09/17/2024 04:43:32 - INFO - __main__ -   {'area_video_r1': 54.1, 'area_video_recall': '54.1/75.5/82.4', 'area_video_ravg': 70.6, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.5/82.1', 'area_video_back_ravg': 68.7}
09/17/2024 04:43:32 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 849--===========

09/17/2024 04:43:32 - INFO - __main__ -   {'video_r1': 37.6, 'video_recall': '37.6/63.6/75.0', 'video_ravg': 58.7}
09/17/2024 04:43:32 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 849=======

09/17/2024 04:43:32 - INFO - __main__ -   {'video_r1': 37.6, 'video_recall': '37.6/63.6/75.0', 'video_ravg': 58.7}
09/17/2024 04:43:32 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 849--===========

09/17/2024 04:43:32 - INFO - __main__ -   {'video_r1': 52.8, 'video_recall': '52.8/74.8/81.9', 'video_ravg': 69.8}
09/17/2024 04:43:32 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 549=======

09/17/2024 04:43:32 - INFO - __main__ -   {'video_r1': 54.5, 'video_recall': '54.5/76.1/83.4', 'video_ravg': 71.3}
[h264 @ 0x560742f36800] mmco: unref short failure
09/17/2024 04:43:58 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.009344371035695076, 'loss_ret%tv%ta--finetune_area/loss_area': 1.1367896795272827, 'loss_ret%tv%ta--finetune_area/total_loss': 1.1461340188980103}
 29%|██▉       | 850/2910 [5:22:15<78:41:48, 137.53s/it] 29%|██▉       | 851/2910 [5:22:18<55:40:29, 97.34s/it]  29%|██▉       | 852/2910 [5:22:22<39:36:04, 69.27s/it] 29%|██▉       | 853/2910 [5:22:27<28:28:22, 49.83s/it][h264 @ 0x55a3137ac680] mmco: unref short failure
[h264 @ 0x560748d2b800] mmco: unref short failure
[h264 @ 0x560748d2b800] mmco: unref short failure
[h264 @ 0x55b5abb78b80] mmco: unref short failure
[h264 @ 0x55b5abb78b80] mmco: unref short failure
 29%|██▉       | 854/2910 [5:22:31<20:39:20, 36.17s/it][h264 @ 0x55b5bdb79040] mmco: unref short failure
[h264 @ 0x55b5bdb79040] mmco: unref short failure
 29%|██▉       | 855/2910 [5:22:36<15:20:23, 26.87s/it][h264 @ 0x55e23aa7f5c0] mmco: unref short failure
[h264 @ 0x55e23aa7f5c0] mmco: unref short failure
[h264 @ 0x55e23aa7f5c0] mmco: unref short failure
[h264 @ 0x55e23aa7f5c0] mmco: unref short failure
 29%|██▉       | 856/2910 [5:22:41<11:35:39, 20.32s/it] 29%|██▉       | 857/2910 [5:22:46<8:59:42, 15.77s/it]  29%|██▉       | 858/2910 [5:22:52<7:12:03, 12.63s/it] 30%|██▉       | 859/2910 [5:22:57<5:57:54, 10.47s/it] 30%|██▉       | 860/2910 [5:23:02<5:03:11,  8.87s/it][h264 @ 0x55e252663b00] mmco: unref short failure
 30%|██▉       | 861/2910 [5:23:07<4:23:09,  7.71s/it][h264 @ 0x55e252663b00] mmco: unref short failure
[h264 @ 0x56074c866700] mmco: unref short failure
[h264 @ 0x56074d854d00] mmco: unref short failure
[h264 @ 0x56074d854d00] mmco: unref short failure
 30%|██▉       | 862/2910 [5:23:13<4:04:40,  7.17s/it][h264 @ 0x5607486c74c0] mmco: unref short failure
[h264 @ 0x5607486c74c0] mmco: unref short failure
[h264 @ 0x55b5b9bf7280] mmco: unref short failure
[h264 @ 0x55b5b9bf7280] mmco: unref short failure
 30%|██▉       | 863/2910 [5:23:19<3:50:53,  6.77s/it][h264 @ 0x55b5b318c100] mmco: unref short failure
[h264 @ 0x55b5b318c100] mmco: unref short failure
 30%|██▉       | 864/2910 [5:23:25<3:38:55,  6.42s/it] 30%|██▉       | 865/2910 [5:23:30<3:25:49,  6.04s/it][h264 @ 0x5607424ff080] mmco: unref short failure
09/17/2024 04:45:43 - INFO - __main__ -   current idx gI8ShUTkJf8.29 from finetune_area returns wrong image/video, use 24681 instead.
[h264 @ 0x55a31a5a8000] mmco: unref short failure
[h264 @ 0x55a31a5a8000] mmco: unref short failure
[h264 @ 0x55a31a5a8000] mmco: unref short failure
[h264 @ 0x55a31a5a8000] mmco: unref short failure
[h264 @ 0x55a33477f840] mmco: unref short failure
[h264 @ 0x55b5b273a900] mmco: unref short failure
[h264 @ 0x55e2500e11c0] mmco: unref short failure
 30%|██▉       | 866/2910 [5:24:21<11:06:23, 19.56s/it][h264 @ 0x5607603a0b80] mmco: unref short failure
 30%|██▉       | 867/2910 [5:24:30<9:15:17, 16.31s/it] [h264 @ 0x55e2561386c0] mmco: unref short failure
[h264 @ 0x55e2561386c0] mmco: unref short failure
[h264 @ 0x56075d270500] mmco: unref short failure
[h264 @ 0x55a32f928a00] mmco: unref short failure
[h264 @ 0x55a32f928a00] mmco: unref short failure
[h264 @ 0x55e247836c80] mmco: unref short failure
[h264 @ 0x55e247836c80] mmco: unref short failure
[h264 @ 0x55b5a9fe27c0] mmco: unref short failure
[h264 @ 0x55b5a9fe27c0] mmco: unref short failure
[h264 @ 0x55e25136ac80] mmco: unref short failure
[h264 @ 0x55e25136ac80] mmco: unref short failure
[h264 @ 0x55e25136ac80] mmco: unref short failure
[h264 @ 0x55b5acf06840] mmco: unref short failure
[h264 @ 0x55b5acf06840] mmco: unref short failure
[h264 @ 0x55b5acf06840] mmco: unref short failure
[h264 @ 0x55e24e748580] mmco: unref short failure
[h264 @ 0x55e24e748580] mmco: unref short failure
 30%|██▉       | 868/2910 [5:24:52<10:21:19, 18.26s/it][h264 @ 0x56075d14ccc0] mmco: unref short failure
[h264 @ 0x55a32eadf640] mmco: unref short failure
[h264 @ 0x560760050480] mmco: unref short failure
 30%|██▉       | 869/2910 [5:25:00<8:29:23, 14.97s/it] [h264 @ 0x55e23f5f91c0] mmco: unref short failure
[h264 @ 0x55e23f5f91c0] mmco: unref short failure
[h264 @ 0x55b5ca386e80] mmco: unref short failure
[h264 @ 0x55b5ca386e80] mmco: unref short failure
 30%|██▉       | 870/2910 [5:25:09<7:32:48, 13.32s/it][h264 @ 0x56075bc27cc0] mmco: unref short failure
 30%|██▉       | 871/2910 [5:25:15<6:19:39, 11.17s/it][h264 @ 0x55a326022e40] mmco: unref short failure
[h264 @ 0x55a326022e40] mmco: unref short failure
[h264 @ 0x56074b172880] mmco: unref short failure
[h264 @ 0x56074b172880] mmco: unref short failure
 30%|██▉       | 872/2910 [5:25:21<5:22:41,  9.50s/it] 30%|███       | 873/2910 [5:25:27<4:43:08,  8.34s/it][h264 @ 0x560753b20cc0] mmco: unref short failure
[h264 @ 0x56074412cf00] mmco: unref short failure
[h264 @ 0x5607593c1740] mmco: unref short failure
[h264 @ 0x55b5ba3b0680] mmco: unref short failure
[h264 @ 0x55b5ba3b0680] mmco: unref short failure
[h264 @ 0x55a321d50300] mmco: unref short failure
[h264 @ 0x55a321d50300] mmco: unref short failure
09/17/2024 04:47:45 - INFO - __main__ -   current idx TVD87stlv5k.46 from finetune_area returns wrong image/video, use 67859 instead.
09/17/2024 04:47:53 - INFO - __main__ -   current idx hDAA1fIvxDY.2 from finetune_area returns wrong image/video, use 28742 instead.
[h264 @ 0x55b5c2988cc0] mmco: unref short failure
[h264 @ 0x55e24f425040] mmco: unref short failure
[h264 @ 0x55e24f425040] mmco: unref short failure
[h264 @ 0x560741a87780] mmco: unref short failure
[h264 @ 0x55e240395c80] mmco: unref short failure
[h264 @ 0x55e23bafb1c0] mmco: unref short failure
[h264 @ 0x5607542f7fc0] mmco: unref short failure
 30%|███       | 874/2910 [5:26:51<17:42:09, 31.30s/it][h264 @ 0x560741cb9900] mmco: unref short failure
[h264 @ 0x55e252a70b40] mmco: unref short failure
[h264 @ 0x55e24f425040] mmco: unref short failure
[h264 @ 0x55e24f425040] mmco: unref short failure
 30%|███       | 875/2910 [5:27:13<16:05:54, 28.48s/it][h264 @ 0x55e251caf080] mmco: unref short failure
[h264 @ 0x55e251caf080] mmco: unref short failure
[h264 @ 0x55e251caf080] mmco: unref short failure
[h264 @ 0x55e251caf080] mmco: unref short failure
[h264 @ 0x55e2392721c0] mmco: unref short failure
[h264 @ 0x55a30ff52480] mmco: unref short failure
 30%|███       | 876/2910 [5:27:23<12:51:37, 22.76s/it] 30%|███       | 877/2910 [5:27:28<9:51:33, 17.46s/it] [h264 @ 0x55a31116cec0] mmco: unref short failure
[h264 @ 0x55a31116cec0] mmco: unref short failure
[h264 @ 0x55b5b6dee340] mmco: unref short failure
 30%|███       | 878/2910 [5:27:40<8:56:49, 15.85s/it] 30%|███       | 879/2910 [5:27:45<7:04:11, 12.53s/it][h264 @ 0x55e23b2a1b80] mmco: unref short failure
[h264 @ 0x55b5c04cd540] mmco: unref short failure
[h264 @ 0x55b5c04cd540] mmco: unref short failure
 30%|███       | 880/2910 [5:27:50<5:50:17, 10.35s/it] 30%|███       | 881/2910 [5:27:57<5:16:08,  9.35s/it][h264 @ 0x5607487e1000] mmco: unref short failure
[h264 @ 0x5607487e1000] mmco: unref short failure
[h264 @ 0x5607487e1000] mmco: unref short failure
[h264 @ 0x5607487e1000] mmco: unref short failure
[h264 @ 0x5607487e1000] mmco: unref short failure
[h264 @ 0x5607487e1000] mmco: unref short failure
[h264 @ 0x5607487e1000] mmco: unref short failure
[h264 @ 0x5607487e1000] mmco: unref short failure
09/17/2024 04:49:58 - INFO - __main__ -   current idx 6D_ahpoF_r4.148 from finetune_area returns wrong image/video, use 104227 instead.
09/17/2024 04:50:05 - INFO - __main__ -   current idx bFHOzJ5hSFg.79 from finetune_area returns wrong image/video, use 106211 instead.
[h264 @ 0x55e249a905c0] mmco: unref short failure
[h264 @ 0x55a319a6e280] mmco: unref short failure
[h264 @ 0x55a319a6e280] mmco: unref short failure
[h264 @ 0x55e23b718c00] mmco: unref short failure
[h264 @ 0x55e23bafb1c0] mmco: unref short failure
[h264 @ 0x55e23bafb1c0] mmco: unref short failure
[h264 @ 0x55a3108a2f00] mmco: unref short failure
[h264 @ 0x55a3108a2f00] mmco: unref short failure
[h264 @ 0x55a30fd8d000] mmco: unref short failure
[h264 @ 0x560745f2b480] mmco: unref short failure
[h264 @ 0x55e245b87500] mmco: unref short failure
[h264 @ 0x5607477149c0] mmco: unref short failure
[h264 @ 0x5607477149c0] mmco: unref short failure
[h264 @ 0x5607477149c0] mmco: unref short failure
[h264 @ 0x5607477149c0] mmco: unref short failure
[h264 @ 0x5607477149c0] mmco: unref short failure
[h264 @ 0x5607477149c0] mmco: unref short failure
[h264 @ 0x55b5cb70f8c0] mmco: unref short failure
[h264 @ 0x55b5cb70f8c0] mmco: unref short failure
[h264 @ 0x55e2570f75c0] mmco: unref short failure
[h264 @ 0x56074dda5e80] mmco: unref short failure
[h264 @ 0x55e25396f5c0] mmco: unref short failure
 30%|███       | 882/2910 [5:29:20<17:47:43, 31.59s/it]09/17/2024 04:51:12 - INFO - __main__ -   current idx d018IFLZh_8.4 from finetune_area returns wrong image/video, use 64184 instead.
[h264 @ 0x55e23faedac0] mmco: unref short failure
[h264 @ 0x55e23faedac0] mmco: unref short failure
[h264 @ 0x55e241cef940] mmco: unref short failure
[h264 @ 0x55b5b831b3c0] mmco: unref short failure
[h264 @ 0x55b5b831b3c0] mmco: unref short failure
[h264 @ 0x55b5b16bb340] mmco: unref short failure
[h264 @ 0x55b5b16bb340] mmco: unref short failure
[h264 @ 0x56075d9aae80] mmco: unref short failure
[h264 @ 0x56075d9aae80] mmco: unref short failure
[h264 @ 0x560754bd6d40] mmco: unref short failure
 30%|███       | 883/2910 [5:29:57<18:36:33, 33.05s/it] 30%|███       | 884/2910 [5:30:02<13:53:03, 24.67s/it] 30%|███       | 885/2910 [5:30:07<10:37:08, 18.88s/it] 30%|███       | 886/2910 [5:30:14<8:27:53, 15.06s/it] 09/17/2024 04:51:59 - INFO - __main__ -   current idx 0Hu1HI7Jvzs.159 from finetune_area returns wrong image/video, use 38725 instead.
[h264 @ 0x55b5bffc5f80] mmco: unref short failure
 30%|███       | 887/2910 [5:30:19<6:48:32, 12.12s/it][h264 @ 0x5607628d2d00] mmco: unref short failure
[h264 @ 0x5607628d2d00] mmco: unref short failure
[h264 @ 0x5607628d2d00] mmco: unref short failure
[h264 @ 0x5607628d2d00] mmco: unref short failure
 31%|███       | 888/2910 [5:30:25<5:45:42, 10.26s/it][h264 @ 0x55e255f29740] mmco: unref short failure
 31%|███       | 889/2910 [5:30:30<4:53:54,  8.73s/it][h264 @ 0x55b5b8abe9c0] mmco: unref short failure
[h264 @ 0x55b5b8abe9c0] mmco: unref short failure
[h264 @ 0x55e2434e1880] mmco: unref short failure
[h264 @ 0x55e2434e1880] mmco: unref short failure
[h264 @ 0x55a32d8b4980] mmco: unref short failure
[h264 @ 0x560756d82380] mmco: unref short failure
[h264 @ 0x560756d82380] mmco: unref short failure
[h264 @ 0x560756d82380] mmco: unref short failure
[h264 @ 0x55b5aa6dd800] mmco: unref short failure
[h264 @ 0x55b5aa6dd800] mmco: unref short failure
[h264 @ 0x5607524c9040] mmco: unref short failure
[h264 @ 0x5607524c9040] mmco: unref short failure
[h264 @ 0x5607524c9040] mmco: unref short failure
[h264 @ 0x55a31df135c0] mmco: unref short failure
[h264 @ 0x55a31df135c0] mmco: unref short failure
[h264 @ 0x560750907bc0] mmco: unref short failure
[h264 @ 0x560750907bc0] mmco: unref short failure
09/17/2024 04:52:59 - INFO - __main__ -   current idx 4XizDIlnZbw.3 from finetune_area returns wrong image/video, use 96832 instead.
[h264 @ 0x55a327e3ed80] mmco: unref short failure
[h264 @ 0x55a327e3ed80] mmco: unref short failure
[h264 @ 0x55a329b96fc0] mmco: unref short failure
[h264 @ 0x55a329b96fc0] mmco: unref short failure
[h264 @ 0x55e24ec13440] mmco: unref short failure
[h264 @ 0x56074e8d3380] mmco: unref short failure
[h264 @ 0x56074e8d3380] mmco: unref short failure
[h264 @ 0x56074e8d3380] mmco: unref short failure
[h264 @ 0x56074e8d3380] mmco: unref short failure
[h264 @ 0x55a312a34940] mmco: unref short failure
[h264 @ 0x55b5c37db480] mmco: unref short failure
 31%|███       | 890/2910 [5:31:51<17:05:08, 30.45s/it][h264 @ 0x55a310b7d700] mmco: unref short failure
[h264 @ 0x55b5bf6b8c00] mmco: unref short failure
[h264 @ 0x55e23bafafc0] mmco: unref short failure
[h264 @ 0x55e23bafafc0] mmco: unref short failure
[h264 @ 0x560747636900] mmco: unref short failure
[h264 @ 0x560744a079c0] mmco: unref short failure
[h264 @ 0x560744a079c0] mmco: unref short failure
 31%|███       | 891/2910 [5:32:27<17:56:27, 31.99s/it][h264 @ 0x55e246862140] mmco: unref short failure
 31%|███       | 892/2910 [5:32:32<13:26:47, 23.99s/it][h264 @ 0x55a3191cda80] mmco: unref short failure
[h264 @ 0x55a3191cda80] mmco: unref short failure
[h264 @ 0x55b5b10dfe80] mmco: unref short failure
[h264 @ 0x55b5b10dfe80] mmco: unref short failure
[h264 @ 0x55b5b10dfe80] mmco: unref short failure
[h264 @ 0x55b5b10dfe80] mmco: unref short failure
[h264 @ 0x55e23fd78300] mmco: unref short failure
 31%|███       | 893/2910 [5:32:37<10:19:33, 18.43s/it][h264 @ 0x55a3191cda80] mmco: unref short failure
[h264 @ 0x55a3191cda80] mmco: unref short failure
[h264 @ 0x56074a166080] mmco: unref short failure
[h264 @ 0x56074a166080] mmco: unref short failure
[h264 @ 0x55a314a00840] mmco: unref short failure
 31%|███       | 894/2910 [5:32:43<8:06:50, 14.49s/it]  31%|███       | 895/2910 [5:32:49<6:40:31, 11.93s/it][h264 @ 0x55b5b9e1dc80] mmco: unref short failure
[h264 @ 0x55b5b9e1dc80] mmco: unref short failure
 31%|███       | 896/2910 [5:32:54<5:36:20, 10.02s/it][h264 @ 0x55b5b15c9640] mmco: unref short failure
 31%|███       | 897/2910 [5:33:01<4:59:23,  8.92s/it][h264 @ 0x55e247f190c0] mmco: unref short failure
09/17/2024 04:54:47 - INFO - __main__ -   current idx 3cJe7Dudc7U.114 from finetune_area returns wrong image/video, use 111693 instead.
[h264 @ 0x560741503c00] mmco: unref short failure
09/17/2024 04:55:00 - INFO - __main__ -   current idx OVwFPMxJUJU.30 from finetune_area returns wrong image/video, use 54891 instead.
[h264 @ 0x55e2504e1a40] mmco: unref short failure
[h264 @ 0x55e2504e1a40] mmco: unref short failure
[h264 @ 0x55a3114c7540] mmco: unref short failure
[h264 @ 0x5607437c0d40] mmco: unref short failure
[h264 @ 0x55e23de771c0] mmco: unref short failure
[h264 @ 0x55a317edc000] mmco: unref short failure
[h264 @ 0x55e2397c2cc0] mmco: unref short failure
[h264 @ 0x55e2397c2cc0] mmco: unref short failure
[h264 @ 0x55a30fe70240] mmco: unref short failure
[h264 @ 0x55a30fe70240] mmco: unref short failure
[h264 @ 0x55b5abe57800] mmco: unref short failure
[h264 @ 0x55b5abe57800] mmco: unref short failure
[h264 @ 0x55a311d74040] mmco: unref short failure
[h264 @ 0x560754c45780] mmco: unref short failure
[h264 @ 0x560754c45780] mmco: unref short failure
[h264 @ 0x55a33093c8c0] mmco: unref short failure
[h264 @ 0x55a33093c8c0] mmco: unref short failure
 31%|███       | 898/2910 [5:34:17<16:18:31, 29.18s/it][h264 @ 0x560755299400] mmco: unref short failure
[h264 @ 0x55b5b2009e40] mmco: unref short failure
 31%|███       | 899/2910 [5:34:51<17:01:24, 30.47s/it]09/17/2024 04:56:36 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 04:56:36 - INFO - __main__ -   start running ret%tva validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55b5b39f5840] mmco: unref short failure
[h264 @ 0x55b5b39f5840] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e23baf59c0] mmco: unref short failure
[h264 @ 0x55e23baf59c0] mmco: unref short failure
[h264 @ 0x560754181580] mmco: unref short failure
[h264 @ 0x560754181580] mmco: unref short failure
[h264 @ 0x560754181580] mmco: unref short failure
[h264 @ 0x560754181580] mmco: unref short failure
[h264 @ 0x55a315755940] mmco: unref short failure
[h264 @ 0x55a315755940] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55b5b68c9380] mmco: unref short failure
[h264 @ 0x55b5b68c9380] mmco: unref short failure
[h264 @ 0x55b5b68c9380] mmco: unref short failure
[h264 @ 0x55b5b68c9380] mmco: unref short failure
[h264 @ 0x55e23c66f600] mmco: unref short failure
[h264 @ 0x56074e7bce00] mmco: unref short failure
[h264 @ 0x56074e7bce00] mmco: unref short failure
[h264 @ 0x55a317a02ac0] mmco: unref short failure
[h264 @ 0x55a317a02ac0] mmco: unref short failure
[h264 @ 0x55a31a0b15c0] mmco: unref short failure
[h264 @ 0x55a31a0b15c0] mmco: unref short failure
[h264 @ 0x55a31a0b15c0] mmco: unref short failure
[h264 @ 0x55a31a0b15c0] mmco: unref short failure
[h264 @ 0x55e2446687c0] mmco: unref short failure
[h264 @ 0x55e2446687c0] mmco: unref short failure
[h264 @ 0x55b5c1206080] mmco: unref short failure
[h264 @ 0x55b5c631f900] mmco: unref short failure
[h264 @ 0x55b5c631f900] mmco: unref short failure
[h264 @ 0x560755f6dfc0] mmco: unref short failure
[h264 @ 0x560755f6dfc0] mmco: unref short failure
[h264 @ 0x55a32d33cf80] mmco: unref short failure
[h264 @ 0x55a32d33cf80] mmco: unref short failure
[h264 @ 0x55a32d33cf80] mmco: unref short failure
[h264 @ 0x55a32d33cf80] mmco: unref short failure
[h264 @ 0x55a32d33cf80] mmco: unref short failure
[h264 @ 0x55e24ae49a00] mmco: unref short failure
[h264 @ 0x55e24ae49a00] mmco: unref short failure
[h264 @ 0x55a33307bd00] mmco: unref short failure
[h264 @ 0x55a33307bd00] mmco: unref short failure
[h264 @ 0x55b5b6fa1240] mmco: unref short failure
[h264 @ 0x55b5b6fa1240] mmco: unref short failure
[h264 @ 0x55b5b6fa1240] mmco: unref short failure
[h264 @ 0x55b5b6fa1240] mmco: unref short failure
[h264 @ 0x55b5b6fa1240] mmco: unref short failure
[h264 @ 0x55b5b6fa1240] mmco: unref short failure
[h264 @ 0x55b5b6fa1240] mmco: unref short failure
[h264 @ 0x55b5b6fa1240] mmco: unref short failure
[h264 @ 0x55b5b6fa1240] mmco: unref short failure
[h264 @ 0x55b5b6fa1240] mmco: unref short failure
[h264 @ 0x55b5b6fa1240] mmco: unref short failure
[h264 @ 0x55b5b6fa1240] mmco: unref short failure
[h264 @ 0x55a31db18a80] mmco: unref short failure
[h264 @ 0x55a31db18a80] mmco: unref short failure
[h264 @ 0x56075efe4080] mmco: unref short failure
[h264 @ 0x55b5cb70f500] mmco: unref short failure
[h264 @ 0x55b5cb70f500] mmco: unref short failure
[h264 @ 0x55a32f25e100] mmco: unref short failure
[h264 @ 0x55a32f25e100] mmco: unref short failure
[h264 @ 0x56074e811c00] mmco: unref short failure
[h264 @ 0x56074e811c00] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<03:07,  1.17it/s][A
  1%|          | 2/221 [00:01<02:39,  1.37it/s][A
  1%|▏         | 3/221 [00:01<01:49,  1.99it/s][A
  2%|▏         | 4/221 [00:01<01:14,  2.90it/s][A
  2%|▏         | 5/221 [00:02<01:05,  3.30it/s][A
  3%|▎         | 6/221 [00:02<00:55,  3.84it/s][A
  3%|▎         | 7/221 [00:02<00:57,  3.71it/s][A
  4%|▎         | 8/221 [00:03<01:31,  2.32it/s][A
  4%|▍         | 9/221 [00:03<01:20,  2.64it/s][A
  5%|▍         | 10/221 [00:03<01:22,  2.55it/s][A
  5%|▍         | 11/221 [00:04<01:05,  3.19it/s][A
  5%|▌         | 12/221 [00:04<01:15,  2.75it/s][A[h264 @ 0x55a315665680] mmco: unref short failure
[h264 @ 0x55a315665680] mmco: unref short failure
[h264 @ 0x55a315665680] mmco: unref short failure
[h264 @ 0x55a315665680] mmco: unref short failure

  6%|▌         | 13/221 [00:04<01:07,  3.10it/s][A09/17/2024 04:58:54 - INFO - __main__ -   current idx g0isRLf0U2E.7 from finetune_area returns wrong image/video, use 112200 instead.

  6%|▋         | 14/221 [00:06<02:20,  1.47it/s][A
  7%|▋         | 15/221 [00:06<01:53,  1.81it/s][A
  7%|▋         | 16/221 [00:06<01:43,  1.98it/s][A[h264 @ 0x55b5c220c400] mmco: unref short failure
[h264 @ 0x55b5c220c400] mmco: unref short failure

  8%|▊         | 17/221 [00:07<01:23,  2.44it/s][A
  8%|▊         | 18/221 [00:07<01:10,  2.87it/s][A
  9%|▊         | 19/221 [00:07<01:01,  3.30it/s][A[h264 @ 0x55b5c220c400] mmco: unref short failure
[h264 @ 0x55b5c220c400] mmco: unref short failure

  9%|▉         | 20/221 [00:07<01:00,  3.33it/s][A
 10%|▉         | 21/221 [00:08<00:53,  3.77it/s][A[h264 @ 0x55b5b6e13800] mmco: unref short failure
[h264 @ 0x55b5b6e13800] mmco: unref short failure

 10%|▉         | 22/221 [00:08<00:59,  3.35it/s][A
 10%|█         | 23/221 [00:08<00:53,  3.70it/s][A
 11%|█         | 24/221 [00:08<00:47,  4.16it/s][A
 11%|█▏        | 25/221 [00:09<00:48,  4.03it/s][A
 12%|█▏        | 26/221 [00:09<00:53,  3.68it/s][A
 13%|█▎        | 28/221 [00:09<00:52,  3.67it/s][A
 13%|█▎        | 29/221 [00:10<00:44,  4.33it/s][A
 14%|█▎        | 30/221 [00:10<00:44,  4.34it/s][A
 14%|█▍        | 31/221 [00:10<00:45,  4.16it/s][A[h264 @ 0x560748cfac40] mmco: unref short failure

 14%|█▍        | 32/221 [00:10<00:44,  4.20it/s][A
 15%|█▍        | 33/221 [00:11<00:55,  3.41it/s][A
 15%|█▌        | 34/221 [00:11<00:50,  3.69it/s][A
 16%|█▌        | 35/221 [00:11<00:43,  4.25it/s][A
 16%|█▋        | 36/221 [00:11<00:45,  4.04it/s][A
 17%|█▋        | 37/221 [00:12<01:04,  2.84it/s][A
 17%|█▋        | 38/221 [00:12<01:04,  2.85it/s][A
 18%|█▊        | 39/221 [00:12<00:55,  3.29it/s][A
 18%|█▊        | 40/221 [00:13<00:55,  3.26it/s][A
 19%|█▊        | 41/221 [00:13<00:44,  4.02it/s][A
 19%|█▉        | 42/221 [00:13<00:51,  3.48it/s][A
 19%|█▉        | 43/221 [00:14<00:48,  3.64it/s][A
 20%|█▉        | 44/221 [00:14<00:48,  3.66it/s][A
 20%|██        | 45/221 [00:15<01:16,  2.29it/s][A
 21%|██        | 46/221 [00:15<01:17,  2.26it/s][A[h264 @ 0x55a32ccc4fc0] mmco: unref short failure

 21%|██▏       | 47/221 [00:16<01:31,  1.90it/s][A
 22%|██▏       | 48/221 [00:16<01:12,  2.38it/s][A
 22%|██▏       | 49/221 [00:16<01:02,  2.76it/s][A
 23%|██▎       | 50/221 [00:16<00:49,  3.44it/s][A
 23%|██▎       | 51/221 [00:16<00:40,  4.15it/s][A
 24%|██▎       | 52/221 [00:17<00:40,  4.13it/s][A
 24%|██▍       | 53/221 [00:17<00:36,  4.65it/s][A
 24%|██▍       | 54/221 [00:18<01:41,  1.65it/s][A
 25%|██▍       | 55/221 [00:19<01:35,  1.73it/s][A
 25%|██▌       | 56/221 [00:19<01:19,  2.09it/s][A
 26%|██▌       | 57/221 [00:19<01:04,  2.53it/s][A
 26%|██▌       | 58/221 [00:19<00:50,  3.26it/s][A
 27%|██▋       | 59/221 [00:20<00:45,  3.56it/s][A
 27%|██▋       | 60/221 [00:20<00:48,  3.29it/s][A
 28%|██▊       | 61/221 [00:20<00:44,  3.61it/s][A
 28%|██▊       | 62/221 [00:20<00:43,  3.66it/s][A
 29%|██▊       | 63/221 [00:21<00:38,  4.15it/s][A
 29%|██▉       | 64/221 [00:21<00:32,  4.86it/s][A
 29%|██▉       | 65/221 [00:21<00:33,  4.62it/s][A09/17/2024 04:59:11 - INFO - __main__ -   current idx 4xNo2X1ZunM.19 from finetune_area returns wrong image/video, use 43691 instead.

 30%|██▉       | 66/221 [00:21<00:45,  3.42it/s][A
 30%|███       | 67/221 [00:22<00:48,  3.16it/s][A
 31%|███       | 68/221 [00:22<00:43,  3.48it/s][A[h264 @ 0x55e259d60a40] mmco: unref short failure

 31%|███       | 69/221 [00:23<01:02,  2.41it/s][A
 32%|███▏      | 70/221 [00:23<00:55,  2.74it/s][A
 32%|███▏      | 71/221 [00:26<02:31,  1.01s/it][A
 33%|███▎      | 72/221 [00:26<01:56,  1.28it/s][A
 33%|███▎      | 73/221 [00:26<01:36,  1.54it/s][A
 33%|███▎      | 74/221 [00:26<01:16,  1.92it/s][A
 34%|███▍      | 75/221 [00:27<01:08,  2.13it/s][A
 34%|███▍      | 76/221 [00:27<00:55,  2.63it/s][A
 35%|███▍      | 77/221 [00:27<00:47,  3.03it/s][A
 35%|███▌      | 78/221 [00:27<00:46,  3.06it/s][A
 36%|███▌      | 79/221 [00:28<00:58,  2.41it/s][A
 36%|███▌      | 80/221 [00:28<00:46,  3.05it/s][A
 37%|███▋      | 81/221 [00:28<00:41,  3.40it/s][A
 37%|███▋      | 82/221 [00:29<00:35,  3.93it/s][A
 38%|███▊      | 83/221 [00:29<00:30,  4.47it/s][A
 38%|███▊      | 84/221 [00:29<00:31,  4.41it/s][A
 38%|███▊      | 85/221 [00:29<00:30,  4.50it/s][A
 39%|███▉      | 86/221 [00:29<00:27,  4.83it/s][A
 39%|███▉      | 87/221 [00:30<00:43,  3.08it/s][A[h264 @ 0x56074c99e680] mmco: unref short failure
[h264 @ 0x56074c99e680] mmco: unref short failure

 40%|███▉      | 88/221 [00:30<00:46,  2.85it/s][A
 40%|████      | 89/221 [00:33<02:17,  1.04s/it][A[h264 @ 0x55a318a10040] mmco: unref short failure

 41%|████      | 90/221 [00:33<01:54,  1.15it/s][A
 41%|████      | 91/221 [00:34<01:24,  1.54it/s][A
 42%|████▏     | 92/221 [00:34<01:08,  1.89it/s][A
 42%|████▏     | 93/221 [00:34<01:12,  1.76it/s][A
 43%|████▎     | 94/221 [00:35<01:01,  2.07it/s][A
 43%|████▎     | 95/221 [00:35<00:49,  2.54it/s][A
 43%|████▎     | 96/221 [00:35<00:45,  2.75it/s][A
 44%|████▍     | 97/221 [00:35<00:36,  3.44it/s][A
 44%|████▍     | 98/221 [00:36<00:35,  3.46it/s][A
 45%|████▍     | 99/221 [00:36<00:32,  3.80it/s][A
 45%|████▌     | 100/221 [00:36<00:31,  3.79it/s][A
 46%|████▌     | 101/221 [00:36<00:29,  4.13it/s][A
 46%|████▌     | 102/221 [00:37<00:32,  3.64it/s][A
 47%|████▋     | 103/221 [00:37<00:28,  4.14it/s][A
 47%|████▋     | 104/221 [00:37<00:24,  4.86it/s][A
 48%|████▊     | 105/221 [00:37<00:26,  4.42it/s][A
 48%|████▊     | 106/221 [00:38<00:53,  2.15it/s][A
 48%|████▊     | 107/221 [00:38<00:40,  2.79it/s][A
 49%|████▉     | 108/221 [00:39<00:38,  2.95it/s][A
 49%|████▉     | 109/221 [00:39<00:37,  2.99it/s][A
 50%|████▉     | 110/221 [00:39<00:34,  3.23it/s][A
 50%|█████     | 111/221 [00:40<00:40,  2.71it/s][A
 51%|█████     | 112/221 [00:40<00:34,  3.13it/s][A
 51%|█████     | 113/221 [00:40<00:34,  3.14it/s][A
 52%|█████▏    | 114/221 [00:40<00:27,  3.91it/s][A[h264 @ 0x55b5b0387800] mmco: unref short failure
[h264 @ 0x55b5b0387800] mmco: unref short failure
[h264 @ 0x55b5b0387800] mmco: unref short failure
[h264 @ 0x55b5b0387800] mmco: unref short failure

 52%|█████▏    | 115/221 [00:41<00:24,  4.25it/s][A[h264 @ 0x55b5c0f66d40] mmco: unref short failure
[h264 @ 0x55b5c0f66d40] mmco: unref short failure

 52%|█████▏    | 116/221 [00:45<02:52,  1.64s/it][A
 53%|█████▎    | 117/221 [00:46<02:08,  1.24s/it][A
 53%|█████▎    | 118/221 [00:46<01:40,  1.03it/s][A
 54%|█████▍    | 119/221 [00:46<01:15,  1.34it/s][A
 54%|█████▍    | 120/221 [00:47<01:01,  1.64it/s][A
 55%|█████▌    | 122/221 [00:47<00:39,  2.54it/s][A
 56%|█████▌    | 123/221 [00:47<00:32,  3.00it/s][A
 56%|█████▌    | 124/221 [00:47<00:30,  3.19it/s][A[h264 @ 0x560747dbbec0] mmco: unref short failure
[h264 @ 0x560747dbbec0] mmco: unref short failure

 57%|█████▋    | 125/221 [00:48<00:30,  3.12it/s][A
 57%|█████▋    | 126/221 [00:48<00:32,  2.89it/s][A
 57%|█████▋    | 127/221 [00:49<00:38,  2.42it/s][A
 58%|█████▊    | 128/221 [00:49<00:37,  2.46it/s][A
 58%|█████▊    | 129/221 [00:49<00:33,  2.73it/s][A
 59%|█████▉    | 130/221 [00:50<00:30,  2.97it/s][A
 59%|█████▉    | 131/221 [00:50<00:25,  3.60it/s][A[h264 @ 0x55a31f819240] mmco: unref short failure

 60%|█████▉    | 132/221 [00:50<00:22,  3.89it/s][A
 60%|██████    | 133/221 [00:50<00:26,  3.30it/s][A
 61%|██████    | 134/221 [00:51<00:26,  3.27it/s][A
 61%|██████    | 135/221 [00:51<00:30,  2.78it/s][A
 62%|██████▏   | 136/221 [00:52<00:33,  2.54it/s][A
 62%|██████▏   | 137/221 [00:52<00:28,  2.98it/s][A
 62%|██████▏   | 138/221 [00:52<00:28,  2.91it/s][A
 63%|██████▎   | 139/221 [00:53<00:29,  2.77it/s][A
 63%|██████▎   | 140/221 [00:53<00:28,  2.85it/s][A
 64%|██████▍   | 141/221 [00:53<00:23,  3.36it/s][A
 64%|██████▍   | 142/221 [00:54<00:28,  2.79it/s][A
 65%|██████▍   | 143/221 [00:54<00:33,  2.32it/s][A
 65%|██████▌   | 144/221 [00:54<00:30,  2.52it/s][A
 66%|██████▌   | 145/221 [00:55<00:25,  3.04it/s][A
 66%|██████▌   | 146/221 [00:55<00:23,  3.22it/s][A
 67%|██████▋   | 147/221 [00:55<00:21,  3.44it/s][A
 67%|██████▋   | 148/221 [00:55<00:20,  3.51it/s][A
 67%|██████▋   | 149/221 [00:56<00:18,  3.80it/s][A
 68%|██████▊   | 150/221 [00:56<00:17,  4.03it/s][A
 68%|██████▊   | 151/221 [00:57<00:39,  1.78it/s][A
 69%|██████▉   | 152/221 [00:58<00:34,  2.00it/s][A
 69%|██████▉   | 153/221 [00:58<00:29,  2.28it/s][A
 70%|██████▉   | 154/221 [00:58<00:32,  2.07it/s][A
 70%|███████   | 155/221 [00:59<00:24,  2.69it/s][A
 71%|███████   | 156/221 [00:59<00:21,  3.03it/s][A
 71%|███████   | 157/221 [01:01<00:49,  1.30it/s][A
 71%|███████▏  | 158/221 [01:01<00:39,  1.58it/s][A
 72%|███████▏  | 159/221 [01:01<00:29,  2.08it/s][A
 72%|███████▏  | 160/221 [01:01<00:26,  2.34it/s][A
 73%|███████▎  | 162/221 [01:02<00:16,  3.49it/s][A
 74%|███████▍  | 163/221 [01:02<00:16,  3.60it/s][A
 74%|███████▍  | 164/221 [01:02<00:18,  3.02it/s][A[h264 @ 0x55b5c9a1dfc0] mmco: unref short failure
[h264 @ 0x55b5c9a1dfc0] mmco: unref short failure

 75%|███████▌  | 166/221 [01:03<00:17,  3.08it/s][A
 76%|███████▌  | 167/221 [01:03<00:15,  3.38it/s][A[h264 @ 0x560761d6c300] mmco: unref short failure
[h264 @ 0x560761d6c300] mmco: unref short failure

 76%|███████▌  | 168/221 [01:05<00:36,  1.47it/s][A
 76%|███████▋  | 169/221 [01:05<00:29,  1.76it/s][A
 77%|███████▋  | 170/221 [01:05<00:25,  2.00it/s][A
 77%|███████▋  | 171/221 [01:06<00:21,  2.28it/s][A
 78%|███████▊  | 172/221 [01:06<00:19,  2.54it/s][A
 78%|███████▊  | 173/221 [01:06<00:15,  3.17it/s][A
 79%|███████▉  | 175/221 [01:07<00:11,  4.01it/s][A
 80%|███████▉  | 176/221 [01:07<00:12,  3.74it/s][A
 80%|████████  | 177/221 [01:07<00:09,  4.41it/s][A
 81%|████████  | 178/221 [01:07<00:11,  3.65it/s][A
 81%|████████  | 179/221 [01:08<00:13,  3.16it/s][A
 81%|████████▏ | 180/221 [01:08<00:10,  3.84it/s][A
 82%|████████▏ | 181/221 [01:08<00:10,  3.83it/s][A
 82%|████████▏ | 182/221 [01:08<00:09,  4.27it/s][A
 83%|████████▎ | 183/221 [01:08<00:08,  4.66it/s][A
 83%|████████▎ | 184/221 [01:09<00:09,  3.72it/s][A
 84%|████████▎ | 185/221 [01:09<00:08,  4.23it/s][A
 84%|████████▍ | 186/221 [01:10<00:10,  3.24it/s][A
 85%|████████▍ | 187/221 [01:10<00:08,  3.95it/s][A
 85%|████████▌ | 188/221 [01:10<00:09,  3.60it/s][A
 86%|████████▌ | 189/221 [01:10<00:09,  3.54it/s][A
 86%|████████▌ | 190/221 [01:11<00:08,  3.46it/s][A
 86%|████████▋ | 191/221 [01:11<00:06,  4.29it/s][A
 87%|████████▋ | 192/221 [01:11<00:06,  4.54it/s][A
 88%|████████▊ | 194/221 [01:12<00:07,  3.51it/s][A
 88%|████████▊ | 195/221 [01:12<00:06,  3.99it/s][A
 89%|████████▉ | 197/221 [01:12<00:04,  5.37it/s][A
 90%|████████▉ | 198/221 [01:12<00:04,  4.84it/s][A
 90%|█████████ | 199/221 [01:12<00:04,  4.72it/s][A
 90%|█████████ | 200/221 [01:13<00:05,  3.88it/s][A
 91%|█████████ | 201/221 [01:13<00:05,  3.80it/s][A
 91%|█████████▏| 202/221 [01:13<00:04,  4.12it/s][A
 92%|█████████▏| 203/221 [01:13<00:04,  4.47it/s][A
 92%|█████████▏| 204/221 [01:14<00:03,  5.20it/s][A[h264 @ 0x55e2577b0ec0] mmco: unref short failure

 93%|█████████▎| 205/221 [01:14<00:02,  5.89it/s][A
 93%|█████████▎| 206/221 [01:14<00:04,  3.29it/s][A
 94%|█████████▍| 208/221 [01:15<00:02,  4.46it/s][A
 95%|█████████▌| 210/221 [01:15<00:01,  6.30it/s][A
 95%|█████████▌| 211/221 [01:15<00:02,  4.85it/s][A
 96%|█████████▌| 212/221 [01:15<00:01,  5.15it/s][A
 97%|█████████▋| 214/221 [01:16<00:01,  3.77it/s][A
 97%|█████████▋| 215/221 [01:16<00:01,  3.90it/s][A
 98%|█████████▊| 216/221 [01:16<00:01,  3.82it/s][A
 98%|█████████▊| 217/221 [01:17<00:01,  3.08it/s][A
 99%|█████████▊| 218/221 [01:17<00:00,  3.14it/s][A
 99%|█████████▉| 219/221 [01:18<00:00,  3.33it/s][A[h264 @ 0x55a330263980] mmco: unref short failure

100%|█████████▉| 220/221 [01:21<00:01,  1.31s/it][A
100%|██████████| 221/221 [01:22<00:00,  1.00it/s][A100%|██████████| 221/221 [01:22<00:00,  2.69it/s]
[h264 @ 0x55e240f84180] mmco: unref short failure
[h264 @ 0x55e240f84180] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:04,  3.41it/s][A
  1%|          | 2/221 [00:00<01:05,  3.36it/s][A
  1%|▏         | 3/221 [00:00<01:04,  3.37it/s][A
  2%|▏         | 4/221 [00:01<01:04,  3.38it/s][A
  2%|▏         | 5/221 [00:01<01:03,  3.39it/s][A
  3%|▎         | 6/221 [00:01<01:03,  3.39it/s][A
  3%|▎         | 7/221 [00:02<01:03,  3.35it/s][A
  4%|▎         | 8/221 [00:02<01:03,  3.37it/s][A
  4%|▍         | 9/221 [00:02<01:02,  3.37it/s][A
  5%|▍         | 10/221 [00:02<01:03,  3.31it/s][A
  5%|▍         | 11/221 [00:03<01:02,  3.34it/s][A
  5%|▌         | 12/221 [00:03<01:03,  3.31it/s][A
  6%|▌         | 13/221 [00:03<01:02,  3.34it/s][A
  6%|▋         | 14/221 [00:04<01:01,  3.35it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.34it/s][A[h264 @ 0x55e240c2cb40] mmco: unref short failure
[h264 @ 0x55e240c2cb40] mmco: unref short failure

  7%|▋         | 16/221 [00:04<01:01,  3.32it/s][A
  8%|▊         | 17/221 [00:05<01:00,  3.35it/s][A
  8%|▊         | 18/221 [00:05<01:00,  3.36it/s][A
  9%|▊         | 19/221 [00:05<00:59,  3.38it/s][A
  9%|▉         | 20/221 [00:05<01:01,  3.27it/s][A
 10%|▉         | 21/221 [00:06<01:00,  3.31it/s][A
 10%|▉         | 22/221 [00:06<01:00,  3.29it/s][A
 10%|█         | 23/221 [00:06<00:59,  3.32it/s][A
 11%|█         | 24/221 [00:07<00:58,  3.34it/s][A
 11%|█▏        | 25/221 [00:07<00:59,  3.30it/s][A
 12%|█▏        | 26/221 [00:07<00:58,  3.33it/s][A
 12%|█▏        | 27/221 [00:08<00:58,  3.31it/s][A
 13%|█▎        | 28/221 [00:08<00:58,  3.33it/s][A
 13%|█▎        | 29/221 [00:08<00:57,  3.32it/s][A
 14%|█▎        | 30/221 [00:09<00:58,  3.28it/s][A
 14%|█▍        | 31/221 [00:09<00:57,  3.32it/s][A
 14%|█▍        | 32/221 [00:09<00:57,  3.30it/s][A[h264 @ 0x55b5bdf3e8c0] mmco: unref short failure
[h264 @ 0x55b5bdf3e8c0] mmco: unref short failure
[h264 @ 0x55b5bdf3e8c0] mmco: unref short failure
[h264 @ 0x55b5bdf3e8c0] mmco: unref short failure

 15%|█▍        | 33/221 [00:09<00:57,  3.29it/s][A
 15%|█▌        | 34/221 [00:10<00:56,  3.30it/s][A
 16%|█▌        | 35/221 [00:10<00:55,  3.33it/s][A
 16%|█▋        | 36/221 [00:10<00:55,  3.35it/s][A
 17%|█▋        | 37/221 [00:11<00:54,  3.36it/s][A
 17%|█▋        | 38/221 [00:11<00:54,  3.38it/s][A
 18%|█▊        | 39/221 [00:11<00:53,  3.39it/s][A
 18%|█▊        | 40/221 [00:11<00:53,  3.39it/s][A
 19%|█▊        | 41/221 [00:12<00:53,  3.40it/s][A
 19%|█▉        | 42/221 [00:12<00:52,  3.40it/s][A
 19%|█▉        | 43/221 [00:12<00:52,  3.40it/s][A
 20%|█▉        | 44/221 [00:13<00:52,  3.40it/s][A
 20%|██        | 45/221 [00:13<00:51,  3.39it/s][A
 21%|██        | 46/221 [00:13<00:51,  3.40it/s][A
 21%|██▏       | 47/221 [00:14<00:51,  3.40it/s][A
 22%|██▏       | 48/221 [00:14<00:50,  3.40it/s][A
 22%|██▏       | 49/221 [00:14<00:50,  3.40it/s][A
 23%|██▎       | 50/221 [00:14<00:50,  3.40it/s][A
 23%|██▎       | 51/221 [00:15<00:49,  3.40it/s][A
 24%|██▎       | 52/221 [00:15<00:49,  3.40it/s][A
 24%|██▍       | 53/221 [00:15<00:49,  3.40it/s][A
 24%|██▍       | 54/221 [00:16<00:49,  3.39it/s][A
 25%|██▍       | 55/221 [00:16<00:49,  3.37it/s][A
 25%|██▌       | 56/221 [00:16<00:48,  3.38it/s][A
 26%|██▌       | 57/221 [00:16<00:48,  3.39it/s][A
 26%|██▌       | 58/221 [00:17<00:48,  3.37it/s][A
 27%|██▋       | 59/221 [00:17<00:47,  3.38it/s][A
 27%|██▋       | 60/221 [00:17<00:47,  3.39it/s][A
 28%|██▊       | 61/221 [00:18<00:47,  3.39it/s][A
 28%|██▊       | 62/221 [00:18<00:46,  3.40it/s][A
 29%|██▊       | 63/221 [00:18<00:46,  3.40it/s][A
 29%|██▉       | 64/221 [00:19<00:46,  3.40it/s][A
 29%|██▉       | 65/221 [00:19<00:45,  3.40it/s][A
 30%|██▉       | 66/221 [00:19<00:45,  3.40it/s][A[h264 @ 0x55b5a9ef4880] mmco: unref short failure

 30%|███       | 67/221 [00:19<00:45,  3.38it/s][A
 31%|███       | 68/221 [00:20<00:45,  3.39it/s][A
 31%|███       | 69/221 [00:20<00:44,  3.39it/s][A
 32%|███▏      | 70/221 [00:20<00:44,  3.40it/s][A
 32%|███▏      | 71/221 [00:21<00:44,  3.40it/s][A
 33%|███▎      | 72/221 [00:21<00:43,  3.40it/s][A
 33%|███▎      | 73/221 [00:21<00:43,  3.41it/s][A
 33%|███▎      | 74/221 [00:21<00:43,  3.41it/s][A
 34%|███▍      | 75/221 [00:22<00:42,  3.41it/s][A
 34%|███▍      | 76/221 [00:22<00:42,  3.41it/s][A
 35%|███▍      | 77/221 [00:22<00:42,  3.41it/s][A
 35%|███▌      | 78/221 [00:23<00:41,  3.41it/s][A
 36%|███▌      | 79/221 [00:23<00:41,  3.41it/s][A
 36%|███▌      | 80/221 [00:23<00:41,  3.41it/s][A
 37%|███▋      | 81/221 [00:24<00:41,  3.41it/s][A
 37%|███▋      | 82/221 [00:24<00:40,  3.41it/s][A
 38%|███▊      | 83/221 [00:24<00:40,  3.41it/s][A
 38%|███▊      | 84/221 [00:24<00:40,  3.41it/s][A
 38%|███▊      | 85/221 [00:25<00:39,  3.41it/s][A
 39%|███▉      | 86/221 [00:25<00:39,  3.42it/s][A
 39%|███▉      | 87/221 [00:25<00:39,  3.42it/s][A
 40%|███▉      | 88/221 [00:26<00:38,  3.42it/s][A
 40%|████      | 89/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 90/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 91/221 [00:26<00:38,  3.42it/s][A
 42%|████▏     | 92/221 [00:27<00:37,  3.42it/s][A
 42%|████▏     | 93/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 94/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 95/221 [00:28<00:36,  3.42it/s][A
 43%|████▎     | 96/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 97/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 98/221 [00:29<00:35,  3.42it/s][A
 45%|████▍     | 99/221 [00:29<00:35,  3.42it/s][A
 45%|████▌     | 100/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 101/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 102/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 104/221 [00:30<00:34,  3.42it/s][A
 48%|████▊     | 105/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 107/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 108/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 109/221 [00:32<00:32,  3.42it/s][A
 50%|████▉     | 110/221 [00:32<00:32,  3.42it/s][A
 50%|█████     | 111/221 [00:32<00:32,  3.42it/s][A
 51%|█████     | 112/221 [00:33<00:31,  3.42it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 114/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:33<00:30,  3.42it/s][A
 52%|█████▏    | 116/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:34<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:35<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:35<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:38<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:38<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:39<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:40<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:40<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:41<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:43<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:45<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:45<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:45<00:18,  3.42it/s][A
 71%|███████   | 157/221 [00:46<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:47<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:48<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:48<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:48<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:49<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:49<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:50<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:50<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:51<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:52<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:52<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:54<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:55<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:55<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:56<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:57<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:57<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:57<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:58<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [00:59<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:03<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:04<00:00,  3.42it/s][A100%|██████████| 221/221 [01:04<00:00,  3.40it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:30,  7.18it/s][A
  1%|          | 2/221 [00:00<00:40,  5.37it/s][A
  1%|▏         | 3/221 [00:00<01:03,  3.41it/s][A
  2%|▏         | 4/221 [00:00<00:48,  4.45it/s][A
  2%|▏         | 5/221 [00:01<00:48,  4.42it/s][A
  3%|▎         | 7/221 [00:01<00:46,  4.60it/s][A
  4%|▎         | 8/221 [00:01<00:50,  4.24it/s][A
  4%|▍         | 9/221 [00:02<00:52,  4.01it/s][A
  5%|▍         | 10/221 [00:02<00:44,  4.76it/s][A
  5%|▍         | 11/221 [00:02<00:51,  4.10it/s][A
  5%|▌         | 12/221 [00:02<00:48,  4.33it/s][A
  6%|▌         | 13/221 [00:03<01:31,  2.28it/s][A
  6%|▋         | 14/221 [00:03<01:12,  2.87it/s][A
  7%|▋         | 15/221 [00:04<01:19,  2.60it/s][A
  7%|▋         | 16/221 [00:04<01:23,  2.46it/s][A
  8%|▊         | 17/221 [00:05<01:19,  2.57it/s][A
  8%|▊         | 18/221 [00:05<01:08,  2.95it/s][A
  9%|▉         | 20/221 [00:05<00:55,  3.61it/s][A
 10%|▉         | 21/221 [00:05<00:49,  4.02it/s][A
 10%|▉         | 22/221 [00:06<00:45,  4.38it/s][A
 10%|█         | 23/221 [00:06<00:38,  5.13it/s][A
 11%|█         | 24/221 [00:06<00:35,  5.49it/s][A
 11%|█▏        | 25/221 [00:06<00:47,  4.11it/s][A
 12%|█▏        | 26/221 [00:07<00:50,  3.88it/s][A
 12%|█▏        | 27/221 [00:07<00:53,  3.62it/s][A
 13%|█▎        | 28/221 [00:07<01:00,  3.19it/s][A
 13%|█▎        | 29/221 [00:08<01:00,  3.18it/s][A
 14%|█▎        | 30/221 [00:08<01:06,  2.89it/s][A
 14%|█▍        | 31/221 [00:08<01:03,  2.99it/s][A
 14%|█▍        | 32/221 [00:09<00:57,  3.30it/s][A
 15%|█▍        | 33/221 [00:09<01:02,  3.00it/s][A
 15%|█▌        | 34/221 [00:10<01:30,  2.07it/s][A
 16%|█▌        | 35/221 [00:10<01:12,  2.55it/s][A
 16%|█▋        | 36/221 [00:10<01:04,  2.89it/s][A
 17%|█▋        | 37/221 [00:10<00:56,  3.25it/s][A
 17%|█▋        | 38/221 [00:11<00:54,  3.33it/s][A
 18%|█▊        | 39/221 [00:11<00:46,  3.92it/s][A
 18%|█▊        | 40/221 [00:11<00:47,  3.84it/s][A
 19%|█▊        | 41/221 [00:11<00:50,  3.59it/s][A
 19%|█▉        | 42/221 [00:12<00:42,  4.20it/s][A
 19%|█▉        | 43/221 [00:12<00:43,  4.08it/s][A
 20%|█▉        | 44/221 [00:12<00:43,  4.10it/s][A
 20%|██        | 45/221 [00:12<00:49,  3.56it/s][A
 21%|██        | 46/221 [00:13<00:44,  3.95it/s][A
 21%|██▏       | 47/221 [00:13<00:39,  4.38it/s][A
 22%|██▏       | 48/221 [00:13<00:33,  5.18it/s][A
 23%|██▎       | 50/221 [00:13<00:34,  5.01it/s][A
 23%|██▎       | 51/221 [00:14<00:37,  4.53it/s][A
 24%|██▎       | 52/221 [00:14<00:35,  4.79it/s][A
 24%|██▍       | 53/221 [00:14<00:42,  3.97it/s][A
 24%|██▍       | 54/221 [00:14<00:40,  4.10it/s][A
 25%|██▍       | 55/221 [00:15<00:47,  3.49it/s][A
 25%|██▌       | 56/221 [00:15<00:44,  3.69it/s][A
 26%|██▌       | 57/221 [00:15<00:50,  3.22it/s][A
 26%|██▌       | 58/221 [00:16<00:51,  3.19it/s][A
 27%|██▋       | 59/221 [00:16<00:51,  3.15it/s][A
 27%|██▋       | 60/221 [00:16<00:42,  3.78it/s][A
 28%|██▊       | 61/221 [00:16<00:39,  4.08it/s][A
 28%|██▊       | 62/221 [00:17<00:43,  3.65it/s][A
 29%|██▉       | 64/221 [00:17<00:33,  4.69it/s][A
 29%|██▉       | 65/221 [00:17<00:34,  4.54it/s][A
 30%|██▉       | 66/221 [00:18<00:37,  4.09it/s][A
 30%|███       | 67/221 [00:18<00:45,  3.40it/s][A
 31%|███       | 68/221 [00:18<00:42,  3.58it/s][A
 31%|███       | 69/221 [00:19<00:56,  2.69it/s][A
 32%|███▏      | 70/221 [00:19<00:47,  3.17it/s][A
 32%|███▏      | 71/221 [00:19<00:48,  3.08it/s][A
 33%|███▎      | 72/221 [00:20<00:50,  2.93it/s][A
 33%|███▎      | 73/221 [00:20<00:49,  2.98it/s][A
 33%|███▎      | 74/221 [00:20<00:45,  3.20it/s][A
 34%|███▍      | 75/221 [00:21<00:46,  3.17it/s][A
 34%|███▍      | 76/221 [00:21<00:37,  3.91it/s][A
 35%|███▍      | 77/221 [00:21<00:39,  3.61it/s][A
 35%|███▌      | 78/221 [00:22<00:47,  3.02it/s][A
 36%|███▌      | 79/221 [00:22<00:43,  3.29it/s][A
 36%|███▌      | 80/221 [00:22<00:39,  3.55it/s][A
 37%|███▋      | 81/221 [00:22<00:37,  3.76it/s][A
 37%|███▋      | 82/221 [00:22<00:35,  3.92it/s][A
 38%|███▊      | 83/221 [00:23<00:32,  4.19it/s][A
 38%|███▊      | 84/221 [00:23<00:42,  3.25it/s][A
 38%|███▊      | 85/221 [00:24<00:47,  2.85it/s][A
 39%|███▉      | 86/221 [00:24<00:49,  2.74it/s][A
 39%|███▉      | 87/221 [00:24<00:53,  2.50it/s][A
 40%|███▉      | 88/221 [00:25<00:49,  2.67it/s][A
 40%|████      | 89/221 [00:25<00:49,  2.69it/s][A
 41%|████      | 90/221 [00:26<00:52,  2.49it/s][A
 41%|████      | 91/221 [00:26<00:46,  2.80it/s][A
 42%|████▏     | 92/221 [00:26<00:48,  2.67it/s][A
 42%|████▏     | 93/221 [00:27<01:02,  2.06it/s][A
 43%|████▎     | 94/221 [00:27<00:51,  2.45it/s][A
 43%|████▎     | 95/221 [00:28<01:00,  2.07it/s][A
 43%|████▎     | 96/221 [00:28<00:55,  2.24it/s][A
 44%|████▍     | 97/221 [00:29<00:47,  2.60it/s][A
 44%|████▍     | 98/221 [00:29<00:45,  2.73it/s][A
 45%|████▍     | 99/221 [00:29<00:38,  3.20it/s][A
 45%|████▌     | 100/221 [00:29<00:31,  3.83it/s][A
 46%|████▌     | 101/221 [00:29<00:26,  4.46it/s][A
 46%|████▌     | 102/221 [00:30<00:30,  3.90it/s][A
 47%|████▋     | 103/221 [00:30<00:27,  4.23it/s][A
 47%|████▋     | 104/221 [00:30<00:25,  4.62it/s][A
 48%|████▊     | 105/221 [00:30<00:30,  3.75it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 107/221 [00:31<00:32,  3.49it/s][A
 49%|████▉     | 108/221 [00:31<00:28,  3.91it/s][A
 49%|████▉     | 109/221 [00:31<00:28,  3.99it/s][A
 50%|████▉     | 110/221 [00:32<00:28,  3.95it/s][A
 50%|█████     | 111/221 [00:32<00:32,  3.42it/s][A
 51%|█████     | 112/221 [00:32<00:34,  3.15it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 114/221 [00:33<00:26,  4.06it/s][A
 52%|█████▏    | 115/221 [00:33<00:24,  4.34it/s][A
 52%|█████▏    | 116/221 [00:33<00:22,  4.68it/s][A
 53%|█████▎    | 117/221 [00:33<00:23,  4.46it/s][A
 53%|█████▎    | 118/221 [00:34<00:31,  3.24it/s][A
 54%|█████▍    | 119/221 [00:34<00:35,  2.89it/s][A
 54%|█████▍    | 120/221 [00:35<00:33,  3.05it/s][A
 55%|█████▍    | 121/221 [00:35<00:28,  3.45it/s][A
 55%|█████▌    | 122/221 [00:35<00:26,  3.73it/s][A
 56%|█████▌    | 123/221 [00:35<00:28,  3.48it/s][A
 56%|█████▌    | 124/221 [00:36<00:29,  3.34it/s][A
 57%|█████▋    | 125/221 [00:36<00:37,  2.58it/s][A
 57%|█████▋    | 126/221 [00:36<00:29,  3.20it/s][A
 57%|█████▋    | 127/221 [00:37<00:40,  2.35it/s][A
 58%|█████▊    | 128/221 [00:37<00:33,  2.77it/s][A
 58%|█████▊    | 129/221 [00:38<00:29,  3.14it/s][A
 59%|█████▉    | 130/221 [00:38<00:28,  3.14it/s][A
 59%|█████▉    | 131/221 [00:38<00:24,  3.62it/s][A
 60%|█████▉    | 132/221 [00:38<00:23,  3.71it/s][A
 60%|██████    | 133/221 [00:39<00:33,  2.59it/s][A
 61%|██████    | 134/221 [00:40<00:38,  2.27it/s][A
 62%|██████▏   | 136/221 [00:40<00:28,  3.01it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.40it/s][A
 62%|██████▏   | 138/221 [00:40<00:23,  3.59it/s][A
 63%|██████▎   | 139/221 [00:41<00:25,  3.20it/s][A
 63%|██████▎   | 140/221 [00:41<00:22,  3.53it/s][A
 64%|██████▍   | 141/221 [00:41<00:24,  3.25it/s][A
 64%|██████▍   | 142/221 [00:42<00:22,  3.59it/s][A
 65%|██████▍   | 143/221 [00:42<00:21,  3.56it/s][A
 65%|██████▌   | 144/221 [00:42<00:21,  3.56it/s][A
 66%|██████▌   | 145/221 [00:43<00:23,  3.24it/s][A
 66%|██████▌   | 146/221 [00:43<00:23,  3.22it/s][A
 67%|██████▋   | 147/221 [00:43<00:20,  3.58it/s][A
 67%|██████▋   | 148/221 [00:43<00:20,  3.61it/s][A
 67%|██████▋   | 149/221 [00:44<00:18,  3.83it/s][A
 68%|██████▊   | 150/221 [00:44<00:19,  3.64it/s][A
 68%|██████▊   | 151/221 [00:44<00:23,  2.95it/s][A
 69%|██████▉   | 152/221 [00:45<00:34,  2.00it/s][A
 69%|██████▉   | 153/221 [00:45<00:28,  2.42it/s][A
 70%|██████▉   | 154/221 [00:46<00:25,  2.60it/s][A
 70%|███████   | 155/221 [00:46<00:24,  2.72it/s][A
 71%|███████   | 156/221 [00:46<00:20,  3.20it/s][A
 71%|███████   | 157/221 [00:47<00:19,  3.33it/s][A
 71%|███████▏  | 158/221 [00:47<00:20,  3.02it/s][A
 72%|███████▏  | 159/221 [00:47<00:17,  3.47it/s][A
 72%|███████▏  | 160/221 [00:47<00:15,  3.89it/s][A
 73%|███████▎  | 161/221 [00:47<00:14,  4.17it/s][A
 73%|███████▎  | 162/221 [00:48<00:11,  4.98it/s][A
 74%|███████▍  | 163/221 [00:48<00:12,  4.50it/s][A
 74%|███████▍  | 164/221 [00:48<00:12,  4.67it/s][A
 75%|███████▍  | 165/221 [00:48<00:12,  4.40it/s][A
 75%|███████▌  | 166/221 [00:49<00:14,  3.80it/s][A
 76%|███████▌  | 167/221 [00:49<00:12,  4.37it/s][A
 76%|███████▌  | 168/221 [00:49<00:11,  4.49it/s][A
 77%|███████▋  | 170/221 [00:50<00:15,  3.34it/s][A
 77%|███████▋  | 171/221 [00:50<00:15,  3.15it/s][A
 78%|███████▊  | 172/221 [00:51<00:16,  2.99it/s][A
 78%|███████▊  | 173/221 [00:51<00:15,  3.04it/s][A
 79%|███████▊  | 174/221 [00:51<00:12,  3.66it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.45it/s][A
 80%|███████▉  | 176/221 [00:52<00:11,  3.81it/s][A
 80%|████████  | 177/221 [00:52<00:11,  3.81it/s][A
 81%|████████  | 178/221 [00:53<00:16,  2.54it/s][A
 81%|████████  | 179/221 [00:53<00:14,  2.85it/s][A
 81%|████████▏ | 180/221 [00:53<00:13,  3.08it/s][A
 82%|████████▏ | 181/221 [00:54<00:15,  2.61it/s][A
 82%|████████▏ | 182/221 [00:54<00:13,  2.80it/s][A
 83%|████████▎ | 183/221 [00:54<00:12,  3.02it/s][A
 83%|████████▎ | 184/221 [00:54<00:12,  2.92it/s][A
 84%|████████▍ | 186/221 [00:55<00:10,  3.25it/s][A
 85%|████████▍ | 187/221 [00:55<00:09,  3.41it/s][A
 85%|████████▌ | 188/221 [00:56<00:09,  3.33it/s][A
 86%|████████▌ | 189/221 [00:56<00:08,  3.64it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.19it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.75it/s][A
 87%|████████▋ | 192/221 [00:57<00:07,  3.95it/s][A
 87%|████████▋ | 193/221 [00:57<00:06,  4.30it/s][A
 88%|████████▊ | 194/221 [00:57<00:06,  4.34it/s][A
 88%|████████▊ | 195/221 [00:57<00:06,  4.33it/s][A
 89%|████████▊ | 196/221 [00:58<00:08,  2.94it/s][A
 89%|████████▉ | 197/221 [00:58<00:08,  2.75it/s][A
 90%|████████▉ | 198/221 [00:59<00:08,  2.63it/s][A
 90%|█████████ | 199/221 [00:59<00:07,  3.11it/s][A
 90%|█████████ | 200/221 [00:59<00:06,  3.22it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.48it/s][A
 91%|█████████▏| 202/221 [01:00<00:05,  3.39it/s][A
 92%|█████████▏| 203/221 [01:00<00:05,  3.59it/s][A
 92%|█████████▏| 204/221 [01:00<00:05,  3.19it/s][A
 93%|█████████▎| 205/221 [01:01<00:04,  3.50it/s][A
 93%|█████████▎| 206/221 [01:01<00:05,  2.90it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  2.83it/s][A
 94%|█████████▍| 208/221 [01:02<00:03,  3.34it/s][A
 95%|█████████▍| 209/221 [01:02<00:03,  3.52it/s][A
 95%|█████████▌| 210/221 [01:02<00:03,  3.18it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.46it/s][A
 96%|█████████▌| 212/221 [01:03<00:02,  3.28it/s][A
 96%|█████████▋| 213/221 [01:03<00:02,  3.34it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:04<00:01,  3.30it/s][A
 98%|█████████▊| 216/221 [01:04<00:01,  3.19it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.39it/s][A
 99%|█████████▊| 218/221 [01:05<00:00,  3.22it/s][A
 99%|█████████▉| 219/221 [01:05<00:00,  3.01it/s][A
100%|█████████▉| 220/221 [01:05<00:00,  3.49it/s][A
100%|██████████| 221/221 [01:06<00:00,  3.13it/s][A100%|██████████| 221/221 [01:06<00:00,  3.35it/s]
09/17/2024 05:02:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 899--===========

09/17/2024 05:02:29 - INFO - __main__ -   {'area_r1': 40.7, 'area_recall': '40.7/65.7/75.2', 'area_ravg': 60.6}
09/17/2024 05:02:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 899--===========

09/17/2024 05:02:29 - INFO - __main__ -   {'forward_r1': 39.3, 'forward_recall': '39.3/66.3/77.8', 'forward_ravg': 61.1}
09/17/2024 05:02:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 899--===========

09/17/2024 05:02:29 - INFO - __main__ -   {'area_video_r1': 40.2, 'area_video_recall': '40.2/67.2/78.4', 'area_video_ravg': 61.9}
09/17/2024 05:02:29 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 299=======

09/17/2024 05:02:29 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 05:02:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 899--===========

09/17/2024 05:02:29 - INFO - __main__ -   {'area_video_r1': 53.1, 'area_video_recall': '53.1/75.5/82.1', 'area_video_ravg': 70.2, 'area_video_back_r1': 47.3, 'area_video_back_recall': '47.3/74.9/81.9', 'area_video_back_ravg': 68.0}
09/17/2024 05:02:29 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 549=======

09/17/2024 05:02:29 - INFO - __main__ -   {'area_video_r1': 54.1, 'area_video_recall': '54.1/75.5/82.4', 'area_video_ravg': 70.6, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.5/82.1', 'area_video_back_ravg': 68.7}
09/17/2024 05:02:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 899--===========

09/17/2024 05:02:29 - INFO - __main__ -   {'video_r1': 37.8, 'video_recall': '37.8/63.1/74.8', 'video_ravg': 58.6}
09/17/2024 05:02:29 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 899=======

09/17/2024 05:02:29 - INFO - __main__ -   {'video_r1': 37.8, 'video_recall': '37.8/63.1/74.8', 'video_ravg': 58.6}
09/17/2024 05:02:29 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 899--===========

09/17/2024 05:02:29 - INFO - __main__ -   {'video_r1': 53.4, 'video_recall': '53.4/75.8/82.4', 'video_ravg': 70.5}
09/17/2024 05:02:29 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 549=======

09/17/2024 05:02:29 - INFO - __main__ -   {'video_r1': 54.5, 'video_recall': '54.5/76.1/83.4', 'video_ravg': 71.3}
09/17/2024 05:02:55 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.006858320906758308, 'loss_ret%tv%ta--finetune_area/loss_area': 1.0891212224960327, 'loss_ret%tv%ta--finetune_area/total_loss': 1.0959795713424683}
[h264 @ 0x55b5c53700c0] mmco: unref short failure
 31%|███       | 900/2910 [5:41:11<75:41:21, 135.56s/it] 31%|███       | 901/2910 [5:41:15<53:32:56, 95.96s/it] 09/17/2024 05:03:03 - INFO - __main__ -   current idx Zsx1-4aJ4ys.28 from finetune_area returns wrong image/video, use 4441 instead.
 31%|███       | 902/2910 [5:41:19<38:11:00, 68.46s/it][h264 @ 0x5607484ada00] mmco: unref short failure
[h264 @ 0x5607484ada00] mmco: unref short failure
 31%|███       | 903/2910 [5:41:23<27:22:04, 49.09s/it][h264 @ 0x55b5b59d7040] mmco: unref short failure
 31%|███       | 904/2910 [5:41:27<19:53:27, 35.70s/it] 31%|███       | 905/2910 [5:41:33<14:49:27, 26.62s/it][h264 @ 0x560746081600] mmco: unref short failure
[h264 @ 0x560746081600] mmco: unref short failure
[h264 @ 0x55b5cbee3c80] mmco: unref short failure
[h264 @ 0x55e254e92d00] mmco: unref short failure
[h264 @ 0x55e254e92d00] mmco: unref short failure
 31%|███       | 906/2910 [5:41:38<11:13:37, 20.17s/it][h264 @ 0x55b5b6e25980] mmco: unref short failure
[h264 @ 0x55b5b6e25980] mmco: unref short failure
[h264 @ 0x56074d4e2ec0] mmco: unref short failure
[h264 @ 0x56074d4e2ec0] mmco: unref short failure
 31%|███       | 907/2910 [5:41:43<8:40:48, 15.60s/it] [h264 @ 0x55a325f6e480] mmco: unref short failure
 31%|███       | 908/2910 [5:41:49<7:03:39, 12.70s/it] 31%|███       | 909/2910 [5:41:54<5:48:21, 10.45s/it][h264 @ 0x560754bd6d40] mmco: unref short failure
[h264 @ 0x55a32817e880] mmco: unref short failure
[h264 @ 0x55a32817e880] mmco: unref short failure
 31%|███▏      | 910/2910 [5:41:59<4:53:47,  8.81s/it][h264 @ 0x560751433a40] mmco: unref short failure
[h264 @ 0x560751433a40] mmco: unref short failure
 31%|███▏      | 911/2910 [5:42:05<4:28:43,  8.07s/it] 31%|███▏      | 912/2910 [5:42:11<4:01:54,  7.26s/it] 31%|███▏      | 913/2910 [5:42:16<3:42:50,  6.70s/it][h264 @ 0x55a31e21ec00] mmco: unref short failure
[h264 @ 0x55a31e21ec00] mmco: unref short failure
[h264 @ 0x55b5b8a1b600] mmco: unref short failure
 31%|███▏      | 914/2910 [5:42:23<3:47:49,  6.85s/it] 31%|███▏      | 915/2910 [5:42:29<3:34:09,  6.44s/it][h264 @ 0x560751513200] mmco: unref short failure
[h264 @ 0x560751513200] mmco: unref short failure
[h264 @ 0x55a32a668580] mmco: unref short failure
[h264 @ 0x55a32a668580] mmco: unref short failure
[h264 @ 0x55e25720fa00] mmco: unref short failure
[h264 @ 0x55a317cee140] mmco: unref short failure
[h264 @ 0x55a317cee140] mmco: unref short failure
[h264 @ 0x560744625d80] mmco: unref short failure
[h264 @ 0x560744625d80] mmco: unref short failure
[h264 @ 0x560760d31500] mmco: unref short failure
[h264 @ 0x560760d31500] mmco: unref short failure
[h264 @ 0x560748cc1b00] mmco: unref short failure
[h264 @ 0x560748cc1b00] mmco: unref short failure
[h264 @ 0x55e24bf28e80] mmco: unref short failure
[h264 @ 0x55a32ca1b1c0] mmco: unref short failure
 31%|███▏      | 916/2910 [5:43:27<12:12:06, 22.03s/it] 32%|███▏      | 917/2910 [5:43:33<9:29:14, 17.14s/it] [h264 @ 0x560754bd6d40] mmco: unref short failure
[h264 @ 0x55e2564689c0] mmco: unref short failure
[h264 @ 0x55e2564689c0] mmco: unref short failure
[h264 @ 0x55a321018f00] mmco: unref short failure
[h264 @ 0x55a321018f00] mmco: unref short failure
[h264 @ 0x55a321018f00] mmco: unref short failure
[h264 @ 0x55a321018f00] mmco: unref short failure
[h264 @ 0x55b5b20a5d40] mmco: unref short failure
[h264 @ 0x56074803b280] mmco: unref short failure
[h264 @ 0x55a321018f00] mmco: unref short failure
[h264 @ 0x55a321018f00] mmco: unref short failure
 32%|███▏      | 918/2910 [5:43:46<8:48:36, 15.92s/it]09/17/2024 05:05:39 - INFO - __main__ -   current idx 9W2zPcc4Kl8.5 from finetune_area returns wrong image/video, use 77506 instead.
[h264 @ 0x55b5b5678380] mmco: unref short failure
 32%|███▏      | 919/2910 [5:43:55<7:35:44, 13.73s/it][h264 @ 0x560753fbcf40] mmco: unref short failure
 32%|███▏      | 920/2910 [5:44:05<6:58:21, 12.61s/it][h264 @ 0x56075b907540] mmco: unref short failure
 32%|███▏      | 921/2910 [5:44:20<7:23:15, 13.37s/it][h264 @ 0x55b5c7774d80] mmco: unref short failure
[h264 @ 0x55b5c7774d80] mmco: unref short failure
09/17/2024 05:06:11 - INFO - __main__ -   current idx JyHu6qXDg1E.525 from finetune_area returns wrong image/video, use 35537 instead.
 32%|███▏      | 922/2910 [5:44:26<6:08:13, 11.11s/it][h264 @ 0x55e24fd47bc0] mmco: unref short failure
[h264 @ 0x55e24fd47bc0] mmco: unref short failure
[h264 @ 0x55a31a07dec0] mmco: unref short failure
[h264 @ 0x55a31a07dec0] mmco: unref short failure
 32%|███▏      | 923/2910 [5:44:31<5:11:41,  9.41s/it][h264 @ 0x560741912b80] mmco: unref short failure
[h264 @ 0x55b5ca1e8840] mmco: unref short failure
[h264 @ 0x55b5ca1e8840] mmco: unref short failure
[h264 @ 0x55a31f648ac0] mmco: unref short failure
[h264 @ 0x55a31f648ac0] mmco: unref short failure
[h264 @ 0x55b5bfbeea40] mmco: unref short failure
[h264 @ 0x55b5bfbeea40] mmco: unref short failure
[h264 @ 0x560748c1bd00] mmco: unref short failure
[h264 @ 0x560748c1bd00] mmco: unref short failure
09/17/2024 05:06:49 - INFO - __main__ -   current idx 6aaFlMlB90k.2 from finetune_area returns wrong image/video, use 96989 instead.
[h264 @ 0x560743d224c0] mmco: unref short failure
[h264 @ 0x560743d224c0] mmco: unref short failure
[h264 @ 0x560743d224c0] mmco: unref short failure
[h264 @ 0x560743d224c0] mmco: unref short failure
[h264 @ 0x55a32ca62d00] mmco: unref short failure
[h264 @ 0x55a330106e80] mmco: unref short failure
[h264 @ 0x55a330106e80] mmco: unref short failure
[h264 @ 0x55a32ca32f80] mmco: unref short failure
[h264 @ 0x55a32ca32f80] mmco: unref short failure
[h264 @ 0x55e24860a5c0] mmco: unref short failure
[h264 @ 0x55e24860a5c0] mmco: unref short failure
[h264 @ 0x55a31a0ae400] mmco: unref short failure
[h264 @ 0x55a31a0ae400] mmco: unref short failure
09/17/2024 05:07:31 - INFO - __main__ -   current idx NplowkZTvc0.7 from finetune_area returns wrong image/video, use 108120 instead.
[h264 @ 0x55a322199900] mmco: unref short failure
[h264 @ 0x55a322199900] mmco: unref short failure
[h264 @ 0x55a322199900] mmco: unref short failure
[h264 @ 0x55a322199900] mmco: unref short failure
[h264 @ 0x55e23d731d80] mmco: unref short failure
[h264 @ 0x55a31a7bb540] mmco: unref short failure
[h264 @ 0x55a31a7bb540] mmco: unref short failure
 32%|███▏      | 924/2910 [5:45:59<18:09:20, 32.91s/it][h264 @ 0x55a310a3f980] mmco: unref short failure
[h264 @ 0x55a310a3f980] mmco: unref short failure
09/17/2024 05:07:54 - INFO - __main__ -   current idx bgTXI7WKWoY.26 from finetune_area returns wrong image/video, use 139569 instead.
 32%|███▏      | 925/2910 [5:46:08<14:10:35, 25.71s/it][h264 @ 0x55e252426cc0] mmco: unref short failure
[h264 @ 0x55e252426cc0] mmco: unref short failure
 32%|███▏      | 926/2910 [5:46:28<13:20:16, 24.20s/it][h264 @ 0x55e23c508640] mmco: unref short failure
[h264 @ 0x55e23c508640] mmco: unref short failure
[h264 @ 0x55e23f5b62c0] mmco: unref short failure
[h264 @ 0x55e23f5b62c0] mmco: unref short failure
[h264 @ 0x55e23f5b62c0] mmco: unref short failure
[h264 @ 0x55e23f5b62c0] mmco: unref short failure
[h264 @ 0x55e23e2ea500] mmco: unref short failure
[h264 @ 0x55e23e2ea500] mmco: unref short failure
[h264 @ 0x55e236977f00] mmco: unref short failure
[h264 @ 0x55e236977f00] mmco: unref short failure
[h264 @ 0x55b5b9301200] mmco: unref short failure
[h264 @ 0x55a3130b7740] mmco: unref short failure
[h264 @ 0x5607607a99c0] mmco: unref short failure
[h264 @ 0x5607607a99c0] mmco: unref short failure
[h264 @ 0x55e24ab96ac0] mmco: unref short failure
[h264 @ 0x55e24ab96ac0] mmco: unref short failure
[h264 @ 0x55e24ab96ac0] mmco: unref short failure
[h264 @ 0x55e24ab96ac0] mmco: unref short failure
[h264 @ 0x55e2504c1340] mmco: unref short failure
[h264 @ 0x55e2504c1340] mmco: unref short failure
[h264 @ 0x55e2504c1340] mmco: unref short failure
[h264 @ 0x55e2504c1340] mmco: unref short failure
[h264 @ 0x55a30f9a4100] mmco: unref short failure
[h264 @ 0x55a30f9a4100] mmco: unref short failure
[h264 @ 0x55a32b994e80] mmco: unref short failure
[h264 @ 0x55a30fc1fc80] mmco: unref short failure
[h264 @ 0x55a30fc1fc80] mmco: unref short failure
[h264 @ 0x55a30fc1fc80] mmco: unref short failure
[h264 @ 0x55a30fc1fc80] mmco: unref short failure
09/17/2024 05:09:16 - INFO - __main__ -   current idx 14WUuya94QE.364 from finetune_area returns wrong image/video, use 51961 instead.
[h264 @ 0x55b5c3ded480] mmco: unref short failure
[h264 @ 0x55b5b59d7040] mmco: unref short failure
[h264 @ 0x55b5c3ded480] mmco: unref short failure
[h264 @ 0x55b5c3ded480] mmco: unref short failure
09/17/2024 05:09:22 - INFO - __main__ -   current idx Dqfrs5K971Y.40 from finetune_area returns wrong image/video, use 91994 instead.
[h264 @ 0x55b5cbee3c80] mmco: unref short failure
[h264 @ 0x55e256afbc80] mmco: unref short failure
[h264 @ 0x55e256afbc80] mmco: unref short failure
[h264 @ 0x55e23fea2a80] mmco: unref short failure
[h264 @ 0x55e23fea2a80] mmco: unref short failure
[h264 @ 0x55e23fea2a80] mmco: unref short failure
[h264 @ 0x55e24b4080c0] mmco: unref short failure
[h264 @ 0x55e24b4080c0] mmco: unref short failure
[h264 @ 0x55a31c82e900] mmco: unref short failure
[h264 @ 0x55a31c82e900] mmco: unref short failure
[h264 @ 0x55e24ca09c80] mmco: unref short failure
[h264 @ 0x55e24ca09c80] mmco: unref short failure
[h264 @ 0x56074eed4640] mmco: unref short failure
[h264 @ 0x56074eed4640] mmco: unref short failure
[h264 @ 0x55b5ae4289c0] mmco: unref short failure
[h264 @ 0x55b5ae4289c0] mmco: unref short failure
[h264 @ 0x55b5c7541880] mmco: unref short failure
[h264 @ 0x55b5c7541880] mmco: unref short failure
[h264 @ 0x55b5cbee3c80] mmco: unref short failure
[h264 @ 0x55b5cbee3c80] mmco: unref short failure
[h264 @ 0x55b5c7541880] mmco: unref short failure
[h264 @ 0x55b5c7541880] mmco: unref short failure
[h264 @ 0x55b5cc172bc0] mmco: unref short failure
[h264 @ 0x55b5cc172bc0] mmco: unref short failure
[h264 @ 0x55e23de99900] mmco: unref short failure
[h264 @ 0x55e23de99900] mmco: unref short failure
[h264 @ 0x55e24b499c00] mmco: unref short failure
[h264 @ 0x55e24b499c00] mmco: unref short failure
[h264 @ 0x560761016f00] mmco: unref short failure
[h264 @ 0x55a315fe8f40] mmco: unref short failure
[h264 @ 0x55a315fe8f40] mmco: unref short failure
[h264 @ 0x55a315fe8f40] mmco: unref short failure
[h264 @ 0x55a315fe8f40] mmco: unref short failure
[h264 @ 0x55e242f32300] mmco: unref short failure
[h264 @ 0x55e242f32300] mmco: unref short failure
[h264 @ 0x55b5cbd2bec0] mmco: unref short failure
[h264 @ 0x55b5cbd2bec0] mmco: unref short failure
[h264 @ 0x55e241ef47c0] mmco: unref short failure
[h264 @ 0x55e241ef47c0] mmco: unref short failure
[h264 @ 0x55e241ef47c0] mmco: unref short failure
[h264 @ 0x56075880fc40] mmco: unref short failure
09/17/2024 05:10:55 - INFO - __main__ -   current idx Q_Kn3yzSJ5w.69 from finetune_area returns wrong image/video, use 20849 instead.
[h264 @ 0x55b5c1d0ce80] mmco: unref short failure
[h264 @ 0x55b5c1d0ce80] mmco: unref short failure
[h264 @ 0x55b5c1d0ce80] mmco: unref short failure
[h264 @ 0x55b5c1d0ce80] mmco: unref short failure
[h264 @ 0x560751ac1e80] mmco: unref short failure
[h264 @ 0x560751ac1e80] mmco: unref short failure
[h264 @ 0x55a318f77080] mmco: unref short failure
[h264 @ 0x55a318f77080] mmco: unref short failure
09/17/2024 05:11:14 - INFO - __main__ -   current idx TXPcr1HyKkY.54 from finetune_area returns wrong image/video, use 43983 instead.
 32%|███▏      | 927/2910 [5:49:31<39:34:36, 71.85s/it] 32%|███▏      | 928/2910 [5:49:36<28:25:36, 51.63s/it] 32%|███▏      | 929/2910 [5:49:42<20:49:19, 37.84s/it] 32%|███▏      | 930/2910 [5:49:47<15:27:22, 28.10s/it][h264 @ 0x55e2377b5900] mmco: unref short failure
 32%|███▏      | 931/2910 [5:49:52<11:41:24, 21.27s/it] 32%|███▏      | 932/2910 [5:49:58<9:07:50, 16.62s/it] 09/17/2024 05:11:44 - INFO - __main__ -   current idx fTdLpt9yfqg.43 from finetune_area returns wrong image/video, use 62556 instead.
 32%|███▏      | 933/2910 [5:50:04<7:17:46, 13.29s/it] 32%|███▏      | 934/2910 [5:50:08<5:54:07, 10.75s/it][h264 @ 0x55e24fd4cfc0] mmco: unref short failure
[h264 @ 0x55e24fd4cfc0] mmco: unref short failure
[h264 @ 0x55b5b12908c0] mmco: unref short failure
[h264 @ 0x55e253ef7680] mmco: unref short failure
[h264 @ 0x55e253ef7680] mmco: unref short failure
[h264 @ 0x55e253ef7680] mmco: unref short failure
[h264 @ 0x55e253ef7680] mmco: unref short failure
[h264 @ 0x55e23a5a7880] mmco: unref short failure
[h264 @ 0x55e23a5a7880] mmco: unref short failure
[h264 @ 0x56074b731840] mmco: unref short failure
09/17/2024 05:13:15 - INFO - __main__ -   current idx Iuir8LDIDfY.45 from finetune_area returns wrong image/video, use 42525 instead.
[h264 @ 0x55e23c3cc380] mmco: unref short failure
09/17/2024 05:13:34 - INFO - __main__ -   current idx eerUbqV6Md4.168 from finetune_area returns wrong image/video, use 17030 instead.
 32%|███▏      | 935/2910 [5:51:55<21:44:49, 39.64s/it][h264 @ 0x55b5cbd2bec0] mmco: unref short failure
[h264 @ 0x55b5b822af80] mmco: unref short failure
[h264 @ 0x56075f7d9940] mmco: unref short failure
09/17/2024 05:13:45 - INFO - __main__ -   current idx siiaopJ0dTo.6 from finetune_area returns wrong image/video, use 132685 instead.
 32%|███▏      | 936/2910 [5:52:01<16:06:26, 29.38s/it][h264 @ 0x55b5b3904c80] mmco: unref short failure
[h264 @ 0x55b5b3904c80] mmco: unref short failure
 32%|███▏      | 937/2910 [5:52:06<12:06:17, 22.09s/it][h264 @ 0x56074a621040] mmco: unref short failure
[h264 @ 0x56074a621040] mmco: unref short failure
[h264 @ 0x55e256356ec0] mmco: unref short failure
 32%|███▏      | 938/2910 [5:52:12<9:29:30, 17.33s/it] [h264 @ 0x55a32a5e5700] mmco: unref short failure
[h264 @ 0x55a32a5e5700] mmco: unref short failure
 32%|███▏      | 939/2910 [5:52:18<7:36:06, 13.88s/it][h264 @ 0x55e238c41480] mmco: unref short failure
[h264 @ 0x55e238c41480] mmco: unref short failure
[h264 @ 0x55a318f77080] mmco: unref short failure
 32%|███▏      | 940/2910 [5:52:25<6:26:22, 11.77s/it] 32%|███▏      | 941/2910 [5:52:31<5:35:24, 10.22s/it][h264 @ 0x55a32a668580] mmco: unref short failure
[h264 @ 0x55a32a668580] mmco: unref short failure
[h264 @ 0x55b5bacee040] mmco: unref short failure
[h264 @ 0x55e248295f80] mmco: unref short failure
[h264 @ 0x55e248295f80] mmco: unref short failure
 32%|███▏      | 942/2910 [5:52:38<4:55:03,  9.00s/it]09/17/2024 05:14:26 - INFO - __main__ -   current idx TWvBvDgrB6I.128 from finetune_area returns wrong image/video, use 24968 instead.
[h264 @ 0x55e254c59380] mmco: unref short failure
[h264 @ 0x55e254c59380] mmco: unref short failure
[h264 @ 0x55e254c59380] mmco: unref short failure
[h264 @ 0x55e254c59380] mmco: unref short failure
[h264 @ 0x55e250574d40] mmco: unref short failure
09/17/2024 05:14:36 - INFO - __main__ -   current idx WwLGb5RDcG0.21 from finetune_area returns wrong image/video, use 51873 instead.
[h264 @ 0x55a30efef600] mmco: unref short failure
[h264 @ 0x55b5ae067800] mmco: unref short failure
[h264 @ 0x55b5c1d0ce80] mmco: unref short failure
[h264 @ 0x55b5c1d0ce80] mmco: unref short failure
[h264 @ 0x55e2499e4080] mmco: unref short failure
[h264 @ 0x55e2499e4080] mmco: unref short failure
[h264 @ 0x560751f81ac0] mmco: unref short failure
[h264 @ 0x560743ebf1c0] mmco: unref short failure
[h264 @ 0x560743ebf1c0] mmco: unref short failure
[h264 @ 0x55b5aab8c880] mmco: unref short failure
[h264 @ 0x55b5af2c6a00] mmco: unref short failure
[h264 @ 0x5607498eb940] mmco: unref short failure
[h264 @ 0x55e2561106c0] mmco: unref short failure
[h264 @ 0x55e23dbd3080] mmco: unref short failure
[h264 @ 0x55a312d44c40] mmco: unref short failure
[h264 @ 0x55a312d44c40] mmco: unref short failure
[h264 @ 0x55e240d70280] mmco: unref short failure
[h264 @ 0x55e240d70280] mmco: unref short failure
[h264 @ 0x55a31e7c7f80] mmco: unref short failure
[h264 @ 0x55a31e7c7f80] mmco: unref short failure
[h264 @ 0x560745fb0d00] mmco: unref short failure
[h264 @ 0x560745fb0d00] mmco: unref short failure
[h264 @ 0x56074e7bce00] mmco: unref short failure
[h264 @ 0x56074e7bce00] mmco: unref short failure
[h264 @ 0x56074daff440] mmco: unref short failure
[h264 @ 0x56074daff440] mmco: unref short failure
[h264 @ 0x55e23c461140] mmco: unref short failure
[h264 @ 0x55e23c461140] mmco: unref short failure
[h264 @ 0x55e238f71940] mmco: unref short failure
[h264 @ 0x55e238f71940] mmco: unref short failure
 32%|███▏      | 943/2910 [5:54:28<21:33:34, 39.46s/it][h264 @ 0x55a31610a780] mmco: unref short failure
[h264 @ 0x55a31610a780] mmco: unref short failure
[h264 @ 0x5607498eb940] mmco: unref short failure
[h264 @ 0x5607498eb940] mmco: unref short failure
 32%|███▏      | 944/2910 [5:54:34<16:02:19, 29.37s/it] 32%|███▏      | 945/2910 [5:54:40<12:09:03, 22.26s/it][h264 @ 0x55e254c07d40] mmco: unref short failure
[h264 @ 0x55e254c07d40] mmco: unref short failure
[h264 @ 0x55a312d377c0] mmco: unref short failure
 33%|███▎      | 946/2910 [5:54:45<9:25:49, 17.29s/it] [h264 @ 0x55e254c07d40] mmco: unref short failure
 33%|███▎      | 947/2910 [5:54:51<7:34:15, 13.88s/it][h264 @ 0x55a30fef6480] mmco: unref short failure
[h264 @ 0x55a30fef6480] mmco: unref short failure
 33%|███▎      | 948/2910 [5:54:57<6:13:34, 11.42s/it] 33%|███▎      | 949/2910 [5:55:02<5:09:57,  9.48s/it]09/17/2024 05:16:48 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 05:16:48 - INFO - __main__ -   start running ret%tva validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a318a80880] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55b5c1d0ce80] mmco: unref short failure
[h264 @ 0x55b5c1d0ce80] mmco: unref short failure
[h264 @ 0x55e249e1d140] mmco: unref short failure
[h264 @ 0x55e249e1d140] mmco: unref short failure
[h264 @ 0x55b5c390b800] mmco: unref short failure
[h264 @ 0x55b5c390b800] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e253c0d780] mmco: unref short failure
[h264 @ 0x55e253c0d780] mmco: unref short failure
[h264 @ 0x55e253c0d780] mmco: unref short failure
[h264 @ 0x55e253c0d780] mmco: unref short failure
[h264 @ 0x560740dbf780] mmco: unref short failure
[h264 @ 0x560740dbf780] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x56074f943140] mmco: unref short failure
[h264 @ 0x55e2560a7b40] mmco: unref short failure
[h264 @ 0x55e2560a7b40] mmco: unref short failure
[h264 @ 0x55e25885d140] mmco: unref short failure
[h264 @ 0x55e25885d140] mmco: unref short failure
[h264 @ 0x55a32817e880] mmco: unref short failure
[h264 @ 0x55a32817e880] mmco: unref short failure
[h264 @ 0x55b5b73a7b80] mmco: unref short failure
[h264 @ 0x55b5b73a7b80] mmco: unref short failure
[h264 @ 0x560762726480] mmco: unref short failure
[h264 @ 0x56074d14b780] mmco: unref short failure
[h264 @ 0x55e256356ec0] mmco: unref short failure
[h264 @ 0x55e256356ec0] mmco: unref short failure
[h264 @ 0x55e256356ec0] mmco: unref short failure
[h264 @ 0x55e256356ec0] mmco: unref short failure
[h264 @ 0x55e256356ec0] mmco: unref short failure
[h264 @ 0x55e256356ec0] mmco: unref short failure
[h264 @ 0x55e256356ec0] mmco: unref short failure
[h264 @ 0x55e256356ec0] mmco: unref short failure
[h264 @ 0x55b5aaf8d5c0] mmco: unref short failure
[h264 @ 0x55a31800e040] mmco: unref short failure
[h264 @ 0x55a31800e040] mmco: unref short failure
[h264 @ 0x55e25403d940] mmco: unref short failure
[h264 @ 0x55e25403d940] mmco: unref short failure
[h264 @ 0x56075c2c7400] mmco: unref short failure
[h264 @ 0x56075c2c7400] mmco: unref short failure
[h264 @ 0x55b5b604c900] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:01<04:21,  1.19s/it][A
  1%|          | 2/221 [00:01<03:01,  1.21it/s][A
  1%|▏         | 3/221 [00:01<01:54,  1.91it/s][A
  2%|▏         | 5/221 [00:02<00:58,  3.68it/s][A
  3%|▎         | 6/221 [00:02<00:52,  4.07it/s][A
  3%|▎         | 7/221 [00:02<00:56,  3.78it/s][A
  4%|▎         | 8/221 [00:03<01:23,  2.56it/s][A
  4%|▍         | 9/221 [00:03<01:11,  2.98it/s][A
  5%|▍         | 10/221 [00:03<01:15,  2.78it/s][A
  5%|▍         | 11/221 [00:04<01:03,  3.33it/s][A
  5%|▌         | 12/221 [00:04<01:07,  3.10it/s][A
  6%|▌         | 13/221 [00:04<01:06,  3.15it/s][A
  6%|▋         | 14/221 [00:07<03:11,  1.08it/s][A
  7%|▋         | 15/221 [00:07<02:28,  1.38it/s][A
  7%|▋         | 16/221 [00:07<02:05,  1.64it/s][A
  8%|▊         | 17/221 [00:07<01:41,  2.01it/s][A
  8%|▊         | 18/221 [00:08<01:23,  2.43it/s][A
  9%|▊         | 19/221 [00:08<01:06,  3.04it/s][A
  9%|▉         | 20/221 [00:08<00:53,  3.76it/s][A
 10%|▉         | 21/221 [00:08<00:49,  4.08it/s][A
 10%|▉         | 22/221 [00:08<00:48,  4.07it/s][A
 10%|█         | 23/221 [00:08<00:40,  4.91it/s][A
 11%|█▏        | 25/221 [00:09<00:33,  5.80it/s][A
 12%|█▏        | 26/221 [00:09<00:36,  5.40it/s][A
 12%|█▏        | 27/221 [00:09<00:36,  5.25it/s][A
 13%|█▎        | 28/221 [00:10<00:49,  3.93it/s][A
 14%|█▎        | 30/221 [00:10<00:42,  4.54it/s][A
 14%|█▍        | 31/221 [00:10<00:44,  4.24it/s][A
 15%|█▍        | 33/221 [00:11<00:43,  4.36it/s][A
 15%|█▌        | 34/221 [00:11<00:41,  4.46it/s][A
 16%|█▌        | 35/221 [00:11<00:48,  3.84it/s][A
 16%|█▋        | 36/221 [00:12<00:56,  3.25it/s][A
 17%|█▋        | 37/221 [00:12<01:10,  2.59it/s][A[h264 @ 0x55b5afa87240] mmco: unref short failure

 17%|█▋        | 38/221 [00:13<01:08,  2.66it/s][A
 18%|█▊        | 40/221 [00:13<00:50,  3.60it/s][A
 19%|█▊        | 41/221 [00:13<00:42,  4.22it/s][A[h264 @ 0x55a31a118400] mmco: unref short failure

 19%|█▉        | 42/221 [00:13<00:50,  3.53it/s][A
 19%|█▉        | 43/221 [00:14<00:44,  4.04it/s][A
 20%|█▉        | 44/221 [00:14<00:40,  4.39it/s][A
 20%|██        | 45/221 [00:15<01:17,  2.27it/s][A
 21%|██        | 46/221 [00:15<01:19,  2.19it/s][A09/17/2024 05:19:22 - INFO - __main__ -   current idx hCH4rs-KEeA.16 from finetune_area returns wrong image/video, use 3944 instead.

 21%|██▏       | 47/221 [00:16<01:32,  1.88it/s][A
 22%|██▏       | 48/221 [00:16<01:13,  2.37it/s][A
 22%|██▏       | 49/221 [00:16<01:03,  2.71it/s][A
 23%|██▎       | 50/221 [00:17<00:54,  3.15it/s][A
 23%|██▎       | 51/221 [00:17<00:48,  3.53it/s][A
 24%|██▎       | 52/221 [00:17<00:42,  3.97it/s][A
 24%|██▍       | 53/221 [00:17<00:36,  4.66it/s][A
 24%|██▍       | 54/221 [00:19<01:37,  1.71it/s][A
 25%|██▍       | 55/221 [00:19<01:26,  1.92it/s][A
 25%|██▌       | 56/221 [00:19<01:10,  2.35it/s][A
 26%|██▌       | 57/221 [00:19<01:02,  2.61it/s][A
 26%|██▌       | 58/221 [00:20<00:52,  3.08it/s][A
 27%|██▋       | 59/221 [00:20<00:46,  3.49it/s][A[h264 @ 0x55a3179ffa40] mmco: unref short failure
[h264 @ 0x55a3179ffa40] mmco: unref short failure

 27%|██▋       | 60/221 [00:20<00:48,  3.29it/s][A
 28%|██▊       | 61/221 [00:20<00:42,  3.78it/s][A
 28%|██▊       | 62/221 [00:21<00:42,  3.78it/s][A
 29%|██▊       | 63/221 [00:21<00:36,  4.32it/s][A
 29%|██▉       | 64/221 [00:21<00:31,  5.01it/s][A
 29%|██▉       | 65/221 [00:21<00:29,  5.28it/s][A
 30%|██▉       | 66/221 [00:21<00:40,  3.82it/s][A
 30%|███       | 67/221 [00:22<00:41,  3.69it/s][A
 31%|███       | 68/221 [00:22<00:33,  4.54it/s][A
 31%|███       | 69/221 [00:23<00:58,  2.58it/s][A[h264 @ 0x55b5ae3ef640] mmco: unref short failure
[h264 @ 0x55b5ae3ef640] mmco: unref short failure

 32%|███▏      | 70/221 [00:23<00:48,  3.14it/s][A[h264 @ 0x55b5ae3ef640] mmco: unref short failure
[h264 @ 0x55b5ae3ef640] mmco: unref short failure

 32%|███▏      | 71/221 [00:25<01:57,  1.28it/s][A
 33%|███▎      | 72/221 [00:25<01:30,  1.65it/s][A
 33%|███▎      | 73/221 [00:25<01:14,  1.98it/s][A
 33%|███▎      | 74/221 [00:25<00:59,  2.48it/s][A
 34%|███▍      | 75/221 [00:26<00:57,  2.54it/s][A
 34%|███▍      | 76/221 [00:26<00:53,  2.72it/s][A
 35%|███▍      | 77/221 [00:26<00:47,  3.05it/s][A
 35%|███▌      | 78/221 [00:26<00:47,  2.98it/s][A
 36%|███▌      | 79/221 [00:27<01:02,  2.29it/s][A
 36%|███▌      | 80/221 [00:27<00:54,  2.60it/s][A
 37%|███▋      | 81/221 [00:28<00:50,  2.78it/s][A
 37%|███▋      | 82/221 [00:28<00:45,  3.06it/s][A
 38%|███▊      | 83/221 [00:28<00:41,  3.29it/s][A
 38%|███▊      | 84/221 [00:28<00:37,  3.64it/s][A
 39%|███▉      | 86/221 [00:29<00:27,  4.95it/s][A
 39%|███▉      | 87/221 [00:29<00:39,  3.38it/s][A
 40%|███▉      | 88/221 [00:30<00:40,  3.30it/s][A[h264 @ 0x560760f10200] mmco: unref short failure
[h264 @ 0x560760f10200] mmco: unref short failure

 40%|████      | 89/221 [00:32<01:53,  1.16it/s][A
 41%|████      | 90/221 [00:32<01:35,  1.37it/s][A
 41%|████      | 91/221 [00:32<01:11,  1.82it/s][A
 42%|████▏     | 92/221 [00:33<00:56,  2.27it/s][A
 42%|████▏     | 93/221 [00:33<01:05,  1.96it/s][A
 43%|████▎     | 94/221 [00:34<00:55,  2.27it/s][A
 43%|████▎     | 95/221 [00:34<00:42,  2.93it/s][A
 43%|████▎     | 96/221 [00:34<00:40,  3.08it/s][A
 44%|████▍     | 97/221 [00:34<00:32,  3.79it/s][A[h264 @ 0x55a3298b7b40] mmco: unref short failure
[h264 @ 0x55a3298b7b40] mmco: unref short failure

 44%|████▍     | 98/221 [00:34<00:32,  3.77it/s][A
 45%|████▍     | 99/221 [00:35<00:29,  4.16it/s][A
 45%|████▌     | 100/221 [00:35<00:30,  4.01it/s][A
 46%|████▌     | 101/221 [00:35<00:26,  4.61it/s][A
 46%|████▌     | 102/221 [00:35<00:30,  3.90it/s][A
 47%|████▋     | 103/221 [00:35<00:25,  4.60it/s][A
 47%|████▋     | 104/221 [00:36<00:22,  5.31it/s][A
 48%|████▊     | 105/221 [00:36<00:23,  5.03it/s][A
 48%|████▊     | 106/221 [00:37<00:55,  2.06it/s][A
 48%|████▊     | 107/221 [00:37<00:42,  2.70it/s][A
 49%|████▉     | 108/221 [00:37<00:35,  3.15it/s][A
 49%|████▉     | 109/221 [00:38<00:36,  3.11it/s][A
 50%|████▉     | 110/221 [00:38<00:30,  3.64it/s][A
 50%|█████     | 111/221 [00:38<00:34,  3.20it/s][A
 51%|█████     | 112/221 [00:38<00:29,  3.64it/s][A
 51%|█████     | 113/221 [00:39<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:39<00:22,  4.67it/s][A[h264 @ 0x560745783040] mmco: unref short failure

 52%|█████▏    | 116/221 [00:44<02:21,  1.34s/it][A
 53%|█████▎    | 117/221 [00:44<01:50,  1.07s/it][A
 53%|█████▎    | 118/221 [00:44<01:29,  1.15it/s][A
 54%|█████▍    | 119/221 [00:44<01:08,  1.50it/s][A
 54%|█████▍    | 120/221 [00:45<00:55,  1.82it/s][A
 55%|█████▌    | 122/221 [00:45<00:34,  2.86it/s][A
 56%|█████▌    | 123/221 [00:45<00:29,  3.36it/s][A
 56%|█████▌    | 124/221 [00:45<00:26,  3.70it/s][A
 57%|█████▋    | 125/221 [00:45<00:26,  3.69it/s][A
 57%|█████▋    | 126/221 [00:46<00:29,  3.23it/s][A
 57%|█████▋    | 127/221 [00:46<00:33,  2.83it/s][A
 58%|█████▊    | 128/221 [00:47<00:31,  2.93it/s][A[h264 @ 0x560763c4cf00] mmco: unref short failure
[h264 @ 0x560763c4cf00] mmco: unref short failure

 58%|█████▊    | 129/221 [00:47<00:28,  3.20it/s][A
 59%|█████▉    | 130/221 [00:47<00:25,  3.58it/s][A
 59%|█████▉    | 131/221 [00:47<00:20,  4.39it/s][A
 60%|█████▉    | 132/221 [00:47<00:18,  4.89it/s][A
 60%|██████    | 133/221 [00:48<00:24,  3.64it/s][A[h264 @ 0x55a31eceff80] mmco: unref short failure

 61%|██████    | 134/221 [00:48<00:23,  3.76it/s][A
 61%|██████    | 135/221 [00:49<00:29,  2.95it/s][A
 62%|██████▏   | 136/221 [00:49<00:29,  2.85it/s][A
 62%|██████▏   | 137/221 [00:49<00:25,  3.32it/s][A
 62%|██████▏   | 138/221 [00:49<00:26,  3.10it/s][A
 63%|██████▎   | 139/221 [00:50<00:27,  2.98it/s][A
 63%|██████▎   | 140/221 [00:50<00:27,  2.94it/s][A
 64%|██████▍   | 141/221 [00:50<00:23,  3.45it/s][A
 64%|██████▍   | 142/221 [00:51<00:23,  3.34it/s][A
 65%|██████▍   | 143/221 [00:51<00:27,  2.87it/s][A
 65%|██████▌   | 144/221 [00:51<00:22,  3.48it/s][A
 66%|██████▌   | 146/221 [00:51<00:14,  5.17it/s][A
 67%|██████▋   | 147/221 [00:52<00:12,  5.70it/s][A
 67%|██████▋   | 148/221 [00:52<00:14,  5.09it/s][A
 67%|██████▋   | 149/221 [00:52<00:12,  5.64it/s][A
 68%|██████▊   | 150/221 [00:52<00:11,  5.99it/s][A
 68%|██████▊   | 151/221 [00:54<00:36,  1.92it/s][A
 69%|██████▉   | 152/221 [00:54<00:31,  2.16it/s][A
 69%|██████▉   | 153/221 [00:54<00:27,  2.46it/s][A
 70%|██████▉   | 154/221 [00:55<00:28,  2.36it/s][A
 70%|███████   | 155/221 [00:55<00:21,  3.00it/s][A
 71%|███████   | 156/221 [00:55<00:18,  3.52it/s][A
 71%|███████   | 157/221 [00:56<00:38,  1.67it/s][A
 71%|███████▏  | 158/221 [00:56<00:30,  2.06it/s][A
 72%|███████▏  | 159/221 [00:57<00:23,  2.63it/s][A
 72%|███████▏  | 160/221 [00:57<00:19,  3.11it/s][A
 73%|███████▎  | 162/221 [00:57<00:12,  4.63it/s][A
 74%|███████▍  | 163/221 [00:57<00:12,  4.56it/s][A
 74%|███████▍  | 164/221 [00:57<00:13,  4.28it/s][A
 75%|███████▍  | 165/221 [00:58<00:11,  4.95it/s][A
 75%|███████▌  | 166/221 [00:58<00:14,  3.91it/s][A
 76%|███████▌  | 167/221 [00:58<00:11,  4.59it/s][A[h264 @ 0x55b5ade131c0] mmco: unref short failure
[h264 @ 0x55b5ade131c0] mmco: unref short failure

 76%|███████▌  | 168/221 [01:00<00:33,  1.57it/s][A
 76%|███████▋  | 169/221 [01:00<00:28,  1.80it/s][A
 77%|███████▋  | 170/221 [01:00<00:23,  2.13it/s][A
 77%|███████▋  | 171/221 [01:01<00:20,  2.47it/s][A
 78%|███████▊  | 172/221 [01:01<00:18,  2.70it/s][A
 78%|███████▊  | 173/221 [01:01<00:14,  3.42it/s][A
 79%|███████▉  | 175/221 [01:01<00:10,  4.45it/s][A
 80%|███████▉  | 176/221 [01:02<00:10,  4.32it/s][A
 81%|████████  | 178/221 [01:02<00:08,  4.95it/s][A
 81%|████████  | 179/221 [01:02<00:10,  3.93it/s][A
 82%|████████▏ | 181/221 [01:03<00:08,  4.64it/s][A
 82%|████████▏ | 182/221 [01:03<00:07,  5.14it/s][A
 83%|████████▎ | 183/221 [01:03<00:07,  5.26it/s][A
 83%|████████▎ | 184/221 [01:03<00:08,  4.27it/s][A
 84%|████████▎ | 185/221 [01:03<00:07,  4.57it/s][A
 84%|████████▍ | 186/221 [01:04<00:10,  3.35it/s][A
 85%|████████▌ | 188/221 [01:04<00:08,  4.07it/s][A
 86%|████████▌ | 189/221 [01:04<00:07,  4.24it/s][A
 86%|████████▌ | 190/221 [01:05<00:07,  4.21it/s][A
 87%|████████▋ | 192/221 [01:05<00:05,  5.05it/s][A
 88%|████████▊ | 194/221 [01:06<00:07,  3.48it/s][A
 88%|████████▊ | 195/221 [01:06<00:06,  3.96it/s][A
 89%|████████▉ | 197/221 [01:06<00:04,  5.24it/s][A
 90%|████████▉ | 198/221 [01:06<00:04,  4.87it/s][A
 90%|█████████ | 199/221 [01:07<00:04,  5.04it/s][A
 90%|█████████ | 200/221 [01:07<00:04,  4.54it/s][A
 91%|█████████ | 201/221 [01:07<00:04,  4.68it/s][A
 91%|█████████▏| 202/221 [01:07<00:03,  4.99it/s][A
 92%|█████████▏| 203/221 [01:07<00:03,  5.66it/s][A
 93%|█████████▎| 205/221 [01:08<00:02,  7.04it/s][A
 93%|█████████▎| 206/221 [01:08<00:03,  4.22it/s][A
 94%|█████████▍| 208/221 [01:08<00:02,  5.71it/s][A
 95%|█████████▌| 210/221 [01:08<00:01,  7.60it/s][A
 96%|█████████▌| 212/221 [01:09<00:01,  5.54it/s][A
 97%|█████████▋| 214/221 [01:10<00:01,  4.18it/s][A
 97%|█████████▋| 215/221 [01:10<00:01,  4.23it/s][A
 98%|█████████▊| 216/221 [01:10<00:01,  4.25it/s][A
 98%|█████████▊| 217/221 [01:11<00:01,  3.48it/s][A
 99%|█████████▊| 218/221 [01:11<00:00,  3.46it/s][A
 99%|█████████▉| 219/221 [01:11<00:00,  3.78it/s][A
100%|█████████▉| 220/221 [01:15<00:01,  1.37s/it][A
100%|██████████| 221/221 [01:16<00:00,  1.03s/it][A100%|██████████| 221/221 [01:16<00:00,  2.91it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:04,  3.42it/s][A
  1%|          | 2/221 [00:00<01:04,  3.42it/s][A
  1%|▏         | 3/221 [00:00<01:03,  3.42it/s][A
  2%|▏         | 4/221 [00:01<01:03,  3.42it/s][A
  2%|▏         | 5/221 [00:01<01:03,  3.42it/s][A
  3%|▎         | 6/221 [00:01<01:02,  3.42it/s][A
  3%|▎         | 7/221 [00:02<01:02,  3.42it/s][A
  4%|▎         | 8/221 [00:02<01:02,  3.42it/s][A
  4%|▍         | 9/221 [00:02<01:01,  3.42it/s][A
  5%|▍         | 10/221 [00:02<01:01,  3.42it/s][A
  5%|▍         | 11/221 [00:03<01:01,  3.42it/s][A
  5%|▌         | 12/221 [00:03<01:01,  3.42it/s][A
  6%|▌         | 13/221 [00:03<01:00,  3.42it/s][A
  6%|▋         | 14/221 [00:04<01:00,  3.41it/s][A
  7%|▋         | 15/221 [00:04<01:00,  3.42it/s][A
  7%|▋         | 16/221 [00:04<00:59,  3.42it/s][A
  8%|▊         | 17/221 [00:04<00:59,  3.42it/s][A
  8%|▊         | 18/221 [00:05<00:59,  3.42it/s][A
  9%|▊         | 19/221 [00:05<00:59,  3.42it/s][A
  9%|▉         | 20/221 [00:05<00:58,  3.42it/s][A
 10%|▉         | 21/221 [00:06<00:58,  3.42it/s][A
 10%|▉         | 22/221 [00:06<00:58,  3.42it/s][A
 10%|█         | 23/221 [00:06<00:57,  3.42it/s][A
 11%|█         | 24/221 [00:07<00:57,  3.42it/s][A
 11%|█▏        | 25/221 [00:07<00:57,  3.42it/s][A
 12%|█▏        | 26/221 [00:07<00:57,  3.42it/s][A
 12%|█▏        | 27/221 [00:07<00:56,  3.42it/s][A
 13%|█▎        | 28/221 [00:08<00:56,  3.42it/s][A
 13%|█▎        | 29/221 [00:08<00:56,  3.42it/s][A
 14%|█▎        | 30/221 [00:08<00:55,  3.42it/s][A
 14%|█▍        | 31/221 [00:09<00:55,  3.42it/s][A
 14%|█▍        | 32/221 [00:09<00:55,  3.42it/s][A
 15%|█▍        | 33/221 [00:09<00:54,  3.42it/s][A
 15%|█▌        | 34/221 [00:09<00:54,  3.42it/s][A
 16%|█▌        | 35/221 [00:10<00:54,  3.42it/s][A
 16%|█▋        | 36/221 [00:10<00:54,  3.42it/s][A
 17%|█▋        | 37/221 [00:10<00:53,  3.42it/s][A
 17%|█▋        | 38/221 [00:11<00:53,  3.42it/s][A
 18%|█▊        | 39/221 [00:11<00:53,  3.42it/s][A
 18%|█▊        | 40/221 [00:11<00:52,  3.42it/s][A
 19%|█▊        | 41/221 [00:11<00:52,  3.42it/s][A
 19%|█▉        | 42/221 [00:12<00:52,  3.42it/s][A
 19%|█▉        | 43/221 [00:12<00:52,  3.42it/s][A
 20%|█▉        | 44/221 [00:12<00:51,  3.42it/s][A
 20%|██        | 45/221 [00:13<00:51,  3.42it/s][A
 21%|██        | 46/221 [00:13<00:51,  3.42it/s][A
 21%|██▏       | 47/221 [00:13<00:50,  3.42it/s][A
 22%|██▏       | 48/221 [00:14<00:50,  3.42it/s][A
 22%|██▏       | 49/221 [00:14<00:50,  3.42it/s][A
 23%|██▎       | 50/221 [00:14<00:49,  3.42it/s][A
 23%|██▎       | 51/221 [00:14<00:49,  3.42it/s][A
 24%|██▎       | 52/221 [00:15<00:49,  3.42it/s][A
 24%|██▍       | 53/221 [00:15<00:49,  3.42it/s][A
 24%|██▍       | 54/221 [00:15<00:48,  3.42it/s][A
 25%|██▍       | 55/221 [00:16<00:48,  3.42it/s][A
 25%|██▌       | 56/221 [00:16<00:48,  3.42it/s][A
 26%|██▌       | 57/221 [00:16<00:47,  3.42it/s][A
 26%|██▌       | 58/221 [00:16<00:47,  3.42it/s][A
 27%|██▋       | 59/221 [00:17<00:47,  3.42it/s][A
 27%|██▋       | 60/221 [00:17<00:47,  3.42it/s][A
 28%|██▊       | 61/221 [00:17<00:46,  3.42it/s][A
 28%|██▊       | 62/221 [00:18<00:46,  3.42it/s][A
 29%|██▊       | 63/221 [00:18<00:46,  3.42it/s][A
 29%|██▉       | 64/221 [00:18<00:45,  3.42it/s][A
 29%|██▉       | 65/221 [00:19<00:45,  3.42it/s][A
 30%|██▉       | 66/221 [00:19<00:45,  3.42it/s][A
 30%|███       | 67/221 [00:19<00:45,  3.42it/s][A
 31%|███       | 68/221 [00:19<00:44,  3.42it/s][A
 31%|███       | 69/221 [00:20<00:44,  3.42it/s][A
 32%|███▏      | 70/221 [00:20<00:44,  3.42it/s][A
 32%|███▏      | 71/221 [00:20<00:43,  3.42it/s][A
 33%|███▎      | 72/221 [00:21<00:43,  3.42it/s][A
 33%|███▎      | 73/221 [00:21<00:43,  3.42it/s][A
 33%|███▎      | 74/221 [00:21<00:42,  3.42it/s][A
 34%|███▍      | 75/221 [00:21<00:42,  3.42it/s][A
 34%|███▍      | 76/221 [00:22<00:42,  3.42it/s][A
 35%|███▍      | 77/221 [00:22<00:42,  3.42it/s][A
 35%|███▌      | 78/221 [00:22<00:41,  3.42it/s][A
 36%|███▌      | 79/221 [00:23<00:41,  3.42it/s][A
 36%|███▌      | 80/221 [00:23<00:41,  3.42it/s][A
 37%|███▋      | 81/221 [00:23<00:40,  3.42it/s][A
 37%|███▋      | 82/221 [00:23<00:40,  3.42it/s][A
 38%|███▊      | 83/221 [00:24<00:40,  3.42it/s][A
 38%|███▊      | 84/221 [00:24<00:40,  3.42it/s][A
 38%|███▊      | 85/221 [00:24<00:39,  3.42it/s][A
 39%|███▉      | 86/221 [00:25<00:39,  3.42it/s][A
 39%|███▉      | 87/221 [00:25<00:39,  3.42it/s][A
 40%|███▉      | 88/221 [00:25<00:38,  3.42it/s][A
 40%|████      | 89/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 90/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 91/221 [00:26<00:38,  3.42it/s][A
 42%|████▏     | 92/221 [00:26<00:37,  3.42it/s][A
 42%|████▏     | 93/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 94/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 95/221 [00:27<00:36,  3.42it/s][A
 43%|████▎     | 96/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 97/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 98/221 [00:28<00:35,  3.42it/s][A
 45%|████▍     | 99/221 [00:28<00:35,  3.42it/s][A
 45%|████▌     | 100/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 101/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 102/221 [00:29<00:34,  3.42it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 104/221 [00:30<00:34,  3.42it/s][A
 48%|████▊     | 105/221 [00:30<00:33,  3.42it/s][A
 48%|████▊     | 106/221 [00:30<00:33,  3.42it/s][A
 48%|████▊     | 107/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 108/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 109/221 [00:31<00:32,  3.42it/s][A
 50%|████▉     | 110/221 [00:32<00:32,  3.42it/s][A
 50%|█████     | 111/221 [00:32<00:32,  3.42it/s][A
 51%|█████     | 112/221 [00:32<00:31,  3.42it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 114/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:33<00:30,  3.42it/s][A
 52%|█████▏    | 116/221 [00:33<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:34<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:34<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:35<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:35<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:35<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:36<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:37<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:38<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:38<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:38<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:39<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:39<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:40<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:40<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:40<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:41<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:41<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:42<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:42<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:43<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:43<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:44<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:45<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:45<00:18,  3.42it/s][A
 71%|███████   | 157/221 [00:45<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:46<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:47<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:47<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:47<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:48<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:48<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:48<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:49<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:49<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:49<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:50<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:50<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:51<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:51<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:52<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:52<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:52<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:53<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:54<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:54<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:54<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:55<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:55<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:56<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:56<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:57<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:57<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:57<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:58<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:58<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [00:59<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [00:59<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:00<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:01<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:01<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:02<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:03<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:03<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:04<00:00,  3.42it/s][A100%|██████████| 221/221 [01:04<00:00,  3.42it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:25,  8.64it/s][A
  1%|          | 2/221 [00:00<00:37,  5.86it/s][A
  1%|▏         | 3/221 [00:00<00:59,  3.68it/s][A
  2%|▏         | 4/221 [00:00<00:48,  4.48it/s][A
  2%|▏         | 5/221 [00:01<00:50,  4.24it/s][A
  3%|▎         | 7/221 [00:01<00:48,  4.44it/s][A
  4%|▎         | 8/221 [00:01<00:50,  4.18it/s][A
  4%|▍         | 9/221 [00:02<00:53,  3.94it/s][A
  5%|▍         | 11/221 [00:02<00:46,  4.55it/s][A
  5%|▌         | 12/221 [00:02<00:44,  4.70it/s][A
  6%|▌         | 13/221 [00:03<01:21,  2.55it/s][A
  6%|▋         | 14/221 [00:03<01:10,  2.96it/s][A
  7%|▋         | 15/221 [00:04<01:16,  2.71it/s][A
  7%|▋         | 16/221 [00:04<01:22,  2.48it/s][A
  8%|▊         | 17/221 [00:05<01:17,  2.63it/s][A
  8%|▊         | 18/221 [00:05<01:07,  2.99it/s][A
  9%|▉         | 20/221 [00:05<00:55,  3.59it/s][A
 10%|▉         | 21/221 [00:05<00:50,  3.95it/s][A
 10%|▉         | 22/221 [00:05<00:44,  4.48it/s][A
 11%|█         | 24/221 [00:06<00:36,  5.34it/s][A
 11%|█▏        | 25/221 [00:06<00:48,  4.08it/s][A
 12%|█▏        | 26/221 [00:06<00:47,  4.13it/s][A
 12%|█▏        | 27/221 [00:07<00:53,  3.65it/s][A
 13%|█▎        | 28/221 [00:07<00:56,  3.43it/s][A
 13%|█▎        | 29/221 [00:07<00:54,  3.50it/s][A
 14%|█▎        | 30/221 [00:08<01:05,  2.93it/s][A
 14%|█▍        | 31/221 [00:08<01:05,  2.90it/s][A
 14%|█▍        | 32/221 [00:08<00:57,  3.30it/s][A
 15%|█▍        | 33/221 [00:09<00:59,  3.18it/s][A
 15%|█▌        | 34/221 [00:10<01:24,  2.22it/s][A
 16%|█▌        | 35/221 [00:10<01:11,  2.60it/s][A
 16%|█▋        | 36/221 [00:10<01:08,  2.70it/s][A
 17%|█▋        | 37/221 [00:10<00:58,  3.13it/s][A
 17%|█▋        | 38/221 [00:11<00:55,  3.31it/s][A
 18%|█▊        | 39/221 [00:11<00:47,  3.84it/s][A
 18%|█▊        | 40/221 [00:11<00:46,  3.89it/s][A
 19%|█▊        | 41/221 [00:11<00:54,  3.33it/s][A
 19%|█▉        | 42/221 [00:12<00:44,  3.99it/s][A
 19%|█▉        | 43/221 [00:12<00:43,  4.05it/s][A
 20%|█▉        | 44/221 [00:12<00:40,  4.32it/s][A
 20%|██        | 45/221 [00:12<00:46,  3.76it/s][A
 21%|██        | 46/221 [00:13<00:45,  3.88it/s][A
 22%|██▏       | 48/221 [00:13<00:31,  5.46it/s][A
 22%|██▏       | 49/221 [00:13<00:28,  6.01it/s][A
 23%|██▎       | 50/221 [00:13<00:35,  4.77it/s][A
 23%|██▎       | 51/221 [00:13<00:38,  4.46it/s][A
 24%|██▎       | 52/221 [00:14<00:36,  4.67it/s][A
 24%|██▍       | 53/221 [00:14<00:43,  3.85it/s][A
 24%|██▍       | 54/221 [00:14<00:40,  4.15it/s][A
 25%|██▍       | 55/221 [00:15<00:44,  3.70it/s][A
 25%|██▌       | 56/221 [00:15<00:43,  3.77it/s][A
 26%|██▌       | 57/221 [00:15<00:45,  3.57it/s][A
 26%|██▌       | 58/221 [00:15<00:47,  3.40it/s][A
 27%|██▋       | 59/221 [00:16<00:44,  3.64it/s][A
 27%|██▋       | 60/221 [00:16<00:39,  4.10it/s][A
 28%|██▊       | 61/221 [00:16<00:37,  4.29it/s][A
 28%|██▊       | 62/221 [00:16<00:37,  4.20it/s][A
 29%|██▉       | 64/221 [00:17<00:33,  4.67it/s][A
 29%|██▉       | 65/221 [00:17<00:34,  4.49it/s][A
 30%|██▉       | 66/221 [00:17<00:39,  3.94it/s][A
 30%|███       | 67/221 [00:18<00:50,  3.07it/s][A
 31%|███       | 68/221 [00:18<00:44,  3.45it/s][A
 31%|███       | 69/221 [00:19<00:54,  2.80it/s][A
 32%|███▏      | 70/221 [00:19<00:46,  3.25it/s][A
 32%|███▏      | 71/221 [00:19<00:53,  2.83it/s][A
 33%|███▎      | 72/221 [00:20<00:55,  2.67it/s][A
 33%|███▎      | 73/221 [00:20<00:53,  2.79it/s][A
 33%|███▎      | 74/221 [00:20<00:52,  2.82it/s][A
 34%|███▍      | 75/221 [00:21<00:48,  3.02it/s][A
 34%|███▍      | 76/221 [00:21<00:38,  3.75it/s][A
 35%|███▍      | 77/221 [00:21<00:47,  3.02it/s][A
 35%|███▌      | 78/221 [00:21<00:47,  2.99it/s][A
 36%|███▌      | 79/221 [00:22<00:44,  3.22it/s][A
 36%|███▌      | 80/221 [00:22<00:41,  3.39it/s][A
 37%|███▋      | 81/221 [00:22<00:38,  3.60it/s][A
 37%|███▋      | 82/221 [00:22<00:35,  3.96it/s][A
 38%|███▊      | 83/221 [00:23<00:34,  3.97it/s][A
 38%|███▊      | 84/221 [00:23<00:42,  3.22it/s][A
 38%|███▊      | 85/221 [00:24<00:46,  2.95it/s][A
 39%|███▉      | 86/221 [00:24<00:50,  2.69it/s][A
 39%|███▉      | 87/221 [00:24<00:54,  2.46it/s][A
 40%|███▉      | 88/221 [00:25<00:49,  2.71it/s][A
 40%|████      | 89/221 [00:25<00:49,  2.69it/s][A
 41%|████      | 90/221 [00:26<00:58,  2.25it/s][A
 41%|████      | 91/221 [00:26<00:51,  2.54it/s][A
 42%|████▏     | 92/221 [00:26<00:48,  2.67it/s][A
 42%|████▏     | 93/221 [00:27<01:02,  2.05it/s][A
 43%|████▎     | 94/221 [00:27<00:52,  2.42it/s][A
 43%|████▎     | 95/221 [00:28<00:58,  2.14it/s][A
 43%|████▎     | 96/221 [00:28<00:55,  2.24it/s][A
 44%|████▍     | 97/221 [00:29<00:47,  2.61it/s][A
 44%|████▍     | 98/221 [00:29<00:44,  2.76it/s][A
 45%|████▍     | 99/221 [00:29<00:41,  2.97it/s][A
 45%|████▌     | 100/221 [00:29<00:34,  3.51it/s][A
 46%|████▌     | 101/221 [00:29<00:30,  3.95it/s][A
 46%|████▌     | 102/221 [00:30<00:36,  3.25it/s][A
 47%|████▋     | 103/221 [00:30<00:31,  3.74it/s][A
 47%|████▋     | 104/221 [00:30<00:28,  4.05it/s][A
 48%|████▊     | 105/221 [00:31<00:32,  3.55it/s][A
 48%|████▊     | 106/221 [00:31<00:34,  3.33it/s][A
 48%|████▊     | 107/221 [00:31<00:36,  3.12it/s][A
 49%|████▉     | 108/221 [00:32<00:33,  3.38it/s][A
 49%|████▉     | 109/221 [00:32<00:32,  3.46it/s][A
 50%|████▉     | 110/221 [00:32<00:28,  3.89it/s][A
 50%|█████     | 111/221 [00:32<00:30,  3.57it/s][A
 51%|█████     | 112/221 [00:33<00:33,  3.24it/s][A
 51%|█████     | 113/221 [00:33<00:32,  3.34it/s][A
 52%|█████▏    | 114/221 [00:33<00:26,  4.09it/s][A
 52%|█████▏    | 115/221 [00:33<00:21,  4.86it/s][A
 52%|█████▏    | 116/221 [00:33<00:19,  5.30it/s][A
 53%|█████▎    | 117/221 [00:34<00:21,  4.80it/s][A
 53%|█████▎    | 118/221 [00:34<00:29,  3.47it/s][A
 54%|█████▍    | 119/221 [00:35<00:34,  2.93it/s][A
 54%|█████▍    | 120/221 [00:35<00:34,  2.95it/s][A
 55%|█████▍    | 121/221 [00:35<00:29,  3.40it/s][A
 55%|█████▌    | 122/221 [00:35<00:26,  3.69it/s][A
 56%|█████▌    | 123/221 [00:36<00:29,  3.35it/s][A
 56%|█████▌    | 124/221 [00:36<00:27,  3.56it/s][A
 57%|█████▋    | 125/221 [00:36<00:32,  2.92it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.51it/s][A
 57%|█████▋    | 127/221 [00:37<00:36,  2.59it/s][A
 58%|█████▊    | 128/221 [00:37<00:30,  3.02it/s][A
 58%|█████▊    | 129/221 [00:38<00:28,  3.19it/s][A
 59%|█████▉    | 130/221 [00:38<00:29,  3.10it/s][A
 59%|█████▉    | 131/221 [00:38<00:25,  3.49it/s][A
 60%|█████▉    | 132/221 [00:38<00:24,  3.63it/s][A
 60%|██████    | 133/221 [00:39<00:31,  2.82it/s][A
 61%|██████    | 134/221 [00:40<00:34,  2.50it/s][A
 61%|██████    | 135/221 [00:40<00:30,  2.80it/s][A
 62%|██████▏   | 136/221 [00:40<00:28,  2.96it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.46it/s][A
 62%|██████▏   | 138/221 [00:40<00:22,  3.71it/s][A
 63%|██████▎   | 139/221 [00:41<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:21,  3.74it/s][A
 64%|██████▍   | 141/221 [00:41<00:24,  3.28it/s][A
 64%|██████▍   | 142/221 [00:42<00:21,  3.68it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.52it/s][A
 65%|██████▌   | 144/221 [00:42<00:20,  3.70it/s][A
 66%|██████▌   | 145/221 [00:43<00:22,  3.44it/s][A
 66%|██████▌   | 146/221 [00:43<00:22,  3.33it/s][A
 67%|██████▋   | 147/221 [00:43<00:20,  3.55it/s][A
 67%|██████▋   | 148/221 [00:43<00:20,  3.63it/s][A
 67%|██████▋   | 149/221 [00:44<00:19,  3.68it/s][A
 68%|██████▊   | 150/221 [00:44<00:19,  3.66it/s][A
 68%|██████▊   | 151/221 [00:44<00:24,  2.81it/s][A
 69%|██████▉   | 152/221 [00:45<00:34,  1.98it/s][A
 69%|██████▉   | 153/221 [00:46<00:28,  2.36it/s][A
 70%|██████▉   | 154/221 [00:46<00:25,  2.67it/s][A
 70%|███████   | 155/221 [00:46<00:23,  2.77it/s][A
 71%|███████   | 156/221 [00:46<00:19,  3.26it/s][A
 71%|███████   | 157/221 [00:47<00:19,  3.33it/s][A
 71%|███████▏  | 158/221 [00:47<00:19,  3.23it/s][A
 72%|███████▏  | 159/221 [00:47<00:17,  3.52it/s][A
 72%|███████▏  | 160/221 [00:47<00:15,  3.84it/s][A
 73%|███████▎  | 161/221 [00:48<00:14,  4.09it/s][A
 73%|███████▎  | 162/221 [00:48<00:12,  4.76it/s][A
 74%|███████▍  | 163/221 [00:48<00:13,  4.34it/s][A
 74%|███████▍  | 164/221 [00:48<00:12,  4.55it/s][A
 75%|███████▍  | 165/221 [00:48<00:13,  4.18it/s][A
 75%|███████▌  | 166/221 [00:49<00:14,  3.70it/s][A
 76%|███████▌  | 167/221 [00:49<00:12,  4.38it/s][A
 76%|███████▌  | 168/221 [00:49<00:11,  4.56it/s][A
 76%|███████▋  | 169/221 [00:49<00:09,  5.35it/s][A
 77%|███████▋  | 170/221 [00:50<00:16,  3.02it/s][A
 77%|███████▋  | 171/221 [00:50<00:16,  3.09it/s][A
 78%|███████▊  | 172/221 [00:51<00:15,  3.11it/s][A
 78%|███████▊  | 173/221 [00:51<00:15,  3.12it/s][A
 79%|███████▊  | 174/221 [00:51<00:14,  3.30it/s][A
 79%|███████▉  | 175/221 [00:51<00:15,  3.06it/s][A
 80%|███████▉  | 176/221 [00:52<00:14,  3.16it/s][A
 80%|████████  | 177/221 [00:52<00:13,  3.29it/s][A
 81%|████████  | 178/221 [00:53<00:16,  2.66it/s][A
 81%|████████  | 179/221 [00:53<00:14,  2.98it/s][A
 81%|████████▏ | 180/221 [00:53<00:12,  3.19it/s][A
 82%|████████▏ | 181/221 [00:53<00:13,  2.89it/s][A
 82%|████████▏ | 182/221 [00:54<00:11,  3.30it/s][A
 83%|████████▎ | 183/221 [00:54<00:12,  3.02it/s][A
 83%|████████▎ | 184/221 [00:54<00:12,  2.92it/s][A
 84%|████████▍ | 186/221 [00:55<00:11,  2.92it/s][A
 85%|████████▍ | 187/221 [00:55<00:10,  3.12it/s][A
 85%|████████▌ | 188/221 [00:56<00:10,  3.29it/s][A
 86%|████████▌ | 189/221 [00:56<00:08,  3.56it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.32it/s][A
 86%|████████▋ | 191/221 [00:56<00:07,  3.91it/s][A
 87%|████████▋ | 192/221 [00:57<00:07,  3.94it/s][A
 87%|████████▋ | 193/221 [00:57<00:06,  4.08it/s][A
 88%|████████▊ | 194/221 [00:57<00:06,  4.21it/s][A
 88%|████████▊ | 195/221 [00:57<00:06,  4.28it/s][A
 89%|████████▊ | 196/221 [00:58<00:07,  3.41it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.02it/s][A
 90%|████████▉ | 198/221 [00:59<00:08,  2.71it/s][A
 90%|█████████ | 199/221 [00:59<00:06,  3.22it/s][A
 90%|█████████ | 200/221 [00:59<00:06,  3.48it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.88it/s][A
 91%|█████████▏| 202/221 [01:00<00:05,  3.51it/s][A
 92%|█████████▏| 203/221 [01:00<00:04,  3.86it/s][A
 92%|█████████▏| 204/221 [01:00<00:05,  3.35it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.59it/s][A
 93%|█████████▎| 206/221 [01:01<00:05,  2.94it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  2.84it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.54it/s][A
 95%|█████████▍| 209/221 [01:02<00:03,  3.63it/s][A
 95%|█████████▌| 210/221 [01:02<00:03,  2.93it/s][A
 95%|█████████▌| 211/221 [01:02<00:03,  3.27it/s][A
 96%|█████████▌| 212/221 [01:03<00:03,  2.93it/s][A
 96%|█████████▋| 213/221 [01:03<00:02,  3.02it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.00it/s][A
 97%|█████████▋| 215/221 [01:04<00:01,  3.08it/s][A
 98%|█████████▊| 216/221 [01:04<00:01,  3.02it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.29it/s][A
 99%|█████████▊| 218/221 [01:05<00:00,  3.08it/s][A
 99%|█████████▉| 219/221 [01:05<00:00,  3.07it/s][A
100%|█████████▉| 220/221 [01:05<00:00,  3.56it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.39it/s][A100%|██████████| 221/221 [01:05<00:00,  3.35it/s]
09/17/2024 05:22:42 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 949--===========

09/17/2024 05:22:42 - INFO - __main__ -   {'area_r1': 40.3, 'area_recall': '40.3/65.2/74.4', 'area_ravg': 60.0}
09/17/2024 05:22:42 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 949--===========

09/17/2024 05:22:42 - INFO - __main__ -   {'forward_r1': 37.2, 'forward_recall': '37.2/65.0/77.6', 'forward_ravg': 60.0}
09/17/2024 05:22:42 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 949--===========

09/17/2024 05:22:42 - INFO - __main__ -   {'area_video_r1': 39.0, 'area_video_recall': '39.0/66.4/78.3', 'area_video_ravg': 61.2}
09/17/2024 05:22:42 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 299=======

09/17/2024 05:22:42 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 05:22:42 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 949--===========

09/17/2024 05:22:42 - INFO - __main__ -   {'area_video_r1': 53.8, 'area_video_recall': '53.8/75.5/82.8', 'area_video_ravg': 70.7, 'area_video_back_r1': 47.6, 'area_video_back_recall': '47.6/74.2/82.2', 'area_video_back_ravg': 68.0}
09/17/2024 05:22:42 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 549=======

09/17/2024 05:22:42 - INFO - __main__ -   {'area_video_r1': 54.1, 'area_video_recall': '54.1/75.5/82.4', 'area_video_ravg': 70.6, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.5/82.1', 'area_video_back_ravg': 68.7}
09/17/2024 05:22:42 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 949--===========

09/17/2024 05:22:42 - INFO - __main__ -   {'video_r1': 38.7, 'video_recall': '38.7/64.3/74.1', 'video_ravg': 59.0}
09/17/2024 05:22:42 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 949=======

09/17/2024 05:22:42 - INFO - __main__ -   {'video_r1': 38.7, 'video_recall': '38.7/64.3/74.1', 'video_ravg': 59.0}
09/17/2024 05:22:42 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 949--===========

09/17/2024 05:22:42 - INFO - __main__ -   {'video_r1': 53.7, 'video_recall': '53.7/75.1/82.4', 'video_ravg': 70.4}
09/17/2024 05:22:42 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 549=======

09/17/2024 05:22:42 - INFO - __main__ -   {'video_r1': 54.5, 'video_recall': '54.5/76.1/83.4', 'video_ravg': 71.3}
[h264 @ 0x55a318a80880] mmco: unref short failure
[h264 @ 0x55a318a80880] mmco: unref short failure
[h264 @ 0x55a318a80880] mmco: unref short failure
[h264 @ 0x55a318a80880] mmco: unref short failure
09/17/2024 05:23:09 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.006675373297184706, 'loss_ret%tv%ta--finetune_area/loss_area': 1.1124887466430664, 'loss_ret%tv%ta--finetune_area/total_loss': 1.1191641092300415}
[h264 @ 0x55a318a80880] mmco: unref short failure
[h264 @ 0x55a318a80880] mmco: unref short failure
 33%|███▎      | 950/2910 [6:01:26<66:20:31, 121.85s/it] 33%|███▎      | 951/2910 [6:01:30<46:59:46, 86.36s/it] [h264 @ 0x55a30eea0a80] mmco: unref short failure
[h264 @ 0x55a30eea0a80] mmco: unref short failure
[h264 @ 0x55e243b42180] mmco: unref short failure
[h264 @ 0x55e243b42180] mmco: unref short failure
[h264 @ 0x560751513200] mmco: unref short failure
[h264 @ 0x560751513200] mmco: unref short failure
 33%|███▎      | 952/2910 [6:01:33<33:30:51, 61.62s/it] 33%|███▎      | 953/2910 [6:01:37<24:06:47, 44.36s/it][h264 @ 0x560748d13500] mmco: unref short failure
 33%|███▎      | 954/2910 [6:01:42<17:37:58, 32.45s/it][h264 @ 0x55b5c875f780] mmco: unref short failure
[h264 @ 0x55b5c875f780] mmco: unref short failure
 33%|███▎      | 955/2910 [6:01:48<13:13:09, 24.34s/it] 33%|███▎      | 956/2910 [6:01:53<10:04:16, 18.55s/it][h264 @ 0x55e24cfb2a00] mmco: unref short failure
[h264 @ 0x55e24cfb2a00] mmco: unref short failure
 33%|███▎      | 957/2910 [6:01:58<7:53:34, 14.55s/it]  33%|███▎      | 958/2910 [6:02:03<6:25:33, 11.85s/it] 33%|███▎      | 959/2910 [6:02:09<5:25:26, 10.01s/it][h264 @ 0x560760f10200] mmco: unref short failure
[h264 @ 0x560760f10200] mmco: unref short failure
 33%|███▎      | 960/2910 [6:02:16<4:56:01,  9.11s/it] 33%|███▎      | 961/2910 [6:02:22<4:25:22,  8.17s/it] 33%|███▎      | 962/2910 [6:02:28<4:00:43,  7.41s/it][h264 @ 0x56074233db80] mmco: unref short failure
[h264 @ 0x56074233db80] mmco: unref short failure
[h264 @ 0x55a3259c9240] mmco: unref short failure
[h264 @ 0x55a3259c9240] mmco: unref short failure
[h264 @ 0x55a3259c9240] mmco: unref short failure
[h264 @ 0x55a3259c9240] mmco: unref short failure
[h264 @ 0x55a3259c9240] mmco: unref short failure
[h264 @ 0x55a3259c9240] mmco: unref short failure
 33%|███▎      | 963/2910 [6:02:33<3:39:35,  6.77s/it][h264 @ 0x55a32c80bb40] mmco: unref short failure
[h264 @ 0x55b5b1537e80] mmco: unref short failure
[h264 @ 0x55a318857b80] mmco: unref short failure
 33%|███▎      | 964/2910 [6:02:38<3:26:29,  6.37s/it]09/17/2024 05:24:27 - INFO - __main__ -   current idx -bLVFJgtJwI.0 from finetune_area returns wrong image/video, use 4720 instead.
[h264 @ 0x55e24df2d800] mmco: unref short failure
 33%|███▎      | 965/2910 [6:02:44<3:14:23,  6.00s/it][h264 @ 0x55e23bebc240] mmco: unref short failure
[h264 @ 0x56075089c5c0] mmco: unref short failure
[h264 @ 0x56075089c5c0] mmco: unref short failure
[h264 @ 0x55e258f4fa00] mmco: unref short failure
[h264 @ 0x55a3134fc900] mmco: unref short failure
[h264 @ 0x55a3134fc900] mmco: unref short failure
[h264 @ 0x55e259cbaa80] mmco: unref short failure
[h264 @ 0x55e259cbaa80] mmco: unref short failure
 33%|███▎      | 966/2910 [6:03:36<10:42:10, 19.82s/it][h264 @ 0x55e251993900] mmco: unref short failure
[h264 @ 0x55e251993900] mmco: unref short failure
[h264 @ 0x55e251993900] mmco: unref short failure
[h264 @ 0x55e25403d940] mmco: unref short failure
[h264 @ 0x55e25403d940] mmco: unref short failure
[h264 @ 0x55e24e229500] mmco: unref short failure
[h264 @ 0x55e24e229500] mmco: unref short failure
 33%|███▎      | 967/2910 [6:03:58<11:02:26, 20.46s/it] 33%|███▎      | 968/2910 [6:04:06<9:06:32, 16.89s/it]  33%|███▎      | 969/2910 [6:04:12<7:19:16, 13.58s/it] 33%|███▎      | 970/2910 [6:04:18<6:04:15, 11.27s/it][h264 @ 0x55e251106fc0] mmco: unref short failure
[h264 @ 0x55a32c80bb40] mmco: unref short failure
[h264 @ 0x55a32c80bb40] mmco: unref short failure
 33%|███▎      | 971/2910 [6:04:24<5:12:15,  9.66s/it][h264 @ 0x5607481cb7c0] mmco: unref short failure
 33%|███▎      | 972/2910 [6:04:29<4:30:54,  8.39s/it][h264 @ 0x55b5ae288440] mmco: unref short failure
[h264 @ 0x55b5ae288440] mmco: unref short failure
[h264 @ 0x55b5c7b84280] mmco: unref short failure
[h264 @ 0x55a3277f0fc0] mmco: unref short failure
[h264 @ 0x55a3277f0fc0] mmco: unref short failure
[h264 @ 0x55b5cca1a880] mmco: unref short failure
[h264 @ 0x55b5cca1a880] mmco: unref short failure
 33%|███▎      | 973/2910 [6:04:49<6:18:13, 11.72s/it][h264 @ 0x56076305fd00] mmco: unref short failure
[h264 @ 0x56076305fd00] mmco: unref short failure
[h264 @ 0x56076305fd00] mmco: unref short failure
[h264 @ 0x56076305fd00] mmco: unref short failure
[h264 @ 0x55b5c05dd440] mmco: unref short failure
[h264 @ 0x55b5c05dd440] mmco: unref short failure
09/17/2024 05:26:51 - INFO - __main__ -   current idx gcVsZE1_ynw.15 from finetune_area returns wrong image/video, use 40598 instead.
[h264 @ 0x55b5c06794c0] mmco: unref short failure
[h264 @ 0x55a3110a9a40] mmco: unref short failure
[h264 @ 0x55a3110a9a40] mmco: unref short failure
[h264 @ 0x55a3110a9a40] mmco: unref short failure
[h264 @ 0x55a3110a9a40] mmco: unref short failure
[h264 @ 0x55a3134fc900] mmco: unref short failure
[h264 @ 0x55b5cad301c0] mmco: unref short failure
[h264 @ 0x55b5cad301c0] mmco: unref short failure
[h264 @ 0x56075184e980] mmco: unref short failure
[h264 @ 0x55e238c4b6c0] mmco: unref short failure
[h264 @ 0x55a3228a1b80] mmco: unref short failure
 33%|███▎      | 974/2910 [6:05:56<15:15:19, 28.37s/it][h264 @ 0x55e23c582c80] mmco: unref short failure
[h264 @ 0x55e257e0f040] mmco: unref short failure
[h264 @ 0x55e257e0f040] mmco: unref short failure
[h264 @ 0x55e257e0f040] mmco: unref short failure
[h264 @ 0x55e241eefc40] mmco: unref short failure
[h264 @ 0x55a32ead8740] mmco: unref short failure
[h264 @ 0x55e24eb7fa00] mmco: unref short failure
[h264 @ 0x55e24eb7fa00] mmco: unref short failure
[h264 @ 0x55a31053d980] mmco: unref short failure
[h264 @ 0x560746dd79c0] mmco: unref short failure
[h264 @ 0x560746dd79c0] mmco: unref short failure
 34%|███▎      | 975/2910 [6:06:24<15:10:35, 28.24s/it][h264 @ 0x55a31a2db400] mmco: unref short failure
[h264 @ 0x55a31a2db400] mmco: unref short failure
 34%|███▎      | 976/2910 [6:06:40<13:09:09, 24.48s/it] 34%|███▎      | 977/2910 [6:06:45<10:01:44, 18.68s/it][h264 @ 0x55e238f71940] mmco: unref short failure
 34%|███▎      | 978/2910 [6:06:50<7:55:07, 14.76s/it] 09/17/2024 05:28:40 - INFO - __main__ -   current idx h0wIcmfgWWQ.54 from finetune_area returns wrong image/video, use 127564 instead.
[h264 @ 0x55a30fedde80] mmco: unref short failure
[h264 @ 0x55a30fedde80] mmco: unref short failure
[h264 @ 0x56074da92800] mmco: unref short failure
[h264 @ 0x56074da92800] mmco: unref short failure
 34%|███▎      | 979/2910 [6:06:56<6:24:34, 11.95s/it] 34%|███▎      | 980/2910 [6:07:01<5:25:08, 10.11s/it][h264 @ 0x55b5c7168680] mmco: unref short failure
 34%|███▎      | 981/2910 [6:07:15<6:02:15, 11.27s/it][h264 @ 0x55a310d6f000] mmco: unref short failure
[h264 @ 0x55a310d6f000] mmco: unref short failure
[h264 @ 0x55b5aa7aff80] mmco: unref short failure
[h264 @ 0x56075da01300] mmco: unref short failure
[h264 @ 0x55e23cd6b940] mmco: unref short failure
[h264 @ 0x55b5bc280940] mmco: unref short failure
[h264 @ 0x55b5bc280940] mmco: unref short failure
[h264 @ 0x55a3290927c0] mmco: unref short failure
[h264 @ 0x55b5cbd2bec0] mmco: unref short failure
[h264 @ 0x56074f753d40] mmco: unref short failure
[h264 @ 0x55e23bb63540] mmco: unref short failure
[h264 @ 0x55e23bb63540] mmco: unref short failure
[h264 @ 0x55e23bb63540] mmco: unref short failure
[h264 @ 0x55e23bb63540] mmco: unref short failure
[h264 @ 0x55a326faebc0] mmco: unref short failure
[h264 @ 0x55a326faebc0] mmco: unref short failure
[h264 @ 0x55a326faebc0] mmco: unref short failure
09/17/2024 05:29:59 - INFO - __main__ -   current idx E_j3lYgDR7U.12 from finetune_area returns wrong image/video, use 138341 instead.
 34%|███▎      | 982/2910 [6:08:21<14:48:41, 27.66s/it][h264 @ 0x56075b41fd80] mmco: unref short failure
[h264 @ 0x56075b41fd80] mmco: unref short failure
[h264 @ 0x55e241869380] mmco: unref short failure
[h264 @ 0x55e241869380] mmco: unref short failure
[h264 @ 0x55e241869380] mmco: unref short failure
[h264 @ 0x55e241869380] mmco: unref short failure
[h264 @ 0x55e241869380] mmco: unref short failure
[h264 @ 0x55a312d44c40] mmco: unref short failure
[h264 @ 0x55a312d44c40] mmco: unref short failure
[h264 @ 0x55a312d44c40] mmco: unref short failure
[h264 @ 0x55a312d44c40] mmco: unref short failure
[h264 @ 0x560748849c40] mmco: unref short failure
[h264 @ 0x55b5b2da9f00] mmco: unref short failure
[h264 @ 0x55b5b2da9f00] mmco: unref short failure
[h264 @ 0x55b5b2da9f00] mmco: unref short failure
[h264 @ 0x55b5b2da9f00] mmco: unref short failure
 34%|███▍      | 983/2910 [6:08:44<14:04:27, 26.29s/it][h264 @ 0x55e256356ec0] mmco: unref short failure
[h264 @ 0x5607475ee640] mmco: unref short failure
[h264 @ 0x5607475ee640] mmco: unref short failure
[h264 @ 0x560762b44980] mmco: unref short failure
[h264 @ 0x560748d13500] mmco: unref short failure
[h264 @ 0x55b5cb76a900] mmco: unref short failure
[h264 @ 0x55b5cb76a900] mmco: unref short failure
 34%|███▍      | 984/2910 [6:09:15<14:41:20, 27.46s/it][h264 @ 0x55a320332700] mmco: unref short failure
[h264 @ 0x560748d13500] mmco: unref short failure
[h264 @ 0x560748d13500] mmco: unref short failure
[h264 @ 0x560751b86c40] mmco: unref short failure
 34%|███▍      | 985/2910 [6:09:21<11:17:51, 21.13s/it][h264 @ 0x56074d407300] mmco: unref short failure
[h264 @ 0x56074d407300] mmco: unref short failure
[h264 @ 0x55a310d55700] mmco: unref short failure
[h264 @ 0x55a310d55700] mmco: unref short failure
[h264 @ 0x55a310d55700] mmco: unref short failure
[h264 @ 0x55a310d55700] mmco: unref short failure
 34%|███▍      | 986/2910 [6:09:27<8:52:21, 16.60s/it]  34%|███▍      | 987/2910 [6:09:33<7:04:54, 13.26s/it] 34%|███▍      | 988/2910 [6:09:38<5:53:36, 11.04s/it] 34%|███▍      | 989/2910 [6:09:55<6:46:06, 12.68s/it][h264 @ 0x560753b25e00] mmco: unref short failure
[h264 @ 0x55e25743ec00] mmco: unref short failure
[h264 @ 0x55e25743ec00] mmco: unref short failure
[h264 @ 0x55a319a47c80] mmco: unref short failure
[h264 @ 0x55a319a47c80] mmco: unref short failure
09/17/2024 05:31:56 - INFO - __main__ -   current idx c36bv6MjqLE.0 from finetune_area returns wrong image/video, use 119021 instead.
[h264 @ 0x560756977f80] mmco: unref short failure
[h264 @ 0x55a313488940] mmco: unref short failure
[h264 @ 0x55a313488940] mmco: unref short failure
[h264 @ 0x55b5b1e59f40] mmco: unref short failure
[h264 @ 0x55b5b1e59f40] mmco: unref short failure
[h264 @ 0x55b5b1e59f40] mmco: unref short failure
[h264 @ 0x55b5b1e59f40] mmco: unref short failure
[h264 @ 0x55e25403d940] mmco: unref short failure
[h264 @ 0x55e25403d940] mmco: unref short failure
[h264 @ 0x55b5abfeb000] mmco: unref short failure
[h264 @ 0x55b5abfeb000] mmco: unref short failure
[h264 @ 0x55b5ac121040] mmco: unref short failure
 34%|███▍      | 990/2910 [6:10:44<12:35:30, 23.61s/it][h264 @ 0x55e2429e3840] mmco: unref short failure
[h264 @ 0x55b5c2ac55c0] mmco: unref short failure
[h264 @ 0x55b5c2ac55c0] mmco: unref short failure
[h264 @ 0x560741684800] mmco: unref short failure
[h264 @ 0x55e24fc49600] mmco: unref short failure
[h264 @ 0x55e24fc49600] mmco: unref short failure
[h264 @ 0x55e24fc49600] mmco: unref short failure
[h264 @ 0x55e24fc49600] mmco: unref short failure
[h264 @ 0x55a32f898400] mmco: unref short failure
[h264 @ 0x55a329ba9240] mmco: unref short failure
 34%|███▍      | 991/2910 [6:11:16<13:50:57, 25.98s/it][h264 @ 0x56074971ffc0] mmco: unref short failure
[h264 @ 0x56074971ffc0] mmco: unref short failure
[h264 @ 0x55a32d7cda40] mmco: unref short failure
[h264 @ 0x55a32d7cda40] mmco: unref short failure
[h264 @ 0x55b5b1936400] mmco: unref short failure
[h264 @ 0x55b5b1936400] mmco: unref short failure
09/17/2024 05:33:27 - INFO - __main__ -   current idx 6wN4IYAiKIg.50 from finetune_area returns wrong image/video, use 95209 instead.
[h264 @ 0x55a330bc3cc0] mmco: unref short failure
[h264 @ 0x55a323263e40] mmco: unref short failure
 34%|███▍      | 992/2910 [6:12:04<17:28:36, 32.80s/it] 34%|███▍      | 993/2910 [6:12:11<13:14:20, 24.86s/it][h264 @ 0x560750629b00] mmco: unref short failure
09/17/2024 05:33:58 - INFO - __main__ -   current idx SguG4-Tr-F8.13 from finetune_area returns wrong image/video, use 66228 instead.
[h264 @ 0x55e2577a5080] mmco: unref short failure
 34%|███▍      | 994/2910 [6:12:16<10:05:06, 18.95s/it][h264 @ 0x560762726480] mmco: unref short failure
[h264 @ 0x560762726480] mmco: unref short failure
 34%|███▍      | 995/2910 [6:12:21<7:54:43, 14.87s/it] 09/17/2024 05:34:07 - INFO - __main__ -   current idx c-OFuj2DzPc.20 from finetune_area returns wrong image/video, use 113541 instead.
 34%|███▍      | 996/2910 [6:12:26<6:21:02, 11.95s/it][h264 @ 0x55e23968d640] mmco: unref short failure
 34%|███▍      | 997/2910 [6:12:33<5:29:04, 10.32s/it][h264 @ 0x55b5ba3b0c80] mmco: unref short failure
[h264 @ 0x55b5ba3b0c80] mmco: unref short failure
[h264 @ 0x55b5ba3b0c80] mmco: unref short failure
[h264 @ 0x55b5ba3b0c80] mmco: unref short failure
[h264 @ 0x55a330bc3cc0] mmco: unref short failure
09/17/2024 05:34:29 - INFO - __main__ -   current idx fQszS3V8sxI.1 from finetune_area returns wrong image/video, use 54813 instead.
[h264 @ 0x560763b518c0] mmco: unref short failure
[h264 @ 0x560763b518c0] mmco: unref short failure
[h264 @ 0x55b5c47a2380] mmco: unref short failure
[h264 @ 0x560762726480] mmco: unref short failure
[h264 @ 0x560762726480] mmco: unref short failure
[h264 @ 0x55e2556662c0] mmco: unref short failure
[h264 @ 0x55b5c5849a00] mmco: unref short failure
[h264 @ 0x55a326faebc0] mmco: unref short failure
[h264 @ 0x55a330bc3cc0] mmco: unref short failure
[h264 @ 0x55a330bc3cc0] mmco: unref short failure
[h264 @ 0x55a330bc3cc0] mmco: unref short failure
[h264 @ 0x55a330bc3cc0] mmco: unref short failure
 34%|███▍      | 998/2910 [6:13:19<11:11:56, 21.09s/it][h264 @ 0x55e2398f9700] mmco: unref short failure
[h264 @ 0x55a327a8de40] mmco: unref short failure
[h264 @ 0x55e23b27c8c0] mmco: unref short failure
[h264 @ 0x560741684800] mmco: unref short failure
[h264 @ 0x560741684800] mmco: unref short failure
[h264 @ 0x560741684800] mmco: unref short failure
[h264 @ 0x560741684800] mmco: unref short failure
[h264 @ 0x55e2376ca4c0] mmco: unref short failure
[h264 @ 0x55e2376ca4c0] mmco: unref short failure
 34%|███▍      | 999/2910 [6:13:44<11:49:29, 22.28s/it]09/17/2024 05:35:30 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 05:35:30 - INFO - __main__ -   start running ret%tva validation...
[h264 @ 0x55b5aef62ac0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a319f4e240] mmco: unref short failure
[h264 @ 0x55a319f4e240] mmco: unref short failure
[h264 @ 0x55a319f4e240] mmco: unref short failure
[h264 @ 0x55a319f4e240] mmco: unref short failure
[h264 @ 0x55a31217a9c0] mmco: unref short failure
[h264 @ 0x55a31217a9c0] mmco: unref short failure
[h264 @ 0x55b5b38799c0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a330ed4000] mmco: unref short failure
[h264 @ 0x55a31217a9c0] mmco: unref short failure
[h264 @ 0x55b5ba3b0c80] mmco: unref short failure
[h264 @ 0x55b5b7bce880] mmco: unref short failure
[h264 @ 0x55a31217a9c0] mmco: unref short failure
[h264 @ 0x55a313041740] mmco: unref short failure
[h264 @ 0x5607481cb7c0] mmco: unref short failure
[h264 @ 0x5607481cb7c0] mmco: unref short failure
[h264 @ 0x55e2503a94c0] mmco: unref short failure
[h264 @ 0x55e2503a94c0] mmco: unref short failure
[h264 @ 0x56074461c000] mmco: unref short failure
[h264 @ 0x56074461c000] mmco: unref short failure
[h264 @ 0x55b5ae4289c0] mmco: unref short failure
[h264 @ 0x55b5ae4289c0] mmco: unref short failure
[h264 @ 0x55a31f7f1c80] mmco: unref short failure
[h264 @ 0x55a31f7f1c80] mmco: unref short failure
[h264 @ 0x560747fe22c0] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:01<04:34,  1.25s/it][A
  1%|          | 2/221 [00:01<03:09,  1.16it/s][A
  1%|▏         | 3/221 [00:02<01:59,  1.83it/s][A
  2%|▏         | 5/221 [00:02<01:01,  3.51it/s][A
  3%|▎         | 6/221 [00:02<00:50,  4.30it/s][A
  3%|▎         | 7/221 [00:02<00:51,  4.15it/s][A
  4%|▎         | 8/221 [00:03<01:21,  2.61it/s][A
  4%|▍         | 9/221 [00:03<01:11,  2.96it/s][A[h264 @ 0x55a311659200] mmco: unref short failure
[h264 @ 0x55a311659200] mmco: unref short failure
[h264 @ 0x55a311659200] mmco: unref short failure
[h264 @ 0x55a311659200] mmco: unref short failure

  5%|▍         | 10/221 [00:03<01:10,  2.98it/s][A
  5%|▍         | 11/221 [00:04<01:04,  3.25it/s][A
  5%|▌         | 12/221 [00:04<01:14,  2.80it/s][A
  6%|▌         | 13/221 [00:04<01:02,  3.32it/s][A[h264 @ 0x56074482fb80] mmco: unref short failure
[h264 @ 0x55b5c190da80] mmco: unref short failure
[h264 @ 0x55b5c190da80] mmco: unref short failure
[h264 @ 0x55b5c190da80] mmco: unref short failure
[h264 @ 0x55b5c190da80] mmco: unref short failure

  6%|▋         | 14/221 [00:06<02:59,  1.16it/s][A
  7%|▋         | 15/221 [00:07<02:20,  1.46it/s][A[h264 @ 0x55b5b5d2cf40] mmco: unref short failure
[h264 @ 0x55b5b5d2cf40] mmco: unref short failure

  7%|▋         | 16/221 [00:07<02:00,  1.70it/s][A
  8%|▊         | 17/221 [00:07<01:41,  2.02it/s][A
  8%|▊         | 18/221 [00:08<01:27,  2.33it/s][A
  9%|▊         | 19/221 [00:08<01:13,  2.75it/s][A
  9%|▉         | 20/221 [00:08<01:04,  3.12it/s][A
 10%|▉         | 21/221 [00:08<00:56,  3.55it/s][A
 10%|▉         | 22/221 [00:08<00:52,  3.81it/s][A
 10%|█         | 23/221 [00:09<00:42,  4.61it/s][A
 11%|█         | 24/221 [00:09<00:38,  5.12it/s][A
 11%|█▏        | 25/221 [00:09<00:39,  4.91it/s][A
 12%|█▏        | 26/221 [00:09<00:43,  4.44it/s][A
 12%|█▏        | 27/221 [00:09<00:37,  5.21it/s][A
 13%|█▎        | 28/221 [00:10<00:52,  3.68it/s][A
 13%|█▎        | 29/221 [00:10<00:42,  4.54it/s][A[h264 @ 0x56074c017b40] mmco: unref short failure
[h264 @ 0x56074c017b40] mmco: unref short failure

 14%|█▎        | 30/221 [00:10<00:44,  4.34it/s][A
 14%|█▍        | 31/221 [00:10<00:49,  3.87it/s][A
 14%|█▍        | 32/221 [00:11<00:41,  4.58it/s][A
 15%|█▍        | 33/221 [00:11<00:48,  3.87it/s][A
 15%|█▌        | 34/221 [00:11<00:41,  4.53it/s][A
 16%|█▌        | 35/221 [00:11<00:35,  5.18it/s][A
 16%|█▋        | 36/221 [00:11<00:40,  4.51it/s][A
 17%|█▋        | 37/221 [00:12<01:00,  3.06it/s][A
 17%|█▋        | 38/221 [00:12<01:02,  2.92it/s][A
 18%|█▊        | 39/221 [00:13<00:49,  3.69it/s][A
 18%|█▊        | 40/221 [00:13<00:52,  3.47it/s][A
 19%|█▊        | 41/221 [00:13<00:42,  4.21it/s][A
 19%|█▉        | 42/221 [00:13<00:53,  3.32it/s][A
 19%|█▉        | 43/221 [00:14<00:44,  4.02it/s][A
 20%|█▉        | 44/221 [00:14<00:38,  4.57it/s][A
 20%|██        | 45/221 [00:15<01:34,  1.87it/s][A
 21%|██        | 46/221 [00:16<01:42,  1.70it/s][A
 21%|██▏       | 47/221 [00:16<01:49,  1.59it/s][A
 22%|██▏       | 48/221 [00:17<01:23,  2.06it/s][A
 22%|██▏       | 49/221 [00:17<01:10,  2.45it/s][A
 23%|██▎       | 50/221 [00:17<00:56,  3.01it/s][A
 23%|██▎       | 51/221 [00:17<00:46,  3.63it/s][A
 24%|██▎       | 52/221 [00:17<00:39,  4.25it/s][A
 24%|██▍       | 53/221 [00:17<00:35,  4.69it/s][A[h264 @ 0x55b5ab8f5fc0] mmco: unref short failure
[h264 @ 0x55a3231cad80] mmco: unref short failure

 24%|██▍       | 54/221 [00:19<01:40,  1.66it/s][A
 25%|██▍       | 55/221 [00:19<01:30,  1.83it/s][A
 25%|██▌       | 56/221 [00:20<01:19,  2.07it/s][A
 26%|██▌       | 57/221 [00:20<01:04,  2.53it/s][A
 26%|██▌       | 58/221 [00:20<00:51,  3.14it/s][A[h264 @ 0x55e24e342b40] mmco: unref short failure

 27%|██▋       | 59/221 [00:20<00:47,  3.43it/s][A[h264 @ 0x55e24e342b40] mmco: unref short failure

 27%|██▋       | 60/221 [00:21<00:52,  3.07it/s][A
 28%|██▊       | 61/221 [00:21<00:49,  3.22it/s][A
 28%|██▊       | 62/221 [00:21<00:46,  3.45it/s][A
 29%|██▊       | 63/221 [00:21<00:43,  3.64it/s][A
 29%|██▉       | 64/221 [00:22<00:40,  3.92it/s][A
 29%|██▉       | 65/221 [00:22<00:38,  4.09it/s][h264 @ 0x55e239695400] mmco: unref short failure
[h264 @ 0x55e239695400] mmco: unref short failure
[A[h264 @ 0x55e239695400] mmco: unref short failure
[h264 @ 0x55e239695400] mmco: unref short failure

 30%|██▉       | 66/221 [00:22<00:42,  3.67it/s][A
 30%|███       | 67/221 [00:22<00:43,  3.55it/s][A[h264 @ 0x55e23d9ee340] mmco: unref short failure
[h264 @ 0x55e23d9ee340] mmco: unref short failure

 31%|███       | 68/221 [00:23<00:35,  4.29it/s][A[h264 @ 0x55e23d9ee340] mmco: unref short failure
[h264 @ 0x55e23d9ee340] mmco: unref short failure
[h264 @ 0x55b5afd69400] mmco: unref short failure
[h264 @ 0x55b5afd69400] mmco: unref short failure

 31%|███       | 69/221 [00:23<01:02,  2.44it/s][A
 32%|███▏      | 70/221 [00:24<00:51,  2.95it/s][A[h264 @ 0x55e23d9ee340] mmco: unref short failure
[h264 @ 0x55e23d9ee340] mmco: unref short failure
[h264 @ 0x55e239d08e40] mmco: unref short failure
[h264 @ 0x55e239d08e40] mmco: unref short failure
[h264 @ 0x56075b396700] mmco: unref short failure
[h264 @ 0x56075b396700] mmco: unref short failure

 32%|███▏      | 71/221 [00:26<02:15,  1.11it/s][A
 33%|███▎      | 72/221 [00:26<01:46,  1.40it/s][A
 33%|███▎      | 73/221 [00:26<01:27,  1.70it/s][A
 33%|███▎      | 74/221 [00:27<01:12,  2.02it/s][A
 34%|███▍      | 75/221 [00:27<01:13,  2.00it/s][A
 34%|███▍      | 76/221 [00:27<01:00,  2.39it/s][A
 35%|███▍      | 77/221 [00:28<00:51,  2.80it/s][A
 35%|███▌      | 78/221 [00:28<00:50,  2.84it/s][A
 36%|███▌      | 79/221 [00:29<01:03,  2.22it/s][A
 36%|███▌      | 80/221 [00:29<00:51,  2.72it/s][A
 37%|███▋      | 81/221 [00:29<00:48,  2.86it/s][A
 37%|███▋      | 82/221 [00:29<00:42,  3.27it/s][A
 38%|███▊      | 83/221 [00:29<00:35,  3.89it/s][A
 38%|███▊      | 84/221 [00:30<00:30,  4.51it/s][A
 38%|███▊      | 85/221 [00:30<00:26,  5.14it/s][A
 39%|███▉      | 86/221 [00:30<00:24,  5.56it/s][A
 39%|███▉      | 87/221 [00:30<00:40,  3.28it/s][A
 40%|███▉      | 88/221 [00:31<00:42,  3.10it/s][A
 40%|████      | 89/221 [00:34<02:44,  1.25s/it][A
 41%|████      | 90/221 [00:35<02:07,  1.03it/s][A
 41%|████      | 91/221 [00:35<01:33,  1.39it/s][A
 42%|████▏     | 92/221 [00:35<01:12,  1.79it/s][A
 42%|████▏     | 93/221 [00:36<01:16,  1.68it/s][A
 43%|████▎     | 94/221 [00:36<01:04,  1.97it/s][A
 43%|████▎     | 95/221 [00:36<00:50,  2.52it/s][A
 43%|████▎     | 96/221 [00:36<00:48,  2.60it/s][A
 44%|████▍     | 97/221 [00:36<00:37,  3.30it/s][A[h264 @ 0x55b5b83f7740] mmco: unref short failure
[h264 @ 0x55b5b83f7740] mmco: unref short failure

 44%|████▍     | 98/221 [00:37<00:32,  3.74it/s][A
 45%|████▍     | 99/221 [00:37<00:27,  4.37it/s][A[h264 @ 0x560742f519c0] mmco: unref short failure

 45%|████▌     | 100/221 [00:37<00:26,  4.64it/s][A
 46%|████▌     | 101/221 [00:37<00:23,  5.02it/s][A
 46%|████▌     | 102/221 [00:37<00:27,  4.35it/s][A
 47%|████▋     | 103/221 [00:38<00:26,  4.44it/s][A
 47%|████▋     | 104/221 [00:38<00:24,  4.69it/s][A
 48%|████▊     | 105/221 [00:38<00:32,  3.61it/s][A
 48%|████▊     | 106/221 [00:39<00:59,  1.95it/s][A
 48%|████▊     | 107/221 [00:40<00:50,  2.25it/s][A
 49%|████▉     | 108/221 [00:40<00:48,  2.34it/s][A
 49%|████▉     | 109/221 [00:40<00:51,  2.17it/s][A
 50%|████▉     | 110/221 [00:41<00:44,  2.49it/s][A
 50%|█████     | 111/221 [00:41<00:48,  2.25it/s][A
 51%|█████     | 112/221 [00:42<00:47,  2.30it/s][A
 51%|█████     | 113/221 [00:42<00:53,  2.03it/s][A
 52%|█████▏    | 114/221 [00:43<00:46,  2.29it/s][A
 52%|█████▏    | 115/221 [00:43<00:38,  2.74it/s][A
 52%|█████▏    | 116/221 [00:48<02:54,  1.66s/it][A
 53%|█████▎    | 117/221 [00:48<02:10,  1.25s/it][A
 53%|█████▎    | 118/221 [00:48<01:44,  1.01s/it][A
 54%|█████▍    | 119/221 [00:49<01:21,  1.26it/s][A
 54%|█████▍    | 120/221 [00:49<01:07,  1.50it/s][A
 55%|█████▍    | 121/221 [00:49<00:51,  1.95it/s][A
 55%|█████▌    | 122/221 [00:49<00:42,  2.35it/s][A[h264 @ 0x560744013700] mmco: unref short failure

 56%|█████▌    | 123/221 [00:49<00:34,  2.87it/s][A
 56%|█████▌    | 124/221 [00:50<00:30,  3.20it/s][A
 57%|█████▋    | 125/221 [00:50<00:28,  3.39it/s][A
 57%|█████▋    | 126/221 [00:51<00:39,  2.39it/s][A
 57%|█████▋    | 127/221 [00:51<00:44,  2.13it/s][A
 58%|█████▊    | 128/221 [00:52<00:41,  2.25it/s][A
 58%|█████▊    | 129/221 [00:52<00:36,  2.55it/s][A
 59%|█████▉    | 130/221 [00:52<00:32,  2.84it/s][A
 59%|█████▉    | 131/221 [00:52<00:24,  3.61it/s][A
 60%|█████▉    | 132/221 [00:52<00:22,  3.91it/s][A
 60%|██████    | 133/221 [00:53<00:26,  3.28it/s][A
 61%|██████    | 134/221 [00:53<00:26,  3.22it/s][A
 61%|██████    | 135/221 [00:54<00:30,  2.86it/s][A
 62%|██████▏   | 136/221 [00:54<00:31,  2.67it/s][A
 62%|██████▏   | 137/221 [00:54<00:27,  3.08it/s][A
 62%|██████▏   | 138/221 [00:55<00:28,  2.87it/s][A
 63%|██████▎   | 139/221 [00:55<00:31,  2.62it/s][A
 63%|██████▎   | 140/221 [00:56<00:31,  2.57it/s][A
 64%|██████▍   | 141/221 [00:56<00:25,  3.13it/s][A
 64%|██████▍   | 142/221 [00:56<00:28,  2.81it/s][A
 65%|██████▍   | 143/221 [00:57<00:29,  2.68it/s][A
 65%|██████▌   | 144/221 [00:57<00:23,  3.24it/s][A
 66%|██████▌   | 145/221 [00:57<00:20,  3.69it/s][A
 67%|██████▋   | 147/221 [00:57<00:17,  4.31it/s][A
 67%|██████▋   | 148/221 [00:58<00:18,  3.85it/s][A
 67%|██████▋   | 149/221 [00:58<00:16,  4.48it/s][A
 68%|██████▊   | 150/221 [00:58<00:15,  4.67it/s][A
 68%|██████▊   | 151/221 [00:59<00:36,  1.91it/s][A[h264 @ 0x560758761c40] mmco: unref short failure
[h264 @ 0x560758761c40] mmco: unref short failure

 69%|██████▉   | 152/221 [01:00<00:34,  2.00it/s][A[h264 @ 0x55a3249504c0] mmco: unref short failure

 69%|██████▉   | 153/221 [01:00<00:32,  2.11it/s][A
 70%|██████▉   | 154/221 [01:01<00:31,  2.12it/s][A
 70%|███████   | 155/221 [01:01<00:25,  2.64it/s][A
 71%|███████   | 156/221 [01:01<00:20,  3.18it/s][A
 71%|███████   | 157/221 [01:03<00:45,  1.40it/s][A
 71%|███████▏  | 158/221 [01:03<00:36,  1.72it/s][A
 72%|███████▏  | 159/221 [01:03<00:28,  2.16it/s][A
 72%|███████▏  | 160/221 [01:03<00:23,  2.55it/s][A
 73%|███████▎  | 162/221 [01:04<00:16,  3.60it/s][A
 74%|███████▍  | 163/221 [01:04<00:15,  3.73it/s][A
 74%|███████▍  | 164/221 [01:04<00:14,  4.03it/s][A
 75%|███████▍  | 165/221 [01:04<00:13,  4.24it/s][A
 75%|███████▌  | 166/221 [01:05<00:17,  3.19it/s][A
 76%|███████▌  | 167/221 [01:05<00:14,  3.76it/s][A
 76%|███████▌  | 168/221 [01:06<00:31,  1.68it/s][A
 76%|███████▋  | 169/221 [01:07<00:27,  1.87it/s][A
 77%|███████▋  | 170/221 [01:07<00:24,  2.10it/s][A
 77%|███████▋  | 171/221 [01:07<00:21,  2.29it/s][A
 78%|███████▊  | 172/221 [01:08<00:18,  2.67it/s][A
 78%|███████▊  | 173/221 [01:08<00:14,  3.25it/s][A
 79%|███████▊  | 174/221 [01:08<00:13,  3.58it/s][A
 79%|███████▉  | 175/221 [01:08<00:12,  3.54it/s][A
 80%|███████▉  | 176/221 [01:08<00:13,  3.45it/s][A
 80%|████████  | 177/221 [01:09<00:10,  4.03it/s][A
 81%|████████  | 178/221 [01:09<00:12,  3.52it/s][A
 81%|████████  | 179/221 [01:09<00:13,  3.04it/s][A
 81%|████████▏ | 180/221 [01:10<00:10,  3.74it/s][A
 82%|████████▏ | 181/221 [01:10<00:10,  3.78it/s][A
 82%|████████▏ | 182/221 [01:10<00:09,  4.22it/s][A
 83%|████████▎ | 183/221 [01:10<00:08,  4.59it/s][A
 83%|████████▎ | 184/221 [01:11<00:09,  3.91it/s][A
 84%|████████▎ | 185/221 [01:11<00:08,  4.17it/s][A
 84%|████████▍ | 186/221 [01:11<00:11,  3.13it/s][A
 85%|████████▍ | 187/221 [01:11<00:08,  3.85it/s][A
 85%|████████▌ | 188/221 [01:12<00:08,  3.81it/s][A
 86%|████████▌ | 189/221 [01:12<00:08,  3.67it/s][A
 86%|████████▌ | 190/221 [01:12<00:08,  3.61it/s][A
 86%|████████▋ | 191/221 [01:12<00:07,  4.27it/s][A
 87%|████████▋ | 192/221 [01:13<00:06,  4.41it/s][A
 87%|████████▋ | 193/221 [01:13<00:05,  5.17it/s][A
 88%|████████▊ | 194/221 [01:14<00:10,  2.57it/s][A
 88%|████████▊ | 195/221 [01:14<00:08,  3.09it/s][A
 89%|████████▉ | 197/221 [01:14<00:05,  4.33it/s][A
 90%|████████▉ | 198/221 [01:14<00:05,  4.56it/s][A
 90%|█████████ | 199/221 [01:14<00:04,  4.89it/s][A09/17/2024 05:39:05 - INFO - __main__ -   current idx BxSP425mQ4g.34 from finetune_area returns wrong image/video, use 47636 instead.

 90%|█████████ | 200/221 [01:15<00:05,  4.10it/s][A
 91%|█████████ | 201/221 [01:15<00:04,  4.03it/s][A
 91%|█████████▏| 202/221 [01:15<00:04,  4.28it/s][A[h264 @ 0x55b5af2c55c0] mmco: unref short failure
[h264 @ 0x55b5af2c55c0] mmco: unref short failure

 92%|█████████▏| 203/221 [01:17<00:12,  1.41it/s][A
 93%|█████████▎| 205/221 [01:17<00:06,  2.31it/s][A
 93%|█████████▎| 206/221 [01:18<00:07,  2.13it/s][A
 94%|█████████▍| 208/221 [01:18<00:04,  3.11it/s][A
 95%|█████████▌| 210/221 [01:18<00:02,  4.35it/s][A[h264 @ 0x55b5aa5e1780] mmco: unref short failure
[h264 @ 0x55b5aa5e1780] mmco: unref short failure
[h264 @ 0x55b5aa5e1780] mmco: unref short failure
[h264 @ 0x55b5aa5e1780] mmco: unref short failure

 95%|█████████▌| 211/221 [01:19<00:02,  3.64it/s][A
 96%|█████████▌| 212/221 [01:19<00:02,  3.89it/s][A
 97%|█████████▋| 214/221 [01:20<00:02,  2.73it/s][A
 97%|█████████▋| 215/221 [01:20<00:02,  2.89it/s][A
 98%|█████████▊| 216/221 [01:20<00:01,  3.11it/s][A
 98%|█████████▊| 217/221 [01:21<00:01,  2.42it/s][A
 99%|█████████▊| 218/221 [01:21<00:01,  2.54it/s][A
 99%|█████████▉| 219/221 [01:22<00:00,  2.98it/s][A
100%|█████████▉| 220/221 [01:26<00:01,  1.44s/it][A
100%|██████████| 221/221 [01:26<00:00,  1.08s/it][A100%|██████████| 221/221 [01:26<00:00,  2.56it/s]
[h264 @ 0x55b5b2a73f00] mmco: unref short failure
[h264 @ 0x55b5b2a73f00] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:05,  3.33it/s][A
  1%|          | 2/221 [00:00<01:06,  3.29it/s][A
  1%|▏         | 3/221 [00:00<01:05,  3.34it/s][A
  2%|▏         | 4/221 [00:01<01:05,  3.30it/s][A
  2%|▏         | 5/221 [00:01<01:05,  3.29it/s][A
  3%|▎         | 6/221 [00:01<01:05,  3.29it/s][A
  3%|▎         | 7/221 [00:02<01:05,  3.26it/s][A
  4%|▎         | 8/221 [00:02<01:04,  3.31it/s][A
  4%|▍         | 9/221 [00:02<01:04,  3.28it/s][A
  5%|▍         | 10/221 [00:03<01:04,  3.28it/s][A
  5%|▍         | 11/221 [00:03<01:03,  3.31it/s][A09/17/2024 05:39:24 - INFO - __main__ -   current idx QCTlsbvtDIQ.2 from finetune_area returns wrong image/video, use 98016 instead.

  5%|▌         | 12/221 [00:03<01:02,  3.34it/s][A
  6%|▌         | 13/221 [00:03<01:02,  3.32it/s][A
  6%|▋         | 14/221 [00:04<01:02,  3.30it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.33it/s][A
  7%|▋         | 16/221 [00:04<01:01,  3.34it/s][A
  8%|▊         | 17/221 [00:05<01:00,  3.36it/s][A
  8%|▊         | 18/221 [00:05<01:01,  3.33it/s][A
  9%|▊         | 19/221 [00:05<01:02,  3.25it/s][A
  9%|▉         | 20/221 [00:06<01:01,  3.28it/s][A
 10%|▉         | 21/221 [00:06<01:00,  3.32it/s][A[h264 @ 0x55a31044abc0] mmco: unref short failure
[h264 @ 0x55e238f71940] mmco: unref short failure
[h264 @ 0x55e238f71940] mmco: unref short failure

 10%|▉         | 22/221 [00:06<01:00,  3.29it/s][A
 10%|█         | 23/221 [00:07<01:03,  3.09it/s][A
 11%|█         | 24/221 [00:07<01:01,  3.18it/s][A[h264 @ 0x560749739840] mmco: unref short failure
[h264 @ 0x560749739840] mmco: unref short failure

 11%|█▏        | 25/221 [00:07<01:01,  3.19it/s][A[h264 @ 0x560759808b40] mmco: unref short failure
[h264 @ 0x560759808b40] mmco: unref short failure

 12%|█▏        | 26/221 [00:07<01:00,  3.25it/s][A
 12%|█▏        | 27/221 [00:08<00:58,  3.29it/s][A
 13%|█▎        | 28/221 [00:08<00:58,  3.28it/s][A
 13%|█▎        | 29/221 [00:08<00:59,  3.22it/s][A
 14%|█▎        | 30/221 [00:09<00:59,  3.24it/s][A
 14%|█▍        | 31/221 [00:09<00:58,  3.25it/s][A
 14%|█▍        | 32/221 [00:09<00:57,  3.27it/s][A
 15%|█▍        | 33/221 [00:10<00:56,  3.31it/s][A
 15%|█▌        | 34/221 [00:10<00:56,  3.33it/s][A
 16%|█▌        | 35/221 [00:10<00:55,  3.35it/s][A
 16%|█▋        | 36/221 [00:10<00:54,  3.37it/s][A
 17%|█▋        | 37/221 [00:11<00:54,  3.37it/s][A
 17%|█▋        | 38/221 [00:11<00:54,  3.37it/s][A[h264 @ 0x55a31507a800] mmco: unref short failure
[h264 @ 0x55a31507a800] mmco: unref short failure
[h264 @ 0x55a31507a800] mmco: unref short failure
[h264 @ 0x55a31507a800] mmco: unref short failure
[h264 @ 0x55a31507a800] mmco: unref short failure
[h264 @ 0x55a31507a800] mmco: unref short failure
[h264 @ 0x55a31507a800] mmco: unref short failure
[h264 @ 0x55a31507a800] mmco: unref short failure

 18%|█▊        | 39/221 [00:11<00:53,  3.38it/s][A
 18%|█▊        | 40/221 [00:12<00:53,  3.36it/s][A
 19%|█▊        | 41/221 [00:12<00:53,  3.34it/s][A
 19%|█▉        | 42/221 [00:12<00:53,  3.35it/s][A
 19%|█▉        | 43/221 [00:13<00:53,  3.31it/s][A
 20%|█▉        | 44/221 [00:13<00:53,  3.33it/s][A
 20%|██        | 45/221 [00:13<00:52,  3.32it/s][A
 21%|██        | 46/221 [00:13<00:52,  3.30it/s][A
 21%|██▏       | 47/221 [00:14<00:52,  3.29it/s][A
 22%|██▏       | 48/221 [00:14<00:52,  3.30it/s][A
 22%|██▏       | 49/221 [00:14<00:51,  3.33it/s][A
 23%|██▎       | 50/221 [00:15<00:51,  3.34it/s][A
 23%|██▎       | 51/221 [00:15<00:50,  3.35it/s][A
 24%|██▎       | 52/221 [00:15<00:50,  3.36it/s][A
 24%|██▍       | 53/221 [00:16<00:50,  3.31it/s][A
 24%|██▍       | 54/221 [00:16<00:50,  3.29it/s][A
 25%|██▍       | 55/221 [00:16<00:51,  3.24it/s][A
 25%|██▌       | 56/221 [00:16<00:50,  3.29it/s][A
 26%|██▌       | 57/221 [00:17<00:49,  3.32it/s][A
 26%|██▌       | 58/221 [00:17<00:48,  3.34it/s][A
 27%|██▋       | 59/221 [00:17<00:48,  3.36it/s][A
 27%|██▋       | 60/221 [00:18<00:48,  3.35it/s][A
 28%|██▊       | 61/221 [00:18<00:47,  3.36it/s][A
 28%|██▊       | 62/221 [00:18<00:47,  3.37it/s][A
 29%|██▊       | 63/221 [00:19<00:46,  3.38it/s][A
 29%|██▉       | 64/221 [00:19<00:46,  3.34it/s][A
 29%|██▉       | 65/221 [00:19<00:46,  3.36it/s][A
 30%|██▉       | 66/221 [00:19<00:45,  3.37it/s][A
 30%|███       | 67/221 [00:20<00:45,  3.36it/s][A
 31%|███       | 68/221 [00:20<00:45,  3.33it/s][A
 31%|███       | 69/221 [00:20<00:45,  3.31it/s][A
 32%|███▏      | 70/221 [00:21<00:46,  3.26it/s][A
 32%|███▏      | 71/221 [00:21<00:46,  3.24it/s][A
 33%|███▎      | 72/221 [00:21<00:45,  3.27it/s][A
 33%|███▎      | 73/221 [00:22<00:44,  3.30it/s][A
 33%|███▎      | 74/221 [00:22<00:45,  3.24it/s][A
 34%|███▍      | 75/221 [00:22<00:44,  3.29it/s][A
 34%|███▍      | 76/221 [00:22<00:43,  3.32it/s][A
 35%|███▍      | 77/221 [00:23<00:43,  3.34it/s][A
 35%|███▌      | 78/221 [00:23<00:42,  3.36it/s][A
 36%|███▌      | 79/221 [00:23<00:42,  3.37it/s][A
 36%|███▌      | 80/221 [00:24<00:42,  3.33it/s][A
 37%|███▋      | 81/221 [00:24<00:42,  3.32it/s][A
 37%|███▋      | 82/221 [00:24<00:41,  3.34it/s][A
 38%|███▊      | 83/221 [00:25<00:41,  3.33it/s][A
 38%|███▊      | 84/221 [00:25<00:40,  3.35it/s][A
 38%|███▊      | 85/221 [00:25<00:40,  3.36it/s][A
 39%|███▉      | 86/221 [00:25<00:40,  3.36it/s][A[h264 @ 0x55a330c58580] mmco: unref short failure

 39%|███▉      | 87/221 [00:26<00:39,  3.37it/s][A
 40%|███▉      | 88/221 [00:26<00:39,  3.38it/s][A
 40%|████      | 89/221 [00:26<00:39,  3.38it/s][A
 41%|████      | 90/221 [00:27<00:38,  3.39it/s][A
 41%|████      | 91/221 [00:27<00:38,  3.39it/s][A
 42%|████▏     | 92/221 [00:27<00:38,  3.39it/s][A
 42%|████▏     | 93/221 [00:28<00:37,  3.39it/s][A
 43%|████▎     | 94/221 [00:28<00:37,  3.39it/s][A
 43%|████▎     | 95/221 [00:28<00:37,  3.40it/s][A
 43%|████▎     | 96/221 [00:28<00:36,  3.39it/s][A
 44%|████▍     | 97/221 [00:29<00:36,  3.39it/s][A
 44%|████▍     | 98/221 [00:29<00:36,  3.40it/s][A
 45%|████▍     | 99/221 [00:29<00:35,  3.40it/s][A
 45%|████▌     | 100/221 [00:30<00:35,  3.40it/s][A
 46%|████▌     | 101/221 [00:30<00:35,  3.40it/s][A
 46%|████▌     | 102/221 [00:30<00:34,  3.41it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.41it/s][A
 47%|████▋     | 104/221 [00:31<00:34,  3.41it/s][A
 48%|████▊     | 105/221 [00:31<00:34,  3.41it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.40it/s][A
 48%|████▊     | 107/221 [00:32<00:33,  3.40it/s][A
 49%|████▉     | 108/221 [00:32<00:33,  3.41it/s][A
 49%|████▉     | 109/221 [00:32<00:32,  3.41it/s][A
 50%|████▉     | 110/221 [00:33<00:32,  3.41it/s][A
 50%|█████     | 111/221 [00:33<00:32,  3.41it/s][A
 51%|█████     | 112/221 [00:33<00:31,  3.42it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 114/221 [00:34<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:34<00:30,  3.42it/s][A
 52%|█████▏    | 116/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:35<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:35<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:35<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:36<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:37<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:37<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:38<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:39<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:39<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:40<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:40<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:41<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:41<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:42<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:42<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:43<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:44<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:44<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:45<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:45<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:45<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:46<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:46<00:19,  3.42it/s][A
 71%|███████   | 157/221 [00:46<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:47<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:47<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:48<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:48<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:49<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:49<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:49<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:50<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:50<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:51<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:51<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:52<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:52<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:53<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:54<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:54<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:55<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:55<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:56<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:57<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:57<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:58<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:59<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:59<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [01:00<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:01<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:02<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:04<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:05<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.42it/s][A100%|██████████| 221/221 [01:05<00:00,  3.38it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:30,  7.17it/s][A
  1%|          | 2/221 [00:00<00:40,  5.36it/s][A
  1%|▏         | 3/221 [00:00<00:58,  3.72it/s][A
  2%|▏         | 4/221 [00:00<00:51,  4.25it/s][A
  2%|▏         | 5/221 [00:01<00:49,  4.32it/s][A
  3%|▎         | 7/221 [00:01<00:48,  4.39it/s][A
  4%|▎         | 8/221 [00:01<00:53,  3.99it/s][A
  4%|▍         | 9/221 [00:02<00:52,  4.07it/s][A
  5%|▍         | 10/221 [00:02<00:43,  4.84it/s][A
  5%|▍         | 11/221 [00:02<00:46,  4.49it/s][A
  5%|▌         | 12/221 [00:02<00:46,  4.51it/s][A
  6%|▌         | 13/221 [00:03<01:35,  2.18it/s][A
  6%|▋         | 14/221 [00:03<01:18,  2.64it/s][A
  7%|▋         | 15/221 [00:04<01:18,  2.63it/s][A
  7%|▋         | 16/221 [00:04<01:27,  2.33it/s][A
  8%|▊         | 17/221 [00:05<01:25,  2.39it/s][A
  8%|▊         | 18/221 [00:05<01:14,  2.74it/s][A
  9%|▉         | 20/221 [00:05<00:57,  3.50it/s][A
 10%|▉         | 21/221 [00:06<00:53,  3.76it/s][A
 10%|▉         | 22/221 [00:06<00:48,  4.11it/s][A
 11%|█         | 24/221 [00:06<00:38,  5.13it/s][A
 11%|█▏        | 25/221 [00:06<00:50,  3.86it/s][A
 12%|█▏        | 26/221 [00:07<00:48,  4.05it/s][A
 12%|█▏        | 27/221 [00:07<00:54,  3.57it/s][A
 13%|█▎        | 28/221 [00:07<00:56,  3.40it/s][A
 13%|█▎        | 29/221 [00:08<00:55,  3.47it/s][A
 14%|█▎        | 30/221 [00:08<01:06,  2.89it/s][A
 14%|█▍        | 31/221 [00:09<01:06,  2.85it/s][A
 14%|█▍        | 32/221 [00:09<01:04,  2.92it/s][A
 15%|█▍        | 33/221 [00:09<01:06,  2.85it/s][A
 15%|█▌        | 34/221 [00:10<01:31,  2.05it/s][A
 16%|█▌        | 35/221 [00:10<01:16,  2.44it/s][A
 16%|█▋        | 36/221 [00:11<01:12,  2.56it/s][A
 17%|█▋        | 37/221 [00:11<01:01,  2.98it/s][A
 17%|█▋        | 38/221 [00:11<00:57,  3.16it/s][A
 18%|█▊        | 39/221 [00:11<00:47,  3.81it/s][A
 18%|█▊        | 40/221 [00:12<00:48,  3.75it/s][A
 19%|█▊        | 41/221 [00:12<00:53,  3.39it/s][A
 19%|█▉        | 42/221 [00:12<00:46,  3.88it/s][A
 19%|█▉        | 43/221 [00:12<00:44,  4.01it/s][A
 20%|█▉        | 44/221 [00:12<00:40,  4.32it/s][A
 20%|██        | 45/221 [00:13<00:48,  3.62it/s][A
 21%|██        | 46/221 [00:13<00:46,  3.79it/s][A
 22%|██▏       | 48/221 [00:13<00:32,  5.36it/s][A
 22%|██▏       | 49/221 [00:13<00:28,  5.96it/s][A
 23%|██▎       | 50/221 [00:14<00:35,  4.81it/s][A
 23%|██▎       | 51/221 [00:14<00:40,  4.21it/s][A
 24%|██▎       | 52/221 [00:14<00:38,  4.43it/s][A
 24%|██▍       | 53/221 [00:15<00:46,  3.62it/s][A
 24%|██▍       | 54/221 [00:15<00:41,  4.04it/s][A
 25%|██▍       | 55/221 [00:15<00:48,  3.40it/s][A
 25%|██▌       | 56/221 [00:15<00:47,  3.46it/s][A
 26%|██▌       | 57/221 [00:16<00:47,  3.47it/s][A
 26%|██▌       | 58/221 [00:16<00:50,  3.26it/s][A
 27%|██▋       | 59/221 [00:16<00:47,  3.40it/s][A
 27%|██▋       | 60/221 [00:17<00:42,  3.77it/s][A
 28%|██▊       | 61/221 [00:17<00:39,  4.05it/s][A
 28%|██▊       | 62/221 [00:17<00:42,  3.71it/s][A
 29%|██▉       | 64/221 [00:17<00:37,  4.21it/s][A
 29%|██▉       | 65/221 [00:18<00:36,  4.23it/s][A
 30%|██▉       | 66/221 [00:18<00:38,  4.04it/s][A
 30%|███       | 67/221 [00:18<00:45,  3.37it/s][A
 31%|███       | 68/221 [00:19<00:42,  3.62it/s][A
 31%|███       | 69/221 [00:19<00:53,  2.83it/s][A
 32%|███▏      | 70/221 [00:19<00:48,  3.11it/s][A
 32%|███▏      | 71/221 [00:20<00:51,  2.91it/s][A
 33%|███▎      | 72/221 [00:20<00:57,  2.60it/s][A
 33%|███▎      | 73/221 [00:21<00:54,  2.74it/s][A
 33%|███▎      | 74/221 [00:21<00:51,  2.84it/s][A
 34%|███▍      | 75/221 [00:21<00:48,  3.02it/s][A
 35%|███▍      | 77/221 [00:22<00:41,  3.48it/s][A
 35%|███▌      | 78/221 [00:22<00:42,  3.35it/s][A
 36%|███▌      | 79/221 [00:22<00:42,  3.31it/s][A
 36%|███▌      | 80/221 [00:23<00:40,  3.52it/s][A
 37%|███▋      | 81/221 [00:23<00:38,  3.68it/s][A
 37%|███▋      | 82/221 [00:23<00:39,  3.51it/s][A
 38%|███▊      | 83/221 [00:23<00:37,  3.71it/s][A
 38%|███▊      | 84/221 [00:24<00:47,  2.90it/s][A
 38%|███▊      | 85/221 [00:24<00:48,  2.79it/s][A
 39%|███▉      | 86/221 [00:25<00:50,  2.65it/s][A
 39%|███▉      | 87/221 [00:25<00:52,  2.55it/s][A
 40%|███▉      | 88/221 [00:25<00:47,  2.79it/s][A
 40%|████      | 89/221 [00:26<00:46,  2.82it/s][A
 41%|████      | 90/221 [00:26<00:46,  2.80it/s][A
 41%|████      | 91/221 [00:26<00:45,  2.87it/s][A
 42%|████▏     | 92/221 [00:27<00:44,  2.91it/s][A
 42%|████▏     | 93/221 [00:27<00:57,  2.24it/s][A
 43%|████▎     | 94/221 [00:28<00:48,  2.64it/s][A
 43%|████▎     | 95/221 [00:28<00:56,  2.22it/s][A
 43%|████▎     | 96/221 [00:29<00:52,  2.38it/s][A
 44%|████▍     | 97/221 [00:29<00:44,  2.80it/s][A
 44%|████▍     | 98/221 [00:29<00:40,  3.01it/s][A
 45%|████▍     | 99/221 [00:29<00:39,  3.05it/s][A
 45%|████▌     | 100/221 [00:30<00:32,  3.69it/s][A
 46%|████▌     | 101/221 [00:30<00:29,  4.11it/s][A
 46%|████▌     | 102/221 [00:30<00:30,  3.92it/s][A
 47%|████▋     | 103/221 [00:30<00:27,  4.22it/s][A
 47%|████▋     | 104/221 [00:30<00:26,  4.49it/s][A
 48%|████▊     | 105/221 [00:31<00:31,  3.69it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.39it/s][A
 48%|████▊     | 107/221 [00:32<00:36,  3.11it/s][A
 49%|████▉     | 108/221 [00:32<00:33,  3.42it/s][A
 49%|████▉     | 109/221 [00:32<00:30,  3.68it/s][A
 50%|████▉     | 110/221 [00:32<00:28,  3.88it/s][A
 50%|█████     | 111/221 [00:33<00:29,  3.67it/s][A
 51%|█████     | 112/221 [00:33<00:32,  3.33it/s][A
 51%|█████     | 113/221 [00:33<00:32,  3.35it/s][A
 52%|█████▏    | 115/221 [00:34<00:24,  4.38it/s][A
 52%|█████▏    | 116/221 [00:34<00:22,  4.65it/s][A
 53%|█████▎    | 117/221 [00:34<00:22,  4.55it/s][A
 53%|█████▎    | 118/221 [00:34<00:30,  3.35it/s][A
 54%|█████▍    | 119/221 [00:35<00:35,  2.84it/s][A
 54%|█████▍    | 120/221 [00:35<00:35,  2.85it/s][A
 55%|█████▍    | 121/221 [00:35<00:30,  3.32it/s][A
 55%|█████▌    | 122/221 [00:36<00:27,  3.57it/s][A
 56%|█████▌    | 123/221 [00:36<00:27,  3.52it/s][A
 56%|█████▌    | 124/221 [00:36<00:27,  3.56it/s][A
 57%|█████▋    | 125/221 [00:37<00:31,  3.06it/s][A
 57%|█████▋    | 126/221 [00:37<00:26,  3.57it/s][A
 57%|█████▋    | 127/221 [00:38<00:37,  2.53it/s][A
 58%|█████▊    | 128/221 [00:38<00:31,  2.92it/s][A
 58%|█████▊    | 129/221 [00:38<00:29,  3.14it/s][A
 59%|█████▉    | 130/221 [00:38<00:30,  2.98it/s][A
 59%|█████▉    | 131/221 [00:39<00:25,  3.58it/s][A
 60%|█████▉    | 132/221 [00:39<00:23,  3.73it/s][A
 60%|██████    | 133/221 [00:39<00:31,  2.79it/s][A
 61%|██████    | 134/221 [00:40<00:33,  2.57it/s][A
 61%|██████    | 135/221 [00:40<00:29,  2.91it/s][A
 62%|██████▏   | 136/221 [00:40<00:28,  3.01it/s][A
 62%|██████▏   | 137/221 [00:41<00:23,  3.52it/s][A
 62%|██████▏   | 138/221 [00:41<00:21,  3.78it/s][A
 63%|██████▎   | 139/221 [00:41<00:24,  3.29it/s][A
 63%|██████▎   | 140/221 [00:41<00:22,  3.57it/s][A
 64%|██████▍   | 141/221 [00:42<00:24,  3.26it/s][A
 64%|██████▍   | 142/221 [00:42<00:21,  3.66it/s][A
 65%|██████▍   | 143/221 [00:42<00:20,  3.74it/s][A
 65%|██████▌   | 144/221 [00:42<00:18,  4.07it/s][A
 66%|██████▌   | 145/221 [00:43<00:22,  3.37it/s][A
 66%|██████▌   | 146/221 [00:43<00:21,  3.49it/s][A
 67%|██████▋   | 147/221 [00:43<00:20,  3.68it/s][A
 67%|██████▋   | 148/221 [00:44<00:20,  3.60it/s][A
 67%|██████▋   | 149/221 [00:44<00:18,  3.79it/s][A
 68%|██████▊   | 150/221 [00:44<00:18,  3.91it/s][A
 68%|██████▊   | 151/221 [00:44<00:22,  3.15it/s][A
 69%|██████▉   | 152/221 [00:45<00:34,  2.00it/s][A
 69%|██████▉   | 153/221 [00:46<00:29,  2.31it/s][A
 70%|██████▉   | 154/221 [00:46<00:25,  2.64it/s][A
 70%|███████   | 155/221 [00:46<00:24,  2.66it/s][A
 71%|███████   | 156/221 [00:46<00:19,  3.25it/s][A
 71%|███████   | 157/221 [00:47<00:19,  3.23it/s][A
 71%|███████▏  | 158/221 [00:47<00:21,  2.97it/s][A
 72%|███████▏  | 159/221 [00:47<00:18,  3.40it/s][A
 72%|███████▏  | 160/221 [00:48<00:15,  3.83it/s][A
 73%|███████▎  | 161/221 [00:48<00:14,  4.20it/s][A
 73%|███████▎  | 162/221 [00:48<00:11,  5.04it/s][A
 74%|███████▍  | 163/221 [00:48<00:12,  4.64it/s][A
 74%|███████▍  | 164/221 [00:48<00:11,  4.85it/s][A
 75%|███████▍  | 165/221 [00:49<00:12,  4.57it/s][A
 75%|███████▌  | 166/221 [00:49<00:13,  4.00it/s][A
 76%|███████▌  | 167/221 [00:49<00:11,  4.75it/s][A
 76%|███████▌  | 168/221 [00:49<00:11,  4.55it/s][A
 77%|███████▋  | 170/221 [00:50<00:16,  3.05it/s][A
 77%|███████▋  | 171/221 [00:50<00:16,  2.97it/s][A
 78%|███████▊  | 172/221 [00:51<00:16,  2.94it/s][A
 78%|███████▊  | 173/221 [00:51<00:15,  3.13it/s][A
 79%|███████▊  | 174/221 [00:51<00:15,  3.07it/s][A
 79%|███████▉  | 175/221 [00:52<00:14,  3.08it/s][A
 80%|███████▉  | 176/221 [00:52<00:13,  3.35it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.51it/s][A
 81%|████████  | 178/221 [00:53<00:16,  2.58it/s][A
 81%|████████  | 179/221 [00:53<00:14,  2.89it/s][A
 81%|████████▏ | 180/221 [00:53<00:13,  3.07it/s][A
 82%|████████▏ | 181/221 [00:54<00:15,  2.59it/s][A
 82%|████████▏ | 182/221 [00:54<00:13,  2.96it/s][A
 83%|████████▎ | 183/221 [00:55<00:12,  2.94it/s][A
 83%|████████▎ | 184/221 [00:55<00:12,  2.85it/s][A
 84%|████████▍ | 186/221 [00:56<00:11,  2.98it/s][A
 85%|████████▍ | 187/221 [00:56<00:10,  3.18it/s][A
 85%|████████▌ | 188/221 [00:56<00:10,  3.18it/s][A
 86%|████████▌ | 189/221 [00:56<00:09,  3.47it/s][A
 86%|████████▌ | 190/221 [00:57<00:09,  3.22it/s][A
 86%|████████▋ | 191/221 [00:57<00:07,  3.82it/s][A
 87%|████████▋ | 192/221 [00:57<00:07,  3.99it/s][A
 87%|████████▋ | 193/221 [00:57<00:06,  4.12it/s][A
 88%|████████▊ | 194/221 [00:58<00:06,  4.13it/s][A
 88%|████████▊ | 195/221 [00:58<00:05,  4.44it/s][A
 89%|████████▊ | 196/221 [00:58<00:08,  3.08it/s][A
 89%|████████▉ | 197/221 [00:59<00:08,  2.88it/s][A
 90%|████████▉ | 198/221 [00:59<00:08,  2.82it/s][A
 90%|█████████ | 199/221 [00:59<00:06,  3.44it/s][A
 90%|█████████ | 200/221 [00:59<00:05,  3.63it/s][A
 91%|█████████ | 201/221 [01:00<00:05,  3.96it/s][A
 91%|█████████▏| 202/221 [01:00<00:05,  3.36it/s][A
 92%|█████████▏| 203/221 [01:00<00:04,  3.71it/s][A
 92%|█████████▏| 204/221 [01:01<00:05,  3.18it/s][A
 93%|█████████▎| 205/221 [01:01<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:01<00:05,  2.84it/s][A
 94%|█████████▎| 207/221 [01:02<00:05,  2.62it/s][A
 94%|█████████▍| 208/221 [01:02<00:03,  3.32it/s][A
 95%|█████████▍| 209/221 [01:02<00:03,  3.67it/s][A
 95%|█████████▌| 210/221 [01:03<00:03,  3.04it/s][A
 95%|█████████▌| 211/221 [01:03<00:02,  3.34it/s][A
 96%|█████████▌| 212/221 [01:03<00:02,  3.10it/s][A
 96%|█████████▋| 213/221 [01:03<00:02,  3.25it/s][A
 97%|█████████▋| 214/221 [01:04<00:02,  3.22it/s][A
 97%|█████████▋| 215/221 [01:04<00:01,  3.17it/s][A
 98%|█████████▊| 216/221 [01:04<00:01,  3.14it/s][A
 98%|█████████▊| 217/221 [01:05<00:01,  3.22it/s][A
 99%|█████████▊| 218/221 [01:05<00:00,  3.30it/s][A
 99%|█████████▉| 219/221 [01:05<00:00,  3.15it/s][A
100%|█████████▉| 220/221 [01:06<00:00,  3.60it/s][A
100%|██████████| 221/221 [01:06<00:00,  3.55it/s][A100%|██████████| 221/221 [01:06<00:00,  3.33it/s]
09/17/2024 05:41:34 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 999--===========

09/17/2024 05:41:34 - INFO - __main__ -   {'area_r1': 39.7, 'area_recall': '39.7/63.8/73.2', 'area_ravg': 58.9}
09/17/2024 05:41:34 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 999--===========

09/17/2024 05:41:34 - INFO - __main__ -   {'forward_r1': 37.3, 'forward_recall': '37.3/65.5/76.2', 'forward_ravg': 59.7}
09/17/2024 05:41:34 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 999--===========

09/17/2024 05:41:34 - INFO - __main__ -   {'area_video_r1': 38.8, 'area_video_recall': '38.8/66.6/77.5', 'area_video_ravg': 61.0}
09/17/2024 05:41:34 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 299=======

09/17/2024 05:41:34 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 05:41:34 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 999--===========

09/17/2024 05:41:34 - INFO - __main__ -   {'area_video_r1': 52.6, 'area_video_recall': '52.6/75.2/82.1', 'area_video_ravg': 70.0, 'area_video_back_r1': 47.7, 'area_video_back_recall': '47.7/74.5/82.0', 'area_video_back_ravg': 68.1}
09/17/2024 05:41:34 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 549=======

09/17/2024 05:41:34 - INFO - __main__ -   {'area_video_r1': 54.1, 'area_video_recall': '54.1/75.5/82.4', 'area_video_ravg': 70.6, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.5/82.1', 'area_video_back_ravg': 68.7}
09/17/2024 05:41:34 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 999--===========

09/17/2024 05:41:34 - INFO - __main__ -   {'video_r1': 37.4, 'video_recall': '37.4/64.4/74.3', 'video_ravg': 58.7}
09/17/2024 05:41:34 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 949=======

09/17/2024 05:41:34 - INFO - __main__ -   {'video_r1': 38.7, 'video_recall': '38.7/64.3/74.1', 'video_ravg': 59.0}
09/17/2024 05:41:34 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 999--===========

09/17/2024 05:41:34 - INFO - __main__ -   {'video_r1': 52.7, 'video_recall': '52.7/75.3/82.9', 'video_ravg': 70.3}
09/17/2024 05:41:34 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 549=======

09/17/2024 05:41:34 - INFO - __main__ -   {'video_r1': 54.5, 'video_recall': '54.5/76.1/83.4', 'video_ravg': 71.3}
09/17/2024 05:41:57 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.008479982614517212, 'loss_ret%tv%ta--finetune_area/loss_area': 1.118841528892517, 'loss_ret%tv%ta--finetune_area/total_loss': 1.127321481704712}
[h264 @ 0x55b5c517da00] mmco: unref short failure
[h264 @ 0x55b5c517da00] mmco: unref short failure
 34%|███▍      | 1000/2910 [6:20:13<70:16:13, 132.45s/it] 34%|███▍      | 1001/2910 [6:20:17<49:46:14, 93.86s/it] [h264 @ 0x55b5ae4289c0] mmco: unref short failure
[h264 @ 0x55b5ae4289c0] mmco: unref short failure
 34%|███▍      | 1002/2910 [6:20:21<35:25:41, 66.85s/it][h264 @ 0x55a323b9ef80] mmco: unref short failure
[h264 @ 0x55a323b9ef80] mmco: unref short failure
09/17/2024 05:42:11 - INFO - __main__ -   current idx OTXYBNGzWpQ.110 from finetune_area returns wrong image/video, use 70925 instead.
 34%|███▍      | 1003/2910 [6:20:26<25:29:25, 48.12s/it][h264 @ 0x55b5cbb86f00] mmco: unref short failure
[h264 @ 0x55b5cbb86f00] mmco: unref short failure
[h264 @ 0x560745011c00] mmco: unref short failure
[h264 @ 0x560745011c00] mmco: unref short failure
09/17/2024 05:42:16 - INFO - __main__ -   current idx 3UV1kgubC10.7 from finetune_area returns wrong image/video, use 58206 instead.
 35%|███▍      | 1004/2910 [6:20:30<18:33:32, 35.05s/it] 35%|███▍      | 1005/2910 [6:20:35<13:45:52, 26.01s/it][h264 @ 0x55b5b4c73540] mmco: unref short failure
[h264 @ 0x55b5b4c73540] mmco: unref short failure
[h264 @ 0x55b5b4c73540] mmco: unref short failure
 35%|███▍      | 1006/2910 [6:20:41<10:30:25, 19.87s/it][h264 @ 0x55a31b709cc0] mmco: unref short failure
 35%|███▍      | 1007/2910 [6:20:46<8:13:44, 15.57s/it]  35%|███▍      | 1008/2910 [6:20:51<6:35:57, 12.49s/it] 35%|███▍      | 1009/2910 [6:20:57<5:29:39, 10.40s/it] 35%|███▍      | 1010/2910 [6:21:02<4:40:07,  8.85s/it][h264 @ 0x55e252318b00] mmco: unref short failure
[h264 @ 0x55b5c367af00] mmco: unref short failure
[h264 @ 0x55b5c367af00] mmco: unref short failure
 35%|███▍      | 1011/2910 [6:21:08<4:13:45,  8.02s/it][h264 @ 0x55b5b39019c0] mmco: unref short failure
[h264 @ 0x55b5b39019c0] mmco: unref short failure
[h264 @ 0x55b5b39019c0] mmco: unref short failure
[h264 @ 0x55b5b39019c0] mmco: unref short failure
 35%|███▍      | 1012/2910 [6:21:13<3:46:02,  7.15s/it] 35%|███▍      | 1013/2910 [6:21:18<3:24:59,  6.48s/it][h264 @ 0x55e24f3c17c0] mmco: unref short failure
[h264 @ 0x55e24f3c17c0] mmco: unref short failure
 35%|███▍      | 1014/2910 [6:21:23<3:09:36,  6.00s/it] 35%|███▍      | 1015/2910 [6:21:28<3:00:52,  5.73s/it][h264 @ 0x55a31891d440] mmco: unref short failure
[h264 @ 0x560754858200] mmco: unref short failure
[h264 @ 0x55e254be7bc0] mmco: unref short failure
[h264 @ 0x55a31c16c4c0] mmco: unref short failure
[h264 @ 0x55a31c16c4c0] mmco: unref short failure
[h264 @ 0x55e243233bc0] mmco: unref short failure
[h264 @ 0x55e243233bc0] mmco: unref short failure
[h264 @ 0x55e243233bc0] mmco: unref short failure
[h264 @ 0x55e243233bc0] mmco: unref short failure
[h264 @ 0x55b5af9c7d80] mmco: unref short failure
[h264 @ 0x55b5af9c7d80] mmco: unref short failure
[h264 @ 0x55e24eb09e00] mmco: unref short failure
[h264 @ 0x55e24eb09e00] mmco: unref short failure
[h264 @ 0x55e24eb09e00] mmco: unref short failure
[h264 @ 0x55e24eb09e00] mmco: unref short failure
[h264 @ 0x55e24eb09e00] mmco: unref short failure
[h264 @ 0x55e24eb09e00] mmco: unref short failure
[h264 @ 0x55b5ba5b9f40] mmco: unref short failure
[h264 @ 0x55b5ba5b9f40] mmco: unref short failure
 35%|███▍      | 1016/2910 [6:22:14<9:22:28, 17.82s/it][h264 @ 0x55a318aa01c0] mmco: unref short failure
[h264 @ 0x55a318aa01c0] mmco: unref short failure
[h264 @ 0x55e249201f40] mmco: unref short failure
[h264 @ 0x55e249201f40] mmco: unref short failure
[h264 @ 0x55e249201f40] mmco: unref short failure
[h264 @ 0x55e249201f40] mmco: unref short failure
 35%|███▍      | 1017/2910 [6:22:29<8:56:53, 17.02s/it][h264 @ 0x55a3134fc900] mmco: unref short failure
[h264 @ 0x55a3193a6ec0] mmco: unref short failure
[h264 @ 0x55a3193a6ec0] mmco: unref short failure
[h264 @ 0x55a3193a6ec0] mmco: unref short failure
[h264 @ 0x55a3193a6ec0] mmco: unref short failure
[h264 @ 0x55b5b10e7c80] mmco: unref short failure
[h264 @ 0x55b5b10e7c80] mmco: unref short failure
 35%|███▍      | 1018/2910 [6:22:44<8:33:07, 16.27s/it] 35%|███▌      | 1019/2910 [6:22:49<6:50:27, 13.02s/it]09/17/2024 05:44:36 - INFO - __main__ -   current idx PhpkFkc8SS8.32 from finetune_area returns wrong image/video, use 2124 instead.
[h264 @ 0x560748b6e0c0] mmco: unref short failure
[h264 @ 0x55a32f188080] mmco: unref short failure
[h264 @ 0x55a32f188080] mmco: unref short failure
[h264 @ 0x55b5c54b69c0] mmco: unref short failure
[h264 @ 0x55b5c54b69c0] mmco: unref short failure
 35%|███▌      | 1020/2910 [6:22:59<6:17:54, 12.00s/it][h264 @ 0x56074a15d600] mmco: unref short failure
[h264 @ 0x55e24ae25280] mmco: unref short failure
 35%|███▌      | 1021/2910 [6:23:11<6:18:31, 12.02s/it] 35%|███▌      | 1022/2910 [6:23:16<5:11:33,  9.90s/it] 35%|███▌      | 1023/2910 [6:23:21<4:25:21,  8.44s/it][h264 @ 0x55b5b2a73f00] mmco: unref short failure
[h264 @ 0x55b5b2a73f00] mmco: unref short failure
[h264 @ 0x55b5b2a73f00] mmco: unref short failure
[h264 @ 0x55b5b2a73f00] mmco: unref short failure
[h264 @ 0x55a31891d440] mmco: unref short failure
[h264 @ 0x55a31891d440] mmco: unref short failure
[h264 @ 0x55e23be53800] mmco: unref short failure
[h264 @ 0x55e24fd3ce40] mmco: unref short failure
[h264 @ 0x55e24ae25280] mmco: unref short failure
[h264 @ 0x55e24ae25280] mmco: unref short failure
[h264 @ 0x55b5b883d600] mmco: unref short failure
[h264 @ 0x55b5b883d600] mmco: unref short failure
[h264 @ 0x55b5aeaa7100] mmco: unref short failure
[h264 @ 0x55b5aeaa7100] mmco: unref short failure
[h264 @ 0x55b5aeaa7100] mmco: unref short failure
[h264 @ 0x55b5aeaa7100] mmco: unref short failure
[h264 @ 0x5607434831c0] mmco: unref short failure
[h264 @ 0x5607434831c0] mmco: unref short failure
[h264 @ 0x55a310913bc0] mmco: unref short failure
[h264 @ 0x55b5b883d600] mmco: unref short failure
[h264 @ 0x55b5aaaca8c0] mmco: unref short failure
[h264 @ 0x55b5aaaca8c0] mmco: unref short failure
[h264 @ 0x55b5b83f7740] mmco: unref short failure
[h264 @ 0x55b5aeaa7100] mmco: unref short failure
[h264 @ 0x55b5aeaa7100] mmco: unref short failure
[h264 @ 0x55a313488940] mmco: unref short failure
[h264 @ 0x55a313488940] mmco: unref short failure
not have audios 8-qwaveiHMM.3
[h264 @ 0x55a311cbbd00] mmco: unref short failure
[h264 @ 0x55a311cbbd00] mmco: unref short failure
[h264 @ 0x55e2449ebd00] mmco: unref short failure
[h264 @ 0x55e2449ebd00] mmco: unref short failure
[h264 @ 0x55e23700e000] mmco: unref short failure
[h264 @ 0x55e23700e000] mmco: unref short failure
[h264 @ 0x560741e2b200] mmco: unref short failure
[h264 @ 0x55b5c5849a00] mmco: unref short failure
[h264 @ 0x56075184e980] mmco: unref short failure
[h264 @ 0x55e2494e9f40] mmco: unref short failure
 35%|███▌      | 1024/2910 [6:24:53<17:36:18, 33.60s/it][h264 @ 0x55e2494e9f40] mmco: unref short failure
[h264 @ 0x55e2494e9f40] mmco: unref short failure
 35%|███▌      | 1025/2910 [6:25:01<13:29:50, 25.78s/it][h264 @ 0x56075420f900] mmco: unref short failure
[h264 @ 0x55b5b6509b80] mmco: unref short failure
[h264 @ 0x55a3119202c0] mmco: unref short failure
 35%|███▌      | 1026/2910 [6:25:20<12:22:59, 23.66s/it] 35%|███▌      | 1027/2910 [6:25:24<9:25:11, 18.01s/it] [h264 @ 0x56074482fb80] mmco: unref short failure
 35%|███▌      | 1028/2910 [6:25:30<7:24:15, 14.16s/it] 35%|███▌      | 1029/2910 [6:25:35<5:57:14, 11.40s/it][h264 @ 0x55b5aa5bedc0] mmco: unref short failure
[h264 @ 0x55b5aa5bedc0] mmco: unref short failure
[h264 @ 0x55b5aa5bedc0] mmco: unref short failure
[h264 @ 0x55b5aa5bedc0] mmco: unref short failure
[h264 @ 0x560756977f80] mmco: unref short failure
[h264 @ 0x560756977f80] mmco: unref short failure
 35%|███▌      | 1030/2910 [6:25:50<6:32:38, 12.53s/it][h264 @ 0x5607526daac0] mmco: unref short failure
 35%|███▌      | 1031/2910 [6:25:55<5:27:26, 10.46s/it][h264 @ 0x55b5bdbde500] mmco: unref short failure
[h264 @ 0x55b5bdbde500] mmco: unref short failure
[h264 @ 0x55b5c91b9200] mmco: unref short failure
[h264 @ 0x55e23c582c80] mmco: unref short failure
[h264 @ 0x55e23c582c80] mmco: unref short failure
[h264 @ 0x55e23c582c80] mmco: unref short failure
[h264 @ 0x55e23c582c80] mmco: unref short failure
[h264 @ 0x55a3324cce40] mmco: unref short failure
[h264 @ 0x55a32e18e180] mmco: unref short failure
[h264 @ 0x55e259db97c0] mmco: unref short failure
[h264 @ 0x55e259db97c0] mmco: unref short failure
[h264 @ 0x55a315747240] mmco: unref short failure
[h264 @ 0x55a315747240] mmco: unref short failure
[h264 @ 0x55b5b9f9ab80] mmco: unref short failure
[h264 @ 0x55b5b9f9ab80] mmco: unref short failure
[h264 @ 0x55b5ca659180] mmco: unref short failure
[h264 @ 0x55a31891d440] mmco: unref short failure
[h264 @ 0x55a311e2b7c0] mmco: unref short failure
[h264 @ 0x55a311e2b7c0] mmco: unref short failure
[h264 @ 0x55b5be7319c0] mmco: unref short failure
[h264 @ 0x5607434831c0] mmco: unref short failure
[h264 @ 0x5607434831c0] mmco: unref short failure
[h264 @ 0x55a3287a4140] mmco: unref short failure
[h264 @ 0x55a3287a4140] mmco: unref short failure
[h264 @ 0x55a325033b00] mmco: unref short failure
[h264 @ 0x55a325033b00] mmco: unref short failure
[h264 @ 0x55b5ac23c3c0] mmco: unref short failure
[h264 @ 0x55b5ac23c3c0] mmco: unref short failure
[h264 @ 0x55b5ac23c3c0] mmco: unref short failure
[h264 @ 0x55b5ac23c3c0] mmco: unref short failure
[h264 @ 0x55a311e2b7c0] mmco: unref short failure
[h264 @ 0x55a311e2b7c0] mmco: unref short failure
[h264 @ 0x55a311e2b7c0] mmco: unref short failure
[h264 @ 0x55a311e2b7c0] mmco: unref short failure
[h264 @ 0x55a3119202c0] mmco: unref short failure
[h264 @ 0x55a3119202c0] mmco: unref short failure
[h264 @ 0x55b5bd946d80] mmco: unref short failure
[h264 @ 0x55b5bd946d80] mmco: unref short failure
[h264 @ 0x55b5bd946d80] mmco: unref short failure
[h264 @ 0x55b5bd946d80] mmco: unref short failure
[h264 @ 0x55e247b4b080] mmco: unref short failure
[h264 @ 0x55e247b4b080] mmco: unref short failure
[h264 @ 0x55b5b1a10980] mmco: unref short failure
[h264 @ 0x55b5b1a10980] mmco: unref short failure
[h264 @ 0x55b5b1a10980] mmco: unref short failure
[h264 @ 0x55b5b1a10980] mmco: unref short failure
 35%|███▌      | 1032/2910 [6:27:19<16:55:44, 32.45s/it][h264 @ 0x55a325033b00] mmco: unref short failure
[h264 @ 0x55a325033b00] mmco: unref short failure
[h264 @ 0x55a311e2b7c0] mmco: unref short failure
[h264 @ 0x55a311e2b7c0] mmco: unref short failure
[h264 @ 0x55a311e2b7c0] mmco: unref short failure
 35%|███▌      | 1033/2910 [6:27:31<13:37:34, 26.13s/it][h264 @ 0x55a31978b300] mmco: unref short failure
[h264 @ 0x55a31978b300] mmco: unref short failure
[h264 @ 0x55a31978b300] mmco: unref short failure
[h264 @ 0x55a31978b300] mmco: unref short failure
[h264 @ 0x55a31978b300] mmco: unref short failure
 36%|███▌      | 1034/2910 [6:27:39<10:51:15, 20.83s/it][h264 @ 0x55e258f4fa00] mmco: unref short failure
 36%|███▌      | 1035/2910 [6:27:51<9:23:49, 18.04s/it] [h264 @ 0x55b5c0aa1e00] mmco: unref short failure
[h264 @ 0x55b5c0aa1e00] mmco: unref short failure
[h264 @ 0x55e24236d3c0] mmco: unref short failure
[h264 @ 0x55e24236d3c0] mmco: unref short failure
 36%|███▌      | 1036/2910 [6:28:01<8:13:06, 15.79s/it][h264 @ 0x55a30f9a4100] mmco: unref short failure
[h264 @ 0x55a30f9a4100] mmco: unref short failure
 36%|███▌      | 1037/2910 [6:28:07<6:38:09, 12.75s/it][h264 @ 0x55e2472d0780] mmco: unref short failure
[h264 @ 0x56075fa264c0] mmco: unref short failure
[h264 @ 0x56075fa264c0] mmco: unref short failure
 36%|███▌      | 1038/2910 [6:28:13<5:39:38, 10.89s/it][h264 @ 0x55e247925200] mmco: unref short failure
[h264 @ 0x55e247925200] mmco: unref short failure
 36%|███▌      | 1039/2910 [6:28:19<4:47:26,  9.22s/it][h264 @ 0x55e2544c7d80] mmco: unref short failure
[h264 @ 0x55e2544c7d80] mmco: unref short failure
[h264 @ 0x55b5b9f9ab80] mmco: unref short failure
[h264 @ 0x55b5b9f9ab80] mmco: unref short failure
[h264 @ 0x55e247925200] mmco: unref short failure
[h264 @ 0x55b5bf902e80] mmco: unref short failure
[h264 @ 0x55b5bf902e80] mmco: unref short failure
[h264 @ 0x55a310913bc0] mmco: unref short failure
[h264 @ 0x55a310913bc0] mmco: unref short failure
09/17/2024 05:50:24 - INFO - __main__ -   current idx XY_lzonfE3I.29 from finetune_area returns wrong image/video, use 65242 instead.
[h264 @ 0x56074d99fa80] mmco: unref short failure
[h264 @ 0x55e256752040] mmco: unref short failure
[h264 @ 0x55e2376feac0] mmco: unref short failure
[h264 @ 0x55e2376feac0] mmco: unref short failure
09/17/2024 05:50:34 - INFO - __main__ -   current idx -Gh2S5bmJFk.26 from finetune_area returns wrong image/video, use 66694 instead.
[h264 @ 0x560758693380] mmco: unref short failure
[h264 @ 0x55b5c714d040] mmco: unref short failure
[h264 @ 0x55b5c714d040] mmco: unref short failure
[h264 @ 0x55e23c5b0600] mmco: unref short failure
[h264 @ 0x55e24ae25280] mmco: unref short failure
[h264 @ 0x55e24ae25280] mmco: unref short failure
[h264 @ 0x55e24ae25280] mmco: unref short failure
[h264 @ 0x55e24ae25280] mmco: unref short failure
[h264 @ 0x55a321f3d100] mmco: unref short failure
[h264 @ 0x55a321f3d100] mmco: unref short failure
[h264 @ 0x55b5b83f7740] mmco: unref short failure
[h264 @ 0x55b5b83f7740] mmco: unref short failure
[h264 @ 0x55e23825cec0] mmco: unref short failure
[h264 @ 0x55e24a63d740] mmco: unref short failure
[h264 @ 0x55e24a63d740] mmco: unref short failure
[h264 @ 0x56075bb10880] mmco: unref short failure
[h264 @ 0x56075bb10880] mmco: unref short failure
[h264 @ 0x56075bb10880] mmco: unref short failure
[h264 @ 0x56075bb10880] mmco: unref short failure
[h264 @ 0x55a31df3b100] mmco: unref short failure
[h264 @ 0x55a31df3b100] mmco: unref short failure
 36%|███▌      | 1040/2910 [6:29:53<18:05:07, 34.82s/it][h264 @ 0x55e250ae5b00] mmco: unref short failure
 36%|███▌      | 1041/2910 [6:29:59<13:35:11, 26.17s/it][h264 @ 0x56074c017b40] mmco: unref short failure
[h264 @ 0x56074c017b40] mmco: unref short failure
[h264 @ 0x55a30ebe2480] mmco: unref short failure
 36%|███▌      | 1042/2910 [6:30:05<10:26:59, 20.14s/it][h264 @ 0x55e247925200] mmco: unref short failure
[h264 @ 0x56075fa264c0] mmco: unref short failure
[h264 @ 0x56075fa264c0] mmco: unref short failure
[h264 @ 0x55e2376feac0] mmco: unref short failure
[h264 @ 0x55b5aeaa7100] mmco: unref short failure
 36%|███▌      | 1043/2910 [6:30:25<10:23:16, 20.03s/it][h264 @ 0x55e23995c040] mmco: unref short failure
[h264 @ 0x55e23995c040] mmco: unref short failure
[h264 @ 0x55a327951c40] mmco: unref short failure
[h264 @ 0x55a327951c40] mmco: unref short failure
[h264 @ 0x55a3134fc900] mmco: unref short failure
[h264 @ 0x55a3134fc900] mmco: unref short failure
 36%|███▌      | 1044/2910 [6:30:39<9:27:06, 18.23s/it] [h264 @ 0x55b5c79f8200] mmco: unref short failure
[h264 @ 0x55b5c79f8200] mmco: unref short failure
[h264 @ 0x55b5c79f8200] mmco: unref short failure
[h264 @ 0x55b5c79f8200] mmco: unref short failure
 36%|███▌      | 1045/2910 [6:30:45<7:28:05, 14.42s/it] 36%|███▌      | 1046/2910 [6:30:50<6:07:43, 11.84s/it][h264 @ 0x56074905dec0] mmco: unref short failure
[h264 @ 0x56074905dec0] mmco: unref short failure
[h264 @ 0x55b5b10e7c80] mmco: unref short failure
[h264 @ 0x55e249667d00] mmco: unref short failure
[h264 @ 0x55e249667d00] mmco: unref short failure
[h264 @ 0x55e258f4f580] mmco: unref short failure
[h264 @ 0x55e258f4f580] mmco: unref short failure
 36%|███▌      | 1047/2910 [6:30:56<5:07:58,  9.92s/it][h264 @ 0x55e24199c300] mmco: unref short failure
[h264 @ 0x55e24199c300] mmco: unref short failure
[h264 @ 0x55a31e9a8080] mmco: unref short failure
[h264 @ 0x560749654400] mmco: unref short failure
[h264 @ 0x560749654400] mmco: unref short failure
[h264 @ 0x55b5b10e7c80] mmco: unref short failure
[h264 @ 0x55b5b10e7c80] mmco: unref short failure
[h264 @ 0x560748cade40] mmco: unref short failure
[h264 @ 0x560748cade40] mmco: unref short failure
[h264 @ 0x55b5c5292c40] mmco: unref short failure
[h264 @ 0x55e2571cbb40] mmco: unref short failure
[h264 @ 0x55e23995c040] mmco: unref short failure
[h264 @ 0x55e23995c040] mmco: unref short failure
[h264 @ 0x55e23ef9ff80] mmco: unref short failure
[h264 @ 0x55a319090440] mmco: unref short failure
[h264 @ 0x55a327ea13c0] mmco: unref short failure
[h264 @ 0x55a327ea13c0] mmco: unref short failure
[h264 @ 0x55a31f0f1100] mmco: unref short failure
[h264 @ 0x55a31f0f1100] mmco: unref short failure
[h264 @ 0x55b5b630f3c0] mmco: unref short failure
[h264 @ 0x55b5b630f3c0] mmco: unref short failure
09/17/2024 05:53:48 - INFO - __main__ -   current idx ZFfJ2HTRUeU.13 from finetune_area returns wrong image/video, use 141527 instead.
[h264 @ 0x55a32443f280] mmco: unref short failure
[h264 @ 0x5607526daac0] mmco: unref short failure
[h264 @ 0x5607526daac0] mmco: unref short failure
[h264 @ 0x5607526daac0] mmco: unref short failure
[h264 @ 0x5607526daac0] mmco: unref short failure
[h264 @ 0x55a325033b00] mmco: unref short failure
[h264 @ 0x55b5b5d2cf40] mmco: unref short failure
[h264 @ 0x55b5b5d2cf40] mmco: unref short failure
[h264 @ 0x55b5b5d2cf40] mmco: unref short failure
[h264 @ 0x55b5b5d2cf40] mmco: unref short failure
[h264 @ 0x55e247fb9d40] mmco: unref short failure
09/17/2024 05:54:11 - INFO - __main__ -   current idx 6S63HrRqSXw.2 from finetune_area returns wrong image/video, use 95087 instead.
[h264 @ 0x55a3111e7b40] mmco: unref short failure
[h264 @ 0x55a3111e7b40] mmco: unref short failure
[h264 @ 0x55a3111e7b40] mmco: unref short failure
[h264 @ 0x56074ae5e640] mmco: unref short failure
[h264 @ 0x56074ae5e640] mmco: unref short failure
 36%|███▌      | 1048/2910 [6:32:32<18:30:40, 35.79s/it] 36%|███▌      | 1049/2910 [6:32:37<13:47:08, 26.67s/it]09/17/2024 05:54:23 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 05:54:23 - INFO - __main__ -   start running ret%tva validation...
[h264 @ 0x55e25d546dc0] mmco: unref short failure
[h264 @ 0x55e25d546dc0] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55b5c4e47540] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e2544c7d80] mmco: unref short failure
[h264 @ 0x55e2544c7d80] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x5607526daac0] mmco: unref short failure
[h264 @ 0x5607526daac0] mmco: unref short failure
[h264 @ 0x55e2472d0780] mmco: unref short failure
[h264 @ 0x55e2472d0780] mmco: unref short failure
[h264 @ 0x55e2472d0780] mmco: unref short failure
[h264 @ 0x55e2472d0780] mmco: unref short failure
[h264 @ 0x55a328852180] mmco: unref short failure
[h264 @ 0x55a328852180] mmco: unref short failure
[h264 @ 0x55a31335af80] mmco: unref short failure
[h264 @ 0x55e23ae4dc80] mmco: unref short failure
[h264 @ 0x55e23ae4dc80] mmco: unref short failure
[h264 @ 0x55e24c328b00] mmco: unref short failure
[h264 @ 0x560745648640] mmco: unref short failure
[h264 @ 0x560745648640] mmco: unref short failure
[h264 @ 0x55e23ffba940] mmco: unref short failure
[h264 @ 0x55e23ffba940] mmco: unref short failure
[h264 @ 0x55e23ffba940] mmco: unref short failure
[h264 @ 0x55e23ffba940] mmco: unref short failure
09/17/2024 05:56:30 - INFO - __main__ -   current idx 7tqvfeOf2ug.2 from finetune_area returns wrong image/video, use 70421 instead.
[h264 @ 0x5607526daac0] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:01<05:14,  1.43s/it][A
  1%|          | 2/221 [00:01<03:20,  1.09it/s][A
  1%|▏         | 3/221 [00:02<02:03,  1.77it/s][A
  2%|▏         | 4/221 [00:02<01:23,  2.61it/s][A
  2%|▏         | 5/221 [00:02<01:00,  3.54it/s][A
  3%|▎         | 6/221 [00:02<00:48,  4.42it/s][A
  3%|▎         | 7/221 [00:02<00:56,  3.80it/s][A
  4%|▎         | 8/221 [00:03<01:28,  2.41it/s][A
  4%|▍         | 9/221 [00:03<01:16,  2.78it/s][A
  5%|▍         | 10/221 [00:04<01:17,  2.71it/s][A
  5%|▍         | 11/221 [00:04<01:01,  3.42it/s][A
  5%|▌         | 12/221 [00:04<01:10,  2.98it/s][A
  6%|▌         | 13/221 [00:04<00:56,  3.66it/s][A[h264 @ 0x55b5c4e47540] mmco: unref short failure
[h264 @ 0x55b5c4e47540] mmco: unref short failure
[h264 @ 0x55b5c4e47540] mmco: unref short failure
[h264 @ 0x55b5c4e47540] mmco: unref short failure

  6%|▋         | 14/221 [00:06<02:13,  1.55it/s][A
  7%|▋         | 15/221 [00:06<01:48,  1.90it/s][A
  7%|▋         | 16/221 [00:06<01:32,  2.21it/s][A
  8%|▊         | 17/221 [00:07<01:18,  2.61it/s][A
  8%|▊         | 18/221 [00:07<01:08,  2.95it/s][A
  9%|▊         | 19/221 [00:07<00:55,  3.64it/s][A
  9%|▉         | 20/221 [00:07<00:47,  4.21it/s][A
 10%|▉         | 21/221 [00:07<00:40,  4.92it/s][A
 10%|▉         | 22/221 [00:07<00:40,  4.92it/s][A
 10%|█         | 23/221 [00:08<00:35,  5.58it/s][A
 11%|█         | 24/221 [00:08<00:32,  6.15it/s][A
 11%|█▏        | 25/221 [00:08<00:32,  5.97it/s][A
 12%|█▏        | 26/221 [00:08<00:35,  5.42it/s][A
 12%|█▏        | 27/221 [00:08<00:33,  5.82it/s][A
 13%|█▎        | 28/221 [00:09<00:56,  3.44it/s][A
 13%|█▎        | 29/221 [00:09<00:45,  4.21it/s][A
 14%|█▎        | 30/221 [00:09<00:45,  4.21it/s][A
 14%|█▍        | 31/221 [00:09<00:47,  3.99it/s][A
 14%|█▍        | 32/221 [00:10<00:39,  4.83it/s][A[h264 @ 0x55b5b12bd000] mmco: unref short failure
[h264 @ 0x55b5b12bd000] mmco: unref short failure

 15%|█▍        | 33/221 [00:10<00:49,  3.76it/s][A
 15%|█▌        | 34/221 [00:10<00:48,  3.87it/s][A
 16%|█▌        | 35/221 [00:10<00:42,  4.42it/s][A
 16%|█▋        | 36/221 [00:11<00:45,  4.06it/s][A[h264 @ 0x55a3118dfd80] mmco: unref short failure
[h264 @ 0x55a3118dfd80] mmco: unref short failure

 17%|█▋        | 37/221 [00:11<01:02,  2.93it/s][A
 17%|█▋        | 38/221 [00:11<01:00,  3.05it/s][A
 18%|█▊        | 39/221 [00:12<00:47,  3.82it/s][A
 18%|█▊        | 40/221 [00:12<00:47,  3.83it/s][A
 19%|█▊        | 41/221 [00:12<00:39,  4.60it/s][A
 19%|█▉        | 42/221 [00:12<00:53,  3.37it/s][A
 19%|█▉        | 43/221 [00:13<00:52,  3.39it/s][A
 20%|█▉        | 44/221 [00:13<00:41,  4.22it/s][A
 20%|██        | 45/221 [00:14<01:53,  1.55it/s][A
 21%|██        | 46/221 [00:15<01:48,  1.61it/s][A
 21%|██▏       | 47/221 [00:16<01:54,  1.51it/s][A[h264 @ 0x560745648640] mmco: unref short failure

 22%|██▏       | 48/221 [00:16<01:25,  2.02it/s][A[h264 @ 0x560747ded7c0] mmco: unref short failure
[h264 @ 0x560747ded7c0] mmco: unref short failure
[h264 @ 0x560747ded7c0] mmco: unref short failure
[h264 @ 0x560747ded7c0] mmco: unref short failure

 22%|██▏       | 49/221 [00:16<01:13,  2.33it/s][A
 23%|██▎       | 50/221 [00:16<00:58,  2.92it/s][A
 23%|██▎       | 51/221 [00:16<00:50,  3.36it/s][A
 24%|██▎       | 52/221 [00:17<00:48,  3.48it/s][A
 24%|██▍       | 53/221 [00:17<00:44,  3.79it/s][A
 24%|██▍       | 54/221 [00:18<01:43,  1.62it/s][A
 25%|██▍       | 55/221 [00:19<01:40,  1.66it/s][A
 25%|██▌       | 56/221 [00:19<01:28,  1.87it/s][A
 26%|██▌       | 57/221 [00:20<01:14,  2.20it/s][A
 27%|██▋       | 59/221 [00:20<00:48,  3.37it/s][A
 27%|██▋       | 60/221 [00:20<00:55,  2.89it/s][A
 28%|██▊       | 61/221 [00:21<00:52,  3.04it/s][A
 28%|██▊       | 62/221 [00:21<00:48,  3.27it/s][A
 29%|██▊       | 63/221 [00:21<00:46,  3.42it/s][A
 29%|██▉       | 64/221 [00:21<00:41,  3.76it/s][A
 29%|██▉       | 65/221 [00:22<00:40,  3.86it/s][A
 30%|██▉       | 66/221 [00:22<00:45,  3.43it/s][A
 30%|███       | 67/221 [00:22<00:43,  3.57it/s][A
 31%|███       | 68/221 [00:22<00:36,  4.24it/s][A
 31%|███       | 69/221 [00:23<01:02,  2.41it/s][A
 32%|███▏      | 70/221 [00:23<00:51,  2.96it/s][A
 32%|███▏      | 71/221 [00:26<02:15,  1.11it/s][A
 33%|███▎      | 72/221 [00:26<01:44,  1.43it/s][A
 33%|███▎      | 73/221 [00:26<01:25,  1.74it/s][A
 33%|███▎      | 74/221 [00:26<01:05,  2.26it/s][A
 34%|███▍      | 75/221 [00:27<01:05,  2.21it/s][A
 34%|███▍      | 76/221 [00:27<00:52,  2.78it/s][A
 35%|███▍      | 77/221 [00:27<00:43,  3.28it/s][A
 35%|███▌      | 78/221 [00:27<00:38,  3.73it/s][A
 36%|███▌      | 79/221 [00:28<00:54,  2.62it/s][A
 36%|███▌      | 80/221 [00:28<00:43,  3.25it/s][A
 37%|███▋      | 81/221 [00:28<00:38,  3.61it/s][A
 37%|███▋      | 82/221 [00:28<00:33,  4.09it/s][A
 38%|███▊      | 83/221 [00:28<00:31,  4.41it/s][A
 38%|███▊      | 84/221 [00:29<00:31,  4.38it/s][A
 38%|███▊      | 85/221 [00:29<00:29,  4.68it/s][A
 39%|███▉      | 86/221 [00:29<00:27,  4.98it/s][A
 39%|███▉      | 87/221 [00:30<00:42,  3.18it/s][A
 40%|███▉      | 88/221 [00:30<00:49,  2.70it/s][A[h264 @ 0x55b5c5386380] mmco: unref short failure

 40%|████      | 89/221 [00:33<02:39,  1.21s/it][A
 41%|████      | 90/221 [00:34<02:01,  1.08it/s][A
 41%|████      | 91/221 [00:34<01:36,  1.35it/s][A
 42%|████▏     | 92/221 [00:34<01:14,  1.73it/s][A
 42%|████▏     | 93/221 [00:35<01:20,  1.59it/s][A
 43%|████▎     | 94/221 [00:35<01:08,  1.87it/s][A
 43%|████▎     | 95/221 [00:35<00:52,  2.41it/s][A
 43%|████▎     | 96/221 [00:36<00:51,  2.44it/s][A
 44%|████▍     | 97/221 [00:36<00:41,  3.02it/s][A
 44%|████▍     | 98/221 [00:36<00:38,  3.22it/s][A
 45%|████▍     | 99/221 [00:36<00:31,  3.89it/s][A
 45%|████▌     | 100/221 [00:36<00:27,  4.34it/s][A
 46%|████▌     | 101/221 [00:37<00:24,  4.96it/s][A
 46%|████▌     | 102/221 [00:37<00:30,  3.87it/s][A
 47%|████▋     | 103/221 [00:37<00:25,  4.63it/s][A
 47%|████▋     | 104/221 [00:37<00:23,  4.96it/s][A
 48%|████▊     | 105/221 [00:37<00:24,  4.68it/s][A[h264 @ 0x55b5c8798bc0] mmco: unref short failure
[h264 @ 0x55b5c8798bc0] mmco: unref short failure

 48%|████▊     | 106/221 [00:39<01:01,  1.88it/s][A
 48%|████▊     | 107/221 [00:39<00:46,  2.44it/s][A
 49%|████▉     | 108/221 [00:39<00:39,  2.85it/s][A
 49%|████▉     | 109/221 [00:39<00:39,  2.86it/s][A
 50%|████▉     | 110/221 [00:40<00:34,  3.19it/s][A
 50%|█████     | 111/221 [00:40<00:41,  2.64it/s][A
 51%|█████     | 112/221 [00:40<00:35,  3.06it/s][A
 51%|█████     | 113/221 [00:41<00:38,  2.77it/s][A
 52%|█████▏    | 114/221 [00:41<00:31,  3.40it/s][A
 52%|█████▏    | 115/221 [00:41<00:26,  4.08it/s][A
 52%|█████▏    | 116/221 [00:46<02:49,  1.62s/it][A
 53%|█████▎    | 117/221 [00:46<02:07,  1.23s/it][A
 53%|█████▎    | 118/221 [00:47<01:39,  1.03it/s][A
 54%|█████▍    | 119/221 [00:47<01:16,  1.33it/s][A
 54%|█████▍    | 120/221 [00:47<01:03,  1.59it/s][A
 55%|█████▍    | 121/221 [00:47<00:49,  2.03it/s][A
 55%|█████▌    | 122/221 [00:48<00:40,  2.42it/s][A
 56%|█████▌    | 123/221 [00:48<00:33,  2.95it/s][A
 56%|█████▌    | 124/221 [00:48<00:31,  3.13it/s][A
 57%|█████▋    | 125/221 [00:48<00:28,  3.33it/s][A
 57%|█████▋    | 126/221 [00:49<00:39,  2.40it/s][A
 57%|█████▋    | 127/221 [00:49<00:40,  2.30it/s][A
 58%|█████▊    | 128/221 [00:50<00:38,  2.42it/s][A
 58%|█████▊    | 129/221 [00:50<00:35,  2.62it/s][A
 59%|█████▉    | 130/221 [00:50<00:30,  2.99it/s][A
 59%|█████▉    | 131/221 [00:50<00:24,  3.71it/s][A
 60%|█████▉    | 132/221 [00:51<00:24,  3.62it/s][A
 60%|██████    | 133/221 [00:51<00:30,  2.87it/s][A
 61%|██████    | 134/221 [00:52<00:29,  2.99it/s][A
 61%|██████    | 135/221 [00:52<00:32,  2.62it/s][A
 62%|██████▏   | 136/221 [00:52<00:33,  2.57it/s][A
 62%|██████▏   | 137/221 [00:53<00:27,  3.11it/s][A
 62%|██████▏   | 138/221 [00:53<00:28,  2.89it/s][A
 63%|██████▎   | 139/221 [00:53<00:28,  2.92it/s][A
 63%|██████▎   | 140/221 [00:54<00:29,  2.77it/s][A
 64%|██████▍   | 141/221 [00:54<00:24,  3.29it/s][A
 64%|██████▍   | 142/221 [00:54<00:27,  2.83it/s][A
 65%|██████▍   | 143/221 [00:55<00:32,  2.41it/s][A
 65%|██████▌   | 144/221 [00:55<00:29,  2.65it/s][A
 66%|██████▌   | 145/221 [00:56<00:27,  2.80it/s][A[h264 @ 0x55e24ae25280] mmco: unref short failure

 67%|██████▋   | 147/221 [00:56<00:18,  3.99it/s][A
 67%|██████▋   | 148/221 [00:56<00:18,  3.88it/s][A
 67%|██████▋   | 149/221 [00:56<00:15,  4.52it/s][A
 68%|██████▊   | 150/221 [00:56<00:14,  4.91it/s][A
 68%|██████▊   | 151/221 [00:58<00:34,  2.01it/s][A
 69%|██████▉   | 152/221 [00:58<00:32,  2.14it/s][A
 69%|██████▉   | 153/221 [00:58<00:29,  2.31it/s][A
 70%|██████▉   | 154/221 [00:59<00:31,  2.14it/s][A
 70%|███████   | 155/221 [00:59<00:25,  2.63it/s][A
 71%|███████   | 156/221 [00:59<00:21,  3.03it/s][A
 71%|███████   | 157/221 [01:00<00:36,  1.77it/s][A
 71%|███████▏  | 158/221 [01:01<00:29,  2.11it/s][A
 72%|███████▏  | 159/221 [01:01<00:24,  2.53it/s][A
 72%|███████▏  | 160/221 [01:01<00:19,  3.10it/s][A
 73%|███████▎  | 162/221 [01:01<00:13,  4.50it/s][A
 74%|███████▍  | 163/221 [01:02<00:13,  4.22it/s][A
 74%|███████▍  | 164/221 [01:02<00:14,  3.97it/s][A
 75%|███████▍  | 165/221 [01:02<00:13,  4.08it/s][A
 75%|███████▌  | 166/221 [01:02<00:15,  3.51it/s][A
 76%|███████▌  | 167/221 [01:03<00:13,  3.94it/s][A
 76%|███████▌  | 168/221 [01:04<00:34,  1.52it/s][A
 76%|███████▋  | 169/221 [01:05<00:28,  1.82it/s][A
 77%|███████▋  | 170/221 [01:05<00:24,  2.12it/s][A
 77%|███████▋  | 171/221 [01:05<00:20,  2.42it/s][A
 78%|███████▊  | 172/221 [01:05<00:17,  2.73it/s][A
 78%|███████▊  | 173/221 [01:05<00:13,  3.45it/s][A
 79%|███████▊  | 174/221 [01:06<00:12,  3.83it/s][A
 79%|███████▉  | 175/221 [01:06<00:14,  3.25it/s][A
 80%|███████▉  | 176/221 [01:06<00:14,  3.21it/s][A
 80%|████████  | 177/221 [01:07<00:11,  3.71it/s][A
 81%|████████  | 178/221 [01:07<00:13,  3.16it/s][A
 81%|████████  | 179/221 [01:07<00:14,  2.81it/s][A
 82%|████████▏ | 181/221 [01:08<00:11,  3.61it/s][A
 82%|████████▏ | 182/221 [01:08<00:09,  3.95it/s][A
 83%|████████▎ | 183/221 [01:08<00:08,  4.33it/s][A
 83%|████████▎ | 184/221 [01:08<00:09,  3.85it/s][A
 84%|████████▎ | 185/221 [01:09<00:08,  4.06it/s][A
 84%|████████▍ | 186/221 [01:09<00:10,  3.34it/s][A
 85%|████████▍ | 187/221 [01:09<00:08,  3.96it/s][A
 85%|████████▌ | 188/221 [01:10<00:09,  3.61it/s][A
 86%|████████▌ | 189/221 [01:10<00:09,  3.52it/s][A
 86%|████████▌ | 190/221 [01:10<00:08,  3.54it/s][A
 86%|████████▋ | 191/221 [01:10<00:07,  4.23it/s][A
 87%|████████▋ | 192/221 [01:11<00:07,  4.08it/s][A
 88%|████████▊ | 194/221 [01:11<00:09,  2.95it/s][A
 88%|████████▊ | 195/221 [01:12<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [01:12<00:06,  4.10it/s][A
 89%|████████▉ | 197/221 [01:12<00:05,  4.68it/s][A
 90%|████████▉ | 198/221 [01:12<00:04,  4.75it/s][A
 90%|█████████ | 199/221 [01:12<00:04,  4.66it/s][A
 90%|█████████ | 200/221 [01:13<00:05,  3.95it/s][A
 91%|█████████ | 201/221 [01:13<00:05,  3.88it/s][A
 91%|█████████▏| 202/221 [01:13<00:04,  3.95it/s][A
 92%|█████████▏| 203/221 [01:13<00:04,  4.36it/s][A
 92%|█████████▏| 204/221 [01:13<00:03,  5.17it/s][A
 93%|█████████▎| 205/221 [01:14<00:02,  5.86it/s][A
 93%|█████████▎| 206/221 [01:14<00:04,  3.08it/s][A
 94%|█████████▍| 208/221 [01:14<00:02,  4.70it/s][A
 95%|█████████▍| 209/221 [01:15<00:02,  5.40it/s][A
 95%|█████████▌| 211/221 [01:15<00:02,  4.56it/s][A
 96%|█████████▌| 212/221 [01:15<00:01,  5.13it/s][A
 97%|█████████▋| 214/221 [01:16<00:02,  2.72it/s][A
 97%|█████████▋| 215/221 [01:17<00:02,  2.79it/s][A
 98%|█████████▊| 216/221 [01:17<00:01,  3.02it/s][A
 98%|█████████▊| 217/221 [01:18<00:01,  2.54it/s][A
 99%|█████████▊| 218/221 [01:18<00:01,  2.59it/s][A
 99%|█████████▉| 219/221 [01:18<00:00,  2.91it/s][A[h264 @ 0x55b5c5e21300] mmco: unref short failure

100%|█████████▉| 220/221 [01:23<00:01,  1.51s/it][A
100%|██████████| 221/221 [01:23<00:00,  1.13s/it][A100%|██████████| 221/221 [01:23<00:00,  2.65it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:09,  3.17it/s][A
  1%|          | 2/221 [00:00<01:06,  3.31it/s][A
  1%|▏         | 3/221 [00:00<01:07,  3.23it/s][A
  2%|▏         | 4/221 [00:01<01:06,  3.25it/s][A
  2%|▏         | 5/221 [00:01<01:06,  3.26it/s][A
  3%|▎         | 6/221 [00:01<01:04,  3.31it/s][A
  3%|▎         | 7/221 [00:02<01:04,  3.30it/s][A
  4%|▎         | 8/221 [00:02<01:05,  3.27it/s][A
  4%|▍         | 9/221 [00:02<01:06,  3.17it/s][A
  5%|▍         | 10/221 [00:03<01:06,  3.19it/s][A
  5%|▍         | 11/221 [00:03<01:04,  3.26it/s][A
  5%|▌         | 12/221 [00:03<01:03,  3.28it/s][A
  6%|▌         | 13/221 [00:03<01:02,  3.30it/s][A
  6%|▋         | 14/221 [00:04<01:02,  3.33it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.35it/s][A
  7%|▋         | 16/221 [00:04<01:01,  3.35it/s][A
  8%|▊         | 17/221 [00:05<01:02,  3.25it/s][A
  8%|▊         | 18/221 [00:05<01:01,  3.30it/s][A
  9%|▊         | 19/221 [00:05<01:00,  3.32it/s][A
  9%|▉         | 20/221 [00:06<01:00,  3.31it/s][A[h264 @ 0x55a30fefd100] mmco: unref short failure

 10%|▉         | 21/221 [00:06<00:59,  3.33it/s][A
 10%|▉         | 22/221 [00:06<00:59,  3.35it/s][A
 10%|█         | 23/221 [00:06<00:59,  3.34it/s][A
 11%|█         | 24/221 [00:07<00:59,  3.32it/s][A
 11%|█▏        | 25/221 [00:07<00:58,  3.35it/s][A[h264 @ 0x55a32ea071c0] mmco: unref short failure
[h264 @ 0x55a32ea071c0] mmco: unref short failure

 12%|█▏        | 26/221 [00:07<00:58,  3.34it/s][A
 12%|█▏        | 27/221 [00:08<00:57,  3.36it/s][A
 13%|█▎        | 28/221 [00:08<00:57,  3.34it/s][A
 13%|█▎        | 29/221 [00:08<00:57,  3.36it/s][A
 14%|█▎        | 30/221 [00:09<00:58,  3.29it/s][A
 14%|█▍        | 31/221 [00:09<00:58,  3.26it/s][A
 14%|█▍        | 32/221 [00:09<00:58,  3.26it/s][A
 15%|█▍        | 33/221 [00:10<00:57,  3.30it/s][A
 15%|█▌        | 34/221 [00:10<00:57,  3.27it/s][A
 16%|█▌        | 35/221 [00:10<00:56,  3.31it/s][A
 16%|█▋        | 36/221 [00:10<00:55,  3.34it/s][A
 17%|█▋        | 37/221 [00:11<00:54,  3.35it/s][A
 17%|█▋        | 38/221 [00:11<00:54,  3.36it/s][A
 18%|█▊        | 39/221 [00:11<00:53,  3.37it/s][A
 18%|█▊        | 40/221 [00:12<00:53,  3.38it/s][A
 19%|█▊        | 41/221 [00:12<00:53,  3.38it/s][A09/17/2024 05:58:23 - INFO - __main__ -   current idx 4VH9UPwnHCQ.1 from finetune_area returns wrong image/video, use 49393 instead.

 19%|█▉        | 42/221 [00:12<00:52,  3.39it/s][A
 19%|█▉        | 43/221 [00:12<00:52,  3.39it/s][A
 20%|█▉        | 44/221 [00:13<00:52,  3.40it/s][A
 20%|██        | 45/221 [00:13<00:51,  3.40it/s][A
 21%|██        | 46/221 [00:13<00:51,  3.40it/s][A
 21%|██▏       | 47/221 [00:14<00:51,  3.36it/s][A
 22%|██▏       | 48/221 [00:14<00:52,  3.29it/s][A
 22%|██▏       | 49/221 [00:14<00:51,  3.33it/s][A
 23%|██▎       | 50/221 [00:15<00:51,  3.35it/s][A
 23%|██▎       | 51/221 [00:15<00:50,  3.36it/s][A
 24%|██▎       | 52/221 [00:15<00:50,  3.35it/s][A
 24%|██▍       | 53/221 [00:15<00:49,  3.36it/s][A
 24%|██▍       | 54/221 [00:16<00:49,  3.37it/s][A
 25%|██▍       | 55/221 [00:16<00:49,  3.33it/s][A
 25%|██▌       | 56/221 [00:16<00:49,  3.30it/s][A
 26%|██▌       | 57/221 [00:17<00:49,  3.33it/s][A
 26%|██▌       | 58/221 [00:17<00:48,  3.35it/s][A
 27%|██▋       | 59/221 [00:17<00:48,  3.37it/s][A
 27%|██▋       | 60/221 [00:18<00:48,  3.35it/s][A
 28%|██▊       | 61/221 [00:18<00:48,  3.33it/s][A
 28%|██▊       | 62/221 [00:18<00:48,  3.30it/s][A
 29%|██▊       | 63/221 [00:18<00:47,  3.33it/s][A[h264 @ 0x55a31e9a8080] mmco: unref short failure
[h264 @ 0x55a31e9a8080] mmco: unref short failure
[h264 @ 0x55a31e9a8080] mmco: unref short failure
[h264 @ 0x55a31e9a8080] mmco: unref short failure

 29%|██▉       | 64/221 [00:19<00:47,  3.33it/s][A
 29%|██▉       | 65/221 [00:19<00:46,  3.35it/s][A
 30%|██▉       | 66/221 [00:19<00:46,  3.30it/s][A
 30%|███       | 67/221 [00:20<00:46,  3.33it/s][A
 31%|███       | 68/221 [00:20<00:45,  3.33it/s][A
 31%|███       | 69/221 [00:20<00:45,  3.35it/s][A
 32%|███▏      | 70/221 [00:21<00:44,  3.36it/s][A
 32%|███▏      | 71/221 [00:21<00:45,  3.31it/s][A
 33%|███▎      | 72/221 [00:21<00:46,  3.19it/s][A
 33%|███▎      | 73/221 [00:21<00:45,  3.25it/s][A
 33%|███▎      | 74/221 [00:22<00:44,  3.30it/s][A
 34%|███▍      | 75/221 [00:22<00:43,  3.32it/s][A
 34%|███▍      | 76/221 [00:22<00:43,  3.30it/s][A
 35%|███▍      | 77/221 [00:23<00:43,  3.32it/s][A
 35%|███▌      | 78/221 [00:23<00:42,  3.34it/s][A
 36%|███▌      | 79/221 [00:23<00:43,  3.30it/s][A
 36%|███▌      | 80/221 [00:24<00:42,  3.33it/s][A
 37%|███▋      | 81/221 [00:24<00:41,  3.34it/s][A
 37%|███▋      | 82/221 [00:24<00:41,  3.36it/s][A
 38%|███▊      | 83/221 [00:24<00:40,  3.37it/s][A
 38%|███▊      | 84/221 [00:25<00:40,  3.38it/s][A
 38%|███▊      | 85/221 [00:25<00:40,  3.39it/s][A
 39%|███▉      | 86/221 [00:25<00:39,  3.39it/s][A
 39%|███▉      | 87/221 [00:26<00:39,  3.40it/s][A
 40%|███▉      | 88/221 [00:26<00:39,  3.40it/s][A
 40%|████      | 89/221 [00:26<00:38,  3.40it/s][A
 41%|████      | 90/221 [00:27<00:38,  3.40it/s][A
 41%|████      | 91/221 [00:27<00:38,  3.40it/s][A
 42%|████▏     | 92/221 [00:27<00:37,  3.41it/s][A
 42%|████▏     | 93/221 [00:27<00:37,  3.41it/s][A
 43%|████▎     | 94/221 [00:28<00:37,  3.41it/s][A
 43%|████▎     | 95/221 [00:28<00:36,  3.41it/s][A
 43%|████▎     | 96/221 [00:28<00:36,  3.41it/s][A
 44%|████▍     | 97/221 [00:29<00:36,  3.41it/s][A
 44%|████▍     | 98/221 [00:29<00:36,  3.41it/s][A
 45%|████▍     | 99/221 [00:29<00:35,  3.41it/s][A
 45%|████▌     | 100/221 [00:29<00:35,  3.41it/s][A
 46%|████▌     | 101/221 [00:30<00:35,  3.41it/s][A
 46%|████▌     | 102/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 104/221 [00:31<00:34,  3.42it/s][A
 48%|████▊     | 105/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 107/221 [00:32<00:33,  3.42it/s][A
 49%|████▉     | 108/221 [00:32<00:33,  3.42it/s][A
 49%|████▉     | 109/221 [00:32<00:32,  3.42it/s][A
 50%|████▉     | 110/221 [00:32<00:32,  3.42it/s][A
 50%|█████     | 111/221 [00:33<00:32,  3.42it/s][A
 51%|█████     | 112/221 [00:33<00:31,  3.42it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 114/221 [00:34<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:34<00:30,  3.42it/s][A
 52%|█████▏    | 116/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:35<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:35<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:36<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:37<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:38<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:39<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:39<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:40<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:41<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:41<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:42<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:43<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:44<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:45<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:45<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:46<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:46<00:18,  3.42it/s][A
 71%|███████   | 157/221 [00:46<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:47<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:48<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:48<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:48<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:49<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:49<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:50<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:50<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:51<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:51<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:52<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:53<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:54<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:55<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:55<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:57<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:57<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:58<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:59<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [01:00<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:02<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:05<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.42it/s][A100%|██████████| 221/221 [01:05<00:00,  3.38it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  1%|          | 2/221 [00:00<00:32,  6.73it/s][A
  1%|▏         | 3/221 [00:00<00:53,  4.11it/s][A
  2%|▏         | 4/221 [00:00<00:42,  5.07it/s][A
  2%|▏         | 5/221 [00:00<00:43,  5.01it/s][A
  3%|▎         | 7/221 [00:01<00:42,  4.98it/s][A
  4%|▎         | 8/221 [00:01<00:50,  4.25it/s][A
  4%|▍         | 9/221 [00:02<00:54,  3.86it/s][A
  5%|▍         | 11/221 [00:02<00:46,  4.47it/s][A
  5%|▌         | 12/221 [00:02<00:45,  4.64it/s][A
  6%|▌         | 13/221 [00:03<01:29,  2.32it/s][A
  6%|▋         | 14/221 [00:03<01:16,  2.72it/s][A
  7%|▋         | 15/221 [00:04<01:22,  2.50it/s][A
  7%|▋         | 16/221 [00:04<01:23,  2.46it/s][A
  8%|▊         | 17/221 [00:05<01:17,  2.62it/s][A
  8%|▊         | 18/221 [00:05<01:06,  3.03it/s][A
  9%|▉         | 20/221 [00:05<00:54,  3.71it/s][A
 10%|▉         | 21/221 [00:05<00:47,  4.17it/s][A
 10%|▉         | 22/221 [00:05<00:42,  4.70it/s][A
 11%|█         | 24/221 [00:06<00:35,  5.58it/s][A
 11%|█▏        | 25/221 [00:06<00:43,  4.56it/s][A
 12%|█▏        | 26/221 [00:06<00:42,  4.61it/s][A
 12%|█▏        | 27/221 [00:07<00:50,  3.80it/s][A
 13%|█▎        | 28/221 [00:07<00:56,  3.43it/s][A
 13%|█▎        | 29/221 [00:07<00:59,  3.21it/s][A
 14%|█▎        | 30/221 [00:08<01:10,  2.72it/s][A
 14%|█▍        | 31/221 [00:08<01:09,  2.73it/s][A
 14%|█▍        | 32/221 [00:09<01:04,  2.92it/s][A
 15%|█▍        | 33/221 [00:09<01:12,  2.61it/s][A
 15%|█▌        | 34/221 [00:10<01:49,  1.71it/s][A
 16%|█▌        | 35/221 [00:10<01:28,  2.09it/s][A
 16%|█▋        | 36/221 [00:11<01:16,  2.43it/s][A
 17%|█▋        | 37/221 [00:11<01:03,  2.88it/s][A
 17%|█▋        | 38/221 [00:11<00:58,  3.11it/s][A
 18%|█▊        | 39/221 [00:11<00:50,  3.62it/s][A
 18%|█▊        | 40/221 [00:11<00:47,  3.81it/s][A
 19%|█▊        | 41/221 [00:12<00:52,  3.42it/s][A
 19%|█▉        | 42/221 [00:12<00:45,  3.91it/s][A
 19%|█▉        | 43/221 [00:12<00:43,  4.14it/s][A
 20%|█▉        | 44/221 [00:12<00:42,  4.18it/s][A
 20%|██        | 45/221 [00:13<00:48,  3.60it/s][A
 21%|██        | 46/221 [00:13<00:46,  3.75it/s][A
 21%|██▏       | 47/221 [00:13<00:41,  4.16it/s][A
 22%|██▏       | 48/221 [00:13<00:34,  5.00it/s][A
 22%|██▏       | 49/221 [00:13<00:29,  5.77it/s][A
 23%|██▎       | 50/221 [00:14<00:40,  4.23it/s][A
 23%|██▎       | 51/221 [00:14<00:43,  3.89it/s][A
 24%|██▎       | 52/221 [00:14<00:42,  4.01it/s][A
 24%|██▍       | 53/221 [00:15<00:48,  3.46it/s][A
 24%|██▍       | 54/221 [00:15<00:43,  3.84it/s][A
 25%|██▍       | 55/221 [00:15<00:50,  3.29it/s][A
 25%|██▌       | 56/221 [00:16<00:48,  3.43it/s][A
 26%|██▌       | 57/221 [00:16<00:51,  3.15it/s][A
 26%|██▌       | 58/221 [00:16<00:52,  3.11it/s][A
 27%|██▋       | 59/221 [00:17<00:49,  3.26it/s][A
 27%|██▋       | 60/221 [00:17<00:42,  3.74it/s][A
 28%|██▊       | 61/221 [00:17<00:40,  3.96it/s][A
 28%|██▊       | 62/221 [00:17<00:43,  3.68it/s][A
 29%|██▊       | 63/221 [00:17<00:35,  4.50it/s][A
 29%|██▉       | 64/221 [00:18<00:39,  3.97it/s][A
 29%|██▉       | 65/221 [00:18<00:38,  4.08it/s][A
 30%|██▉       | 66/221 [00:18<00:39,  3.92it/s][A
 30%|███       | 67/221 [00:19<00:44,  3.46it/s][A
 31%|███       | 68/221 [00:19<00:40,  3.73it/s][A
 31%|███       | 69/221 [00:19<00:58,  2.59it/s][A
 32%|███▏      | 70/221 [00:20<00:52,  2.86it/s][A
 32%|███▏      | 71/221 [00:20<00:56,  2.67it/s][A
 33%|███▎      | 72/221 [00:21<00:59,  2.52it/s][A
 33%|███▎      | 73/221 [00:21<00:54,  2.70it/s][A
 33%|███▎      | 74/221 [00:21<00:49,  2.96it/s][A
 34%|███▍      | 75/221 [00:21<00:46,  3.17it/s][A
 34%|███▍      | 76/221 [00:22<00:36,  3.96it/s][A
 35%|███▍      | 77/221 [00:22<00:37,  3.83it/s][A
 35%|███▌      | 78/221 [00:22<00:40,  3.54it/s][A
 36%|███▌      | 79/221 [00:22<00:39,  3.62it/s][A
 36%|███▌      | 80/221 [00:23<00:35,  3.95it/s][A
 37%|███▋      | 81/221 [00:23<00:34,  4.04it/s][A
 37%|███▋      | 82/221 [00:23<00:34,  3.99it/s][A
 38%|███▊      | 83/221 [00:23<00:31,  4.39it/s][A
 38%|███▊      | 84/221 [00:24<00:39,  3.48it/s][A
 38%|███▊      | 85/221 [00:24<00:44,  3.04it/s][A
 39%|███▉      | 86/221 [00:25<00:45,  2.98it/s][A
 39%|███▉      | 87/221 [00:25<00:50,  2.65it/s][A
 40%|███▉      | 88/221 [00:25<00:46,  2.88it/s][A
 40%|████      | 89/221 [00:26<00:46,  2.84it/s][A
 41%|████      | 90/221 [00:26<00:45,  2.85it/s][A
 41%|████      | 91/221 [00:26<00:43,  3.02it/s][A
 42%|████▏     | 92/221 [00:27<00:45,  2.81it/s][A
 42%|████▏     | 93/221 [00:27<01:01,  2.09it/s][A
 43%|████▎     | 94/221 [00:28<00:50,  2.53it/s][A
 43%|████▎     | 95/221 [00:28<01:01,  2.05it/s][A
 43%|████▎     | 96/221 [00:29<00:58,  2.13it/s][A
 44%|████▍     | 97/221 [00:29<00:48,  2.56it/s][A
 44%|████▍     | 98/221 [00:29<00:45,  2.68it/s][A
 45%|████▍     | 99/221 [00:30<00:40,  3.00it/s][A
 45%|████▌     | 100/221 [00:30<00:34,  3.54it/s][A
 46%|████▌     | 101/221 [00:30<00:28,  4.18it/s][A
 46%|████▌     | 102/221 [00:30<00:29,  3.99it/s][A
 47%|████▋     | 103/221 [00:30<00:27,  4.28it/s][A
 47%|████▋     | 104/221 [00:30<00:23,  5.08it/s][A
 48%|████▊     | 105/221 [00:31<00:29,  3.99it/s][A
 48%|████▊     | 106/221 [00:31<00:30,  3.74it/s][A
 48%|████▊     | 107/221 [00:31<00:31,  3.66it/s][A
 49%|████▉     | 108/221 [00:32<00:30,  3.76it/s][A
 49%|████▉     | 109/221 [00:32<00:27,  4.05it/s][A
 50%|████▉     | 110/221 [00:32<00:26,  4.16it/s][A
 50%|█████     | 111/221 [00:32<00:29,  3.71it/s][A
 51%|█████     | 112/221 [00:33<00:33,  3.27it/s][A
 51%|█████     | 113/221 [00:33<00:34,  3.13it/s][A
 52%|█████▏    | 114/221 [00:33<00:28,  3.76it/s][A
 52%|█████▏    | 115/221 [00:33<00:25,  4.22it/s][A
 52%|█████▏    | 116/221 [00:34<00:23,  4.52it/s][A
 53%|█████▎    | 117/221 [00:34<00:23,  4.50it/s][A
 53%|█████▎    | 118/221 [00:34<00:31,  3.26it/s][A
 54%|█████▍    | 119/221 [00:35<00:34,  2.93it/s][A
 54%|█████▍    | 120/221 [00:35<00:35,  2.83it/s][A
 55%|█████▍    | 121/221 [00:35<00:30,  3.32it/s][A
 55%|█████▌    | 122/221 [00:36<00:27,  3.56it/s][A
 56%|█████▌    | 123/221 [00:36<00:29,  3.33it/s][A
 56%|█████▌    | 124/221 [00:36<00:27,  3.51it/s][A
 57%|█████▋    | 125/221 [00:37<00:33,  2.88it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.43it/s][A
 57%|█████▋    | 127/221 [00:38<00:38,  2.41it/s][A
 58%|█████▊    | 128/221 [00:38<00:32,  2.86it/s][A
 58%|█████▊    | 129/221 [00:38<00:28,  3.28it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.47it/s][A
 59%|█████▉    | 131/221 [00:38<00:23,  3.85it/s][A
 60%|█████▉    | 132/221 [00:39<00:24,  3.65it/s][A
 60%|██████    | 133/221 [00:39<00:35,  2.51it/s][A
 61%|██████    | 134/221 [00:40<00:37,  2.35it/s][A
 61%|██████    | 135/221 [00:40<00:30,  2.79it/s][A
 62%|██████▏   | 136/221 [00:40<00:29,  2.89it/s][A
 62%|██████▏   | 137/221 [00:41<00:24,  3.49it/s][A
 62%|██████▏   | 138/221 [00:41<00:21,  3.82it/s][A
 63%|██████▎   | 139/221 [00:41<00:24,  3.37it/s][A
 63%|██████▎   | 140/221 [00:41<00:22,  3.58it/s][A
 64%|██████▍   | 141/221 [00:42<00:26,  2.98it/s][A
 64%|██████▍   | 142/221 [00:42<00:23,  3.40it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.54it/s][A
 65%|██████▌   | 144/221 [00:43<00:21,  3.63it/s][A
 66%|██████▌   | 145/221 [00:43<00:24,  3.09it/s][A
 66%|██████▌   | 146/221 [00:43<00:23,  3.25it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.44it/s][A
 67%|██████▋   | 148/221 [00:44<00:22,  3.25it/s][A
 67%|██████▋   | 149/221 [00:44<00:19,  3.68it/s][A
 68%|██████▊   | 150/221 [00:44<00:17,  4.07it/s][A
 68%|██████▊   | 151/221 [00:45<00:22,  3.06it/s][A
 69%|██████▉   | 152/221 [00:46<00:31,  2.16it/s][A
 69%|██████▉   | 153/221 [00:46<00:27,  2.45it/s][A
 70%|██████▉   | 154/221 [00:46<00:26,  2.57it/s][A
 70%|███████   | 155/221 [00:46<00:24,  2.73it/s][A
 71%|███████   | 156/221 [00:47<00:19,  3.32it/s][A
 71%|███████   | 157/221 [00:47<00:18,  3.40it/s][A
 71%|███████▏  | 158/221 [00:47<00:19,  3.18it/s][A
 72%|███████▏  | 159/221 [00:47<00:17,  3.46it/s][A
 72%|███████▏  | 160/221 [00:48<00:15,  3.88it/s][A
 73%|███████▎  | 161/221 [00:48<00:13,  4.30it/s][A
 74%|███████▍  | 163/221 [00:48<00:11,  4.84it/s][A
 74%|███████▍  | 164/221 [00:48<00:11,  5.06it/s][A
 75%|███████▍  | 165/221 [00:49<00:13,  4.06it/s][A
 75%|███████▌  | 166/221 [00:49<00:14,  3.67it/s][A
 76%|███████▌  | 168/221 [00:49<00:11,  4.57it/s][A
 77%|███████▋  | 170/221 [00:50<00:15,  3.23it/s][A
 77%|███████▋  | 171/221 [00:51<00:15,  3.18it/s][A
 78%|███████▊  | 172/221 [00:51<00:15,  3.14it/s][A
 78%|███████▊  | 173/221 [00:51<00:15,  3.07it/s][A
 79%|███████▊  | 174/221 [00:52<00:15,  3.11it/s][A
 79%|███████▉  | 175/221 [00:52<00:14,  3.13it/s][A
 80%|███████▉  | 176/221 [00:52<00:12,  3.46it/s][A
 80%|████████  | 177/221 [00:52<00:11,  3.68it/s][A
 81%|████████  | 178/221 [00:53<00:16,  2.60it/s][A
 81%|████████  | 179/221 [00:53<00:14,  2.89it/s][A
 81%|████████▏ | 180/221 [00:54<00:13,  3.11it/s][A
 82%|████████▏ | 181/221 [00:54<00:17,  2.33it/s][A
 82%|████████▏ | 182/221 [00:55<00:15,  2.52it/s][A
 83%|████████▎ | 183/221 [00:55<00:14,  2.65it/s][A
 83%|████████▎ | 184/221 [00:55<00:13,  2.81it/s][A
 84%|████████▍ | 186/221 [00:56<00:11,  3.17it/s][A
 85%|████████▍ | 187/221 [00:56<00:09,  3.41it/s][A
 85%|████████▌ | 188/221 [00:56<00:11,  2.97it/s][A
 86%|████████▌ | 189/221 [00:57<00:09,  3.33it/s][A
 86%|████████▌ | 190/221 [00:57<00:10,  3.09it/s][A
 86%|████████▋ | 191/221 [00:57<00:08,  3.71it/s][A
 87%|████████▋ | 192/221 [00:57<00:07,  3.68it/s][A
 87%|████████▋ | 193/221 [00:58<00:07,  3.81it/s][A
 88%|████████▊ | 194/221 [00:58<00:06,  3.94it/s][A
 88%|████████▊ | 195/221 [00:58<00:06,  4.05it/s][A
 89%|████████▊ | 196/221 [00:59<00:09,  2.76it/s][A
 89%|████████▉ | 197/221 [00:59<00:09,  2.49it/s][A
 90%|████████▉ | 198/221 [01:00<00:08,  2.59it/s][A
 90%|█████████ | 199/221 [01:00<00:06,  3.29it/s][A
 90%|█████████ | 200/221 [01:00<00:05,  3.55it/s][A
 91%|█████████ | 201/221 [01:00<00:04,  4.06it/s][A
 91%|█████████▏| 202/221 [01:00<00:04,  3.87it/s][A
 92%|█████████▏| 203/221 [01:01<00:04,  4.11it/s][A
 92%|█████████▏| 204/221 [01:01<00:05,  3.23it/s][A
 93%|█████████▎| 205/221 [01:01<00:04,  3.43it/s][A
 93%|█████████▎| 206/221 [01:02<00:05,  2.90it/s][A
 94%|█████████▎| 207/221 [01:02<00:05,  2.66it/s][A
 94%|█████████▍| 208/221 [01:02<00:03,  3.27it/s][A
 95%|█████████▍| 209/221 [01:03<00:03,  3.57it/s][A
 95%|█████████▌| 210/221 [01:03<00:03,  2.85it/s][A
 95%|█████████▌| 211/221 [01:03<00:03,  3.26it/s][A
 96%|█████████▌| 212/221 [01:04<00:02,  3.09it/s][A
 96%|█████████▋| 213/221 [01:04<00:02,  3.35it/s][A
 97%|█████████▋| 214/221 [01:04<00:02,  3.24it/s][A
 97%|█████████▋| 215/221 [01:05<00:01,  3.11it/s][A
 98%|█████████▊| 216/221 [01:05<00:01,  2.98it/s][A
 98%|█████████▊| 217/221 [01:05<00:01,  3.14it/s][A
 99%|█████████▊| 218/221 [01:06<00:01,  2.99it/s][A
 99%|█████████▉| 219/221 [01:06<00:00,  2.92it/s][A
100%|█████████▉| 220/221 [01:06<00:00,  3.41it/s][A
100%|██████████| 221/221 [01:06<00:00,  3.25it/s][A100%|██████████| 221/221 [01:06<00:00,  3.30it/s]
09/17/2024 06:00:24 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 1049--===========

09/17/2024 06:00:24 - INFO - __main__ -   {'area_r1': 38.7, 'area_recall': '38.7/64.0/73.5', 'area_ravg': 58.7}
09/17/2024 06:00:24 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 1049--===========

09/17/2024 06:00:24 - INFO - __main__ -   {'forward_r1': 37.2, 'forward_recall': '37.2/66.1/76.7', 'forward_ravg': 60.0}
09/17/2024 06:00:24 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 1049--===========

09/17/2024 06:00:24 - INFO - __main__ -   {'area_video_r1': 38.6, 'area_video_recall': '38.6/66.4/77.5', 'area_video_ravg': 60.8}
09/17/2024 06:00:24 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 299=======

09/17/2024 06:00:24 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 06:00:24 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 1049--===========

09/17/2024 06:00:24 - INFO - __main__ -   {'area_video_r1': 52.4, 'area_video_recall': '52.4/74.8/82.0', 'area_video_ravg': 69.7, 'area_video_back_r1': 47.6, 'area_video_back_recall': '47.6/74.5/82.5', 'area_video_back_ravg': 68.2}
09/17/2024 06:00:24 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 549=======

09/17/2024 06:00:24 - INFO - __main__ -   {'area_video_r1': 54.1, 'area_video_recall': '54.1/75.5/82.4', 'area_video_ravg': 70.6, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.5/82.1', 'area_video_back_ravg': 68.7}
09/17/2024 06:00:24 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 1049--===========

09/17/2024 06:00:24 - INFO - __main__ -   {'video_r1': 37.9, 'video_recall': '37.9/63.6/74.0', 'video_ravg': 58.5}
09/17/2024 06:00:24 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 949=======

09/17/2024 06:00:24 - INFO - __main__ -   {'video_r1': 38.7, 'video_recall': '38.7/64.3/74.1', 'video_ravg': 59.0}
09/17/2024 06:00:24 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 1049--===========

09/17/2024 06:00:24 - INFO - __main__ -   {'video_r1': 52.0, 'video_recall': '52.0/75.0/83.0', 'video_ravg': 70.0}
09/17/2024 06:00:24 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 549=======

09/17/2024 06:00:24 - INFO - __main__ -   {'video_r1': 54.5, 'video_recall': '54.5/76.1/83.4', 'video_ravg': 71.3}
09/17/2024 06:00:47 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.007736681029200554, 'loss_ret%tv%ta--finetune_area/loss_area': 1.125370979309082, 'loss_ret%tv%ta--finetune_area/total_loss': 1.1331076622009277}
 36%|███▌      | 1050/2910 [6:39:04<69:30:31, 134.53s/it] 36%|███▌      | 1051/2910 [6:39:07<49:12:14, 95.29s/it]  36%|███▌      | 1052/2910 [6:39:11<35:02:44, 67.90s/it][h264 @ 0x55a324d2cf00] mmco: unref short failure
[h264 @ 0x55a324d2cf00] mmco: unref short failure
 36%|███▌      | 1053/2910 [6:39:15<25:09:55, 48.79s/it][h264 @ 0x55e24ae25280] mmco: unref short failure
[h264 @ 0x5607446d3600] mmco: unref short failure
 36%|███▌      | 1054/2910 [6:39:20<18:19:39, 35.55s/it][h264 @ 0x55a31335af80] mmco: unref short failure
[h264 @ 0x55a31335af80] mmco: unref short failure
 36%|███▋      | 1055/2910 [6:39:25<13:35:25, 26.38s/it][h264 @ 0x55a32b0d8e40] mmco: unref short failure
[h264 @ 0x55a32b0d8e40] mmco: unref short failure
 36%|███▋      | 1056/2910 [6:39:31<10:21:52, 20.13s/it] 36%|███▋      | 1057/2910 [6:39:36<8:03:33, 15.66s/it]  36%|███▋      | 1058/2910 [6:39:42<6:32:14, 12.71s/it][h264 @ 0x55b5bd946d80] mmco: unref short failure
[h264 @ 0x55a31daa8f40] mmco: unref short failure
 36%|███▋      | 1059/2910 [6:39:47<5:27:35, 10.62s/it] 36%|███▋      | 1060/2910 [6:39:53<4:40:17,  9.09s/it] 36%|███▋      | 1061/2910 [6:39:59<4:08:27,  8.06s/it] 36%|███▋      | 1062/2910 [6:40:04<3:40:21,  7.15s/it] 37%|███▋      | 1063/2910 [6:40:09<3:25:46,  6.68s/it] 37%|███▋      | 1064/2910 [6:40:16<3:22:57,  6.60s/it] 37%|███▋      | 1065/2910 [6:40:21<3:11:32,  6.23s/it][h264 @ 0x560741c97ac0] mmco: unref short failure
[h264 @ 0x55b5b630f3c0] mmco: unref short failure
[h264 @ 0x55b5b630f3c0] mmco: unref short failure
[h264 @ 0x55b5aacd7c80] mmco: unref short failure
[h264 @ 0x55a32115f2c0] mmco: unref short failure
[h264 @ 0x55e2376feac0] mmco: unref short failure
[h264 @ 0x55e2376feac0] mmco: unref short failure
[h264 @ 0x55e240bb85c0] mmco: unref short failure
[h264 @ 0x55a32443f280] mmco: unref short failure
[h264 @ 0x55a32443f280] mmco: unref short failure
[h264 @ 0x55b5c5e21300] mmco: unref short failure
[h264 @ 0x55b5c5e21300] mmco: unref short failure
 37%|███▋      | 1066/2910 [6:41:10<9:43:01, 18.97s/it][h264 @ 0x55e250eaa900] mmco: unref short failure
[h264 @ 0x55e250eaa900] mmco: unref short failure
[h264 @ 0x55b5ca140180] mmco: unref short failure
[h264 @ 0x55b5ca140180] mmco: unref short failure
09/17/2024 06:03:05 - INFO - __main__ -   current idx EDyva2crZas.40 from finetune_area returns wrong image/video, use 47057 instead.
[h264 @ 0x55b5aef46100] mmco: unref short failure
[h264 @ 0x55b5aef46100] mmco: unref short failure
[h264 @ 0x55b5b0839b40] mmco: unref short failure
[h264 @ 0x55b5b0839b40] mmco: unref short failure
 37%|███▋      | 1067/2910 [6:41:24<8:56:09, 17.45s/it][h264 @ 0x55b5cca7f0c0] mmco: unref short failure
[h264 @ 0x55b5cca7f0c0] mmco: unref short failure
[h264 @ 0x55b5cca7f0c0] mmco: unref short failure
[h264 @ 0x55b5cca7f0c0] mmco: unref short failure
[h264 @ 0x55e24ae25280] mmco: unref short failure
[h264 @ 0x55e24ae25280] mmco: unref short failure
 37%|███▋      | 1068/2910 [6:41:31<7:23:39, 14.45s/it][h264 @ 0x55e2406edc00] mmco: unref short failure
[h264 @ 0x55e2406edc00] mmco: unref short failure
 37%|███▋      | 1069/2910 [6:41:49<7:55:53, 15.51s/it][h264 @ 0x55b5c5e21300] mmco: unref short failure
[h264 @ 0x55b5c5e21300] mmco: unref short failure
[h264 @ 0x55e24c328b00] mmco: unref short failure
 37%|███▋      | 1070/2910 [6:41:54<6:22:17, 12.47s/it] 37%|███▋      | 1071/2910 [6:42:00<5:14:55, 10.28s/it][h264 @ 0x55a33277d680] mmco: unref short failure
[h264 @ 0x55a33277d680] mmco: unref short failure
[h264 @ 0x56075b644c00] mmco: unref short failure
[h264 @ 0x56075b644c00] mmco: unref short failure
[h264 @ 0x56075b644c00] mmco: unref short failure
[h264 @ 0x56075b644c00] mmco: unref short failure
 37%|███▋      | 1072/2910 [6:42:06<4:41:10,  9.18s/it] 37%|███▋      | 1073/2910 [6:42:11<4:04:51,  8.00s/it][h264 @ 0x55e23bb01400] mmco: unref short failure
[h264 @ 0x56074164fbc0] mmco: unref short failure
[h264 @ 0x56074164fbc0] mmco: unref short failure
[h264 @ 0x5607497b8e00] mmco: unref short failure
[h264 @ 0x5607497b8e00] mmco: unref short failure
[h264 @ 0x5607497b8e00] mmco: unref short failure
[h264 @ 0x5607497b8e00] mmco: unref short failure
[h264 @ 0x55b5b12bd000] mmco: unref short failure
[h264 @ 0x55b5b12bd000] mmco: unref short failure
[h264 @ 0x5607497b8e00] mmco: unref short failure
[h264 @ 0x5607497b8e00] mmco: unref short failure
[h264 @ 0x5607497b8e00] mmco: unref short failure
[h264 @ 0x5607497b8e00] mmco: unref short failure
[h264 @ 0x560741904480] mmco: unref short failure
[h264 @ 0x55a3180b1b40] mmco: unref short failure
[h264 @ 0x55a3180b1b40] mmco: unref short failure
[h264 @ 0x55e239e0d180] mmco: unref short failure
[h264 @ 0x55e239e0d180] mmco: unref short failure
[h264 @ 0x560756977f80] mmco: unref short failure
[h264 @ 0x560742a63c80] mmco: unref short failure
[h264 @ 0x55e2562a3ec0] mmco: unref short failure
[h264 @ 0x55e2562a3ec0] mmco: unref short failure
[h264 @ 0x560741c0bbc0] mmco: unref short failure
[h264 @ 0x560741c0bbc0] mmco: unref short failure
[h264 @ 0x56075ff60640] mmco: unref short failure
[h264 @ 0x56075ff60640] mmco: unref short failure
[h264 @ 0x56075ff60640] mmco: unref short failure
[h264 @ 0x56075ff60640] mmco: unref short failure
[h264 @ 0x55a3118dfd80] mmco: unref short failure
[h264 @ 0x55a3118dfd80] mmco: unref short failure
[h264 @ 0x55b5c0267380] mmco: unref short failure
[h264 @ 0x55e240d04b00] mmco: unref short failure
[h264 @ 0x55b5ca140180] mmco: unref short failure
[h264 @ 0x55b5ca140180] mmco: unref short failure
 37%|███▋      | 1074/2910 [6:43:46<17:18:09, 33.93s/it][h264 @ 0x55a3324cce40] mmco: unref short failure
[h264 @ 0x55b5ae281840] mmco: unref short failure
[h264 @ 0x55a32ddddc00] mmco: unref short failure
[h264 @ 0x55a32ddddc00] mmco: unref short failure
 37%|███▋      | 1075/2910 [6:43:55<13:31:28, 26.53s/it][h264 @ 0x55e252f75b80] mmco: unref short failure
 37%|███▋      | 1076/2910 [6:44:00<10:12:22, 20.03s/it][h264 @ 0x56075277c680] mmco: unref short failure
[h264 @ 0x56075277c680] mmco: unref short failure
[h264 @ 0x56075277c680] mmco: unref short failure
[h264 @ 0x55e23eee8340] mmco: unref short failure
[h264 @ 0x55b5a9ef4880] mmco: unref short failure
 37%|███▋      | 1077/2910 [6:44:22<10:30:01, 20.62s/it][h264 @ 0x560750b6ac80] mmco: unref short failure
[h264 @ 0x560750b6ac80] mmco: unref short failure
[h264 @ 0x55a330091500] mmco: unref short failure
[h264 @ 0x55a330091500] mmco: unref short failure
 37%|███▋      | 1078/2910 [6:44:27<8:09:55, 16.05s/it] [h264 @ 0x55a311cbbd00] mmco: unref short failure
 37%|███▋      | 1079/2910 [6:44:35<6:56:21, 13.64s/it][h264 @ 0x55b5c5e21300] mmco: unref short failure
[h264 @ 0x55b5c5e21300] mmco: unref short failure
 37%|███▋      | 1080/2910 [6:44:41<5:38:30, 11.10s/it][h264 @ 0x55e252f75b80] mmco: unref short failure
 37%|███▋      | 1081/2910 [6:44:46<4:44:57,  9.35s/it]09/17/2024 06:06:32 - INFO - __main__ -   current idx KPOxRziYDzs.2 from finetune_area returns wrong image/video, use 39168 instead.
[h264 @ 0x55b5c5e21300] mmco: unref short failure
[h264 @ 0x55e23eee8340] mmco: unref short failure
[h264 @ 0x55e23eee8340] mmco: unref short failure
[h264 @ 0x55e23eee8340] mmco: unref short failure
[h264 @ 0x55a32115f2c0] mmco: unref short failure
09/17/2024 06:06:38 - INFO - __main__ -   current idx JOgG5komufg.1 from finetune_area returns wrong image/video, use 71036 instead.
[h264 @ 0x55e2472b3140] mmco: unref short failure
[h264 @ 0x55e2472b3140] mmco: unref short failure
[h264 @ 0x55a30ebe2480] mmco: unref short failure
[h264 @ 0x55a31c220380] mmco: unref short failure
[h264 @ 0x55a31c220380] mmco: unref short failure
[h264 @ 0x55b5bbd80f40] mmco: unref short failure
[h264 @ 0x55a329dbdcc0] mmco: unref short failure
[h264 @ 0x55a329dbdcc0] mmco: unref short failure
[h264 @ 0x55a311e12d40] mmco: unref short failure
09/17/2024 06:07:41 - INFO - __main__ -   current idx BdXk2SoCZnM.55 from finetune_area returns wrong image/video, use 34045 instead.
[h264 @ 0x5607416dcd80] mmco: unref short failure
[h264 @ 0x5607416dcd80] mmco: unref short failure
[h264 @ 0x55a313e733c0] mmco: unref short failure
[h264 @ 0x55a3111e7b40] mmco: unref short failure
[h264 @ 0x55a3111e7b40] mmco: unref short failure
[h264 @ 0x5607526daac0] mmco: unref short failure
 37%|███▋      | 1082/2910 [6:46:20<17:36:41, 34.68s/it][h264 @ 0x55a32af8ea40] mmco: unref short failure
[h264 @ 0x55a32af8ea40] mmco: unref short failure
 37%|███▋      | 1083/2910 [6:46:25<13:12:31, 26.03s/it] 37%|███▋      | 1084/2910 [6:46:31<10:04:39, 19.87s/it][h264 @ 0x55b5bcf2be00] mmco: unref short failure
[h264 @ 0x55b5bcf2be00] mmco: unref short failure
 37%|███▋      | 1085/2910 [6:46:46<9:16:47, 18.31s/it] [h264 @ 0x56075b1040c0] mmco: unref short failure
[h264 @ 0x56075b1040c0] mmco: unref short failure
[h264 @ 0x56075b1040c0] mmco: unref short failure
09/17/2024 06:08:33 - INFO - __main__ -   current idx gRQlnvFSOjM.28 from finetune_area returns wrong image/video, use 81051 instead.
 37%|███▋      | 1086/2910 [6:46:51<7:20:39, 14.50s/it][h264 @ 0x55e247afdb00] mmco: unref short failure
 37%|███▋      | 1087/2910 [6:47:00<6:24:03, 12.64s/it][h264 @ 0x55b5c5c8aa40] mmco: unref short failure
[h264 @ 0x55b5c5c8aa40] mmco: unref short failure
[h264 @ 0x55a310d5e480] mmco: unref short failure
[h264 @ 0x5607414847c0] mmco: unref short failure
 37%|███▋      | 1088/2910 [6:47:17<7:05:39, 14.02s/it] 37%|███▋      | 1089/2910 [6:47:22<5:47:45, 11.46s/it][h264 @ 0x55b5b3833900] mmco: unref short failure
[h264 @ 0x55b5b3833900] mmco: unref short failure
[h264 @ 0x55e23bde9e80] mmco: unref short failure
[h264 @ 0x55e23bde9e80] mmco: unref short failure
[h264 @ 0x55e23bde9e80] mmco: unref short failure
[h264 @ 0x560747bdd500] mmco: unref short failure
[h264 @ 0x560747bdd500] mmco: unref short failure
[h264 @ 0x55a313404b40] mmco: unref short failure
[h264 @ 0x55a313404b40] mmco: unref short failure
[h264 @ 0x55b5c1bea580] mmco: unref short failure
[h264 @ 0x55b5c37e6ec0] mmco: unref short failure
[h264 @ 0x55b5c37e6ec0] mmco: unref short failure
[h264 @ 0x55e237829e00] mmco: unref short failure
[h264 @ 0x55e239257780] mmco: unref short failure
[h264 @ 0x55a3324cce40] mmco: unref short failure
[h264 @ 0x56074a1cccc0] mmco: unref short failure
[h264 @ 0x56074a1cccc0] mmco: unref short failure
[h264 @ 0x55b5ca140180] mmco: unref short failure
[h264 @ 0x55b5ca140180] mmco: unref short failure
[h264 @ 0x560759ead100] mmco: unref short failure
[h264 @ 0x560759ead100] mmco: unref short failure
[h264 @ 0x560759ead100] mmco: unref short failure
[h264 @ 0x560759ead100] mmco: unref short failure
[h264 @ 0x55b5c981e180] mmco: unref short failure
[h264 @ 0x55b5c981e180] mmco: unref short failure
[h264 @ 0x5607526daac0] mmco: unref short failure
[h264 @ 0x56075f66c580] mmco: unref short failure
[h264 @ 0x56075f66c580] mmco: unref short failure
[h264 @ 0x56075f66c580] mmco: unref short failure
[h264 @ 0x56075f66c580] mmco: unref short failure
[h264 @ 0x56075f66c580] mmco: unref short failure
[h264 @ 0x56075f66c580] mmco: unref short failure
[h264 @ 0x55b5b8204b80] mmco: unref short failure
[h264 @ 0x5607526daac0] mmco: unref short failure
[h264 @ 0x5607526daac0] mmco: unref short failure
09/17/2024 06:10:35 - INFO - __main__ -   current idx JLcL4VGOk3o.15 from finetune_area returns wrong image/video, use 148036 instead.
[h264 @ 0x55b5bd88a440] mmco: unref short failure
[h264 @ 0x55b5bd88a440] mmco: unref short failure
 37%|███▋      | 1090/2910 [6:48:51<17:30:10, 34.62s/it][h264 @ 0x55b5ae346d40] mmco: unref short failure
 37%|███▋      | 1091/2910 [6:48:56<13:01:12, 25.77s/it] 38%|███▊      | 1092/2910 [6:49:01<9:53:48, 19.60s/it] [h264 @ 0x55e243511ec0] mmco: unref short failure
[h264 @ 0x55e243511ec0] mmco: unref short failure
[h264 @ 0x55b5bd946d80] mmco: unref short failure
[h264 @ 0x55e25703be80] mmco: unref short failure
 38%|███▊      | 1093/2910 [6:49:11<8:26:26, 16.72s/it][h264 @ 0x55e23bde9e80] mmco: unref short failure
[h264 @ 0x55e23bde9e80] mmco: unref short failure
[h264 @ 0x55e239e0d180] mmco: unref short failure
[h264 @ 0x55e239e0d180] mmco: unref short failure
[h264 @ 0x55e239e0d180] mmco: unref short failure
[h264 @ 0x55e239e0d180] mmco: unref short failure
 38%|███▊      | 1094/2910 [6:49:16<6:41:05, 13.25s/it][h264 @ 0x55a31bd177c0] mmco: unref short failure
 38%|███▊      | 1095/2910 [6:49:30<6:46:04, 13.42s/it][h264 @ 0x55a325881200] mmco: unref short failure
[h264 @ 0x55a325881200] mmco: unref short failure
[h264 @ 0x56075ff60640] mmco: unref short failure
[h264 @ 0x55b5af2c55c0] mmco: unref short failure
[h264 @ 0x560741c0bbc0] mmco: unref short failure
[h264 @ 0x560741c0bbc0] mmco: unref short failure
[h264 @ 0x55e240f07d00] mmco: unref short failure
[h264 @ 0x55e240f07d00] mmco: unref short failure
 38%|███▊      | 1096/2910 [6:49:47<7:16:14, 14.43s/it] 38%|███▊      | 1097/2910 [6:49:53<5:55:45, 11.77s/it][h264 @ 0x55b5b0dc6980] mmco: unref short failure
[h264 @ 0x55b5b0dc6980] mmco: unref short failure
[h264 @ 0x55b5c56fedc0] mmco: unref short failure
[h264 @ 0x55b5c56fedc0] mmco: unref short failure
[h264 @ 0x55a317c458c0] mmco: unref short failure
[h264 @ 0x55a317c458c0] mmco: unref short failure
[h264 @ 0x55e238926740] mmco: unref short failure
[h264 @ 0x55a317c458c0] mmco: unref short failure
[h264 @ 0x55a317c458c0] mmco: unref short failure
[h264 @ 0x55a31bd177c0] mmco: unref short failure
[h264 @ 0x55e247c2e440] mmco: unref short failure
[h264 @ 0x55e247c2e440] mmco: unref short failure
[h264 @ 0x56075b20d100] mmco: unref short failure
[h264 @ 0x5607563f4180] mmco: unref short failure
[h264 @ 0x5607563f4180] mmco: unref short failure
09/17/2024 06:12:19 - INFO - __main__ -   current idx kZsPqzB36mk.13 from finetune_area returns wrong image/video, use 48396 instead.
[h264 @ 0x55a325881200] mmco: unref short failure
[h264 @ 0x55a325881200] mmco: unref short failure
[h264 @ 0x560754b48080] mmco: unref short failure
[h264 @ 0x560754b48080] mmco: unref short failure
[h264 @ 0x55b5b39853c0] mmco: unref short failure
[h264 @ 0x55b5b39853c0] mmco: unref short failure
[h264 @ 0x560749facfc0] mmco: unref short failure
[h264 @ 0x55a311cbbd00] mmco: unref short failure
[h264 @ 0x55a311cbbd00] mmco: unref short failure
[h264 @ 0x55a311cbbd00] mmco: unref short failure
[h264 @ 0x55a311cbbd00] mmco: unref short failure
[h264 @ 0x55e23e3be580] mmco: unref short failure
[h264 @ 0x55e23e3be580] mmco: unref short failure
[h264 @ 0x55e25c34ca80] mmco: unref short failure
[h264 @ 0x55b5aed77040] mmco: unref short failure
[h264 @ 0x55b5aed77040] mmco: unref short failure
[h264 @ 0x55a325a19f80] mmco: unref short failure
[h264 @ 0x55a325a19f80] mmco: unref short failure
[h264 @ 0x55a325a19f80] mmco: unref short failure
[h264 @ 0x55a325a19f80] mmco: unref short failure
[h264 @ 0x55a310d5e480] mmco: unref short failure
 38%|███▊      | 1098/2910 [6:51:21<17:26:07, 34.64s/it] 38%|███▊      | 1099/2910 [6:51:31<13:44:37, 27.32s/it]09/17/2024 06:13:17 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 06:13:17 - INFO - __main__ -   start running ret%tva validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55b5b32d9380] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x560751d91780] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55b5b841c400] mmco: unref short failure
[h264 @ 0x55b5b841c400] mmco: unref short failure
[h264 @ 0x56075d2ec040] mmco: unref short failure
[h264 @ 0x56075d2ec040] mmco: unref short failure
[h264 @ 0x55a324309940] mmco: unref short failure
[h264 @ 0x5607526daac0] mmco: unref short failure
[h264 @ 0x56074d448dc0] mmco: unref short failure
[h264 @ 0x56074d448dc0] mmco: unref short failure
[h264 @ 0x55a3278a16c0] mmco: unref short failure
[h264 @ 0x55b5b667dd00] mmco: unref short failure
[h264 @ 0x55b5bdb25280] mmco: unref short failure
[h264 @ 0x55b5bdb25280] mmco: unref short failure
09/17/2024 06:15:31 - INFO - __main__ -   current idx c0na5aaBMBE.58 from finetune_area returns wrong image/video, use 32605 instead.
[h264 @ 0x55e23e2fe880] mmco: unref short failure
[h264 @ 0x55e250dcd700] mmco: unref short failure
[h264 @ 0x55e250dcd700] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:01<07:14,  1.98s/it][A[h264 @ 0x55e25434bf80] mmco: unref short failure
[h264 @ 0x55e25434bf80] mmco: unref short failure

  1%|          | 2/221 [00:02<04:23,  1.21s/it][A
  1%|▏         | 3/221 [00:02<02:36,  1.39it/s][A
  2%|▏         | 4/221 [00:02<01:43,  2.10it/s][A
  2%|▏         | 5/221 [00:02<01:13,  2.92it/s][A
  3%|▎         | 6/221 [00:03<00:56,  3.78it/s][A
  3%|▎         | 7/221 [00:03<00:54,  3.92it/s][A
  4%|▎         | 8/221 [00:03<01:20,  2.65it/s][A
  4%|▍         | 9/221 [00:04<01:08,  3.11it/s][A
  5%|▍         | 10/221 [00:04<01:11,  2.95it/s][A
  5%|▌         | 12/221 [00:05<01:02,  3.32it/s][A
  6%|▌         | 13/221 [00:05<00:54,  3.79it/s][A
  6%|▋         | 14/221 [00:06<02:03,  1.68it/s][A
  7%|▋         | 15/221 [00:06<01:43,  1.99it/s][A
  7%|▋         | 16/221 [00:07<01:31,  2.24it/s][A
  8%|▊         | 17/221 [00:07<01:18,  2.61it/s][A
  8%|▊         | 18/221 [00:07<01:12,  2.78it/s][A
  9%|▊         | 19/221 [00:08<01:01,  3.26it/s][A
  9%|▉         | 20/221 [00:08<00:52,  3.86it/s][A[h264 @ 0x560755ff3000] mmco: unref short failure

 10%|▉         | 21/221 [00:08<00:45,  4.42it/s][A
 10%|▉         | 22/221 [00:08<00:44,  4.49it/s][A
 10%|█         | 23/221 [00:08<00:37,  5.32it/s][A
 11%|█         | 24/221 [00:08<00:32,  6.06it/s][A
 11%|█▏        | 25/221 [00:08<00:33,  5.86it/s][A
 12%|█▏        | 26/221 [00:09<00:38,  5.05it/s][A
 12%|█▏        | 27/221 [00:09<00:35,  5.47it/s][A
 13%|█▎        | 28/221 [00:09<00:53,  3.58it/s][A
 13%|█▎        | 29/221 [00:10<00:48,  3.92it/s][A
 14%|█▎        | 30/221 [00:10<00:45,  4.21it/s][A
 14%|█▍        | 31/221 [00:10<00:47,  4.01it/s][A
 14%|█▍        | 32/221 [00:10<00:41,  4.56it/s][A
 15%|█▍        | 33/221 [00:11<00:58,  3.22it/s][A
 15%|█▌        | 34/221 [00:11<00:48,  3.83it/s][A
 16%|█▌        | 35/221 [00:11<00:43,  4.28it/s][A
 16%|█▋        | 36/221 [00:11<00:49,  3.77it/s][A[h264 @ 0x55e247c996c0] mmco: unref short failure
[h264 @ 0x55e247c996c0] mmco: unref short failure
[h264 @ 0x55b5b630f3c0] mmco: unref short failure
[h264 @ 0x55b5b630f3c0] mmco: unref short failure
[h264 @ 0x55e247c996c0] mmco: unref short failure
[h264 @ 0x55e247c996c0] mmco: unref short failure

 17%|█▋        | 37/221 [00:12<01:05,  2.82it/s][A
 17%|█▋        | 38/221 [00:12<01:06,  2.75it/s][A
 18%|█▊        | 39/221 [00:12<00:52,  3.47it/s][A
 18%|█▊        | 40/221 [00:13<00:50,  3.59it/s][A
 19%|█▊        | 41/221 [00:13<00:41,  4.38it/s][A
 19%|█▉        | 42/221 [00:13<00:50,  3.56it/s][A
 19%|█▉        | 43/221 [00:13<00:49,  3.60it/s][A
 20%|█▉        | 44/221 [00:14<00:43,  4.09it/s][A
 20%|██        | 45/221 [00:14<01:14,  2.37it/s][A[h264 @ 0x55b5c56fedc0] mmco: unref short failure

 21%|██        | 46/221 [00:15<01:28,  1.97it/s][A
 21%|██▏       | 47/221 [00:16<01:58,  1.47it/s][A
 22%|██▏       | 48/221 [00:16<01:33,  1.85it/s][A
 22%|██▏       | 49/221 [00:17<01:21,  2.11it/s][A
 23%|██▎       | 50/221 [00:17<01:02,  2.75it/s][A
 23%|██▎       | 51/221 [00:17<00:49,  3.42it/s][A
 24%|██▎       | 52/221 [00:17<00:41,  4.10it/s][A
 24%|██▍       | 53/221 [00:17<00:35,  4.75it/s][A
 24%|██▍       | 54/221 [00:19<01:29,  1.86it/s][A
 25%|██▍       | 55/221 [00:19<01:31,  1.80it/s][A
 25%|██▌       | 56/221 [00:19<01:15,  2.19it/s][A
 26%|██▌       | 57/221 [00:20<01:04,  2.56it/s][A
 26%|██▌       | 58/221 [00:20<00:53,  3.07it/s][A
 27%|██▋       | 59/221 [00:20<00:45,  3.56it/s][A
 27%|██▋       | 60/221 [00:20<00:51,  3.11it/s][A
 28%|██▊       | 61/221 [00:21<00:45,  3.54it/s][A
 28%|██▊       | 62/221 [00:21<00:42,  3.71it/s][A
 29%|██▊       | 63/221 [00:21<00:38,  4.06it/s][A
 29%|██▉       | 64/221 [00:21<00:34,  4.51it/s][A
 29%|██▉       | 65/221 [00:21<00:31,  4.99it/s][A
 30%|██▉       | 66/221 [00:22<00:41,  3.77it/s][A
 30%|███       | 67/221 [00:22<00:42,  3.62it/s][A
 31%|███       | 68/221 [00:22<00:35,  4.34it/s][A
 31%|███       | 69/221 [00:23<00:56,  2.70it/s][A
 32%|███▏      | 70/221 [00:23<00:44,  3.39it/s][A
 32%|███▏      | 71/221 [00:25<01:55,  1.30it/s][A
 33%|███▎      | 72/221 [00:25<01:26,  1.72it/s][A
 33%|███▎      | 73/221 [00:25<01:12,  2.03it/s][A
 33%|███▎      | 74/221 [00:25<00:58,  2.51it/s][A
 34%|███▍      | 75/221 [00:26<00:57,  2.52it/s][A
 34%|███▍      | 76/221 [00:26<00:48,  2.99it/s][A
 35%|███▍      | 77/221 [00:26<00:42,  3.40it/s][A
 35%|███▌      | 78/221 [00:27<00:42,  3.40it/s][A
 36%|███▌      | 79/221 [00:27<01:01,  2.32it/s][A
 36%|███▌      | 80/221 [00:27<00:48,  2.93it/s][A
 37%|███▋      | 81/221 [00:28<00:43,  3.21it/s][A
 37%|███▋      | 82/221 [00:28<00:40,  3.42it/s][A
 38%|███▊      | 83/221 [00:28<00:36,  3.73it/s][A
 38%|███▊      | 84/221 [00:28<00:32,  4.25it/s][A
 38%|███▊      | 85/221 [00:28<00:27,  4.94it/s][A
 39%|███▉      | 86/221 [00:29<00:25,  5.36it/s][A
 39%|███▉      | 87/221 [00:29<00:42,  3.17it/s][A
 40%|███▉      | 88/221 [00:29<00:40,  3.26it/s][A[h264 @ 0x560759130ac0] mmco: unref short failure

 40%|████      | 89/221 [00:32<02:22,  1.08s/it][A
 41%|████      | 90/221 [00:33<01:50,  1.18it/s][A
 41%|████      | 91/221 [00:33<01:20,  1.61it/s][A
 42%|████▏     | 92/221 [00:33<01:02,  2.07it/s][A
 42%|████▏     | 93/221 [00:33<01:06,  1.93it/s][A
 43%|████▎     | 94/221 [00:34<00:58,  2.17it/s][A
 43%|████▎     | 95/221 [00:34<00:46,  2.71it/s][A[h264 @ 0x55e24e7be340] mmco: unref short failure

 43%|████▎     | 96/221 [00:34<00:46,  2.71it/s][A
 44%|████▍     | 97/221 [00:35<00:41,  3.00it/s][A
 44%|████▍     | 98/221 [00:35<00:40,  3.03it/s][A
 45%|████▍     | 99/221 [00:35<00:32,  3.75it/s][A
 45%|████▌     | 100/221 [00:35<00:29,  4.09it/s][A
 46%|████▌     | 101/221 [00:35<00:25,  4.62it/s][A[h264 @ 0x55e238926740] mmco: unref short failure
[h264 @ 0x55e238926740] mmco: unref short failure

 46%|████▌     | 102/221 [00:36<00:31,  3.83it/s][A
 47%|████▋     | 103/221 [00:36<00:26,  4.38it/s][A
 48%|████▊     | 105/221 [00:36<00:22,  5.14it/s][A
 48%|████▊     | 106/221 [00:37<00:43,  2.66it/s][A
 48%|████▊     | 107/221 [00:37<00:34,  3.28it/s][A
 49%|████▉     | 108/221 [00:37<00:31,  3.55it/s][A[h264 @ 0x55b5b7bce880] mmco: unref short failure

 49%|████▉     | 109/221 [00:38<00:34,  3.22it/s][A
 50%|████▉     | 110/221 [00:38<00:30,  3.67it/s][A
 50%|█████     | 111/221 [00:39<00:37,  2.96it/s][A
 51%|█████     | 112/221 [00:39<00:34,  3.19it/s][A
 51%|█████     | 113/221 [00:39<00:36,  2.96it/s][A
 52%|█████▏    | 114/221 [00:39<00:33,  3.21it/s][A
 52%|█████▏    | 115/221 [00:40<00:34,  3.09it/s][A
 52%|█████▏    | 116/221 [00:45<03:00,  1.72s/it][A
 53%|█████▎    | 117/221 [00:45<02:13,  1.28s/it][A
 53%|█████▎    | 118/221 [00:45<01:44,  1.02s/it][A
 54%|█████▍    | 119/221 [00:46<01:18,  1.30it/s][A
 54%|█████▍    | 120/221 [00:46<01:00,  1.66it/s][A
 55%|█████▍    | 121/221 [00:46<00:46,  2.16it/s][A
 55%|█████▌    | 122/221 [00:46<00:38,  2.56it/s][A
 56%|█████▌    | 123/221 [00:46<00:32,  2.98it/s][A
 56%|█████▌    | 124/221 [00:47<00:29,  3.33it/s][A
 57%|█████▋    | 125/221 [00:47<00:25,  3.70it/s][A
 57%|█████▋    | 126/221 [00:47<00:36,  2.62it/s][A
 57%|█████▋    | 127/221 [00:48<00:37,  2.47it/s][A
 58%|█████▊    | 128/221 [00:48<00:37,  2.50it/s][A
 58%|█████▊    | 129/221 [00:49<00:34,  2.68it/s][A
 59%|█████▉    | 130/221 [00:49<00:29,  3.04it/s][A
 59%|█████▉    | 131/221 [00:49<00:23,  3.77it/s][A
 60%|█████▉    | 132/221 [00:49<00:22,  4.00it/s][A
 60%|██████    | 133/221 [00:50<00:28,  3.07it/s][A
 61%|██████    | 134/221 [00:50<00:27,  3.20it/s][A
 61%|██████    | 135/221 [00:50<00:32,  2.61it/s][A
 62%|██████▏   | 136/221 [00:51<00:35,  2.42it/s][A
 62%|██████▏   | 137/221 [00:51<00:29,  2.89it/s][A[h264 @ 0x56074c32ef40] mmco: unref short failure
[h264 @ 0x56074c32ef40] mmco: unref short failure

 62%|██████▏   | 138/221 [00:52<00:31,  2.65it/s][A
 63%|██████▎   | 139/221 [00:52<00:31,  2.59it/s][A
 63%|██████▎   | 140/221 [00:52<00:32,  2.49it/s][A
 64%|██████▍   | 141/221 [00:53<00:27,  2.95it/s][A
 64%|██████▍   | 142/221 [00:53<00:32,  2.47it/s][A
 65%|██████▍   | 143/221 [00:54<00:33,  2.30it/s][A
 65%|██████▌   | 144/221 [00:54<00:27,  2.84it/s][A
 66%|██████▌   | 145/221 [00:54<00:21,  3.62it/s][A
 66%|██████▌   | 146/221 [00:54<00:16,  4.46it/s][A
 67%|██████▋   | 147/221 [00:54<00:15,  4.83it/s][A
 67%|██████▋   | 148/221 [00:55<00:17,  4.21it/s][A
 68%|██████▊   | 150/221 [00:55<00:13,  5.34it/s][A
 68%|██████▊   | 151/221 [00:56<00:25,  2.74it/s][A
 69%|██████▉   | 152/221 [00:56<00:25,  2.72it/s][A
 69%|██████▉   | 153/221 [00:56<00:23,  2.90it/s][A
 70%|██████▉   | 154/221 [00:57<00:25,  2.67it/s][A
 70%|███████   | 155/221 [00:57<00:21,  3.11it/s][A
 71%|███████   | 156/221 [00:57<00:17,  3.76it/s][A
 71%|███████   | 157/221 [00:59<00:50,  1.28it/s][A
 71%|███████▏  | 158/221 [01:00<00:40,  1.57it/s][A
 72%|███████▏  | 159/221 [01:00<00:34,  1.81it/s][A
 72%|███████▏  | 160/221 [01:00<00:27,  2.26it/s][A
 73%|███████▎  | 161/221 [01:00<00:20,  2.91it/s][A
 73%|███████▎  | 162/221 [01:00<00:17,  3.43it/s][A
 74%|███████▍  | 163/221 [01:01<00:16,  3.62it/s][A
 74%|███████▍  | 164/221 [01:01<00:13,  4.16it/s][A
 75%|███████▍  | 165/221 [01:01<00:11,  4.89it/s][A
 75%|███████▌  | 166/221 [01:01<00:15,  3.53it/s][A
 76%|███████▌  | 167/221 [01:01<00:12,  4.32it/s][A
 76%|███████▌  | 168/221 [01:04<00:44,  1.20it/s][A
 76%|███████▋  | 169/221 [01:04<00:34,  1.50it/s][A
 77%|███████▋  | 170/221 [01:04<00:28,  1.80it/s][A
 77%|███████▋  | 171/221 [01:04<00:22,  2.19it/s][A
 78%|███████▊  | 172/221 [01:05<00:19,  2.53it/s][A
 79%|███████▊  | 174/221 [01:05<00:11,  4.05it/s][A
 79%|███████▉  | 175/221 [01:05<00:10,  4.29it/s][A
 80%|███████▉  | 176/221 [01:05<00:10,  4.24it/s][A
 80%|████████  | 177/221 [01:05<00:08,  5.02it/s][A
 81%|████████  | 178/221 [01:06<00:09,  4.31it/s][A
 81%|████████  | 179/221 [01:06<00:13,  3.02it/s][A
 82%|████████▏ | 181/221 [01:07<00:10,  3.71it/s][A
 82%|████████▏ | 182/221 [01:07<00:09,  3.93it/s][A
 83%|████████▎ | 183/221 [01:07<00:08,  4.31it/s][A
 83%|████████▎ | 184/221 [01:07<00:09,  3.90it/s][A
 84%|████████▎ | 185/221 [01:08<00:08,  4.22it/s][A
 84%|████████▍ | 186/221 [01:08<00:09,  3.67it/s][A
 85%|████████▍ | 187/221 [01:08<00:07,  4.30it/s][A
 85%|████████▌ | 188/221 [01:08<00:08,  4.11it/s][A
 86%|████████▌ | 189/221 [01:09<00:07,  4.07it/s][A[h264 @ 0x56075686eb00] mmco: unref short failure

 86%|████████▌ | 190/221 [01:09<00:07,  4.08it/s][A
 87%|████████▋ | 192/221 [01:09<00:06,  4.81it/s][A
 87%|████████▋ | 193/221 [01:09<00:05,  5.48it/s][A[h264 @ 0x55a313e733c0] mmco: unref short failure
[h264 @ 0x55a313e733c0] mmco: unref short failure

 88%|████████▊ | 194/221 [01:10<00:11,  2.31it/s][A
 88%|████████▊ | 195/221 [01:11<00:09,  2.70it/s][A
 89%|████████▉ | 197/221 [01:11<00:06,  3.94it/s][A
 90%|████████▉ | 198/221 [01:11<00:05,  4.13it/s][A
 90%|█████████ | 199/221 [01:11<00:05,  4.35it/s][A09/17/2024 06:16:50 - INFO - __main__ -   current idx HnCSd-QjKvs.136 from finetune_area returns wrong image/video, use 95869 instead.

 90%|█████████ | 200/221 [01:11<00:05,  4.05it/s][A
 91%|█████████ | 201/221 [01:12<00:04,  4.32it/s][A
 91%|█████████▏| 202/221 [01:12<00:03,  4.84it/s][A
 92%|█████████▏| 203/221 [01:12<00:03,  5.53it/s][A
 93%|█████████▎| 205/221 [01:12<00:02,  7.45it/s][A
 93%|█████████▎| 206/221 [01:13<00:03,  4.48it/s][A
 94%|█████████▍| 208/221 [01:13<00:02,  5.89it/s][A
 95%|█████████▌| 210/221 [01:13<00:01,  7.92it/s][A
 96%|█████████▌| 212/221 [01:13<00:01,  5.44it/s][A
 97%|█████████▋| 214/221 [01:14<00:01,  4.08it/s][A
 97%|█████████▋| 215/221 [01:14<00:01,  4.06it/s][A
 98%|█████████▊| 216/221 [01:15<00:01,  4.08it/s][A
 98%|█████████▊| 217/221 [01:16<00:01,  2.42it/s][A
 99%|█████████▊| 218/221 [01:16<00:01,  2.55it/s][A
 99%|█████████▉| 219/221 [01:16<00:00,  2.93it/s][A
100%|█████████▉| 220/221 [01:21<00:01,  1.51s/it][A
100%|██████████| 221/221 [01:21<00:00,  1.13s/it][A100%|██████████| 221/221 [01:21<00:00,  2.71it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:04,  3.41it/s][A
  1%|          | 2/221 [00:00<01:04,  3.41it/s][A
  1%|▏         | 3/221 [00:00<01:05,  3.35it/s][A
  2%|▏         | 4/221 [00:01<01:04,  3.36it/s][A
  2%|▏         | 5/221 [00:01<01:03,  3.38it/s][A
  3%|▎         | 6/221 [00:01<01:03,  3.38it/s][A
  3%|▎         | 7/221 [00:02<01:03,  3.36it/s][A
  4%|▎         | 8/221 [00:02<01:03,  3.37it/s][A
  4%|▍         | 9/221 [00:02<01:03,  3.36it/s][A
  5%|▍         | 10/221 [00:02<01:03,  3.34it/s][A
  5%|▍         | 11/221 [00:03<01:03,  3.29it/s][A
  5%|▌         | 12/221 [00:03<01:02,  3.33it/s][A[h264 @ 0x55a32dbcfe40] mmco: unref short failure
[h264 @ 0x55a32dbcfe40] mmco: unref short failure

  6%|▌         | 13/221 [00:03<01:02,  3.35it/s][A
  6%|▋         | 14/221 [00:04<01:01,  3.37it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.35it/s][A
  7%|▋         | 16/221 [00:04<01:00,  3.37it/s][A
  8%|▊         | 17/221 [00:05<01:00,  3.38it/s][A
  8%|▊         | 18/221 [00:05<01:01,  3.33it/s][A
  9%|▊         | 19/221 [00:05<01:00,  3.34it/s][A
  9%|▉         | 20/221 [00:05<01:01,  3.28it/s][A
 10%|▉         | 21/221 [00:06<01:01,  3.27it/s][A
 10%|▉         | 22/221 [00:06<01:00,  3.31it/s][A
 10%|█         | 23/221 [00:06<00:59,  3.32it/s][A
 11%|█         | 24/221 [00:07<01:00,  3.28it/s][A
 11%|█▏        | 25/221 [00:07<00:59,  3.31it/s][A
 12%|█▏        | 26/221 [00:07<00:59,  3.30it/s][A
 12%|█▏        | 27/221 [00:08<00:58,  3.30it/s][A
 13%|█▎        | 28/221 [00:08<00:58,  3.32it/s][A
 13%|█▎        | 29/221 [00:08<01:00,  3.20it/s][A
 14%|█▎        | 30/221 [00:09<00:59,  3.23it/s][A
 14%|█▍        | 31/221 [00:09<00:57,  3.28it/s][A
 14%|█▍        | 32/221 [00:09<00:56,  3.32it/s][A[h264 @ 0x55b5c2cb9340] mmco: unref short failure
[h264 @ 0x55b5c2cb9340] mmco: unref short failure

 15%|█▍        | 33/221 [00:09<00:56,  3.34it/s][A
 15%|█▌        | 34/221 [00:10<00:56,  3.31it/s][A
 16%|█▌        | 35/221 [00:10<00:55,  3.34it/s][A
 16%|█▋        | 36/221 [00:10<00:55,  3.35it/s][A
 17%|█▋        | 37/221 [00:11<00:54,  3.37it/s][A
 17%|█▋        | 38/221 [00:11<00:54,  3.37it/s][A[h264 @ 0x55b5b2beeb40] mmco: unref short failure
[h264 @ 0x55b5b2beeb40] mmco: unref short failure

 18%|█▊        | 39/221 [00:11<00:53,  3.38it/s][A
 18%|█▊        | 40/221 [00:12<00:53,  3.39it/s][A
 19%|█▊        | 41/221 [00:12<00:53,  3.35it/s][A
 19%|█▉        | 42/221 [00:12<00:53,  3.35it/s][A
 19%|█▉        | 43/221 [00:12<00:52,  3.37it/s][A
 20%|█▉        | 44/221 [00:13<00:53,  3.33it/s][A
 20%|██        | 45/221 [00:13<00:53,  3.26it/s][A
 21%|██        | 46/221 [00:13<00:53,  3.27it/s][A
 21%|██▏       | 47/221 [00:14<00:53,  3.24it/s][A
 22%|██▏       | 48/221 [00:14<00:52,  3.28it/s][A
 22%|██▏       | 49/221 [00:14<00:52,  3.28it/s][A
 23%|██▎       | 50/221 [00:15<00:51,  3.30it/s][A
 23%|██▎       | 51/221 [00:15<00:51,  3.33it/s][A
 24%|██▎       | 52/221 [00:15<00:51,  3.27it/s][A[h264 @ 0x56075ebf5c40] mmco: unref short failure
[h264 @ 0x56075ebf5c40] mmco: unref short failure

 24%|██▍       | 53/221 [00:15<00:50,  3.31it/s][A[h264 @ 0x56075ebf5c40] mmco: unref short failure
[h264 @ 0x56075ebf5c40] mmco: unref short failure

 24%|██▍       | 54/221 [00:16<00:50,  3.33it/s][A
 25%|██▍       | 55/221 [00:16<00:49,  3.35it/s][A
 25%|██▌       | 56/221 [00:16<00:49,  3.35it/s][A
 26%|██▌       | 57/221 [00:17<00:48,  3.37it/s][A
 26%|██▌       | 58/221 [00:17<00:48,  3.38it/s][A[mov,mp4,m4a,3gp,3g2,mj2 @ 0x55a316d9de80] moov atom not found

 27%|██▋       | 59/221 [00:17<00:48,  3.37it/s][A
 27%|██▋       | 60/221 [00:18<00:47,  3.36it/s][A
 28%|██▊       | 61/221 [00:18<00:47,  3.36it/s][A
 28%|██▊       | 62/221 [00:18<00:47,  3.37it/s][A
 29%|██▊       | 63/221 [00:18<00:46,  3.38it/s][A
 29%|██▉       | 64/221 [00:19<00:46,  3.39it/s][A
 29%|██▉       | 65/221 [00:19<00:46,  3.39it/s][A
 30%|██▉       | 66/221 [00:19<00:45,  3.39it/s][A
 30%|███       | 67/221 [00:20<00:45,  3.40it/s][A
 31%|███       | 68/221 [00:20<00:45,  3.40it/s][A
 31%|███       | 69/221 [00:20<00:44,  3.40it/s][A
 32%|███▏      | 70/221 [00:20<00:44,  3.40it/s][A[h264 @ 0x55b5c3da7a80] mmco: unref short failure
[h264 @ 0x55b5c3da7a80] mmco: unref short failure
[h264 @ 0x55b5c3da7a80] mmco: unref short failure
[h264 @ 0x55b5c3da7a80] mmco: unref short failure

 32%|███▏      | 71/221 [00:21<00:44,  3.41it/s][A
 33%|███▎      | 72/221 [00:21<00:43,  3.40it/s][A
 33%|███▎      | 73/221 [00:21<00:43,  3.40it/s][A
 33%|███▎      | 74/221 [00:22<00:43,  3.40it/s][A
 34%|███▍      | 75/221 [00:22<00:42,  3.41it/s][A
 34%|███▍      | 76/221 [00:22<00:42,  3.41it/s][A
 35%|███▍      | 77/221 [00:23<00:42,  3.41it/s][A
 35%|███▌      | 78/221 [00:23<00:41,  3.41it/s][A
 36%|███▌      | 79/221 [00:23<00:41,  3.41it/s][A
 36%|███▌      | 80/221 [00:23<00:41,  3.41it/s][A
 37%|███▋      | 81/221 [00:24<00:41,  3.41it/s][A
 37%|███▋      | 82/221 [00:24<00:40,  3.41it/s][A
 38%|███▊      | 83/221 [00:24<00:40,  3.41it/s][A
 38%|███▊      | 84/221 [00:25<00:40,  3.41it/s][A
 38%|███▊      | 85/221 [00:25<00:39,  3.41it/s][A
 39%|███▉      | 86/221 [00:25<00:39,  3.41it/s][A
 39%|███▉      | 87/221 [00:25<00:39,  3.42it/s][A
 40%|███▉      | 88/221 [00:26<00:38,  3.42it/s][A
 40%|████      | 89/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 90/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 91/221 [00:27<00:38,  3.42it/s][A
 42%|████▏     | 92/221 [00:27<00:37,  3.42it/s][A
 42%|████▏     | 93/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 94/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 95/221 [00:28<00:36,  3.42it/s][A
 43%|████▎     | 96/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 97/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 98/221 [00:29<00:35,  3.42it/s][A
 45%|████▍     | 99/221 [00:29<00:35,  3.42it/s][A
 45%|████▌     | 100/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 101/221 [00:30<00:35,  3.42it/s][A
 46%|████▌     | 102/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 104/221 [00:30<00:34,  3.42it/s][A
 48%|████▊     | 105/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 107/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 108/221 [00:32<00:33,  3.42it/s][A
 49%|████▉     | 109/221 [00:32<00:32,  3.42it/s][A
 50%|████▉     | 110/221 [00:32<00:32,  3.42it/s][A
 50%|█████     | 111/221 [00:32<00:32,  3.42it/s][A
 51%|█████     | 112/221 [00:33<00:31,  3.42it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 114/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:34<00:30,  3.42it/s][A
 52%|█████▏    | 116/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:35<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:35<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:35<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:37<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:38<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:39<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:39<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:40<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:41<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:42<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:44<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:45<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:45<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:46<00:18,  3.42it/s][A
 71%|███████   | 157/221 [00:46<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:47<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:48<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:48<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:49<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:49<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:49<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:50<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:51<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:51<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:52<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:54<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:54<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:55<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:56<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:57<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:57<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:58<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:03<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.42it/s][A100%|██████████| 221/221 [01:05<00:00,  3.39it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:30,  7.16it/s][A
  1%|          | 2/221 [00:00<00:42,  5.13it/s][A
  1%|▏         | 3/221 [00:00<01:01,  3.56it/s][A
  2%|▏         | 4/221 [00:00<00:54,  3.96it/s][A
  2%|▏         | 5/221 [00:01<00:54,  3.95it/s][A
  3%|▎         | 7/221 [00:01<00:50,  4.24it/s][A
  4%|▎         | 8/221 [00:02<00:58,  3.64it/s][A
  4%|▍         | 9/221 [00:02<01:00,  3.49it/s][A
  5%|▍         | 10/221 [00:02<00:53,  3.97it/s][A
  5%|▍         | 11/221 [00:02<00:52,  4.03it/s][A
  5%|▌         | 12/221 [00:02<00:47,  4.42it/s][A
  6%|▌         | 13/221 [00:03<01:20,  2.57it/s][A
  6%|▋         | 14/221 [00:03<01:09,  2.98it/s][A
  7%|▋         | 15/221 [00:04<01:12,  2.84it/s][A
  7%|▋         | 16/221 [00:04<01:28,  2.31it/s][A
  8%|▊         | 17/221 [00:05<01:21,  2.50it/s][A
  8%|▊         | 18/221 [00:05<01:11,  2.86it/s][A
  9%|▉         | 20/221 [00:05<00:52,  3.79it/s][A
 10%|▉         | 21/221 [00:06<00:50,  3.94it/s][A
 10%|▉         | 22/221 [00:06<00:44,  4.46it/s][A
 10%|█         | 23/221 [00:06<00:39,  5.01it/s][A
 11%|█         | 24/221 [00:06<00:36,  5.39it/s][A
 11%|█▏        | 25/221 [00:06<00:51,  3.80it/s][A
 12%|█▏        | 26/221 [00:07<00:49,  3.97it/s][A
 12%|█▏        | 27/221 [00:07<00:49,  3.92it/s][A
 13%|█▎        | 28/221 [00:07<00:47,  4.02it/s][A
 13%|█▎        | 29/221 [00:07<00:52,  3.64it/s][A
 14%|█▎        | 30/221 [00:08<01:04,  2.96it/s][A
 14%|█▍        | 31/221 [00:08<01:06,  2.85it/s][A
 14%|█▍        | 32/221 [00:09<01:05,  2.87it/s][A
 15%|█▍        | 33/221 [00:09<01:08,  2.75it/s][A
 15%|█▌        | 34/221 [00:10<01:29,  2.09it/s][A
 16%|█▌        | 35/221 [00:10<01:13,  2.53it/s][A
 16%|█▋        | 36/221 [00:10<01:10,  2.63it/s][A
 17%|█▋        | 37/221 [00:11<00:58,  3.13it/s][A
 17%|█▋        | 38/221 [00:11<00:56,  3.23it/s][A
 18%|█▊        | 39/221 [00:11<00:49,  3.70it/s][A
 18%|█▊        | 40/221 [00:11<00:48,  3.73it/s][A
 19%|█▊        | 41/221 [00:12<00:52,  3.45it/s][A
 19%|█▉        | 42/221 [00:12<00:45,  3.93it/s][A
 19%|█▉        | 43/221 [00:12<00:42,  4.23it/s][A
 20%|█▉        | 44/221 [00:12<00:43,  4.11it/s][A
 20%|██        | 45/221 [00:13<00:49,  3.53it/s][A
 21%|██        | 46/221 [00:13<00:49,  3.53it/s][A
 21%|██▏       | 47/221 [00:13<00:43,  4.01it/s][A
 22%|██▏       | 48/221 [00:13<00:36,  4.78it/s][A
 22%|██▏       | 49/221 [00:13<00:31,  5.40it/s][A
 23%|██▎       | 50/221 [00:14<00:41,  4.12it/s][A
 23%|██▎       | 51/221 [00:14<00:45,  3.75it/s][A
 24%|██▎       | 52/221 [00:14<00:43,  3.86it/s][A
 24%|██▍       | 53/221 [00:15<00:54,  3.06it/s][A
 24%|██▍       | 54/221 [00:15<00:48,  3.43it/s][A
 25%|██▍       | 55/221 [00:15<00:58,  2.84it/s][A
 25%|██▌       | 56/221 [00:16<00:54,  3.04it/s][A
 26%|██▌       | 57/221 [00:16<00:49,  3.28it/s][A
 26%|██▌       | 58/221 [00:16<00:51,  3.15it/s][A
 27%|██▋       | 59/221 [00:17<00:48,  3.35it/s][A
 27%|██▋       | 60/221 [00:17<00:41,  3.88it/s][A
 28%|██▊       | 61/221 [00:17<00:38,  4.19it/s][A
 28%|██▊       | 62/221 [00:17<00:41,  3.86it/s][A
 29%|██▉       | 64/221 [00:18<00:36,  4.30it/s][A
 29%|██▉       | 65/221 [00:18<00:36,  4.23it/s][A
 30%|██▉       | 66/221 [00:18<00:38,  4.04it/s][A
 30%|███       | 67/221 [00:19<00:43,  3.52it/s][A
 31%|███       | 68/221 [00:19<00:41,  3.70it/s][A
 31%|███       | 69/221 [00:19<00:54,  2.81it/s][A
 32%|███▏      | 70/221 [00:20<00:49,  3.07it/s][A
 32%|███▏      | 71/221 [00:20<00:52,  2.88it/s][A
 33%|███▎      | 72/221 [00:20<00:49,  2.98it/s][A
 33%|███▎      | 73/221 [00:21<00:48,  3.03it/s][A
 33%|███▎      | 74/221 [00:21<00:50,  2.91it/s][A
 34%|███▍      | 75/221 [00:21<00:47,  3.07it/s][A
 34%|███▍      | 76/221 [00:21<00:38,  3.74it/s][A
 35%|███▍      | 77/221 [00:22<00:40,  3.55it/s][A
 35%|███▌      | 78/221 [00:22<00:42,  3.35it/s][A
 36%|███▌      | 79/221 [00:22<00:40,  3.51it/s][A
 36%|███▌      | 80/221 [00:23<00:36,  3.83it/s][A
 37%|███▋      | 81/221 [00:23<00:35,  3.96it/s][A
 37%|███▋      | 82/221 [00:23<00:34,  3.97it/s][A
 38%|███▊      | 83/221 [00:23<00:35,  3.88it/s][A
 38%|███▊      | 84/221 [00:24<00:52,  2.60it/s][A
 38%|███▊      | 85/221 [00:24<00:51,  2.64it/s][A
 39%|███▉      | 86/221 [00:25<00:53,  2.54it/s][A
 39%|███▉      | 87/221 [00:25<00:51,  2.58it/s][A
 40%|███▉      | 88/221 [00:25<00:45,  2.92it/s][A
 40%|████      | 89/221 [00:26<00:48,  2.73it/s][A
 41%|████      | 90/221 [00:26<00:47,  2.77it/s][A
 41%|████      | 91/221 [00:27<00:47,  2.75it/s][A
 42%|████▏     | 92/221 [00:27<00:47,  2.73it/s][A
 42%|████▏     | 93/221 [00:28<01:01,  2.08it/s][A
 43%|████▎     | 94/221 [00:28<00:52,  2.41it/s][A
 43%|████▎     | 95/221 [00:29<01:00,  2.08it/s][A
 43%|████▎     | 96/221 [00:29<00:59,  2.08it/s][A
 44%|████▍     | 97/221 [00:29<00:48,  2.55it/s][A
 44%|████▍     | 98/221 [00:30<00:48,  2.54it/s][A
 45%|████▍     | 99/221 [00:30<00:43,  2.80it/s][A
 45%|████▌     | 100/221 [00:30<00:36,  3.34it/s][A
 46%|████▌     | 101/221 [00:30<00:31,  3.84it/s][A
 46%|████▌     | 102/221 [00:31<00:34,  3.49it/s][A
 47%|████▋     | 103/221 [00:31<00:31,  3.80it/s][A
 47%|████▋     | 104/221 [00:31<00:28,  4.18it/s][A
 48%|████▊     | 105/221 [00:31<00:34,  3.35it/s][A
 48%|████▊     | 106/221 [00:32<00:35,  3.21it/s][A
 48%|████▊     | 107/221 [00:32<00:39,  2.88it/s][A
 49%|████▉     | 108/221 [00:32<00:34,  3.28it/s][A
 49%|████▉     | 109/221 [00:33<00:29,  3.74it/s][A
 50%|████▉     | 110/221 [00:33<00:29,  3.82it/s][A
 50%|█████     | 111/221 [00:33<00:31,  3.51it/s][A
 51%|█████     | 112/221 [00:33<00:33,  3.28it/s][A
 51%|█████     | 113/221 [00:34<00:34,  3.14it/s][A
 52%|█████▏    | 114/221 [00:34<00:29,  3.67it/s][A
 52%|█████▏    | 115/221 [00:34<00:26,  4.02it/s][A
 52%|█████▏    | 116/221 [00:34<00:25,  4.14it/s][A
 53%|█████▎    | 117/221 [00:35<00:25,  4.16it/s][A
 53%|█████▎    | 118/221 [00:35<00:31,  3.26it/s][A
 54%|█████▍    | 119/221 [00:36<00:37,  2.76it/s][A
 54%|█████▍    | 120/221 [00:36<00:36,  2.76it/s][A
 55%|█████▍    | 121/221 [00:36<00:32,  3.10it/s][A
 55%|█████▌    | 122/221 [00:36<00:29,  3.38it/s][A
 56%|█████▌    | 123/221 [00:37<00:30,  3.17it/s][A
 56%|█████▌    | 124/221 [00:37<00:27,  3.52it/s][A
 57%|█████▋    | 125/221 [00:37<00:32,  3.00it/s][A
 57%|█████▋    | 126/221 [00:38<00:27,  3.50it/s][A
 57%|█████▋    | 127/221 [00:38<00:34,  2.76it/s][A
 58%|█████▊    | 128/221 [00:38<00:29,  3.12it/s][A
 58%|█████▊    | 129/221 [00:39<00:26,  3.48it/s][A
 59%|█████▉    | 130/221 [00:39<00:25,  3.52it/s][A
 59%|█████▉    | 131/221 [00:39<00:23,  3.86it/s][A
 60%|█████▉    | 132/221 [00:39<00:23,  3.86it/s][A
 60%|██████    | 133/221 [00:40<00:32,  2.68it/s][A
 61%|██████    | 134/221 [00:40<00:35,  2.47it/s][A
 61%|██████    | 135/221 [00:41<00:28,  3.05it/s][A
 62%|██████▏   | 136/221 [00:41<00:26,  3.18it/s][A
 62%|██████▏   | 137/221 [00:41<00:22,  3.67it/s][A
 62%|██████▏   | 138/221 [00:41<00:21,  3.95it/s][A
 63%|██████▎   | 139/221 [00:42<00:26,  3.11it/s][A
 63%|██████▎   | 140/221 [00:42<00:24,  3.36it/s][A
 64%|██████▍   | 141/221 [00:42<00:25,  3.09it/s][A
 64%|██████▍   | 142/221 [00:43<00:22,  3.49it/s][A
 65%|██████▍   | 143/221 [00:43<00:21,  3.62it/s][A
 65%|██████▌   | 144/221 [00:43<00:21,  3.61it/s][A
 66%|██████▌   | 145/221 [00:44<00:24,  3.04it/s][A
 66%|██████▌   | 146/221 [00:44<00:23,  3.25it/s][A
 67%|██████▋   | 147/221 [00:44<00:21,  3.40it/s][A
 67%|██████▋   | 148/221 [00:44<00:22,  3.24it/s][A
 67%|██████▋   | 149/221 [00:45<00:20,  3.53it/s][A
 68%|██████▊   | 150/221 [00:45<00:18,  3.74it/s][A
 68%|██████▊   | 151/221 [00:45<00:22,  3.06it/s][A
 69%|██████▉   | 152/221 [00:46<00:33,  2.09it/s][A
 69%|██████▉   | 153/221 [00:46<00:28,  2.38it/s][A
 70%|██████▉   | 154/221 [00:47<00:26,  2.53it/s][A
 70%|███████   | 155/221 [00:47<00:24,  2.64it/s][A
 71%|███████   | 156/221 [00:47<00:20,  3.23it/s][A
 71%|███████   | 157/221 [00:48<00:18,  3.39it/s][A
 71%|███████▏  | 158/221 [00:48<00:20,  3.05it/s][A
 72%|███████▏  | 159/221 [00:48<00:18,  3.31it/s][A
 72%|███████▏  | 160/221 [00:48<00:17,  3.59it/s][A
 73%|███████▎  | 161/221 [00:49<00:14,  4.17it/s][A
 73%|███████▎  | 162/221 [00:49<00:11,  5.01it/s][A
 74%|███████▍  | 163/221 [00:49<00:13,  4.40it/s][A
 74%|███████▍  | 164/221 [00:49<00:12,  4.60it/s][A
 75%|███████▍  | 165/221 [00:49<00:14,  3.99it/s][A
 75%|███████▌  | 166/221 [00:50<00:15,  3.56it/s][A
 76%|███████▌  | 168/221 [00:50<00:11,  4.61it/s][A
 77%|███████▋  | 170/221 [00:51<00:13,  3.66it/s][A
 77%|███████▋  | 171/221 [00:51<00:14,  3.48it/s][A
 78%|███████▊  | 172/221 [00:52<00:14,  3.31it/s][A
 78%|███████▊  | 173/221 [00:52<00:13,  3.47it/s][A
 79%|███████▊  | 174/221 [00:52<00:13,  3.39it/s][A
 79%|███████▉  | 175/221 [00:52<00:13,  3.40it/s][A
 80%|███████▉  | 176/221 [00:53<00:11,  3.78it/s][A
 80%|████████  | 177/221 [00:53<00:12,  3.58it/s][A
 81%|████████  | 178/221 [00:54<00:17,  2.46it/s][A
 81%|████████  | 179/221 [00:54<00:14,  2.80it/s][A
 81%|████████▏ | 180/221 [00:54<00:14,  2.90it/s][A
 82%|████████▏ | 181/221 [00:55<00:18,  2.16it/s][A
 82%|████████▏ | 182/221 [00:55<00:15,  2.46it/s][A
 83%|████████▎ | 183/221 [00:55<00:14,  2.66it/s][A
 83%|████████▎ | 184/221 [00:56<00:14,  2.64it/s][A
 84%|████████▎ | 185/221 [00:56<00:10,  3.33it/s][A
 84%|████████▍ | 186/221 [00:56<00:11,  3.12it/s][A
 85%|████████▍ | 187/221 [00:57<00:10,  3.33it/s][A
 85%|████████▌ | 188/221 [00:57<00:09,  3.49it/s][A
 86%|████████▌ | 189/221 [00:57<00:08,  3.82it/s][A
 86%|████████▌ | 190/221 [00:57<00:09,  3.43it/s][A
 86%|████████▋ | 191/221 [00:58<00:08,  3.68it/s][A
 87%|████████▋ | 192/221 [00:58<00:07,  3.68it/s][A
 87%|████████▋ | 193/221 [00:58<00:07,  3.81it/s][A
 88%|████████▊ | 194/221 [00:58<00:07,  3.85it/s][A
 88%|████████▊ | 195/221 [00:59<00:05,  4.47it/s][A
 89%|████████▊ | 196/221 [00:59<00:07,  3.41it/s][A
 89%|████████▉ | 197/221 [00:59<00:07,  3.14it/s][A
 90%|████████▉ | 198/221 [01:00<00:07,  3.04it/s][A
 90%|█████████ | 199/221 [01:00<00:05,  3.68it/s][A
 90%|█████████ | 200/221 [01:00<00:06,  3.49it/s][A
 91%|█████████ | 201/221 [01:00<00:05,  3.75it/s][A
 91%|█████████▏| 202/221 [01:01<00:05,  3.37it/s][A
 92%|█████████▏| 203/221 [01:01<00:04,  3.64it/s][A
 92%|█████████▏| 204/221 [01:01<00:05,  3.39it/s][A
 93%|█████████▎| 205/221 [01:02<00:04,  3.71it/s][A
 93%|█████████▎| 206/221 [01:02<00:04,  3.06it/s][A
 94%|█████████▎| 207/221 [01:02<00:04,  3.09it/s][A
 94%|█████████▍| 208/221 [01:03<00:03,  3.57it/s][A
 95%|█████████▍| 209/221 [01:03<00:02,  4.18it/s][A
 95%|█████████▌| 210/221 [01:03<00:03,  3.29it/s][A
 95%|█████████▌| 211/221 [01:03<00:02,  3.55it/s][A
 96%|█████████▌| 212/221 [01:04<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:04<00:02,  3.53it/s][A
 97%|█████████▋| 214/221 [01:04<00:01,  3.66it/s][A
 97%|█████████▋| 215/221 [01:04<00:01,  3.44it/s][A
 98%|█████████▊| 216/221 [01:05<00:01,  3.30it/s][A
 98%|█████████▊| 217/221 [01:05<00:01,  3.47it/s][A
 99%|█████████▊| 218/221 [01:05<00:00,  3.52it/s][A
 99%|█████████▉| 219/221 [01:06<00:00,  3.15it/s][A
100%|█████████▉| 220/221 [01:06<00:00,  3.56it/s][A
100%|██████████| 221/221 [01:06<00:00,  3.39it/s][A100%|██████████| 221/221 [01:06<00:00,  3.31it/s]
09/17/2024 06:19:18 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 1099--===========

09/17/2024 06:19:18 - INFO - __main__ -   {'area_r1': 38.7, 'area_recall': '38.7/62.9/72.7', 'area_ravg': 58.1}
09/17/2024 06:19:18 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 1099--===========

09/17/2024 06:19:18 - INFO - __main__ -   {'forward_r1': 37.6, 'forward_recall': '37.6/66.1/76.9', 'forward_ravg': 60.2}
09/17/2024 06:19:18 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 1099--===========

09/17/2024 06:19:18 - INFO - __main__ -   {'area_video_r1': 38.3, 'area_video_recall': '38.3/66.3/77.3', 'area_video_ravg': 60.6}
09/17/2024 06:19:18 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 299=======

09/17/2024 06:19:18 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 06:19:18 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 1099--===========

09/17/2024 06:19:18 - INFO - __main__ -   {'area_video_r1': 53.2, 'area_video_recall': '53.2/75.6/82.1', 'area_video_ravg': 70.3, 'area_video_back_r1': 48.1, 'area_video_back_recall': '48.1/75.6/82.2', 'area_video_back_ravg': 68.6}
09/17/2024 06:19:18 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 549=======

09/17/2024 06:19:18 - INFO - __main__ -   {'area_video_r1': 54.1, 'area_video_recall': '54.1/75.5/82.4', 'area_video_ravg': 70.6, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.5/82.1', 'area_video_back_ravg': 68.7}
09/17/2024 06:19:18 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 1099--===========

09/17/2024 06:19:18 - INFO - __main__ -   {'video_r1': 38.0, 'video_recall': '38.0/63.8/73.9', 'video_ravg': 58.6}
09/17/2024 06:19:18 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 949=======

09/17/2024 06:19:18 - INFO - __main__ -   {'video_r1': 38.7, 'video_recall': '38.7/64.3/74.1', 'video_ravg': 59.0}
09/17/2024 06:19:18 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 1099--===========

09/17/2024 06:19:18 - INFO - __main__ -   {'video_r1': 52.8, 'video_recall': '52.8/74.9/82.2', 'video_ravg': 70.0}
09/17/2024 06:19:18 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 549=======

09/17/2024 06:19:18 - INFO - __main__ -   {'video_r1': 54.5, 'video_recall': '54.5/76.1/83.4', 'video_ravg': 71.3}
09/17/2024 06:19:40 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.007852260023355484, 'loss_ret%tv%ta--finetune_area/loss_area': 1.0727663040161133, 'loss_ret%tv%ta--finetune_area/total_loss': 1.0806186199188232}
 38%|███▊      | 1100/2910 [6:57:57<67:48:31, 134.87s/it] 38%|███▊      | 1101/2910 [6:58:00<47:58:12, 95.46s/it] [h264 @ 0x55e238926740] mmco: unref short failure
 38%|███▊      | 1102/2910 [6:58:04<34:09:41, 68.02s/it] 38%|███▊      | 1103/2910 [6:58:08<24:32:26, 48.89s/it] 38%|███▊      | 1104/2910 [6:58:13<17:48:50, 35.51s/it][h264 @ 0x55b5c201fcc0] mmco: unref short failure
 38%|███▊      | 1105/2910 [6:58:17<13:09:31, 26.24s/it] 38%|███▊      | 1106/2910 [6:58:23<10:07:33, 20.21s/it][h264 @ 0x55b5c6820340] mmco: unref short failure
[h264 @ 0x55b5c6820340] mmco: unref short failure
[h264 @ 0x55b5c6820340] mmco: unref short failure
[h264 @ 0x56075e7090c0] mmco: unref short failure
[h264 @ 0x56075e7090c0] mmco: unref short failure
 38%|███▊      | 1107/2910 [6:58:29<7:54:53, 15.80s/it]  38%|███▊      | 1108/2910 [6:58:35<6:24:08, 12.79s/it]09/17/2024 06:20:22 - INFO - __main__ -   current idx ISueLekeFew.95 from finetune_area returns wrong image/video, use 28771 instead.
[h264 @ 0x55e24d7b8640] mmco: unref short failure
[h264 @ 0x55e24d7b8640] mmco: unref short failure
 38%|███▊      | 1109/2910 [6:58:40<5:19:43, 10.65s/it][h264 @ 0x5607563f4180] mmco: unref short failure
[h264 @ 0x5607563f4180] mmco: unref short failure
[h264 @ 0x55a319a47c80] mmco: unref short failure
[h264 @ 0x55a327b0ae00] mmco: unref short failure
 38%|███▊      | 1110/2910 [6:58:47<4:40:34,  9.35s/it][h264 @ 0x55a316b9ba00] mmco: unref short failure
[h264 @ 0x55a316b9ba00] mmco: unref short failure
[h264 @ 0x55a327b0ae00] mmco: unref short failure
 38%|███▊      | 1111/2910 [6:58:52<4:04:53,  8.17s/it][h264 @ 0x55e24d7b8640] mmco: unref short failure
 38%|███▊      | 1112/2910 [6:58:58<3:45:11,  7.51s/it][h264 @ 0x55b5b93ba240] mmco: unref short failure
 38%|███▊      | 1113/2910 [6:59:04<3:32:20,  7.09s/it][h264 @ 0x56075ff46400] mmco: unref short failure
 38%|███▊      | 1114/2910 [6:59:09<3:14:51,  6.51s/it] 38%|███▊      | 1115/2910 [6:59:15<3:11:05,  6.39s/it][h264 @ 0x55b5ab372d80] mmco: unref short failure
[h264 @ 0x55b5ab372d80] mmco: unref short failure
[h264 @ 0x55b5c76ab0c0] mmco: unref short failure
[h264 @ 0x55e23caced00] mmco: unref short failure
[h264 @ 0x55e23caced00] mmco: unref short failure
[h264 @ 0x55e23caced00] mmco: unref short failure
[h264 @ 0x55e23caced00] mmco: unref short failure
[h264 @ 0x55b5abec4ec0] mmco: unref short failure
09/17/2024 06:21:15 - INFO - __main__ -   current idx aPvQDKl-LG4.51 from finetune_area returns wrong image/video, use 56728 instead.
[h264 @ 0x55e245711d00] mmco: unref short failure
[h264 @ 0x55a32e8e7f80] mmco: unref short failure
[h264 @ 0x55a32e8e7f80] mmco: unref short failure
[h264 @ 0x55a32e8e7f80] mmco: unref short failure
[h264 @ 0x55a32e8e7f80] mmco: unref short failure
[h264 @ 0x55b5c5fbed80] mmco: unref short failure
[h264 @ 0x55b5c5fbed80] mmco: unref short failure
[h264 @ 0x55b5c5fbed80] mmco: unref short failure
[h264 @ 0x55b5c5fbed80] mmco: unref short failure
[h264 @ 0x55a31c220380] mmco: unref short failure
[h264 @ 0x55a31c220380] mmco: unref short failure
 38%|███▊      | 1116/2910 [7:00:04<9:30:40, 19.09s/it][h264 @ 0x5607563f4180] mmco: unref short failure
 38%|███▊      | 1117/2910 [7:00:18<8:43:57, 17.53s/it][h264 @ 0x55b5ab8fe3c0] mmco: unref short failure
[h264 @ 0x55a31daa8f40] mmco: unref short failure
[h264 @ 0x55a31daa8f40] mmco: unref short failure
[h264 @ 0x55b5ab8fe3c0] mmco: unref short failure
[h264 @ 0x55b5ab8fe3c0] mmco: unref short failure
[h264 @ 0x55b5ae4d9840] mmco: unref short failure
[h264 @ 0x55b5ae4d9840] mmco: unref short failure
[h264 @ 0x55a326d81bc0] mmco: unref short failure
[h264 @ 0x55a326d81bc0] mmco: unref short failure
 38%|███▊      | 1118/2910 [7:00:24<6:59:31, 14.05s/it][h264 @ 0x56075694ddc0] mmco: unref short failure
[h264 @ 0x56075694ddc0] mmco: unref short failure
[h264 @ 0x55a320274dc0] mmco: unref short failure
[h264 @ 0x55a320274dc0] mmco: unref short failure
 38%|███▊      | 1119/2910 [7:00:35<6:28:53, 13.03s/it][h264 @ 0x55a31d492040] mmco: unref short failure
[h264 @ 0x55a31d492040] mmco: unref short failure
[h264 @ 0x55a31d492040] mmco: unref short failure
[h264 @ 0x55a3111f0b40] mmco: unref short failure
[h264 @ 0x55a3111f0b40] mmco: unref short failure
[h264 @ 0x55a3111f0b40] mmco: unref short failure
[h264 @ 0x55a3111f0b40] mmco: unref short failure
[h264 @ 0x55b5b9a3ce40] mmco: unref short failure
[h264 @ 0x55b5b9a3ce40] mmco: unref short failure
[h264 @ 0x55b5b2beeb40] mmco: unref short failure
[h264 @ 0x55a31d492040] mmco: unref short failure
[h264 @ 0x55a31d492040] mmco: unref short failure
 38%|███▊      | 1120/2910 [7:01:03<8:49:23, 17.74s/it] 39%|███▊      | 1121/2910 [7:01:09<7:03:07, 14.19s/it][h264 @ 0x55a31b483380] mmco: unref short failure
 39%|███▊      | 1122/2910 [7:01:14<5:39:46, 11.40s/it][h264 @ 0x55e23e426380] mmco: unref short failure
 39%|███▊      | 1123/2910 [7:01:20<4:46:45,  9.63s/it][h264 @ 0x55b5c56fedc0] mmco: unref short failure
[h264 @ 0x55b5c56fedc0] mmco: unref short failure
[h264 @ 0x55b5c5e0c4c0] mmco: unref short failure
[h264 @ 0x5607546be380] mmco: unref short failure
[h264 @ 0x56075ed1e280] mmco: unref short failure
[h264 @ 0x56075ed1e280] mmco: unref short failure
[h264 @ 0x55e239257780] mmco: unref short failure
[h264 @ 0x55b5aad0b0c0] mmco: unref short failure
[h264 @ 0x55b5aad0b0c0] mmco: unref short failure
[h264 @ 0x55a311e1e080] mmco: unref short failure
[h264 @ 0x55a311e1e080] mmco: unref short failure
[h264 @ 0x55a32444e380] mmco: unref short failure
[h264 @ 0x55a32444e380] mmco: unref short failure
[h264 @ 0x55a323254900] mmco: unref short failure
[h264 @ 0x55a323254900] mmco: unref short failure
[h264 @ 0x55a323254900] mmco: unref short failure
[h264 @ 0x55a323254900] mmco: unref short failure
09/17/2024 06:23:43 - INFO - __main__ -   current idx n28tYo5T1Po.62 from finetune_area returns wrong image/video, use 86165 instead.
09/17/2024 06:23:46 - INFO - __main__ -   current idx gtt8O0yuAiA.7 from finetune_area returns wrong image/video, use 57438 instead.
[h264 @ 0x560744b77880] mmco: unref short failure
[h264 @ 0x55a323254900] mmco: unref short failure
[h264 @ 0x55b5aed77040] mmco: unref short failure
[h264 @ 0x560757cf5940] mmco: unref short failure
[h264 @ 0x560757cf5940] mmco: unref short failure
 39%|███▊      | 1124/2910 [7:02:34<14:23:40, 29.01s/it][h264 @ 0x560751c1b440] mmco: unref short failure
[h264 @ 0x560751c1b440] mmco: unref short failure
 39%|███▊      | 1125/2910 [7:02:44<11:35:37, 23.38s/it]09/17/2024 06:24:33 - INFO - __main__ -   current idx H3sDc6_8nAc.67 from finetune_area returns wrong image/video, use 3732 instead.
[h264 @ 0x55e248808240] mmco: unref short failure
[h264 @ 0x55e257150040] mmco: unref short failure
 39%|███▊      | 1126/2910 [7:02:57<10:01:44, 20.24s/it][h264 @ 0x55a311e1e080] mmco: unref short failure
[h264 @ 0x55a311e1e080] mmco: unref short failure
 39%|███▊      | 1127/2910 [7:03:03<7:50:10, 15.82s/it] [h264 @ 0x55e25546b2c0] mmco: unref short failure
[h264 @ 0x55e25546b2c0] mmco: unref short failure
[h264 @ 0x55e25546b2c0] mmco: unref short failure
[h264 @ 0x55b5c2bad680] mmco: unref short failure
[h264 @ 0x55b5c2bad680] mmco: unref short failure
[h264 @ 0x55b5c2bad680] mmco: unref short failure
[h264 @ 0x55b5c2bad680] mmco: unref short failure
 39%|███▉      | 1128/2910 [7:03:23<8:29:16, 17.15s/it] 39%|███▉      | 1129/2910 [7:03:29<6:49:23, 13.79s/it][h264 @ 0x55e25434bf80] mmco: unref short failure
 39%|███▉      | 1130/2910 [7:03:34<5:32:08, 11.20s/it][h264 @ 0x55b5c2bad680] mmco: unref short failure
[h264 @ 0x55b5c2bad680] mmco: unref short failure
[h264 @ 0x55a31c220380] mmco: unref short failure
[h264 @ 0x55a31c220380] mmco: unref short failure
 39%|███▉      | 1131/2910 [7:03:39<4:40:32,  9.46s/it][h264 @ 0x55e23ffd71c0] mmco: unref short failure
[h264 @ 0x55e23ffd71c0] mmco: unref short failure
[h264 @ 0x5607549e3d00] mmco: unref short failure
[h264 @ 0x5607549e3d00] mmco: unref short failure
[h264 @ 0x55a32f179840] mmco: unref short failure
[h264 @ 0x55a32f179840] mmco: unref short failure
[h264 @ 0x55e2562a3ec0] mmco: unref short failure
[h264 @ 0x55e2562a3ec0] mmco: unref short failure
[h264 @ 0x55e2562a3ec0] mmco: unref short failure
[h264 @ 0x55e24668ec40] mmco: unref short failure
[h264 @ 0x55e2599eb940] mmco: unref short failure
[h264 @ 0x55e2599eb940] mmco: unref short failure
[h264 @ 0x56075d10c780] mmco: unref short failure
[h264 @ 0x55a32ce2b700] mmco: unref short failure
[h264 @ 0x55a32ce2b700] mmco: unref short failure
[h264 @ 0x55e259a1a800] mmco: unref short failure
[h264 @ 0x55e259a1a800] mmco: unref short failure
[h264 @ 0x55b5b2beeb40] mmco: unref short failure
[h264 @ 0x55b5af5f0a40] mmco: unref short failure
[h264 @ 0x55b5af5f0a40] mmco: unref short failure
[h264 @ 0x55e23e426380] mmco: unref short failure
[h264 @ 0x55a31bd177c0] mmco: unref short failure
[h264 @ 0x55a31bd177c0] mmco: unref short failure
[h264 @ 0x55b5cdb36d40] mmco: unref short failure
[h264 @ 0x55e252428680] mmco: unref short failure
[h264 @ 0x55e252428680] mmco: unref short failure
[h264 @ 0x55a31c220380] mmco: unref short failure
[h264 @ 0x55a31c220380] mmco: unref short failure
[h264 @ 0x55a31c220380] mmco: unref short failure
[h264 @ 0x55a31c220380] mmco: unref short failure
[h264 @ 0x55b5bd88a440] mmco: unref short failure
[h264 @ 0x55b5bd88a440] mmco: unref short failure
[h264 @ 0x56075a177640] mmco: unref short failure
[h264 @ 0x56075a177640] mmco: unref short failure
 39%|███▉      | 1132/2910 [7:04:59<15:03:41, 30.50s/it][h264 @ 0x55a31c2a8dc0] mmco: unref short failure
[h264 @ 0x560744ecc9c0] mmco: unref short failure
[h264 @ 0x560744ecc9c0] mmco: unref short failure
[h264 @ 0x55b5b2ba5180] mmco: unref short failure
[h264 @ 0x55e259a1a800] mmco: unref short failure
[h264 @ 0x55a31ce82640] mmco: unref short failure
[h264 @ 0x55a31ce82640] mmco: unref short failure
 39%|███▉      | 1133/2910 [7:05:16<13:05:52, 26.54s/it][h264 @ 0x55b5b7e753c0] mmco: unref short failure
[h264 @ 0x55a31c220380] mmco: unref short failure
[h264 @ 0x55a31c220380] mmco: unref short failure
[h264 @ 0x55a31ba02500] mmco: unref short failure
[h264 @ 0x55a31ba02500] mmco: unref short failure
 39%|███▉      | 1134/2910 [7:05:27<10:48:45, 21.92s/it] 39%|███▉      | 1135/2910 [7:05:33<8:19:52, 16.90s/it] [h264 @ 0x55b5ba4b4d00] mmco: unref short failure
[h264 @ 0x55b5b12bd000] mmco: unref short failure
[h264 @ 0x55b5b9bacac0] mmco: unref short failure
[h264 @ 0x56075a177640] mmco: unref short failure
[h264 @ 0x56075a177640] mmco: unref short failure
 39%|███▉      | 1136/2910 [7:05:48<8:08:48, 16.53s/it][h264 @ 0x56075a172d40] mmco: unref short failure
[h264 @ 0x56075a172d40] mmco: unref short failure
[h264 @ 0x55b5c5e0c4c0] mmco: unref short failure
[h264 @ 0x55b5c5e0c4c0] mmco: unref short failure
 39%|███▉      | 1137/2910 [7:05:58<7:12:32, 14.64s/it] 39%|███▉      | 1138/2910 [7:06:05<5:57:11, 12.09s/it][h264 @ 0x55a326acf200] mmco: unref short failure
 39%|███▉      | 1139/2910 [7:06:10<4:57:56, 10.09s/it][h264 @ 0x55b5b7e753c0] mmco: unref short failure
[h264 @ 0x5607546be380] mmco: unref short failure
[h264 @ 0x5607546be380] mmco: unref short failure
[h264 @ 0x55b5c5e0c4c0] mmco: unref short failure
[h264 @ 0x55b5c5e0c4c0] mmco: unref short failure
[h264 @ 0x56075ed1e280] mmco: unref short failure
[h264 @ 0x56075ed1e280] mmco: unref short failure
[h264 @ 0x55b5b6806300] mmco: unref short failure
[h264 @ 0x55e2378ed540] mmco: unref short failure
[h264 @ 0x55e2378ed540] mmco: unref short failure
[h264 @ 0x55b5b7e753c0] mmco: unref short failure
[h264 @ 0x55e23ffd71c0] mmco: unref short failure
[h264 @ 0x55a32ec5ee00] mmco: unref short failure
[h264 @ 0x55a32ec5ee00] mmco: unref short failure
[h264 @ 0x55b5b517bb40] mmco: unref short failure
[h264 @ 0x56076152f6c0] mmco: unref short failure
[h264 @ 0x5607429ff840] mmco: unref short failure
[h264 @ 0x55e24571f3c0] mmco: unref short failure
[h264 @ 0x55b5aaa39540] mmco: unref short failure
[h264 @ 0x55b5aaa39540] mmco: unref short failure
[h264 @ 0x56075a177640] mmco: unref short failure
[h264 @ 0x56075a177640] mmco: unref short failure
[h264 @ 0x56075a177640] mmco: unref short failure
[h264 @ 0x56075a177640] mmco: unref short failure
[h264 @ 0x55b5aaa39540] mmco: unref short failure
[h264 @ 0x55b5aaa39540] mmco: unref short failure
[h264 @ 0x56075d10c780] mmco: unref short failure
[h264 @ 0x56075d10c780] mmco: unref short failure
 39%|███▉      | 1140/2910 [7:07:25<14:27:58, 29.42s/it][h264 @ 0x56075ed1e280] mmco: unref short failure
[h264 @ 0x56075ed1e280] mmco: unref short failure
[h264 @ 0x55a324d2cf00] mmco: unref short failure
[h264 @ 0x55a324d2cf00] mmco: unref short failure
[h264 @ 0x55a32cad8b80] mmco: unref short failure
[h264 @ 0x55a32cad8b80] mmco: unref short failure
[h264 @ 0x55e2529094c0] mmco: unref short failure
[h264 @ 0x55e2529094c0] mmco: unref short failure
09/17/2024 06:29:32 - INFO - __main__ -   current idx thKB7z_wbWY.26 from finetune_area returns wrong image/video, use 76556 instead.
[h264 @ 0x5607546be380] mmco: unref short failure
[h264 @ 0x5607546be380] mmco: unref short failure
 39%|███▉      | 1141/2910 [7:07:55<14:37:44, 29.77s/it] 39%|███▉      | 1142/2910 [7:08:02<11:18:43, 23.03s/it][h264 @ 0x55b5aed77040] mmco: unref short failure
[h264 @ 0x55b5aed77040] mmco: unref short failure
 39%|███▉      | 1143/2910 [7:08:07<8:37:18, 17.57s/it] [h264 @ 0x560757cf5940] mmco: unref short failure
[h264 @ 0x560757cf5940] mmco: unref short failure
[h264 @ 0x55e2392a5600] mmco: unref short failure
[h264 @ 0x55e2392a5600] mmco: unref short failure
[h264 @ 0x55e2518ca740] mmco: unref short failure
[h264 @ 0x55e2518ca740] mmco: unref short failure
[h264 @ 0x55a32d88ee80] mmco: unref short failure
[h264 @ 0x55a32d88ee80] mmco: unref short failure
[h264 @ 0x55a328579340] mmco: unref short failure
[h264 @ 0x55a328579340] mmco: unref short failure
[h264 @ 0x55a328579340] mmco: unref short failure
 39%|███▉      | 1144/2910 [7:08:35<10:10:08, 20.73s/it][h264 @ 0x56074ae0e640] mmco: unref short failure
[h264 @ 0x56074ae0e640] mmco: unref short failure
 39%|███▉      | 1145/2910 [7:08:41<7:57:01, 16.22s/it] [h264 @ 0x56074633ca80] mmco: unref short failure
[h264 @ 0x56074633ca80] mmco: unref short failure
[h264 @ 0x55a328579340] mmco: unref short failure
[h264 @ 0x55a328579340] mmco: unref short failure
[h264 @ 0x55a328579340] mmco: unref short failure
[h264 @ 0x55a328579340] mmco: unref short failure
 39%|███▉      | 1146/2910 [7:08:47<6:23:03, 13.03s/it][h264 @ 0x55a31a954040] mmco: unref short failure
[h264 @ 0x55a31a954040] mmco: unref short failure
[h264 @ 0x56075c43f500] mmco: unref short failure
 39%|███▉      | 1147/2910 [7:08:52<5:12:43, 10.64s/it][h264 @ 0x55e25067dc40] mmco: unref short failure
[h264 @ 0x55b5c9c07940] mmco: unref short failure
[h264 @ 0x55b5c9c07940] mmco: unref short failure
[h264 @ 0x560741979140] mmco: unref short failure
[h264 @ 0x55b5b5f80ec0] mmco: unref short failure
[h264 @ 0x55b5b5f80ec0] mmco: unref short failure
[h264 @ 0x56075d339540] mmco: unref short failure
[h264 @ 0x55b5c546bc00] mmco: unref short failure
[h264 @ 0x55b5c546bc00] mmco: unref short failure
[h264 @ 0x560741979140] mmco: unref short failure
[h264 @ 0x55e258f4fa00] mmco: unref short failure
 39%|███▉      | 1148/2910 [7:09:59<13:31:07, 27.62s/it][h264 @ 0x55e2518ca740] mmco: unref short failure
[h264 @ 0x56075a177640] mmco: unref short failure
[h264 @ 0x56075a177640] mmco: unref short failure
[h264 @ 0x55e2529094c0] mmco: unref short failure
[h264 @ 0x55e2529094c0] mmco: unref short failure
[h264 @ 0x55e2529094c0] mmco: unref short failure
[h264 @ 0x55e2529094c0] mmco: unref short failure
[h264 @ 0x55b5b6f487c0] mmco: unref short failure
09/17/2024 06:32:01 - INFO - __main__ -   current idx UGjfq2kyBqs.34 from finetune_area returns wrong image/video, use 48593 instead.
[h264 @ 0x55a31cb9aa80] mmco: unref short failure
09/17/2024 06:32:07 - INFO - __main__ -   current idx Xy31jShyKEY.64 from finetune_area returns wrong image/video, use 99620 instead.
09/17/2024 06:32:08 - INFO - __main__ -   current idx TomRXmGEw8s.31 from finetune_area returns wrong image/video, use 118793 instead.
[h264 @ 0x55e240e95440] mmco: unref short failure
[h264 @ 0x55e240e95440] mmco: unref short failure
[h264 @ 0x560764c88e40] mmco: unref short failure
[h264 @ 0x560764c88e40] mmco: unref short failure
[h264 @ 0x55a327bb8e80] mmco: unref short failure
[h264 @ 0x55a327bb8e80] mmco: unref short failure
[h264 @ 0x55a327bb8e80] mmco: unref short failure
[h264 @ 0x55a327bb8e80] mmco: unref short failure
[h264 @ 0x5607599eb0c0] mmco: unref short failure
[h264 @ 0x5607599eb0c0] mmco: unref short failure
 39%|███▉      | 1149/2910 [7:10:29<13:51:27, 28.33s/it]09/17/2024 06:32:15 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 06:32:15 - INFO - __main__ -   start running ret%tva validation...
[h264 @ 0x55b5b39853c0] mmco: unref short failure
[h264 @ 0x55e240140b80] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e249f73340] mmco: unref short failure
[h264 @ 0x55e249f73340] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55b5b6e29680] mmco: unref short failure
[h264 @ 0x55e252428680] mmco: unref short failure
[h264 @ 0x55e252428680] mmco: unref short failure
[h264 @ 0x55a31c36be80] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a31afc2e00] mmco: unref short failure
[h264 @ 0x55a31afc2e00] mmco: unref short failure
[h264 @ 0x55a31afc2e00] mmco: unref short failure
[h264 @ 0x55a31afc2e00] mmco: unref short failure
[h264 @ 0x5607481a8c40] mmco: unref short failure
[h264 @ 0x5607481a8c40] mmco: unref short failure
[h264 @ 0x55b5c5e0c4c0] mmco: unref short failure
[h264 @ 0x55b5c5e0c4c0] mmco: unref short failure
[h264 @ 0x56075ebf5c40] mmco: unref short failure
[h264 @ 0x55a33379b6c0] mmco: unref short failure
[h264 @ 0x55b5c5fbed80] mmco: unref short failure
[h264 @ 0x55b5b6806300] mmco: unref short failure
[h264 @ 0x55b5b6806300] mmco: unref short failure
[h264 @ 0x55a3111f0b40] mmco: unref short failure
[h264 @ 0x55a3111f0b40] mmco: unref short failure
[h264 @ 0x55a31b483380] mmco: unref short failure
[h264 @ 0x55a31b483380] mmco: unref short failure
[h264 @ 0x55b5aed77040] mmco: unref short failure
[h264 @ 0x55b5c5e0c4c0] mmco: unref short failure
[h264 @ 0x55b5c5e0c4c0] mmco: unref short failure
[h264 @ 0x55b5c5e0c4c0] mmco: unref short failure
[h264 @ 0x55b5c5e0c4c0] mmco: unref short failure
[h264 @ 0x55b5c5fbed80] mmco: unref short failure
[h264 @ 0x55b5c5fbed80] mmco: unref short failure
[h264 @ 0x56075300f800] mmco: unref short failure
[h264 @ 0x56075300f800] mmco: unref short failure
[h264 @ 0x560744239380] mmco: unref short failure
[h264 @ 0x560744239380] mmco: unref short failure
[h264 @ 0x560748303bc0] mmco: unref short failure
[h264 @ 0x55e23a8bacc0] mmco: unref short failure
[h264 @ 0x55e23a8bacc0] mmco: unref short failure
[h264 @ 0x55b5b39853c0] mmco: unref short failure
[h264 @ 0x55e258f4fa00] mmco: unref short failure
[h264 @ 0x55a327bb8e80] mmco: unref short failure
[h264 @ 0x55a327bb8e80] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:01<03:55,  1.07s/it][A
  1%|          | 2/221 [00:01<02:55,  1.25it/s][A
  1%|▏         | 3/221 [00:01<01:47,  2.03it/s][A
  2%|▏         | 4/221 [00:01<01:14,  2.91it/s][A
  2%|▏         | 5/221 [00:02<00:55,  3.88it/s][A
  3%|▎         | 6/221 [00:02<00:44,  4.81it/s][A
  3%|▎         | 7/221 [00:02<00:44,  4.82it/s][A
  4%|▎         | 8/221 [00:03<01:15,  2.81it/s][A
  4%|▍         | 9/221 [00:03<01:02,  3.38it/s][A
  5%|▍         | 10/221 [00:03<01:11,  2.94it/s][A
  5%|▍         | 11/221 [00:03<01:00,  3.45it/s][A[h264 @ 0x55b5cca7d740] mmco: unref short failure
[h264 @ 0x55b5cca7d740] mmco: unref short failure

  5%|▌         | 12/221 [00:04<01:22,  2.54it/s][A
  6%|▌         | 13/221 [00:04<01:04,  3.20it/s][A
  6%|▋         | 14/221 [00:06<02:46,  1.24it/s][A
  7%|▋         | 15/221 [00:06<02:14,  1.53it/s][A
  7%|▋         | 16/221 [00:07<01:59,  1.71it/s][A
  8%|▊         | 17/221 [00:07<01:39,  2.04it/s][A
  8%|▊         | 18/221 [00:07<01:24,  2.41it/s][A
  9%|▊         | 19/221 [00:07<01:06,  3.04it/s][A
  9%|▉         | 20/221 [00:08<00:54,  3.69it/s][A
 10%|▉         | 21/221 [00:08<00:45,  4.39it/s][A
 10%|▉         | 22/221 [00:08<00:42,  4.70it/s][A
 10%|█         | 23/221 [00:08<00:35,  5.51it/s][A
 11%|█         | 24/221 [00:08<00:32,  6.01it/s][A
 11%|█▏        | 25/221 [00:08<00:32,  6.01it/s][A
 12%|█▏        | 26/221 [00:09<00:44,  4.43it/s][A
 12%|█▏        | 27/221 [00:09<00:51,  3.77it/s][A
 13%|█▎        | 28/221 [00:09<01:02,  3.11it/s][A
 13%|█▎        | 29/221 [00:09<00:49,  3.91it/s][A
 14%|█▎        | 30/221 [00:10<00:44,  4.25it/s][A
 14%|█▍        | 31/221 [00:10<00:44,  4.24it/s][A
 15%|█▍        | 33/221 [00:11<00:50,  3.75it/s][A
 15%|█▌        | 34/221 [00:11<00:51,  3.66it/s][A
 16%|█▌        | 35/221 [00:11<00:51,  3.63it/s][A
 16%|█▋        | 36/221 [00:11<00:49,  3.74it/s][A
 17%|█▋        | 37/221 [00:12<01:08,  2.69it/s][A
 17%|█▋        | 38/221 [00:12<01:06,  2.77it/s][A
 18%|█▊        | 40/221 [00:13<00:49,  3.66it/s][A
 19%|█▊        | 41/221 [00:13<00:46,  3.85it/s][A
 19%|█▉        | 42/221 [00:13<00:52,  3.43it/s][A
 19%|█▉        | 43/221 [00:13<00:46,  3.81it/s][A
 20%|█▉        | 44/221 [00:14<00:44,  3.94it/s][A
 20%|██        | 45/221 [00:15<01:42,  1.71it/s][A[h264 @ 0x55a330a2e340] mmco: unref short failure
[h264 @ 0x55a330a2e340] mmco: unref short failure

 21%|██        | 46/221 [00:16<01:40,  1.75it/s][A
 21%|██▏       | 47/221 [00:17<02:14,  1.29it/s][A
 22%|██▏       | 48/221 [00:17<01:42,  1.68it/s][A09/17/2024 06:34:48 - INFO - __main__ -   current idx CZpZmpPh3NY.13 from finetune_area returns wrong image/video, use 88345 instead.

 22%|██▏       | 49/221 [00:17<01:26,  1.98it/s][A
 23%|██▎       | 50/221 [00:17<01:07,  2.53it/s][A
 23%|██▎       | 51/221 [00:18<00:53,  3.20it/s][A
 24%|██▎       | 52/221 [00:18<00:43,  3.92it/s][A
 24%|██▍       | 53/221 [00:18<00:35,  4.73it/s][A
 24%|██▍       | 54/221 [00:19<01:14,  2.25it/s][A
 25%|██▍       | 55/221 [00:19<01:21,  2.03it/s][A
 25%|██▌       | 56/221 [00:20<01:08,  2.41it/s][A
 26%|██▌       | 57/221 [00:20<00:59,  2.78it/s][A
 27%|██▋       | 59/221 [00:20<00:39,  4.13it/s][A
 27%|██▋       | 60/221 [00:20<00:43,  3.70it/s][A
 28%|██▊       | 61/221 [00:21<00:40,  3.98it/s][A
 28%|██▊       | 62/221 [00:21<00:39,  4.03it/s][A[h264 @ 0x5607641411c0] mmco: unref short failure

 29%|██▊       | 63/221 [00:21<00:35,  4.50it/s][A
 29%|██▉       | 64/221 [00:21<00:30,  5.18it/s][A
 29%|██▉       | 65/221 [00:21<00:26,  5.81it/s][A[h264 @ 0x55e246c15200] mmco: unref short failure

 30%|██▉       | 66/221 [00:22<00:33,  4.65it/s][A[h264 @ 0x55e246c15200] mmco: unref short failure

 30%|███       | 67/221 [00:22<00:35,  4.38it/s][A
 31%|███       | 68/221 [00:22<00:29,  5.11it/s][A
 31%|███       | 69/221 [00:23<00:54,  2.78it/s][A
 32%|███▏      | 70/221 [00:23<00:48,  3.14it/s][A
 32%|███▏      | 71/221 [00:25<02:23,  1.04it/s][A
 33%|███▎      | 72/221 [00:26<01:48,  1.37it/s][A
 33%|███▎      | 73/221 [00:26<01:28,  1.67it/s][A
 33%|███▎      | 74/221 [00:26<01:07,  2.16it/s][A
 34%|███▍      | 75/221 [00:27<01:09,  2.11it/s][A
 34%|███▍      | 76/221 [00:27<00:56,  2.57it/s][A
 35%|███▍      | 77/221 [00:27<00:49,  2.94it/s][A
 35%|███▌      | 78/221 [00:27<00:49,  2.89it/s][A
 36%|███▌      | 79/221 [00:28<01:01,  2.30it/s][A
 36%|███▌      | 80/221 [00:28<00:49,  2.86it/s][A
 37%|███▋      | 81/221 [00:28<00:43,  3.22it/s][A
 37%|███▋      | 82/221 [00:29<00:40,  3.41it/s][A
 38%|███▊      | 83/221 [00:29<00:35,  3.94it/s][A
 38%|███▊      | 84/221 [00:29<00:29,  4.66it/s][A
 39%|███▉      | 86/221 [00:29<00:22,  5.89it/s][A[h264 @ 0x56076152f6c0] mmco: unref short failure
[h264 @ 0x56076152f6c0] mmco: unref short failure

 39%|███▉      | 87/221 [00:30<00:32,  4.08it/s][A
 40%|███▉      | 88/221 [00:30<00:34,  3.82it/s][A
 40%|████      | 89/221 [00:33<02:09,  1.02it/s][A
 41%|████      | 90/221 [00:33<01:42,  1.28it/s][A
 41%|████      | 91/221 [00:33<01:16,  1.70it/s][A
 42%|████▏     | 92/221 [00:33<00:59,  2.17it/s][A
 42%|████▏     | 93/221 [00:34<01:02,  2.05it/s][A
 43%|████▎     | 94/221 [00:34<00:55,  2.27it/s][A
 43%|████▎     | 95/221 [00:34<00:44,  2.83it/s][A
 43%|████▎     | 96/221 [00:35<00:43,  2.87it/s][A
 44%|████▍     | 97/221 [00:35<00:34,  3.64it/s][A
 44%|████▍     | 98/221 [00:35<00:32,  3.80it/s][A
 45%|████▍     | 99/221 [00:35<00:27,  4.44it/s][A
 45%|████▌     | 100/221 [00:35<00:25,  4.68it/s][A
 46%|████▌     | 101/221 [00:35<00:23,  5.14it/s][A
 46%|████▌     | 102/221 [00:36<00:25,  4.62it/s][A
 47%|████▋     | 103/221 [00:36<00:23,  5.05it/s][A
 47%|████▋     | 104/221 [00:36<00:21,  5.55it/s][A
 48%|████▊     | 105/221 [00:36<00:21,  5.32it/s][A
 48%|████▊     | 106/221 [00:37<00:52,  2.19it/s][A
 48%|████▊     | 107/221 [00:37<00:40,  2.83it/s][A
 49%|████▉     | 108/221 [00:38<00:34,  3.27it/s][A
 49%|████▉     | 109/221 [00:38<00:34,  3.26it/s][A
 50%|████▉     | 110/221 [00:38<00:30,  3.62it/s][A
 50%|█████     | 111/221 [00:39<00:38,  2.89it/s][A
 51%|█████     | 112/221 [00:39<00:33,  3.24it/s][A
 51%|█████     | 113/221 [00:39<00:33,  3.20it/s][A
 52%|█████▏    | 115/221 [00:39<00:22,  4.78it/s][A
 52%|█████▏    | 116/221 [00:44<02:25,  1.39s/it][A
 53%|█████▎    | 117/221 [00:45<01:55,  1.11s/it][A
 53%|█████▎    | 118/221 [00:45<01:35,  1.08it/s][A
 54%|█████▍    | 119/221 [00:45<01:12,  1.40it/s][A
 54%|█████▍    | 120/221 [00:45<00:57,  1.75it/s][A
 55%|█████▌    | 122/221 [00:46<00:37,  2.65it/s][A
 56%|█████▌    | 123/221 [00:46<00:32,  3.01it/s][A
 56%|█████▌    | 124/221 [00:46<00:29,  3.31it/s][A
 57%|█████▋    | 125/221 [00:46<00:26,  3.67it/s][A[h264 @ 0x55b5bb86f8c0] mmco: unref short failure
[h264 @ 0x55b5bb86f8c0] mmco: unref short failure

 57%|█████▋    | 126/221 [00:47<00:35,  2.67it/s][A
 57%|█████▋    | 127/221 [00:47<00:35,  2.66it/s][A
 58%|█████▊    | 128/221 [00:48<00:34,  2.67it/s][A
 58%|█████▊    | 129/221 [00:48<00:30,  3.06it/s][A
 59%|█████▉    | 130/221 [00:48<00:26,  3.45it/s][A
 59%|█████▉    | 131/221 [00:48<00:21,  4.24it/s][A
 60%|█████▉    | 132/221 [00:49<00:21,  4.14it/s][A
 60%|██████    | 133/221 [00:49<00:25,  3.50it/s][A
 61%|██████    | 134/221 [00:49<00:23,  3.76it/s][A
 61%|██████    | 135/221 [00:50<00:29,  2.88it/s][A
 62%|██████▏   | 136/221 [00:50<00:31,  2.71it/s][A
 62%|██████▏   | 137/221 [00:50<00:26,  3.20it/s][A
 62%|██████▏   | 138/221 [00:51<00:28,  2.87it/s][A
 63%|██████▎   | 139/221 [00:51<00:26,  3.05it/s][A
 63%|██████▎   | 140/221 [00:51<00:27,  2.95it/s][A
 64%|██████▍   | 141/221 [00:52<00:24,  3.33it/s][A[h264 @ 0x55e238ebc140] mmco: unref short failure
[h264 @ 0x55e238ebc140] mmco: unref short failure

 64%|██████▍   | 142/221 [00:52<00:29,  2.69it/s][A
 65%|██████▍   | 143/221 [00:52<00:28,  2.76it/s][A
 65%|██████▌   | 144/221 [00:53<00:23,  3.26it/s][A
 66%|██████▌   | 145/221 [00:53<00:20,  3.79it/s][A
 66%|██████▌   | 146/221 [00:53<00:16,  4.49it/s][A
 67%|██████▋   | 147/221 [00:53<00:13,  5.31it/s][A
 67%|██████▋   | 148/221 [00:53<00:14,  5.12it/s][A
 68%|██████▊   | 150/221 [00:53<00:10,  6.66it/s][A
 68%|██████▊   | 151/221 [00:54<00:22,  3.06it/s][A
 69%|██████▉   | 152/221 [00:54<00:20,  3.39it/s][A
 69%|██████▉   | 153/221 [00:55<00:19,  3.56it/s][A
 70%|██████▉   | 154/221 [00:55<00:21,  3.17it/s][A
 70%|███████   | 155/221 [00:55<00:17,  3.88it/s][A
 71%|███████   | 157/221 [00:58<00:41,  1.53it/s][A
 71%|███████▏  | 158/221 [00:58<00:34,  1.84it/s][A
 72%|███████▏  | 159/221 [00:58<00:27,  2.22it/s][A
 72%|███████▏  | 160/221 [00:58<00:23,  2.65it/s][A
 73%|███████▎  | 161/221 [00:58<00:18,  3.31it/s][A
 74%|███████▍  | 163/221 [00:58<00:12,  4.48it/s][A
 74%|███████▍  | 164/221 [00:59<00:12,  4.74it/s][A
 75%|███████▌  | 166/221 [00:59<00:12,  4.52it/s][A
 76%|███████▌  | 168/221 [01:03<00:40,  1.30it/s][A
 76%|███████▋  | 169/221 [01:03<00:34,  1.51it/s][A
 77%|███████▋  | 170/221 [01:03<00:29,  1.74it/s][A
 77%|███████▋  | 171/221 [01:03<00:24,  2.08it/s][A
 78%|███████▊  | 172/221 [01:03<00:20,  2.39it/s][A
 79%|███████▊  | 174/221 [01:04<00:12,  3.79it/s][A
 79%|███████▉  | 175/221 [01:04<00:11,  4.06it/s][A
 80%|███████▉  | 176/221 [01:04<00:10,  4.15it/s][A
 81%|████████  | 178/221 [01:04<00:09,  4.77it/s][A
 81%|████████  | 179/221 [01:05<00:11,  3.50it/s][A
 82%|████████▏ | 181/221 [01:05<00:10,  4.00it/s][A
 82%|████████▏ | 182/221 [01:05<00:09,  4.30it/s][A
 83%|████████▎ | 183/221 [01:06<00:07,  4.78it/s][A
 83%|████████▎ | 184/221 [01:06<00:08,  4.13it/s][A
 84%|████████▎ | 185/221 [01:06<00:08,  4.36it/s][A
 84%|████████▍ | 186/221 [01:06<00:09,  3.82it/s][A
 85%|████████▍ | 187/221 [01:07<00:07,  4.35it/s][A
 85%|████████▌ | 188/221 [01:07<00:07,  4.18it/s][A
 86%|████████▌ | 189/221 [01:07<00:07,  4.01it/s][A
 86%|████████▌ | 190/221 [01:07<00:07,  4.05it/s][A
 87%|████████▋ | 192/221 [01:08<00:05,  5.17it/s][A
 88%|████████▊ | 194/221 [01:09<00:07,  3.47it/s][A
 89%|████████▊ | 196/221 [01:09<00:05,  4.64it/s][A
 90%|████████▉ | 198/221 [01:09<00:04,  5.30it/s][A
 90%|█████████ | 199/221 [01:09<00:04,  5.22it/s][A
 90%|█████████ | 200/221 [01:09<00:04,  5.00it/s][A
 91%|█████████ | 201/221 [01:10<00:03,  5.13it/s][A
 91%|█████████▏| 202/221 [01:10<00:03,  5.50it/s][A
 92%|█████████▏| 204/221 [01:10<00:02,  7.29it/s][A
 93%|█████████▎| 206/221 [01:10<00:03,  4.94it/s][A
 94%|█████████▍| 208/221 [01:11<00:02,  6.35it/s][A
 95%|█████████▌| 211/221 [01:11<00:01,  5.98it/s][A
 96%|█████████▋| 213/221 [01:11<00:01,  7.21it/s][A
 97%|█████████▋| 214/221 [01:12<00:01,  4.48it/s][A
 97%|█████████▋| 215/221 [01:12<00:01,  4.61it/s][A
 98%|█████████▊| 216/221 [01:12<00:01,  4.70it/s][A
 98%|█████████▊| 217/221 [01:13<00:01,  2.88it/s][A
 99%|█████████▊| 218/221 [01:13<00:01,  2.97it/s][A
 99%|█████████▉| 219/221 [01:14<00:00,  3.38it/s][A
100%|█████████▉| 220/221 [01:18<00:01,  1.50s/it][A
100%|██████████| 221/221 [01:18<00:00,  1.12s/it][A100%|██████████| 221/221 [01:18<00:00,  2.80it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:04,  3.42it/s][A
  1%|          | 2/221 [00:00<01:04,  3.42it/s][A
  1%|▏         | 3/221 [00:00<01:03,  3.42it/s][A
  2%|▏         | 4/221 [00:01<01:03,  3.42it/s][A
  2%|▏         | 5/221 [00:01<01:03,  3.42it/s][A
  3%|▎         | 6/221 [00:01<01:02,  3.42it/s][A
  3%|▎         | 7/221 [00:02<01:02,  3.42it/s][A
  4%|▎         | 8/221 [00:02<01:02,  3.42it/s][A
  4%|▍         | 9/221 [00:02<01:01,  3.42it/s][A
  5%|▍         | 10/221 [00:02<01:01,  3.42it/s][A
  5%|▍         | 11/221 [00:03<01:01,  3.42it/s][A
  5%|▌         | 12/221 [00:03<01:01,  3.42it/s][A
  6%|▌         | 13/221 [00:03<01:00,  3.42it/s][A
  6%|▋         | 14/221 [00:04<01:00,  3.42it/s][A
  7%|▋         | 15/221 [00:04<01:00,  3.42it/s][A
  7%|▋         | 16/221 [00:04<00:59,  3.42it/s][A
  8%|▊         | 17/221 [00:04<00:59,  3.42it/s][A
  8%|▊         | 18/221 [00:05<00:59,  3.42it/s][A
  9%|▊         | 19/221 [00:05<00:59,  3.42it/s][A
  9%|▉         | 20/221 [00:05<00:58,  3.42it/s][A
 10%|▉         | 21/221 [00:06<00:58,  3.42it/s][A
 10%|▉         | 22/221 [00:06<00:58,  3.42it/s][A
 10%|█         | 23/221 [00:06<00:57,  3.42it/s][A
 11%|█         | 24/221 [00:07<00:57,  3.42it/s][A
 11%|█▏        | 25/221 [00:07<00:57,  3.42it/s][A
 12%|█▏        | 26/221 [00:07<00:57,  3.42it/s][A
 12%|█▏        | 27/221 [00:07<00:56,  3.42it/s][A
 13%|█▎        | 28/221 [00:08<00:56,  3.42it/s][A
 13%|█▎        | 29/221 [00:08<00:56,  3.42it/s][A
 14%|█▎        | 30/221 [00:08<00:55,  3.42it/s][A
 14%|█▍        | 31/221 [00:09<00:55,  3.42it/s][A
 14%|█▍        | 32/221 [00:09<00:55,  3.42it/s][A
 15%|█▍        | 33/221 [00:09<00:54,  3.42it/s][A
 15%|█▌        | 34/221 [00:09<00:54,  3.42it/s][A
 16%|█▌        | 35/221 [00:10<00:54,  3.42it/s][A
 16%|█▋        | 36/221 [00:10<00:54,  3.42it/s][A
 17%|█▋        | 37/221 [00:10<00:53,  3.42it/s][A
 17%|█▋        | 38/221 [00:11<00:53,  3.42it/s][A
 18%|█▊        | 39/221 [00:11<00:53,  3.42it/s][A
 18%|█▊        | 40/221 [00:11<00:52,  3.42it/s][A
 19%|█▊        | 41/221 [00:11<00:52,  3.42it/s][A
 19%|█▉        | 42/221 [00:12<00:52,  3.42it/s][A
 19%|█▉        | 43/221 [00:12<00:52,  3.42it/s][A
 20%|█▉        | 44/221 [00:12<00:51,  3.42it/s][A
 20%|██        | 45/221 [00:13<00:51,  3.42it/s][A
 21%|██        | 46/221 [00:13<00:51,  3.42it/s][A
 21%|██▏       | 47/221 [00:13<00:50,  3.42it/s][A
 22%|██▏       | 48/221 [00:14<00:50,  3.42it/s][A
 22%|██▏       | 49/221 [00:14<00:50,  3.42it/s][A
 23%|██▎       | 50/221 [00:14<00:50,  3.42it/s][A
 23%|██▎       | 51/221 [00:14<00:49,  3.42it/s][A
 24%|██▎       | 52/221 [00:15<00:49,  3.42it/s][A
 24%|██▍       | 53/221 [00:15<00:49,  3.42it/s][A
 24%|██▍       | 54/221 [00:15<00:48,  3.42it/s][A
 25%|██▍       | 55/221 [00:16<00:48,  3.42it/s][A
 25%|██▌       | 56/221 [00:16<00:48,  3.42it/s][A
 26%|██▌       | 57/221 [00:16<00:47,  3.42it/s][A
 26%|██▌       | 58/221 [00:16<00:47,  3.42it/s][A
 27%|██▋       | 59/221 [00:17<00:47,  3.42it/s][A
 27%|██▋       | 60/221 [00:17<00:47,  3.42it/s][A
 28%|██▊       | 61/221 [00:17<00:46,  3.42it/s][A
 28%|██▊       | 62/221 [00:18<00:46,  3.42it/s][A
 29%|██▊       | 63/221 [00:18<00:46,  3.42it/s][A
 29%|██▉       | 64/221 [00:18<00:45,  3.42it/s][A
 29%|██▉       | 65/221 [00:19<00:45,  3.42it/s][A
 30%|██▉       | 66/221 [00:19<00:45,  3.42it/s][A
 30%|███       | 67/221 [00:19<00:45,  3.42it/s][A
 31%|███       | 68/221 [00:19<00:44,  3.41it/s][A
 31%|███       | 69/221 [00:20<00:44,  3.42it/s][A
 32%|███▏      | 70/221 [00:20<00:44,  3.42it/s][A
 32%|███▏      | 71/221 [00:20<00:43,  3.42it/s][A
 33%|███▎      | 72/221 [00:21<00:43,  3.42it/s][A
 33%|███▎      | 73/221 [00:21<00:43,  3.42it/s][A
 33%|███▎      | 74/221 [00:21<00:42,  3.42it/s][A
 34%|███▍      | 75/221 [00:21<00:42,  3.42it/s][A
 34%|███▍      | 76/221 [00:22<00:42,  3.42it/s][A
 35%|███▍      | 77/221 [00:22<00:42,  3.42it/s][A
 35%|███▌      | 78/221 [00:22<00:41,  3.42it/s][A
 36%|███▌      | 79/221 [00:23<00:41,  3.42it/s][A
 36%|███▌      | 80/221 [00:23<00:41,  3.42it/s][A
 37%|███▋      | 81/221 [00:23<00:40,  3.42it/s][A
 37%|███▋      | 82/221 [00:23<00:40,  3.42it/s][A
 38%|███▊      | 83/221 [00:24<00:40,  3.42it/s][A
 38%|███▊      | 84/221 [00:24<00:40,  3.42it/s][A
 38%|███▊      | 85/221 [00:24<00:39,  3.42it/s][A
 39%|███▉      | 86/221 [00:25<00:39,  3.42it/s][A
 39%|███▉      | 87/221 [00:25<00:39,  3.42it/s][A
 40%|███▉      | 88/221 [00:25<00:38,  3.42it/s][A
 40%|████      | 89/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 90/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 91/221 [00:26<00:38,  3.42it/s][A
 42%|████▏     | 92/221 [00:26<00:37,  3.42it/s][A
 42%|████▏     | 93/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 94/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 95/221 [00:27<00:36,  3.42it/s][A
 43%|████▎     | 96/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 97/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 98/221 [00:28<00:35,  3.42it/s][A
 45%|████▍     | 99/221 [00:28<00:35,  3.42it/s][A
 45%|████▌     | 100/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 101/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 102/221 [00:29<00:34,  3.42it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 104/221 [00:30<00:34,  3.42it/s][A
 48%|████▊     | 105/221 [00:30<00:33,  3.42it/s][A
 48%|████▊     | 106/221 [00:30<00:33,  3.42it/s][A
 48%|████▊     | 107/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 108/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 109/221 [00:31<00:32,  3.42it/s][A
 50%|████▉     | 110/221 [00:32<00:32,  3.42it/s][A
 50%|█████     | 111/221 [00:32<00:32,  3.42it/s][A
 51%|█████     | 112/221 [00:32<00:31,  3.42it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 114/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:33<00:30,  3.42it/s][A
 52%|█████▏    | 116/221 [00:33<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:34<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:34<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:35<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:35<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:35<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:36<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:37<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:38<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:38<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:38<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:39<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:39<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:40<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:40<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:40<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:41<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:41<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:42<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:42<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:43<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:43<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:44<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:45<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:45<00:19,  3.42it/s][A
 71%|███████   | 157/221 [00:45<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:46<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:47<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:47<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:47<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:48<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:48<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:48<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:49<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:49<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:49<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:50<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:50<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:51<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:51<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:52<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:52<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:52<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:53<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:54<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:54<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:54<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:55<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:55<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:56<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:56<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:57<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:57<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:57<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:58<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:58<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [00:59<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [00:59<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:00<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:01<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:01<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:02<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:03<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:03<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:04<00:00,  3.42it/s][A100%|██████████| 221/221 [01:04<00:00,  3.42it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:31,  7.00it/s][A
  1%|          | 2/221 [00:00<00:37,  5.77it/s][A
  1%|▏         | 3/221 [00:00<00:57,  3.82it/s][A
  2%|▏         | 4/221 [00:00<00:49,  4.40it/s][A
  2%|▏         | 5/221 [00:01<00:47,  4.53it/s][A
  3%|▎         | 7/221 [00:01<00:47,  4.49it/s][A
  4%|▎         | 8/221 [00:01<00:56,  3.79it/s][A
  4%|▍         | 9/221 [00:02<00:57,  3.68it/s][A
  5%|▍         | 10/221 [00:02<00:50,  4.15it/s][A
  5%|▍         | 11/221 [00:02<00:50,  4.16it/s][A
  5%|▌         | 12/221 [00:02<00:45,  4.55it/s][A
  6%|▌         | 13/221 [00:03<01:23,  2.50it/s][A
  6%|▋         | 14/221 [00:03<01:12,  2.86it/s][A
  7%|▋         | 15/221 [00:04<01:15,  2.74it/s][A
  7%|▋         | 16/221 [00:04<01:25,  2.39it/s][A
  8%|▊         | 17/221 [00:05<01:23,  2.44it/s][A
  8%|▊         | 18/221 [00:05<01:10,  2.87it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.73it/s][A
 10%|▉         | 21/221 [00:05<00:52,  3.84it/s][A
 10%|▉         | 22/221 [00:06<00:45,  4.42it/s][A
 10%|█         | 23/221 [00:06<00:39,  4.96it/s][A
 11%|█         | 24/221 [00:06<00:37,  5.24it/s][A
 11%|█▏        | 25/221 [00:06<00:49,  3.98it/s][A
 12%|█▏        | 26/221 [00:07<00:46,  4.19it/s][A
 12%|█▏        | 27/221 [00:07<00:49,  3.96it/s][A
 13%|█▎        | 28/221 [00:07<00:46,  4.12it/s][A
 13%|█▎        | 29/221 [00:07<00:51,  3.73it/s][A
 14%|█▎        | 30/221 [00:08<01:05,  2.91it/s][A
 14%|█▍        | 31/221 [00:08<01:05,  2.90it/s][A
 14%|█▍        | 32/221 [00:08<01:01,  3.09it/s][A
 15%|█▍        | 33/221 [00:09<01:04,  2.91it/s][A
 15%|█▌        | 34/221 [00:10<01:28,  2.12it/s][A
 16%|█▌        | 35/221 [00:10<01:10,  2.63it/s][A
 16%|█▋        | 36/221 [00:10<01:08,  2.71it/s][A
 17%|█▋        | 37/221 [00:10<00:57,  3.19it/s][A
 17%|█▋        | 38/221 [00:11<00:55,  3.31it/s][A
 18%|█▊        | 39/221 [00:11<00:50,  3.58it/s][A
 18%|█▊        | 40/221 [00:11<00:49,  3.66it/s][A
 19%|█▊        | 41/221 [00:11<00:53,  3.37it/s][A
 19%|█▉        | 42/221 [00:12<00:47,  3.80it/s][A
 19%|█▉        | 43/221 [00:12<00:43,  4.05it/s][A
 20%|█▉        | 44/221 [00:12<00:43,  4.09it/s][A
 20%|██        | 45/221 [00:12<00:50,  3.50it/s][A
 21%|██        | 46/221 [00:13<00:50,  3.50it/s][A
 21%|██▏       | 47/221 [00:13<00:44,  3.89it/s][A
 22%|██▏       | 48/221 [00:13<00:37,  4.57it/s][A
 22%|██▏       | 49/221 [00:13<00:31,  5.41it/s][A
 23%|██▎       | 50/221 [00:14<00:44,  3.84it/s][A
 23%|██▎       | 51/221 [00:14<00:46,  3.62it/s][A
 24%|██▎       | 52/221 [00:14<00:46,  3.62it/s][A
 24%|██▍       | 53/221 [00:15<01:01,  2.75it/s][A
 24%|██▍       | 54/221 [00:15<00:51,  3.27it/s][A
 25%|██▍       | 55/221 [00:15<00:56,  2.92it/s][A
 25%|██▌       | 56/221 [00:16<00:53,  3.10it/s][A
 26%|██▌       | 57/221 [00:16<00:48,  3.35it/s][A
 26%|██▌       | 58/221 [00:16<00:51,  3.18it/s][A
 27%|██▋       | 59/221 [00:17<00:49,  3.28it/s][A
 27%|██▋       | 60/221 [00:17<00:41,  3.87it/s][A
 28%|██▊       | 61/221 [00:17<00:38,  4.13it/s][A
 28%|██▊       | 62/221 [00:17<00:41,  3.80it/s][A
 29%|██▉       | 64/221 [00:18<00:36,  4.28it/s][A
 29%|██▉       | 65/221 [00:18<00:36,  4.28it/s][A
 30%|██▉       | 66/221 [00:18<00:37,  4.16it/s][A
 30%|███       | 67/221 [00:18<00:40,  3.84it/s][A
 31%|███       | 68/221 [00:19<00:38,  4.02it/s][A
 31%|███       | 69/221 [00:19<00:52,  2.92it/s][A
 32%|███▏      | 70/221 [00:19<00:49,  3.07it/s][A
 32%|███▏      | 71/221 [00:20<00:49,  3.03it/s][A
 33%|███▎      | 72/221 [00:20<00:50,  2.97it/s][A
 33%|███▎      | 73/221 [00:21<00:50,  2.94it/s][A
 33%|███▎      | 74/221 [00:21<00:51,  2.87it/s][A
 34%|███▍      | 75/221 [00:21<00:47,  3.10it/s][A
 34%|███▍      | 76/221 [00:21<00:38,  3.76it/s][A
 35%|███▍      | 77/221 [00:22<00:41,  3.50it/s][A
 35%|███▌      | 78/221 [00:22<00:40,  3.55it/s][A
 36%|███▌      | 79/221 [00:22<00:39,  3.58it/s][A
 36%|███▌      | 80/221 [00:22<00:36,  3.83it/s][A
 37%|███▋      | 81/221 [00:23<00:36,  3.84it/s][A
 37%|███▋      | 82/221 [00:23<00:33,  4.13it/s][A
 38%|███▊      | 83/221 [00:23<00:31,  4.39it/s][A
 38%|███▊      | 84/221 [00:24<00:46,  2.93it/s][A
 38%|███▊      | 85/221 [00:24<00:45,  2.99it/s][A
 39%|███▉      | 86/221 [00:24<00:52,  2.55it/s][A
 39%|███▉      | 87/221 [00:25<00:52,  2.55it/s][A
 40%|███▉      | 88/221 [00:25<00:48,  2.73it/s][A
 40%|████      | 89/221 [00:26<00:47,  2.78it/s][A
 41%|████      | 90/221 [00:26<00:45,  2.87it/s][A
 41%|████      | 91/221 [00:26<00:46,  2.81it/s][A
 42%|████▏     | 92/221 [00:27<00:45,  2.84it/s][A
 42%|████▏     | 93/221 [00:27<00:55,  2.32it/s][A
 43%|████▎     | 94/221 [00:27<00:48,  2.63it/s][A
 43%|████▎     | 95/221 [00:28<00:54,  2.30it/s][A
 43%|████▎     | 96/221 [00:28<00:55,  2.26it/s][A
 44%|████▍     | 97/221 [00:29<00:45,  2.72it/s][A
 44%|████▍     | 98/221 [00:29<00:43,  2.85it/s][A
 45%|████▍     | 99/221 [00:29<00:40,  3.00it/s][A
 45%|████▌     | 100/221 [00:29<00:34,  3.51it/s][A
 46%|████▌     | 101/221 [00:30<00:29,  4.03it/s][A
 46%|████▌     | 102/221 [00:30<00:31,  3.72it/s][A
 47%|████▋     | 103/221 [00:30<00:29,  3.94it/s][A
 47%|████▋     | 104/221 [00:30<00:27,  4.29it/s][A
 48%|████▊     | 105/221 [00:31<00:33,  3.51it/s][A
 48%|████▊     | 106/221 [00:31<00:36,  3.14it/s][A
 48%|████▊     | 107/221 [00:32<00:41,  2.76it/s][A
 49%|████▉     | 108/221 [00:32<00:36,  3.12it/s][A
 49%|████▉     | 109/221 [00:32<00:31,  3.53it/s][A
 50%|████▉     | 110/221 [00:32<00:30,  3.63it/s][A
 50%|█████     | 111/221 [00:33<00:31,  3.45it/s][A
 51%|█████     | 112/221 [00:33<00:33,  3.27it/s][A
 51%|█████     | 113/221 [00:33<00:35,  3.04it/s][A
 52%|█████▏    | 114/221 [00:33<00:31,  3.45it/s][A
 52%|█████▏    | 115/221 [00:34<00:27,  3.87it/s][A
 52%|█████▏    | 116/221 [00:34<00:25,  4.18it/s][A
 53%|█████▎    | 117/221 [00:34<00:24,  4.17it/s][A
 53%|█████▎    | 118/221 [00:35<00:31,  3.27it/s][A
 54%|█████▍    | 119/221 [00:35<00:36,  2.80it/s][A
 54%|█████▍    | 120/221 [00:35<00:36,  2.75it/s][A
 55%|█████▍    | 121/221 [00:36<00:32,  3.03it/s][A
 55%|█████▌    | 122/221 [00:36<00:29,  3.36it/s][A
 56%|█████▌    | 123/221 [00:36<00:31,  3.07it/s][A
 56%|█████▌    | 124/221 [00:37<00:28,  3.36it/s][A
 57%|█████▋    | 125/221 [00:37<00:33,  2.90it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.40it/s][A
 57%|█████▋    | 127/221 [00:38<00:33,  2.77it/s][A
 58%|█████▊    | 128/221 [00:38<00:29,  3.10it/s][A
 58%|█████▊    | 129/221 [00:38<00:26,  3.49it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.39it/s][A
 59%|█████▉    | 131/221 [00:39<00:23,  3.78it/s][A
 60%|█████▉    | 132/221 [00:39<00:25,  3.55it/s][A
 60%|██████    | 133/221 [00:39<00:29,  2.96it/s][A
 61%|██████    | 134/221 [00:40<00:33,  2.60it/s][A
 61%|██████    | 135/221 [00:40<00:29,  2.94it/s][A
 62%|██████▏   | 136/221 [00:40<00:27,  3.11it/s][A
 62%|██████▏   | 137/221 [00:41<00:23,  3.61it/s][A
 62%|██████▏   | 138/221 [00:41<00:21,  3.94it/s][A
 63%|██████▎   | 139/221 [00:41<00:24,  3.39it/s][A
 63%|██████▎   | 140/221 [00:41<00:22,  3.65it/s][A
 64%|██████▍   | 141/221 [00:42<00:27,  2.90it/s][A
 64%|██████▍   | 142/221 [00:42<00:24,  3.26it/s][A
 65%|██████▍   | 143/221 [00:42<00:21,  3.70it/s][A
 65%|██████▌   | 144/221 [00:43<00:21,  3.52it/s][A
 66%|██████▌   | 145/221 [00:43<00:24,  3.05it/s][A
 66%|██████▌   | 146/221 [00:43<00:23,  3.25it/s][A
 67%|██████▋   | 147/221 [00:44<00:21,  3.51it/s][A
 67%|██████▋   | 148/221 [00:44<00:22,  3.18it/s][A
 67%|██████▋   | 149/221 [00:44<00:20,  3.45it/s][A
 68%|██████▊   | 150/221 [00:44<00:19,  3.66it/s][A
 68%|██████▊   | 151/221 [00:45<00:23,  3.01it/s][A
 69%|██████▉   | 152/221 [00:46<00:31,  2.16it/s][A
 69%|██████▉   | 153/221 [00:46<00:28,  2.41it/s][A
 70%|██████▉   | 154/221 [00:46<00:26,  2.50it/s][A
 70%|███████   | 155/221 [00:47<00:24,  2.69it/s][A
 71%|███████   | 156/221 [00:47<00:20,  3.19it/s][A
 71%|███████   | 157/221 [00:47<00:18,  3.38it/s][A
 71%|███████▏  | 158/221 [00:47<00:20,  3.08it/s][A
 72%|███████▏  | 159/221 [00:48<00:18,  3.30it/s][A
 72%|███████▏  | 160/221 [00:48<00:16,  3.71it/s][A
 73%|███████▎  | 161/221 [00:48<00:14,  4.08it/s][A
 73%|███████▎  | 162/221 [00:48<00:12,  4.85it/s][A
 74%|███████▍  | 163/221 [00:48<00:13,  4.36it/s][A
 74%|███████▍  | 164/221 [00:49<00:12,  4.73it/s][A
 75%|███████▍  | 165/221 [00:49<00:14,  3.81it/s][A
 75%|███████▌  | 166/221 [00:49<00:15,  3.46it/s][A
 76%|███████▌  | 168/221 [00:50<00:12,  4.21it/s][A
 77%|███████▋  | 170/221 [00:50<00:13,  3.78it/s][A
 77%|███████▋  | 171/221 [00:51<00:13,  3.58it/s][A
 78%|███████▊  | 172/221 [00:51<00:14,  3.47it/s][A
 78%|███████▊  | 173/221 [00:51<00:13,  3.66it/s][A
 79%|███████▊  | 174/221 [00:51<00:12,  3.86it/s][A
 79%|███████▉  | 175/221 [00:52<00:12,  3.62it/s][A
 80%|███████▉  | 176/221 [00:52<00:11,  3.93it/s][A
 80%|████████  | 177/221 [00:52<00:11,  3.83it/s][A
 81%|████████  | 178/221 [00:53<00:17,  2.47it/s][A
 81%|████████  | 179/221 [00:53<00:15,  2.78it/s][A
 81%|████████▏ | 180/221 [00:54<00:13,  2.96it/s][A
 82%|████████▏ | 181/221 [00:54<00:17,  2.26it/s][A
 82%|████████▏ | 182/221 [00:55<00:15,  2.45it/s][A
 83%|████████▎ | 183/221 [00:55<00:14,  2.61it/s][A
 83%|████████▎ | 184/221 [00:55<00:13,  2.83it/s][A
 84%|████████▎ | 185/221 [00:55<00:10,  3.53it/s][A
 84%|████████▍ | 186/221 [00:56<00:11,  3.08it/s][A
 85%|████████▍ | 187/221 [00:56<00:10,  3.31it/s][A
 85%|████████▌ | 188/221 [00:56<00:09,  3.48it/s][A
 86%|████████▌ | 189/221 [00:56<00:08,  3.75it/s][A
 86%|████████▌ | 190/221 [00:57<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:57<00:08,  3.65it/s][A
 87%|████████▋ | 192/221 [00:57<00:08,  3.62it/s][A
 87%|████████▋ | 193/221 [00:58<00:07,  3.69it/s][A
 88%|████████▊ | 194/221 [00:58<00:07,  3.55it/s][A
 88%|████████▊ | 195/221 [00:58<00:06,  4.24it/s][A
 89%|████████▊ | 196/221 [00:58<00:07,  3.45it/s][A
 89%|████████▉ | 197/221 [00:59<00:07,  3.10it/s][A
 90%|████████▉ | 198/221 [00:59<00:07,  2.94it/s][A
 90%|█████████ | 199/221 [00:59<00:06,  3.57it/s][A
 90%|█████████ | 200/221 [01:00<00:05,  3.68it/s][A
 91%|█████████ | 201/221 [01:00<00:05,  3.88it/s][A
 91%|█████████▏| 202/221 [01:00<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [01:00<00:04,  3.74it/s][A
 92%|█████████▏| 204/221 [01:01<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:01<00:04,  3.61it/s][A
 93%|█████████▎| 206/221 [01:01<00:04,  3.01it/s][A
 94%|█████████▎| 207/221 [01:02<00:05,  2.70it/s][A
 94%|█████████▍| 208/221 [01:02<00:04,  3.12it/s][A
 95%|█████████▍| 209/221 [01:02<00:03,  3.63it/s][A
 95%|█████████▌| 210/221 [01:03<00:03,  2.81it/s][A
 95%|█████████▌| 211/221 [01:03<00:03,  3.08it/s][A
 96%|█████████▌| 212/221 [01:03<00:02,  3.21it/s][A
 96%|█████████▋| 213/221 [01:04<00:02,  3.47it/s][A
 97%|█████████▋| 214/221 [01:04<00:02,  3.40it/s][A
 97%|█████████▋| 215/221 [01:04<00:01,  3.13it/s][A
 98%|█████████▊| 216/221 [01:05<00:01,  3.14it/s][A
 98%|█████████▊| 217/221 [01:05<00:01,  3.33it/s][A
 99%|█████████▊| 218/221 [01:05<00:00,  3.23it/s][A
 99%|█████████▉| 219/221 [01:06<00:00,  2.99it/s][A
100%|█████████▉| 220/221 [01:06<00:00,  3.49it/s][A
100%|██████████| 221/221 [01:06<00:00,  3.52it/s][A100%|██████████| 221/221 [01:06<00:00,  3.32it/s]
09/17/2024 06:38:07 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 1149--===========

09/17/2024 06:38:07 - INFO - __main__ -   {'area_r1': 38.5, 'area_recall': '38.5/62.7/72.6', 'area_ravg': 57.9}
09/17/2024 06:38:07 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 1149--===========

09/17/2024 06:38:07 - INFO - __main__ -   {'forward_r1': 38.1, 'forward_recall': '38.1/66.0/77.3', 'forward_ravg': 60.4}
09/17/2024 06:38:07 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 1149--===========

09/17/2024 06:38:07 - INFO - __main__ -   {'area_video_r1': 39.8, 'area_video_recall': '39.8/66.6/77.1', 'area_video_ravg': 61.2}
09/17/2024 06:38:07 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 299=======

09/17/2024 06:38:07 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 06:38:07 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 1149--===========

09/17/2024 06:38:07 - INFO - __main__ -   {'area_video_r1': 52.1, 'area_video_recall': '52.1/74.5/82.0', 'area_video_ravg': 69.6, 'area_video_back_r1': 47.5, 'area_video_back_recall': '47.5/74.2/81.9', 'area_video_back_ravg': 67.9}
09/17/2024 06:38:07 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 549=======

09/17/2024 06:38:07 - INFO - __main__ -   {'area_video_r1': 54.1, 'area_video_recall': '54.1/75.5/82.4', 'area_video_ravg': 70.6, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.5/82.1', 'area_video_back_ravg': 68.7}
09/17/2024 06:38:07 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 1149--===========

09/17/2024 06:38:07 - INFO - __main__ -   {'video_r1': 37.7, 'video_recall': '37.7/63.7/73.4', 'video_ravg': 58.3}
09/17/2024 06:38:07 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 949=======

09/17/2024 06:38:07 - INFO - __main__ -   {'video_r1': 38.7, 'video_recall': '38.7/64.3/74.1', 'video_ravg': 59.0}
09/17/2024 06:38:07 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 1149--===========

09/17/2024 06:38:07 - INFO - __main__ -   {'video_r1': 52.3, 'video_recall': '52.3/74.8/82.0', 'video_ravg': 69.7}
09/17/2024 06:38:07 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 549=======

09/17/2024 06:38:07 - INFO - __main__ -   {'video_r1': 54.5, 'video_recall': '54.5/76.1/83.4', 'video_ravg': 71.3}
09/17/2024 06:38:31 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.006557141430675983, 'loss_ret%tv%ta--finetune_area/loss_area': 1.0998318195343018, 'loss_ret%tv%ta--finetune_area/total_loss': 1.1063889265060425}
 40%|███▉      | 1150/2910 [7:16:48<65:17:42, 133.56s/it] 40%|███▉      | 1151/2910 [7:16:51<46:10:03, 94.49s/it]  40%|███▉      | 1152/2910 [7:16:55<32:46:45, 67.13s/it] 40%|███▉      | 1153/2910 [7:16:58<23:24:56, 47.98s/it] 40%|███▉      | 1154/2910 [7:17:01<16:52:06, 34.58s/it] 40%|███▉      | 1155/2910 [7:17:05<12:17:02, 25.20s/it] 40%|███▉      | 1156/2910 [7:17:08<9:04:47, 18.64s/it]  40%|███▉      | 1157/2910 [7:17:11<6:50:17, 14.04s/it] 40%|███▉      | 1158/2910 [7:17:15<5:16:10, 10.83s/it] 40%|███▉      | 1159/2910 [7:17:18<4:10:06,  8.57s/it] 40%|███▉      | 1160/2910 [7:17:21<3:23:52,  6.99s/it] 40%|███▉      | 1161/2910 [7:17:24<2:51:30,  5.88s/it] 40%|███▉      | 1162/2910 [7:17:28<2:29:03,  5.12s/it] 40%|███▉      | 1163/2910 [7:17:31<2:13:19,  4.58s/it]/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
09/17/2024 06:39:35 - INFO - __main__ -   current idx hvInlSH5o8c.6 from finetune_area returns wrong image/video, use 58277 instead.
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
09/17/2024 06:39:38 - INFO - __main__ -   current idx EPDKsPkI96E.8 from finetune_area returns wrong image/video, use 53857 instead.
[h264 @ 0x5607415f7400] mmco: unref short failure
[h264 @ 0x55a30f4ede40] mmco: unref short failure
09/17/2024 06:39:43 - INFO - __main__ -   current idx YaJzQ11Pq8c.26 from finetune_area returns wrong image/video, use 141665 instead.
[h264 @ 0x55b5aabc0340] mmco: unref short failure
[h264 @ 0x55b5aabc0340] mmco: unref short failure
[h264 @ 0x55e2377d7a00] mmco: unref short failure
[h264 @ 0x55e237d41140] mmco: unref short failure
[h264 @ 0x560741300e00] mmco: unref short failure
[h264 @ 0x55e237a5a140] mmco: unref short failure
[h264 @ 0x55e237a5a140] mmco: unref short failure
[h264 @ 0x55e237c9c380] mmco: unref short failure
[h264 @ 0x560741e14880] mmco: unref short failure
[h264 @ 0x560741e14880] mmco: unref short failure
[h264 @ 0x55a30f810300] mmco: unref short failure
[h264 @ 0x55a30f810300] mmco: unref short failure
[h264 @ 0x55a30ff56380] mmco: unref short failure
[h264 @ 0x5607419a9880] mmco: unref short failure
[h264 @ 0x5607419a9880] mmco: unref short failure
[h264 @ 0x560741041e00] mmco: unref short failure
[h264 @ 0x55e237513cc0] mmco: unref short failure
[h264 @ 0x55e237513cc0] mmco: unref short failure
[h264 @ 0x56074170db00] mmco: unref short failure
[h264 @ 0x56074170db00] mmco: unref short failure
[h264 @ 0x55e2382e6400] mmco: unref short failure
[h264 @ 0x55e2382e6400] mmco: unref short failure
[h264 @ 0x55b5aa603d40] mmco: unref short failure
[h264 @ 0x55b5aa603d40] mmco: unref short failure
[h264 @ 0x560745edb040] mmco: unref short failure
[h264 @ 0x55b5a9fccd00] mmco: unref short failure
[h264 @ 0x55b5a9fccd00] mmco: unref short failure
[h264 @ 0x55b5a9fccd00] mmco: unref short failure
09/17/2024 06:41:13 - INFO - __main__ -   current idx dMEgMG6TS3c.6 from finetune_area returns wrong image/video, use 15963 instead.
[h264 @ 0x55b5af29cd00] mmco: unref short failure
09/17/2024 06:41:35 - INFO - __main__ -   current idx 0qE_NisFgLw.2 from finetune_area returns wrong image/video, use 137038 instead.
[h264 @ 0x55b5a9397bc0] mmco: unref short failure
[h264 @ 0x55b5aacbf9c0] mmco: unref short failure
[h264 @ 0x55b5aacbf9c0] mmco: unref short failure
[h264 @ 0x55b5aacbf9c0] mmco: unref short failure
[h264 @ 0x55b5aacbf9c0] mmco: unref short failure
[h264 @ 0x55e238124d00] mmco: unref short failure
[h264 @ 0x55e238124d00] mmco: unref short failure
[h264 @ 0x55e23c7bf300] mmco: unref short failure
[h264 @ 0x55e23c7bf300] mmco: unref short failure
[h264 @ 0x55e23ca9f5c0] mmco: unref short failure
 40%|████      | 1164/2910 [7:20:14<25:13:31, 52.01s/it][h264 @ 0x5607455d4780] mmco: unref short failure
[h264 @ 0x5607455d4780] mmco: unref short failure
[h264 @ 0x5607455d4780] mmco: unref short failure
[h264 @ 0x5607455d4780] mmco: unref short failure
[h264 @ 0x55b5aa14ff80] mmco: unref short failure
 40%|████      | 1165/2910 [7:20:21<18:43:29, 38.63s/it][h264 @ 0x55e237d8d040] mmco: unref short failure
 40%|████      | 1166/2910 [7:20:27<13:55:35, 28.75s/it]09/17/2024 06:42:13 - INFO - __main__ -   current idx jwBpRLj02q4.46 from finetune_area returns wrong image/video, use 48306 instead.
[h264 @ 0x560741b95200] mmco: unref short failure
[h264 @ 0x560741b95200] mmco: unref short failure
[h264 @ 0x560741b95200] mmco: unref short failure
[h264 @ 0x55e23c7c2100] mmco: unref short failure
 40%|████      | 1167/2910 [7:20:32<10:28:12, 21.63s/it][h264 @ 0x560744a11b80] mmco: unref short failure
[h264 @ 0x560744a11b80] mmco: unref short failure
 40%|████      | 1168/2910 [7:20:37<8:06:13, 16.75s/it]  40%|████      | 1169/2910 [7:20:42<6:22:12, 13.17s/it][h264 @ 0x55a3153ae840] mmco: unref short failure
[h264 @ 0x55a3153ae840] mmco: unref short failure
[h264 @ 0x56074a66c5c0] mmco: unref short failure
[h264 @ 0x56074a66c5c0] mmco: unref short failure
[h264 @ 0x55e237e8d200] mmco: unref short failure
[h264 @ 0x55b5aa201800] mmco: unref short failure
[h264 @ 0x55e237613080] mmco: unref short failure
[h264 @ 0x56074225ec80] mmco: unref short failure
 40%|████      | 1170/2910 [7:20:47<5:09:37, 10.68s/it] 40%|████      | 1171/2910 [7:20:53<4:28:11,  9.25s/it][h264 @ 0x5607465ba900] mmco: unref short failure
[h264 @ 0x5607465ba900] mmco: unref short failure
[h264 @ 0x55e2367c18c0] mmco: unref short failure
09/17/2024 06:42:47 - INFO - __main__ -   current idx _QteUi76_ZA.36 from finetune_area returns wrong image/video, use 148529 instead.
[h264 @ 0x55e23b7f37c0] mmco: unref short failure
[h264 @ 0x55e23b7f37c0] mmco: unref short failure
[h264 @ 0x55e23b7f37c0] mmco: unref short failure
[h264 @ 0x55e23b7f37c0] mmco: unref short failure
[h264 @ 0x55b5ab619fc0] mmco: unref short failure
[h264 @ 0x55b5ab619fc0] mmco: unref short failure
[h264 @ 0x55b5a9e830c0] mmco: unref short failure
[h264 @ 0x55e239d9ff40] mmco: unref short failure
[h264 @ 0x55e239d9ff40] mmco: unref short failure
[h264 @ 0x55b5aa785dc0] mmco: unref short failure
[h264 @ 0x55b5aa785dc0] mmco: unref short failure
09/17/2024 06:43:12 - INFO - __main__ -   current idx VF7SD44bbzI.9 from finetune_area returns wrong image/video, use 61383 instead.
09/17/2024 06:43:19 - INFO - __main__ -   current idx Fo_7-g_Hdvc.61 from finetune_area returns wrong image/video, use 70544 instead.
[h264 @ 0x55b5aafc9c40] mmco: unref short failure
[h264 @ 0x55b5aafc9c40] mmco: unref short failure
[h264 @ 0x55e23a867280] mmco: unref short failure
[h264 @ 0x5607498c2680] mmco: unref short failure
[h264 @ 0x5607498c2680] mmco: unref short failure
[h264 @ 0x55b5b41b5900] mmco: unref short failure
[h264 @ 0x55b5b41b5900] mmco: unref short failure
[h264 @ 0x56074694c440] mmco: unref short failure
[h264 @ 0x56074694c440] mmco: unref short failure
[h264 @ 0x55e23c1965c0] mmco: unref short failure
09/17/2024 06:44:02 - INFO - __main__ -   current idx 9GAdW4Xa3MU.69 from finetune_area returns wrong image/video, use 76622 instead.
[h264 @ 0x55e23ba0a540] mmco: unref short failure
[h264 @ 0x55e23ba0a540] mmco: unref short failure
[h264 @ 0x55e23ba0a540] mmco: unref short failure
[h264 @ 0x560740dd6d00] mmco: unref short failure
[h264 @ 0x56074984f200] mmco: unref short failure
[h264 @ 0x560744bdd900] mmco: unref short failure
09/17/2024 06:44:29 - INFO - __main__ -   current idx iQnvNd6wTj4.78 from finetune_area returns wrong image/video, use 33910 instead.
 40%|████      | 1172/2910 [7:22:44<19:13:26, 39.82s/it] 40%|████      | 1173/2910 [7:22:49<14:10:08, 29.37s/it][h264 @ 0x55a315b44b00] mmco: unref short failure
[h264 @ 0x55e23acd8640] mmco: unref short failure
[h264 @ 0x55e23acd8640] mmco: unref short failure
 40%|████      | 1174/2910 [7:22:55<10:43:03, 22.23s/it] 40%|████      | 1175/2910 [7:23:00<8:18:45, 17.25s/it] [h264 @ 0x55b5b3219980] mmco: unref short failure
 40%|████      | 1176/2910 [7:23:06<6:38:36, 13.79s/it][h264 @ 0x55a31864d080] mmco: unref short failure
[h264 @ 0x55a31864d080] mmco: unref short failure
 40%|████      | 1177/2910 [7:23:13<5:43:29, 11.89s/it][h264 @ 0x55e23764ef80] mmco: unref short failure
[h264 @ 0x55b5b0e68b40] mmco: unref short failure
[h264 @ 0x55b5b0e68b40] mmco: unref short failure
[h264 @ 0x55b5b0e68b40] mmco: unref short failure
[h264 @ 0x55b5b0e68b40] mmco: unref short failure
09/17/2024 06:45:04 - INFO - __main__ -   current idx bKcVjDTXHbM.6 from finetune_area returns wrong image/video, use 109854 instead.
 40%|████      | 1178/2910 [7:23:19<4:45:55,  9.91s/it] 41%|████      | 1179/2910 [7:23:24<4:09:21,  8.64s/it][h264 @ 0x55b5af3badc0] mmco: unref short failure
[h264 @ 0x55b5af3badc0] mmco: unref short failure
[h264 @ 0x55a3115415c0] mmco: unref short failure
[h264 @ 0x55a3115415c0] mmco: unref short failure
[h264 @ 0x55b5af714980] mmco: unref short failure
[h264 @ 0x55b5af714980] mmco: unref short failure
09/17/2024 06:45:26 - INFO - __main__ -   current idx E852WPZZnME.32 from finetune_area returns wrong image/video, use 103597 instead.
[h264 @ 0x5607480c61c0] mmco: unref short failure
[h264 @ 0x5607480c61c0] mmco: unref short failure
[h264 @ 0x55a31a982280] mmco: unref short failure
[h264 @ 0x5607420d9f40] mmco: unref short failure
[h264 @ 0x5607477b7b00] mmco: unref short failure
[h264 @ 0x5607477b7b00] mmco: unref short failure
[h264 @ 0x55e244e55f80] mmco: unref short failure
[h264 @ 0x55e244e55f80] mmco: unref short failure
[h264 @ 0x55e23c3e18c0] mmco: unref short failure
[h264 @ 0x55a30f06d080] mmco: unref short failure
[h264 @ 0x55a30f06d080] mmco: unref short failure
[h264 @ 0x55b5a9798980] mmco: unref short failure
[h264 @ 0x55b5a9798980] mmco: unref short failure
[h264 @ 0x55a31a95a500] mmco: unref short failure
[h264 @ 0x55e2449c9b80] mmco: unref short failure
[h264 @ 0x55e2449c9b80] mmco: unref short failure
[h264 @ 0x55e2449c9b80] mmco: unref short failure
[h264 @ 0x55e2449c9b80] mmco: unref short failure
[h264 @ 0x55e2380d4a80] mmco: unref short failure
[h264 @ 0x55e2380d4a80] mmco: unref short failure
[h264 @ 0x560741c34380] mmco: unref short failure
[h264 @ 0x560741c34380] mmco: unref short failure
[h264 @ 0x560741c34380] mmco: unref short failure
[h264 @ 0x560741c34380] mmco: unref short failure
[h264 @ 0x55b5ab83ac40] mmco: unref short failure
09/17/2024 06:46:13 - INFO - __main__ -   current idx A2e7HyCQqvE.54 from finetune_area returns wrong image/video, use 16231 instead.
09/17/2024 06:46:18 - INFO - __main__ -   current idx edpFNTpJidw.6 from finetune_area returns wrong image/video, use 65972 instead.
[h264 @ 0x560742655f00] mmco: unref short failure
[h264 @ 0x560742655f00] mmco: unref short failure
[h264 @ 0x55e23b92ae40] mmco: unref short failure
[h264 @ 0x560741d35b40] mmco: unref short failure
[h264 @ 0x560741d35b40] mmco: unref short failure
[h264 @ 0x55a313cdf200] mmco: unref short failure
[h264 @ 0x55a313cdf200] mmco: unref short failure
[h264 @ 0x560742bfeb80] mmco: unref short failure
[h264 @ 0x560742bfeb80] mmco: unref short failure
[h264 @ 0x560742bfeb80] mmco: unref short failure
[h264 @ 0x560742bfeb80] mmco: unref short failure
[h264 @ 0x560742bfeb80] mmco: unref short failure
[h264 @ 0x560742bfeb80] mmco: unref short failure
[h264 @ 0x560742bfeb80] mmco: unref short failure
[h264 @ 0x560742bfeb80] mmco: unref short failure
[h264 @ 0x55e237b3e100] mmco: unref short failure
[h264 @ 0x55b5abcd2ec0] mmco: unref short failure
09/17/2024 06:46:55 - INFO - __main__ -   current idx sisprxhsc6I.5 from finetune_area returns wrong image/video, use 11803 instead.
 41%|████      | 1180/2910 [7:25:14<18:44:44, 39.01s/it] 41%|████      | 1181/2910 [7:25:20<13:54:40, 28.96s/it] 41%|████      | 1182/2910 [7:25:25<10:33:33, 22.00s/it][h264 @ 0x55a31aa8db40] mmco: unref short failure
 41%|████      | 1183/2910 [7:25:32<8:15:52, 17.23s/it] [h264 @ 0x55e2435cef00] mmco: unref short failure
[h264 @ 0x55e2435cef00] mmco: unref short failure
[h264 @ 0x560741e6b740] mmco: unref short failure
[h264 @ 0x55b5aa6ffb40] mmco: unref short failure
 41%|████      | 1184/2910 [7:25:37<6:32:37, 13.65s/it] 41%|████      | 1185/2910 [7:25:42<5:18:10, 11.07s/it] 41%|████      | 1186/2910 [7:25:47<4:27:54,  9.32s/it][h264 @ 0x55e239f6c4c0] mmco: unref short failure
[h264 @ 0x55e239f6c4c0] mmco: unref short failure
[h264 @ 0x55a311232c40] mmco: unref short failure
[h264 @ 0x55a311232c40] mmco: unref short failure
[h264 @ 0x55e23c868280] mmco: unref short failure
 41%|████      | 1187/2910 [7:25:53<3:56:06,  8.22s/it][h264 @ 0x55b5b02f8380] mmco: unref short failure
[h264 @ 0x560744b0ab40] mmco: unref short failure
[h264 @ 0x560744b0ab40] mmco: unref short failure
[h264 @ 0x55e246c048c0] mmco: unref short failure
[h264 @ 0x55a3151f67c0] mmco: unref short failure
[h264 @ 0x55a3151f67c0] mmco: unref short failure
[h264 @ 0x55b5aabf1f80] mmco: unref short failure
[h264 @ 0x55b5aabf1f80] mmco: unref short failure
[h264 @ 0x5607529a3f40] mmco: unref short failure
[h264 @ 0x5607529a3f40] mmco: unref short failure
[h264 @ 0x55b5ada66340] mmco: unref short failure
[h264 @ 0x55b5ada66340] mmco: unref short failure
[h264 @ 0x56074949cfc0] mmco: unref short failure
[h264 @ 0x55b5abeaaf00] mmco: unref short failure
[h264 @ 0x55b5abeaaf00] mmco: unref short failure
[h264 @ 0x55e237ad7fc0] mmco: unref short failure
[h264 @ 0x55e237ad7fc0] mmco: unref short failure
[h264 @ 0x55a31e8d9e80] mmco: unref short failure
[h264 @ 0x55a31e8d9e80] mmco: unref short failure
[h264 @ 0x55a31e8d9e80] mmco: unref short failure
[h264 @ 0x55a31e8d9e80] mmco: unref short failure
[h264 @ 0x55a31e8d9e80] mmco: unref short failure
[h264 @ 0x55a31e8d9e80] mmco: unref short failure
[h264 @ 0x55a31e8d9e80] mmco: unref short failure
[h264 @ 0x55a31e8d9e80] mmco: unref short failure
[h264 @ 0x56074223a680] mmco: unref short failure
[h264 @ 0x56074223a680] mmco: unref short failure
[h264 @ 0x55e239b166c0] mmco: unref short failure
 41%|████      | 1188/2910 [7:27:45<18:52:32, 39.46s/it][h264 @ 0x55e246f55a80] mmco: unref short failure
[h264 @ 0x55e246f55a80] mmco: unref short failure
[h264 @ 0x55b5b0927ac0] mmco: unref short failure
[h264 @ 0x55b5b0927ac0] mmco: unref short failure
[h264 @ 0x56074f89d340] mmco: unref short failure
 41%|████      | 1189/2910 [7:28:08<16:25:12, 34.35s/it][h264 @ 0x560745f6e000] mmco: unref short failure
[h264 @ 0x560745f6e000] mmco: unref short failure
[h264 @ 0x55e2458aa280] mmco: unref short failure
 41%|████      | 1190/2910 [7:28:13<12:16:10, 25.68s/it] 41%|████      | 1191/2910 [7:28:18<9:18:58, 19.51s/it]  41%|████      | 1192/2910 [7:28:23<7:15:07, 15.20s/it][h264 @ 0x55e2486d6880] mmco: unref short failure
 41%|████      | 1193/2910 [7:28:28<5:46:29, 12.11s/it][h264 @ 0x55b5ab203940] mmco: unref short failure
09/17/2024 06:50:18 - INFO - __main__ -   current idx gVhwSbu4UfU.1 from finetune_area returns wrong image/video, use 49459 instead.
 41%|████      | 1194/2910 [7:28:33<4:48:02, 10.07s/it] 41%|████      | 1195/2910 [7:28:39<4:06:18,  8.62s/it][h264 @ 0x55a31cdd7f80] mmco: unref short failure
[h264 @ 0x55a31cdd7f80] mmco: unref short failure
09/17/2024 06:50:47 - INFO - __main__ -   current idx rGthtRZl8B0.21 from finetune_area returns wrong image/video, use 18014 instead.
[h264 @ 0x55b5bd64e200] mmco: unref short failure
[h264 @ 0x55b5bd64e200] mmco: unref short failure
[h264 @ 0x55b5b2798d00] mmco: unref short failure
[h264 @ 0x560746bf8f00] mmco: unref short failure
[h264 @ 0x560746bf8f00] mmco: unref short failure
[h264 @ 0x55b5b22dd9c0] mmco: unref short failure
[h264 @ 0x55b5b22dd9c0] mmco: unref short failure
[h264 @ 0x55b5b252c2c0] mmco: unref short failure
[h264 @ 0x55b5ad630980] mmco: unref short failure
[h264 @ 0x55b5ad630980] mmco: unref short failure
[h264 @ 0x55a31114a480] mmco: unref short failure
[h264 @ 0x55a31113fe00] mmco: unref short failure
[h264 @ 0x55a31113fe00] mmco: unref short failure
[h264 @ 0x56074fe60240] mmco: unref short failure
[h264 @ 0x56074fe60240] mmco: unref short failure
[h264 @ 0x5607428fe540] mmco: unref short failure
[h264 @ 0x55a31b0d5300] mmco: unref short failure
[h264 @ 0x55a31b0d5300] mmco: unref short failure
[h264 @ 0x55a31b0d5300] mmco: unref short failure
[h264 @ 0x55a3128b8fc0] mmco: unref short failure
[h264 @ 0x55a3128b8fc0] mmco: unref short failure
[h264 @ 0x56074e3dbc80] mmco: unref short failure
[h264 @ 0x55e23678c200] mmco: unref short failure
[h264 @ 0x55e23678c200] mmco: unref short failure
[h264 @ 0x55b5af8a7d80] mmco: unref short failure
[h264 @ 0x55b5b1a7bd80] mmco: unref short failure
[h264 @ 0x55b5b1a7bd80] mmco: unref short failure
09/17/2024 06:51:34 - INFO - __main__ -   current idx ABt7P6s9bFM.27 from finetune_area returns wrong image/video, use 18727 instead.
[h264 @ 0x55a322a10140] mmco: unref short failure
[h264 @ 0x55a322a10140] mmco: unref short failure
[h264 @ 0x55e239b62400] mmco: unref short failure
[h264 @ 0x55b5bb1f8a80] mmco: unref short failure
[h264 @ 0x55b5bb1f8a80] mmco: unref short failure
[h264 @ 0x55e23b09e500] mmco: unref short failure
[h264 @ 0x55e23b09e500] mmco: unref short failure
[h264 @ 0x56074d5f2000] mmco: unref short failure
[h264 @ 0x56074d5f2000] mmco: unref short failure
[h264 @ 0x56074d5f2000] mmco: unref short failure
[h264 @ 0x56074d5f2000] mmco: unref short failure
 41%|████      | 1196/2910 [7:30:17<16:51:24, 35.41s/it][h264 @ 0x55b5b55516c0] mmco: unref short failure
[h264 @ 0x55b5b55516c0] mmco: unref short failure
09/17/2024 06:52:08 - INFO - __main__ -   current idx 7KJbYhfV6fg.3 from finetune_area returns wrong image/video, use 52439 instead.
[h264 @ 0x5607438b3740] mmco: unref short failure
[h264 @ 0x5607438b3740] mmco: unref short failure
[h264 @ 0x5607438b3740] mmco: unref short failure
[h264 @ 0x5607438b3740] mmco: unref short failure
 41%|████      | 1197/2910 [7:30:30<13:39:46, 28.71s/it] 41%|████      | 1198/2910 [7:30:35<10:19:08, 21.70s/it][h264 @ 0x55a31ceccd80] mmco: unref short failure
 41%|████      | 1199/2910 [7:30:41<8:01:49, 16.90s/it] 09/17/2024 06:52:27 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 06:52:27 - INFO - __main__ -   start running ret%tva validation...
[h264 @ 0x55a31041d500] mmco: unref short failure
[h264 @ 0x55a31041d500] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a3185f7b80] mmco: unref short failure
[h264 @ 0x55a3185f7b80] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a310709300] mmco: unref short failure
[h264 @ 0x55a310709300] mmco: unref short failure
[h264 @ 0x55a310709300] mmco: unref short failure
[h264 @ 0x55a310709300] mmco: unref short failure
[h264 @ 0x55a310709300] mmco: unref short failure
[h264 @ 0x55a310709300] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e248f54e40] mmco: unref short failure
[h264 @ 0x55e23a184040] mmco: unref short failure
[h264 @ 0x55e23a184040] mmco: unref short failure
[h264 @ 0x55e23a184040] mmco: unref short failure
[h264 @ 0x55e23a184040] mmco: unref short failure
[h264 @ 0x55a3213a1c00] mmco: unref short failure
[h264 @ 0x55a3213a1c00] mmco: unref short failure
09/17/2024 06:53:58 - INFO - __main__ -   current idx fghob2AsEWE.61 from finetune_area returns wrong image/video, use 79709 instead.
[h264 @ 0x55a31cb63200] mmco: unref short failure
[h264 @ 0x55a31cb63200] mmco: unref short failure
[h264 @ 0x56074b22dc80] mmco: unref short failure
[h264 @ 0x56074b22dc80] mmco: unref short failure
[h264 @ 0x55e241d56700] mmco: unref short failure
[h264 @ 0x56075a1706c0] mmco: unref short failure
[h264 @ 0x56075a1706c0] mmco: unref short failure
[h264 @ 0x56074c444e00] mmco: unref short failure
[h264 @ 0x56074c444e00] mmco: unref short failure
[h264 @ 0x55a318782200] mmco: unref short failure
[h264 @ 0x55a318782200] mmco: unref short failure
[h264 @ 0x55b5b4ef52c0] mmco: unref short failure
[h264 @ 0x560747807fc0] mmco: unref short failure
[h264 @ 0x55a3168e2180] mmco: unref short failure
[h264 @ 0x55a3168e2180] mmco: unref short failure
[h264 @ 0x56075622d940] mmco: unref short failure
[h264 @ 0x56075622d940] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A[h264 @ 0x560751365c80] mmco: unref short failure
[h264 @ 0x560751365c80] mmco: unref short failure

  0%|          | 1/221 [00:01<03:48,  1.04s/it][A
  1%|          | 2/221 [00:01<02:45,  1.32it/s][A
  1%|▏         | 3/221 [00:01<01:51,  1.96it/s][A
  2%|▏         | 4/221 [00:02<01:25,  2.52it/s][A
  2%|▏         | 5/221 [00:02<01:07,  3.21it/s][A
  3%|▎         | 7/221 [00:02<00:48,  4.40it/s][A
  4%|▎         | 8/221 [00:03<01:10,  3.02it/s][A
  4%|▍         | 9/221 [00:03<01:01,  3.45it/s][A
  5%|▍         | 10/221 [00:03<01:03,  3.35it/s][A
  5%|▍         | 11/221 [00:03<00:51,  4.10it/s][A
  5%|▌         | 12/221 [00:04<01:10,  2.96it/s][A
  6%|▌         | 13/221 [00:04<00:57,  3.60it/s][A
  6%|▋         | 14/221 [00:06<02:31,  1.37it/s][A
  7%|▋         | 15/221 [00:06<02:00,  1.72it/s][A
  7%|▋         | 16/221 [00:06<01:41,  2.03it/s][A
  8%|▊         | 17/221 [00:06<01:24,  2.42it/s][A
  8%|▊         | 18/221 [00:07<01:13,  2.77it/s][A
  9%|▊         | 19/221 [00:07<00:58,  3.43it/s][A
  9%|▉         | 20/221 [00:07<00:49,  4.07it/s][A
 10%|▉         | 21/221 [00:07<00:40,  4.91it/s][A
 10%|▉         | 22/221 [00:07<00:39,  5.00it/s][A
 10%|█         | 23/221 [00:07<00:36,  5.49it/s][A
 11%|█         | 24/221 [00:08<00:35,  5.59it/s][A
 11%|█▏        | 25/221 [00:08<00:35,  5.49it/s][A
 12%|█▏        | 26/221 [00:08<00:42,  4.61it/s][A
 13%|█▎        | 28/221 [00:08<00:41,  4.63it/s][A[h264 @ 0x55e23a5b5b80] mmco: unref short failure

 14%|█▎        | 30/221 [00:09<00:34,  5.48it/s][A
 14%|█▍        | 31/221 [00:09<00:36,  5.25it/s][A
 15%|█▍        | 33/221 [00:10<00:44,  4.18it/s][A
 15%|█▌        | 34/221 [00:10<00:39,  4.74it/s][A
 16%|█▌        | 35/221 [00:10<00:35,  5.23it/s][A
 16%|█▋        | 36/221 [00:10<00:36,  5.13it/s][A
 17%|█▋        | 37/221 [00:11<01:01,  2.98it/s][A
 17%|█▋        | 38/221 [00:11<01:03,  2.90it/s][A
 18%|█▊        | 40/221 [00:11<00:45,  3.96it/s][A
 19%|█▊        | 41/221 [00:12<00:45,  3.93it/s][A
 19%|█▉        | 42/221 [00:12<00:51,  3.48it/s][A
 19%|█▉        | 43/221 [00:12<00:42,  4.19it/s][A
 20%|█▉        | 44/221 [00:12<00:35,  4.95it/s][A
 20%|██        | 45/221 [00:14<01:28,  1.99it/s][A
 21%|██        | 46/221 [00:14<01:29,  1.95it/s][A
 21%|██▏       | 47/221 [00:16<02:15,  1.28it/s][A
 22%|██▏       | 48/221 [00:16<01:43,  1.68it/s][A
 22%|██▏       | 49/221 [00:16<01:23,  2.05it/s][A
 23%|██▎       | 50/221 [00:16<01:11,  2.39it/s][A
 23%|██▎       | 51/221 [00:16<00:57,  2.93it/s][A
 24%|██▎       | 52/221 [00:16<00:47,  3.55it/s][A
 24%|██▍       | 53/221 [00:17<00:39,  4.28it/s][A
 24%|██▍       | 54/221 [00:17<01:13,  2.26it/s][A
 25%|██▍       | 55/221 [00:18<01:12,  2.30it/s][A
 25%|██▌       | 56/221 [00:18<01:05,  2.51it/s][A
 26%|██▌       | 57/221 [00:18<00:56,  2.88it/s][A
 26%|██▌       | 58/221 [00:19<00:55,  2.95it/s][A
 27%|██▋       | 59/221 [00:19<00:46,  3.46it/s][A
 27%|██▋       | 60/221 [00:19<00:50,  3.18it/s][A
 28%|██▊       | 61/221 [00:20<00:46,  3.47it/s][A
 28%|██▊       | 62/221 [00:20<00:38,  4.13it/s][A
 29%|██▊       | 63/221 [00:20<00:35,  4.40it/s][A
 29%|██▉       | 64/221 [00:20<00:33,  4.68it/s][A
 29%|██▉       | 65/221 [00:20<00:28,  5.41it/s][A
 30%|██▉       | 66/221 [00:20<00:33,  4.63it/s][A
 30%|███       | 67/221 [00:21<00:32,  4.75it/s][A
 31%|███       | 68/221 [00:21<00:28,  5.32it/s][A
 31%|███       | 69/221 [00:21<00:46,  3.28it/s][A
 32%|███▏      | 70/221 [00:22<00:38,  3.93it/s][A
 32%|███▏      | 71/221 [00:24<02:33,  1.02s/it][A
 33%|███▎      | 72/221 [00:24<01:51,  1.34it/s][A
 33%|███▎      | 73/221 [00:25<01:28,  1.67it/s][A
 33%|███▎      | 74/221 [00:25<01:09,  2.12it/s][A
 34%|███▍      | 75/221 [00:25<01:11,  2.05it/s][A
 34%|███▍      | 76/221 [00:26<00:55,  2.60it/s][A
 35%|███▍      | 77/221 [00:26<00:46,  3.12it/s][A
 35%|███▌      | 78/221 [00:26<00:44,  3.21it/s][A
 36%|███▌      | 79/221 [00:27<00:59,  2.37it/s][A
 37%|███▋      | 81/221 [00:27<00:40,  3.42it/s][A
 37%|███▋      | 82/221 [00:27<00:36,  3.76it/s][A
 38%|███▊      | 83/221 [00:27<00:32,  4.29it/s][A
 38%|███▊      | 84/221 [00:27<00:28,  4.87it/s][A
 39%|███▉      | 86/221 [00:28<00:21,  6.21it/s][A
 39%|███▉      | 87/221 [00:28<00:28,  4.63it/s][A
 40%|███▉      | 88/221 [00:28<00:31,  4.27it/s][A
 40%|████      | 89/221 [00:31<02:05,  1.05it/s][A
 41%|████      | 90/221 [00:31<01:38,  1.34it/s][A
 42%|████▏     | 92/221 [00:32<00:58,  2.21it/s][A
 42%|████▏     | 93/221 [00:32<01:01,  2.08it/s][A
 43%|████▎     | 94/221 [00:32<00:55,  2.30it/s][A
 43%|████▎     | 95/221 [00:33<00:43,  2.89it/s][A
 43%|████▎     | 96/221 [00:33<00:42,  2.96it/s][A
 44%|████▍     | 97/221 [00:33<00:33,  3.69it/s][A
 44%|████▍     | 98/221 [00:33<00:32,  3.80it/s][A
 45%|████▍     | 99/221 [00:33<00:27,  4.50it/s][A
 45%|████▌     | 100/221 [00:34<00:25,  4.73it/s][A
 46%|████▌     | 101/221 [00:34<00:25,  4.76it/s][A
 46%|████▌     | 102/221 [00:34<00:25,  4.63it/s][A
 47%|████▋     | 104/221 [00:34<00:17,  6.51it/s][A
 48%|████▊     | 105/221 [00:34<00:19,  6.04it/s][A
 48%|████▊     | 106/221 [00:35<00:41,  2.79it/s][A
 48%|████▊     | 107/221 [00:35<00:33,  3.41it/s][A
 49%|████▉     | 108/221 [00:36<00:30,  3.67it/s][A
 49%|████▉     | 109/221 [00:36<00:31,  3.55it/s][A
 50%|████▉     | 110/221 [00:36<00:25,  4.35it/s][A
 50%|█████     | 111/221 [00:36<00:33,  3.32it/s][A
 51%|█████     | 112/221 [00:37<00:29,  3.66it/s][A
 51%|█████     | 113/221 [00:37<00:31,  3.47it/s][A
 52%|█████▏    | 115/221 [00:37<00:19,  5.48it/s][A
 52%|█████▏    | 116/221 [00:42<02:21,  1.35s/it][A
 53%|█████▎    | 117/221 [00:42<01:50,  1.06s/it][A
 53%|█████▎    | 118/221 [00:43<01:32,  1.12it/s][A
 54%|█████▍    | 119/221 [00:43<01:10,  1.44it/s][A
 54%|█████▍    | 120/221 [00:43<00:56,  1.80it/s][A
 55%|█████▌    | 122/221 [00:43<00:36,  2.70it/s][A
 56%|█████▌    | 123/221 [00:44<00:30,  3.18it/s][A
 56%|█████▌    | 124/221 [00:44<00:27,  3.59it/s][A
 57%|█████▋    | 125/221 [00:44<00:27,  3.49it/s][A
 57%|█████▋    | 126/221 [00:44<00:32,  2.95it/s][A
 57%|█████▋    | 127/221 [00:45<00:34,  2.76it/s][A
 58%|█████▊    | 128/221 [00:45<00:35,  2.63it/s][A
 58%|█████▊    | 129/221 [00:46<00:31,  2.88it/s][A
 59%|█████▉    | 130/221 [00:46<00:28,  3.20it/s][A
 60%|█████▉    | 132/221 [00:46<00:21,  4.14it/s][A
 60%|██████    | 133/221 [00:47<00:24,  3.64it/s][A
 61%|██████    | 134/221 [00:47<00:23,  3.77it/s][A
 61%|██████    | 135/221 [00:47<00:27,  3.09it/s][A
 62%|██████▏   | 136/221 [00:48<00:30,  2.76it/s][A[h264 @ 0x55a318918a00] mmco: unref short failure
[h264 @ 0x55a318918a00] mmco: unref short failure

 62%|██████▏   | 137/221 [00:48<00:27,  3.08it/s][A
 62%|██████▏   | 138/221 [00:48<00:30,  2.70it/s][A
 63%|██████▎   | 139/221 [00:49<00:29,  2.78it/s][A
 63%|██████▎   | 140/221 [00:49<00:29,  2.75it/s][A
 64%|██████▍   | 141/221 [00:49<00:26,  3.02it/s][A
 64%|██████▍   | 142/221 [00:50<00:28,  2.79it/s][A
 65%|██████▍   | 143/221 [00:50<00:25,  3.03it/s][A
 65%|██████▌   | 144/221 [00:50<00:20,  3.71it/s][A
 66%|██████▌   | 146/221 [00:50<00:14,  5.22it/s][A
 67%|██████▋   | 147/221 [00:51<00:13,  5.68it/s][A
 67%|██████▋   | 148/221 [00:51<00:14,  5.07it/s][A
 68%|██████▊   | 150/221 [00:51<00:11,  6.39it/s][A
 68%|██████▊   | 151/221 [00:52<00:23,  2.95it/s][A
 69%|██████▉   | 152/221 [00:52<00:21,  3.16it/s][A
 69%|██████▉   | 153/221 [00:52<00:20,  3.29it/s][A
 70%|██████▉   | 154/221 [00:53<00:23,  2.83it/s][A
 70%|███████   | 155/221 [00:53<00:19,  3.37it/s][A
 71%|███████   | 156/221 [00:53<00:16,  3.96it/s][A[h264 @ 0x56074906abc0] mmco: unref short failure
[h264 @ 0x56074906abc0] mmco: unref short failure

 71%|███████   | 157/221 [00:56<01:08,  1.07s/it][A
 71%|███████▏  | 158/221 [00:56<00:51,  1.23it/s][A
 72%|███████▏  | 159/221 [00:57<00:39,  1.58it/s][A
 72%|███████▏  | 160/221 [00:57<00:30,  1.98it/s][A
 73%|███████▎  | 161/221 [00:57<00:23,  2.54it/s][A
 74%|███████▍  | 163/221 [00:57<00:15,  3.68it/s][A
 74%|███████▍  | 164/221 [00:58<00:15,  3.59it/s][A
 75%|███████▌  | 166/221 [00:58<00:14,  3.91it/s][A
 76%|███████▌  | 167/221 [00:58<00:12,  4.45it/s][A[h264 @ 0x55b5ac6ca740] mmco: unref short failure
[h264 @ 0x55b5ac6ca740] mmco: unref short failure

 76%|███████▌  | 168/221 [01:01<00:50,  1.06it/s][A
 76%|███████▋  | 169/221 [01:02<00:41,  1.26it/s][A
 77%|███████▋  | 170/221 [01:02<00:33,  1.50it/s][A
 77%|███████▋  | 171/221 [01:02<00:27,  1.84it/s][A
 78%|███████▊  | 172/221 [01:02<00:22,  2.22it/s][A
 79%|███████▊  | 174/221 [01:03<00:14,  3.31it/s][A
 79%|███████▉  | 175/221 [01:03<00:13,  3.49it/s][A
 80%|███████▉  | 176/221 [01:03<00:12,  3.67it/s][A
 80%|████████  | 177/221 [01:03<00:11,  3.99it/s][A
 81%|████████  | 178/221 [01:04<00:10,  4.02it/s][A
 81%|████████  | 179/221 [01:04<00:15,  2.72it/s][A
 82%|████████▏ | 181/221 [01:05<00:11,  3.45it/s][A
 82%|████████▏ | 182/221 [01:05<00:10,  3.75it/s][A
 83%|████████▎ | 183/221 [01:05<00:09,  4.20it/s][A
 83%|████████▎ | 184/221 [01:05<00:10,  3.57it/s][A
 84%|████████▎ | 185/221 [01:06<00:09,  3.89it/s][A
 84%|████████▍ | 186/221 [01:06<00:09,  3.50it/s][A
 85%|████████▍ | 187/221 [01:06<00:08,  4.01it/s][A
 85%|████████▌ | 188/221 [01:06<00:08,  3.98it/s][A
 86%|████████▌ | 189/221 [01:07<00:08,  3.57it/s][A
 86%|████████▌ | 190/221 [01:07<00:08,  3.77it/s][A
 87%|████████▋ | 192/221 [01:07<00:06,  4.52it/s][A
 87%|████████▋ | 193/221 [01:07<00:05,  5.07it/s][A
 88%|████████▊ | 194/221 [01:08<00:09,  2.93it/s][A
 88%|████████▊ | 195/221 [01:08<00:07,  3.54it/s][A
 89%|████████▉ | 197/221 [01:08<00:04,  4.99it/s][A
 90%|████████▉ | 198/221 [01:09<00:04,  5.16it/s][A
 90%|█████████ | 199/221 [01:09<00:04,  4.40it/s][A
 90%|█████████ | 200/221 [01:09<00:05,  3.94it/s][A
 91%|█████████ | 201/221 [01:09<00:04,  4.21it/s][A[h264 @ 0x55a327aaf600] mmco: unref short failure

 91%|█████████▏| 202/221 [01:10<00:04,  4.73it/s][A
 92%|█████████▏| 203/221 [01:10<00:03,  4.90it/s][A
 93%|█████████▎| 205/221 [01:10<00:02,  6.78it/s][A
 93%|█████████▎| 206/221 [01:10<00:03,  4.41it/s][A
 94%|█████████▍| 208/221 [01:11<00:02,  5.73it/s][A
 95%|█████████▌| 210/221 [01:11<00:01,  7.11it/s][A
 95%|█████████▌| 211/221 [01:11<00:02,  4.66it/s][A
 96%|█████████▌| 212/221 [01:11<00:01,  5.28it/s][A
 97%|█████████▋| 214/221 [01:12<00:01,  3.88it/s][A
 97%|█████████▋| 215/221 [01:12<00:01,  3.78it/s][A
 98%|█████████▊| 216/221 [01:13<00:01,  4.03it/s][A
 98%|█████████▊| 217/221 [01:13<00:01,  2.90it/s][A
 99%|█████████▊| 218/221 [01:14<00:01,  2.72it/s][A
 99%|█████████▉| 219/221 [01:14<00:00,  3.11it/s][A
100%|█████████▉| 220/221 [01:19<00:01,  1.58s/it][A
100%|██████████| 221/221 [01:19<00:00,  1.16s/it][A100%|██████████| 221/221 [01:19<00:00,  2.79it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:06,  3.32it/s][A
  1%|          | 2/221 [00:00<01:05,  3.37it/s][A
  1%|▏         | 3/221 [00:00<01:11,  3.04it/s][A
  2%|▏         | 4/221 [00:01<01:08,  3.17it/s][A
  2%|▏         | 5/221 [00:01<01:08,  3.16it/s][A
  3%|▎         | 6/221 [00:01<01:06,  3.24it/s][A
  3%|▎         | 7/221 [00:02<01:07,  3.19it/s][A
  4%|▎         | 8/221 [00:02<01:05,  3.26it/s][A
  4%|▍         | 9/221 [00:02<01:05,  3.25it/s][A
  5%|▍         | 10/221 [00:03<01:04,  3.26it/s][A
  5%|▍         | 11/221 [00:03<01:03,  3.28it/s][A
  5%|▌         | 12/221 [00:03<01:03,  3.27it/s][A
  6%|▌         | 13/221 [00:04<01:02,  3.31it/s][A
  6%|▋         | 14/221 [00:04<01:02,  3.34it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.36it/s][A
  7%|▋         | 16/221 [00:04<01:00,  3.37it/s][A
  8%|▊         | 17/221 [00:05<01:00,  3.38it/s][A
  8%|▊         | 18/221 [00:05<01:01,  3.33it/s][A
  9%|▊         | 19/221 [00:05<01:00,  3.35it/s][A
  9%|▉         | 20/221 [00:06<00:59,  3.36it/s][A
 10%|▉         | 21/221 [00:06<00:59,  3.37it/s][A
 10%|▉         | 22/221 [00:06<00:58,  3.38it/s][A
 10%|█         | 23/221 [00:06<00:58,  3.39it/s][A
 11%|█         | 24/221 [00:07<00:58,  3.39it/s][A
 11%|█▏        | 25/221 [00:07<00:57,  3.40it/s][A
 12%|█▏        | 26/221 [00:07<00:57,  3.40it/s][A
 12%|█▏        | 27/221 [00:08<00:57,  3.40it/s][A
 13%|█▎        | 28/221 [00:08<00:56,  3.40it/s][A
 13%|█▎        | 29/221 [00:08<00:56,  3.40it/s][A
 14%|█▎        | 30/221 [00:09<00:56,  3.40it/s][A
 14%|█▍        | 31/221 [00:09<00:55,  3.40it/s][A
 14%|█▍        | 32/221 [00:09<00:55,  3.40it/s][A
 15%|█▍        | 33/221 [00:09<00:55,  3.40it/s][A
 15%|█▌        | 34/221 [00:10<00:54,  3.41it/s][A
 16%|█▌        | 35/221 [00:10<00:54,  3.41it/s][A
 16%|█▋        | 36/221 [00:10<00:54,  3.41it/s][A
 17%|█▋        | 37/221 [00:11<00:53,  3.41it/s][A
 17%|█▋        | 38/221 [00:11<00:53,  3.41it/s][A
 18%|█▊        | 39/221 [00:11<00:53,  3.41it/s][A
 18%|█▊        | 40/221 [00:11<00:52,  3.42it/s][A
 19%|█▊        | 41/221 [00:12<00:52,  3.42it/s][A
 19%|█▉        | 42/221 [00:12<00:52,  3.42it/s][A
 19%|█▉        | 43/221 [00:12<00:52,  3.42it/s][A
 20%|█▉        | 44/221 [00:13<00:51,  3.42it/s][A
 20%|██        | 45/221 [00:13<00:51,  3.42it/s][A
 21%|██        | 46/221 [00:13<00:51,  3.42it/s][A
 21%|██▏       | 47/221 [00:13<00:50,  3.42it/s][A
 22%|██▏       | 48/221 [00:14<00:50,  3.42it/s][A
 22%|██▏       | 49/221 [00:14<00:50,  3.42it/s][A
 23%|██▎       | 50/221 [00:14<00:49,  3.42it/s][A
 23%|██▎       | 51/221 [00:15<00:49,  3.42it/s][A
 24%|██▎       | 52/221 [00:15<00:49,  3.42it/s][A
 24%|██▍       | 53/221 [00:15<00:49,  3.42it/s][A
 24%|██▍       | 54/221 [00:16<00:48,  3.42it/s][A
 25%|██▍       | 55/221 [00:16<00:48,  3.42it/s][A
 25%|██▌       | 56/221 [00:16<00:48,  3.42it/s][A
 26%|██▌       | 57/221 [00:16<00:47,  3.42it/s][A
 26%|██▌       | 58/221 [00:17<00:47,  3.42it/s][A
 27%|██▋       | 59/221 [00:17<00:47,  3.42it/s][A
 27%|██▋       | 60/221 [00:17<00:47,  3.42it/s][A
 28%|██▊       | 61/221 [00:18<00:46,  3.42it/s][A
 28%|██▊       | 62/221 [00:18<00:46,  3.42it/s][A
 29%|██▊       | 63/221 [00:18<00:46,  3.42it/s][A
 29%|██▉       | 64/221 [00:18<00:45,  3.42it/s][A
 29%|██▉       | 65/221 [00:19<00:45,  3.42it/s][A
 30%|██▉       | 66/221 [00:19<00:45,  3.42it/s][A
 30%|███       | 67/221 [00:19<00:45,  3.42it/s][A
 31%|███       | 68/221 [00:20<00:44,  3.42it/s][A
 31%|███       | 69/221 [00:20<00:44,  3.42it/s][A
 32%|███▏      | 70/221 [00:20<00:44,  3.42it/s][A
 32%|███▏      | 71/221 [00:21<00:43,  3.42it/s][A
 33%|███▎      | 72/221 [00:21<00:43,  3.42it/s][A
 33%|███▎      | 73/221 [00:21<00:43,  3.42it/s][A
 33%|███▎      | 74/221 [00:21<00:42,  3.42it/s][A
 34%|███▍      | 75/221 [00:22<00:42,  3.42it/s][A
 34%|███▍      | 76/221 [00:22<00:42,  3.42it/s][A
 35%|███▍      | 77/221 [00:22<00:42,  3.42it/s][A
 35%|███▌      | 78/221 [00:23<00:41,  3.42it/s][A
 36%|███▌      | 79/221 [00:23<00:41,  3.42it/s][A
 36%|███▌      | 80/221 [00:23<00:41,  3.42it/s][A
 37%|███▋      | 81/221 [00:23<00:40,  3.42it/s][A
 37%|███▋      | 82/221 [00:24<00:40,  3.42it/s][A
 38%|███▊      | 83/221 [00:24<00:40,  3.42it/s][A
 38%|███▊      | 84/221 [00:24<00:40,  3.42it/s][A
 38%|███▊      | 85/221 [00:25<00:39,  3.42it/s][A
 39%|███▉      | 86/221 [00:25<00:39,  3.42it/s][A
 39%|███▉      | 87/221 [00:25<00:39,  3.42it/s][A
 40%|███▉      | 88/221 [00:25<00:38,  3.42it/s][A
 40%|████      | 89/221 [00:26<00:38,  3.42it/s][A
 41%|████      | 90/221 [00:26<00:38,  3.41it/s][A
 41%|████      | 91/221 [00:26<00:38,  3.41it/s][A
 42%|████▏     | 92/221 [00:27<00:37,  3.42it/s][A
 42%|████▏     | 93/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 94/221 [00:27<00:37,  3.42it/s][A
 43%|████▎     | 95/221 [00:28<00:36,  3.42it/s][A
 43%|████▎     | 96/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 97/221 [00:28<00:36,  3.42it/s][A
 44%|████▍     | 98/221 [00:28<00:35,  3.42it/s][A
 45%|████▍     | 99/221 [00:29<00:35,  3.42it/s][A
 45%|████▌     | 100/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 101/221 [00:29<00:35,  3.42it/s][A
 46%|████▌     | 102/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.42it/s][A
 47%|████▋     | 104/221 [00:30<00:34,  3.42it/s][A
 48%|████▊     | 105/221 [00:30<00:33,  3.42it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 107/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 108/221 [00:31<00:33,  3.42it/s][A
 49%|████▉     | 109/221 [00:32<00:32,  3.42it/s][A
 50%|████▉     | 110/221 [00:32<00:32,  3.42it/s][A
 50%|█████     | 111/221 [00:32<00:32,  3.42it/s][A
 51%|█████     | 112/221 [00:32<00:31,  3.42it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 114/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:33<00:30,  3.42it/s][A
 52%|█████▏    | 116/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:34<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:35<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:35<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:35<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:36<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:37<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:38<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:38<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:39<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:40<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:40<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:41<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:42<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:43<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:44<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:45<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:45<00:19,  3.42it/s][A
 71%|███████   | 157/221 [00:46<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:47<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:47<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:48<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:48<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:49<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:49<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:49<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:50<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:51<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:52<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:52<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:54<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:54<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:55<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:56<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:56<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:57<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:57<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:58<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [00:59<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:01<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:02<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:03<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:03<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:04<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:04<00:00,  3.42it/s][A100%|██████████| 221/221 [01:04<00:00,  3.41it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:30,  7.16it/s][A
  1%|          | 2/221 [00:00<00:41,  5.28it/s][A
  1%|▏         | 3/221 [00:00<00:56,  3.86it/s][A
  2%|▏         | 4/221 [00:00<00:50,  4.28it/s][A
  2%|▏         | 5/221 [00:01<00:50,  4.25it/s][A
  3%|▎         | 7/221 [00:01<00:48,  4.45it/s][A
  4%|▎         | 8/221 [00:01<00:56,  3.77it/s][A
  4%|▍         | 9/221 [00:02<00:55,  3.82it/s][A
  5%|▍         | 10/221 [00:02<00:47,  4.45it/s][A
  5%|▍         | 11/221 [00:02<00:46,  4.48it/s][A
  5%|▌         | 12/221 [00:02<00:43,  4.76it/s][A
  6%|▌         | 13/221 [00:03<01:20,  2.59it/s][A
  6%|▋         | 14/221 [00:03<01:10,  2.95it/s][A
  7%|▋         | 15/221 [00:04<01:13,  2.80it/s][A
  7%|▋         | 16/221 [00:04<01:20,  2.55it/s][A
  8%|▊         | 17/221 [00:04<01:17,  2.64it/s][A
  8%|▊         | 18/221 [00:05<01:08,  2.96it/s][A
  9%|▉         | 20/221 [00:05<00:53,  3.73it/s][A
 10%|▉         | 21/221 [00:05<00:50,  3.98it/s][A
 10%|▉         | 22/221 [00:05<00:45,  4.38it/s][A
 10%|█         | 23/221 [00:06<00:43,  4.60it/s][A
 11%|█         | 24/221 [00:06<00:39,  5.04it/s][A
 11%|█▏        | 25/221 [00:06<00:49,  3.99it/s][A
 12%|█▏        | 26/221 [00:06<00:47,  4.14it/s][A
 12%|█▏        | 27/221 [00:07<00:44,  4.34it/s][A
 13%|█▎        | 28/221 [00:07<00:42,  4.52it/s][A
 13%|█▎        | 29/221 [00:07<00:46,  4.16it/s][A
 14%|█▎        | 30/221 [00:08<01:05,  2.90it/s][A
 14%|█▍        | 31/221 [00:08<01:05,  2.88it/s][A
 14%|█▍        | 32/221 [00:08<01:01,  3.05it/s][A
 15%|█▍        | 33/221 [00:09<01:03,  2.96it/s][A
 15%|█▌        | 34/221 [00:09<01:17,  2.40it/s][A
 16%|█▌        | 35/221 [00:09<01:03,  2.94it/s][A
 16%|█▋        | 36/221 [00:10<00:59,  3.09it/s][A
 17%|█▋        | 37/221 [00:10<00:51,  3.57it/s][A
 17%|█▋        | 38/221 [00:10<00:54,  3.37it/s][A
 18%|█▊        | 39/221 [00:10<00:47,  3.86it/s][A
 18%|█▊        | 40/221 [00:11<00:46,  3.88it/s][A
 19%|█▊        | 41/221 [00:11<00:50,  3.59it/s][A
 19%|█▉        | 42/221 [00:11<00:42,  4.21it/s][A
 19%|█▉        | 43/221 [00:11<00:39,  4.48it/s][A
 20%|█▉        | 44/221 [00:12<00:41,  4.26it/s][A
 20%|██        | 45/221 [00:12<00:50,  3.51it/s][A
 21%|██        | 46/221 [00:12<00:52,  3.34it/s][A
 21%|██▏       | 47/221 [00:13<00:47,  3.63it/s][A
 22%|██▏       | 48/221 [00:13<00:40,  4.29it/s][A
 23%|██▎       | 50/221 [00:13<00:38,  4.44it/s][A
 23%|██▎       | 51/221 [00:13<00:40,  4.16it/s][A
 24%|██▎       | 52/221 [00:14<00:42,  3.97it/s][A
 24%|██▍       | 53/221 [00:14<00:54,  3.07it/s][A
 24%|██▍       | 54/221 [00:14<00:46,  3.61it/s][A
 25%|██▍       | 55/221 [00:15<00:57,  2.89it/s][A
 25%|██▌       | 56/221 [00:15<00:54,  3.05it/s][A
 26%|██▌       | 57/221 [00:15<00:53,  3.09it/s][A
 26%|██▌       | 58/221 [00:16<00:50,  3.20it/s][A
 27%|██▋       | 59/221 [00:16<00:48,  3.33it/s][A
 27%|██▋       | 60/221 [00:16<00:43,  3.70it/s][A
 28%|██▊       | 61/221 [00:16<00:39,  4.01it/s][A
 28%|██▊       | 62/221 [00:17<00:40,  3.95it/s][A
 29%|██▉       | 64/221 [00:17<00:37,  4.17it/s][A
 29%|██▉       | 65/221 [00:17<00:36,  4.26it/s][A
 30%|██▉       | 66/221 [00:18<00:38,  4.07it/s][A
 30%|███       | 67/221 [00:18<00:39,  3.93it/s][A
 31%|███       | 68/221 [00:18<00:37,  4.04it/s][A
 31%|███       | 69/221 [00:19<00:53,  2.85it/s][A
 32%|███▏      | 70/221 [00:19<00:51,  2.93it/s][A
 32%|███▏      | 71/221 [00:19<00:50,  3.00it/s][A
 33%|███▎      | 72/221 [00:20<00:52,  2.84it/s][A
 33%|███▎      | 73/221 [00:20<00:51,  2.86it/s][A
 33%|███▎      | 74/221 [00:20<00:47,  3.10it/s][A
 34%|███▍      | 75/221 [00:21<00:43,  3.33it/s][A
 34%|███▍      | 76/221 [00:21<00:38,  3.81it/s][A
 35%|███▍      | 77/221 [00:21<00:38,  3.71it/s][A
 35%|███▌      | 78/221 [00:21<00:41,  3.42it/s][A
 36%|███▌      | 79/221 [00:22<00:38,  3.65it/s][A
 36%|███▌      | 80/221 [00:22<00:35,  3.95it/s][A
 37%|███▋      | 81/221 [00:22<00:34,  4.05it/s][A
 37%|███▋      | 82/221 [00:22<00:34,  4.04it/s][A
 38%|███▊      | 83/221 [00:23<00:31,  4.43it/s][A
 38%|███▊      | 84/221 [00:23<00:49,  2.75it/s][A
 38%|███▊      | 85/221 [00:23<00:45,  2.97it/s][A
 39%|███▉      | 86/221 [00:24<00:56,  2.41it/s][A
 39%|███▉      | 87/221 [00:24<00:52,  2.56it/s][A
 40%|███▉      | 88/221 [00:25<00:50,  2.65it/s][A
 40%|████      | 89/221 [00:25<00:48,  2.74it/s][A
 41%|████      | 90/221 [00:25<00:44,  2.95it/s][A
 41%|████      | 91/221 [00:26<00:47,  2.76it/s][A
 42%|████▏     | 92/221 [00:26<00:46,  2.75it/s][A
 42%|████▏     | 93/221 [00:27<00:58,  2.20it/s][A
 43%|████▎     | 94/221 [00:27<00:50,  2.50it/s][A
 43%|████▎     | 95/221 [00:28<00:56,  2.25it/s][A
 43%|████▎     | 96/221 [00:28<00:56,  2.20it/s][A
 44%|████▍     | 97/221 [00:28<00:49,  2.52it/s][A
 44%|████▍     | 98/221 [00:29<00:46,  2.64it/s][A
 45%|████▍     | 99/221 [00:29<00:42,  2.87it/s][A
 45%|████▌     | 100/221 [00:29<00:36,  3.34it/s][A
 46%|████▌     | 101/221 [00:29<00:31,  3.82it/s][A
 46%|████▌     | 102/221 [00:30<00:32,  3.61it/s][A
 47%|████▋     | 103/221 [00:30<00:31,  3.80it/s][A
 47%|████▋     | 104/221 [00:30<00:26,  4.48it/s][A
 48%|████▊     | 105/221 [00:31<00:34,  3.36it/s][A
 48%|████▊     | 106/221 [00:31<00:37,  3.09it/s][A
 48%|████▊     | 107/221 [00:31<00:39,  2.90it/s][A
 49%|████▉     | 108/221 [00:32<00:35,  3.19it/s][A
 49%|████▉     | 109/221 [00:32<00:30,  3.64it/s][A
 50%|████▉     | 110/221 [00:32<00:28,  3.85it/s][A
 50%|█████     | 111/221 [00:32<00:30,  3.66it/s][A
 51%|█████     | 112/221 [00:33<00:31,  3.45it/s][A
 51%|█████     | 113/221 [00:33<00:34,  3.09it/s][A
 52%|█████▏    | 114/221 [00:33<00:29,  3.60it/s][A
 52%|█████▏    | 115/221 [00:33<00:26,  3.96it/s][A
 52%|█████▏    | 116/221 [00:34<00:24,  4.23it/s][A
 53%|█████▎    | 117/221 [00:34<00:24,  4.26it/s][A
 53%|█████▎    | 118/221 [00:34<00:29,  3.44it/s][A
 54%|█████▍    | 119/221 [00:35<00:36,  2.81it/s][A
 54%|█████▍    | 120/221 [00:35<00:36,  2.74it/s][A
 55%|█████▍    | 121/221 [00:35<00:35,  2.83it/s][A
 55%|█████▌    | 122/221 [00:36<00:32,  3.04it/s][A
 56%|█████▌    | 123/221 [00:36<00:35,  2.78it/s][A
 56%|█████▌    | 124/221 [00:36<00:30,  3.14it/s][A
 57%|█████▋    | 125/221 [00:37<00:31,  3.07it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.47it/s][A
 57%|█████▋    | 127/221 [00:37<00:33,  2.83it/s][A
 58%|█████▊    | 128/221 [00:38<00:30,  3.04it/s][A
 58%|█████▊    | 129/221 [00:38<00:25,  3.54it/s][A
 59%|█████▉    | 130/221 [00:38<00:27,  3.30it/s][A
 59%|█████▉    | 131/221 [00:38<00:26,  3.44it/s][A
 60%|█████▉    | 132/221 [00:39<00:24,  3.62it/s][A
 60%|██████    | 133/221 [00:39<00:30,  2.90it/s][A
 61%|██████    | 134/221 [00:40<00:31,  2.72it/s][A
 61%|██████    | 135/221 [00:40<00:28,  3.01it/s][A
 62%|██████▏   | 136/221 [00:40<00:27,  3.05it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.39it/s][A
 62%|██████▏   | 138/221 [00:41<00:22,  3.65it/s][A
 63%|██████▎   | 139/221 [00:41<00:26,  3.12it/s][A
 63%|██████▎   | 140/221 [00:41<00:24,  3.37it/s][A
 64%|██████▍   | 141/221 [00:42<00:27,  2.90it/s][A
 64%|██████▍   | 142/221 [00:42<00:24,  3.19it/s][A
 65%|██████▍   | 143/221 [00:42<00:21,  3.58it/s][A
 65%|██████▌   | 144/221 [00:42<00:20,  3.68it/s][A
 66%|██████▌   | 145/221 [00:43<00:25,  2.95it/s][A
 66%|██████▌   | 146/221 [00:43<00:23,  3.17it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.36it/s][A
 67%|██████▋   | 148/221 [00:44<00:24,  2.97it/s][A
 67%|██████▋   | 149/221 [00:44<00:21,  3.35it/s][A
 68%|██████▊   | 150/221 [00:44<00:19,  3.56it/s][A
 68%|██████▊   | 151/221 [00:45<00:22,  3.07it/s][A
 69%|██████▉   | 152/221 [00:45<00:30,  2.27it/s][A
 69%|██████▉   | 153/221 [00:46<00:27,  2.46it/s][A
 70%|██████▉   | 154/221 [00:46<00:27,  2.43it/s][A
 70%|███████   | 155/221 [00:47<00:25,  2.56it/s][A
 71%|███████   | 156/221 [00:47<00:21,  3.06it/s][A
 71%|███████   | 157/221 [00:47<00:20,  3.16it/s][A
 71%|███████▏  | 158/221 [00:47<00:21,  2.89it/s][A
 72%|███████▏  | 159/221 [00:48<00:20,  2.97it/s][A
 72%|███████▏  | 160/221 [00:48<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:48<00:15,  3.87it/s][A
 74%|███████▍  | 163/221 [00:48<00:12,  4.51it/s][A
 74%|███████▍  | 164/221 [00:49<00:12,  4.58it/s][A
 75%|███████▍  | 165/221 [00:49<00:14,  3.97it/s][A
 75%|███████▌  | 166/221 [00:49<00:15,  3.62it/s][A
 76%|███████▌  | 167/221 [00:49<00:12,  4.37it/s][A
 76%|███████▌  | 168/221 [00:50<00:14,  3.73it/s][A
 77%|███████▋  | 170/221 [00:50<00:14,  3.43it/s][A
 77%|███████▋  | 171/221 [00:51<00:15,  3.30it/s][A
 78%|███████▊  | 172/221 [00:51<00:15,  3.25it/s][A
 78%|███████▊  | 173/221 [00:51<00:13,  3.45it/s][A
 79%|███████▊  | 174/221 [00:52<00:13,  3.57it/s][A
 79%|███████▉  | 175/221 [00:52<00:12,  3.55it/s][A
 80%|███████▉  | 176/221 [00:52<00:11,  3.90it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.65it/s][A
 81%|████████  | 178/221 [00:53<00:17,  2.53it/s][A
 81%|████████  | 179/221 [00:53<00:14,  2.81it/s][A
 81%|████████▏ | 180/221 [00:54<00:13,  3.02it/s][A
 82%|████████▏ | 181/221 [00:54<00:16,  2.40it/s][A
 82%|████████▏ | 182/221 [00:55<00:15,  2.59it/s][A
 83%|████████▎ | 183/221 [00:55<00:14,  2.68it/s][A
 83%|████████▎ | 184/221 [00:55<00:13,  2.80it/s][A
 84%|████████▎ | 185/221 [00:55<00:10,  3.51it/s][A
 84%|████████▍ | 186/221 [00:56<00:11,  3.03it/s][A
 85%|████████▍ | 187/221 [00:56<00:10,  3.30it/s][A
 85%|████████▌ | 188/221 [00:56<00:09,  3.44it/s][A
 86%|████████▌ | 189/221 [00:57<00:08,  3.62it/s][A
 86%|████████▌ | 190/221 [00:57<00:08,  3.51it/s][A
 86%|████████▋ | 191/221 [00:57<00:08,  3.63it/s][A
 87%|████████▋ | 192/221 [00:57<00:08,  3.60it/s][A
 87%|████████▋ | 193/221 [00:58<00:08,  3.49it/s][A
 88%|████████▊ | 194/221 [00:58<00:07,  3.49it/s][A
 88%|████████▊ | 195/221 [00:58<00:06,  4.26it/s][A
 89%|████████▊ | 196/221 [00:58<00:06,  3.58it/s][A
 89%|████████▉ | 197/221 [00:59<00:07,  3.18it/s][A
 90%|████████▉ | 198/221 [00:59<00:07,  3.16it/s][A
 90%|█████████ | 199/221 [00:59<00:05,  3.69it/s][A
 90%|█████████ | 200/221 [01:00<00:05,  3.74it/s][A
 91%|█████████ | 201/221 [01:00<00:04,  4.08it/s][A
 91%|█████████▏| 202/221 [01:00<00:05,  3.55it/s][A
 92%|█████████▏| 203/221 [01:00<00:04,  3.64it/s][A
 92%|█████████▏| 204/221 [01:01<00:05,  3.25it/s][A
 93%|█████████▎| 205/221 [01:01<00:04,  3.30it/s][A
 93%|█████████▎| 206/221 [01:02<00:05,  2.94it/s][A
 94%|█████████▎| 207/221 [01:02<00:05,  2.63it/s][A
 94%|█████████▍| 208/221 [01:02<00:04,  2.98it/s][A
 95%|█████████▍| 209/221 [01:02<00:03,  3.47it/s][A
 95%|█████████▌| 210/221 [01:03<00:04,  2.57it/s][A
 95%|█████████▌| 211/221 [01:03<00:03,  2.80it/s][A
 96%|█████████▌| 212/221 [01:04<00:03,  2.98it/s][A
 96%|█████████▋| 213/221 [01:04<00:02,  3.28it/s][A
 97%|█████████▋| 214/221 [01:04<00:02,  3.32it/s][A
 97%|█████████▋| 215/221 [01:05<00:02,  2.97it/s][A
 98%|█████████▊| 216/221 [01:05<00:01,  2.94it/s][A
 98%|█████████▊| 217/221 [01:05<00:01,  3.16it/s][A
 99%|█████████▊| 218/221 [01:05<00:00,  3.41it/s][A
 99%|█████████▉| 219/221 [01:06<00:00,  3.06it/s][A
100%|█████████▉| 220/221 [01:06<00:00,  3.47it/s][A
100%|██████████| 221/221 [01:06<00:00,  3.84it/s][A100%|██████████| 221/221 [01:06<00:00,  3.31it/s]
09/17/2024 06:58:31 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 1199--===========

09/17/2024 06:58:31 - INFO - __main__ -   {'area_r1': 36.9, 'area_recall': '36.9/61.8/71.6', 'area_ravg': 56.7}
09/17/2024 06:58:31 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 1199--===========

09/17/2024 06:58:31 - INFO - __main__ -   {'forward_r1': 37.3, 'forward_recall': '37.3/65.8/76.9', 'forward_ravg': 60.0}
09/17/2024 06:58:31 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 1199--===========

09/17/2024 06:58:31 - INFO - __main__ -   {'area_video_r1': 38.7, 'area_video_recall': '38.7/66.1/77.3', 'area_video_ravg': 60.7}
09/17/2024 06:58:31 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 299=======

09/17/2024 06:58:31 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 06:58:31 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 1199--===========

09/17/2024 06:58:31 - INFO - __main__ -   {'area_video_r1': 52.1, 'area_video_recall': '52.1/74.7/81.3', 'area_video_ravg': 69.4, 'area_video_back_r1': 47.2, 'area_video_back_recall': '47.2/74.1/82.5', 'area_video_back_ravg': 67.9}
09/17/2024 06:58:31 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 549=======

09/17/2024 06:58:31 - INFO - __main__ -   {'area_video_r1': 54.1, 'area_video_recall': '54.1/75.5/82.4', 'area_video_ravg': 70.6, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.5/82.1', 'area_video_back_ravg': 68.7}
09/17/2024 06:58:31 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 1199--===========

09/17/2024 06:58:31 - INFO - __main__ -   {'video_r1': 36.4, 'video_recall': '36.4/64.6/73.2', 'video_ravg': 58.1}
09/17/2024 06:58:31 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 949=======

09/17/2024 06:58:31 - INFO - __main__ -   {'video_r1': 38.7, 'video_recall': '38.7/64.3/74.1', 'video_ravg': 59.0}
09/17/2024 06:58:31 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 1199--===========

09/17/2024 06:58:31 - INFO - __main__ -   {'video_r1': 52.3, 'video_recall': '52.3/74.0/81.8', 'video_ravg': 69.3}
09/17/2024 06:58:31 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 549=======

09/17/2024 06:58:31 - INFO - __main__ -   {'video_r1': 54.5, 'video_recall': '54.5/76.1/83.4', 'video_ravg': 71.3}
09/17/2024 06:58:56 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.007318439893424511, 'loss_ret%tv%ta--finetune_area/loss_area': 1.0605955123901367, 'loss_ret%tv%ta--finetune_area/total_loss': 1.0679140090942383}
 41%|████      | 1200/2910 [7:37:12<61:26:14, 129.34s/it] 41%|████▏     | 1201/2910 [7:37:16<43:29:01, 91.60s/it]  41%|████▏     | 1202/2910 [7:37:20<30:58:00, 65.27s/it][h264 @ 0x55e243d24340] mmco: unref short failure
[h264 @ 0x55b5b3170380] mmco: unref short failure
 41%|████▏     | 1203/2910 [7:37:24<22:16:50, 46.99s/it] 41%|████▏     | 1204/2910 [7:37:28<16:12:01, 34.19s/it][h264 @ 0x55b5be765c80] mmco: unref short failure
[h264 @ 0x55b5be765c80] mmco: unref short failure
[h264 @ 0x55e247c1a000] mmco: unref short failure
[h264 @ 0x55e247c1a000] mmco: unref short failure
 41%|████▏     | 1205/2910 [7:37:34<12:03:13, 25.45s/it][h264 @ 0x55b5b066b940] mmco: unref short failure
[h264 @ 0x55b5afcf1fc0] mmco: unref short failure
 41%|████▏     | 1206/2910 [7:37:39<9:11:22, 19.41s/it] [h264 @ 0x55a31a1d6f40] mmco: unref short failure
[h264 @ 0x55a31a1d6f40] mmco: unref short failure
[h264 @ 0x55e2457a0800] mmco: unref short failure
 41%|████▏     | 1207/2910 [7:37:44<7:09:56, 15.15s/it] 42%|████▏     | 1208/2910 [7:37:50<5:51:37, 12.40s/it] 42%|████▏     | 1209/2910 [7:37:56<4:59:44, 10.57s/it] 42%|████▏     | 1210/2910 [7:38:02<4:15:05,  9.00s/it][h264 @ 0x55a323979440] mmco: unref short failure
 42%|████▏     | 1211/2910 [7:38:07<3:47:46,  8.04s/it] 42%|████▏     | 1212/2910 [7:38:13<3:26:55,  7.31s/it][h264 @ 0x55b5ac5daa80] mmco: unref short failure
[h264 @ 0x55b5ac5daa80] mmco: unref short failure
[h264 @ 0x55e238952040] mmco: unref short failure
[h264 @ 0x55e238952040] mmco: unref short failure
 42%|████▏     | 1213/2910 [7:38:18<3:08:51,  6.68s/it][h264 @ 0x55b5bbdf4e40] mmco: unref short failure
[h264 @ 0x55b5bbdf4e40] mmco: unref short failure
 42%|████▏     | 1214/2910 [7:38:24<3:00:44,  6.39s/it] 42%|████▏     | 1215/2910 [7:38:29<2:52:06,  6.09s/it][h264 @ 0x55e242528580] mmco: unref short failure
[h264 @ 0x55e242528580] mmco: unref short failure
[h264 @ 0x55b5bee87940] mmco: unref short failure
[h264 @ 0x55b5b1004340] mmco: unref short failure
09/17/2024 07:00:27 - INFO - __main__ -   current idx Q6X76LfJ4-U.35 from finetune_area returns wrong image/video, use 66870 instead.
[h264 @ 0x55e23e25bd80] mmco: unref short failure
[h264 @ 0x55e23bdb31c0] mmco: unref short failure
[h264 @ 0x55e23bdb31c0] mmco: unref short failure
[h264 @ 0x55e240ed3fc0] mmco: unref short failure
[h264 @ 0x55a31eb1eb00] mmco: unref short failure
[h264 @ 0x55a321c14c00] mmco: unref short failure
[h264 @ 0x55a321c14c00] mmco: unref short failure
 42%|████▏     | 1216/2910 [7:39:26<10:00:03, 21.25s/it][h264 @ 0x55a31aca5480] mmco: unref short failure
[h264 @ 0x55a31aca5480] mmco: unref short failure
[h264 @ 0x55e2425e7280] mmco: unref short failure
[h264 @ 0x55e2425e7280] mmco: unref short failure
 42%|████▏     | 1217/2910 [7:39:34<8:10:12, 17.37s/it] 09/17/2024 07:01:22 - INFO - __main__ -   current idx KQezF6-NY_o.24 from finetune_area returns wrong image/video, use 97316 instead.
[h264 @ 0x55b5b7ac3dc0] mmco: unref short failure
[h264 @ 0x55b5b7ac3dc0] mmco: unref short failure
[h264 @ 0x55b5b7ac3dc0] mmco: unref short failure
[h264 @ 0x55b5b7ac3dc0] mmco: unref short failure
[h264 @ 0x55b5af8f8640] mmco: unref short failure
 42%|████▏     | 1218/2910 [7:39:46<7:18:49, 15.56s/it][h264 @ 0x55e23ed88bc0] mmco: unref short failure
 42%|████▏     | 1219/2910 [7:39:50<5:47:22, 12.33s/it][h264 @ 0x55b5b277aa40] mmco: unref short failure
[h264 @ 0x55b5b277aa40] mmco: unref short failure
[h264 @ 0x55a31655aac0] mmco: unref short failure
 42%|████▏     | 1220/2910 [7:39:59<5:13:54, 11.14s/it] 42%|████▏     | 1221/2910 [7:40:06<4:35:56,  9.80s/it] 42%|████▏     | 1222/2910 [7:40:11<3:56:10,  8.39s/it] 42%|████▏     | 1223/2910 [7:40:25<4:45:19, 10.15s/it][h264 @ 0x55b5b4ef4e40] mmco: unref short failure
[h264 @ 0x55b5b4ef4e40] mmco: unref short failure
[h264 @ 0x55b5bebb5b40] mmco: unref short failure
[h264 @ 0x55b5bebb5b40] mmco: unref short failure
[h264 @ 0x55b5bebb5b40] mmco: unref short failure
[h264 @ 0x55b5bebb5b40] mmco: unref short failure
[h264 @ 0x55e23b86aa00] mmco: unref short failure
[h264 @ 0x55e23b86aa00] mmco: unref short failure
[h264 @ 0x55a311193580] mmco: unref short failure
[h264 @ 0x55b5be09ed40] mmco: unref short failure
[h264 @ 0x55b5aa8d4680] mmco: unref short failure
[h264 @ 0x55e24f368140] mmco: unref short failure
[h264 @ 0x55e24f368140] mmco: unref short failure
[h264 @ 0x5607593df480] mmco: unref short failure
[h264 @ 0x5607593df480] mmco: unref short failure
[h264 @ 0x56075472a0c0] mmco: unref short failure
[h264 @ 0x55b5b4ef3600] mmco: unref short failure
[h264 @ 0x55b5b4ef3600] mmco: unref short failure
[h264 @ 0x55e24452d180] mmco: unref short failure
[h264 @ 0x55e24452d180] mmco: unref short failure
[h264 @ 0x5607593ded40] mmco: unref short failure
[h264 @ 0x5607593ded40] mmco: unref short failure
 42%|████▏     | 1224/2910 [7:41:47<14:48:56, 31.63s/it][h264 @ 0x55a31f9af180] mmco: unref short failure
 42%|████▏     | 1225/2910 [7:42:04<12:46:19, 27.29s/it][h264 @ 0x560741f60380] mmco: unref short failure
[h264 @ 0x56074e9b5cc0] mmco: unref short failure
[h264 @ 0x55b5b5d1a540] mmco: unref short failure
[h264 @ 0x55b5b5d1a540] mmco: unref short failure
[h264 @ 0x55a31ec11f80] mmco: unref short failure
[h264 @ 0x55a31ec11f80] mmco: unref short failure
[h264 @ 0x55a31ec11f80] mmco: unref short failure
[h264 @ 0x55a31ec11f80] mmco: unref short failure
[h264 @ 0x55a32314b880] mmco: unref short failure
[h264 @ 0x55a32314b880] mmco: unref short failure
[h264 @ 0x55e23a183e00] mmco: unref short failure
not have audios 7wavFXW3AFw.7
 42%|████▏     | 1226/2910 [7:42:24<11:42:08, 25.02s/it] 42%|████▏     | 1227/2910 [7:42:29<8:58:53, 19.21s/it]  42%|████▏     | 1228/2910 [7:42:35<7:03:40, 15.11s/it] 42%|████▏     | 1229/2910 [7:42:40<5:41:58, 12.21s/it] 42%|████▏     | 1230/2910 [7:42:45<4:42:34, 10.09s/it][h264 @ 0x560747d73300] mmco: unref short failure
[h264 @ 0x55e243d02300] mmco: unref short failure
[h264 @ 0x55e243d02300] mmco: unref short failure
[h264 @ 0x55b5b79f8f00] mmco: unref short failure
[h264 @ 0x55b5b79f8f00] mmco: unref short failure
09/17/2024 07:04:37 - INFO - __main__ -   current idx eIBeK5EEG4o.35 from finetune_area returns wrong image/video, use 50092 instead.
 42%|████▏     | 1231/2910 [7:42:51<4:06:49,  8.82s/it][h264 @ 0x55e240e44ac0] mmco: unref short failure
[h264 @ 0x55e239431740] mmco: unref short failure
[h264 @ 0x55e24d2b2d40] mmco: unref short failure
[h264 @ 0x55e24d2b2d40] mmco: unref short failure
[h264 @ 0x56075fba7e00] mmco: unref short failure
[h264 @ 0x56075fba7e00] mmco: unref short failure
[h264 @ 0x55e24cbd7180] mmco: unref short failure
[h264 @ 0x55e24cbd7180] mmco: unref short failure
[h264 @ 0x55a316bf0640] mmco: unref short failure
[h264 @ 0x55b5bb9e75c0] mmco: unref short failure
[h264 @ 0x55b5bb9e75c0] mmco: unref short failure
[h264 @ 0x55a320846a80] mmco: unref short failure
[h264 @ 0x55a320846a80] mmco: unref short failure
[h264 @ 0x55e24ce9dac0] mmco: unref short failure
[h264 @ 0x55e24ce9dac0] mmco: unref short failure
[h264 @ 0x55a3203b3280] mmco: unref short failure
[h264 @ 0x55b5bb9e7140] mmco: unref short failure
 42%|████▏     | 1232/2910 [7:44:14<14:26:08, 30.97s/it][h264 @ 0x55a3238c91c0] mmco: unref short failure
[h264 @ 0x55a3238c91c0] mmco: unref short failure
 42%|████▏     | 1233/2910 [7:44:25<11:43:30, 25.17s/it][h264 @ 0x55b5af15e140] mmco: unref short failure
[h264 @ 0x55b5af15e140] mmco: unref short failure
[h264 @ 0x560743161900] mmco: unref short failure
[h264 @ 0x55e2381ee700] mmco: unref short failure
[h264 @ 0x55e2381ee700] mmco: unref short failure
[h264 @ 0x55a31b94a980] mmco: unref short failure
 42%|████▏     | 1234/2910 [7:44:51<11:43:52, 25.20s/it] 42%|████▏     | 1235/2910 [7:44:56<9:00:00, 19.34s/it]  42%|████▏     | 1236/2910 [7:45:02<7:06:35, 15.29s/it] 43%|████▎     | 1237/2910 [7:45:08<5:43:28, 12.32s/it][h264 @ 0x560749ebb240] mmco: unref short failure
[h264 @ 0x560749ebb240] mmco: unref short failure
[h264 @ 0x55b5b872b5c0] mmco: unref short failure
[h264 @ 0x55b5b872b5c0] mmco: unref short failure
[h264 @ 0x55b5bc968f00] mmco: unref short failure
 43%|████▎     | 1238/2910 [7:45:13<4:47:54, 10.33s/it]09/17/2024 07:06:59 - INFO - __main__ -   current idx AP5rCSSlwrk.27 from finetune_area returns wrong image/video, use 139502 instead.
 43%|████▎     | 1239/2910 [7:45:19<4:06:38,  8.86s/it][h264 @ 0x55b5c47ff940] mmco: unref short failure
[h264 @ 0x55b5b4fae400] mmco: unref short failure
[h264 @ 0x55b5b4fae400] mmco: unref short failure
09/17/2024 07:07:15 - INFO - __main__ -   current idx 14WUuya94QE.50 from finetune_area returns wrong image/video, use 125031 instead.
[h264 @ 0x55a318c8bb40] mmco: unref short failure
[h264 @ 0x55a318c8bb40] mmco: unref short failure
[h264 @ 0x55a317a32800] mmco: unref short failure
[h264 @ 0x55b5b919d140] mmco: unref short failure
[h264 @ 0x55b5b919d140] mmco: unref short failure
[h264 @ 0x55a327b98180] mmco: unref short failure
[h264 @ 0x55a3127c0a00] mmco: unref short failure
[h264 @ 0x55e24c3ad8c0] mmco: unref short failure
[h264 @ 0x55e24c3ad8c0] mmco: unref short failure
[h264 @ 0x55a30f508cc0] mmco: unref short failure
[h264 @ 0x55a30f508cc0] mmco: unref short failure
[h264 @ 0x55a32afda740] mmco: unref short failure
[h264 @ 0x55a32afda740] mmco: unref short failure
[h264 @ 0x560742c46280] mmco: unref short failure
[h264 @ 0x560742c46280] mmco: unref short failure
[h264 @ 0x55a3245fd800] mmco: unref short failure
[h264 @ 0x55a3245fd800] mmco: unref short failure
[h264 @ 0x55b5b6477fc0] mmco: unref short failure
[h264 @ 0x55b5b6477fc0] mmco: unref short failure
[h264 @ 0x55a325fe1840] mmco: unref short failure
[h264 @ 0x55e24f27e080] mmco: unref short failure
[h264 @ 0x55e24f27e080] mmco: unref short failure
[h264 @ 0x560745b63c80] mmco: unref short failure
[h264 @ 0x560745b63c80] mmco: unref short failure
 43%|████▎     | 1240/2910 [7:46:42<14:28:52, 31.22s/it][h264 @ 0x55e24ae7cb40] mmco: unref short failure
 43%|████▎     | 1241/2910 [7:46:53<11:39:00, 25.13s/it][h264 @ 0x55e24f241840] mmco: unref short failure
[h264 @ 0x55e24f241840] mmco: unref short failure
[h264 @ 0x55e248dca600] mmco: unref short failure
[h264 @ 0x55e248dca600] mmco: unref short failure
[h264 @ 0x55a327043c80] mmco: unref short failure
[h264 @ 0x56074341eb00] mmco: unref short failure
[h264 @ 0x55a32856d8c0] mmco: unref short failure
[h264 @ 0x56074802b440] mmco: unref short failure
[h264 @ 0x56074802b440] mmco: unref short failure
[h264 @ 0x55b5b525adc0] mmco: unref short failure
[h264 @ 0x55b5b6253980] mmco: unref short failure
[h264 @ 0x560743161680] mmco: unref short failure
[h264 @ 0x560743161680] mmco: unref short failure
[h264 @ 0x55b5c355fc00] mmco: unref short failure
[h264 @ 0x55b5c355fc00] mmco: unref short failure
 43%|████▎     | 1242/2910 [7:47:46<15:29:27, 33.43s/it][h264 @ 0x55b5bc1c4b00] mmco: unref short failure
 43%|████▎     | 1243/2910 [7:47:52<11:39:45, 25.19s/it] 43%|████▎     | 1244/2910 [7:47:57<8:53:44, 19.22s/it] [h264 @ 0x56074c53bac0] mmco: unref short failure
 43%|████▎     | 1245/2910 [7:48:02<6:56:30, 15.01s/it] 43%|████▎     | 1246/2910 [7:48:08<5:38:01, 12.19s/it] 43%|████▎     | 1247/2910 [7:48:13<4:37:52, 10.03s/it][h264 @ 0x55e249eee640] mmco: unref short failure
[h264 @ 0x55e249eee640] mmco: unref short failure
[h264 @ 0x55a313650400] mmco: unref short failure
[h264 @ 0x55a31294dcc0] mmco: unref short failure
[h264 @ 0x55a31294dcc0] mmco: unref short failure
[h264 @ 0x55a31bd01100] mmco: unref short failure
[h264 @ 0x55a31bd01100] mmco: unref short failure
[h264 @ 0x55a325f49680] mmco: unref short failure
[h264 @ 0x55a325f49680] mmco: unref short failure
[h264 @ 0x55a325f49680] mmco: unref short failure
[h264 @ 0x55a325f49680] mmco: unref short failure
[h264 @ 0x55a30f629540] mmco: unref short failure
[h264 @ 0x55a30f629540] mmco: unref short failure
[h264 @ 0x55a328562900] mmco: unref short failure
[h264 @ 0x55a328562900] mmco: unref short failure
[h264 @ 0x55a31a107400] mmco: unref short failure
[h264 @ 0x55a31a107400] mmco: unref short failure
[h264 @ 0x55a31a107400] mmco: unref short failure
[h264 @ 0x55a31a107400] mmco: unref short failure
[h264 @ 0x55a31a107400] mmco: unref short failure
[h264 @ 0x55a31a107400] mmco: unref short failure
[h264 @ 0x55a31a107400] mmco: unref short failure
[h264 @ 0x55a31a107400] mmco: unref short failure
[h264 @ 0x55a32b0a4c80] mmco: unref short failure
[h264 @ 0x55a32b0a4c80] mmco: unref short failure
[h264 @ 0x56075be21480] mmco: unref short failure
 43%|████▎     | 1248/2910 [7:49:13<11:35:04, 25.09s/it][h264 @ 0x56075b28d3c0] mmco: unref short failure
[h264 @ 0x56075b28d3c0] mmco: unref short failure
[h264 @ 0x55e24c3bb680] mmco: unref short failure
[h264 @ 0x55e24c3bb680] mmco: unref short failure
[h264 @ 0x55a31ad8fd80] mmco: unref short failure
 43%|████▎     | 1249/2910 [7:49:23<9:25:54, 20.44s/it] 09/17/2024 07:11:09 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 07:11:09 - INFO - __main__ -   start running ret%tva validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55a327265700] mmco: unref short failure
[h264 @ 0x55a327265700] mmco: unref short failure
[h264 @ 0x56074b104300] mmco: unref short failure
[h264 @ 0x56074b104300] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e2533e5a80] mmco: unref short failure
[h264 @ 0x55e2533e5a80] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55b5c466f740] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x55e2519c2280] mmco: unref short failure
[h264 @ 0x560743e30600] mmco: unref short failure
[h264 @ 0x55b5c0610fc0] mmco: unref short failure
[h264 @ 0x55b5c0610fc0] mmco: unref short failure
[h264 @ 0x560757933580] mmco: unref short failure
[h264 @ 0x560757857d00] mmco: unref short failure
[h264 @ 0x560757857d00] mmco: unref short failure
[h264 @ 0x55b5b2af7180] mmco: unref short failure
[h264 @ 0x55b5b2af7180] mmco: unref short failure
[h264 @ 0x55b5b4ddfb80] mmco: unref short failure
[h264 @ 0x55b5b4ddfb80] mmco: unref short failure
09/17/2024 07:13:06 - INFO - __main__ -   current idx ULdsvnXj9Hc.89 from finetune_area returns wrong image/video, use 16956 instead.
[h264 @ 0x55b5b1f03840] mmco: unref short failure
[h264 @ 0x55a3112fca40] mmco: unref short failure
[h264 @ 0x55e248dca600] mmco: unref short failure
[h264 @ 0x55b5be92ad40] mmco: unref short failure
[h264 @ 0x55b5be92ad40] mmco: unref short failure
[h264 @ 0x55b5be92ad40] mmco: unref short failure
[h264 @ 0x55b5be92ad40] mmco: unref short failure
[h264 @ 0x55b5be92ad40] mmco: unref short failure
[h264 @ 0x55b5be92ad40] mmco: unref short failure
[h264 @ 0x55b5be92ad40] mmco: unref short failure
[h264 @ 0x55b5be92ad40] mmco: unref short failure
[h264 @ 0x55b5be92ad40] mmco: unref short failure
[h264 @ 0x55b5be92ad40] mmco: unref short failure
[h264 @ 0x55b5be92ad40] mmco: unref short failure
[h264 @ 0x55b5be92ad40] mmco: unref short failure
[h264 @ 0x55e24befd480] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:01<04:42,  1.29s/it][A
  1%|          | 2/221 [00:01<03:02,  1.20it/s][A
  1%|▏         | 3/221 [00:02<02:00,  1.82it/s][A
  2%|▏         | 4/221 [00:02<01:21,  2.67it/s][A
  2%|▏         | 5/221 [00:02<01:12,  2.99it/s][A
  3%|▎         | 6/221 [00:02<01:01,  3.49it/s][A
  3%|▎         | 7/221 [00:02<00:56,  3.79it/s][A
  4%|▎         | 8/221 [00:03<01:19,  2.69it/s][A
  4%|▍         | 9/221 [00:03<01:09,  3.03it/s][A
  5%|▍         | 10/221 [00:03<01:08,  3.06it/s][A
  5%|▍         | 11/221 [00:04<01:00,  3.50it/s][A
  5%|▌         | 12/221 [00:04<01:22,  2.53it/s][A
  6%|▌         | 13/221 [00:04<01:04,  3.21it/s][A
  6%|▋         | 14/221 [00:06<02:26,  1.41it/s][A
  7%|▋         | 15/221 [00:06<01:58,  1.74it/s][A
  7%|▋         | 16/221 [00:07<01:41,  2.02it/s][A
  8%|▊         | 17/221 [00:07<01:27,  2.32it/s][A
  8%|▊         | 18/221 [00:07<01:19,  2.56it/s][A
  9%|▊         | 19/221 [00:07<01:04,  3.15it/s][A
  9%|▉         | 20/221 [00:07<00:52,  3.83it/s][A
 10%|▉         | 21/221 [00:08<00:45,  4.44it/s][A
 10%|▉         | 22/221 [00:08<00:42,  4.72it/s][A
 11%|█         | 24/221 [00:08<00:37,  5.22it/s][A
 11%|█▏        | 25/221 [00:08<00:35,  5.47it/s][A
 12%|█▏        | 26/221 [00:09<00:44,  4.42it/s][A
 13%|█▎        | 28/221 [00:09<00:42,  4.58it/s][A[h264 @ 0x55a31eb8b7c0] mmco: unref short failure
[h264 @ 0x55a31eb8b7c0] mmco: unref short failure

 14%|█▎        | 30/221 [00:09<00:37,  5.15it/s][A
 14%|█▍        | 31/221 [00:10<00:38,  4.97it/s][A
 14%|█▍        | 32/221 [00:10<00:34,  5.54it/s][A
 15%|█▍        | 33/221 [00:10<00:53,  3.53it/s][A
 15%|█▌        | 34/221 [00:10<00:48,  3.83it/s][A
 16%|█▌        | 35/221 [00:11<00:44,  4.22it/s][A
 16%|█▋        | 36/221 [00:11<00:49,  3.73it/s][A
 17%|█▋        | 37/221 [00:12<01:17,  2.38it/s][A
 17%|█▋        | 38/221 [00:12<01:18,  2.34it/s][A
 18%|█▊        | 39/221 [00:12<01:00,  3.01it/s][A
 18%|█▊        | 40/221 [00:13<00:53,  3.38it/s][A
 19%|█▉        | 42/221 [00:13<00:50,  3.57it/s][A
 19%|█▉        | 43/221 [00:13<00:44,  4.03it/s][A
 20%|█▉        | 44/221 [00:13<00:42,  4.18it/s][A
 20%|██        | 45/221 [00:14<01:10,  2.51it/s][A
 21%|██        | 46/221 [00:15<01:12,  2.40it/s][A
 21%|██▏       | 47/221 [00:17<02:41,  1.07it/s][A
 22%|██▏       | 48/221 [00:17<02:04,  1.39it/s][A
 22%|██▏       | 49/221 [00:17<01:39,  1.72it/s][A
 23%|██▎       | 50/221 [00:18<01:22,  2.08it/s][A
 23%|██▎       | 51/221 [00:18<01:02,  2.72it/s][A
 24%|██▎       | 52/221 [00:18<00:51,  3.29it/s][A
 24%|██▍       | 53/221 [00:18<00:49,  3.36it/s][A
 24%|██▍       | 54/221 [00:19<01:19,  2.10it/s][A
 25%|██▍       | 55/221 [00:20<01:20,  2.07it/s][A
 25%|██▌       | 56/221 [00:20<01:05,  2.51it/s][A
 26%|██▌       | 57/221 [00:20<00:59,  2.77it/s][A
 26%|██▌       | 58/221 [00:20<00:52,  3.11it/s][A
 27%|██▋       | 59/221 [00:20<00:44,  3.63it/s][A[h264 @ 0x55b5b0df7680] mmco: unref short failure

 27%|██▋       | 60/221 [00:21<00:48,  3.31it/s][A
 28%|██▊       | 61/221 [00:21<00:44,  3.60it/s][A
 28%|██▊       | 62/221 [00:21<00:40,  3.92it/s][A
 29%|██▊       | 63/221 [00:21<00:34,  4.58it/s][A
 29%|██▉       | 64/221 [00:22<00:30,  5.11it/s][A
 29%|██▉       | 65/221 [00:22<00:26,  5.87it/s][A
 30%|██▉       | 66/221 [00:22<00:35,  4.42it/s][A
 30%|███       | 67/221 [00:22<00:37,  4.10it/s][A
 31%|███       | 68/221 [00:23<00:37,  4.06it/s][A
 31%|███       | 69/221 [00:23<00:53,  2.82it/s][A
 32%|███▏      | 70/221 [00:23<00:46,  3.25it/s][A
 32%|███▏      | 71/221 [00:26<02:37,  1.05s/it][A
 33%|███▎      | 72/221 [00:26<01:59,  1.25it/s][A
 33%|███▎      | 73/221 [00:27<01:38,  1.50it/s][A
 33%|███▎      | 74/221 [00:27<01:16,  1.92it/s][A
 34%|███▍      | 75/221 [00:27<01:11,  2.04it/s][A
 34%|███▍      | 76/221 [00:27<00:57,  2.52it/s][A
 35%|███▍      | 77/221 [00:28<00:49,  2.93it/s][A
 35%|███▌      | 78/221 [00:28<00:45,  3.17it/s][A
 36%|███▌      | 79/221 [00:29<01:11,  1.99it/s][A
 36%|███▌      | 80/221 [00:29<00:55,  2.56it/s][A
 37%|███▋      | 81/221 [00:29<00:47,  2.93it/s][A
 37%|███▋      | 82/221 [00:29<00:44,  3.15it/s][A
 38%|███▊      | 83/221 [00:30<00:36,  3.82it/s][A
 38%|███▊      | 84/221 [00:30<00:33,  4.07it/s][A
 38%|███▊      | 85/221 [00:30<00:30,  4.47it/s][A
 39%|███▉      | 86/221 [00:30<00:27,  4.97it/s][A
 39%|███▉      | 87/221 [00:31<00:38,  3.44it/s][A
 40%|███▉      | 88/221 [00:31<00:39,  3.36it/s][A[h264 @ 0x55a329e4f840] mmco: unref short failure
[h264 @ 0x55a329e4f840] mmco: unref short failure

 40%|████      | 89/221 [00:34<02:46,  1.26s/it][A
 41%|████      | 90/221 [00:35<02:07,  1.03it/s][A
 41%|████      | 91/221 [00:35<01:32,  1.40it/s][A
 42%|████▏     | 92/221 [00:35<01:11,  1.80it/s][A
 42%|████▏     | 93/221 [00:36<01:14,  1.72it/s][A
 43%|████▎     | 94/221 [00:36<01:06,  1.92it/s][A
 43%|████▎     | 95/221 [00:36<00:54,  2.31it/s][A
 43%|████▎     | 96/221 [00:37<00:48,  2.59it/s][A[h264 @ 0x55a3213b0e80] mmco: unref short failure
[h264 @ 0x55a3213b0e80] mmco: unref short failure

 44%|████▍     | 97/221 [00:37<00:40,  3.04it/s][A
 44%|████▍     | 98/221 [00:37<00:37,  3.26it/s][A
 45%|████▍     | 99/221 [00:37<00:30,  4.00it/s][A
 45%|████▌     | 100/221 [00:37<00:31,  3.86it/s][A
 46%|████▌     | 101/221 [00:38<00:30,  3.94it/s][A
 46%|████▌     | 102/221 [00:38<00:30,  3.87it/s][A
 47%|████▋     | 103/221 [00:38<00:26,  4.48it/s][A
 47%|████▋     | 104/221 [00:38<00:22,  5.16it/s][A
 48%|████▊     | 105/221 [00:38<00:24,  4.81it/s][A
 48%|████▊     | 106/221 [00:40<00:56,  2.05it/s][A
 48%|████▊     | 107/221 [00:40<00:45,  2.52it/s][A
 49%|████▉     | 108/221 [00:40<00:38,  2.90it/s][A
 49%|████▉     | 109/221 [00:40<00:37,  3.02it/s][A[h264 @ 0x55e23f4389c0] mmco: unref short failure
[h264 @ 0x55e23f4389c0] mmco: unref short failure

 50%|████▉     | 110/221 [00:41<00:34,  3.24it/s][A
 50%|█████     | 111/221 [00:41<00:40,  2.73it/s][A
 51%|█████     | 112/221 [00:41<00:35,  3.06it/s][A
 51%|█████     | 113/221 [00:42<00:37,  2.87it/s][A
 52%|█████▏    | 115/221 [00:42<00:26,  4.06it/s][A
 52%|█████▏    | 116/221 [00:47<02:26,  1.39s/it][A
 53%|█████▎    | 117/221 [00:47<01:54,  1.10s/it][A
 53%|█████▎    | 118/221 [00:48<01:36,  1.07it/s][A
 54%|█████▍    | 119/221 [00:48<01:13,  1.39it/s][A
 54%|█████▍    | 120/221 [00:48<00:58,  1.72it/s][A
 55%|█████▍    | 121/221 [00:48<00:44,  2.23it/s][A
 55%|█████▌    | 122/221 [00:48<00:38,  2.60it/s][A
 56%|█████▌    | 123/221 [00:49<00:31,  3.09it/s][A
 56%|█████▌    | 124/221 [00:49<00:27,  3.47it/s][A
 57%|█████▋    | 125/221 [00:49<00:24,  3.86it/s][A
 57%|█████▋    | 126/221 [00:49<00:27,  3.41it/s][A
 57%|█████▋    | 127/221 [00:50<00:31,  2.98it/s][A
 58%|█████▊    | 128/221 [00:50<00:35,  2.65it/s][A
 58%|█████▊    | 129/221 [00:50<00:31,  2.91it/s][A
 59%|█████▉    | 130/221 [00:51<00:28,  3.17it/s][A
 59%|█████▉    | 131/221 [00:51<00:23,  3.82it/s][A
 60%|█████▉    | 132/221 [00:51<00:21,  4.13it/s][A
 60%|██████    | 133/221 [00:52<00:27,  3.23it/s][A
 61%|██████    | 134/221 [00:52<00:28,  3.04it/s][A
 61%|██████    | 135/221 [00:52<00:33,  2.60it/s][A
 62%|██████▏   | 136/221 [00:53<00:38,  2.21it/s][A
 62%|██████▏   | 137/221 [00:53<00:34,  2.41it/s][A
 62%|██████▏   | 138/221 [00:54<00:39,  2.12it/s][A
 63%|██████▎   | 139/221 [00:54<00:34,  2.35it/s][A
 63%|██████▎   | 140/221 [00:55<00:33,  2.45it/s][A
 64%|██████▍   | 141/221 [00:55<00:26,  3.00it/s][A
 64%|██████▍   | 142/221 [00:55<00:28,  2.75it/s][A
 65%|██████▍   | 143/221 [00:56<00:26,  2.90it/s][A
 65%|██████▌   | 144/221 [00:56<00:22,  3.42it/s][A[h264 @ 0x55b5c20e6100] mmco: unref short failure

 66%|██████▌   | 145/221 [00:56<00:18,  4.11it/s][A
 66%|██████▌   | 146/221 [00:56<00:15,  4.88it/s][A
 67%|██████▋   | 147/221 [00:56<00:13,  5.42it/s][A
 67%|██████▋   | 148/221 [00:56<00:16,  4.52it/s][A
 67%|██████▋   | 149/221 [00:57<00:15,  4.53it/s][A
 68%|██████▊   | 150/221 [00:57<00:15,  4.66it/s][A
 68%|██████▊   | 151/221 [00:58<00:26,  2.61it/s][A
 69%|██████▉   | 152/221 [00:58<00:22,  3.00it/s][A
 69%|██████▉   | 153/221 [00:58<00:21,  3.12it/s][A
 70%|██████▉   | 154/221 [00:59<00:26,  2.57it/s][A
 70%|███████   | 155/221 [00:59<00:21,  3.13it/s][A
 71%|███████   | 156/221 [00:59<00:18,  3.49it/s][A[h264 @ 0x55a324a40500] mmco: unref short failure

 71%|███████   | 157/221 [01:02<01:18,  1.22s/it][A
 71%|███████▏  | 158/221 [01:03<00:58,  1.07it/s][A
 72%|███████▏  | 159/221 [01:03<00:45,  1.37it/s][A
 72%|███████▏  | 160/221 [01:03<00:35,  1.74it/s][A
 73%|███████▎  | 161/221 [01:03<00:26,  2.27it/s][A
 74%|███████▍  | 163/221 [01:04<00:17,  3.23it/s][A
 74%|███████▍  | 164/221 [01:04<00:17,  3.27it/s][A
 75%|███████▍  | 165/221 [01:04<00:15,  3.62it/s][A
 75%|███████▌  | 166/221 [01:05<00:17,  3.06it/s][A
 76%|███████▌  | 167/221 [01:05<00:16,  3.20it/s][A[h264 @ 0x55b5cb141740] mmco: unref short failure
[h264 @ 0x55b5cb141740] mmco: unref short failure

 76%|███████▌  | 168/221 [01:08<01:02,  1.18s/it][A[h264 @ 0x55b5b8d36400] mmco: unref short failure
[h264 @ 0x55b5b8d36400] mmco: unref short failure

 76%|███████▋  | 169/221 [01:08<00:48,  1.08it/s][A
 77%|███████▋  | 170/221 [01:09<00:38,  1.33it/s][A
 77%|███████▋  | 171/221 [01:09<00:30,  1.65it/s][A
 78%|███████▊  | 172/221 [01:09<00:25,  1.94it/s][A
 79%|███████▊  | 174/221 [01:10<00:15,  3.08it/s][A
 79%|███████▉  | 175/221 [01:10<00:14,  3.16it/s][A
 80%|███████▉  | 176/221 [01:10<00:13,  3.31it/s][A
 80%|████████  | 177/221 [01:10<00:11,  3.70it/s][A
 81%|████████  | 178/221 [01:11<00:11,  3.75it/s][A
 81%|████████  | 179/221 [01:12<00:22,  1.85it/s][A
 81%|████████▏ | 180/221 [01:12<00:17,  2.38it/s][A
 82%|████████▏ | 181/221 [01:12<00:14,  2.72it/s][A[h264 @ 0x55b5aa86ec00] mmco: unref short failure
[h264 @ 0x55b5aa86ec00] mmco: unref short failure
[h264 @ 0x55b5aa86ec00] mmco: unref short failure
[h264 @ 0x55b5aa86ec00] mmco: unref short failure

 82%|████████▏ | 182/221 [01:12<00:13,  2.93it/s][A
 83%|████████▎ | 183/221 [01:13<00:11,  3.39it/s][A[h264 @ 0x55a32a6a2f00] mmco: unref short failure

 83%|████████▎ | 184/221 [01:13<00:11,  3.09it/s][A
 84%|████████▎ | 185/221 [01:13<00:09,  3.74it/s][A
 84%|████████▍ | 186/221 [01:13<00:09,  3.60it/s][A
 85%|████████▍ | 187/221 [01:14<00:07,  4.35it/s][A
 85%|████████▌ | 188/221 [01:14<00:07,  4.35it/s][A
 86%|████████▌ | 189/221 [01:14<00:10,  3.08it/s][A
 86%|████████▌ | 190/221 [01:15<00:11,  2.75it/s][A
 86%|████████▋ | 191/221 [01:15<00:08,  3.40it/s][A
 87%|████████▋ | 192/221 [01:15<00:08,  3.34it/s][A
 87%|████████▋ | 193/221 [01:15<00:07,  3.61it/s][A
 88%|████████▊ | 194/221 [01:16<00:12,  2.17it/s][A
 88%|████████▊ | 195/221 [01:16<00:09,  2.72it/s][A
 89%|████████▊ | 196/221 [01:17<00:07,  3.41it/s][A
 89%|████████▉ | 197/221 [01:17<00:06,  3.91it/s][A
 90%|████████▉ | 198/221 [01:17<00:05,  4.29it/s][A
 90%|█████████ | 199/221 [01:17<00:05,  4.15it/s][A
 90%|█████████ | 200/221 [01:17<00:05,  3.96it/s][A
 91%|█████████ | 201/221 [01:18<00:05,  3.72it/s][A
 91%|█████████▏| 202/221 [01:18<00:04,  4.32it/s][A
 92%|█████████▏| 203/221 [01:18<00:03,  4.53it/s][A
 92%|█████████▏| 204/221 [01:18<00:03,  5.40it/s][A
 93%|█████████▎| 205/221 [01:18<00:02,  6.20it/s][A
 93%|█████████▎| 206/221 [01:19<00:03,  3.83it/s][A
 94%|█████████▎| 207/221 [01:19<00:03,  4.36it/s][A
 94%|█████████▍| 208/221 [01:19<00:02,  4.99it/s][A
 95%|█████████▍| 209/221 [01:19<00:02,  5.05it/s][A
 95%|█████████▌| 210/221 [01:19<00:02,  5.20it/s][A[h264 @ 0x55b5b08e3e00] mmco: unref short failure
[h264 @ 0x55b5b08e3e00] mmco: unref short failure

 95%|█████████▌| 211/221 [01:20<00:02,  3.44it/s][A
 96%|█████████▌| 212/221 [01:20<00:02,  4.16it/s][A
 96%|█████████▋| 213/221 [01:20<00:01,  4.57it/s][A
 97%|█████████▋| 214/221 [01:21<00:02,  2.58it/s][A
 97%|█████████▋| 215/221 [01:21<00:02,  2.82it/s][A
 98%|█████████▊| 216/221 [01:22<00:01,  2.89it/s][A
 98%|█████████▊| 217/221 [01:23<00:02,  1.79it/s][A
 99%|█████████▊| 218/221 [01:23<00:01,  1.81it/s][A
 99%|█████████▉| 219/221 [01:23<00:00,  2.20it/s][A[h264 @ 0x56074a4e0ac0] mmco: unref short failure

100%|█████████▉| 220/221 [01:28<00:01,  1.77s/it][A
100%|██████████| 221/221 [01:28<00:00,  1.29s/it][A100%|██████████| 221/221 [01:28<00:00,  2.48it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:05,  3.37it/s][A
  1%|          | 2/221 [00:00<01:05,  3.37it/s][A
  1%|▏         | 3/221 [00:00<01:04,  3.38it/s][A
  2%|▏         | 4/221 [00:01<01:05,  3.33it/s][A
  2%|▏         | 5/221 [00:01<01:04,  3.34it/s][A
  3%|▎         | 6/221 [00:01<01:04,  3.31it/s][A
  3%|▎         | 7/221 [00:02<01:05,  3.27it/s][A
  4%|▎         | 8/221 [00:02<01:05,  3.26it/s][A
  4%|▍         | 9/221 [00:02<01:04,  3.30it/s][A
  5%|▍         | 10/221 [00:03<01:04,  3.28it/s][A
  5%|▍         | 11/221 [00:03<01:03,  3.31it/s][A
  5%|▌         | 12/221 [00:03<01:02,  3.34it/s][A
  6%|▌         | 13/221 [00:03<01:02,  3.34it/s][A
  6%|▋         | 14/221 [00:04<01:01,  3.36it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.35it/s][A
  7%|▋         | 16/221 [00:04<01:00,  3.37it/s][A
  8%|▊         | 17/221 [00:05<01:00,  3.37it/s][A
  8%|▊         | 18/221 [00:05<01:00,  3.36it/s][A
  9%|▊         | 19/221 [00:05<01:00,  3.35it/s][A
  9%|▉         | 20/221 [00:06<01:00,  3.32it/s][A
 10%|▉         | 21/221 [00:06<00:59,  3.34it/s][A
 10%|▉         | 22/221 [00:06<00:59,  3.34it/s][A
 10%|█         | 23/221 [00:06<01:00,  3.30it/s][A
 11%|█         | 24/221 [00:07<00:59,  3.33it/s][A
 11%|█▏        | 25/221 [00:07<00:59,  3.28it/s][A
 12%|█▏        | 26/221 [00:07<00:58,  3.32it/s][A
 12%|█▏        | 27/221 [00:08<00:58,  3.34it/s][A
 13%|█▎        | 28/221 [00:08<00:57,  3.33it/s][A
 13%|█▎        | 29/221 [00:08<00:58,  3.30it/s][A
 14%|█▎        | 30/221 [00:09<00:58,  3.29it/s][A
 14%|█▍        | 31/221 [00:09<00:58,  3.24it/s][A
 14%|█▍        | 32/221 [00:09<00:57,  3.29it/s][A
 15%|█▍        | 33/221 [00:09<00:57,  3.28it/s][A
 15%|█▌        | 34/221 [00:10<00:56,  3.31it/s][A
 16%|█▌        | 35/221 [00:10<00:55,  3.34it/s][A
 16%|█▋        | 36/221 [00:10<00:55,  3.35it/s][A
 17%|█▋        | 37/221 [00:11<00:54,  3.37it/s][A
 17%|█▋        | 38/221 [00:11<00:54,  3.37it/s][A
 18%|█▊        | 39/221 [00:11<00:53,  3.37it/s][A
 18%|█▊        | 40/221 [00:12<00:53,  3.36it/s][A
 19%|█▊        | 41/221 [00:12<00:53,  3.37it/s][A[h264 @ 0x55e2528df400] mmco: unref short failure

 19%|█▉        | 42/221 [00:12<00:53,  3.38it/s][A
 19%|█▉        | 43/221 [00:12<00:52,  3.38it/s][A
 20%|█▉        | 44/221 [00:13<00:53,  3.28it/s][A
 20%|██        | 45/221 [00:13<00:54,  3.23it/s][A
 21%|██        | 46/221 [00:13<00:53,  3.28it/s][A
 21%|██▏       | 47/221 [00:14<00:52,  3.32it/s][A
 22%|██▏       | 48/221 [00:14<00:51,  3.34it/s][A
 22%|██▏       | 49/221 [00:14<00:51,  3.36it/s][A
 23%|██▎       | 50/221 [00:15<00:51,  3.34it/s][A[h264 @ 0x55e24459ed80] mmco: unref short failure

 23%|██▎       | 51/221 [00:15<00:51,  3.33it/s][A
 24%|██▎       | 52/221 [00:15<00:50,  3.33it/s][A
 24%|██▍       | 53/221 [00:15<00:50,  3.33it/s][A
 24%|██▍       | 54/221 [00:16<00:50,  3.32it/s][A
 25%|██▍       | 55/221 [00:16<00:49,  3.35it/s][A
 25%|██▌       | 56/221 [00:16<00:49,  3.34it/s][A
 26%|██▌       | 57/221 [00:17<00:48,  3.36it/s][A[h264 @ 0x55e24de29e40] mmco: unref short failure
[h264 @ 0x55e24de29e40] mmco: unref short failure

 26%|██▌       | 58/221 [00:18<01:18,  2.08it/s][A
 27%|██▋       | 59/221 [00:18<01:09,  2.34it/s][A
 27%|██▋       | 60/221 [00:18<01:02,  2.58it/s][A
 28%|██▊       | 61/221 [00:18<00:57,  2.78it/s][A
 28%|██▊       | 62/221 [00:19<00:54,  2.93it/s][A
 29%|██▊       | 63/221 [00:19<00:52,  3.02it/s][A
 29%|██▉       | 64/221 [00:19<00:50,  3.12it/s][A
 29%|██▉       | 65/221 [00:20<00:48,  3.20it/s][A
 30%|██▉       | 66/221 [00:20<00:47,  3.26it/s][A
 30%|███       | 67/221 [00:20<00:46,  3.30it/s][A
 31%|███       | 68/221 [00:20<00:45,  3.33it/s][A[h264 @ 0x55e24f692780] mmco: unref short failure
[h264 @ 0x55e24f692780] mmco: unref short failure

 31%|███       | 69/221 [00:21<00:45,  3.31it/s][A
 32%|███▏      | 70/221 [00:21<00:45,  3.33it/s][A[h264 @ 0x55e252312180] mmco: unref short failure
[h264 @ 0x55e252312180] mmco: unref short failure

 32%|███▏      | 71/221 [00:21<00:45,  3.32it/s][A
 33%|███▎      | 72/221 [00:22<00:44,  3.34it/s][A
 33%|███▎      | 73/221 [00:22<00:44,  3.36it/s][A
 33%|███▎      | 74/221 [00:22<00:44,  3.34it/s][A
 34%|███▍      | 75/221 [00:23<00:43,  3.36it/s][A
 34%|███▍      | 76/221 [00:23<00:43,  3.36it/s][A
 35%|███▍      | 77/221 [00:23<00:42,  3.37it/s][A
 35%|███▌      | 78/221 [00:23<00:42,  3.38it/s][A
 36%|███▌      | 79/221 [00:24<00:43,  3.24it/s][A
 36%|███▌      | 80/221 [00:24<00:43,  3.23it/s][A
 37%|███▋      | 81/221 [00:24<00:42,  3.27it/s][A
 37%|███▋      | 82/221 [00:25<00:42,  3.31it/s][A
 38%|███▊      | 83/221 [00:25<00:41,  3.34it/s][A
 38%|███▊      | 84/221 [00:25<00:40,  3.35it/s][A
 38%|███▊      | 85/221 [00:26<00:40,  3.37it/s][A
 39%|███▉      | 86/221 [00:26<00:39,  3.38it/s][A
 39%|███▉      | 87/221 [00:26<00:39,  3.38it/s][A
 40%|███▉      | 88/221 [00:26<00:39,  3.39it/s][A
 40%|████      | 89/221 [00:27<00:38,  3.39it/s][A
 41%|████      | 90/221 [00:27<00:38,  3.40it/s][A
 41%|████      | 91/221 [00:27<00:38,  3.40it/s][A
 42%|████▏     | 92/221 [00:28<00:37,  3.40it/s][A
 42%|████▏     | 93/221 [00:28<00:37,  3.40it/s][A
 43%|████▎     | 94/221 [00:28<00:37,  3.40it/s][A
 43%|████▎     | 95/221 [00:29<00:37,  3.40it/s][A
 43%|████▎     | 96/221 [00:29<00:36,  3.40it/s][A
 44%|████▍     | 97/221 [00:29<00:36,  3.40it/s][A
 44%|████▍     | 98/221 [00:29<00:36,  3.40it/s][A
 45%|████▍     | 99/221 [00:30<00:35,  3.40it/s][A
 45%|████▌     | 100/221 [00:30<00:35,  3.41it/s][A
 46%|████▌     | 101/221 [00:30<00:35,  3.41it/s][A
 46%|████▌     | 102/221 [00:31<00:34,  3.41it/s][A
 47%|████▋     | 103/221 [00:31<00:34,  3.41it/s][A
 47%|████▋     | 104/221 [00:31<00:34,  3.41it/s][A
 48%|████▊     | 105/221 [00:31<00:34,  3.41it/s][A
 48%|████▊     | 106/221 [00:32<00:33,  3.41it/s][A
 48%|████▊     | 107/221 [00:32<00:33,  3.41it/s][A
 49%|████▉     | 108/221 [00:32<00:33,  3.41it/s][A
 49%|████▉     | 109/221 [00:33<00:32,  3.41it/s][A
 50%|████▉     | 110/221 [00:33<00:32,  3.41it/s][A
 50%|█████     | 111/221 [00:33<00:32,  3.42it/s][A
 51%|█████     | 112/221 [00:34<00:31,  3.42it/s][A
 51%|█████     | 113/221 [00:34<00:31,  3.42it/s][A
 52%|█████▏    | 114/221 [00:34<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:34<00:30,  3.42it/s][A
 52%|█████▏    | 116/221 [00:35<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:35<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:35<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:36<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:36<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:36<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:37<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:37<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:37<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:38<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:38<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:38<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:39<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:39<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:39<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:40<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:40<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:40<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:41<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:41<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:41<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:41<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:42<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:42<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:42<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:43<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:43<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:43<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:44<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:44<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:44<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:45<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:45<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:45<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:46<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:46<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:46<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:46<00:18,  3.42it/s][A
 71%|███████   | 157/221 [00:47<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:47<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:47<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:48<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:48<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:48<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:48<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:49<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:49<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:49<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:50<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:50<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:50<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:50<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:51<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:51<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:51<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:52<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:52<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:52<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:53<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:53<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:53<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:54<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:54<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:54<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:55<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:55<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:55<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:55<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:56<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:56<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:57<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:57<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:57<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:57<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:58<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:58<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:59<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:59<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:59<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [01:00<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [01:00<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [01:00<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:01<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:01<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:02<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:02<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:02<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:03<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:04<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:04<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:05<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:05<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:05<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.42it/s][A100%|██████████| 221/221 [01:05<00:00,  3.35it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:35,  6.11it/s][A
  1%|          | 2/221 [00:00<00:41,  5.34it/s][A
  1%|▏         | 3/221 [00:00<01:01,  3.56it/s][A
  2%|▏         | 4/221 [00:00<00:52,  4.12it/s][A
  2%|▏         | 5/221 [00:01<00:49,  4.41it/s][A
  3%|▎         | 6/221 [00:01<00:39,  5.38it/s][A
  3%|▎         | 7/221 [00:01<00:47,  4.53it/s][A
  4%|▎         | 8/221 [00:01<01:00,  3.54it/s][A
  4%|▍         | 9/221 [00:02<00:58,  3.62it/s][A
  5%|▍         | 10/221 [00:02<00:51,  4.09it/s][A
  5%|▍         | 11/221 [00:02<00:48,  4.31it/s][A
  5%|▌         | 12/221 [00:02<00:45,  4.56it/s][A
  6%|▌         | 13/221 [00:03<01:20,  2.57it/s][A
  6%|▋         | 14/221 [00:03<01:10,  2.93it/s][A
  7%|▋         | 15/221 [00:04<01:19,  2.60it/s][A
  7%|▋         | 16/221 [00:04<01:20,  2.54it/s][A
  8%|▊         | 17/221 [00:05<01:20,  2.53it/s][A
  8%|▊         | 18/221 [00:05<01:11,  2.84it/s][A
  9%|▉         | 20/221 [00:05<00:51,  3.91it/s][A
 10%|▉         | 21/221 [00:05<00:46,  4.30it/s][A
 10%|▉         | 22/221 [00:05<00:41,  4.78it/s][A
 10%|█         | 23/221 [00:06<00:37,  5.23it/s][A
 11%|█         | 24/221 [00:06<00:34,  5.63it/s][A
 11%|█▏        | 25/221 [00:06<00:43,  4.48it/s][A
 12%|█▏        | 26/221 [00:06<00:43,  4.47it/s][A
 12%|█▏        | 27/221 [00:07<00:43,  4.50it/s][A
 13%|█▎        | 28/221 [00:07<00:42,  4.52it/s][A
 13%|█▎        | 29/221 [00:07<00:49,  3.87it/s][A
 14%|█▎        | 30/221 [00:08<01:05,  2.92it/s][A
 14%|█▍        | 31/221 [00:08<01:04,  2.96it/s][A
 14%|█▍        | 32/221 [00:08<00:56,  3.34it/s][A
 15%|█▍        | 33/221 [00:09<01:03,  2.98it/s][A
 15%|█▌        | 34/221 [00:09<01:10,  2.64it/s][A
 16%|█▌        | 35/221 [00:09<00:57,  3.24it/s][A
 16%|█▋        | 36/221 [00:10<00:59,  3.13it/s][A
 17%|█▋        | 37/221 [00:10<00:51,  3.56it/s][A
 17%|█▋        | 38/221 [00:10<00:51,  3.52it/s][A
 18%|█▊        | 39/221 [00:10<00:48,  3.78it/s][A
 18%|█▊        | 40/221 [00:10<00:46,  3.88it/s][A
 19%|█▊        | 41/221 [00:11<00:50,  3.55it/s][A
 19%|█▉        | 42/221 [00:11<00:44,  4.06it/s][A
 19%|█▉        | 43/221 [00:11<00:41,  4.26it/s][A
 20%|█▉        | 44/221 [00:12<00:45,  3.85it/s][A
 20%|██        | 45/221 [00:12<00:59,  2.97it/s][A
 21%|██        | 46/221 [00:12<00:56,  3.09it/s][A
 21%|██▏       | 47/221 [00:13<00:51,  3.39it/s][A
 22%|██▏       | 48/221 [00:13<00:43,  3.98it/s][A
 23%|██▎       | 50/221 [00:13<00:45,  3.78it/s][A
 23%|██▎       | 51/221 [00:14<00:48,  3.54it/s][A
 24%|██▎       | 52/221 [00:14<00:47,  3.57it/s][A
 24%|██▍       | 53/221 [00:14<00:57,  2.92it/s][A
 24%|██▍       | 54/221 [00:15<00:50,  3.33it/s][A
 25%|██▍       | 55/221 [00:15<00:58,  2.83it/s][A
 25%|██▌       | 56/221 [00:15<00:56,  2.92it/s][A
 26%|██▌       | 57/221 [00:16<00:57,  2.86it/s][A
 26%|██▌       | 58/221 [00:16<00:56,  2.90it/s][A
 27%|██▋       | 59/221 [00:16<00:53,  3.00it/s][A
 27%|██▋       | 60/221 [00:17<00:47,  3.42it/s][A
 28%|██▊       | 61/221 [00:17<00:43,  3.70it/s][A
 28%|██▊       | 62/221 [00:17<00:44,  3.56it/s][A
 29%|██▉       | 64/221 [00:17<00:38,  4.12it/s][A
 29%|██▉       | 65/221 [00:18<00:36,  4.26it/s][A
 30%|██▉       | 66/221 [00:18<00:37,  4.15it/s][A
 30%|███       | 67/221 [00:18<00:38,  4.01it/s][A
 31%|███       | 68/221 [00:18<00:36,  4.20it/s][A
 31%|███       | 69/221 [00:19<00:56,  2.69it/s][A
 32%|███▏      | 70/221 [00:19<00:53,  2.81it/s][A
 32%|███▏      | 71/221 [00:20<00:51,  2.89it/s][A
 33%|███▎      | 72/221 [00:20<00:52,  2.82it/s][A
 33%|███▎      | 73/221 [00:21<00:53,  2.77it/s][A
 33%|███▎      | 74/221 [00:21<00:48,  3.05it/s][A
 34%|███▍      | 75/221 [00:21<00:44,  3.27it/s][A
 34%|███▍      | 76/221 [00:21<00:39,  3.71it/s][A
 35%|███▍      | 77/221 [00:22<00:39,  3.65it/s][A
 35%|███▌      | 78/221 [00:22<00:41,  3.41it/s][A
 36%|███▌      | 79/221 [00:22<00:41,  3.41it/s][A
 36%|███▌      | 80/221 [00:22<00:38,  3.67it/s][A
 37%|███▋      | 81/221 [00:23<00:37,  3.73it/s][A
 37%|███▋      | 82/221 [00:23<00:37,  3.69it/s][A
 38%|███▊      | 83/221 [00:23<00:32,  4.26it/s][A
 38%|███▊      | 84/221 [00:24<00:50,  2.72it/s][A
 38%|███▊      | 85/221 [00:24<00:41,  3.24it/s][A
 39%|███▉      | 86/221 [00:24<00:48,  2.80it/s][A
 39%|███▉      | 87/221 [00:25<00:50,  2.67it/s][A
 40%|███▉      | 88/221 [00:25<00:45,  2.91it/s][A
 40%|████      | 89/221 [00:25<00:46,  2.83it/s][A
 41%|████      | 90/221 [00:26<00:46,  2.84it/s][A
 41%|████      | 91/221 [00:26<00:46,  2.80it/s][A
 42%|████▏     | 92/221 [00:27<00:46,  2.76it/s][A
 42%|████▏     | 93/221 [00:27<00:57,  2.21it/s][A
 43%|████▎     | 94/221 [00:27<00:51,  2.49it/s][A
 43%|████▎     | 95/221 [00:28<01:01,  2.03it/s][A
 43%|████▎     | 96/221 [00:29<00:59,  2.11it/s][A
 44%|████▍     | 97/221 [00:29<00:51,  2.40it/s][A
 44%|████▍     | 98/221 [00:29<00:50,  2.43it/s][A
 45%|████▍     | 99/221 [00:30<00:44,  2.72it/s][A
 45%|████▌     | 100/221 [00:30<00:37,  3.23it/s][A
 46%|████▌     | 101/221 [00:30<00:33,  3.62it/s][A
 46%|████▌     | 102/221 [00:30<00:33,  3.58it/s][A
 47%|████▋     | 103/221 [00:30<00:30,  3.90it/s][A
 47%|████▋     | 104/221 [00:31<00:25,  4.67it/s][A
 48%|████▊     | 105/221 [00:31<00:33,  3.51it/s][A
 48%|████▊     | 106/221 [00:31<00:37,  3.05it/s][A
 48%|████▊     | 107/221 [00:32<00:37,  3.05it/s][A
 49%|████▉     | 108/221 [00:32<00:35,  3.17it/s][A
 49%|████▉     | 109/221 [00:32<00:31,  3.60it/s][A
 50%|████▉     | 110/221 [00:32<00:28,  3.89it/s][A
 50%|█████     | 111/221 [00:33<00:30,  3.58it/s][A
 51%|█████     | 112/221 [00:33<00:33,  3.23it/s][A
 51%|█████     | 113/221 [00:34<00:35,  3.03it/s][A
 52%|█████▏    | 114/221 [00:34<00:30,  3.54it/s][A
 52%|█████▏    | 115/221 [00:34<00:27,  3.89it/s][A
 52%|█████▏    | 116/221 [00:34<00:24,  4.22it/s][A
 53%|█████▎    | 117/221 [00:34<00:24,  4.32it/s][A
 53%|█████▎    | 118/221 [00:35<00:31,  3.28it/s][A
 54%|█████▍    | 119/221 [00:35<00:35,  2.86it/s][A
 54%|█████▍    | 120/221 [00:36<00:36,  2.76it/s][A
 55%|█████▍    | 121/221 [00:36<00:38,  2.61it/s][A
 55%|█████▌    | 122/221 [00:36<00:35,  2.81it/s][A
 56%|█████▌    | 123/221 [00:37<00:36,  2.67it/s][A
 56%|█████▌    | 124/221 [00:37<00:33,  2.90it/s][A
 57%|█████▋    | 125/221 [00:37<00:33,  2.90it/s][A
 57%|█████▋    | 126/221 [00:38<00:28,  3.29it/s][A
 57%|█████▋    | 127/221 [00:38<00:35,  2.68it/s][A
 58%|█████▊    | 128/221 [00:38<00:31,  2.91it/s][A
 58%|█████▊    | 129/221 [00:39<00:26,  3.51it/s][A
 59%|█████▉    | 130/221 [00:39<00:25,  3.54it/s][A
 59%|█████▉    | 131/221 [00:39<00:23,  3.79it/s][A
 60%|█████▉    | 132/221 [00:39<00:23,  3.80it/s][A
 60%|██████    | 133/221 [00:40<00:28,  3.04it/s][A
 61%|██████    | 134/221 [00:40<00:33,  2.62it/s][A
 61%|██████    | 135/221 [00:41<00:29,  2.95it/s][A
 62%|██████▏   | 136/221 [00:41<00:27,  3.10it/s][A
 62%|██████▏   | 137/221 [00:41<00:23,  3.58it/s][A
 62%|██████▏   | 138/221 [00:41<00:20,  3.96it/s][A
 63%|██████▎   | 139/221 [00:42<00:26,  3.15it/s][A
 63%|██████▎   | 140/221 [00:42<00:23,  3.43it/s][A
 64%|██████▍   | 141/221 [00:42<00:26,  3.03it/s][A
 64%|██████▍   | 142/221 [00:43<00:23,  3.33it/s][A
 65%|██████▍   | 143/221 [00:43<00:20,  3.77it/s][A
 65%|██████▌   | 144/221 [00:43<00:20,  3.74it/s][A
 66%|██████▌   | 145/221 [00:43<00:25,  2.94it/s][A
 66%|██████▌   | 146/221 [00:44<00:24,  3.12it/s][A
 67%|██████▋   | 147/221 [00:44<00:21,  3.41it/s][A
 67%|██████▋   | 148/221 [00:45<00:26,  2.77it/s][A
 67%|██████▋   | 149/221 [00:45<00:21,  3.29it/s][A
 68%|██████▊   | 150/221 [00:45<00:19,  3.69it/s][A
 68%|██████▊   | 151/221 [00:45<00:22,  3.06it/s][A
 69%|██████▉   | 152/221 [00:46<00:31,  2.16it/s][A
 69%|██████▉   | 153/221 [00:46<00:28,  2.37it/s][A
 70%|██████▉   | 154/221 [00:47<00:29,  2.25it/s][A
 70%|███████   | 155/221 [00:47<00:26,  2.52it/s][A
 71%|███████   | 156/221 [00:47<00:21,  3.02it/s][A
 71%|███████   | 157/221 [00:48<00:20,  3.19it/s][A
 71%|███████▏  | 158/221 [00:48<00:22,  2.77it/s][A
 72%|███████▏  | 159/221 [00:48<00:20,  3.03it/s][A
 72%|███████▏  | 160/221 [00:49<00:18,  3.31it/s][A
 73%|███████▎  | 161/221 [00:49<00:16,  3.64it/s][A
 74%|███████▍  | 163/221 [00:49<00:13,  4.30it/s][A
 74%|███████▍  | 164/221 [00:49<00:13,  4.34it/s][A
 75%|███████▍  | 165/221 [00:50<00:14,  3.83it/s][A
 75%|███████▌  | 166/221 [00:50<00:16,  3.43it/s][A
 76%|███████▌  | 167/221 [00:50<00:12,  4.17it/s][A
 76%|███████▌  | 168/221 [00:51<00:13,  4.06it/s][A
 77%|███████▋  | 170/221 [00:51<00:13,  3.76it/s][A
 77%|███████▋  | 171/221 [00:51<00:14,  3.56it/s][A
 78%|███████▊  | 172/221 [00:52<00:13,  3.52it/s][A
 78%|███████▊  | 173/221 [00:52<00:13,  3.56it/s][A
 79%|███████▊  | 174/221 [00:52<00:13,  3.41it/s][A
 79%|███████▉  | 175/221 [00:53<00:13,  3.46it/s][A
 80%|███████▉  | 176/221 [00:53<00:11,  3.78it/s][A
 80%|████████  | 177/221 [00:53<00:10,  4.10it/s][A
 81%|████████  | 178/221 [00:54<00:15,  2.74it/s][A
 81%|████████  | 179/221 [00:54<00:13,  3.03it/s][A
 81%|████████▏ | 180/221 [00:54<00:12,  3.19it/s][A
 82%|████████▏ | 181/221 [00:55<00:15,  2.56it/s][A
 82%|████████▏ | 182/221 [00:55<00:14,  2.68it/s][A
 83%|████████▎ | 183/221 [00:55<00:13,  2.77it/s][A
 83%|████████▎ | 184/221 [00:56<00:12,  2.94it/s][A
 84%|████████▎ | 185/221 [00:56<00:09,  3.66it/s][A
 84%|████████▍ | 186/221 [00:56<00:11,  3.03it/s][A
 85%|████████▍ | 187/221 [00:57<00:10,  3.35it/s][A
 85%|████████▌ | 188/221 [00:57<00:09,  3.48it/s][A
 86%|████████▌ | 189/221 [00:57<00:08,  3.74it/s][A
 86%|████████▌ | 190/221 [00:57<00:08,  3.47it/s][A
 86%|████████▋ | 191/221 [00:58<00:08,  3.69it/s][A
 87%|████████▋ | 192/221 [00:58<00:07,  3.67it/s][A
 87%|████████▋ | 193/221 [00:58<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:59<00:08,  3.32it/s][A
 88%|████████▊ | 195/221 [00:59<00:06,  3.98it/s][A
 89%|████████▊ | 196/221 [00:59<00:07,  3.39it/s][A
 89%|████████▉ | 197/221 [00:59<00:07,  3.05it/s][A
 90%|████████▉ | 198/221 [01:00<00:07,  3.07it/s][A
 90%|█████████ | 199/221 [01:00<00:06,  3.58it/s][A
 90%|█████████ | 200/221 [01:00<00:05,  3.70it/s][A
 91%|█████████ | 201/221 [01:00<00:04,  4.14it/s][A
 91%|█████████▏| 202/221 [01:01<00:05,  3.64it/s][A
 92%|█████████▏| 203/221 [01:01<00:04,  3.71it/s][A
 92%|█████████▏| 204/221 [01:01<00:05,  3.18it/s][A
 93%|█████████▎| 205/221 [01:02<00:04,  3.44it/s][A
 93%|█████████▎| 206/221 [01:02<00:05,  2.88it/s][A
 94%|█████████▎| 207/221 [01:02<00:05,  2.79it/s][A
 94%|█████████▍| 208/221 [01:03<00:04,  3.19it/s][A
 95%|█████████▍| 209/221 [01:03<00:03,  3.56it/s][A
 95%|█████████▌| 210/221 [01:03<00:03,  2.84it/s][A
 95%|█████████▌| 211/221 [01:04<00:03,  3.07it/s][A
 96%|█████████▌| 212/221 [01:04<00:02,  3.28it/s][A
 96%|█████████▋| 213/221 [01:04<00:02,  3.52it/s][A
 97%|█████████▋| 214/221 [01:04<00:02,  3.49it/s][A
 97%|█████████▋| 215/221 [01:05<00:02,  2.96it/s][A
 98%|█████████▊| 216/221 [01:05<00:01,  3.01it/s][A
 98%|█████████▊| 217/221 [01:06<00:01,  3.15it/s][A
 99%|█████████▊| 218/221 [01:06<00:00,  3.26it/s][A
 99%|█████████▉| 219/221 [01:06<00:00,  2.95it/s][A
100%|█████████▉| 220/221 [01:06<00:00,  3.38it/s][A
100%|██████████| 221/221 [01:07<00:00,  3.46it/s][A100%|██████████| 221/221 [01:07<00:00,  3.29it/s]
09/17/2024 07:17:15 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 1249--===========

09/17/2024 07:17:15 - INFO - __main__ -   {'area_r1': 38.5, 'area_recall': '38.5/62.7/72.5', 'area_ravg': 57.9}
09/17/2024 07:17:15 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 1249--===========

09/17/2024 07:17:15 - INFO - __main__ -   {'forward_r1': 37.1, 'forward_recall': '37.1/66.0/76.8', 'forward_ravg': 60.0}
09/17/2024 07:17:15 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 1249--===========

09/17/2024 07:17:15 - INFO - __main__ -   {'area_video_r1': 37.7, 'area_video_recall': '37.7/65.3/77.0', 'area_video_ravg': 60.0}
09/17/2024 07:17:15 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 299=======

09/17/2024 07:17:15 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 07:17:15 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 1249--===========

09/17/2024 07:17:15 - INFO - __main__ -   {'area_video_r1': 52.0, 'area_video_recall': '52.0/74.4/81.7', 'area_video_ravg': 69.4, 'area_video_back_r1': 46.8, 'area_video_back_recall': '46.8/73.8/81.3', 'area_video_back_ravg': 67.3}
09/17/2024 07:17:15 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 549=======

09/17/2024 07:17:15 - INFO - __main__ -   {'area_video_r1': 54.1, 'area_video_recall': '54.1/75.5/82.4', 'area_video_ravg': 70.6, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.5/82.1', 'area_video_back_ravg': 68.7}
09/17/2024 07:17:15 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 1249--===========

09/17/2024 07:17:15 - INFO - __main__ -   {'video_r1': 37.9, 'video_recall': '37.9/64.3/74.0', 'video_ravg': 58.7}
09/17/2024 07:17:15 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 949=======

09/17/2024 07:17:15 - INFO - __main__ -   {'video_r1': 38.7, 'video_recall': '38.7/64.3/74.1', 'video_ravg': 59.0}
09/17/2024 07:17:15 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 1249--===========

09/17/2024 07:17:15 - INFO - __main__ -   {'video_r1': 52.5, 'video_recall': '52.5/74.1/81.8', 'video_ravg': 69.5}
09/17/2024 07:17:15 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 549=======

09/17/2024 07:17:15 - INFO - __main__ -   {'video_r1': 54.5, 'video_recall': '54.5/76.1/83.4', 'video_ravg': 71.3}
09/17/2024 07:17:37 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.00738153513520956, 'loss_ret%tv%ta--finetune_area/loss_area': 1.1077556610107422, 'loss_ret%tv%ta--finetune_area/total_loss': 1.1151372194290161}
 43%|████▎     | 1250/2910 [7:55:54<60:41:19, 131.61s/it][h264 @ 0x55e2552da180] mmco: unref short failure
 43%|████▎     | 1251/2910 [7:55:57<42:58:39, 93.26s/it]  43%|████▎     | 1252/2910 [7:56:01<30:35:51, 66.44s/it][h264 @ 0x55e243234d00] mmco: unref short failure
[h264 @ 0x55e243234d00] mmco: unref short failure
[h264 @ 0x55e243234d00] mmco: unref short failure
[h264 @ 0x55e243234d00] mmco: unref short failure
[h264 @ 0x55e243234d00] mmco: unref short failure
[h264 @ 0x55e243234d00] mmco: unref short failure
 43%|████▎     | 1253/2910 [7:56:06<21:59:37, 47.78s/it][h264 @ 0x55b5b32169c0] mmco: unref short failure
[h264 @ 0x55b5b32169c0] mmco: unref short failure
[h264 @ 0x55a31fb9b700] mmco: unref short failure
[h264 @ 0x55a31fb9b700] mmco: unref short failure
[h264 @ 0x55a31fb9b700] mmco: unref short failure
[h264 @ 0x55a31fb9b700] mmco: unref short failure
 43%|████▎     | 1254/2910 [7:56:10<16:00:30, 34.80s/it][h264 @ 0x55e241b7d4c0] mmco: unref short failure
[h264 @ 0x55e254d3fec0] mmco: unref short failure
[h264 @ 0x55e254d3fec0] mmco: unref short failure
[h264 @ 0x55e238852840] mmco: unref short failure
[h264 @ 0x55e238852840] mmco: unref short failure
 43%|████▎     | 1255/2910 [7:56:15<11:50:37, 25.76s/it][h264 @ 0x56075387ff80] mmco: unref short failure
09/17/2024 07:18:02 - INFO - __main__ -   current idx g0isRLf0U2E.7 from finetune_area returns wrong image/video, use 75631 instead.
 43%|████▎     | 1256/2910 [7:56:19<8:55:12, 19.41s/it]  43%|████▎     | 1257/2910 [7:56:24<6:55:14, 15.07s/it] 43%|████▎     | 1258/2910 [7:56:30<5:40:33, 12.37s/it][h264 @ 0x55b5b59dbfc0] mmco: unref short failure
[h264 @ 0x55a318b32500] mmco: unref short failure
[h264 @ 0x55a318b32500] mmco: unref short failure
 43%|████▎     | 1259/2910 [7:56:36<4:45:58, 10.39s/it] 43%|████▎     | 1260/2910 [7:56:41<4:02:44,  8.83s/it][h264 @ 0x55e2565265c0] mmco: unref short failure
[h264 @ 0x55e2565265c0] mmco: unref short failure
 43%|████▎     | 1261/2910 [7:56:46<3:32:08,  7.72s/it][h264 @ 0x55e243e28280] mmco: unref short failure
 43%|████▎     | 1262/2910 [7:56:54<3:27:32,  7.56s/it] 43%|████▎     | 1263/2910 [7:56:59<3:05:07,  6.74s/it][h264 @ 0x55b5bd690f80] mmco: unref short failure
[h264 @ 0x55b5bff78000] mmco: unref short failure
 43%|████▎     | 1264/2910 [7:57:03<2:46:39,  6.08s/it][h264 @ 0x55b5bb990340] mmco: unref short failure
[h264 @ 0x55b5c3a30340] mmco: unref short failure
[h264 @ 0x56075d333880] mmco: unref short failure
[h264 @ 0x56075d333880] mmco: unref short failure
[h264 @ 0x56075d333880] mmco: unref short failure
[h264 @ 0x56075d333880] mmco: unref short failure
[h264 @ 0x56075d333880] mmco: unref short failure
[h264 @ 0x56075d333880] mmco: unref short failure
 43%|████▎     | 1265/2910 [7:57:08<2:39:48,  5.83s/it][h264 @ 0x55e24147d000] mmco: unref short failure
[h264 @ 0x55a311c81580] mmco: unref short failure
[h264 @ 0x55a31f86ab00] mmco: unref short failure
[h264 @ 0x55a31f86ab00] mmco: unref short failure
[h264 @ 0x5607581897c0] mmco: unref short failure
[h264 @ 0x56075350d340] mmco: unref short failure
[h264 @ 0x56075350d340] mmco: unref short failure
[h264 @ 0x55e2522f8700] mmco: unref short failure
[h264 @ 0x55b5bc4364c0] mmco: unref short failure
[h264 @ 0x55b5bc4364c0] mmco: unref short failure
[h264 @ 0x560757b68ac0] mmco: unref short failure
[h264 @ 0x560757b68ac0] mmco: unref short failure
[h264 @ 0x55a311757780] mmco: unref short failure
[h264 @ 0x55b5ca0d7880] mmco: unref short failure
[h264 @ 0x55e23d45bb80] mmco: unref short failure
[h264 @ 0x55a31bf7d240] mmco: unref short failure
[h264 @ 0x55a31bf7d240] mmco: unref short failure
[h264 @ 0x56074f986dc0] mmco: unref short failure
[h264 @ 0x56074f986dc0] mmco: unref short failure
[h264 @ 0x55b5baed16c0] mmco: unref short failure
09/17/2024 07:19:43 - INFO - __main__ -   current idx 3B1z5s6SZbQ.15 from finetune_area returns wrong image/video, use 103907 instead.
[h264 @ 0x55a30f61ce00] mmco: unref short failure
 44%|████▎     | 1266/2910 [7:58:02<9:16:37, 20.31s/it][h264 @ 0x5607585c9f40] mmco: unref short failure
[h264 @ 0x5607585c9f40] mmco: unref short failure
 44%|████▎     | 1267/2910 [7:58:14<8:01:10, 17.57s/it][h264 @ 0x56075a9b0400] mmco: unref short failure
[h264 @ 0x56075a9b0400] mmco: unref short failure
[h264 @ 0x55a31c19b800] mmco: unref short failure
[h264 @ 0x55a31c19b800] mmco: unref short failure
[h264 @ 0x55e24f0bd080] mmco: unref short failure
[h264 @ 0x55e24f0bd080] mmco: unref short failure
not have audios GAwav3sZcGw.4
[h264 @ 0x55e2518a46c0] mmco: unref short failure
09/17/2024 07:20:15 - INFO - __main__ -   current idx A-E7Tr5PbZI.14 from finetune_area returns wrong image/video, use 131236 instead.
[h264 @ 0x55a310751280] mmco: unref short failure
 44%|████▎     | 1268/2910 [7:58:34<8:26:24, 18.50s/it][h264 @ 0x55a31b0c6100] mmco: unref short failure
[h264 @ 0x55a31b0c6100] mmco: unref short failure
 44%|████▎     | 1269/2910 [7:58:42<7:01:18, 15.40s/it][h264 @ 0x55b5ace99400] mmco: unref short failure
[h264 @ 0x55b5ace99400] mmco: unref short failure
[h264 @ 0x55e242684580] mmco: unref short failure
[h264 @ 0x55b5bbf5bd40] mmco: unref short failure
[h264 @ 0x55b5bbf5bd40] mmco: unref short failure
 44%|████▎     | 1270/2910 [7:58:51<6:01:37, 13.23s/it] 44%|████▎     | 1271/2910 [7:58:55<4:51:27, 10.67s/it] 44%|████▎     | 1272/2910 [7:59:00<4:06:21,  9.02s/it][h264 @ 0x55a314e74200] mmco: unref short failure
 44%|████▎     | 1273/2910 [7:59:06<3:37:39,  7.98s/it][h264 @ 0x55e252d9dbc0] mmco: unref short failure
[h264 @ 0x55e252d9dbc0] mmco: unref short failure
[h264 @ 0x55a328c789c0] mmco: unref short failure
[h264 @ 0x55a328c789c0] mmco: unref short failure
[h264 @ 0x55b5bc157a80] mmco: unref short failure
09/17/2024 07:21:08 - INFO - __main__ -   current idx aKaIctkC1IU.24 from finetune_area returns wrong image/video, use 100476 instead.
[h264 @ 0x55b5b19d5cc0] mmco: unref short failure
[h264 @ 0x55b5b19d5cc0] mmco: unref short failure
[h264 @ 0x55e25104c780] mmco: unref short failure
[h264 @ 0x55e25104c780] mmco: unref short failure
[h264 @ 0x55b5b39d3600] mmco: unref short failure
[h264 @ 0x55b5b39d3600] mmco: unref short failure
[h264 @ 0x55b5b39d3600] mmco: unref short failure
[h264 @ 0x55a328c79280] mmco: unref short failure
[h264 @ 0x55a328c79280] mmco: unref short failure
[h264 @ 0x56074ce55440] mmco: unref short failure
[h264 @ 0x56074ce55440] mmco: unref short failure
[h264 @ 0x55b5b2f38400] mmco: unref short failure
[h264 @ 0x55b5b2f38400] mmco: unref short failure
[h264 @ 0x55b5c3be9600] mmco: unref short failure
[h264 @ 0x55b5c3be9600] mmco: unref short failure
[h264 @ 0x56075bdf5ec0] mmco: unref short failure
[h264 @ 0x56075bdf5ec0] mmco: unref short failure
[h264 @ 0x56075bdf5ec0] mmco: unref short failure
[h264 @ 0x56075bdf5ec0] mmco: unref short failure
[h264 @ 0x55a32bdcf800] mmco: unref short failure
[h264 @ 0x55a32bdcf800] mmco: unref short failure
[h264 @ 0x55e255f26840] mmco: unref short failure
[h264 @ 0x55e255f26840] mmco: unref short failure
[h264 @ 0x560742b96bc0] mmco: unref short failure
[h264 @ 0x560742b96bc0] mmco: unref short failure
[h264 @ 0x560742b96bc0] mmco: unref short failure
[h264 @ 0x560742b96bc0] mmco: unref short failure
[h264 @ 0x55e252cb8cc0] mmco: unref short failure
[h264 @ 0x55e23e2e08c0] mmco: unref short failure
[h264 @ 0x55e23e2e08c0] mmco: unref short failure
[h264 @ 0x55a3292f0900] mmco: unref short failure
[h264 @ 0x55a31fb75b00] mmco: unref short failure
 44%|████▍     | 1274/2910 [8:00:32<14:15:12, 31.36s/it][h264 @ 0x5607575d6680] mmco: unref short failure
[h264 @ 0x5607575d6680] mmco: unref short failure
[h264 @ 0x55a3139a58c0] mmco: unref short failure
[h264 @ 0x55a3139a58c0] mmco: unref short failure
[h264 @ 0x55a311be4b80] mmco: unref short failure
[h264 @ 0x55a311be4b80] mmco: unref short failure
 44%|████▍     | 1275/2910 [8:00:45<11:47:56, 25.98s/it][h264 @ 0x560756004b00] mmco: unref short failure
[h264 @ 0x560756004b00] mmco: unref short failure
[h264 @ 0x560756004b00] mmco: unref short failure
[h264 @ 0x560756004b00] mmco: unref short failure
[h264 @ 0x560756004b00] mmco: unref short failure
[h264 @ 0x560756004b00] mmco: unref short failure
[h264 @ 0x55b5a9d37580] mmco: unref short failure
[h264 @ 0x55b5ab880780] mmco: unref short failure
[h264 @ 0x55e254d3fcc0] mmco: unref short failure
[h264 @ 0x55e254d3fcc0] mmco: unref short failure
[h264 @ 0x55e24e241000] mmco: unref short failure
[h264 @ 0x55b5c1e03980] mmco: unref short failure
[h264 @ 0x55b5c1e03980] mmco: unref short failure
[h264 @ 0x55b5c3a3ce00] mmco: unref short failure
[h264 @ 0x55b5c3a3ce00] mmco: unref short failure
 44%|████▍     | 1276/2910 [8:01:08<11:18:56, 24.93s/it][h264 @ 0x55a31f21af80] mmco: unref short failure
[h264 @ 0x55b5cbdcdbc0] mmco: unref short failure
[h264 @ 0x55b5b8cf5b40] mmco: unref short failure
[h264 @ 0x55b5b8cf5b40] mmco: unref short failure
[h264 @ 0x55b5b8cf5b40] mmco: unref short failure
[h264 @ 0x55b5b8cf5b40] mmco: unref short failure
 44%|████▍     | 1277/2910 [8:01:36<11:42:59, 25.83s/it][h264 @ 0x55e23ef9da80] mmco: unref short failure
[h264 @ 0x55e23ef9da80] mmco: unref short failure
 44%|████▍     | 1278/2910 [8:01:41<8:55:23, 19.68s/it] [h264 @ 0x55a30eef7500] mmco: unref short failure
[h264 @ 0x55a30eef7500] mmco: unref short failure
[h264 @ 0x55a30eef7500] mmco: unref short failure
[h264 @ 0x55a30eef7500] mmco: unref short failure
[h264 @ 0x55b5a9d7ab40] mmco: unref short failure
[h264 @ 0x55b5a9d7ab40] mmco: unref short failure
[h264 @ 0x55b5a9d7ab40] mmco: unref short failure
[h264 @ 0x55b5a9d7ab40] mmco: unref short failure
[h264 @ 0x56075f649600] mmco: unref short failure
[h264 @ 0x56075f649600] mmco: unref short failure
 44%|████▍     | 1279/2910 [8:01:47<6:59:07, 15.42s/it][h264 @ 0x55b5c326d480] mmco: unref short failure
[h264 @ 0x55b5c326d480] mmco: unref short failure
[h264 @ 0x55b5c7a3cc00] mmco: unref short failure
[h264 @ 0x55b5c7a3cc00] mmco: unref short failure
 44%|████▍     | 1280/2910 [8:01:53<5:41:43, 12.58s/it] 44%|████▍     | 1281/2910 [8:01:58<4:47:02, 10.57s/it][h264 @ 0x55b5b8b6de80] mmco: unref short failure
09/17/2024 07:23:46 - INFO - __main__ -   current idx Z9v3A-MeZGQ.15 from finetune_area returns wrong image/video, use 36851 instead.
[h264 @ 0x55e23f4507c0] mmco: unref short failure
[h264 @ 0x55e23f4507c0] mmco: unref short failure
[h264 @ 0x560757472e00] mmco: unref short failure
[h264 @ 0x55a326b6d2c0] mmco: unref short failure
[h264 @ 0x56074a58cdc0] mmco: unref short failure
[h264 @ 0x55e23fece100] mmco: unref short failure
[h264 @ 0x55e23fece100] mmco: unref short failure
[h264 @ 0x55b5bea82940] mmco: unref short failure
09/17/2024 07:24:27 - INFO - __main__ -   current idx QRr-nFmU9s8.3 from finetune_area returns wrong image/video, use 122977 instead.
[h264 @ 0x55b5ca032b40] mmco: unref short failure
[h264 @ 0x55a32674f940] mmco: unref short failure
[h264 @ 0x55a32674f940] mmco: unref short failure
[h264 @ 0x55e238b08f80] mmco: unref short failure
[h264 @ 0x55e238b08f80] mmco: unref short failure
 44%|████▍     | 1282/2910 [8:03:01<11:52:21, 26.25s/it][h264 @ 0x56074617af80] mmco: unref short failure
[h264 @ 0x55b5b04b1f40] mmco: unref short failure
[h264 @ 0x55b5b04b1f40] mmco: unref short failure
 44%|████▍     | 1283/2910 [8:03:20<10:52:27, 24.06s/it][h264 @ 0x55e253a95580] mmco: unref short failure
[h264 @ 0x56074c64a940] mmco: unref short failure
[h264 @ 0x56074c64a940] mmco: unref short failure
[h264 @ 0x56074c64a940] mmco: unref short failure
[h264 @ 0x56074c64a940] mmco: unref short failure
[h264 @ 0x55e255304600] mmco: unref short failure
[h264 @ 0x55e255304600] mmco: unref short failure
[h264 @ 0x55e255304600] mmco: unref short failure
[h264 @ 0x55e255304600] mmco: unref short failure
[h264 @ 0x56075d97eb00] mmco: unref short failure
[h264 @ 0x56075d97eb00] mmco: unref short failure
 44%|████▍     | 1284/2910 [8:03:41<10:26:50, 23.13s/it][h264 @ 0x55a326f9e500] mmco: unref short failure
[h264 @ 0x55a326f9e500] mmco: unref short failure
[h264 @ 0x55a3271c4100] mmco: unref short failure
[h264 @ 0x55e23fece7c0] mmco: unref short failure
[h264 @ 0x55b5bbbbeb00] mmco: unref short failure
[h264 @ 0x55b5b06ad880] mmco: unref short failure
[h264 @ 0x55b5b06ad880] mmco: unref short failure
[h264 @ 0x55b5b06ad880] mmco: unref short failure
[h264 @ 0x55b5b06ad880] mmco: unref short failure
[h264 @ 0x55b5b06ad880] mmco: unref short failure
[h264 @ 0x55b5b06ad880] mmco: unref short failure
[h264 @ 0x55e252d58ac0] mmco: unref short failure
[h264 @ 0x55e252d58ac0] mmco: unref short failure
[h264 @ 0x55b5c6b00e40] mmco: unref short failure
[h264 @ 0x55b5b3e4d040] mmco: unref short failure
[h264 @ 0x55b5b3e4d040] mmco: unref short failure
[h264 @ 0x55a321164f80] mmco: unref short failure
[h264 @ 0x55a321164f80] mmco: unref short failure
 44%|████▍     | 1285/2910 [8:04:14<11:46:10, 26.07s/it][h264 @ 0x55a3124f4e40] mmco: unref short failure
[h264 @ 0x55a3124f4e40] mmco: unref short failure
 44%|████▍     | 1286/2910 [8:04:20<9:02:17, 20.04s/it] [h264 @ 0x55a31be8fa00] mmco: unref short failure
[h264 @ 0x56074358eb40] mmco: unref short failure
[h264 @ 0x56074358eb40] mmco: unref short failure
 44%|████▍     | 1287/2910 [8:04:25<7:02:59, 15.64s/it] 44%|████▍     | 1288/2910 [8:04:31<5:41:53, 12.65s/it] 44%|████▍     | 1289/2910 [8:04:37<4:43:54, 10.51s/it][h264 @ 0x5607611bbfc0] mmco: unref short failure
[h264 @ 0x5607611bbfc0] mmco: unref short failure
[h264 @ 0x5607611bbfc0] mmco: unref short failure
[h264 @ 0x5607611bbfc0] mmco: unref short failure
09/17/2024 07:26:31 - INFO - __main__ -   current idx D5HFB_qydCY.50 from finetune_area returns wrong image/video, use 18127 instead.
[h264 @ 0x55e253edb9c0] mmco: unref short failure
[h264 @ 0x55e253edb9c0] mmco: unref short failure
[h264 @ 0x55e253edb9c0] mmco: unref short failure
[h264 @ 0x55e253edb9c0] mmco: unref short failure
[h264 @ 0x55e24b86cac0] mmco: unref short failure
[h264 @ 0x55e24b86cac0] mmco: unref short failure
[h264 @ 0x55a32ab484c0] mmco: unref short failure
[h264 @ 0x55a32ab484c0] mmco: unref short failure
[h264 @ 0x55b5c9aa34c0] mmco: unref short failure
[h264 @ 0x56075271bcc0] mmco: unref short failure
[h264 @ 0x56075271bcc0] mmco: unref short failure
[h264 @ 0x55a32db04680] mmco: unref short failure
[h264 @ 0x55a32db04680] mmco: unref short failure
[h264 @ 0x55b5adab5480] mmco: unref short failure
09/17/2024 07:27:10 - INFO - __main__ -   current idx PXm6mn8_9zE.31 from finetune_area returns wrong image/video, use 16184 instead.
[h264 @ 0x55b5aac84cc0] mmco: unref short failure
[h264 @ 0x56075b434200] mmco: unref short failure
[h264 @ 0x5607498db540] mmco: unref short failure
 44%|████▍     | 1290/2910 [8:05:36<11:23:32, 25.32s/it][h264 @ 0x55b5c2f3ae80] mmco: unref short failure
[h264 @ 0x55b5c2f3ae80] mmco: unref short failure
[h264 @ 0x55b5c2f3ae80] mmco: unref short failure
[h264 @ 0x55b5c2f3ae80] mmco: unref short failure
[h264 @ 0x55b5c2f3ae80] mmco: unref short failure
[h264 @ 0x55b5c2f3ae80] mmco: unref short failure
[h264 @ 0x55b5c2f3ae80] mmco: unref short failure
[h264 @ 0x55b5c2f3ae80] mmco: unref short failure
[h264 @ 0x55b5c2f3ae80] mmco: unref short failure
[h264 @ 0x55b5c2f3ae80] mmco: unref short failure
 44%|████▍     | 1291/2910 [8:05:44<9:01:38, 20.07s/it] [h264 @ 0x56075e64e340] mmco: unref short failure
[h264 @ 0x56075e64e340] mmco: unref short failure
[h264 @ 0x55a32e406600] mmco: unref short failure
[h264 @ 0x55a32e406600] mmco: unref short failure
[h264 @ 0x55e2470fab80] mmco: unref short failure
[h264 @ 0x55e2470fab80] mmco: unref short failure
[h264 @ 0x55e255220b00] mmco: unref short failure
[h264 @ 0x55e255220b00] mmco: unref short failure
 44%|████▍     | 1292/2910 [8:06:11<9:51:39, 21.94s/it][h264 @ 0x55b5b7892b40] mmco: unref short failure
[h264 @ 0x55b5b7892b40] mmco: unref short failure
[h264 @ 0x56074b0d2e80] mmco: unref short failure
[h264 @ 0x56074b0d2e80] mmco: unref short failure
[h264 @ 0x5607535126c0] mmco: unref short failure
[h264 @ 0x5607535126c0] mmco: unref short failure
[h264 @ 0x55b5c5cb0ec0] mmco: unref short failure
[h264 @ 0x55b5c5cb0ec0] mmco: unref short failure
 44%|████▍     | 1293/2910 [8:06:40<10:53:36, 24.25s/it] 44%|████▍     | 1294/2910 [8:06:45<8:18:51, 18.52s/it] 09/17/2024 07:28:36 - INFO - __main__ -   current idx YAXaCmky4Hw.31 from finetune_area returns wrong image/video, use 70706 instead.
 45%|████▍     | 1295/2910 [8:06:51<6:33:31, 14.62s/it][h264 @ 0x55b5a9c8d3c0] mmco: unref short failure
 45%|████▍     | 1296/2910 [8:06:56<5:18:25, 11.84s/it][h264 @ 0x55b5ad02da00] mmco: unref short failure
[h264 @ 0x55b5ad02da00] mmco: unref short failure
 45%|████▍     | 1297/2910 [8:07:02<4:29:57, 10.04s/it][h264 @ 0x55a314ce1100] mmco: unref short failure
[h264 @ 0x56075aab2500] mmco: unref short failure
[h264 @ 0x56075aab2500] mmco: unref short failure
[h264 @ 0x55e242eb1700] mmco: unref short failure
[h264 @ 0x55e242eb1700] mmco: unref short failure
[h264 @ 0x55e2505e0740] mmco: unref short failure
[h264 @ 0x55e2505e0740] mmco: unref short failure
[h264 @ 0x55e25595b8c0] mmco: unref short failure
[h264 @ 0x55e25595b8c0] mmco: unref short failure
[h264 @ 0x55e247ba9000] mmco: unref short failure
[h264 @ 0x55e247ba9000] mmco: unref short failure
[h264 @ 0x55e247ba9000] mmco: unref short failure
[h264 @ 0x55e247ba9000] mmco: unref short failure
[h264 @ 0x55a328ea0500] mmco: unref short failure
[h264 @ 0x55a328ea0500] mmco: unref short failure
[h264 @ 0x56075f177640] mmco: unref short failure
[h264 @ 0x56075f177640] mmco: unref short failure
[h264 @ 0x56074fe8d040] mmco: unref short failure
[h264 @ 0x560754b5f440] mmco: unref short failure
[h264 @ 0x560754b5f440] mmco: unref short failure
[h264 @ 0x55a328ea0080] mmco: unref short failure
[h264 @ 0x55a31e14f7c0] mmco: unref short failure
[h264 @ 0x56074aeea300] mmco: unref short failure
[h264 @ 0x56074aeea300] mmco: unref short failure
09/17/2024 07:29:41 - INFO - __main__ -   current idx 7tqvfeOf2ug.2 from finetune_area returns wrong image/video, use 99459 instead.
[h264 @ 0x55e2556b9280] mmco: unref short failure
[h264 @ 0x55e2556b9280] mmco: unref short failure
[h264 @ 0x5607571bbe00] mmco: unref short failure
[h264 @ 0x5607571bbe00] mmco: unref short failure
 45%|████▍     | 1298/2910 [8:08:09<12:07:55, 27.09s/it][h264 @ 0x55e248631740] mmco: unref short failure
[h264 @ 0x55e248631740] mmco: unref short failure
 45%|████▍     | 1299/2910 [8:08:14<9:11:41, 20.55s/it] 09/17/2024 07:30:00 - INFO - __main__ -   evaluate on ret%tva--msrvtt_ret task
09/17/2024 07:30:00 - INFO - __main__ -   start running ret%tva validation...
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
[h264 @ 0x560760fa9440] mmco: unref short failure
[h264 @ 0x560760fa9440] mmco: unref short failure
[h264 @ 0x560760fa9440] mmco: unref short failure
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
09/17/2024 07:31:09 - INFO - __main__ -   current idx eB3AXJxM634.13 from finetune_area returns wrong image/video, use 48373 instead.
[h264 @ 0x55e243925f00] mmco: unref short failure
[h264 @ 0x55e243925f00] mmco: unref short failure
[h264 @ 0x55b5ae3f3700] mmco: unref short failure
[h264 @ 0x560758f0dd40] mmco: unref short failure
[h264 @ 0x560758f0dd40] mmco: unref short failure
[h264 @ 0x560755c69880] mmco: unref short failure
[h264 @ 0x560755c69880] mmco: unref short failure
[h264 @ 0x560755c69880] mmco: unref short failure
[h264 @ 0x560755c69880] mmco: unref short failure
[h264 @ 0x560755c69880] mmco: unref short failure
[h264 @ 0x55a32498d280] mmco: unref short failure
[h264 @ 0x560754b70f80] mmco: unref short failure
[h264 @ 0x560754b70f80] mmco: unref short failure

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:01<06:07,  1.67s/it][A
  1%|          | 2/221 [00:02<03:43,  1.02s/it][A
  1%|▏         | 3/221 [00:02<02:16,  1.59it/s][A
  2%|▏         | 5/221 [00:02<01:12,  3.00it/s][A
  3%|▎         | 6/221 [00:02<00:59,  3.60it/s][A
  3%|▎         | 7/221 [00:03<00:57,  3.71it/s][A
  4%|▎         | 8/221 [00:03<01:19,  2.69it/s][A[h264 @ 0x55b5b06ad680] mmco: unref short failure

  4%|▍         | 9/221 [00:03<01:04,  3.28it/s][A
  5%|▍         | 10/221 [00:04<01:08,  3.07it/s][A
  5%|▍         | 11/221 [00:04<01:01,  3.44it/s][A
  5%|▌         | 12/221 [00:05<01:29,  2.33it/s][A
  6%|▌         | 13/221 [00:05<01:17,  2.70it/s][A
  6%|▋         | 14/221 [00:06<02:19,  1.49it/s][A
  7%|▋         | 15/221 [00:06<01:50,  1.87it/s][A
  7%|▋         | 16/221 [00:07<01:32,  2.21it/s][A
  8%|▊         | 17/221 [00:07<01:18,  2.60it/s][A
  8%|▊         | 18/221 [00:07<01:07,  3.01it/s][A
  9%|▊         | 19/221 [00:07<00:55,  3.64it/s][A
  9%|▉         | 20/221 [00:07<00:44,  4.50it/s][A
 10%|▉         | 21/221 [00:08<00:41,  4.84it/s][A
 10%|▉         | 22/221 [00:08<00:43,  4.61it/s][A
 10%|█         | 23/221 [00:08<00:37,  5.34it/s][A
 11%|█         | 24/221 [00:08<00:35,  5.58it/s][A
 11%|█▏        | 25/221 [00:08<00:33,  5.84it/s][A
 12%|█▏        | 26/221 [00:08<00:39,  4.91it/s][A
 13%|█▎        | 28/221 [00:09<00:37,  5.15it/s][A
 14%|█▎        | 30/221 [00:09<00:32,  5.84it/s][A
 14%|█▍        | 31/221 [00:09<00:34,  5.46it/s][A
 14%|█▍        | 32/221 [00:10<00:35,  5.33it/s][A
 15%|█▍        | 33/221 [00:10<00:46,  4.04it/s][A
 15%|█▌        | 34/221 [00:10<00:45,  4.09it/s][A
 16%|█▌        | 35/221 [00:10<00:46,  4.02it/s][A
 16%|█▋        | 36/221 [00:11<00:46,  3.97it/s][A
 17%|█▋        | 37/221 [00:11<01:10,  2.63it/s][A
 17%|█▋        | 38/221 [00:12<01:06,  2.74it/s][A
 18%|█▊        | 39/221 [00:12<00:59,  3.08it/s][A
 18%|█▊        | 40/221 [00:12<00:55,  3.27it/s][A
 19%|█▊        | 41/221 [00:12<00:44,  4.06it/s][A
 19%|█▉        | 42/221 [00:13<00:51,  3.49it/s][A
 19%|█▉        | 43/221 [00:13<00:50,  3.51it/s][A
 20%|█▉        | 44/221 [00:13<00:49,  3.55it/s][A[h264 @ 0x55a31b1fbc40] mmco: unref short failure

 20%|██        | 45/221 [00:14<01:18,  2.25it/s][A
 21%|██        | 46/221 [00:15<01:17,  2.26it/s][A
 21%|██▏       | 47/221 [00:17<03:11,  1.10s/it][A
 22%|██▏       | 48/221 [00:17<02:24,  1.20it/s][A
 22%|██▏       | 49/221 [00:18<01:54,  1.51it/s][A
 23%|██▎       | 50/221 [00:18<01:28,  1.93it/s][A
 24%|██▎       | 52/221 [00:18<00:55,  3.07it/s][A
 24%|██▍       | 53/221 [00:18<00:50,  3.31it/s][A
 24%|██▍       | 54/221 [00:19<01:18,  2.14it/s][A
 25%|██▍       | 55/221 [00:20<01:16,  2.17it/s][A
 25%|██▌       | 56/221 [00:20<01:10,  2.34it/s][A
 26%|██▌       | 57/221 [00:20<01:09,  2.35it/s][A
 26%|██▌       | 58/221 [00:21<01:00,  2.69it/s][A
 27%|██▋       | 59/221 [00:21<00:53,  3.01it/s][A
 27%|██▋       | 60/221 [00:22<01:10,  2.28it/s][A
 28%|██▊       | 61/221 [00:22<01:14,  2.15it/s][A
 28%|██▊       | 62/221 [00:22<01:00,  2.64it/s][A
 29%|██▊       | 63/221 [00:22<00:48,  3.24it/s][A
 29%|██▉       | 64/221 [00:23<00:39,  3.96it/s][A
 29%|██▉       | 65/221 [00:23<00:35,  4.42it/s][A
 30%|██▉       | 66/221 [00:23<00:39,  3.92it/s][A
 30%|███       | 67/221 [00:23<00:34,  4.46it/s][A
 31%|███       | 68/221 [00:23<00:29,  5.13it/s][A
 31%|███       | 69/221 [00:24<00:44,  3.45it/s][A
 32%|███▏      | 70/221 [00:24<00:38,  3.90it/s][A
 32%|███▏      | 71/221 [00:28<03:13,  1.29s/it][A
 33%|███▎      | 72/221 [00:28<02:24,  1.03it/s][A
 33%|███▎      | 73/221 [00:28<01:54,  1.29it/s][A
 33%|███▎      | 74/221 [00:28<01:25,  1.73it/s][A
 34%|███▍      | 75/221 [00:29<01:19,  1.83it/s][A
 34%|███▍      | 76/221 [00:29<01:06,  2.19it/s][A
 35%|███▍      | 77/221 [00:29<00:53,  2.69it/s][A
 35%|███▌      | 78/221 [00:30<00:48,  2.95it/s][A[h264 @ 0x55a31bb68180] mmco: unref short failure
[h264 @ 0x55a31bb68180] mmco: unref short failure

 36%|███▌      | 79/221 [00:30<01:06,  2.15it/s][A
 36%|███▌      | 80/221 [00:31<00:58,  2.40it/s][A
 37%|███▋      | 81/221 [00:31<00:57,  2.43it/s][A
 37%|███▋      | 82/221 [00:31<00:56,  2.45it/s][A
 38%|███▊      | 83/221 [00:32<00:45,  3.03it/s][A
 38%|███▊      | 84/221 [00:32<00:37,  3.66it/s][A[h264 @ 0x55b5c328e300] mmco: unref short failure

 38%|███▊      | 85/221 [00:32<00:31,  4.32it/s][A
 39%|███▉      | 86/221 [00:32<00:26,  5.11it/s][A
 39%|███▉      | 87/221 [00:32<00:34,  3.87it/s][A
 40%|███▉      | 88/221 [00:33<00:34,  3.87it/s][A
 40%|████      | 89/221 [00:36<02:52,  1.30s/it][A
 41%|████      | 90/221 [00:37<02:07,  1.02it/s][A
 42%|████▏     | 92/221 [00:37<01:14,  1.74it/s][A
 42%|████▏     | 93/221 [00:37<01:15,  1.69it/s][A
 43%|████▎     | 94/221 [00:38<01:07,  1.89it/s][A
 43%|████▎     | 95/221 [00:38<00:54,  2.32it/s][A
 43%|████▎     | 96/221 [00:38<00:48,  2.60it/s][A
 44%|████▍     | 97/221 [00:38<00:39,  3.14it/s][A
 44%|████▍     | 98/221 [00:39<00:33,  3.62it/s][A
 45%|████▍     | 99/221 [00:39<00:29,  4.16it/s][A
 45%|████▌     | 100/221 [00:39<00:27,  4.32it/s][A
 46%|████▌     | 101/221 [00:39<00:26,  4.46it/s][A
 46%|████▌     | 102/221 [00:39<00:27,  4.34it/s][A
 47%|████▋     | 103/221 [00:39<00:23,  5.01it/s][A
 47%|████▋     | 104/221 [00:40<00:24,  4.79it/s][A
 48%|████▊     | 105/221 [00:40<00:24,  4.78it/s][A[h264 @ 0x55a3104ba440] mmco: unref short failure
[h264 @ 0x55a3104ba440] mmco: unref short failure

 48%|████▊     | 106/221 [00:41<00:56,  2.05it/s][A
 48%|████▊     | 107/221 [00:41<00:43,  2.63it/s][A
 49%|████▉     | 108/221 [00:41<00:36,  3.06it/s][A
 49%|████▉     | 109/221 [00:42<00:36,  3.05it/s][A
 50%|████▉     | 110/221 [00:42<00:29,  3.75it/s][A
 50%|█████     | 111/221 [00:42<00:38,  2.89it/s][A
 51%|█████     | 112/221 [00:43<00:33,  3.24it/s][A
 51%|█████     | 113/221 [00:43<00:37,  2.89it/s][A
 52%|█████▏    | 114/221 [00:43<00:34,  3.10it/s][A
 52%|█████▏    | 115/221 [00:43<00:28,  3.70it/s][A[h264 @ 0x55a313f50a40] mmco: unref short failure
[h264 @ 0x55a313f50a40] mmco: unref short failure
[h264 @ 0x55a313f50a40] mmco: unref short failure
[h264 @ 0x55a313f50a40] mmco: unref short failure

 52%|█████▏    | 116/221 [00:48<02:56,  1.68s/it][A
 53%|█████▎    | 117/221 [00:49<02:12,  1.27s/it][A
 53%|█████▎    | 118/221 [00:49<01:51,  1.08s/it][A
 54%|█████▍    | 119/221 [00:50<01:22,  1.23it/s][A
 54%|█████▍    | 120/221 [00:50<01:04,  1.58it/s][A
 55%|█████▍    | 121/221 [00:50<00:48,  2.06it/s][A
 55%|█████▌    | 122/221 [00:50<00:40,  2.45it/s][A
 56%|█████▌    | 123/221 [00:50<00:32,  2.98it/s][A
 56%|█████▌    | 124/221 [00:51<00:30,  3.22it/s][A
 57%|█████▋    | 125/221 [00:51<00:26,  3.58it/s][A[h264 @ 0x55a31b1fb7c0] mmco: unref short failure
[h264 @ 0x55a31b1fb7c0] mmco: unref short failure

 57%|█████▋    | 126/221 [00:51<00:33,  2.85it/s][A
 57%|█████▋    | 127/221 [00:52<00:33,  2.83it/s][A
 58%|█████▊    | 128/221 [00:52<00:40,  2.31it/s][A
 58%|█████▊    | 129/221 [00:53<00:36,  2.55it/s][A
 59%|█████▉    | 130/221 [00:53<00:29,  3.05it/s][A
 59%|█████▉    | 131/221 [00:53<00:26,  3.46it/s][A
 60%|█████▉    | 132/221 [00:53<00:23,  3.81it/s][A
 60%|██████    | 133/221 [00:54<00:26,  3.34it/s][A
 61%|██████    | 134/221 [00:54<00:24,  3.51it/s][A
 61%|██████    | 135/221 [00:54<00:29,  2.93it/s][A
 62%|██████▏   | 136/221 [00:55<00:35,  2.40it/s][A
 62%|██████▏   | 137/221 [00:55<00:29,  2.81it/s][A
 62%|██████▏   | 138/221 [00:56<00:35,  2.32it/s][A
 63%|██████▎   | 139/221 [00:56<00:33,  2.48it/s][A
 63%|██████▎   | 140/221 [00:56<00:32,  2.49it/s][A
 64%|██████▍   | 141/221 [00:57<00:28,  2.78it/s][A
 64%|██████▍   | 142/221 [00:57<00:32,  2.45it/s][A
 65%|██████▍   | 143/221 [00:57<00:28,  2.72it/s][A
 65%|██████▌   | 144/221 [00:58<00:23,  3.34it/s][A
 66%|██████▌   | 145/221 [00:58<00:18,  4.02it/s][A
 67%|██████▋   | 147/221 [00:58<00:13,  5.64it/s][A
 67%|██████▋   | 148/221 [00:58<00:14,  4.96it/s][A
 68%|██████▊   | 150/221 [00:58<00:11,  6.19it/s][A
 68%|██████▊   | 151/221 [00:59<00:20,  3.47it/s][A
 69%|██████▉   | 152/221 [00:59<00:18,  3.66it/s][A
 69%|██████▉   | 153/221 [01:00<00:19,  3.50it/s][A
 70%|██████▉   | 154/221 [01:00<00:23,  2.83it/s][A
 70%|███████   | 155/221 [01:00<00:19,  3.45it/s][A
 71%|███████   | 156/221 [01:00<00:16,  4.02it/s][A
 71%|███████   | 157/221 [01:04<01:11,  1.11s/it][A
 71%|███████▏  | 158/221 [01:04<00:56,  1.11it/s][A
 72%|███████▏  | 159/221 [01:04<00:44,  1.39it/s][A
 72%|███████▏  | 160/221 [01:05<00:34,  1.76it/s][A
 73%|███████▎  | 161/221 [01:05<00:27,  2.19it/s][A
 73%|███████▎  | 162/221 [01:05<00:21,  2.77it/s][A
 74%|███████▍  | 163/221 [01:05<00:19,  2.99it/s][A
 74%|███████▍  | 164/221 [01:06<00:19,  2.86it/s][A
 75%|███████▍  | 165/221 [01:06<00:17,  3.25it/s][A
 75%|███████▌  | 166/221 [01:06<00:18,  2.95it/s][A
 76%|███████▌  | 167/221 [01:06<00:16,  3.19it/s][A[h264 @ 0x5607584fbf00] mmco: unref short failure

 76%|███████▌  | 168/221 [01:09<00:50,  1.05it/s][A
 76%|███████▋  | 169/221 [01:09<00:39,  1.31it/s][A
 77%|███████▋  | 170/221 [01:09<00:31,  1.61it/s][A
 77%|███████▋  | 171/221 [01:10<00:24,  2.03it/s][A
 78%|███████▊  | 172/221 [01:10<00:19,  2.47it/s][A
 78%|███████▊  | 173/221 [01:10<00:16,  2.83it/s][A
 79%|███████▊  | 174/221 [01:10<00:13,  3.44it/s][A[h264 @ 0x55e253febb40] mmco: unref short failure
[h264 @ 0x55e253febb40] mmco: unref short failure

 79%|███████▉  | 175/221 [01:11<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [01:11<00:12,  3.53it/s][A
 80%|████████  | 177/221 [01:11<00:10,  4.17it/s][A
 81%|████████  | 178/221 [01:11<00:10,  4.14it/s][A
 81%|████████  | 179/221 [01:13<00:24,  1.71it/s][A
 81%|████████▏ | 180/221 [01:13<00:18,  2.19it/s][A
 82%|████████▏ | 181/221 [01:13<00:15,  2.64it/s][A
 82%|████████▏ | 182/221 [01:13<00:12,  3.19it/s][A
 83%|████████▎ | 183/221 [01:13<00:10,  3.53it/s][A
 83%|████████▎ | 184/221 [01:14<00:12,  2.99it/s][A
 84%|████████▎ | 185/221 [01:14<00:10,  3.50it/s][A
 84%|████████▍ | 186/221 [01:14<00:10,  3.35it/s][A
 85%|████████▍ | 187/221 [01:14<00:08,  4.05it/s][A
 85%|████████▌ | 188/221 [01:15<00:07,  4.20it/s][A[h264 @ 0x55e23cb71580] mmco: unref short failure

 86%|████████▌ | 189/221 [01:15<00:08,  3.56it/s][A
 86%|████████▌ | 190/221 [01:15<00:08,  3.45it/s][A
 87%|████████▋ | 192/221 [01:16<00:07,  4.14it/s][A
 87%|████████▋ | 193/221 [01:16<00:06,  4.15it/s][A
 88%|████████▊ | 194/221 [01:17<00:12,  2.25it/s][A
 88%|████████▊ | 195/221 [01:17<00:09,  2.79it/s][A
 89%|████████▉ | 197/221 [01:17<00:05,  4.07it/s][A
 90%|████████▉ | 198/221 [01:17<00:05,  4.50it/s][A
 90%|█████████ | 199/221 [01:18<00:04,  4.48it/s][A
 90%|█████████ | 200/221 [01:18<00:04,  4.44it/s][A
 91%|█████████ | 201/221 [01:18<00:04,  4.59it/s][A
 91%|█████████▏| 202/221 [01:18<00:03,  4.96it/s][A
 92%|█████████▏| 203/221 [01:18<00:03,  4.82it/s][A
 93%|█████████▎| 205/221 [01:19<00:02,  6.71it/s][A
 93%|█████████▎| 206/221 [01:19<00:03,  3.83it/s][A
 94%|█████████▎| 207/221 [01:19<00:03,  4.48it/s][A
 94%|█████████▍| 208/221 [01:19<00:02,  5.13it/s][A
 95%|█████████▌| 210/221 [01:20<00:01,  7.34it/s][A
 96%|█████████▌| 212/221 [01:20<00:01,  5.01it/s][A
 97%|█████████▋| 214/221 [01:21<00:01,  3.52it/s][A
 97%|█████████▋| 215/221 [01:21<00:01,  3.68it/s][A
 98%|█████████▊| 216/221 [01:21<00:01,  4.03it/s][A
 98%|█████████▊| 217/221 [01:22<00:01,  2.36it/s][A
 99%|█████████▊| 218/221 [01:23<00:01,  2.37it/s][A
 99%|█████████▉| 219/221 [01:23<00:00,  2.69it/s][A
100%|█████████▉| 220/221 [01:28<00:01,  1.62s/it][A
100%|██████████| 221/221 [01:28<00:00,  1.20s/it][A100%|██████████| 221/221 [01:28<00:00,  2.50it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<01:06,  3.29it/s][A
  1%|          | 2/221 [00:00<01:07,  3.25it/s][A
  1%|▏         | 3/221 [00:00<01:08,  3.19it/s][A
  2%|▏         | 4/221 [00:01<01:07,  3.20it/s][A
  2%|▏         | 5/221 [00:01<01:07,  3.19it/s][A
  3%|▎         | 6/221 [00:01<01:06,  3.22it/s][A
  3%|▎         | 7/221 [00:02<01:05,  3.27it/s][A
  4%|▎         | 8/221 [00:02<01:04,  3.31it/s][A
  4%|▍         | 9/221 [00:02<01:03,  3.34it/s][A09/17/2024 07:33:50 - INFO - __main__ -   current idx TUTUj9BQYwU.13 from finetune_area returns wrong image/video, use 65466 instead.

  5%|▍         | 10/221 [00:03<01:02,  3.36it/s][A
  5%|▍         | 11/221 [00:03<01:02,  3.37it/s][A
  5%|▌         | 12/221 [00:03<01:01,  3.38it/s][A
  6%|▌         | 13/221 [00:03<01:02,  3.34it/s][A
  6%|▋         | 14/221 [00:04<01:01,  3.36it/s][A
  7%|▋         | 15/221 [00:04<01:01,  3.36it/s][A
  7%|▋         | 16/221 [00:04<01:00,  3.37it/s][A
  8%|▊         | 17/221 [00:05<01:00,  3.38it/s][A
  8%|▊         | 18/221 [00:05<00:59,  3.38it/s][A
  9%|▊         | 19/221 [00:05<00:59,  3.39it/s][A
  9%|▉         | 20/221 [00:06<00:59,  3.39it/s][A
 10%|▉         | 21/221 [00:06<00:58,  3.40it/s][A
 10%|▉         | 22/221 [00:06<00:58,  3.40it/s][A
 10%|█         | 23/221 [00:06<00:58,  3.40it/s][A
 11%|█         | 24/221 [00:07<00:58,  3.39it/s][A
 11%|█▏        | 25/221 [00:07<01:00,  3.25it/s][A
 12%|█▏        | 26/221 [00:07<00:59,  3.26it/s][A[h264 @ 0x55a312794e80] mmco: unref short failure

 12%|█▏        | 27/221 [00:08<00:58,  3.29it/s][A
 13%|█▎        | 28/221 [00:08<00:58,  3.32it/s][A
 13%|█▎        | 29/221 [00:08<00:57,  3.34it/s][A
 14%|█▎        | 30/221 [00:09<00:57,  3.33it/s][A
 14%|█▍        | 31/221 [00:09<00:56,  3.35it/s][A
 14%|█▍        | 32/221 [00:09<00:56,  3.32it/s][A
 15%|█▍        | 33/221 [00:09<00:56,  3.33it/s][A
 15%|█▌        | 34/221 [00:10<00:55,  3.35it/s][A
 16%|█▌        | 35/221 [00:10<00:55,  3.34it/s][A
 16%|█▋        | 36/221 [00:10<00:55,  3.35it/s][A
 17%|█▋        | 37/221 [00:11<00:54,  3.36it/s][A
 17%|█▋        | 38/221 [00:11<00:54,  3.37it/s][A
 18%|█▊        | 39/221 [00:11<00:54,  3.34it/s][A
 18%|█▊        | 40/221 [00:11<00:54,  3.35it/s][A
 19%|█▊        | 41/221 [00:12<00:53,  3.36it/s][A[h264 @ 0x55a31d3a5b40] mmco: unref short failure

 19%|█▉        | 42/221 [00:12<00:53,  3.37it/s][A
 19%|█▉        | 43/221 [00:12<00:52,  3.38it/s][A
 20%|█▉        | 44/221 [00:13<00:52,  3.39it/s][A
 20%|██        | 45/221 [00:13<00:52,  3.34it/s][A[h264 @ 0x55a312f81340] mmco: unref short failure
[h264 @ 0x55a312f81340] mmco: unref short failure

 21%|██        | 46/221 [00:13<00:52,  3.32it/s][A[h264 @ 0x55e255c10740] mmco: unref short failure
[h264 @ 0x55e255c10740] mmco: unref short failure

 21%|██▏       | 47/221 [00:14<00:52,  3.34it/s][A
 22%|██▏       | 48/221 [00:14<00:52,  3.32it/s][A
 22%|██▏       | 49/221 [00:14<00:51,  3.34it/s][A
 23%|██▎       | 50/221 [00:14<00:50,  3.36it/s][A
 23%|██▎       | 51/221 [00:15<00:50,  3.37it/s][A
 24%|██▎       | 52/221 [00:15<00:49,  3.38it/s][A
 24%|██▍       | 53/221 [00:15<00:49,  3.37it/s][A
 24%|██▍       | 54/221 [00:16<00:49,  3.37it/s][A
 25%|██▍       | 55/221 [00:16<00:49,  3.33it/s][A
 25%|██▌       | 56/221 [00:16<00:49,  3.31it/s][A
 26%|██▌       | 57/221 [00:17<00:49,  3.34it/s][A
 26%|██▌       | 58/221 [00:17<00:49,  3.32it/s][A
 27%|██▋       | 59/221 [00:17<00:49,  3.30it/s][A
 27%|██▋       | 60/221 [00:17<00:48,  3.32it/s][A
 28%|██▊       | 61/221 [00:18<00:47,  3.34it/s][A
 28%|██▊       | 62/221 [00:18<00:47,  3.35it/s][A
 29%|██▊       | 63/221 [00:18<00:47,  3.35it/s][A
 29%|██▉       | 64/221 [00:19<00:46,  3.37it/s][A
 29%|██▉       | 65/221 [00:19<00:46,  3.33it/s][A
 30%|██▉       | 66/221 [00:19<00:46,  3.31it/s][A
 30%|███       | 67/221 [00:20<00:46,  3.28it/s][A
 31%|███       | 68/221 [00:20<00:47,  3.24it/s][A
 31%|███       | 69/221 [00:20<00:46,  3.29it/s][A
 32%|███▏      | 70/221 [00:21<00:46,  3.28it/s][A
 32%|███▏      | 71/221 [00:21<00:45,  3.31it/s][A
 33%|███▎      | 72/221 [00:21<00:45,  3.31it/s][A
 33%|███▎      | 73/221 [00:21<00:45,  3.26it/s][A
 33%|███▎      | 74/221 [00:22<00:44,  3.27it/s][A
 34%|███▍      | 75/221 [00:22<00:44,  3.31it/s][A
 34%|███▍      | 76/221 [00:22<00:43,  3.33it/s][A
 35%|███▍      | 77/221 [00:23<00:43,  3.30it/s][A
 35%|███▌      | 78/221 [00:23<00:45,  3.14it/s][A
 36%|███▌      | 79/221 [00:23<00:44,  3.21it/s][A
 36%|███▌      | 80/221 [00:24<00:43,  3.25it/s][A
 37%|███▋      | 81/221 [00:24<00:42,  3.26it/s][A
 37%|███▋      | 82/221 [00:24<00:42,  3.29it/s][A
 38%|███▊      | 83/221 [00:24<00:42,  3.26it/s][A
 38%|███▊      | 84/221 [00:25<00:41,  3.30it/s][A
 38%|███▊      | 85/221 [00:25<00:40,  3.33it/s][A
 39%|███▉      | 86/221 [00:25<00:40,  3.35it/s][A
 39%|███▉      | 87/221 [00:26<00:39,  3.37it/s][A
 40%|███▉      | 88/221 [00:26<00:39,  3.38it/s][A
 40%|████      | 89/221 [00:26<00:38,  3.39it/s][A
 41%|████      | 90/221 [00:27<00:38,  3.38it/s][A
 41%|████      | 91/221 [00:27<00:38,  3.39it/s][A
 42%|████▏     | 92/221 [00:27<00:38,  3.39it/s][A
 42%|████▏     | 93/221 [00:27<00:38,  3.35it/s][A
 43%|████▎     | 94/221 [00:28<00:37,  3.37it/s][A
 43%|████▎     | 95/221 [00:28<00:37,  3.37it/s][A
 43%|████▎     | 96/221 [00:28<00:37,  3.37it/s][A
 44%|████▍     | 97/221 [00:29<00:36,  3.38it/s][A
 44%|████▍     | 98/221 [00:29<00:36,  3.39it/s][A
 45%|████▍     | 99/221 [00:29<00:35,  3.39it/s][A
 45%|████▌     | 100/221 [00:29<00:35,  3.40it/s][A
 46%|████▌     | 101/221 [00:30<00:35,  3.40it/s][A
 46%|████▌     | 102/221 [00:30<00:34,  3.41it/s][A
 47%|████▋     | 103/221 [00:30<00:34,  3.41it/s][A
 47%|████▋     | 104/221 [00:31<00:34,  3.42it/s][A
 48%|████▊     | 105/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 106/221 [00:31<00:33,  3.42it/s][A
 48%|████▊     | 107/221 [00:32<00:33,  3.41it/s][A
 49%|████▉     | 108/221 [00:32<00:33,  3.41it/s][A
 49%|████▉     | 109/221 [00:32<00:32,  3.42it/s][A
 50%|████▉     | 110/221 [00:32<00:32,  3.42it/s][A
 50%|█████     | 111/221 [00:33<00:32,  3.42it/s][A
 51%|█████     | 112/221 [00:33<00:31,  3.42it/s][A
 51%|█████     | 113/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 114/221 [00:34<00:31,  3.42it/s][A
 52%|█████▏    | 115/221 [00:34<00:30,  3.42it/s][A
 52%|█████▏    | 116/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 117/221 [00:34<00:30,  3.42it/s][A
 53%|█████▎    | 118/221 [00:35<00:30,  3.42it/s][A
 54%|█████▍    | 119/221 [00:35<00:29,  3.42it/s][A
 54%|█████▍    | 120/221 [00:35<00:29,  3.42it/s][A
 55%|█████▍    | 121/221 [00:36<00:29,  3.42it/s][A
 55%|█████▌    | 122/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 123/221 [00:36<00:28,  3.42it/s][A
 56%|█████▌    | 124/221 [00:37<00:28,  3.42it/s][A
 57%|█████▋    | 125/221 [00:37<00:28,  3.42it/s][A
 57%|█████▋    | 126/221 [00:37<00:27,  3.42it/s][A
 57%|█████▋    | 127/221 [00:37<00:27,  3.42it/s][A
 58%|█████▊    | 128/221 [00:38<00:27,  3.42it/s][A
 58%|█████▊    | 129/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 130/221 [00:38<00:26,  3.42it/s][A
 59%|█████▉    | 131/221 [00:39<00:26,  3.42it/s][A
 60%|█████▉    | 132/221 [00:39<00:26,  3.42it/s][A
 60%|██████    | 133/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 134/221 [00:39<00:25,  3.42it/s][A
 61%|██████    | 135/221 [00:40<00:25,  3.42it/s][A
 62%|██████▏   | 136/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 137/221 [00:40<00:24,  3.42it/s][A
 62%|██████▏   | 138/221 [00:41<00:24,  3.42it/s][A
 63%|██████▎   | 139/221 [00:41<00:23,  3.42it/s][A
 63%|██████▎   | 140/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 141/221 [00:41<00:23,  3.42it/s][A
 64%|██████▍   | 142/221 [00:42<00:23,  3.42it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.42it/s][A
 65%|██████▌   | 144/221 [00:42<00:22,  3.42it/s][A
 66%|██████▌   | 145/221 [00:43<00:22,  3.42it/s][A
 66%|██████▌   | 146/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 147/221 [00:43<00:21,  3.42it/s][A
 67%|██████▋   | 148/221 [00:44<00:21,  3.42it/s][A
 67%|██████▋   | 149/221 [00:44<00:21,  3.42it/s][A
 68%|██████▊   | 150/221 [00:44<00:20,  3.42it/s][A
 68%|██████▊   | 151/221 [00:44<00:20,  3.42it/s][A
 69%|██████▉   | 152/221 [00:45<00:20,  3.42it/s][A
 69%|██████▉   | 153/221 [00:45<00:19,  3.42it/s][A
 70%|██████▉   | 154/221 [00:45<00:19,  3.42it/s][A
 70%|███████   | 155/221 [00:46<00:19,  3.42it/s][A
 71%|███████   | 156/221 [00:46<00:18,  3.42it/s][A
 71%|███████   | 157/221 [00:46<00:18,  3.42it/s][A
 71%|███████▏  | 158/221 [00:46<00:18,  3.42it/s][A
 72%|███████▏  | 159/221 [00:47<00:18,  3.42it/s][A
 72%|███████▏  | 160/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 161/221 [00:47<00:17,  3.42it/s][A
 73%|███████▎  | 162/221 [00:48<00:17,  3.42it/s][A
 74%|███████▍  | 163/221 [00:48<00:16,  3.42it/s][A
 74%|███████▍  | 164/221 [00:48<00:16,  3.42it/s][A
 75%|███████▍  | 165/221 [00:48<00:16,  3.42it/s][A
 75%|███████▌  | 166/221 [00:49<00:16,  3.42it/s][A
 76%|███████▌  | 167/221 [00:49<00:15,  3.42it/s][A
 76%|███████▌  | 168/221 [00:49<00:15,  3.42it/s][A
 76%|███████▋  | 169/221 [00:50<00:15,  3.42it/s][A
 77%|███████▋  | 170/221 [00:50<00:14,  3.42it/s][A
 77%|███████▋  | 171/221 [00:50<00:14,  3.42it/s][A
 78%|███████▊  | 172/221 [00:51<00:14,  3.42it/s][A
 78%|███████▊  | 173/221 [00:51<00:14,  3.42it/s][A
 79%|███████▊  | 174/221 [00:51<00:13,  3.42it/s][A
 79%|███████▉  | 175/221 [00:51<00:13,  3.42it/s][A
 80%|███████▉  | 176/221 [00:52<00:13,  3.42it/s][A
 80%|████████  | 177/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 178/221 [00:52<00:12,  3.42it/s][A
 81%|████████  | 179/221 [00:53<00:12,  3.42it/s][A
 81%|████████▏ | 180/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 181/221 [00:53<00:11,  3.42it/s][A
 82%|████████▏ | 182/221 [00:53<00:11,  3.42it/s][A
 83%|████████▎ | 183/221 [00:54<00:11,  3.42it/s][A
 83%|████████▎ | 184/221 [00:54<00:10,  3.42it/s][A
 84%|████████▎ | 185/221 [00:54<00:10,  3.42it/s][A
 84%|████████▍ | 186/221 [00:55<00:10,  3.42it/s][A
 85%|████████▍ | 187/221 [00:55<00:09,  3.42it/s][A
 85%|████████▌ | 188/221 [00:55<00:09,  3.42it/s][A
 86%|████████▌ | 189/221 [00:56<00:09,  3.42it/s][A
 86%|████████▌ | 190/221 [00:56<00:09,  3.42it/s][A
 86%|████████▋ | 191/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 192/221 [00:56<00:08,  3.42it/s][A
 87%|████████▋ | 193/221 [00:57<00:08,  3.42it/s][A
 88%|████████▊ | 194/221 [00:57<00:07,  3.42it/s][A
 88%|████████▊ | 195/221 [00:57<00:07,  3.42it/s][A
 89%|████████▊ | 196/221 [00:58<00:07,  3.42it/s][A
 89%|████████▉ | 197/221 [00:58<00:07,  3.42it/s][A
 90%|████████▉ | 198/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 199/221 [00:58<00:06,  3.42it/s][A
 90%|█████████ | 200/221 [00:59<00:06,  3.42it/s][A
 91%|█████████ | 201/221 [00:59<00:05,  3.42it/s][A
 91%|█████████▏| 202/221 [00:59<00:05,  3.42it/s][A
 92%|█████████▏| 203/221 [01:00<00:05,  3.42it/s][A
 92%|█████████▏| 204/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 205/221 [01:00<00:04,  3.42it/s][A
 93%|█████████▎| 206/221 [01:00<00:04,  3.42it/s][A
 94%|█████████▎| 207/221 [01:01<00:04,  3.42it/s][A
 94%|█████████▍| 208/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▍| 209/221 [01:01<00:03,  3.42it/s][A
 95%|█████████▌| 210/221 [01:02<00:03,  3.42it/s][A
 95%|█████████▌| 211/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▌| 212/221 [01:02<00:02,  3.42it/s][A
 96%|█████████▋| 213/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 214/221 [01:03<00:02,  3.42it/s][A
 97%|█████████▋| 215/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 216/221 [01:03<00:01,  3.42it/s][A
 98%|█████████▊| 217/221 [01:04<00:01,  3.42it/s][A
 99%|█████████▊| 218/221 [01:04<00:00,  3.42it/s][A
 99%|█████████▉| 219/221 [01:04<00:00,  3.42it/s][A
100%|█████████▉| 220/221 [01:05<00:00,  3.42it/s][A
100%|██████████| 221/221 [01:05<00:00,  3.42it/s][A100%|██████████| 221/221 [01:05<00:00,  3.38it/s]

  0%|          | 0/221 [00:00<?, ?it/s][A
  0%|          | 1/221 [00:00<00:35,  6.12it/s][A
  1%|          | 2/221 [00:00<00:41,  5.34it/s][A
  1%|▏         | 3/221 [00:00<00:58,  3.74it/s][A
  2%|▏         | 4/221 [00:01<00:59,  3.66it/s][A
  2%|▏         | 5/221 [00:01<00:54,  3.94it/s][A
  3%|▎         | 7/221 [00:01<00:47,  4.48it/s][A
  4%|▎         | 8/221 [00:01<00:54,  3.88it/s][A
  4%|▍         | 9/221 [00:02<00:56,  3.77it/s][A
  5%|▍         | 10/221 [00:02<00:54,  3.88it/s][A
  5%|▍         | 11/221 [00:02<00:51,  4.06it/s][A
  5%|▌         | 12/221 [00:02<00:48,  4.35it/s][A
  6%|▌         | 13/221 [00:03<01:17,  2.69it/s][A
  6%|▋         | 14/221 [00:03<01:11,  2.90it/s][A
  7%|▋         | 15/221 [00:04<01:14,  2.76it/s][A
  7%|▋         | 16/221 [00:04<01:23,  2.46it/s][A
  8%|▊         | 17/221 [00:05<01:22,  2.49it/s][A
  8%|▊         | 18/221 [00:05<01:12,  2.81it/s][A
  9%|▉         | 20/221 [00:05<00:52,  3.86it/s][A
 10%|▉         | 21/221 [00:05<00:47,  4.25it/s][A
 10%|▉         | 22/221 [00:06<00:44,  4.51it/s][A
 10%|█         | 23/221 [00:06<00:41,  4.79it/s][A
 11%|█         | 24/221 [00:06<00:37,  5.25it/s][A
 11%|█▏        | 25/221 [00:06<00:44,  4.36it/s][A
 12%|█▏        | 26/221 [00:06<00:44,  4.36it/s][A
 12%|█▏        | 27/221 [00:07<00:41,  4.66it/s][A
 13%|█▎        | 28/221 [00:07<00:43,  4.45it/s][A
 13%|█▎        | 29/221 [00:07<00:45,  4.26it/s][A
 14%|█▎        | 30/221 [00:08<01:07,  2.83it/s][A
 14%|█▍        | 31/221 [00:08<01:07,  2.83it/s][A
 14%|█▍        | 32/221 [00:08<00:59,  3.15it/s][A
 15%|█▍        | 33/221 [00:09<01:00,  3.09it/s][A
 15%|█▌        | 34/221 [00:09<01:03,  2.93it/s][A
 16%|█▌        | 35/221 [00:09<00:54,  3.43it/s][A
 16%|█▋        | 36/221 [00:10<00:55,  3.36it/s][A
 17%|█▋        | 37/221 [00:10<00:48,  3.77it/s][A
 17%|█▋        | 38/221 [00:10<00:48,  3.74it/s][A
 18%|█▊        | 39/221 [00:10<00:45,  4.02it/s][A
 18%|█▊        | 40/221 [00:10<00:43,  4.12it/s][A
 19%|█▊        | 41/221 [00:11<00:50,  3.59it/s][A
 19%|█▉        | 42/221 [00:11<00:41,  4.33it/s][A
 19%|█▉        | 43/221 [00:11<00:40,  4.37it/s][A
 20%|█▉        | 44/221 [00:11<00:43,  4.04it/s][A
 20%|██        | 45/221 [00:12<00:56,  3.13it/s][A
 21%|██        | 46/221 [00:12<00:58,  3.00it/s][A
 21%|██▏       | 47/221 [00:13<00:54,  3.20it/s][A
 22%|██▏       | 48/221 [00:13<00:44,  3.86it/s][A
 22%|██▏       | 49/221 [00:13<00:36,  4.69it/s][A
 23%|██▎       | 50/221 [00:13<00:43,  3.97it/s][A
 23%|██▎       | 51/221 [00:13<00:44,  3.82it/s][A
 24%|██▎       | 52/221 [00:14<00:42,  3.95it/s][A
 24%|██▍       | 53/221 [00:14<01:01,  2.72it/s][A
 24%|██▍       | 54/221 [00:14<00:51,  3.23it/s][A
 25%|██▍       | 55/221 [00:15<00:57,  2.88it/s][A
 25%|██▌       | 56/221 [00:15<00:59,  2.77it/s][A
 26%|██▌       | 57/221 [00:16<00:54,  2.99it/s][A
 26%|██▌       | 58/221 [00:16<00:52,  3.13it/s][A
 27%|██▋       | 59/221 [00:16<00:48,  3.32it/s][A
 27%|██▋       | 60/221 [00:16<00:45,  3.56it/s][A
 28%|██▊       | 61/221 [00:17<00:41,  3.81it/s][A
 28%|██▊       | 62/221 [00:17<00:42,  3.75it/s][A
 29%|██▊       | 63/221 [00:17<00:34,  4.54it/s][A
 29%|██▉       | 64/221 [00:17<00:35,  4.37it/s][A
 29%|██▉       | 65/221 [00:17<00:35,  4.36it/s][A
 30%|██▉       | 66/221 [00:18<00:35,  4.31it/s][A
 30%|███       | 67/221 [00:18<00:35,  4.32it/s][A
 31%|███       | 68/221 [00:18<00:37,  4.08it/s][A
 31%|███       | 69/221 [00:19<00:56,  2.70it/s][A
 32%|███▏      | 70/221 [00:19<00:54,  2.79it/s][A
 32%|███▏      | 71/221 [00:20<00:51,  2.89it/s][A
 33%|███▎      | 72/221 [00:20<00:50,  2.95it/s][A
 33%|███▎      | 73/221 [00:20<00:51,  2.86it/s][A
 33%|███▎      | 74/221 [00:21<00:49,  2.97it/s][A
 34%|███▍      | 75/221 [00:21<00:44,  3.25it/s][A
 34%|███▍      | 76/221 [00:21<00:38,  3.74it/s][A
 35%|███▍      | 77/221 [00:21<00:36,  3.90it/s][A
 35%|███▌      | 78/221 [00:22<00:40,  3.53it/s][A
 36%|███▌      | 79/221 [00:22<00:42,  3.37it/s][A
 36%|███▌      | 80/221 [00:22<00:37,  3.76it/s][A
 37%|███▋      | 81/221 [00:22<00:37,  3.69it/s][A
 37%|███▋      | 82/221 [00:23<00:39,  3.49it/s][A
 38%|███▊      | 83/221 [00:23<00:33,  4.11it/s][A
 38%|███▊      | 84/221 [00:23<00:51,  2.65it/s][A
 38%|███▊      | 85/221 [00:24<00:41,  3.26it/s][A
 39%|███▉      | 86/221 [00:24<00:44,  3.06it/s][A
 39%|███▉      | 87/221 [00:24<00:45,  2.91it/s][A
 40%|███▉      | 88/221 [00:25<00:43,  3.07it/s][A
 40%|████      | 89/221 [00:25<00:45,  2.89it/s][A
 41%|████      | 90/221 [00:25<00:47,  2.76it/s][A
 41%|████      | 91/221 [00:26<00:42,  3.04it/s][A
 42%|████▏     | 92/221 [00:26<00:45,  2.87it/s][A
 42%|████▏     | 93/221 [00:27<00:53,  2.39it/s][A
 43%|████▎     | 94/221 [00:27<00:47,  2.69it/s][A
 43%|████▎     | 95/221 [00:28<00:55,  2.25it/s][A
 43%|████▎     | 96/221 [00:28<00:58,  2.15it/s][A
 44%|████▍     | 97/221 [00:28<00:50,  2.48it/s][A
 44%|████▍     | 98/221 [00:29<00:46,  2.66it/s][A
 45%|████▍     | 99/221 [00:29<00:41,  2.92it/s][A
 45%|████▌     | 100/221 [00:29<00:34,  3.47it/s][A
 46%|████▌     | 101/221 [00:29<00:32,  3.66it/s][A
 46%|████▌     | 102/221 [00:30<00:32,  3.61it/s][A
 47%|████▋     | 103/221 [00:30<00:30,  3.85it/s][A
 47%|████▋     | 104/221 [00:30<00:25,  4.65it/s][A
 48%|████▊     | 105/221 [00:30<00:33,  3.50it/s][A
 48%|████▊     | 106/221 [00:31<00:39,  2.93it/s][A
 48%|████▊     | 107/221 [00:31<00:36,  3.08it/s][A
 49%|████▉     | 108/221 [00:31<00:33,  3.35it/s][A
 49%|████▉     | 109/221 [00:32<00:29,  3.76it/s][A
 50%|████▉     | 110/221 [00:32<00:28,  3.88it/s][A
 50%|█████     | 111/221 [00:32<00:32,  3.42it/s][A
 51%|█████     | 112/221 [00:33<00:36,  3.02it/s][A
 51%|█████     | 113/221 [00:33<00:38,  2.78it/s][A
 52%|█████▏    | 114/221 [00:33<00:32,  3.25it/s][A
 52%|█████▏    | 115/221 [00:33<00:31,  3.42it/s][A
 52%|█████▏    | 116/221 [00:34<00:27,  3.78it/s][A
 53%|█████▎    | 117/221 [00:34<00:27,  3.85it/s][A
 53%|█████▎    | 118/221 [00:34<00:32,  3.20it/s][A
 54%|█████▍    | 119/221 [00:35<00:36,  2.80it/s][A
 54%|█████▍    | 120/221 [00:35<00:40,  2.48it/s][A
 55%|█████▍    | 121/221 [00:36<00:42,  2.36it/s][A
 55%|█████▌    | 122/221 [00:36<00:38,  2.57it/s][A
 56%|█████▌    | 123/221 [00:36<00:38,  2.56it/s][A
 56%|█████▌    | 124/221 [00:37<00:34,  2.79it/s][A
 57%|█████▋    | 125/221 [00:37<00:37,  2.55it/s][A
 57%|█████▋    | 126/221 [00:37<00:32,  2.97it/s][A
 57%|█████▋    | 127/221 [00:38<00:36,  2.56it/s][A
 58%|█████▊    | 128/221 [00:38<00:32,  2.86it/s][A
 58%|█████▊    | 129/221 [00:38<00:26,  3.48it/s][A
 59%|█████▉    | 130/221 [00:39<00:24,  3.67it/s][A
 59%|█████▉    | 131/221 [00:39<00:22,  4.04it/s][A
 60%|█████▉    | 132/221 [00:39<00:22,  4.01it/s][A
 60%|██████    | 133/221 [00:40<00:28,  3.12it/s][A
 61%|██████    | 134/221 [00:40<00:29,  2.93it/s][A
 61%|██████    | 135/221 [00:40<00:27,  3.16it/s][A
 62%|██████▏   | 136/221 [00:40<00:25,  3.28it/s][A
 62%|██████▏   | 137/221 [00:41<00:22,  3.74it/s][A
 62%|██████▏   | 138/221 [00:41<00:20,  4.05it/s][A
 63%|██████▎   | 139/221 [00:41<00:26,  3.11it/s][A
 63%|██████▎   | 140/221 [00:42<00:24,  3.34it/s][A
 64%|██████▍   | 141/221 [00:42<00:27,  2.89it/s][A
 64%|██████▍   | 142/221 [00:42<00:24,  3.21it/s][A
 65%|██████▍   | 143/221 [00:42<00:22,  3.52it/s][A
 65%|██████▌   | 144/221 [00:43<00:21,  3.55it/s][A
 66%|██████▌   | 145/221 [00:43<00:27,  2.74it/s][A
 66%|██████▌   | 146/221 [00:44<00:24,  3.03it/s][A
 67%|██████▋   | 147/221 [00:44<00:22,  3.27it/s][A
 67%|██████▋   | 148/221 [00:44<00:25,  2.90it/s][A
 68%|██████▊   | 150/221 [00:45<00:18,  3.87it/s][A
 68%|██████▊   | 151/221 [00:45<00:20,  3.46it/s][A
 69%|██████▉   | 152/221 [00:46<00:25,  2.70it/s][A
 69%|██████▉   | 153/221 [00:46<00:25,  2.68it/s][A
 70%|██████▉   | 154/221 [00:46<00:25,  2.66it/s][A
 70%|███████   | 155/221 [00:47<00:22,  2.91it/s][A
 71%|███████   | 156/221 [00:47<00:19,  3.28it/s][A
 71%|███████   | 157/221 [00:47<00:18,  3.47it/s][A
 71%|███████▏  | 158/221 [00:47<00:21,  2.94it/s][A
 72%|███████▏  | 159/221 [00:48<00:18,  3.27it/s][A
 72%|███████▏  | 160/221 [00:48<00:17,  3.57it/s][A
 73%|███████▎  | 161/221 [00:48<00:15,  3.95it/s][A
 74%|███████▍  | 163/221 [00:49<00:13,  4.43it/s][A
 74%|███████▍  | 164/221 [00:49<00:12,  4.41it/s][A
 75%|███████▍  | 165/221 [00:49<00:15,  3.61it/s][A
 75%|███████▌  | 166/221 [00:50<00:17,  3.18it/s][A
 76%|███████▌  | 168/221 [00:50<00:13,  3.92it/s][A
 77%|███████▋  | 170/221 [00:50<00:13,  3.79it/s][A
 77%|███████▋  | 171/221 [00:51<00:13,  3.57it/s][A
 78%|███████▊  | 172/221 [00:51<00:13,  3.54it/s][A
 78%|███████▊  | 173/221 [00:51<00:13,  3.67it/s][A
 79%|███████▊  | 174/221 [00:52<00:13,  3.36it/s][A
 79%|███████▉  | 175/221 [00:52<00:13,  3.50it/s][A
 80%|███████▉  | 176/221 [00:52<00:11,  3.87it/s][A
 80%|████████  | 177/221 [00:52<00:11,  3.89it/s][A
 81%|████████  | 178/221 [00:53<00:16,  2.67it/s][A
 81%|████████  | 179/221 [00:53<00:13,  3.02it/s][A
 81%|████████▏ | 180/221 [00:54<00:12,  3.32it/s][A
 82%|████████▏ | 181/221 [00:54<00:15,  2.53it/s][A
 82%|████████▏ | 182/221 [00:54<00:13,  2.82it/s][A
 83%|████████▎ | 183/221 [00:55<00:13,  2.89it/s][A
 83%|████████▎ | 184/221 [00:55<00:12,  2.96it/s][A
 84%|████████▎ | 185/221 [00:55<00:10,  3.48it/s][A
 84%|████████▍ | 186/221 [00:56<00:10,  3.26it/s][A
 85%|████████▍ | 187/221 [00:56<00:09,  3.60it/s][A
 85%|████████▌ | 188/221 [00:56<00:08,  3.89it/s][A
 86%|████████▌ | 189/221 [00:56<00:07,  4.05it/s][A
 86%|████████▌ | 190/221 [00:57<00:08,  3.59it/s][A
 86%|████████▋ | 191/221 [00:57<00:07,  3.79it/s][A
 87%|████████▋ | 192/221 [00:57<00:07,  3.93it/s][A
 87%|████████▋ | 193/221 [00:57<00:08,  3.34it/s][A
 88%|████████▊ | 194/221 [00:58<00:08,  3.12it/s][A
 88%|████████▊ | 195/221 [00:58<00:06,  3.80it/s][A
 89%|████████▊ | 196/221 [00:58<00:07,  3.28it/s][A
 89%|████████▉ | 197/221 [00:59<00:07,  3.17it/s][A
 90%|████████▉ | 198/221 [00:59<00:07,  3.26it/s][A
 90%|█████████ | 199/221 [00:59<00:05,  3.79it/s][A
 90%|█████████ | 200/221 [00:59<00:05,  3.97it/s][A
 91%|█████████ | 201/221 [01:00<00:04,  4.52it/s][A
 91%|█████████▏| 202/221 [01:00<00:04,  4.13it/s][A
 92%|█████████▏| 203/221 [01:00<00:04,  4.03it/s][A
 92%|█████████▏| 204/221 [01:00<00:05,  3.35it/s][A
 93%|█████████▎| 205/221 [01:01<00:04,  3.76it/s][A
 93%|█████████▎| 206/221 [01:01<00:05,  2.96it/s][A
 94%|█████████▎| 207/221 [01:02<00:05,  2.58it/s][A
 94%|█████████▍| 208/221 [01:02<00:04,  2.86it/s][A
 95%|█████████▍| 209/221 [01:02<00:03,  3.35it/s][A
 95%|█████████▌| 210/221 [01:03<00:03,  2.81it/s][A
 95%|█████████▌| 211/221 [01:03<00:03,  3.06it/s][A
 96%|█████████▌| 212/221 [01:03<00:02,  3.25it/s][A
 96%|█████████▋| 213/221 [01:03<00:02,  3.48it/s][A
 97%|█████████▋| 214/221 [01:04<00:02,  3.21it/s][A
 97%|█████████▋| 215/221 [01:04<00:02,  2.82it/s][A
 98%|█████████▊| 216/221 [01:04<00:01,  2.98it/s][A
 98%|█████████▊| 217/221 [01:05<00:01,  3.21it/s][A
 99%|█████████▊| 218/221 [01:05<00:00,  3.38it/s][A
 99%|█████████▉| 219/221 [01:05<00:00,  2.87it/s][A
100%|█████████▉| 220/221 [01:06<00:00,  3.28it/s][A
100%|██████████| 221/221 [01:06<00:00,  3.68it/s][A100%|██████████| 221/221 [01:06<00:00,  3.33it/s]
09/17/2024 07:36:00 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_forward=====step 1299--===========

09/17/2024 07:36:00 - INFO - __main__ -   {'area_r1': 37.3, 'area_recall': '37.3/62.3/71.5', 'area_ravg': 57.1}
09/17/2024 07:36:00 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_backard=====step 1299--===========

09/17/2024 07:36:00 - INFO - __main__ -   {'forward_r1': 37.4, 'forward_recall': '37.4/66.5/75.8', 'forward_ravg': 59.9}
09/17/2024 07:36:00 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video=====step 1299--===========

09/17/2024 07:36:00 - INFO - __main__ -   {'area_video_r1': 38.6, 'area_video_recall': '38.6/66.2/76.9', 'area_video_ravg': 60.6}
09/17/2024 07:36:00 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_area_back_with_video====history best step: 299=======

09/17/2024 07:36:00 - INFO - __main__ -   {'area_video_r1': 40.6, 'area_video_recall': '40.6/67.5/78.1', 'area_video_ravg': 62.1}
09/17/2024 07:36:00 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_area=====step 1299--===========

09/17/2024 07:36:00 - INFO - __main__ -   {'area_video_r1': 52.4, 'area_video_recall': '52.4/74.7/81.3', 'area_video_ravg': 69.5, 'area_video_back_r1': 47.5, 'area_video_back_recall': '47.5/74.4/82.1', 'area_video_back_ravg': 68.0}
09/17/2024 07:36:00 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_area====history best step: 549=======

09/17/2024 07:36:00 - INFO - __main__ -   {'area_video_r1': 54.1, 'area_video_recall': '54.1/75.5/82.4', 'area_video_ravg': 70.6, 'area_video_back_r1': 49.4, 'area_video_back_recall': '49.4/74.5/82.1', 'area_video_back_ravg': 68.7}
09/17/2024 07:36:00 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itc_tva=====step 1299--===========

09/17/2024 07:36:00 - INFO - __main__ -   {'video_r1': 37.1, 'video_recall': '37.1/63.6/73.6', 'video_ravg': 58.1}
09/17/2024 07:36:00 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itc_tva====history best step: 949=======

09/17/2024 07:36:00 - INFO - __main__ -   {'video_r1': 38.7, 'video_recall': '38.7/64.3/74.1', 'video_ravg': 59.0}
09/17/2024 07:36:00 - INFO - __main__ -   ====-evaluation--ret%tva--msrvtt_ret_ret_itm_tva=====step 1299--===========

09/17/2024 07:36:00 - INFO - __main__ -   {'video_r1': 52.5, 'video_recall': '52.5/74.0/81.8', 'video_ravg': 69.4}
09/17/2024 07:36:00 - INFO - __main__ -   ======evaluation--ret%tva--msrvtt_ret_ret_itm_tva====history best step: 549=======

09/17/2024 07:36:00 - INFO - __main__ -   {'video_r1': 54.5, 'video_recall': '54.5/76.1/83.4', 'video_ravg': 71.3}
09/17/2024 07:36:20 - INFO - __main__ -   {'loss_ret%tv%ta--finetune_area/loss_itc': 0.0, 'loss_ret%tv%ta--finetune_area/loss_itm': 0.005283308681100607, 'loss_ret%tv%ta--finetune_area/loss_area': 1.0349910259246826, 'loss_ret%tv%ta--finetune_area/total_loss': 1.0402743816375732}
[h264 @ 0x55b5aa03ef40] mmco: unref short failure
 45%|████▍     | 1300/2910 [8:14:36<57:42:23, 129.03s/it][h264 @ 0x55b5c23f8e40] mmco: unref short failure
[h264 @ 0x560762a63f80] mmco: unref short failure
 45%|████▍     | 1301/2910 [8:14:40<40:49:54, 91.36s/it]  45%|████▍     | 1302/2910 [8:14:44<29:05:17, 65.12s/it] 45%|████▍     | 1303/2910 [8:14:48<20:55:26, 46.87s/it][h264 @ 0x560741c4de40] mmco: unref short failure
[h264 @ 0x560741c4de40] mmco: unref short failure
09/17/2024 07:36:39 - INFO - __main__ -   current idx TTR3lV4sfVY.61 from finetune_area returns wrong image/video, use 44447 instead.
 45%|████▍     | 1304/2910 [8:14:53<15:19:23, 34.35s/it][h264 @ 0x55e2382ac340] mmco: unref short failure
[h264 @ 0x55e2382ac340] mmco: unref short failure
 45%|████▍     | 1305/2910 [8:14:58<11:18:09, 25.35s/it] 45%|████▍     | 1306/2910 [8:15:03<8:35:14, 19.27s/it]  45%|████▍     | 1307/2910 [8:15:09<6:49:11, 15.32s/it][h264 @ 0x5607511d2a00] mmco: unref short failure
 45%|████▍     | 1308/2910 [8:15:15<5:33:56, 12.51s/it][h264 @ 0x55b5b31f5800] mmco: unref short failure
 45%|████▍     | 1309/2910 [8:15:21<4:41:16, 10.54s/it] 45%|████▌     | 1310/2910 [8:15:26<3:58:24,  8.94s/it][h264 @ 0x55a31fa9af00] mmco: unref short failure
[h264 @ 0x55e2410da7c0] mmco: unref short failure
[h264 @ 0x55e2410da7c0] mmco: unref short failure
[h264 @ 0x55b5bff5f740] mmco: unref short failure
[h264 @ 0x5607477dadc0] mmco: unref short failure
[h264 @ 0x5607477dadc0] mmco: unref short failure
 45%|████▌     | 1311/2910 [8:15:32<3:35:24,  8.08s/it][h264 @ 0x55b5bae53680] mmco: unref short failure
[h264 @ 0x55b5bae53680] mmco: unref short failure
 45%|████▌     | 1312/2910 [8:15:37<3:13:03,  7.25s/it] 45%|████▌     | 1313/2910 [8:15:43<2:58:49,  6.72s/it][h264 @ 0x55b5ab855080] mmco: unref short failure
[h264 @ 0x55b5ab855080] mmco: unref short failure
[h264 @ 0x55b5ab855080] mmco: unref short failure
[h264 @ 0x55b5ab855080] mmco: unref short failure
 45%|████▌     | 1314/2910 [8:15:47<2:42:10,  6.10s/it][h264 @ 0x55e2373a0780] mmco: unref short failure
[h264 @ 0x55e2373a0780] mmco: unref short failure
 45%|████▌     | 1315/2910 [8:15:53<2:35:10,  5.84s/it][h264 @ 0x55e245a2afc0] mmco: unref short failure
[h264 @ 0x55b5af980140] mmco: unref short failure
[h264 @ 0x55b5af980140] mmco: unref short failure
[h264 @ 0x55b5af980140] mmco: unref short failure
[h264 @ 0x55b5af980140] mmco: unref short failure
[h264 @ 0x55e250e519c0] mmco: unref short failure
[h264 @ 0x55e250e519c0] mmco: unref short failure
[h264 @ 0x56074171df80] mmco: unref short failure
[h264 @ 0x56074171df80] mmco: unref short failure
[h264 @ 0x56074171df80] mmco: unref short failure
[h264 @ 0x56074171df80] mmco: unref short failure
[h264 @ 0x55a32e77b9c0] mmco: unref short failure
[h264 @ 0x560764f13c40] mmco: unref short failure
[h264 @ 0x560764f13c40] mmco: unref short failure
[h264 @ 0x55a30f781580] mmco: unref short failure
[h264 @ 0x55a30f781580] mmco: unref short failure
[h264 @ 0x5607424c6900] mmco: unref short failure
[h264 @ 0x5607424c6900] mmco: unref short failure
[h264 @ 0x55b5c9d505c0] mmco: unref short failure
[h264 @ 0x55b5c9d505c0] mmco: unref short failure
[h264 @ 0x55e24e1718c0] mmco: unref short failure
[h264 @ 0x55e24e1718c0] mmco: unref short failure
 45%|████▌     | 1316/2910 [8:16:47<9:02:05, 20.40s/it][h264 @ 0x56074178bdc0] mmco: unref short failure
[h264 @ 0x55b5c55ab1c0] mmco: unref short failure
 45%|████▌     | 1317/2910 [8:17:04<8:32:34, 19.31s/it][h264 @ 0x55e250e51c40] mmco: unref short failure
[h264 @ 0x55e250e51c40] mmco: unref short failure
 45%|████▌     | 1318/2910 [8:17:09<6:39:50, 15.07s/it][h264 @ 0x55b5c55ab1c0] mmco: unref short failure
[h264 @ 0x55b5c55ab1c0] mmco: unref short failure
 45%|████▌     | 1319/2910 [8:17:15<5:25:11, 12.26s/it][h264 @ 0x55e2552bfcc0] mmco: unref short failure
[h264 @ 0x55e2552bfcc0] mmco: unref short failure
[h264 @ 0x55b5aa71d600] mmco: unref short failure
[h264 @ 0x55a30ede5380] mmco: unref short failure
 45%|████▌     | 1320/2910 [8:17:22<4:43:53, 10.71s/it][h264 @ 0x5607417f5980] mmco: unref short failure
[h264 @ 0x5607417f5980] mmco: unref short failure
[h264 @ 0x55e2380182c0] mmco: unref short failure
 45%|████▌     | 1321/2910 [8:17:33<4:44:31, 10.74s/it][h264 @ 0x560764041e80] mmco: unref short failure
[h264 @ 0x560764041e80] mmco: unref short failure
[h264 @ 0x5607417248c0] mmco: unref short failure
 45%|████▌     | 1322/2910 [8:17:38<4:02:17,  9.15s/it][h264 @ 0x56075ec7ea40] mmco: unref short failure
[h264 @ 0x56075ec7ea40] mmco: unref short failure
 45%|████▌     | 1323/2910 [8:17:48<4:09:35,  9.44s/it][h264 @ 0x55a31758b5c0] mmco: unref short failure
[h264 @ 0x55a31758b5c0] mmco: unref short failure
[h264 @ 0x55e2458bb380] mmco: unref short failure
[h264 @ 0x55b5cab96dc0] mmco: unref short failure
[h264 @ 0x560741924ac0] mmco: unref short failure
[h264 @ 0x56074361e740] mmco: unref short failure
[h264 @ 0x56074361e740] mmco: unref short failure
[h264 @ 0x55e249bf9b80] mmco: unref short failure
[h264 @ 0x55e249bf9b80] mmco: unref short failure
[h264 @ 0x55e23676f5c0] mmco: unref short failure
[h264 @ 0x55e23676f5c0] mmco: unref short failure
[h264 @ 0x560748a8ecc0] mmco: unref short failure
[h264 @ 0x56074eb49000] mmco: unref short failure
[h264 @ 0x56074eb49000] mmco: unref short failure
09/17/2024 07:40:46 - INFO - __main__ -   current idx -Gh2S5bmJFk.26 from finetune_area returns wrong image/video, use 4411 instead.
[h264 @ 0x560762a63ac0] mmco: unref short failure
srun: Job step aborted: Waiting up to 92 seconds for job step to finish.
slurmstepd: error: *** JOB 7731831 ON lrdn1006 CANCELLED AT 2024-09-17T07:40:47 ***
