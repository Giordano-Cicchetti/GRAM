NODELIST=lrdn2361
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2031



DEVICE SET
DEVICE SET
DEVICE SET
DEVICE SET
09/17/2024 15:14:25 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 2
09/17/2024 15:14:25 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 1
09/17/2024 15:14:25 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 3
09/17/2024 15:14:25 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 0
09/17/2024 15:14:25 - INFO - torch.distributed.distributed_c10d -   Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
09/17/2024 15:14:25 - INFO - torch.distributed.distributed_c10d -   Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
09/17/2024 15:14:25 - INFO - torch.distributed.distributed_c10d -   Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
09/17/2024 15:14:25 - INFO - torch.distributed.distributed_c10d -   Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
09/17/2024 15:14:25 - INFO - __main__ -   ==================model_configs==================

09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_model_type : vast
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_itm_ratio : 0.1
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_frozen_vision : False
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_frozen_audio : False
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_checkpointing : True
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_max_caption_len : 40
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_max_omni_caption_len : 70
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_max_subtitle_len : 70
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_contra_dim : 512
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_inherit_keys : ['vision_encoder_type', 'audio_encoder_type', 'audio_melbins', 'audio_target_length']
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_frame_embedding_type : adaptive
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_vision_resolution : 224
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_vision_encoder_type : evaclip01_giant
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_audio_encoder_type : beats
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_audio_melbins : 64
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_audio_target_length : 1024
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_beam_size : 3
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_captioner_mode : False
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_generate_nums : 1
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_ret_bidirection_evaluation : False
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_itm_rerank_num : 50
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_evaluation_type : evaluation_mm
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_default : ./config/vast/default_model_cfg.json
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_max_vision_sample_num : 8
09/17/2024 15:14:25 - INFO - __main__ -   model_cfg_max_audio_sample_num : 1
09/17/2024 15:14:25 - INFO - __main__ -   ==================run_configs==================

09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_checkpoint : ./output/vast/pretrain_vast/downstream/finetuneVolume256batchlossonlyvolume4Mod120k/ckpt/best_ret%tva--msrvtt_ret_ret_itm_area.pt
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_output_dir : ./output/vast/pretrain_vast//downstream/finetuneMSRVTT
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_gradient_accumulation_steps : 1
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_clip_lr : 5e-07
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_optim : adamw
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_learning_rate : 2e-05
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_betas : [0.9, 0.98]
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_weight_decay : 0.01
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_grad_norm : 2.0
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_warmup_ratio : 0.1
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_resume : False
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_seed : 50
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_fp16 : True
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_bf16 : False
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_zero_shot : False
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_scheduler : warmup_linear
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_new_lr : 0
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_new_params_name : []
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_valid_freq : 10
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_dataset_mix_type : random
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_remove_before_ckpt : True
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_first_eval : True
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_pretrain_dir : ./output/vast/pretrain_vast/downstream/finetuneVolume256batchlossonlyvolume4Mod120k
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_num_train_steps : 0
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_save_best : True
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_pin_mem : True
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_vision_resolution : 224
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_use_ddp : False
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_mode : training
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_log_steps : 100
09/17/2024 15:14:25 - INFO - __main__ -   run_cfg_default : ./config/vast/default_run_cfg.json
09/17/2024 15:14:25 - INFO - __main__ -   ==================data_configs==================

09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_train_type : annoindexed
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_train_training : True
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_train_name : msrvtt_ret
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_train_txt : datasets/annotations/msrvtt/descs_ret_train.json
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_train_vision : ../MSRVTT/videos/videos
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_train_audio : ../MSRVTT/audios
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_train_vision_transforms : crop_flip
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_train_vision_format : video_rawvideo
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_train_vision_sample_num : 8
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_train_audio_sample_num : 1
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_train_task : ret%tv%ta
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_train_epoch : 3
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_train_n_workers : 8
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_train_batch_size : 64
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_val_type : annoindexed
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_val_training : False
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_val_name : msrvtt_ret
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_val_txt : datasets/annotations/msrvtt/descs_ret_test.json
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_val_vision : ../MSRVTT/video_test
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_val_vision_transforms : crop_flip
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_val_vision_format : video_rawvideo
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_val_audio : ../MSRVTT/audio_test
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_val_vision_sample_num : 8
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_val_audio_sample_num : 1
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_val_task : ret%tvas
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_val_n_workers : 8
09/17/2024 15:14:25 - INFO - __main__ -   data_cfg_msrvtt_ret_val_batch_size : 64
wandb: Tracking run with wandb version 0.17.8
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
09/17/2024 15:14:29 - INFO - __main__ -   msrvtt_ret Using clip mean and std.
09/17/2024 15:14:29 - INFO - __main__ -   msrvtt_ret transforms crop_flip
ci sono 158540 labels
ci sono 158540 labels
ci sono 158540 labels
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
ci sono 884 labelsci sono 884 labels
ci sono 884 labels

/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Please 'pip install xformers'
Please 'pip install xformers'
Please 'pip install xformers'
Please 'pip install xformers'Please 'pip install xformers'

Please 'pip install xformers'
Please 'pip install xformers'Please 'pip install xformers'

Please 'pip install xformers'
09/17/2024 15:14:35 - INFO - root -   Loaded EVA01-CLIP-g-14 model config.
09/17/2024 15:14:35 - INFO - root -   Loaded EVA01-CLIP-g-14 model config.
09/17/2024 15:14:35 - INFO - root -   Loaded EVA01-CLIP-g-14 model config.
ci sono 158540 labels
09/17/2024 15:14:35 - INFO - __main__ -   Create Dataset msrvtt_ret Success
09/17/2024 15:14:35 - INFO - __main__ -    loader ret%tv%ta--msrvtt_ret , ratio 7431 , bs_pergpu 16, n_workers 8
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
09/17/2024 15:14:37 - INFO - __main__ -   msrvtt_ret Using clip mean and std.
09/17/2024 15:14:37 - INFO - __main__ -   msrvtt_ret transforms crop_flip
ci sono 884 labels
09/17/2024 15:14:37 - INFO - __main__ -   Create Dataset msrvtt_ret Success
Please 'pip install xformers'
Please 'pip install xformers'
Please 'pip install xformers'
09/17/2024 15:14:39 - INFO - root -   Loaded EVA01-CLIP-g-14 model config.
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
09/17/2024 15:15:38 - INFO - root -   Loading pretrained EVA01-CLIP-g-14 weights (./pretrained_weights/clip/EVA01_CLIP_g_14_psz14_s11B.pt).
09/17/2024 15:15:38 - INFO - root -   Loading pretrained EVA01-CLIP-g-14 weights (./pretrained_weights/clip/EVA01_CLIP_g_14_psz14_s11B.pt).
09/17/2024 15:15:38 - INFO - root -   Loading pretrained EVA01-CLIP-g-14 weights (./pretrained_weights/clip/EVA01_CLIP_g_14_psz14_s11B.pt).
09/17/2024 15:15:40 - INFO - root -   incompatible_keys.missing_keys: []
09/17/2024 15:15:40 - INFO - root -   incompatible_keys.missing_keys: []
09/17/2024 15:15:40 - INFO - root -   incompatible_keys.missing_keys: []
09/17/2024 15:15:41 - INFO - root -   Loading pretrained EVA01-CLIP-g-14 weights (./pretrained_weights/clip/EVA01_CLIP_g_14_psz14_s11B.pt).
09/17/2024 15:15:41 - INFO - model.audio_encoders.beats.beats -   BEATs Config: {'input_patch_size': 16, 'embed_dim': 512, 'conv_bias': False, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_wise_gradient_decay_ratio': 1.0, 'layer_norm_first': False, 'deep_norm': True, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True, 'finetuned_model': False, 'predictor_dropout': 0.1, 'predictor_class': 527}
09/17/2024 15:15:41 - INFO - model.audio_encoders.beats.beats -   BEATs Config: {'input_patch_size': 16, 'embed_dim': 512, 'conv_bias': False, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_wise_gradient_decay_ratio': 1.0, 'layer_norm_first': False, 'deep_norm': True, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True, 'finetuned_model': False, 'predictor_dropout': 0.1, 'predictor_class': 527}
09/17/2024 15:15:41 - INFO - model.audio_encoders.beats.beats -   BEATs Config: {'input_patch_size': 16, 'embed_dim': 512, 'conv_bias': False, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_wise_gradient_decay_ratio': 1.0, 'layer_norm_first': False, 'deep_norm': True, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True, 'finetuned_model': False, 'predictor_dropout': 0.1, 'predictor_class': 527}
09/17/2024 15:15:42 - INFO - root -   incompatible_keys.missing_keys: []
09/17/2024 15:15:43 - INFO - model.audio_encoders.beats.beats -   BEATs Config: {'input_patch_size': 16, 'embed_dim': 512, 'conv_bias': False, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_wise_gradient_decay_ratio': 1.0, 'layer_norm_first': False, 'deep_norm': True, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True, 'finetuned_model': False, 'predictor_dropout': 0.1, 'predictor_class': 527}
09/17/2024 15:15:43 - WARNING - model.text_encoders.bert.bert -   If you want to use `BertForMaskedLM` make sure `config.is_decoder=False` for bi-directional self-attention.
09/17/2024 15:15:43 - WARNING - model.text_encoders.bert.bert -   If you want to use `BertForMaskedLM` make sure `config.is_decoder=False` for bi-directional self-attention.
09/17/2024 15:15:43 - WARNING - model.text_encoders.bert.bert -   If you want to use `BertForMaskedLM` make sure `config.is_decoder=False` for bi-directional self-attention.
Some weights of BertForMaskedLM were not initialized from the model checkpoint at ./pretrained_weights/bert/bert-base-uncased and are newly initialized: ['encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.value.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'cls.predictions.bias', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.value.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.query.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertForMaskedLM were not initialized from the model checkpoint at ./pretrained_weights/bert/bert-base-uncased and are newly initialized: ['encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.key.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.key.weight', 'cls.predictions.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.7.crossattention.self.key.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of BertForMaskedLM were not initialized from the model checkpoint at ./pretrained_weights/bert/bert-base-uncased and are newly initialized: ['encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.value.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.key.weight', 'cls.predictions.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.value.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Traceback (most recent call last):
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_model.py", line 73, in load_from_pretrained_dir
    step = checkpoint_ls[-1]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/./run.py", line 81, in <module>
    main()
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/./run.py", line 50, in main
    model, optimizer_ckpt, start_step = build_model(args)
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_model.py", line 26, in build_model
    checkpoint = load_from_pretrained_dir(args)
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_model.py", line 94, in load_from_pretrained_dir
    step = checkpoint_ls[-1]
IndexError: list index out of range
Traceback (most recent call last):
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_model.py", line 73, in load_from_pretrained_dir
    step = checkpoint_ls[-1]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/./run.py", line 81, in <module>
    main()
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/./run.py", line 50, in main
    model, optimizer_ckpt, start_step = build_model(args)
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_model.py", line 26, in build_model
    checkpoint = load_from_pretrained_dir(args)
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_model.py", line 94, in load_from_pretrained_dir
    step = checkpoint_ls[-1]
IndexError: list index out of range
Traceback (most recent call last):
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_model.py", line 73, in load_from_pretrained_dir
    step = checkpoint_ls[-1]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/./run.py", line 81, in <module>
    main()
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/./run.py", line 50, in main
    model, optimizer_ckpt, start_step = build_model(args)
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_model.py", line 26, in build_model
    checkpoint = load_from_pretrained_dir(args)
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_model.py", line 94, in load_from_pretrained_dir
    step = checkpoint_ls[-1]
IndexError: list index out of range
09/17/2024 15:15:44 - WARNING - model.text_encoders.bert.bert -   If you want to use `BertForMaskedLM` make sure `config.is_decoder=False` for bi-directional self-attention.
Some weights of BertForMaskedLM were not initialized from the model checkpoint at ./pretrained_weights/bert/bert-base-uncased and are newly initialized: ['encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.value.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.11.crossattention.output.dense.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'cls.predictions.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.key.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.7.crossattention.self.value.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Traceback (most recent call last):
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_model.py", line 73, in load_from_pretrained_dir
    step = checkpoint_ls[-1]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/./run.py", line 81, in <module>
    main()
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/./run.py", line 50, in main
    model, optimizer_ckpt, start_step = build_model(args)
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_model.py", line 26, in build_model
    checkpoint = load_from_pretrained_dir(args)
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_model.py", line 94, in load_from_pretrained_dir
    step = checkpoint_ls[-1]
IndexError: list index out of range
Traceback (most recent call last):
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_model.py", line 73, in load_from_pretrained_dir
    step = checkpoint_ls[-1]
IndexError: list index out of range

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/./run.py", line 81, in <module>
    main()
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/./run.py", line 50, in main
    model, optimizer_ckpt, start_step = build_model(args)
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_model.py", line 26, in build_model
    checkpoint = load_from_pretrained_dir(args)
  File "/leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/utils/build_model.py", line 94, in load_from_pretrained_dir
    step = checkpoint_ls[-1]
IndexError: list index out of range
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /leonardo_scratch/fast/IscrC_GenOpt/giordano/VAST/wandb/offline-run-20240917_151426-hkiuii1u
wandb: Find logs at: ./wandb/offline-run-20240917_151426-hkiuii1u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
09/17/2024 15:15:48 - WARNING - urllib3.connectionpool -   Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x15254ece61f0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
09/17/2024 15:15:48 - WARNING - urllib3.connectionpool -   Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x15254ece7c70>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /api/4504800232407040/envelope/
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1039871 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 1 (pid: 1039872) of binary: /leonardo/home/userexternal/gcicchet/.conda/envs/vast/bin/python3
Traceback (most recent call last):
  File "/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torch/distributed/launch.py", line 196, in <module>
    main()
  File "/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torch/distributed/launch.py", line 192, in main
    launch(args)
  File "/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torch/distributed/launch.py", line 177, in launch
    run(args)
  File "/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/leonardo/home/userexternal/gcicchet/.conda/envs/vast/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
./run.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-09-17_15:15:50
  host      : lrdn2361.leonardo.local
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 1039873)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-09-17_15:15:50
  host      : lrdn2361-net7-3.leonardo.local
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 1039874)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-09-17_15:15:50
  host      : lrdn2361.leonardo.local
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 1039872)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
srun: error: lrdn2361: task 0: Exited with exit code 1
